{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46bdd32c-9b9a-4769-8ba5-7fb16ab1a178",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "\n",
      "### Running SGD with lr=0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (/home/aradilla/.cache/huggingface/datasets/sapientinc___csv/sapientinc--sudoku-extreme-798989c95bd556dd/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n",
      "Found cached dataset csv (/home/aradilla/.cache/huggingface/datasets/sapientinc___csv/sapientinc--sudoku-extreme-798989c95bd556dd/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SGD | lr=0.1] Epoch 1/4000: train_loss=2.2917  test_loss=2.2401  λ_max=4.4451\n",
      "[SGD | lr=0.1] Epoch 2/4000: train_loss=2.2215  test_loss=2.2118  λ_max=3.5454\n",
      "[SGD | lr=0.1] Epoch 3/4000: train_loss=2.2029  test_loss=2.2047  λ_max=3.0534\n",
      "[SGD | lr=0.1] Epoch 4/4000: train_loss=2.1968  test_loss=2.2021  λ_max=2.8718\n",
      "[SGD | lr=0.1] Epoch 5/4000: train_loss=2.1932  test_loss=2.2006  λ_max=2.7883\n",
      "[SGD | lr=0.1] Epoch 6/4000: train_loss=2.1905  test_loss=2.2004  λ_max=2.5958\n",
      "[SGD | lr=0.1] Iter 100: loss=2.1924\n",
      "[SGD | lr=0.1] Epoch 7/4000: train_loss=2.1879  test_loss=2.1991  λ_max=2.6631\n",
      "[SGD | lr=0.1] Epoch 8/4000: train_loss=2.1856  test_loss=2.1990  λ_max=2.7599\n",
      "[SGD | lr=0.1] Epoch 9/4000: train_loss=2.1831  test_loss=2.1980  λ_max=2.8232\n",
      "[SGD | lr=0.1] Epoch 10/4000: train_loss=2.1806  test_loss=2.1983  λ_max=2.8252\n",
      "[SGD | lr=0.1] Epoch 11/4000: train_loss=2.1778  test_loss=2.1973  λ_max=3.0556\n",
      "[SGD | lr=0.1] Epoch 12/4000: train_loss=2.1749  test_loss=2.1972  λ_max=3.2789\n",
      "[SGD | lr=0.1] Iter 200: loss=2.1730\n",
      "[SGD | lr=0.1] Epoch 13/4000: train_loss=2.1712  test_loss=2.1975  λ_max=3.3700\n",
      "[SGD | lr=0.1] Epoch 14/4000: train_loss=2.1672  test_loss=2.1976  λ_max=3.7686\n",
      "[SGD | lr=0.1] Epoch 15/4000: train_loss=2.1625  test_loss=2.1983  λ_max=3.9926\n",
      "[SGD | lr=0.1] Epoch 16/4000: train_loss=2.1569  test_loss=2.1986  λ_max=4.6060\n",
      "[SGD | lr=0.1] Epoch 17/4000: train_loss=2.1505  test_loss=2.1990  λ_max=4.7344\n",
      "[SGD | lr=0.1] Epoch 18/4000: train_loss=2.1432  test_loss=2.2001  λ_max=5.4524\n",
      "[SGD | lr=0.1] Iter 300: loss=2.1308\n",
      "[SGD | lr=0.1] Epoch 19/4000: train_loss=2.1348  test_loss=2.2013  λ_max=5.8205\n",
      "[SGD | lr=0.1] Epoch 20/4000: train_loss=2.1250  test_loss=2.2024  λ_max=6.4416\n",
      "[SGD | lr=0.1] Epoch 21/4000: train_loss=2.1146  test_loss=2.2034  λ_max=6.6956\n",
      "[SGD | lr=0.1] Epoch 22/4000: train_loss=2.1032  test_loss=2.2026  λ_max=7.6824\n",
      "[SGD | lr=0.1] Epoch 23/4000: train_loss=2.0904  test_loss=2.2039  λ_max=8.3647\n",
      "[SGD | lr=0.1] Epoch 24/4000: train_loss=2.0769  test_loss=2.2042  λ_max=8.9276\n",
      "[SGD | lr=0.1] Iter 400: loss=2.0650\n",
      "[SGD | lr=0.1] Epoch 25/4000: train_loss=2.0632  test_loss=2.2032  λ_max=9.4766\n",
      "[SGD | lr=0.1] Epoch 26/4000: train_loss=2.0486  test_loss=2.2011  λ_max=9.1795\n",
      "[SGD | lr=0.1] Epoch 27/4000: train_loss=2.0340  test_loss=2.1988  λ_max=9.5921\n",
      "[SGD | lr=0.1] Epoch 28/4000: train_loss=2.0194  test_loss=2.1978  λ_max=9.9047\n",
      "[SGD | lr=0.1] Epoch 29/4000: train_loss=2.0047  test_loss=2.1944  λ_max=10.5597\n",
      "[SGD | lr=0.1] Epoch 30/4000: train_loss=1.9908  test_loss=2.1915  λ_max=11.3246\n",
      "[SGD | lr=0.1] Epoch 31/4000: train_loss=1.9762  test_loss=2.1874  λ_max=11.4256\n",
      "[SGD | lr=0.1] Iter 500: loss=1.9720\n",
      "[SGD | lr=0.1] Epoch 32/4000: train_loss=1.9627  test_loss=2.1847  λ_max=11.5105\n",
      "[SGD | lr=0.1] Epoch 33/4000: train_loss=1.9481  test_loss=2.1853  λ_max=11.2853\n",
      "[SGD | lr=0.1] Epoch 34/4000: train_loss=1.9347  test_loss=2.1803  λ_max=12.3943\n",
      "[SGD | lr=0.1] Epoch 35/4000: train_loss=1.9261  test_loss=2.1749  λ_max=12.3567\n",
      "[SGD | lr=0.1] Epoch 36/4000: train_loss=1.9097  test_loss=2.1745  λ_max=12.5652\n",
      "[SGD | lr=0.1] Epoch 37/4000: train_loss=1.9016  test_loss=2.1706  λ_max=11.4008\n",
      "[SGD | lr=0.1] Iter 600: loss=1.8766\n",
      "[SGD | lr=0.1] Epoch 38/4000: train_loss=1.8878  test_loss=2.1707  λ_max=12.8474\n",
      "[SGD | lr=0.1] Epoch 39/4000: train_loss=1.8781  test_loss=2.1714  λ_max=12.5945\n",
      "[SGD | lr=0.1] Epoch 40/4000: train_loss=1.8656  test_loss=2.1666  λ_max=12.9021\n",
      "[SGD | lr=0.1] Epoch 41/4000: train_loss=1.8536  test_loss=2.1628  λ_max=12.6261\n",
      "[SGD | lr=0.1] Epoch 42/4000: train_loss=1.8449  test_loss=2.1653  λ_max=12.5783\n",
      "[SGD | lr=0.1] Epoch 43/4000: train_loss=1.8343  test_loss=2.1580  λ_max=13.4958\n",
      "[SGD | lr=0.1] Iter 700: loss=1.8177\n",
      "[SGD | lr=0.1] Epoch 44/4000: train_loss=1.8219  test_loss=2.1559  λ_max=12.6269\n",
      "[SGD | lr=0.1] Epoch 45/4000: train_loss=1.8128  test_loss=2.1599  λ_max=12.6111\n",
      "[SGD | lr=0.1] Epoch 46/4000: train_loss=1.8043  test_loss=2.1540  λ_max=13.6254\n",
      "[SGD | lr=0.1] Epoch 47/4000: train_loss=1.7937  test_loss=2.1530  λ_max=13.3896\n",
      "[SGD | lr=0.1] Epoch 48/4000: train_loss=1.7817  test_loss=2.1517  λ_max=12.7480\n",
      "[SGD | lr=0.1] Epoch 49/4000: train_loss=1.7720  test_loss=2.1497  λ_max=12.8195\n",
      "[SGD | lr=0.1] Iter 800: loss=1.7528\n",
      "[SGD | lr=0.1] Epoch 50/4000: train_loss=1.7622  test_loss=2.1435  λ_max=13.6777\n",
      "[SGD | lr=0.1] Epoch 51/4000: train_loss=1.7512  test_loss=2.1445  λ_max=13.5351\n",
      "[SGD | lr=0.1] Epoch 52/4000: train_loss=1.7457  test_loss=2.1415  λ_max=13.4860\n",
      "[SGD | lr=0.1] Epoch 53/4000: train_loss=1.7342  test_loss=2.1434  λ_max=13.2296\n",
      "[SGD | lr=0.1] Epoch 54/4000: train_loss=1.7249  test_loss=2.1389  λ_max=13.8925\n",
      "[SGD | lr=0.1] Epoch 55/4000: train_loss=1.7181  test_loss=2.1363  λ_max=14.0600\n",
      "[SGD | lr=0.1] Epoch 56/4000: train_loss=1.7064  test_loss=2.1356  λ_max=13.4405\n",
      "[SGD | lr=0.1] Iter 900: loss=1.6931\n",
      "[SGD | lr=0.1] Epoch 57/4000: train_loss=1.6987  test_loss=2.1337  λ_max=14.2313\n",
      "[SGD | lr=0.1] Epoch 58/4000: train_loss=1.6889  test_loss=2.1363  λ_max=13.9741\n",
      "[SGD | lr=0.1] Epoch 59/4000: train_loss=1.6822  test_loss=2.1326  λ_max=13.8243\n",
      "[SGD | lr=0.1] Epoch 60/4000: train_loss=1.6748  test_loss=2.1329  λ_max=13.9223\n",
      "[SGD | lr=0.1] Epoch 61/4000: train_loss=1.6634  test_loss=2.1331  λ_max=13.8148\n",
      "[SGD | lr=0.1] Epoch 62/4000: train_loss=1.6539  test_loss=2.1324  λ_max=13.4053\n",
      "[SGD | lr=0.1] Iter 1000: loss=1.6338\n",
      "[SGD | lr=0.1] Epoch 63/4000: train_loss=1.6429  test_loss=2.1258  λ_max=14.4400\n",
      "[SGD | lr=0.1] Epoch 64/4000: train_loss=1.6317  test_loss=2.1252  λ_max=14.8034\n",
      "[SGD | lr=0.1] Epoch 65/4000: train_loss=1.6284  test_loss=2.1258  λ_max=15.1913\n",
      "[SGD | lr=0.1] Epoch 66/4000: train_loss=1.6202  test_loss=2.1255  λ_max=14.2169\n",
      "[SGD | lr=0.1] Epoch 67/4000: train_loss=1.6099  test_loss=2.1214  λ_max=14.9525\n",
      "[SGD | lr=0.1] Epoch 68/4000: train_loss=1.6033  test_loss=2.1272  λ_max=15.1576\n",
      "[SGD | lr=0.1] Iter 1100: loss=1.5821\n",
      "[SGD | lr=0.1] Epoch 69/4000: train_loss=1.5924  test_loss=2.1234  λ_max=15.6205\n",
      "[SGD | lr=0.1] Epoch 70/4000: train_loss=1.5850  test_loss=2.1173  λ_max=16.1908\n",
      "[SGD | lr=0.1] Epoch 71/4000: train_loss=1.5787  test_loss=2.1209  λ_max=15.3632\n",
      "[SGD | lr=0.1] Epoch 72/4000: train_loss=1.5699  test_loss=2.1224  λ_max=15.7033\n",
      "[SGD | lr=0.1] Epoch 73/4000: train_loss=1.5606  test_loss=2.1250  λ_max=15.3622\n",
      "[SGD | lr=0.1] Epoch 74/4000: train_loss=1.5506  test_loss=2.1182  λ_max=14.8543\n",
      "[SGD | lr=0.1] Iter 1200: loss=1.5383\n",
      "[SGD | lr=0.1] Epoch 75/4000: train_loss=1.5422  test_loss=2.1128  λ_max=15.7420\n",
      "[SGD | lr=0.1] Epoch 76/4000: train_loss=1.5386  test_loss=2.1202  λ_max=15.3881\n",
      "[SGD | lr=0.1] Epoch 77/4000: train_loss=1.5266  test_loss=2.1150  λ_max=15.9507\n",
      "[SGD | lr=0.1] Epoch 78/4000: train_loss=1.5191  test_loss=2.1140  λ_max=15.9175\n",
      "[SGD | lr=0.1] Epoch 79/4000: train_loss=1.5097  test_loss=2.1194  λ_max=16.0555\n",
      "[SGD | lr=0.1] Epoch 80/4000: train_loss=1.5086  test_loss=2.1140  λ_max=16.5372\n",
      "[SGD | lr=0.1] Epoch 81/4000: train_loss=1.4935  test_loss=2.1122  λ_max=16.4742\n",
      "[SGD | lr=0.1] Iter 1300: loss=1.4824\n",
      "[SGD | lr=0.1] Epoch 82/4000: train_loss=1.4896  test_loss=2.1065  λ_max=16.2738\n",
      "[SGD | lr=0.1] Epoch 83/4000: train_loss=1.4832  test_loss=2.1148  λ_max=16.3896\n",
      "[SGD | lr=0.1] Epoch 84/4000: train_loss=1.4752  test_loss=2.1176  λ_max=16.4289\n",
      "[SGD | lr=0.1] Epoch 85/4000: train_loss=1.4688  test_loss=2.1083  λ_max=16.4231\n",
      "[SGD | lr=0.1] Epoch 86/4000: train_loss=1.4555  test_loss=2.1095  λ_max=16.6207\n",
      "[SGD | lr=0.1] Epoch 87/4000: train_loss=1.4528  test_loss=2.1115  λ_max=15.7653\n",
      "[SGD | lr=0.1] Iter 1400: loss=1.4373\n",
      "[SGD | lr=0.1] Epoch 88/4000: train_loss=1.4415  test_loss=2.1094  λ_max=16.1462\n",
      "[SGD | lr=0.1] Epoch 89/4000: train_loss=1.4364  test_loss=2.1026  λ_max=16.9107\n",
      "[SGD | lr=0.1] Epoch 90/4000: train_loss=1.4213  test_loss=2.1104  λ_max=16.3075\n",
      "[SGD | lr=0.1] Epoch 91/4000: train_loss=1.4200  test_loss=2.1079  λ_max=16.1138\n",
      "[SGD | lr=0.1] Epoch 92/4000: train_loss=1.4114  test_loss=2.1102  λ_max=17.2255\n",
      "[SGD | lr=0.1] Epoch 93/4000: train_loss=1.3996  test_loss=2.1111  λ_max=16.6139\n",
      "[SGD | lr=0.1] Iter 1500: loss=1.4001\n",
      "[SGD | lr=0.1] Epoch 94/4000: train_loss=1.3960  test_loss=2.1011  λ_max=17.4265\n",
      "[SGD | lr=0.1] Epoch 95/4000: train_loss=1.3828  test_loss=2.1078  λ_max=16.7777\n",
      "[SGD | lr=0.1] Epoch 96/4000: train_loss=1.3854  test_loss=2.1070  λ_max=17.4220\n",
      "[SGD | lr=0.1] Epoch 97/4000: train_loss=1.3724  test_loss=2.1057  λ_max=17.1990\n",
      "[SGD | lr=0.1] Epoch 98/4000: train_loss=1.3679  test_loss=2.1114  λ_max=16.5626\n",
      "[SGD | lr=0.1] Epoch 99/4000: train_loss=1.3584  test_loss=2.1063  λ_max=16.9731\n",
      "[SGD | lr=0.1] Iter 1600: loss=1.3611\n",
      "[SGD | lr=0.1] Epoch 100/4000: train_loss=1.3557  test_loss=2.1050  λ_max=17.5983\n",
      "[SGD | lr=0.1] Epoch 101/4000: train_loss=1.3491  test_loss=2.1028  λ_max=17.3641\n",
      "[SGD | lr=0.1] Epoch 102/4000: train_loss=1.3354  test_loss=2.1052  λ_max=17.6567\n",
      "[SGD | lr=0.1] Epoch 103/4000: train_loss=1.3296  test_loss=2.1098  λ_max=16.8978\n",
      "[SGD | lr=0.1] Epoch 104/4000: train_loss=1.3231  test_loss=2.1100  λ_max=17.4716\n",
      "[SGD | lr=0.1] Epoch 105/4000: train_loss=1.3181  test_loss=2.1061  λ_max=17.7546\n",
      "[SGD | lr=0.1] Epoch 106/4000: train_loss=1.3076  test_loss=2.1065  λ_max=17.1028\n",
      "[SGD | lr=0.1] Iter 1700: loss=1.2944\n",
      "[SGD | lr=0.1] Epoch 107/4000: train_loss=1.2958  test_loss=2.1126  λ_max=17.2899\n",
      "[SGD | lr=0.1] Epoch 108/4000: train_loss=1.2917  test_loss=2.1122  λ_max=17.8960\n",
      "[SGD | lr=0.1] Epoch 109/4000: train_loss=1.2909  test_loss=2.1160  λ_max=17.6736\n",
      "[SGD | lr=0.1] Epoch 110/4000: train_loss=1.2784  test_loss=2.1125  λ_max=18.6268\n",
      "[SGD | lr=0.1] Epoch 111/4000: train_loss=1.2706  test_loss=2.1054  λ_max=18.2367\n",
      "[SGD | lr=0.1] Epoch 112/4000: train_loss=1.2623  test_loss=2.1003  λ_max=18.0782\n",
      "[SGD | lr=0.1] Iter 1800: loss=1.2642\n",
      "[SGD | lr=0.1] Epoch 113/4000: train_loss=1.2546  test_loss=2.1084  λ_max=18.9340\n",
      "[SGD | lr=0.1] Epoch 114/4000: train_loss=1.2538  test_loss=2.1114  λ_max=19.0070\n",
      "[SGD | lr=0.1] Epoch 115/4000: train_loss=1.2436  test_loss=2.1103  λ_max=19.9723\n",
      "[SGD | lr=0.1] Epoch 116/4000: train_loss=1.2416  test_loss=2.1091  λ_max=19.8156\n",
      "[SGD | lr=0.1] Epoch 117/4000: train_loss=1.2315  test_loss=2.1029  λ_max=19.2451\n",
      "[SGD | lr=0.1] Epoch 118/4000: train_loss=1.2243  test_loss=2.1153  λ_max=18.9202\n",
      "[SGD | lr=0.1] Iter 1900: loss=1.2109\n",
      "[SGD | lr=0.1] Epoch 119/4000: train_loss=1.2159  test_loss=2.1074  λ_max=17.8866\n",
      "[SGD | lr=0.1] Epoch 120/4000: train_loss=1.2071  test_loss=2.1112  λ_max=19.0617\n",
      "[SGD | lr=0.1] Epoch 121/4000: train_loss=1.2019  test_loss=2.1084  λ_max=19.5965\n",
      "[SGD | lr=0.1] Epoch 122/4000: train_loss=1.1997  test_loss=2.1113  λ_max=18.0921\n",
      "[SGD | lr=0.1] Epoch 123/4000: train_loss=1.1836  test_loss=2.1070  λ_max=18.4138\n",
      "[SGD | lr=0.1] Epoch 124/4000: train_loss=1.1816  test_loss=2.1135  λ_max=18.7456\n",
      "[SGD | lr=0.1] Iter 2000: loss=1.1687\n",
      "[SGD | lr=0.1] Epoch 125/4000: train_loss=1.1727  test_loss=2.1200  λ_max=19.6629\n",
      "[SGD | lr=0.1] Epoch 126/4000: train_loss=1.1700  test_loss=2.1129  λ_max=18.6329\n",
      "[SGD | lr=0.1] Epoch 127/4000: train_loss=1.1587  test_loss=2.1191  λ_max=18.1272\n",
      "[SGD | lr=0.1] Epoch 128/4000: train_loss=1.1545  test_loss=2.1156  λ_max=17.8942\n",
      "[SGD | lr=0.1] Epoch 129/4000: train_loss=1.1456  test_loss=2.1238  λ_max=19.0139\n",
      "[SGD | lr=0.1] Epoch 130/4000: train_loss=1.1368  test_loss=2.1228  λ_max=19.8557\n",
      "[SGD | lr=0.1] Epoch 131/4000: train_loss=1.1382  test_loss=2.1171  λ_max=18.7101\n",
      "[SGD | lr=0.1] Iter 2100: loss=1.1302\n",
      "[SGD | lr=0.1] Epoch 132/4000: train_loss=1.1286  test_loss=2.1131  λ_max=18.9235\n",
      "[SGD | lr=0.1] Epoch 133/4000: train_loss=1.1238  test_loss=2.1294  λ_max=19.3841\n",
      "[SGD | lr=0.1] Epoch 134/4000: train_loss=1.1199  test_loss=2.1230  λ_max=18.9048\n",
      "[SGD | lr=0.1] Epoch 135/4000: train_loss=1.1064  test_loss=2.1203  λ_max=18.8523\n",
      "[SGD | lr=0.1] Epoch 136/4000: train_loss=1.1035  test_loss=2.1282  λ_max=19.6277\n",
      "[SGD | lr=0.1] Epoch 137/4000: train_loss=1.0991  test_loss=2.1293  λ_max=19.5887\n",
      "[SGD | lr=0.1] Iter 2200: loss=1.0775\n",
      "[SGD | lr=0.1] Epoch 138/4000: train_loss=1.0913  test_loss=2.1200  λ_max=19.2343\n",
      "[SGD | lr=0.1] Epoch 139/4000: train_loss=1.0819  test_loss=2.1219  λ_max=19.9321\n",
      "[SGD | lr=0.1] Epoch 140/4000: train_loss=1.0737  test_loss=2.1264  λ_max=20.1739\n",
      "[SGD | lr=0.1] Epoch 141/4000: train_loss=1.0705  test_loss=2.1235  λ_max=20.5396\n",
      "[SGD | lr=0.1] Epoch 142/4000: train_loss=1.0638  test_loss=2.1221  λ_max=19.0908\n",
      "[SGD | lr=0.1] Epoch 143/4000: train_loss=1.0570  test_loss=2.1228  λ_max=19.9769\n",
      "[SGD | lr=0.1] Iter 2300: loss=1.0507\n",
      "[SGD | lr=0.1] Epoch 144/4000: train_loss=1.0528  test_loss=2.1383  λ_max=19.1165\n",
      "[SGD | lr=0.1] Epoch 145/4000: train_loss=1.0490  test_loss=2.1273  λ_max=19.1062\n",
      "[SGD | lr=0.1] Epoch 146/4000: train_loss=1.0353  test_loss=2.1323  λ_max=20.3162\n",
      "[SGD | lr=0.1] Epoch 147/4000: train_loss=1.0365  test_loss=2.1502  λ_max=20.0708\n",
      "[SGD | lr=0.1] Epoch 148/4000: train_loss=1.0269  test_loss=2.1351  λ_max=20.2932\n",
      "[SGD | lr=0.1] Epoch 149/4000: train_loss=1.0203  test_loss=2.1339  λ_max=20.1413\n",
      "[SGD | lr=0.1] Iter 2400: loss=1.0094\n",
      "[SGD | lr=0.1] Epoch 150/4000: train_loss=1.0112  test_loss=2.1274  λ_max=20.1276\n",
      "[SGD | lr=0.1] Epoch 151/4000: train_loss=1.0070  test_loss=2.1311  λ_max=19.6419\n",
      "[SGD | lr=0.1] Epoch 152/4000: train_loss=0.9976  test_loss=2.1515  λ_max=19.5536\n",
      "[SGD | lr=0.1] Epoch 153/4000: train_loss=0.9925  test_loss=2.1375  λ_max=19.4593\n",
      "[SGD | lr=0.1] Epoch 154/4000: train_loss=0.9848  test_loss=2.1466  λ_max=19.3686\n",
      "[SGD | lr=0.1] Epoch 155/4000: train_loss=0.9845  test_loss=2.1402  λ_max=20.4535\n",
      "[SGD | lr=0.1] Epoch 156/4000: train_loss=0.9823  test_loss=2.1479  λ_max=18.9882\n",
      "[SGD | lr=0.1] Iter 2500: loss=0.9620\n",
      "[SGD | lr=0.1] Epoch 157/4000: train_loss=0.9730  test_loss=2.1488  λ_max=22.0249\n",
      "[SGD | lr=0.1] Epoch 158/4000: train_loss=0.9642  test_loss=2.1655  λ_max=20.2398\n",
      "[SGD | lr=0.1] Epoch 159/4000: train_loss=0.9600  test_loss=2.1496  λ_max=20.8969\n",
      "[SGD | lr=0.1] Epoch 160/4000: train_loss=0.9583  test_loss=2.1694  λ_max=19.9866\n",
      "[SGD | lr=0.1] Epoch 161/4000: train_loss=0.9513  test_loss=2.1540  λ_max=20.4580\n",
      "[SGD | lr=0.1] Epoch 162/4000: train_loss=0.9399  test_loss=2.1472  λ_max=20.3905\n",
      "[SGD | lr=0.1] Iter 2600: loss=0.9410\n",
      "[SGD | lr=0.1] Epoch 163/4000: train_loss=0.9341  test_loss=2.1624  λ_max=21.3680\n",
      "[SGD | lr=0.1] Epoch 164/4000: train_loss=0.9298  test_loss=2.1591  λ_max=20.4135\n",
      "[SGD | lr=0.1] Epoch 165/4000: train_loss=0.9245  test_loss=2.1627  λ_max=20.0798\n",
      "[SGD | lr=0.1] Epoch 166/4000: train_loss=0.9280  test_loss=2.1758  λ_max=19.8982\n",
      "[SGD | lr=0.1] Epoch 167/4000: train_loss=0.9133  test_loss=2.1646  λ_max=20.8495\n",
      "[SGD | lr=0.1] Epoch 168/4000: train_loss=0.9071  test_loss=2.1625  λ_max=20.5564\n",
      "[SGD | lr=0.1] Iter 2700: loss=0.9200\n",
      "[SGD | lr=0.1] Epoch 169/4000: train_loss=0.9039  test_loss=2.1630  λ_max=19.8102\n",
      "[SGD | lr=0.1] Epoch 170/4000: train_loss=0.8922  test_loss=2.1747  λ_max=21.0066\n",
      "[SGD | lr=0.1] Epoch 171/4000: train_loss=0.8915  test_loss=2.1605  λ_max=20.5003\n",
      "[SGD | lr=0.1] Epoch 172/4000: train_loss=0.8790  test_loss=2.1704  λ_max=21.6434\n",
      "[SGD | lr=0.1] Epoch 173/4000: train_loss=0.8685  test_loss=2.1791  λ_max=22.0792\n",
      "[SGD | lr=0.1] Epoch 174/4000: train_loss=0.8727  test_loss=2.1780  λ_max=21.6552\n",
      "[SGD | lr=0.1] Iter 2800: loss=0.8547\n",
      "[SGD | lr=0.1] Epoch 175/4000: train_loss=0.8711  test_loss=2.1846  λ_max=20.4474\n",
      "[SGD | lr=0.1] Epoch 176/4000: train_loss=0.8603  test_loss=2.1797  λ_max=20.8689\n",
      "[SGD | lr=0.1] Epoch 177/4000: train_loss=0.8642  test_loss=2.1851  λ_max=20.5106\n",
      "[SGD | lr=0.1] Epoch 178/4000: train_loss=0.8514  test_loss=2.1888  λ_max=20.8451\n",
      "[SGD | lr=0.1] Epoch 179/4000: train_loss=0.8447  test_loss=2.1887  λ_max=22.3123\n",
      "[SGD | lr=0.1] Epoch 180/4000: train_loss=0.8417  test_loss=2.1783  λ_max=21.1309\n",
      "[SGD | lr=0.1] Epoch 181/4000: train_loss=0.8340  test_loss=2.1844  λ_max=21.5010\n",
      "[SGD | lr=0.1] Iter 2900: loss=0.8104\n",
      "[SGD | lr=0.1] Epoch 182/4000: train_loss=0.8258  test_loss=2.1866  λ_max=22.3729\n",
      "[SGD | lr=0.1] Epoch 183/4000: train_loss=0.8291  test_loss=2.1893  λ_max=21.0530\n",
      "[SGD | lr=0.1] Epoch 184/4000: train_loss=0.8164  test_loss=2.1881  λ_max=22.6393\n",
      "[SGD | lr=0.1] Epoch 185/4000: train_loss=0.8098  test_loss=2.1959  λ_max=22.6110\n",
      "[SGD | lr=0.1] Epoch 186/4000: train_loss=0.8115  test_loss=2.1982  λ_max=21.7219\n",
      "[SGD | lr=0.1] Epoch 187/4000: train_loss=0.8037  test_loss=2.1926  λ_max=21.8444\n",
      "[SGD | lr=0.1] Iter 3000: loss=0.8091\n",
      "[SGD | lr=0.1] Epoch 188/4000: train_loss=0.8015  test_loss=2.2054  λ_max=21.1573\n",
      "[SGD | lr=0.1] Epoch 189/4000: train_loss=0.7973  test_loss=2.1988  λ_max=21.5693\n",
      "[SGD | lr=0.1] Epoch 190/4000: train_loss=0.7861  test_loss=2.2132  λ_max=22.1445\n",
      "[SGD | lr=0.1] Epoch 191/4000: train_loss=0.7832  test_loss=2.1927  λ_max=22.7713\n",
      "[SGD | lr=0.1] Epoch 192/4000: train_loss=0.7740  test_loss=2.2142  λ_max=22.0448\n",
      "[SGD | lr=0.1] Epoch 193/4000: train_loss=0.7738  test_loss=2.2148  λ_max=21.6908\n",
      "[SGD | lr=0.1] Iter 3100: loss=0.7752\n",
      "[SGD | lr=0.1] Epoch 194/4000: train_loss=0.7725  test_loss=2.2165  λ_max=21.4405\n",
      "[SGD | lr=0.1] Epoch 195/4000: train_loss=0.7677  test_loss=2.2251  λ_max=22.3119\n",
      "[SGD | lr=0.1] Epoch 196/4000: train_loss=0.7578  test_loss=2.2184  λ_max=21.0194\n",
      "[SGD | lr=0.1] Epoch 197/4000: train_loss=0.7634  test_loss=2.2189  λ_max=21.9335\n",
      "[SGD | lr=0.1] Epoch 198/4000: train_loss=0.7475  test_loss=2.2161  λ_max=20.5538\n",
      "[SGD | lr=0.1] Epoch 199/4000: train_loss=0.7470  test_loss=2.2208  λ_max=22.6942\n",
      "[SGD | lr=0.1] Iter 3200: loss=0.7557\n",
      "[SGD | lr=0.1] Epoch 200/4000: train_loss=0.7388  test_loss=2.2157  λ_max=21.1982\n",
      "[SGD | lr=0.1] Epoch 201/4000: train_loss=0.7337  test_loss=2.2310  λ_max=22.0301\n",
      "[SGD | lr=0.1] Epoch 202/4000: train_loss=0.7349  test_loss=2.2367  λ_max=24.3860\n",
      "[SGD | lr=0.1] Epoch 203/4000: train_loss=0.7284  test_loss=2.2366  λ_max=21.6033\n",
      "[SGD | lr=0.1] Epoch 204/4000: train_loss=0.7127  test_loss=2.2349  λ_max=22.5775\n",
      "[SGD | lr=0.1] Epoch 205/4000: train_loss=0.7136  test_loss=2.2363  λ_max=21.5332\n",
      "[SGD | lr=0.1] Epoch 206/4000: train_loss=0.7090  test_loss=2.2446  λ_max=22.5483\n",
      "[SGD | lr=0.1] Iter 3300: loss=0.6876\n",
      "[SGD | lr=0.1] Epoch 207/4000: train_loss=0.7033  test_loss=2.2329  λ_max=22.0800\n",
      "[SGD | lr=0.1] Epoch 208/4000: train_loss=0.6946  test_loss=2.2404  λ_max=22.0374\n",
      "[SGD | lr=0.1] Epoch 209/4000: train_loss=0.7002  test_loss=2.2450  λ_max=22.4299\n",
      "[SGD | lr=0.1] Epoch 210/4000: train_loss=0.6892  test_loss=2.2519  λ_max=21.9345\n",
      "[SGD | lr=0.1] Epoch 211/4000: train_loss=0.6882  test_loss=2.2484  λ_max=22.7647\n",
      "[SGD | lr=0.1] Epoch 212/4000: train_loss=0.6815  test_loss=2.2450  λ_max=22.8105\n",
      "[SGD | lr=0.1] Iter 3400: loss=0.6670\n",
      "[SGD | lr=0.1] Epoch 213/4000: train_loss=0.6771  test_loss=2.2625  λ_max=21.7335\n",
      "[SGD | lr=0.1] Epoch 214/4000: train_loss=0.6717  test_loss=2.2545  λ_max=21.3896\n",
      "[SGD | lr=0.1] Epoch 215/4000: train_loss=0.6706  test_loss=2.2530  λ_max=22.4970\n",
      "[SGD | lr=0.1] Epoch 216/4000: train_loss=0.6603  test_loss=2.2669  λ_max=22.7186\n",
      "[SGD | lr=0.1] Epoch 217/4000: train_loss=0.6525  test_loss=2.2627  λ_max=22.4223\n",
      "[SGD | lr=0.1] Epoch 218/4000: train_loss=0.6471  test_loss=2.2631  λ_max=22.2094\n",
      "[SGD | lr=0.1] Iter 3500: loss=0.6433\n",
      "[SGD | lr=0.1] Epoch 219/4000: train_loss=0.6497  test_loss=2.2728  λ_max=21.5765\n",
      "[SGD | lr=0.1] Epoch 220/4000: train_loss=0.6386  test_loss=2.2622  λ_max=23.1210\n",
      "[SGD | lr=0.1] Epoch 221/4000: train_loss=0.6438  test_loss=2.2725  λ_max=22.5720\n",
      "[SGD | lr=0.1] Epoch 222/4000: train_loss=0.6377  test_loss=2.2749  λ_max=22.4927\n",
      "[SGD | lr=0.1] Epoch 223/4000: train_loss=0.6297  test_loss=2.2703  λ_max=22.2787\n",
      "[SGD | lr=0.1] Epoch 224/4000: train_loss=0.6280  test_loss=2.2808  λ_max=22.8577\n",
      "[SGD | lr=0.1] Iter 3600: loss=0.6299\n",
      "[SGD | lr=0.1] Epoch 225/4000: train_loss=0.6224  test_loss=2.2759  λ_max=22.9475\n",
      "[SGD | lr=0.1] Epoch 226/4000: train_loss=0.6192  test_loss=2.2824  λ_max=21.4139\n",
      "[SGD | lr=0.1] Epoch 227/4000: train_loss=0.6169  test_loss=2.2831  λ_max=23.5653\n",
      "[SGD | lr=0.1] Epoch 228/4000: train_loss=0.6072  test_loss=2.2968  λ_max=22.4050\n",
      "[SGD | lr=0.1] Epoch 229/4000: train_loss=0.6134  test_loss=2.2828  λ_max=23.3941\n",
      "[SGD | lr=0.1] Epoch 230/4000: train_loss=0.6069  test_loss=2.2901  λ_max=22.8019\n",
      "[SGD | lr=0.1] Epoch 231/4000: train_loss=0.5986  test_loss=2.2928  λ_max=21.9350\n",
      "[SGD | lr=0.1] Iter 3700: loss=0.6042\n",
      "[SGD | lr=0.1] Epoch 232/4000: train_loss=0.5934  test_loss=2.2827  λ_max=23.3057\n",
      "[SGD | lr=0.1] Epoch 233/4000: train_loss=0.5943  test_loss=2.3052  λ_max=23.9510\n",
      "[SGD | lr=0.1] Epoch 234/4000: train_loss=0.5872  test_loss=2.2886  λ_max=22.2921\n",
      "[SGD | lr=0.1] Epoch 235/4000: train_loss=0.5828  test_loss=2.3146  λ_max=23.7719\n",
      "[SGD | lr=0.1] Epoch 236/4000: train_loss=0.5743  test_loss=2.2893  λ_max=23.0360\n",
      "[SGD | lr=0.1] Epoch 237/4000: train_loss=0.5759  test_loss=2.3130  λ_max=23.1677\n",
      "[SGD | lr=0.1] Iter 3800: loss=0.5834\n",
      "[SGD | lr=0.1] Epoch 238/4000: train_loss=0.5685  test_loss=2.3124  λ_max=23.4258\n",
      "[SGD | lr=0.1] Epoch 239/4000: train_loss=0.5617  test_loss=2.3152  λ_max=23.6576\n",
      "[SGD | lr=0.1] Epoch 240/4000: train_loss=0.5611  test_loss=2.3267  λ_max=23.8643\n",
      "[SGD | lr=0.1] Epoch 241/4000: train_loss=0.5587  test_loss=2.3304  λ_max=23.8271\n",
      "[SGD | lr=0.1] Epoch 242/4000: train_loss=0.5655  test_loss=2.3235  λ_max=21.8138\n",
      "[SGD | lr=0.1] Epoch 243/4000: train_loss=0.5481  test_loss=2.3219  λ_max=23.7577\n",
      "[SGD | lr=0.1] Iter 3900: loss=0.5375\n",
      "[SGD | lr=0.1] Epoch 244/4000: train_loss=0.5425  test_loss=2.3329  λ_max=24.5756\n",
      "[SGD | lr=0.1] Epoch 245/4000: train_loss=0.5431  test_loss=2.3300  λ_max=23.4099\n",
      "[SGD | lr=0.1] Epoch 246/4000: train_loss=0.5416  test_loss=2.3367  λ_max=23.5843\n",
      "[SGD | lr=0.1] Epoch 247/4000: train_loss=0.5408  test_loss=2.3323  λ_max=24.6397\n",
      "[SGD | lr=0.1] Epoch 248/4000: train_loss=0.5223  test_loss=2.3285  λ_max=24.7014\n",
      "[SGD | lr=0.1] Epoch 249/4000: train_loss=0.5337  test_loss=2.3379  λ_max=23.6458\n",
      "[SGD | lr=0.1] Iter 4000: loss=0.5261\n",
      "[SGD | lr=0.1] Epoch 250/4000: train_loss=0.5209  test_loss=2.3471  λ_max=24.2540\n",
      "[SGD | lr=0.1] Epoch 251/4000: train_loss=0.5232  test_loss=2.3361  λ_max=23.5926\n",
      "[SGD | lr=0.1] Epoch 252/4000: train_loss=0.5194  test_loss=2.3554  λ_max=24.5269\n",
      "[SGD | lr=0.1] Epoch 253/4000: train_loss=0.5172  test_loss=2.3428  λ_max=23.7993\n",
      "[SGD | lr=0.1] Epoch 254/4000: train_loss=0.5064  test_loss=2.3605  λ_max=23.1125\n",
      "[SGD | lr=0.1] Epoch 255/4000: train_loss=0.5051  test_loss=2.3503  λ_max=24.1240\n",
      "[SGD | lr=0.1] Epoch 256/4000: train_loss=0.4972  test_loss=2.3497  λ_max=23.1860\n",
      "[SGD | lr=0.1] Iter 4100: loss=0.4841\n",
      "[SGD | lr=0.1] Epoch 257/4000: train_loss=0.4926  test_loss=2.3510  λ_max=24.8137\n",
      "[SGD | lr=0.1] Epoch 258/4000: train_loss=0.4937  test_loss=2.3605  λ_max=23.9722\n",
      "[SGD | lr=0.1] Epoch 259/4000: train_loss=0.4902  test_loss=2.3557  λ_max=24.4478\n",
      "[SGD | lr=0.1] Epoch 260/4000: train_loss=0.4849  test_loss=2.3654  λ_max=24.1163\n",
      "[SGD | lr=0.1] Epoch 261/4000: train_loss=0.4863  test_loss=2.3587  λ_max=24.0619\n",
      "[SGD | lr=0.1] Epoch 262/4000: train_loss=0.4755  test_loss=2.3729  λ_max=24.7008\n",
      "[SGD | lr=0.1] Iter 4200: loss=0.4773\n",
      "[SGD | lr=0.1] Epoch 263/4000: train_loss=0.4793  test_loss=2.3727  λ_max=24.1412\n",
      "[SGD | lr=0.1] Epoch 264/4000: train_loss=0.4683  test_loss=2.3787  λ_max=23.2201\n",
      "[SGD | lr=0.1] Epoch 265/4000: train_loss=0.4662  test_loss=2.3713  λ_max=24.6641\n",
      "[SGD | lr=0.1] Epoch 266/4000: train_loss=0.4698  test_loss=2.3874  λ_max=24.3831\n",
      "[SGD | lr=0.1] Epoch 267/4000: train_loss=0.4801  test_loss=2.3828  λ_max=24.3677\n",
      "[SGD | lr=0.1] Epoch 268/4000: train_loss=0.4591  test_loss=2.3792  λ_max=24.4668\n",
      "[SGD | lr=0.1] Iter 4300: loss=0.4756\n",
      "[SGD | lr=0.1] Epoch 269/4000: train_loss=0.4644  test_loss=2.3821  λ_max=24.9248\n",
      "[SGD | lr=0.1] Epoch 270/4000: train_loss=0.4517  test_loss=2.3881  λ_max=24.5790\n",
      "[SGD | lr=0.1] Epoch 271/4000: train_loss=0.4511  test_loss=2.4035  λ_max=24.0660\n",
      "[SGD | lr=0.1] Epoch 272/4000: train_loss=0.4462  test_loss=2.3893  λ_max=24.2834\n",
      "[SGD | lr=0.1] Epoch 273/4000: train_loss=0.4404  test_loss=2.4093  λ_max=25.3150\n",
      "[SGD | lr=0.1] Epoch 274/4000: train_loss=0.4479  test_loss=2.4006  λ_max=23.9459\n",
      "[SGD | lr=0.1] Iter 4400: loss=0.4413\n",
      "[SGD | lr=0.1] Epoch 275/4000: train_loss=0.4401  test_loss=2.3932  λ_max=23.0271\n",
      "[SGD | lr=0.1] Epoch 276/4000: train_loss=0.4362  test_loss=2.4082  λ_max=24.7798\n",
      "[SGD | lr=0.1] Epoch 277/4000: train_loss=0.4322  test_loss=2.4062  λ_max=24.4107\n",
      "[SGD | lr=0.1] Epoch 278/4000: train_loss=0.4301  test_loss=2.4151  λ_max=24.8519\n",
      "[SGD | lr=0.1] Epoch 279/4000: train_loss=0.4272  test_loss=2.4153  λ_max=25.5779\n",
      "[SGD | lr=0.1] Epoch 280/4000: train_loss=0.4215  test_loss=2.4207  λ_max=25.0882\n",
      "[SGD | lr=0.1] Epoch 281/4000: train_loss=0.4211  test_loss=2.4151  λ_max=24.7701\n",
      "[SGD | lr=0.1] Iter 4500: loss=0.4179\n",
      "[SGD | lr=0.1] Epoch 282/4000: train_loss=0.4172  test_loss=2.4097  λ_max=24.4354\n",
      "[SGD | lr=0.1] Epoch 283/4000: train_loss=0.4048  test_loss=2.4139  λ_max=24.8158\n",
      "[SGD | lr=0.1] Epoch 284/4000: train_loss=0.4019  test_loss=2.4242  λ_max=25.3652\n",
      "[SGD | lr=0.1] Epoch 285/4000: train_loss=0.4102  test_loss=2.4293  λ_max=25.0514\n",
      "[SGD | lr=0.1] Epoch 286/4000: train_loss=0.4032  test_loss=2.4246  λ_max=25.6976\n",
      "[SGD | lr=0.1] Epoch 287/4000: train_loss=0.3922  test_loss=2.4298  λ_max=24.4962\n",
      "[SGD | lr=0.1] Iter 4600: loss=0.4093\n",
      "[SGD | lr=0.1] Epoch 288/4000: train_loss=0.4006  test_loss=2.4361  λ_max=24.0209\n",
      "[SGD | lr=0.1] Epoch 289/4000: train_loss=0.3947  test_loss=2.4346  λ_max=23.7762\n",
      "[SGD | lr=0.1] Epoch 290/4000: train_loss=0.3879  test_loss=2.4413  λ_max=24.5359\n",
      "[SGD | lr=0.1] Epoch 291/4000: train_loss=0.3880  test_loss=2.4393  λ_max=25.1796\n",
      "[SGD | lr=0.1] Epoch 292/4000: train_loss=0.3873  test_loss=2.4455  λ_max=24.2160\n",
      "[SGD | lr=0.1] Epoch 293/4000: train_loss=0.3854  test_loss=2.4536  λ_max=25.8385\n",
      "[SGD | lr=0.1] Iter 4700: loss=0.3834\n",
      "[SGD | lr=0.1] Epoch 294/4000: train_loss=0.3846  test_loss=2.4464  λ_max=25.2611\n",
      "[SGD | lr=0.1] Epoch 295/4000: train_loss=0.3738  test_loss=2.4489  λ_max=23.9230\n",
      "[SGD | lr=0.1] Epoch 296/4000: train_loss=0.3690  test_loss=2.4507  λ_max=24.5048\n",
      "[SGD | lr=0.1] Epoch 297/4000: train_loss=0.3705  test_loss=2.4607  λ_max=25.1167\n",
      "[SGD | lr=0.1] Epoch 298/4000: train_loss=0.3776  test_loss=2.4662  λ_max=24.9950\n",
      "[SGD | lr=0.1] Epoch 299/4000: train_loss=0.3711  test_loss=2.4595  λ_max=26.6435\n",
      "[SGD | lr=0.1] Iter 4800: loss=0.3629\n",
      "[SGD | lr=0.1] Epoch 300/4000: train_loss=0.3571  test_loss=2.4642  λ_max=25.1594\n",
      "[SGD | lr=0.1] Epoch 301/4000: train_loss=0.3558  test_loss=2.4581  λ_max=25.6099\n",
      "[SGD | lr=0.1] Epoch 302/4000: train_loss=0.3546  test_loss=2.4641  λ_max=25.4581\n",
      "[SGD | lr=0.1] Epoch 303/4000: train_loss=0.3483  test_loss=2.4658  λ_max=24.6276\n",
      "[SGD | lr=0.1] Epoch 304/4000: train_loss=0.3474  test_loss=2.4818  λ_max=24.7940\n",
      "[SGD | lr=0.1] Epoch 305/4000: train_loss=0.3509  test_loss=2.4733  λ_max=26.0378\n",
      "[SGD | lr=0.1] Epoch 306/4000: train_loss=0.3478  test_loss=2.4715  λ_max=26.3307\n",
      "[SGD | lr=0.1] Iter 4900: loss=0.3312\n",
      "[SGD | lr=0.1] Epoch 307/4000: train_loss=0.3327  test_loss=2.4819  λ_max=25.2226\n",
      "[SGD | lr=0.1] Epoch 308/4000: train_loss=0.3388  test_loss=2.4897  λ_max=25.3806\n",
      "[SGD | lr=0.1] Epoch 309/4000: train_loss=0.3429  test_loss=2.4936  λ_max=26.3543\n",
      "[SGD | lr=0.1] Epoch 310/4000: train_loss=0.3409  test_loss=2.5028  λ_max=27.4201\n",
      "[SGD | lr=0.1] Epoch 311/4000: train_loss=0.3386  test_loss=2.4969  λ_max=26.5455\n",
      "[SGD | lr=0.1] Epoch 312/4000: train_loss=0.3349  test_loss=2.4869  λ_max=26.9151\n",
      "[SGD | lr=0.1] Iter 5000: loss=0.3371\n",
      "[SGD | lr=0.1] Epoch 313/4000: train_loss=0.3314  test_loss=2.5012  λ_max=25.9115\n",
      "[SGD | lr=0.1] Epoch 314/4000: train_loss=0.3300  test_loss=2.4981  λ_max=25.5272\n",
      "[SGD | lr=0.1] Epoch 315/4000: train_loss=0.3347  test_loss=2.5030  λ_max=25.8865\n",
      "[SGD | lr=0.1] Epoch 316/4000: train_loss=0.3173  test_loss=2.5012  λ_max=26.5799\n",
      "[SGD | lr=0.1] Epoch 317/4000: train_loss=0.3191  test_loss=2.5164  λ_max=27.3025\n",
      "[SGD | lr=0.1] Epoch 318/4000: train_loss=0.3211  test_loss=2.5024  λ_max=25.1318\n",
      "[SGD | lr=0.1] Iter 5100: loss=0.3171\n",
      "[SGD | lr=0.1] Epoch 319/4000: train_loss=0.3204  test_loss=2.5196  λ_max=26.3890\n",
      "[SGD | lr=0.1] Epoch 320/4000: train_loss=0.3182  test_loss=2.5174  λ_max=25.5795\n",
      "[SGD | lr=0.1] Epoch 321/4000: train_loss=0.3048  test_loss=2.5116  λ_max=25.5859\n",
      "[SGD | lr=0.1] Epoch 322/4000: train_loss=0.2986  test_loss=2.5188  λ_max=25.5873\n",
      "[SGD | lr=0.1] Epoch 323/4000: train_loss=0.3053  test_loss=2.5237  λ_max=26.8892\n",
      "[SGD | lr=0.1] Epoch 324/4000: train_loss=0.3129  test_loss=2.5349  λ_max=26.2424\n",
      "[SGD | lr=0.1] Iter 5200: loss=0.2972\n",
      "[SGD | lr=0.1] Epoch 325/4000: train_loss=0.3035  test_loss=2.5244  λ_max=25.9386\n",
      "[SGD | lr=0.1] Epoch 326/4000: train_loss=0.2893  test_loss=2.5290  λ_max=25.3668\n",
      "[SGD | lr=0.1] Epoch 327/4000: train_loss=0.2943  test_loss=2.5233  λ_max=26.0603\n",
      "[SGD | lr=0.1] Epoch 328/4000: train_loss=0.2849  test_loss=2.5277  λ_max=26.0930\n",
      "[SGD | lr=0.1] Epoch 329/4000: train_loss=0.2932  test_loss=2.5312  λ_max=27.7630\n",
      "[SGD | lr=0.1] Epoch 330/4000: train_loss=0.2894  test_loss=2.5378  λ_max=27.1286\n",
      "[SGD | lr=0.1] Epoch 331/4000: train_loss=0.2849  test_loss=2.5394  λ_max=27.1592\n",
      "[SGD | lr=0.1] Iter 5300: loss=0.2835\n",
      "[SGD | lr=0.1] Epoch 332/4000: train_loss=0.2838  test_loss=2.5455  λ_max=27.2128\n",
      "[SGD | lr=0.1] Epoch 333/4000: train_loss=0.2869  test_loss=2.5448  λ_max=26.4793\n",
      "[SGD | lr=0.1] Epoch 334/4000: train_loss=0.2862  test_loss=2.5536  λ_max=25.9544\n",
      "[SGD | lr=0.1] Epoch 335/4000: train_loss=0.2749  test_loss=2.5587  λ_max=27.9839\n",
      "[SGD | lr=0.1] Epoch 336/4000: train_loss=0.2807  test_loss=2.5565  λ_max=26.9964\n",
      "[SGD | lr=0.1] Epoch 337/4000: train_loss=0.2712  test_loss=2.5538  λ_max=27.4408\n",
      "[SGD | lr=0.1] Iter 5400: loss=0.2840\n",
      "[SGD | lr=0.1] Epoch 338/4000: train_loss=0.2807  test_loss=2.5686  λ_max=26.1423\n",
      "[SGD | lr=0.1] Epoch 339/4000: train_loss=0.2709  test_loss=2.5608  λ_max=26.7915\n",
      "[SGD | lr=0.1] Epoch 340/4000: train_loss=0.2725  test_loss=2.5659  λ_max=27.7740\n",
      "[SGD | lr=0.1] Epoch 341/4000: train_loss=0.2711  test_loss=2.5655  λ_max=27.3571\n",
      "[SGD | lr=0.1] Epoch 342/4000: train_loss=0.2659  test_loss=2.5656  λ_max=25.9734\n",
      "[SGD | lr=0.1] Epoch 343/4000: train_loss=0.2628  test_loss=2.5671  λ_max=26.4113\n",
      "[SGD | lr=0.1] Iter 5500: loss=0.2508\n",
      "[SGD | lr=0.1] Epoch 344/4000: train_loss=0.2551  test_loss=2.5676  λ_max=26.4742\n",
      "[SGD | lr=0.1] Epoch 345/4000: train_loss=0.2524  test_loss=2.5698  λ_max=27.2307\n",
      "[SGD | lr=0.1] Epoch 346/4000: train_loss=0.2460  test_loss=2.5720  λ_max=26.8969\n",
      "[SGD | lr=0.1] Epoch 347/4000: train_loss=0.2483  test_loss=2.5817  λ_max=26.9166\n",
      "[SGD | lr=0.1] Epoch 348/4000: train_loss=0.2549  test_loss=2.5957  λ_max=27.6111\n",
      "[SGD | lr=0.1] Epoch 349/4000: train_loss=0.2547  test_loss=2.5893  λ_max=27.9962\n",
      "[SGD | lr=0.1] Iter 5600: loss=0.2573\n",
      "[SGD | lr=0.1] Epoch 350/4000: train_loss=0.2579  test_loss=2.5962  λ_max=28.0513\n",
      "[SGD | lr=0.1] Epoch 351/4000: train_loss=0.2512  test_loss=2.5953  λ_max=27.7235\n",
      "[SGD | lr=0.1] Epoch 352/4000: train_loss=0.2511  test_loss=2.5930  λ_max=26.9073\n",
      "[SGD | lr=0.1] Epoch 353/4000: train_loss=0.2491  test_loss=2.6050  λ_max=26.8742\n",
      "[SGD | lr=0.1] Epoch 354/4000: train_loss=0.2397  test_loss=2.5980  λ_max=27.3154\n",
      "[SGD | lr=0.1] Epoch 355/4000: train_loss=0.2333  test_loss=2.5975  λ_max=28.1082\n",
      "[SGD | lr=0.1] Epoch 356/4000: train_loss=0.2399  test_loss=2.6094  λ_max=27.5417\n",
      "[SGD | lr=0.1] Iter 5700: loss=0.2338\n",
      "[SGD | lr=0.1] Epoch 357/4000: train_loss=0.2364  test_loss=2.6025  λ_max=27.5180\n",
      "[SGD | lr=0.1] Epoch 358/4000: train_loss=0.2270  test_loss=2.6089  λ_max=27.7057\n",
      "[SGD | lr=0.1] Epoch 359/4000: train_loss=0.2282  test_loss=2.6169  λ_max=27.7993\n",
      "[SGD | lr=0.1] Epoch 360/4000: train_loss=0.2385  test_loss=2.6102  λ_max=28.0891\n",
      "[SGD | lr=0.1] Epoch 361/4000: train_loss=0.2252  test_loss=2.6102  λ_max=28.1976\n",
      "[SGD | lr=0.1] Epoch 362/4000: train_loss=0.2216  test_loss=2.6211  λ_max=28.4416\n",
      "[SGD | lr=0.1] Iter 5800: loss=0.2407\n",
      "[SGD | lr=0.1] Epoch 363/4000: train_loss=0.2357  test_loss=2.6206  λ_max=27.8823\n",
      "[SGD | lr=0.1] Epoch 364/4000: train_loss=0.2257  test_loss=2.6305  λ_max=28.1299\n",
      "[SGD | lr=0.1] Epoch 365/4000: train_loss=0.2239  test_loss=2.6276  λ_max=28.0430\n",
      "[SGD | lr=0.1] Epoch 366/4000: train_loss=0.2190  test_loss=2.6251  λ_max=27.4187\n",
      "[SGD | lr=0.1] Epoch 367/4000: train_loss=0.2148  test_loss=2.6249  λ_max=28.0832\n",
      "[SGD | lr=0.1] Epoch 368/4000: train_loss=0.2150  test_loss=2.6307  λ_max=28.5069\n",
      "[SGD | lr=0.1] Iter 5900: loss=0.2209\n",
      "[SGD | lr=0.1] Epoch 369/4000: train_loss=0.2198  test_loss=2.6477  λ_max=29.2416\n",
      "[SGD | lr=0.1] Epoch 370/4000: train_loss=0.2295  test_loss=2.6483  λ_max=27.7360\n",
      "[SGD | lr=0.1] Epoch 371/4000: train_loss=0.2164  test_loss=2.6409  λ_max=28.9722\n",
      "[SGD | lr=0.1] Epoch 372/4000: train_loss=0.2075  test_loss=2.6418  λ_max=28.3313\n",
      "[SGD | lr=0.1] Epoch 373/4000: train_loss=0.2080  test_loss=2.6484  λ_max=27.5475\n",
      "[SGD | lr=0.1] Epoch 374/4000: train_loss=0.2065  test_loss=2.6443  λ_max=27.9671\n",
      "[SGD | lr=0.1] Iter 6000: loss=0.2021\n",
      "[SGD | lr=0.1] Epoch 375/4000: train_loss=0.2026  test_loss=2.6506  λ_max=28.9824\n",
      "[SGD | lr=0.1] Epoch 376/4000: train_loss=0.2045  test_loss=2.6616  λ_max=30.0205\n",
      "[SGD | lr=0.1] Epoch 377/4000: train_loss=0.2138  test_loss=2.6569  λ_max=29.1433\n",
      "[SGD | lr=0.1] Epoch 378/4000: train_loss=0.1992  test_loss=2.6594  λ_max=28.8909\n",
      "[SGD | lr=0.1] Epoch 379/4000: train_loss=0.1962  test_loss=2.6601  λ_max=27.4798\n",
      "[SGD | lr=0.1] Epoch 380/4000: train_loss=0.1987  test_loss=2.6642  λ_max=28.8185\n",
      "[SGD | lr=0.1] Epoch 381/4000: train_loss=0.2069  test_loss=2.6712  λ_max=29.0201\n",
      "[SGD | lr=0.1] Iter 6100: loss=0.2059\n",
      "[SGD | lr=0.1] Epoch 382/4000: train_loss=0.2106  test_loss=2.6807  λ_max=28.8755\n",
      "[SGD | lr=0.1] Epoch 383/4000: train_loss=0.1996  test_loss=2.6716  λ_max=29.1550\n",
      "[SGD | lr=0.1] Epoch 384/4000: train_loss=0.1923  test_loss=2.6688  λ_max=28.9824\n",
      "[SGD | lr=0.1] Epoch 385/4000: train_loss=0.1877  test_loss=2.6732  λ_max=29.3067\n",
      "[SGD | lr=0.1] Epoch 386/4000: train_loss=0.1889  test_loss=2.6769  λ_max=29.2653\n",
      "[SGD | lr=0.1] Epoch 387/4000: train_loss=0.1872  test_loss=2.6775  λ_max=28.6818\n",
      "[SGD | lr=0.1] Iter 6200: loss=0.1825\n",
      "[SGD | lr=0.1] Epoch 388/4000: train_loss=0.1860  test_loss=2.6805  λ_max=28.3106\n",
      "[SGD | lr=0.1] Epoch 389/4000: train_loss=0.1877  test_loss=2.6840  λ_max=29.2365\n",
      "[SGD | lr=0.1] Epoch 390/4000: train_loss=0.1941  test_loss=2.6910  λ_max=30.1318\n",
      "[SGD | lr=0.1] Epoch 391/4000: train_loss=0.1873  test_loss=2.6971  λ_max=30.0197\n",
      "[SGD | lr=0.1] Epoch 392/4000: train_loss=0.1857  test_loss=2.6936  λ_max=28.5211\n",
      "[SGD | lr=0.1] Epoch 393/4000: train_loss=0.1825  test_loss=2.7035  λ_max=28.4516\n",
      "[SGD | lr=0.1] Iter 6300: loss=0.1798\n",
      "[SGD | lr=0.1] Epoch 394/4000: train_loss=0.1813  test_loss=2.6986  λ_max=29.3565\n",
      "[SGD | lr=0.1] Epoch 395/4000: train_loss=0.1772  test_loss=2.6984  λ_max=29.3559\n",
      "[SGD | lr=0.1] Epoch 396/4000: train_loss=0.1773  test_loss=2.7002  λ_max=30.1308\n",
      "[SGD | lr=0.1] Epoch 397/4000: train_loss=0.1784  test_loss=2.7073  λ_max=29.9375\n",
      "[SGD | lr=0.1] Epoch 398/4000: train_loss=0.1816  test_loss=2.7078  λ_max=28.7598\n",
      "[SGD | lr=0.1] Epoch 399/4000: train_loss=0.1798  test_loss=2.7201  λ_max=29.4018\n",
      "[SGD | lr=0.1] Iter 6400: loss=0.1759\n",
      "[SGD | lr=0.1] Epoch 400/4000: train_loss=0.1786  test_loss=2.7170  λ_max=30.0093\n",
      "[SGD | lr=0.1] Epoch 401/4000: train_loss=0.1747  test_loss=2.7179  λ_max=30.5967\n",
      "[SGD | lr=0.1] Epoch 402/4000: train_loss=0.1727  test_loss=2.7166  λ_max=30.3366\n",
      "[SGD | lr=0.1] Epoch 403/4000: train_loss=0.1681  test_loss=2.7156  λ_max=29.1306\n",
      "[SGD | lr=0.1] Epoch 404/4000: train_loss=0.1692  test_loss=2.7195  λ_max=30.3861\n",
      "[SGD | lr=0.1] Epoch 405/4000: train_loss=0.1693  test_loss=2.7221  λ_max=31.1716\n",
      "[SGD | lr=0.1] Epoch 406/4000: train_loss=0.1667  test_loss=2.7247  λ_max=30.2385\n",
      "[SGD | lr=0.1] Iter 6500: loss=0.1625\n",
      "[SGD | lr=0.1] Epoch 407/4000: train_loss=0.1653  test_loss=2.7304  λ_max=30.3696\n",
      "[SGD | lr=0.1] Epoch 408/4000: train_loss=0.1649  test_loss=2.7306  λ_max=30.7752\n",
      "[SGD | lr=0.1] Epoch 409/4000: train_loss=0.1652  test_loss=2.7346  λ_max=31.6798\n",
      "[SGD | lr=0.1] Epoch 410/4000: train_loss=0.1700  test_loss=2.7426  λ_max=31.4604\n",
      "[SGD | lr=0.1] Epoch 411/4000: train_loss=0.1663  test_loss=2.7383  λ_max=30.4538\n",
      "[SGD | lr=0.1] Epoch 412/4000: train_loss=0.1584  test_loss=2.7378  λ_max=30.3452\n",
      "[SGD | lr=0.1] Iter 6600: loss=0.1595\n",
      "[SGD | lr=0.1] Epoch 413/4000: train_loss=0.1583  test_loss=2.7426  λ_max=30.9263\n",
      "[SGD | lr=0.1] Epoch 414/4000: train_loss=0.1577  test_loss=2.7491  λ_max=29.8592\n",
      "[SGD | lr=0.1] Epoch 415/4000: train_loss=0.1584  test_loss=2.7518  λ_max=29.8332\n",
      "[SGD | lr=0.1] Epoch 416/4000: train_loss=0.1607  test_loss=2.7560  λ_max=30.8580\n",
      "[SGD | lr=0.1] Epoch 417/4000: train_loss=0.1587  test_loss=2.7556  λ_max=30.6418\n",
      "[SGD | lr=0.1] Epoch 418/4000: train_loss=0.1593  test_loss=2.7534  λ_max=30.1407\n",
      "[SGD | lr=0.1] Iter 6700: loss=0.1519\n",
      "[SGD | lr=0.1] Epoch 419/4000: train_loss=0.1551  test_loss=2.7558  λ_max=31.0017\n",
      "[SGD | lr=0.1] Epoch 420/4000: train_loss=0.1518  test_loss=2.7568  λ_max=30.9082\n",
      "[SGD | lr=0.1] Epoch 421/4000: train_loss=0.1517  test_loss=2.7654  λ_max=31.1927\n",
      "[SGD | lr=0.1] Epoch 422/4000: train_loss=0.1530  test_loss=2.7658  λ_max=30.2458\n",
      "[SGD | lr=0.1] Epoch 423/4000: train_loss=0.1521  test_loss=2.7670  λ_max=30.1505\n",
      "[SGD | lr=0.1] Epoch 424/4000: train_loss=0.1505  test_loss=2.7691  λ_max=30.3373\n",
      "[SGD | lr=0.1] Iter 6800: loss=0.1476\n",
      "[SGD | lr=0.1] Epoch 425/4000: train_loss=0.1487  test_loss=2.7711  λ_max=30.8445\n",
      "[SGD | lr=0.1] Epoch 426/4000: train_loss=0.1532  test_loss=2.7796  λ_max=30.2915\n",
      "[SGD | lr=0.1] Epoch 427/4000: train_loss=0.1550  test_loss=2.7860  λ_max=30.5514\n",
      "[SGD | lr=0.1] Epoch 428/4000: train_loss=0.1546  test_loss=2.7803  λ_max=31.4192\n",
      "[SGD | lr=0.1] Epoch 429/4000: train_loss=0.1455  test_loss=2.7782  λ_max=31.5676\n",
      "[SGD | lr=0.1] Epoch 430/4000: train_loss=0.1431  test_loss=2.7832  λ_max=32.1296\n",
      "[SGD | lr=0.1] Epoch 431/4000: train_loss=0.1432  test_loss=2.7844  λ_max=30.8671\n",
      "[SGD | lr=0.1] Iter 6900: loss=0.1427\n",
      "[SGD | lr=0.1] Epoch 432/4000: train_loss=0.1434  test_loss=2.7891  λ_max=31.9719\n",
      "[SGD | lr=0.1] Epoch 433/4000: train_loss=0.1417  test_loss=2.7884  λ_max=31.1318\n",
      "[SGD | lr=0.1] Epoch 434/4000: train_loss=0.1414  test_loss=2.7897  λ_max=31.3088\n",
      "[SGD | lr=0.1] Epoch 435/4000: train_loss=0.1421  test_loss=2.7927  λ_max=31.9276\n",
      "[SGD | lr=0.1] Epoch 436/4000: train_loss=0.1414  test_loss=2.7963  λ_max=31.1119\n",
      "[SGD | lr=0.1] Epoch 437/4000: train_loss=0.1435  test_loss=2.8017  λ_max=31.9410\n",
      "[SGD | lr=0.1] Iter 7000: loss=0.1382\n",
      "[SGD | lr=0.1] Epoch 438/4000: train_loss=0.1409  test_loss=2.8002  λ_max=30.9614\n",
      "[SGD | lr=0.1] Epoch 439/4000: train_loss=0.1371  test_loss=2.8031  λ_max=32.8228\n",
      "[SGD | lr=0.1] Epoch 440/4000: train_loss=0.1357  test_loss=2.8063  λ_max=30.9217\n",
      "[SGD | lr=0.1] Epoch 441/4000: train_loss=0.1353  test_loss=2.8083  λ_max=31.0626\n",
      "[SGD | lr=0.1] Epoch 442/4000: train_loss=0.1362  test_loss=2.8125  λ_max=32.0934\n",
      "[SGD | lr=0.1] Epoch 443/4000: train_loss=0.1353  test_loss=2.8152  λ_max=31.7841\n",
      "[SGD | lr=0.1] Iter 7100: loss=0.1362\n",
      "[SGD | lr=0.1] Epoch 444/4000: train_loss=0.1344  test_loss=2.8159  λ_max=31.4264\n",
      "[SGD | lr=0.1] Epoch 445/4000: train_loss=0.1345  test_loss=2.8148  λ_max=32.3900\n",
      "[SGD | lr=0.1] Epoch 446/4000: train_loss=0.1329  test_loss=2.8165  λ_max=31.4762\n",
      "[SGD | lr=0.1] Epoch 447/4000: train_loss=0.1318  test_loss=2.8190  λ_max=31.9731\n",
      "[SGD | lr=0.1] Epoch 448/4000: train_loss=0.1318  test_loss=2.8201  λ_max=32.1554\n",
      "[SGD | lr=0.1] Epoch 449/4000: train_loss=0.1328  test_loss=2.8218  λ_max=31.5279\n",
      "[SGD | lr=0.1] Iter 7200: loss=0.1284\n",
      "[SGD | lr=0.1] Epoch 450/4000: train_loss=0.1303  test_loss=2.8268  λ_max=31.9244\n",
      "[SGD | lr=0.1] Epoch 451/4000: train_loss=0.1278  test_loss=2.8300  λ_max=31.8632\n",
      "[SGD | lr=0.1] Epoch 452/4000: train_loss=0.1278  test_loss=2.8298  λ_max=31.4894\n",
      "[SGD | lr=0.1] Epoch 453/4000: train_loss=0.1285  test_loss=2.8348  λ_max=32.7636\n",
      "[SGD | lr=0.1] Epoch 454/4000: train_loss=0.1284  test_loss=2.8368  λ_max=33.5855\n",
      "[SGD | lr=0.1] Epoch 455/4000: train_loss=0.1277  test_loss=2.8411  λ_max=32.6537\n",
      "[SGD | lr=0.1] Epoch 456/4000: train_loss=0.1271  test_loss=2.8436  λ_max=32.8001\n",
      "[SGD | lr=0.1] Iter 7300: loss=0.1254\n",
      "[SGD | lr=0.1] Epoch 457/4000: train_loss=0.1255  test_loss=2.8442  λ_max=32.7739\n",
      "[SGD | lr=0.1] Epoch 458/4000: train_loss=0.1252  test_loss=2.8462  λ_max=32.1818\n",
      "[SGD | lr=0.1] Epoch 459/4000: train_loss=0.1243  test_loss=2.8462  λ_max=32.4494\n",
      "[SGD | lr=0.1] Epoch 460/4000: train_loss=0.1231  test_loss=2.8482  λ_max=32.3197\n",
      "[SGD | lr=0.1] Epoch 461/4000: train_loss=0.1226  test_loss=2.8505  λ_max=32.0950\n",
      "[SGD | lr=0.1] Epoch 462/4000: train_loss=0.1228  test_loss=2.8531  λ_max=33.3120\n",
      "[SGD | lr=0.1] Iter 7400: loss=0.1211\n",
      "[SGD | lr=0.1] Epoch 463/4000: train_loss=0.1222  test_loss=2.8553  λ_max=33.2628\n",
      "[SGD | lr=0.1] Epoch 464/4000: train_loss=0.1208  test_loss=2.8573  λ_max=32.6969\n",
      "[SGD | lr=0.1] Epoch 465/4000: train_loss=0.1199  test_loss=2.8604  λ_max=32.6864\n",
      "[SGD | lr=0.1] Epoch 466/4000: train_loss=0.1194  test_loss=2.8635  λ_max=32.1523\n",
      "[SGD | lr=0.1] Epoch 467/4000: train_loss=0.1198  test_loss=2.8636  λ_max=33.9832\n",
      "[SGD | lr=0.1] Epoch 468/4000: train_loss=0.1194  test_loss=2.8645  λ_max=32.8323\n",
      "[SGD | lr=0.1] Iter 7500: loss=0.1173\n",
      "[SGD | lr=0.1] Epoch 469/4000: train_loss=0.1179  test_loss=2.8661  λ_max=32.1921\n",
      "[SGD | lr=0.1] Epoch 470/4000: train_loss=0.1179  test_loss=2.8704  λ_max=32.7612\n",
      "[SGD | lr=0.1] Epoch 471/4000: train_loss=0.1180  test_loss=2.8728  λ_max=33.0917\n",
      "[SGD | lr=0.1] Epoch 472/4000: train_loss=0.1162  test_loss=2.8752  λ_max=34.2340\n",
      "[SGD | lr=0.1] Epoch 473/4000: train_loss=0.1156  test_loss=2.8781  λ_max=32.9828\n",
      "[SGD | lr=0.1] Epoch 474/4000: train_loss=0.1150  test_loss=2.8785  λ_max=33.8307\n",
      "[SGD | lr=0.1] Iter 7600: loss=0.1084\n",
      "[SGD | lr=0.1] Epoch 475/4000: train_loss=0.1144  test_loss=2.8809  λ_max=32.2161\n",
      "[SGD | lr=0.1] Epoch 476/4000: train_loss=0.1140  test_loss=2.8825  λ_max=33.3206\n",
      "[SGD | lr=0.1] Epoch 477/4000: train_loss=0.1140  test_loss=2.8850  λ_max=34.1334\n",
      "[SGD | lr=0.1] Epoch 478/4000: train_loss=0.1134  test_loss=2.8864  λ_max=33.8539\n",
      "[SGD | lr=0.1] Epoch 479/4000: train_loss=0.1135  test_loss=2.8871  λ_max=34.2505\n",
      "[SGD | lr=0.1] Epoch 480/4000: train_loss=0.1122  test_loss=2.8891  λ_max=34.7354\n",
      "[SGD | lr=0.1] Epoch 481/4000: train_loss=0.1115  test_loss=2.8946  λ_max=34.8429\n",
      "[SGD | lr=0.1] Iter 7700: loss=0.1091\n",
      "[SGD | lr=0.1] Epoch 482/4000: train_loss=0.1108  test_loss=2.8957  λ_max=32.8570\n",
      "[SGD | lr=0.1] Epoch 483/4000: train_loss=0.1104  test_loss=2.8959  λ_max=33.7219\n",
      "[SGD | lr=0.1] Epoch 484/4000: train_loss=0.1096  test_loss=2.8986  λ_max=32.9998\n",
      "[SGD | lr=0.1] Epoch 485/4000: train_loss=0.1093  test_loss=2.9028  λ_max=33.3168\n",
      "[SGD | lr=0.1] Epoch 486/4000: train_loss=0.1084  test_loss=2.9019  λ_max=34.1768\n",
      "[SGD | lr=0.1] Epoch 487/4000: train_loss=0.1081  test_loss=2.9043  λ_max=34.3761\n",
      "[SGD | lr=0.1] Iter 7800: loss=0.1086\n",
      "[SGD | lr=0.1] Epoch 488/4000: train_loss=0.1077  test_loss=2.9060  λ_max=34.5670\n",
      "[SGD | lr=0.1] Epoch 489/4000: train_loss=0.1071  test_loss=2.9092  λ_max=34.3079\n",
      "[SGD | lr=0.1] Epoch 490/4000: train_loss=0.1067  test_loss=2.9133  λ_max=34.2922\n",
      "[SGD | lr=0.1] Epoch 491/4000: train_loss=0.1064  test_loss=2.9154  λ_max=34.9084\n",
      "[SGD | lr=0.1] Epoch 492/4000: train_loss=0.1066  test_loss=2.9173  λ_max=34.7303\n",
      "[SGD | lr=0.1] Epoch 493/4000: train_loss=0.1055  test_loss=2.9196  λ_max=34.4492\n",
      "[SGD | lr=0.1] Iter 7900: loss=0.1048\n",
      "[SGD | lr=0.1] Epoch 494/4000: train_loss=0.1054  test_loss=2.9197  λ_max=33.4755\n",
      "[SGD | lr=0.1] Epoch 495/4000: train_loss=0.1045  test_loss=2.9243  λ_max=34.7990\n",
      "[SGD | lr=0.1] Epoch 496/4000: train_loss=0.1039  test_loss=2.9233  λ_max=33.5873\n",
      "[SGD | lr=0.1] Epoch 497/4000: train_loss=0.1038  test_loss=2.9255  λ_max=33.9035\n",
      "[SGD | lr=0.1] Epoch 498/4000: train_loss=0.1033  test_loss=2.9275  λ_max=33.9166\n",
      "[SGD | lr=0.1] Epoch 499/4000: train_loss=0.1026  test_loss=2.9304  λ_max=34.7554\n",
      "[SGD | lr=0.1] Iter 8000: loss=0.1047\n",
      "[SGD | lr=0.1] Epoch 500/4000: train_loss=0.1027  test_loss=2.9310  λ_max=34.5584\n",
      "[SGD | lr=0.1] Epoch 501/4000: train_loss=0.1020  test_loss=2.9343  λ_max=33.9359\n",
      "[SGD | lr=0.1] Epoch 502/4000: train_loss=0.1017  test_loss=2.9376  λ_max=34.4793\n",
      "[SGD | lr=0.1] Epoch 503/4000: train_loss=0.1013  test_loss=2.9364  λ_max=34.4671\n",
      "[SGD | lr=0.1] Epoch 504/4000: train_loss=0.1006  test_loss=2.9387  λ_max=34.2880\n",
      "[SGD | lr=0.1] Epoch 505/4000: train_loss=0.0999  test_loss=2.9420  λ_max=34.5716\n",
      "[SGD | lr=0.1] Epoch 506/4000: train_loss=0.0995  test_loss=2.9444  λ_max=34.1612\n",
      "[SGD | lr=0.1] Iter 8100: loss=0.1001\n",
      "[SGD | lr=0.1] Epoch 507/4000: train_loss=0.0994  test_loss=2.9464  λ_max=34.7937\n",
      "[SGD | lr=0.1] Epoch 508/4000: train_loss=0.0988  test_loss=2.9479  λ_max=34.7271\n",
      "[SGD | lr=0.1] Epoch 509/4000: train_loss=0.0985  test_loss=2.9491  λ_max=34.7306\n",
      "[SGD | lr=0.1] Epoch 510/4000: train_loss=0.0984  test_loss=2.9514  λ_max=35.4598\n",
      "[SGD | lr=0.1] Epoch 511/4000: train_loss=0.0979  test_loss=2.9531  λ_max=34.0696\n",
      "[SGD | lr=0.1] Epoch 512/4000: train_loss=0.0972  test_loss=2.9553  λ_max=35.4834\n",
      "[SGD | lr=0.1] Iter 8200: loss=0.0976\n",
      "[SGD | lr=0.1] Epoch 513/4000: train_loss=0.0966  test_loss=2.9574  λ_max=35.9323\n",
      "[SGD | lr=0.1] Epoch 514/4000: train_loss=0.0969  test_loss=2.9572  λ_max=35.6337\n",
      "[SGD | lr=0.1] Epoch 515/4000: train_loss=0.0958  test_loss=2.9610  λ_max=35.7549\n",
      "[SGD | lr=0.1] Epoch 516/4000: train_loss=0.0955  test_loss=2.9621  λ_max=34.5917\n",
      "[SGD | lr=0.1] Epoch 517/4000: train_loss=0.0950  test_loss=2.9631  λ_max=35.1968\n",
      "[SGD | lr=0.1] Epoch 518/4000: train_loss=0.0947  test_loss=2.9653  λ_max=35.9214\n",
      "[SGD | lr=0.1] Iter 8300: loss=0.0944\n",
      "[SGD | lr=0.1] Epoch 519/4000: train_loss=0.0944  test_loss=2.9673  λ_max=34.5036\n",
      "[SGD | lr=0.1] Epoch 520/4000: train_loss=0.0941  test_loss=2.9696  λ_max=35.9643\n",
      "[SGD | lr=0.1] Epoch 521/4000: train_loss=0.0936  test_loss=2.9733  λ_max=35.4763\n",
      "[SGD | lr=0.1] Epoch 522/4000: train_loss=0.0930  test_loss=2.9740  λ_max=37.0799\n",
      "[SGD | lr=0.1] Epoch 523/4000: train_loss=0.0928  test_loss=2.9752  λ_max=36.2399\n",
      "[SGD | lr=0.1] Epoch 524/4000: train_loss=0.0928  test_loss=2.9774  λ_max=35.2154\n",
      "[SGD | lr=0.1] Iter 8400: loss=0.0901\n",
      "[SGD | lr=0.1] Epoch 525/4000: train_loss=0.0924  test_loss=2.9803  λ_max=34.5673\n",
      "[SGD | lr=0.1] Epoch 526/4000: train_loss=0.0918  test_loss=2.9826  λ_max=36.0375\n",
      "[SGD | lr=0.1] Epoch 527/4000: train_loss=0.0915  test_loss=2.9846  λ_max=35.8344\n",
      "[SGD | lr=0.1] Epoch 528/4000: train_loss=0.0911  test_loss=2.9848  λ_max=36.6525\n",
      "[SGD | lr=0.1] Epoch 529/4000: train_loss=0.0907  test_loss=2.9863  λ_max=36.7078\n",
      "[SGD | lr=0.1] Epoch 530/4000: train_loss=0.0902  test_loss=2.9881  λ_max=35.9500\n",
      "[SGD | lr=0.1] Epoch 531/4000: train_loss=0.0900  test_loss=2.9895  λ_max=35.6393\n",
      "[SGD | lr=0.1] Iter 8500: loss=0.0885\n",
      "[SGD | lr=0.1] Epoch 532/4000: train_loss=0.0895  test_loss=2.9913  λ_max=36.5210\n",
      "[SGD | lr=0.1] Epoch 533/4000: train_loss=0.0892  test_loss=2.9926  λ_max=36.9562\n",
      "[SGD | lr=0.1] Epoch 534/4000: train_loss=0.0888  test_loss=2.9959  λ_max=36.3510\n",
      "[SGD | lr=0.1] Epoch 535/4000: train_loss=0.0885  test_loss=2.9964  λ_max=36.5398\n",
      "[SGD | lr=0.1] Epoch 536/4000: train_loss=0.0881  test_loss=2.9988  λ_max=36.2721\n",
      "[SGD | lr=0.1] Epoch 537/4000: train_loss=0.0882  test_loss=3.0007  λ_max=36.3544\n",
      "[SGD | lr=0.1] Iter 8600: loss=0.0863\n",
      "[SGD | lr=0.1] Epoch 538/4000: train_loss=0.0875  test_loss=3.0038  λ_max=35.5264\n",
      "[SGD | lr=0.1] Epoch 539/4000: train_loss=0.0870  test_loss=3.0050  λ_max=36.2652\n",
      "[SGD | lr=0.1] Epoch 540/4000: train_loss=0.0867  test_loss=3.0061  λ_max=36.8161\n",
      "[SGD | lr=0.1] Epoch 541/4000: train_loss=0.0864  test_loss=3.0076  λ_max=36.8386\n",
      "[SGD | lr=0.1] Epoch 542/4000: train_loss=0.0859  test_loss=3.0084  λ_max=36.0413\n",
      "[SGD | lr=0.1] Epoch 543/4000: train_loss=0.0858  test_loss=3.0118  λ_max=36.2736\n",
      "[SGD | lr=0.1] Iter 8700: loss=0.0861\n",
      "[SGD | lr=0.1] Epoch 544/4000: train_loss=0.0854  test_loss=3.0128  λ_max=36.0258\n",
      "[SGD | lr=0.1] Epoch 545/4000: train_loss=0.0852  test_loss=3.0146  λ_max=35.3249\n",
      "[SGD | lr=0.1] Epoch 546/4000: train_loss=0.0849  test_loss=3.0158  λ_max=36.5635\n",
      "[SGD | lr=0.1] Epoch 547/4000: train_loss=0.0846  test_loss=3.0181  λ_max=35.5238\n",
      "[SGD | lr=0.1] Epoch 548/4000: train_loss=0.0843  test_loss=3.0210  λ_max=36.6514\n",
      "[SGD | lr=0.1] Epoch 549/4000: train_loss=0.0841  test_loss=3.0227  λ_max=36.4407\n",
      "[SGD | lr=0.1] Iter 8800: loss=0.0843\n",
      "[SGD | lr=0.1] Epoch 550/4000: train_loss=0.0836  test_loss=3.0243  λ_max=36.7844\n",
      "[SGD | lr=0.1] Epoch 551/4000: train_loss=0.0833  test_loss=3.0260  λ_max=36.5849\n",
      "[SGD | lr=0.1] Epoch 552/4000: train_loss=0.0829  test_loss=3.0269  λ_max=36.4091\n",
      "[SGD | lr=0.1] Epoch 553/4000: train_loss=0.0827  test_loss=3.0305  λ_max=36.8281\n",
      "[SGD | lr=0.1] Epoch 554/4000: train_loss=0.0823  test_loss=3.0316  λ_max=35.3742\n",
      "[SGD | lr=0.1] Epoch 555/4000: train_loss=0.0822  test_loss=3.0319  λ_max=37.5159\n",
      "[SGD | lr=0.1] Epoch 556/4000: train_loss=0.0819  test_loss=3.0342  λ_max=37.8788\n",
      "[SGD | lr=0.1] Iter 8900: loss=0.0826\n",
      "[SGD | lr=0.1] Epoch 557/4000: train_loss=0.0814  test_loss=3.0367  λ_max=35.2245\n",
      "[SGD | lr=0.1] Epoch 558/4000: train_loss=0.0811  test_loss=3.0386  λ_max=37.8259\n",
      "[SGD | lr=0.1] Epoch 559/4000: train_loss=0.0808  test_loss=3.0399  λ_max=36.6637\n",
      "[SGD | lr=0.1] Epoch 560/4000: train_loss=0.0808  test_loss=3.0418  λ_max=37.8108\n",
      "[SGD | lr=0.1] Epoch 561/4000: train_loss=0.0801  test_loss=3.0432  λ_max=38.8501\n",
      "[SGD | lr=0.1] Epoch 562/4000: train_loss=0.0798  test_loss=3.0444  λ_max=36.2190\n",
      "[SGD | lr=0.1] Iter 9000: loss=0.0797\n",
      "[SGD | lr=0.1] Epoch 563/4000: train_loss=0.0795  test_loss=3.0472  λ_max=37.1410\n",
      "[SGD | lr=0.1] Epoch 564/4000: train_loss=0.0793  test_loss=3.0488  λ_max=38.3148\n",
      "[SGD | lr=0.1] Epoch 565/4000: train_loss=0.0792  test_loss=3.0499  λ_max=37.5526\n",
      "[SGD | lr=0.1] Epoch 566/4000: train_loss=0.0788  test_loss=3.0513  λ_max=36.7897\n",
      "[SGD | lr=0.1] Epoch 567/4000: train_loss=0.0785  test_loss=3.0527  λ_max=38.2026\n",
      "[SGD | lr=0.1] Epoch 568/4000: train_loss=0.0782  test_loss=3.0548  λ_max=37.3220\n",
      "[SGD | lr=0.1] Iter 9100: loss=0.0761\n",
      "[SGD | lr=0.1] Epoch 569/4000: train_loss=0.0781  test_loss=3.0558  λ_max=38.1564\n",
      "[SGD | lr=0.1] Epoch 570/4000: train_loss=0.0776  test_loss=3.0595  λ_max=37.2447\n",
      "[SGD | lr=0.1] Epoch 571/4000: train_loss=0.0774  test_loss=3.0622  λ_max=38.3408\n",
      "[SGD | lr=0.1] Epoch 572/4000: train_loss=0.0773  test_loss=3.0629  λ_max=37.6353\n",
      "[SGD | lr=0.1] Epoch 573/4000: train_loss=0.0769  test_loss=3.0644  λ_max=37.1609\n",
      "[SGD | lr=0.1] Epoch 574/4000: train_loss=0.0765  test_loss=3.0651  λ_max=38.0430\n",
      "[SGD | lr=0.1] Iter 9200: loss=0.0751\n",
      "[SGD | lr=0.1] Epoch 575/4000: train_loss=0.0762  test_loss=3.0686  λ_max=38.4241\n",
      "[SGD | lr=0.1] Epoch 576/4000: train_loss=0.0760  test_loss=3.0692  λ_max=38.1923\n",
      "[SGD | lr=0.1] Epoch 577/4000: train_loss=0.0757  test_loss=3.0702  λ_max=35.7978\n",
      "[SGD | lr=0.1] Epoch 578/4000: train_loss=0.0755  test_loss=3.0729  λ_max=38.7425\n",
      "[SGD | lr=0.1] Epoch 579/4000: train_loss=0.0752  test_loss=3.0734  λ_max=38.1478\n",
      "[SGD | lr=0.1] Epoch 580/4000: train_loss=0.0749  test_loss=3.0758  λ_max=38.1275\n",
      "[SGD | lr=0.1] Epoch 581/4000: train_loss=0.0747  test_loss=3.0773  λ_max=38.8157\n",
      "[SGD | lr=0.1] Iter 9300: loss=0.0738\n",
      "[SGD | lr=0.1] Epoch 582/4000: train_loss=0.0744  test_loss=3.0789  λ_max=37.2007\n",
      "[SGD | lr=0.1] Epoch 583/4000: train_loss=0.0741  test_loss=3.0810  λ_max=37.9780\n",
      "[SGD | lr=0.1] Epoch 584/4000: train_loss=0.0740  test_loss=3.0841  λ_max=37.8354\n",
      "[SGD | lr=0.1] Epoch 585/4000: train_loss=0.0739  test_loss=3.0842  λ_max=37.7604\n",
      "[SGD | lr=0.1] Epoch 586/4000: train_loss=0.0734  test_loss=3.0860  λ_max=37.9426\n",
      "[SGD | lr=0.1] Epoch 587/4000: train_loss=0.0732  test_loss=3.0862  λ_max=38.5362\n",
      "[SGD | lr=0.1] Iter 9400: loss=0.0724\n",
      "[SGD | lr=0.1] Epoch 588/4000: train_loss=0.0730  test_loss=3.0897  λ_max=38.5586\n",
      "[SGD | lr=0.1] Epoch 589/4000: train_loss=0.0727  test_loss=3.0898  λ_max=38.9400\n",
      "[SGD | lr=0.1] Epoch 590/4000: train_loss=0.0724  test_loss=3.0910  λ_max=38.7721\n",
      "[SGD | lr=0.1] Epoch 591/4000: train_loss=0.0722  test_loss=3.0943  λ_max=39.3306\n",
      "[SGD | lr=0.1] Epoch 592/4000: train_loss=0.0721  test_loss=3.0958  λ_max=38.2027\n",
      "[SGD | lr=0.1] Epoch 593/4000: train_loss=0.0718  test_loss=3.0979  λ_max=38.4219\n",
      "[SGD | lr=0.1] Iter 9500: loss=0.0712\n",
      "[SGD | lr=0.1] Epoch 594/4000: train_loss=0.0715  test_loss=3.0987  λ_max=37.9992\n",
      "[SGD | lr=0.1] Epoch 595/4000: train_loss=0.0713  test_loss=3.1005  λ_max=38.6188\n",
      "[SGD | lr=0.1] Epoch 596/4000: train_loss=0.0711  test_loss=3.1017  λ_max=39.6161\n",
      "[SGD | lr=0.1] Epoch 597/4000: train_loss=0.0707  test_loss=3.1032  λ_max=38.8657\n",
      "[SGD | lr=0.1] Epoch 598/4000: train_loss=0.0705  test_loss=3.1047  λ_max=37.8566\n",
      "[SGD | lr=0.1] Epoch 599/4000: train_loss=0.0703  test_loss=3.1059  λ_max=38.0946\n",
      "[SGD | lr=0.1] Iter 9600: loss=0.0714\n",
      "[SGD | lr=0.1] Epoch 600/4000: train_loss=0.0702  test_loss=3.1082  λ_max=39.7188\n",
      "[SGD | lr=0.1] Epoch 601/4000: train_loss=0.0698  test_loss=3.1101  λ_max=39.9603\n",
      "[SGD | lr=0.1] Epoch 602/4000: train_loss=0.0696  test_loss=3.1110  λ_max=40.0770\n",
      "[SGD | lr=0.1] Epoch 603/4000: train_loss=0.0694  test_loss=3.1128  λ_max=38.7012\n",
      "[SGD | lr=0.1] Epoch 604/4000: train_loss=0.0692  test_loss=3.1137  λ_max=39.6135\n",
      "[SGD | lr=0.1] Epoch 605/4000: train_loss=0.0689  test_loss=3.1161  λ_max=40.5717\n",
      "[SGD | lr=0.1] Epoch 606/4000: train_loss=0.0687  test_loss=3.1170  λ_max=38.5505\n",
      "[SGD | lr=0.1] Iter 9700: loss=0.0691\n",
      "[SGD | lr=0.1] Epoch 607/4000: train_loss=0.0685  test_loss=3.1195  λ_max=39.8917\n",
      "[SGD | lr=0.1] Epoch 608/4000: train_loss=0.0683  test_loss=3.1197  λ_max=39.2888\n",
      "[SGD | lr=0.1] Epoch 609/4000: train_loss=0.0680  test_loss=3.1216  λ_max=39.7033\n",
      "[SGD | lr=0.1] Epoch 610/4000: train_loss=0.0678  test_loss=3.1233  λ_max=38.4329\n",
      "[SGD | lr=0.1] Epoch 611/4000: train_loss=0.0676  test_loss=3.1243  λ_max=39.7705\n",
      "[SGD | lr=0.1] Epoch 612/4000: train_loss=0.0674  test_loss=3.1252  λ_max=39.8598\n",
      "[SGD | lr=0.1] Iter 9800: loss=0.0669\n",
      "[SGD | lr=0.1] Epoch 613/4000: train_loss=0.0672  test_loss=3.1281  λ_max=40.0030\n",
      "[SGD | lr=0.1] Epoch 614/4000: train_loss=0.0670  test_loss=3.1297  λ_max=40.2625\n",
      "[SGD | lr=0.1] Epoch 615/4000: train_loss=0.0668  test_loss=3.1311  λ_max=39.9760\n",
      "[SGD | lr=0.1] Epoch 616/4000: train_loss=0.0665  test_loss=3.1325  λ_max=40.0551\n",
      "[SGD | lr=0.1] Epoch 617/4000: train_loss=0.0662  test_loss=3.1343  λ_max=38.9616\n",
      "[SGD | lr=0.1] Epoch 618/4000: train_loss=0.0661  test_loss=3.1359  λ_max=39.8807\n",
      "[SGD | lr=0.1] Iter 9900: loss=0.0657\n",
      "[SGD | lr=0.1] Epoch 619/4000: train_loss=0.0659  test_loss=3.1372  λ_max=38.9833\n",
      "[SGD | lr=0.1] Epoch 620/4000: train_loss=0.0658  test_loss=3.1376  λ_max=39.7716\n",
      "[SGD | lr=0.1] Epoch 621/4000: train_loss=0.0655  test_loss=3.1395  λ_max=39.0109\n",
      "[SGD | lr=0.1] Epoch 622/4000: train_loss=0.0653  test_loss=3.1420  λ_max=39.9478\n",
      "[SGD | lr=0.1] Epoch 623/4000: train_loss=0.0651  test_loss=3.1441  λ_max=40.2435\n",
      "[SGD | lr=0.1] Epoch 624/4000: train_loss=0.0650  test_loss=3.1447  λ_max=38.1515\n",
      "[SGD | lr=0.1] Iter 10000: loss=0.0637\n",
      "[SGD | lr=0.1] Epoch 625/4000: train_loss=0.0647  test_loss=3.1461  λ_max=40.0154\n",
      "[SGD | lr=0.1] Epoch 626/4000: train_loss=0.0645  test_loss=3.1482  λ_max=40.2648\n",
      "[SGD | lr=0.1] Epoch 627/4000: train_loss=0.0642  test_loss=3.1488  λ_max=39.8481\n",
      "[SGD | lr=0.1] Epoch 628/4000: train_loss=0.0641  test_loss=3.1510  λ_max=40.7075\n",
      "[SGD | lr=0.1] Epoch 629/4000: train_loss=0.0639  test_loss=3.1525  λ_max=40.2345\n",
      "[SGD | lr=0.1] Epoch 630/4000: train_loss=0.0637  test_loss=3.1535  λ_max=41.0326\n",
      "[SGD | lr=0.1] Epoch 631/4000: train_loss=0.0635  test_loss=3.1557  λ_max=39.8682\n",
      "[SGD | lr=0.1] Iter 10100: loss=0.0634\n",
      "[SGD | lr=0.1] Epoch 632/4000: train_loss=0.0634  test_loss=3.1568  λ_max=40.4982\n",
      "[SGD | lr=0.1] Epoch 633/4000: train_loss=0.0632  test_loss=3.1587  λ_max=40.7513\n",
      "[SGD | lr=0.1] Epoch 634/4000: train_loss=0.0630  test_loss=3.1595  λ_max=40.8966\n",
      "[SGD | lr=0.1] Epoch 635/4000: train_loss=0.0628  test_loss=3.1607  λ_max=40.1199\n",
      "[SGD | lr=0.1] Epoch 636/4000: train_loss=0.0626  test_loss=3.1624  λ_max=40.9409\n",
      "[SGD | lr=0.1] Epoch 637/4000: train_loss=0.0624  test_loss=3.1636  λ_max=40.8583\n",
      "[SGD | lr=0.1] Iter 10200: loss=0.0617\n",
      "[SGD | lr=0.1] Epoch 638/4000: train_loss=0.0622  test_loss=3.1662  λ_max=39.9105\n",
      "[SGD | lr=0.1] Epoch 639/4000: train_loss=0.0620  test_loss=3.1667  λ_max=39.7435\n",
      "[SGD | lr=0.1] Epoch 640/4000: train_loss=0.0618  test_loss=3.1686  λ_max=40.3924\n",
      "[SGD | lr=0.1] Epoch 641/4000: train_loss=0.0616  test_loss=3.1685  λ_max=39.3939\n",
      "[SGD | lr=0.1] Epoch 642/4000: train_loss=0.0614  test_loss=3.1706  λ_max=39.4139\n",
      "[SGD | lr=0.1] Epoch 643/4000: train_loss=0.0613  test_loss=3.1723  λ_max=40.7593\n",
      "[SGD | lr=0.1] Iter 10300: loss=0.0626\n",
      "[SGD | lr=0.1] Epoch 644/4000: train_loss=0.0611  test_loss=3.1740  λ_max=41.4683\n",
      "[SGD | lr=0.1] Epoch 645/4000: train_loss=0.0609  test_loss=3.1754  λ_max=41.8879\n",
      "[SGD | lr=0.1] Epoch 646/4000: train_loss=0.0607  test_loss=3.1769  λ_max=40.6978\n",
      "[SGD | lr=0.1] Epoch 647/4000: train_loss=0.0606  test_loss=3.1785  λ_max=40.0756\n",
      "[SGD | lr=0.1] Epoch 648/4000: train_loss=0.0603  test_loss=3.1798  λ_max=40.2970\n",
      "[SGD | lr=0.1] Epoch 649/4000: train_loss=0.0602  test_loss=3.1812  λ_max=40.3561\n",
      "[SGD | lr=0.1] Iter 10400: loss=0.0611\n",
      "[SGD | lr=0.1] Epoch 650/4000: train_loss=0.0601  test_loss=3.1835  λ_max=40.8378\n",
      "[SGD | lr=0.1] Epoch 651/4000: train_loss=0.0598  test_loss=3.1836  λ_max=40.1694\n",
      "[SGD | lr=0.1] Epoch 652/4000: train_loss=0.0596  test_loss=3.1858  λ_max=41.3586\n",
      "[SGD | lr=0.1] Epoch 653/4000: train_loss=0.0595  test_loss=3.1871  λ_max=41.1008\n",
      "[SGD | lr=0.1] Epoch 654/4000: train_loss=0.0593  test_loss=3.1884  λ_max=40.9577\n",
      "[SGD | lr=0.1] Epoch 655/4000: train_loss=0.0591  test_loss=3.1900  λ_max=41.1802\n",
      "[SGD | lr=0.1] Epoch 656/4000: train_loss=0.0590  test_loss=3.1914  λ_max=41.3840\n",
      "[SGD | lr=0.1] Iter 10500: loss=0.0580\n",
      "[SGD | lr=0.1] Epoch 657/4000: train_loss=0.0588  test_loss=3.1928  λ_max=41.3450\n",
      "[SGD | lr=0.1] Epoch 658/4000: train_loss=0.0586  test_loss=3.1935  λ_max=41.3607\n",
      "[SGD | lr=0.1] Epoch 659/4000: train_loss=0.0585  test_loss=3.1965  λ_max=40.1274\n",
      "[SGD | lr=0.1] Epoch 660/4000: train_loss=0.0583  test_loss=3.1976  λ_max=41.1230\n",
      "[SGD | lr=0.1] Epoch 661/4000: train_loss=0.0581  test_loss=3.1986  λ_max=41.3039\n",
      "[SGD | lr=0.1] Epoch 662/4000: train_loss=0.0579  test_loss=3.1995  λ_max=42.1374\n",
      "[SGD | lr=0.1] Iter 10600: loss=0.0578\n",
      "[SGD | lr=0.1] Epoch 663/4000: train_loss=0.0578  test_loss=3.2005  λ_max=42.1805\n",
      "[SGD | lr=0.1] Epoch 664/4000: train_loss=0.0576  test_loss=3.2016  λ_max=41.1659\n",
      "[SGD | lr=0.1] Epoch 665/4000: train_loss=0.0574  test_loss=3.2033  λ_max=43.1330\n",
      "[SGD | lr=0.1] Epoch 666/4000: train_loss=0.0573  test_loss=3.2048  λ_max=40.9607\n",
      "[SGD | lr=0.1] Epoch 667/4000: train_loss=0.0571  test_loss=3.2065  λ_max=42.3877\n",
      "[SGD | lr=0.1] Epoch 668/4000: train_loss=0.0570  test_loss=3.2080  λ_max=41.2296\n",
      "[SGD | lr=0.1] Iter 10700: loss=0.0555\n",
      "[SGD | lr=0.1] Epoch 669/4000: train_loss=0.0568  test_loss=3.2099  λ_max=40.7134\n",
      "[SGD | lr=0.1] Epoch 670/4000: train_loss=0.0566  test_loss=3.2105  λ_max=40.6309\n",
      "[SGD | lr=0.1] Epoch 671/4000: train_loss=0.0565  test_loss=3.2124  λ_max=41.4482\n",
      "[SGD | lr=0.1] Epoch 672/4000: train_loss=0.0564  test_loss=3.2139  λ_max=41.0194\n",
      "[SGD | lr=0.1] Epoch 673/4000: train_loss=0.0562  test_loss=3.2149  λ_max=41.5079\n",
      "[SGD | lr=0.1] Epoch 674/4000: train_loss=0.0560  test_loss=3.2155  λ_max=41.1707\n",
      "[SGD | lr=0.1] Iter 10800: loss=0.0574\n",
      "[SGD | lr=0.1] Epoch 675/4000: train_loss=0.0559  test_loss=3.2161  λ_max=42.6764\n",
      "[SGD | lr=0.1] Epoch 676/4000: train_loss=0.0557  test_loss=3.2188  λ_max=42.0414\n",
      "[SGD | lr=0.1] Epoch 677/4000: train_loss=0.0556  test_loss=3.2191  λ_max=41.6762\n",
      "[SGD | lr=0.1] Epoch 678/4000: train_loss=0.0554  test_loss=3.2218  λ_max=42.5353\n",
      "[SGD | lr=0.1] Epoch 679/4000: train_loss=0.0553  test_loss=3.2230  λ_max=42.3027\n",
      "[SGD | lr=0.1] Epoch 680/4000: train_loss=0.0551  test_loss=3.2243  λ_max=42.7808\n",
      "[SGD | lr=0.1] Epoch 681/4000: train_loss=0.0550  test_loss=3.2259  λ_max=42.4041\n",
      "[SGD | lr=0.1] Iter 10900: loss=0.0544\n",
      "[SGD | lr=0.1] Epoch 682/4000: train_loss=0.0548  test_loss=3.2270  λ_max=41.8249\n",
      "[SGD | lr=0.1] Epoch 683/4000: train_loss=0.0546  test_loss=3.2288  λ_max=42.6828\n",
      "[SGD | lr=0.1] Epoch 684/4000: train_loss=0.0545  test_loss=3.2297  λ_max=43.2915\n",
      "[SGD | lr=0.1] Epoch 685/4000: train_loss=0.0544  test_loss=3.2309  λ_max=42.8087\n",
      "[SGD | lr=0.1] Epoch 686/4000: train_loss=0.0542  test_loss=3.2322  λ_max=43.4397\n",
      "[SGD | lr=0.1] Epoch 687/4000: train_loss=0.0540  test_loss=3.2340  λ_max=42.5414\n",
      "[SGD | lr=0.1] Iter 11000: loss=0.0543\n",
      "[SGD | lr=0.1] Epoch 688/4000: train_loss=0.0539  test_loss=3.2351  λ_max=41.9289\n",
      "[SGD | lr=0.1] Epoch 689/4000: train_loss=0.0537  test_loss=3.2365  λ_max=40.9644\n",
      "[SGD | lr=0.1] Epoch 690/4000: train_loss=0.0536  test_loss=3.2384  λ_max=43.0546\n",
      "[SGD | lr=0.1] Epoch 691/4000: train_loss=0.0535  test_loss=3.2402  λ_max=43.9821\n",
      "[SGD | lr=0.1] Epoch 692/4000: train_loss=0.0533  test_loss=3.2406  λ_max=43.2395\n",
      "[SGD | lr=0.1] Epoch 693/4000: train_loss=0.0532  test_loss=3.2416  λ_max=43.0861\n",
      "[SGD | lr=0.1] Iter 11100: loss=0.0535\n",
      "[SGD | lr=0.1] Epoch 694/4000: train_loss=0.0530  test_loss=3.2430  λ_max=41.6225\n",
      "[SGD | lr=0.1] Epoch 695/4000: train_loss=0.0529  test_loss=3.2437  λ_max=43.0750\n",
      "[SGD | lr=0.1] Epoch 696/4000: train_loss=0.0528  test_loss=3.2462  λ_max=43.2963\n",
      "[SGD | lr=0.1] Epoch 697/4000: train_loss=0.0526  test_loss=3.2464  λ_max=42.9338\n",
      "[SGD | lr=0.1] Epoch 698/4000: train_loss=0.0525  test_loss=3.2482  λ_max=42.8000\n",
      "[SGD | lr=0.1] Epoch 699/4000: train_loss=0.0523  test_loss=3.2490  λ_max=42.9964\n",
      "[SGD | lr=0.1] Iter 11200: loss=0.0516\n",
      "[SGD | lr=0.1] Epoch 700/4000: train_loss=0.0522  test_loss=3.2502  λ_max=42.8988\n",
      "[SGD | lr=0.1] Epoch 701/4000: train_loss=0.0521  test_loss=3.2525  λ_max=44.4962\n",
      "[SGD | lr=0.1] Epoch 702/4000: train_loss=0.0519  test_loss=3.2523  λ_max=42.2734\n",
      "[SGD | lr=0.1] Epoch 703/4000: train_loss=0.0518  test_loss=3.2550  λ_max=43.6030\n",
      "[SGD | lr=0.1] Epoch 704/4000: train_loss=0.0517  test_loss=3.2558  λ_max=42.8754\n",
      "[SGD | lr=0.1] Epoch 705/4000: train_loss=0.0515  test_loss=3.2571  λ_max=42.5898\n",
      "[SGD | lr=0.1] Epoch 706/4000: train_loss=0.0514  test_loss=3.2588  λ_max=43.4989\n",
      "[SGD | lr=0.1] Iter 11300: loss=0.0502\n",
      "[SGD | lr=0.1] Epoch 707/4000: train_loss=0.0512  test_loss=3.2597  λ_max=42.9997\n",
      "[SGD | lr=0.1] Epoch 708/4000: train_loss=0.0512  test_loss=3.2613  λ_max=44.0360\n",
      "[SGD | lr=0.1] Epoch 709/4000: train_loss=0.0510  test_loss=3.2614  λ_max=42.4116\n",
      "[SGD | lr=0.1] Epoch 710/4000: train_loss=0.0509  test_loss=3.2624  λ_max=42.8831\n",
      "[SGD | lr=0.1] Epoch 711/4000: train_loss=0.0507  test_loss=3.2650  λ_max=42.5120\n",
      "[SGD | lr=0.1] Epoch 712/4000: train_loss=0.0506  test_loss=3.2658  λ_max=44.2926\n",
      "[SGD | lr=0.1] Iter 11400: loss=0.0507\n",
      "[SGD | lr=0.1] Epoch 713/4000: train_loss=0.0505  test_loss=3.2665  λ_max=41.9713\n",
      "[SGD | lr=0.1] Epoch 714/4000: train_loss=0.0503  test_loss=3.2683  λ_max=44.1580\n",
      "[SGD | lr=0.1] Epoch 715/4000: train_loss=0.0502  test_loss=3.2691  λ_max=42.9294\n",
      "[SGD | lr=0.1] Epoch 716/4000: train_loss=0.0501  test_loss=3.2713  λ_max=43.3444\n",
      "[SGD | lr=0.1] Epoch 717/4000: train_loss=0.0499  test_loss=3.2727  λ_max=43.7532\n",
      "[SGD | lr=0.1] Epoch 718/4000: train_loss=0.0498  test_loss=3.2738  λ_max=43.6960\n",
      "[SGD | lr=0.1] Iter 11500: loss=0.0506\n",
      "[SGD | lr=0.1] Epoch 719/4000: train_loss=0.0497  test_loss=3.2746  λ_max=43.8500\n",
      "[SGD | lr=0.1] Epoch 720/4000: train_loss=0.0496  test_loss=3.2752  λ_max=43.7939\n",
      "[SGD | lr=0.1] Epoch 721/4000: train_loss=0.0494  test_loss=3.2778  λ_max=43.4771\n",
      "[SGD | lr=0.1] Epoch 722/4000: train_loss=0.0493  test_loss=3.2791  λ_max=42.3862\n",
      "[SGD | lr=0.1] Epoch 723/4000: train_loss=0.0492  test_loss=3.2797  λ_max=42.9215\n",
      "[SGD | lr=0.1] Epoch 724/4000: train_loss=0.0490  test_loss=3.2815  λ_max=43.5011\n",
      "[SGD | lr=0.1] Iter 11600: loss=0.0496\n",
      "[SGD | lr=0.1] Epoch 725/4000: train_loss=0.0490  test_loss=3.2827  λ_max=43.2977\n",
      "[SGD | lr=0.1] Epoch 726/4000: train_loss=0.0488  test_loss=3.2833  λ_max=44.5910\n",
      "[SGD | lr=0.1] Epoch 727/4000: train_loss=0.0487  test_loss=3.2839  λ_max=41.9072\n",
      "[SGD | lr=0.1] Epoch 728/4000: train_loss=0.0486  test_loss=3.2858  λ_max=44.2255\n",
      "[SGD | lr=0.1] Epoch 729/4000: train_loss=0.0484  test_loss=3.2871  λ_max=43.2394\n",
      "[SGD | lr=0.1] Epoch 730/4000: train_loss=0.0483  test_loss=3.2882  λ_max=43.6205\n",
      "[SGD | lr=0.1] Epoch 731/4000: train_loss=0.0482  test_loss=3.2889  λ_max=42.6673\n",
      "[SGD | lr=0.1] Iter 11700: loss=0.0478\n",
      "[SGD | lr=0.1] Epoch 732/4000: train_loss=0.0481  test_loss=3.2899  λ_max=42.7518\n",
      "[SGD | lr=0.1] Epoch 733/4000: train_loss=0.0480  test_loss=3.2915  λ_max=43.2020\n",
      "[SGD | lr=0.1] Epoch 734/4000: train_loss=0.0478  test_loss=3.2934  λ_max=44.5618\n",
      "[SGD | lr=0.1] Epoch 735/4000: train_loss=0.0478  test_loss=3.2945  λ_max=42.4296\n",
      "[SGD | lr=0.1] Epoch 736/4000: train_loss=0.0476  test_loss=3.2952  λ_max=43.0317\n",
      "[SGD | lr=0.1] Epoch 737/4000: train_loss=0.0475  test_loss=3.2967  λ_max=42.1998\n",
      "[SGD | lr=0.1] Iter 11800: loss=0.0478\n",
      "[SGD | lr=0.1] Epoch 738/4000: train_loss=0.0474  test_loss=3.2980  λ_max=43.5278\n",
      "[SGD | lr=0.1] Epoch 739/4000: train_loss=0.0472  test_loss=3.2987  λ_max=44.8774\n",
      "[SGD | lr=0.1] Epoch 740/4000: train_loss=0.0472  test_loss=3.3003  λ_max=44.5349\n",
      "[SGD | lr=0.1] Epoch 741/4000: train_loss=0.0471  test_loss=3.3014  λ_max=43.1089\n",
      "[SGD | lr=0.1] Epoch 742/4000: train_loss=0.0469  test_loss=3.3031  λ_max=44.8269\n",
      "[SGD | lr=0.1] Epoch 743/4000: train_loss=0.0468  test_loss=3.3033  λ_max=43.9890\n",
      "[SGD | lr=0.1] Iter 11900: loss=0.0476\n",
      "[SGD | lr=0.1] Epoch 744/4000: train_loss=0.0467  test_loss=3.3050  λ_max=43.5137\n",
      "[SGD | lr=0.1] Epoch 745/4000: train_loss=0.0466  test_loss=3.3063  λ_max=44.6674\n",
      "[SGD | lr=0.1] Epoch 746/4000: train_loss=0.0465  test_loss=3.3073  λ_max=44.1103\n",
      "[SGD | lr=0.1] Epoch 747/4000: train_loss=0.0464  test_loss=3.3079  λ_max=44.1654\n",
      "[SGD | lr=0.1] Epoch 748/4000: train_loss=0.0462  test_loss=3.3096  λ_max=44.4671\n",
      "[SGD | lr=0.1] Epoch 749/4000: train_loss=0.0461  test_loss=3.3106  λ_max=41.9172\n",
      "[SGD | lr=0.1] Iter 12000: loss=0.0462\n",
      "[SGD | lr=0.1] Epoch 750/4000: train_loss=0.0460  test_loss=3.3115  λ_max=45.8951\n",
      "[SGD | lr=0.1] Epoch 751/4000: train_loss=0.0459  test_loss=3.3132  λ_max=43.8590\n",
      "[SGD | lr=0.1] Epoch 752/4000: train_loss=0.0458  test_loss=3.3142  λ_max=44.8108\n",
      "[SGD | lr=0.1] Epoch 753/4000: train_loss=0.0457  test_loss=3.3146  λ_max=45.2446\n",
      "[SGD | lr=0.1] Epoch 754/4000: train_loss=0.0456  test_loss=3.3169  λ_max=45.3847\n",
      "[SGD | lr=0.1] Epoch 755/4000: train_loss=0.0455  test_loss=3.3186  λ_max=45.4905\n",
      "[SGD | lr=0.1] Epoch 756/4000: train_loss=0.0454  test_loss=3.3192  λ_max=44.4215\n",
      "[SGD | lr=0.1] Iter 12100: loss=0.0452\n",
      "[SGD | lr=0.1] Epoch 757/4000: train_loss=0.0452  test_loss=3.3200  λ_max=44.7487\n",
      "[SGD | lr=0.1] Epoch 758/4000: train_loss=0.0451  test_loss=3.3216  λ_max=44.2255\n",
      "[SGD | lr=0.1] Epoch 759/4000: train_loss=0.0450  test_loss=3.3220  λ_max=42.7912\n",
      "[SGD | lr=0.1] Epoch 760/4000: train_loss=0.0450  test_loss=3.3238  λ_max=44.7782\n",
      "[SGD | lr=0.1] Epoch 761/4000: train_loss=0.0448  test_loss=3.3244  λ_max=44.6481\n",
      "[SGD | lr=0.1] Epoch 762/4000: train_loss=0.0447  test_loss=3.3263  λ_max=44.4195\n",
      "[SGD | lr=0.1] Iter 12200: loss=0.0443\n",
      "[SGD | lr=0.1] Epoch 763/4000: train_loss=0.0446  test_loss=3.3276  λ_max=45.7462\n",
      "[SGD | lr=0.1] Epoch 764/4000: train_loss=0.0445  test_loss=3.3280  λ_max=44.0545\n",
      "[SGD | lr=0.1] Epoch 765/4000: train_loss=0.0444  test_loss=3.3296  λ_max=45.0840\n",
      "[SGD | lr=0.1] Epoch 766/4000: train_loss=0.0443  test_loss=3.3306  λ_max=44.3944\n",
      "[SGD | lr=0.1] Epoch 767/4000: train_loss=0.0442  test_loss=3.3319  λ_max=45.8060\n",
      "[SGD | lr=0.1] Epoch 768/4000: train_loss=0.0441  test_loss=3.3326  λ_max=43.2959\n",
      "[SGD | lr=0.1] Iter 12300: loss=0.0434\n",
      "[SGD | lr=0.1] Epoch 769/4000: train_loss=0.0440  test_loss=3.3343  λ_max=45.3771\n",
      "[SGD | lr=0.1] Epoch 770/4000: train_loss=0.0439  test_loss=3.3353  λ_max=45.4310\n",
      "[SGD | lr=0.1] Epoch 771/4000: train_loss=0.0438  test_loss=3.3364  λ_max=45.6057\n",
      "[SGD | lr=0.1] Epoch 772/4000: train_loss=0.0437  test_loss=3.3375  λ_max=43.2693\n",
      "[SGD | lr=0.1] Epoch 773/4000: train_loss=0.0436  test_loss=3.3390  λ_max=43.9598\n",
      "[SGD | lr=0.1] Epoch 774/4000: train_loss=0.0435  test_loss=3.3405  λ_max=45.1747\n",
      "[SGD | lr=0.1] Iter 12400: loss=0.0436\n",
      "[SGD | lr=0.1] Epoch 775/4000: train_loss=0.0434  test_loss=3.3408  λ_max=45.7316\n",
      "[SGD | lr=0.1] Epoch 776/4000: train_loss=0.0433  test_loss=3.3421  λ_max=43.8616\n",
      "[SGD | lr=0.1] Epoch 777/4000: train_loss=0.0432  test_loss=3.3437  λ_max=45.4257\n",
      "[SGD | lr=0.1] Epoch 778/4000: train_loss=0.0431  test_loss=3.3442  λ_max=44.2959\n",
      "[SGD | lr=0.1] Epoch 779/4000: train_loss=0.0430  test_loss=3.3462  λ_max=45.1699\n",
      "[SGD | lr=0.1] Epoch 780/4000: train_loss=0.0429  test_loss=3.3465  λ_max=45.5459\n",
      "[SGD | lr=0.1] Epoch 781/4000: train_loss=0.0428  test_loss=3.3481  λ_max=43.6855\n",
      "[SGD | lr=0.1] Iter 12500: loss=0.0425\n",
      "[SGD | lr=0.1] Epoch 782/4000: train_loss=0.0427  test_loss=3.3492  λ_max=46.1990\n",
      "[SGD | lr=0.1] Epoch 783/4000: train_loss=0.0426  test_loss=3.3500  λ_max=44.8653\n",
      "[SGD | lr=0.1] Epoch 784/4000: train_loss=0.0425  test_loss=3.3515  λ_max=44.0335\n",
      "[SGD | lr=0.1] Epoch 785/4000: train_loss=0.0424  test_loss=3.3530  λ_max=45.8977\n",
      "[SGD | lr=0.1] Epoch 786/4000: train_loss=0.0423  test_loss=3.3532  λ_max=45.4080\n",
      "[SGD | lr=0.1] Epoch 787/4000: train_loss=0.0422  test_loss=3.3547  λ_max=45.4268\n",
      "[SGD | lr=0.1] Iter 12600: loss=0.0420\n",
      "[SGD | lr=0.1] Epoch 788/4000: train_loss=0.0421  test_loss=3.3555  λ_max=43.8497\n",
      "[SGD | lr=0.1] Epoch 789/4000: train_loss=0.0421  test_loss=3.3572  λ_max=45.0326\n",
      "[SGD | lr=0.1] Epoch 790/4000: train_loss=0.0419  test_loss=3.3577  λ_max=46.2330\n",
      "[SGD | lr=0.1] Epoch 791/4000: train_loss=0.0418  test_loss=3.3597  λ_max=46.7994\n",
      "[SGD | lr=0.1] Epoch 792/4000: train_loss=0.0418  test_loss=3.3596  λ_max=45.4580\n",
      "[SGD | lr=0.1] Epoch 793/4000: train_loss=0.0416  test_loss=3.3615  λ_max=44.2006\n",
      "[SGD | lr=0.1] Iter 12700: loss=0.0423\n",
      "[SGD | lr=0.1] Epoch 794/4000: train_loss=0.0416  test_loss=3.3625  λ_max=45.5774\n",
      "[SGD | lr=0.1] Epoch 795/4000: train_loss=0.0415  test_loss=3.3635  λ_max=46.3823\n",
      "[SGD | lr=0.1] Epoch 796/4000: train_loss=0.0414  test_loss=3.3643  λ_max=45.6144\n",
      "[SGD | lr=0.1] Epoch 797/4000: train_loss=0.0413  test_loss=3.3655  λ_max=44.9082\n",
      "[SGD | lr=0.1] Epoch 798/4000: train_loss=0.0412  test_loss=3.3669  λ_max=45.7060\n",
      "[SGD | lr=0.1] Epoch 799/4000: train_loss=0.0411  test_loss=3.3679  λ_max=45.0200\n",
      "[SGD | lr=0.1] Iter 12800: loss=0.0409\n",
      "[SGD | lr=0.1] Epoch 800/4000: train_loss=0.0410  test_loss=3.3684  λ_max=44.0485\n",
      "[SGD | lr=0.1] Epoch 801/4000: train_loss=0.0409  test_loss=3.3695  λ_max=46.1617\n",
      "[SGD | lr=0.1] Epoch 802/4000: train_loss=0.0408  test_loss=3.3711  λ_max=47.5882\n",
      "[SGD | lr=0.1] Epoch 803/4000: train_loss=0.0407  test_loss=3.3720  λ_max=44.3433\n",
      "[SGD | lr=0.1] Epoch 804/4000: train_loss=0.0406  test_loss=3.3731  λ_max=44.7861\n",
      "[SGD | lr=0.1] Epoch 805/4000: train_loss=0.0406  test_loss=3.3738  λ_max=45.2572\n",
      "[SGD | lr=0.1] Epoch 806/4000: train_loss=0.0405  test_loss=3.3759  λ_max=46.8721\n",
      "[SGD | lr=0.1] Iter 12900: loss=0.0401\n",
      "[SGD | lr=0.1] Epoch 807/4000: train_loss=0.0404  test_loss=3.3759  λ_max=46.7118\n",
      "[SGD | lr=0.1] Epoch 808/4000: train_loss=0.0403  test_loss=3.3777  λ_max=46.6676\n",
      "[SGD | lr=0.1] Epoch 809/4000: train_loss=0.0402  test_loss=3.3785  λ_max=45.9272\n",
      "[SGD | lr=0.1] Epoch 810/4000: train_loss=0.0401  test_loss=3.3799  λ_max=46.4971\n",
      "[SGD | lr=0.1] Epoch 811/4000: train_loss=0.0401  test_loss=3.3801  λ_max=47.6731\n",
      "[SGD | lr=0.1] Epoch 812/4000: train_loss=0.0400  test_loss=3.3818  λ_max=45.5666\n",
      "[SGD | lr=0.1] Iter 13000: loss=0.0395\n",
      "[SGD | lr=0.1] Epoch 813/4000: train_loss=0.0399  test_loss=3.3829  λ_max=46.6618\n",
      "[SGD | lr=0.1] Epoch 814/4000: train_loss=0.0398  test_loss=3.3837  λ_max=45.5443\n",
      "[SGD | lr=0.1] Epoch 815/4000: train_loss=0.0397  test_loss=3.3847  λ_max=46.2700\n",
      "[SGD | lr=0.1] Epoch 816/4000: train_loss=0.0396  test_loss=3.3862  λ_max=45.7202\n",
      "[SGD | lr=0.1] Epoch 817/4000: train_loss=0.0395  test_loss=3.3870  λ_max=46.9569\n",
      "[SGD | lr=0.1] Epoch 818/4000: train_loss=0.0394  test_loss=3.3879  λ_max=47.3181\n",
      "[SGD | lr=0.1] Iter 13100: loss=0.0392\n",
      "[SGD | lr=0.1] Epoch 819/4000: train_loss=0.0393  test_loss=3.3886  λ_max=45.9966\n",
      "[SGD | lr=0.1] Epoch 820/4000: train_loss=0.0393  test_loss=3.3898  λ_max=46.3123\n",
      "[SGD | lr=0.1] Epoch 821/4000: train_loss=0.0392  test_loss=3.3919  λ_max=45.4716\n",
      "[SGD | lr=0.1] Epoch 822/4000: train_loss=0.0391  test_loss=3.3919  λ_max=46.6107\n",
      "[SGD | lr=0.1] Epoch 823/4000: train_loss=0.0390  test_loss=3.3938  λ_max=46.4502\n",
      "[SGD | lr=0.1] Epoch 824/4000: train_loss=0.0390  test_loss=3.3943  λ_max=46.3303\n",
      "[SGD | lr=0.1] Iter 13200: loss=0.0398\n",
      "[SGD | lr=0.1] Epoch 825/4000: train_loss=0.0389  test_loss=3.3958  λ_max=45.9763\n",
      "[SGD | lr=0.1] Epoch 826/4000: train_loss=0.0388  test_loss=3.3963  λ_max=45.3229\n",
      "[SGD | lr=0.1] Epoch 827/4000: train_loss=0.0387  test_loss=3.3982  λ_max=46.5283\n",
      "[SGD | lr=0.1] Epoch 828/4000: train_loss=0.0386  test_loss=3.3990  λ_max=46.2043\n",
      "[SGD | lr=0.1] Epoch 829/4000: train_loss=0.0385  test_loss=3.3999  λ_max=46.0396\n",
      "[SGD | lr=0.1] Epoch 830/4000: train_loss=0.0384  test_loss=3.4011  λ_max=46.8480\n",
      "[SGD | lr=0.1] Epoch 831/4000: train_loss=0.0384  test_loss=3.4024  λ_max=46.3426\n",
      "[SGD | lr=0.1] Iter 13300: loss=0.0395\n",
      "[SGD | lr=0.1] Epoch 832/4000: train_loss=0.0383  test_loss=3.4029  λ_max=47.2592\n",
      "[SGD | lr=0.1] Epoch 833/4000: train_loss=0.0382  test_loss=3.4040  λ_max=46.5601\n",
      "[SGD | lr=0.1] Epoch 834/4000: train_loss=0.0382  test_loss=3.4058  λ_max=46.7334\n",
      "[SGD | lr=0.1] Epoch 835/4000: train_loss=0.0380  test_loss=3.4063  λ_max=46.2511\n",
      "[SGD | lr=0.1] Epoch 836/4000: train_loss=0.0380  test_loss=3.4073  λ_max=47.4287\n",
      "[SGD | lr=0.1] Epoch 837/4000: train_loss=0.0379  test_loss=3.4075  λ_max=47.1411\n",
      "[SGD | lr=0.1] Iter 13400: loss=0.0385\n",
      "[SGD | lr=0.1] Epoch 838/4000: train_loss=0.0378  test_loss=3.4095  λ_max=46.8816\n",
      "[SGD | lr=0.1] Epoch 839/4000: train_loss=0.0378  test_loss=3.4102  λ_max=46.6096\n",
      "[SGD | lr=0.1] Epoch 840/4000: train_loss=0.0377  test_loss=3.4109  λ_max=46.8613\n",
      "[SGD | lr=0.1] Epoch 841/4000: train_loss=0.0376  test_loss=3.4123  λ_max=45.2218\n",
      "[SGD | lr=0.1] Epoch 842/4000: train_loss=0.0375  test_loss=3.4133  λ_max=45.9626\n",
      "[SGD | lr=0.1] Epoch 843/4000: train_loss=0.0374  test_loss=3.4141  λ_max=46.7429\n",
      "[SGD | lr=0.1] Iter 13500: loss=0.0368\n",
      "[SGD | lr=0.1] Epoch 844/4000: train_loss=0.0374  test_loss=3.4155  λ_max=46.1602\n",
      "[SGD | lr=0.1] Epoch 845/4000: train_loss=0.0373  test_loss=3.4162  λ_max=47.0353\n",
      "[SGD | lr=0.1] Epoch 846/4000: train_loss=0.0372  test_loss=3.4177  λ_max=46.1480\n",
      "[SGD | lr=0.1] Epoch 847/4000: train_loss=0.0372  test_loss=3.4186  λ_max=47.0931\n",
      "[SGD | lr=0.1] Epoch 848/4000: train_loss=0.0371  test_loss=3.4189  λ_max=47.8125\n",
      "[SGD | lr=0.1] Epoch 849/4000: train_loss=0.0370  test_loss=3.4209  λ_max=46.4592\n",
      "[SGD | lr=0.1] Iter 13600: loss=0.0365\n",
      "[SGD | lr=0.1] Epoch 850/4000: train_loss=0.0369  test_loss=3.4217  λ_max=48.3805\n",
      "[SGD | lr=0.1] Epoch 851/4000: train_loss=0.0368  test_loss=3.4224  λ_max=47.0502\n",
      "[SGD | lr=0.1] Epoch 852/4000: train_loss=0.0367  test_loss=3.4238  λ_max=45.8866\n",
      "[SGD | lr=0.1] Epoch 853/4000: train_loss=0.0367  test_loss=3.4247  λ_max=47.1718\n",
      "[SGD | lr=0.1] Epoch 854/4000: train_loss=0.0366  test_loss=3.4250  λ_max=46.5988\n",
      "[SGD | lr=0.1] Epoch 855/4000: train_loss=0.0365  test_loss=3.4266  λ_max=46.4088\n",
      "[SGD | lr=0.1] Epoch 856/4000: train_loss=0.0365  test_loss=3.4273  λ_max=46.9661\n",
      "[SGD | lr=0.1] Iter 13700: loss=0.0360\n",
      "[SGD | lr=0.1] Epoch 857/4000: train_loss=0.0364  test_loss=3.4284  λ_max=46.3771\n",
      "[SGD | lr=0.1] Epoch 858/4000: train_loss=0.0363  test_loss=3.4294  λ_max=48.2769\n",
      "[SGD | lr=0.1] Epoch 859/4000: train_loss=0.0362  test_loss=3.4308  λ_max=47.7437\n",
      "[SGD | lr=0.1] Epoch 860/4000: train_loss=0.0362  test_loss=3.4317  λ_max=47.1884\n",
      "[SGD | lr=0.1] Epoch 861/4000: train_loss=0.0361  test_loss=3.4333  λ_max=47.3195\n",
      "[SGD | lr=0.1] Epoch 862/4000: train_loss=0.0360  test_loss=3.4334  λ_max=47.2596\n",
      "[SGD | lr=0.1] Iter 13800: loss=0.0362\n",
      "[SGD | lr=0.1] Epoch 863/4000: train_loss=0.0360  test_loss=3.4348  λ_max=47.9708\n",
      "[SGD | lr=0.1] Epoch 864/4000: train_loss=0.0359  test_loss=3.4361  λ_max=47.1557\n",
      "[SGD | lr=0.1] Epoch 865/4000: train_loss=0.0358  test_loss=3.4362  λ_max=47.3375\n",
      "[SGD | lr=0.1] Epoch 866/4000: train_loss=0.0357  test_loss=3.4375  λ_max=47.9067\n",
      "[SGD | lr=0.1] Epoch 867/4000: train_loss=0.0357  test_loss=3.4386  λ_max=47.4744\n",
      "[SGD | lr=0.1] Epoch 868/4000: train_loss=0.0356  test_loss=3.4400  λ_max=47.1723\n",
      "[SGD | lr=0.1] Iter 13900: loss=0.0360\n",
      "[SGD | lr=0.1] Epoch 869/4000: train_loss=0.0355  test_loss=3.4406  λ_max=47.1705\n",
      "[SGD | lr=0.1] Epoch 870/4000: train_loss=0.0354  test_loss=3.4415  λ_max=46.2239\n",
      "[SGD | lr=0.1] Epoch 871/4000: train_loss=0.0354  test_loss=3.4426  λ_max=47.4888\n",
      "[SGD | lr=0.1] Epoch 872/4000: train_loss=0.0353  test_loss=3.4432  λ_max=47.8165\n",
      "[SGD | lr=0.1] Epoch 873/4000: train_loss=0.0353  test_loss=3.4443  λ_max=45.9631\n",
      "[SGD | lr=0.1] Epoch 874/4000: train_loss=0.0352  test_loss=3.4454  λ_max=48.1142\n",
      "[SGD | lr=0.1] Iter 14000: loss=0.0350\n",
      "[SGD | lr=0.1] Epoch 875/4000: train_loss=0.0351  test_loss=3.4466  λ_max=46.7670\n",
      "[SGD | lr=0.1] Epoch 876/4000: train_loss=0.0351  test_loss=3.4477  λ_max=48.0521\n",
      "[SGD | lr=0.1] Epoch 877/4000: train_loss=0.0350  test_loss=3.4483  λ_max=47.0325\n",
      "[SGD | lr=0.1] Epoch 878/4000: train_loss=0.0349  test_loss=3.4491  λ_max=46.3750\n",
      "[SGD | lr=0.1] Epoch 879/4000: train_loss=0.0348  test_loss=3.4502  λ_max=47.5185\n",
      "[SGD | lr=0.1] Epoch 880/4000: train_loss=0.0348  test_loss=3.4510  λ_max=46.5791\n",
      "[SGD | lr=0.1] Epoch 881/4000: train_loss=0.0347  test_loss=3.4528  λ_max=46.5214\n",
      "[SGD | lr=0.1] Iter 14100: loss=0.0343\n",
      "[SGD | lr=0.1] Epoch 882/4000: train_loss=0.0346  test_loss=3.4527  λ_max=47.3375\n",
      "[SGD | lr=0.1] Epoch 883/4000: train_loss=0.0346  test_loss=3.4542  λ_max=48.4055\n",
      "[SGD | lr=0.1] Epoch 884/4000: train_loss=0.0345  test_loss=3.4551  λ_max=48.2726\n",
      "[SGD | lr=0.1] Epoch 885/4000: train_loss=0.0345  test_loss=3.4559  λ_max=48.1033\n",
      "[SGD | lr=0.1] Epoch 886/4000: train_loss=0.0344  test_loss=3.4571  λ_max=46.3648\n",
      "[SGD | lr=0.1] Epoch 887/4000: train_loss=0.0343  test_loss=3.4582  λ_max=49.0251\n",
      "[SGD | lr=0.1] Iter 14200: loss=0.0341\n",
      "[SGD | lr=0.1] Epoch 888/4000: train_loss=0.0343  test_loss=3.4585  λ_max=48.4863\n",
      "[SGD | lr=0.1] Epoch 889/4000: train_loss=0.0342  test_loss=3.4602  λ_max=47.3166\n",
      "[SGD | lr=0.1] Epoch 890/4000: train_loss=0.0341  test_loss=3.4612  λ_max=48.9010\n",
      "[SGD | lr=0.1] Epoch 891/4000: train_loss=0.0340  test_loss=3.4619  λ_max=48.0877\n",
      "[SGD | lr=0.1] Epoch 892/4000: train_loss=0.0340  test_loss=3.4630  λ_max=47.5361\n",
      "[SGD | lr=0.1] Epoch 893/4000: train_loss=0.0339  test_loss=3.4642  λ_max=48.8862\n",
      "[SGD | lr=0.1] Iter 14300: loss=0.0342\n",
      "[SGD | lr=0.1] Epoch 894/4000: train_loss=0.0339  test_loss=3.4648  λ_max=48.9197\n",
      "[SGD | lr=0.1] Epoch 895/4000: train_loss=0.0338  test_loss=3.4652  λ_max=47.6625\n",
      "[SGD | lr=0.1] Epoch 896/4000: train_loss=0.0337  test_loss=3.4665  λ_max=47.7235\n",
      "[SGD | lr=0.1] Epoch 897/4000: train_loss=0.0336  test_loss=3.4671  λ_max=48.8212\n",
      "[SGD | lr=0.1] Epoch 898/4000: train_loss=0.0336  test_loss=3.4686  λ_max=48.0062\n",
      "[SGD | lr=0.1] Epoch 899/4000: train_loss=0.0335  test_loss=3.4697  λ_max=47.4103\n",
      "[SGD | lr=0.1] Iter 14400: loss=0.0338\n",
      "[SGD | lr=0.1] Epoch 900/4000: train_loss=0.0335  test_loss=3.4704  λ_max=48.6339\n",
      "[SGD | lr=0.1] Epoch 901/4000: train_loss=0.0334  test_loss=3.4713  λ_max=47.6046\n",
      "[SGD | lr=0.1] Epoch 902/4000: train_loss=0.0333  test_loss=3.4724  λ_max=48.7354\n",
      "[SGD | lr=0.1] Epoch 903/4000: train_loss=0.0333  test_loss=3.4731  λ_max=47.5512\n",
      "[SGD | lr=0.1] Epoch 904/4000: train_loss=0.0332  test_loss=3.4738  λ_max=48.0395\n",
      "[SGD | lr=0.1] Epoch 905/4000: train_loss=0.0332  test_loss=3.4753  λ_max=46.8316\n",
      "[SGD | lr=0.1] Epoch 906/4000: train_loss=0.0331  test_loss=3.4764  λ_max=47.2538\n",
      "[SGD | lr=0.1] Iter 14500: loss=0.0330\n",
      "[SGD | lr=0.1] Epoch 907/4000: train_loss=0.0330  test_loss=3.4772  λ_max=49.2958\n",
      "[SGD | lr=0.1] Epoch 908/4000: train_loss=0.0330  test_loss=3.4786  λ_max=48.7842\n",
      "[SGD | lr=0.1] Epoch 909/4000: train_loss=0.0329  test_loss=3.4782  λ_max=47.7359\n",
      "[SGD | lr=0.1] Epoch 910/4000: train_loss=0.0329  test_loss=3.4805  λ_max=47.7694\n",
      "[SGD | lr=0.1] Epoch 911/4000: train_loss=0.0328  test_loss=3.4808  λ_max=47.5110\n",
      "[SGD | lr=0.1] Epoch 912/4000: train_loss=0.0327  test_loss=3.4816  λ_max=47.0864\n",
      "[SGD | lr=0.1] Iter 14600: loss=0.0326\n",
      "[SGD | lr=0.1] Epoch 913/4000: train_loss=0.0327  test_loss=3.4834  λ_max=47.3141\n",
      "[SGD | lr=0.1] Epoch 914/4000: train_loss=0.0326  test_loss=3.4834  λ_max=49.0204\n",
      "[SGD | lr=0.1] Epoch 915/4000: train_loss=0.0325  test_loss=3.4843  λ_max=49.1628\n",
      "[SGD | lr=0.1] Epoch 916/4000: train_loss=0.0325  test_loss=3.4855  λ_max=50.2948\n",
      "[SGD | lr=0.1] Epoch 917/4000: train_loss=0.0324  test_loss=3.4867  λ_max=47.0937\n",
      "[SGD | lr=0.1] Epoch 918/4000: train_loss=0.0324  test_loss=3.4875  λ_max=47.9799\n",
      "[SGD | lr=0.1] Iter 14700: loss=0.0320\n",
      "[SGD | lr=0.1] Epoch 919/4000: train_loss=0.0323  test_loss=3.4884  λ_max=48.2049\n",
      "[SGD | lr=0.1] Epoch 920/4000: train_loss=0.0322  test_loss=3.4889  λ_max=48.8584\n",
      "[SGD | lr=0.1] Epoch 921/4000: train_loss=0.0322  test_loss=3.4904  λ_max=48.5381\n",
      "[SGD | lr=0.1] Epoch 922/4000: train_loss=0.0321  test_loss=3.4913  λ_max=47.3659\n",
      "[SGD | lr=0.1] Epoch 923/4000: train_loss=0.0321  test_loss=3.4921  λ_max=47.1368\n",
      "[SGD | lr=0.1] Epoch 924/4000: train_loss=0.0320  test_loss=3.4928  λ_max=47.9484\n",
      "[SGD | lr=0.1] Iter 14800: loss=0.0317\n",
      "[SGD | lr=0.1] Epoch 925/4000: train_loss=0.0319  test_loss=3.4933  λ_max=49.4448\n",
      "[SGD | lr=0.1] Epoch 926/4000: train_loss=0.0319  test_loss=3.4948  λ_max=47.7356\n",
      "[SGD | lr=0.1] Epoch 927/4000: train_loss=0.0318  test_loss=3.4962  λ_max=50.0407\n",
      "[SGD | lr=0.1] Epoch 928/4000: train_loss=0.0318  test_loss=3.4970  λ_max=49.2662\n",
      "[SGD | lr=0.1] Epoch 929/4000: train_loss=0.0317  test_loss=3.4975  λ_max=47.9021\n",
      "[SGD | lr=0.1] Epoch 930/4000: train_loss=0.0317  test_loss=3.4983  λ_max=49.7177\n",
      "[SGD | lr=0.1] Epoch 931/4000: train_loss=0.0316  test_loss=3.4990  λ_max=49.9936\n",
      "[SGD | lr=0.1] Iter 14900: loss=0.0317\n",
      "[SGD | lr=0.1] Epoch 932/4000: train_loss=0.0316  test_loss=3.5003  λ_max=48.7426\n",
      "[SGD | lr=0.1] Epoch 933/4000: train_loss=0.0315  test_loss=3.5010  λ_max=49.4671\n",
      "[SGD | lr=0.1] Epoch 934/4000: train_loss=0.0314  test_loss=3.5020  λ_max=49.6411\n",
      "[SGD | lr=0.1] Epoch 935/4000: train_loss=0.0314  test_loss=3.5032  λ_max=48.0134\n",
      "[SGD | lr=0.1] Epoch 936/4000: train_loss=0.0313  test_loss=3.5039  λ_max=48.7186\n",
      "[SGD | lr=0.1] Epoch 937/4000: train_loss=0.0312  test_loss=3.5046  λ_max=48.9314\n",
      "[SGD | lr=0.1] Iter 15000: loss=0.0310\n",
      "[SGD | lr=0.1] Epoch 938/4000: train_loss=0.0312  test_loss=3.5054  λ_max=49.4233\n",
      "[SGD | lr=0.1] Epoch 939/4000: train_loss=0.0312  test_loss=3.5066  λ_max=49.0082\n",
      "[SGD | lr=0.1] Epoch 940/4000: train_loss=0.0311  test_loss=3.5073  λ_max=48.9193\n",
      "[SGD | lr=0.1] Epoch 941/4000: train_loss=0.0310  test_loss=3.5082  λ_max=50.2745\n",
      "[SGD | lr=0.1] Epoch 942/4000: train_loss=0.0310  test_loss=3.5089  λ_max=48.9389\n",
      "[SGD | lr=0.1] Epoch 943/4000: train_loss=0.0309  test_loss=3.5100  λ_max=49.8770\n",
      "[SGD | lr=0.1] Iter 15100: loss=0.0310\n",
      "[SGD | lr=0.1] Epoch 944/4000: train_loss=0.0309  test_loss=3.5109  λ_max=48.9173\n",
      "[SGD | lr=0.1] Epoch 945/4000: train_loss=0.0308  test_loss=3.5121  λ_max=48.7484\n",
      "[SGD | lr=0.1] Epoch 946/4000: train_loss=0.0308  test_loss=3.5125  λ_max=47.7951\n",
      "[SGD | lr=0.1] Epoch 947/4000: train_loss=0.0307  test_loss=3.5134  λ_max=49.7621\n",
      "[SGD | lr=0.1] Epoch 948/4000: train_loss=0.0307  test_loss=3.5148  λ_max=48.8230\n",
      "[SGD | lr=0.1] Epoch 949/4000: train_loss=0.0306  test_loss=3.5153  λ_max=49.5722\n",
      "[SGD | lr=0.1] Iter 15200: loss=0.0307\n",
      "[SGD | lr=0.1] Epoch 950/4000: train_loss=0.0306  test_loss=3.5170  λ_max=50.3588\n",
      "[SGD | lr=0.1] Epoch 951/4000: train_loss=0.0305  test_loss=3.5171  λ_max=48.4127\n",
      "[SGD | lr=0.1] Epoch 952/4000: train_loss=0.0305  test_loss=3.5180  λ_max=48.3071\n",
      "[SGD | lr=0.1] Epoch 953/4000: train_loss=0.0304  test_loss=3.5187  λ_max=47.7075\n",
      "[SGD | lr=0.1] Epoch 954/4000: train_loss=0.0303  test_loss=3.5195  λ_max=50.5744\n",
      "[SGD | lr=0.1] Epoch 955/4000: train_loss=0.0303  test_loss=3.5207  λ_max=49.2953\n",
      "[SGD | lr=0.1] Epoch 956/4000: train_loss=0.0302  test_loss=3.5211  λ_max=49.9409\n",
      "[SGD | lr=0.1] Iter 15300: loss=0.0304\n",
      "[SGD | lr=0.1] Epoch 957/4000: train_loss=0.0302  test_loss=3.5228  λ_max=49.9213\n",
      "[SGD | lr=0.1] Epoch 958/4000: train_loss=0.0301  test_loss=3.5232  λ_max=48.7312\n",
      "[SGD | lr=0.1] Epoch 959/4000: train_loss=0.0301  test_loss=3.5239  λ_max=49.5456\n",
      "[SGD | lr=0.1] Epoch 960/4000: train_loss=0.0300  test_loss=3.5250  λ_max=49.9409\n",
      "[SGD | lr=0.1] Epoch 961/4000: train_loss=0.0300  test_loss=3.5262  λ_max=48.8545\n",
      "[SGD | lr=0.1] Epoch 962/4000: train_loss=0.0299  test_loss=3.5267  λ_max=49.3455\n",
      "[SGD | lr=0.1] Iter 15400: loss=0.0301\n",
      "[SGD | lr=0.1] Epoch 963/4000: train_loss=0.0299  test_loss=3.5281  λ_max=50.1942\n",
      "[SGD | lr=0.1] Epoch 964/4000: train_loss=0.0298  test_loss=3.5286  λ_max=48.9332\n",
      "[SGD | lr=0.1] Epoch 965/4000: train_loss=0.0298  test_loss=3.5294  λ_max=49.0655\n",
      "[SGD | lr=0.1] Epoch 966/4000: train_loss=0.0297  test_loss=3.5299  λ_max=50.3129\n",
      "[SGD | lr=0.1] Epoch 967/4000: train_loss=0.0297  test_loss=3.5309  λ_max=49.3124\n",
      "[SGD | lr=0.1] Epoch 968/4000: train_loss=0.0296  test_loss=3.5320  λ_max=50.1017\n",
      "[SGD | lr=0.1] Iter 15500: loss=0.0299\n",
      "[SGD | lr=0.1] Epoch 969/4000: train_loss=0.0296  test_loss=3.5330  λ_max=50.7876\n",
      "[SGD | lr=0.1] Epoch 970/4000: train_loss=0.0295  test_loss=3.5336  λ_max=49.9923\n",
      "[SGD | lr=0.1] Epoch 971/4000: train_loss=0.0294  test_loss=3.5347  λ_max=50.1409\n",
      "[SGD | lr=0.1] Epoch 972/4000: train_loss=0.0294  test_loss=3.5356  λ_max=48.9698\n",
      "[SGD | lr=0.1] Epoch 973/4000: train_loss=0.0294  test_loss=3.5362  λ_max=49.9763\n",
      "[SGD | lr=0.1] Epoch 974/4000: train_loss=0.0293  test_loss=3.5370  λ_max=48.6713\n",
      "[SGD | lr=0.1] Iter 15600: loss=0.0294\n",
      "[SGD | lr=0.1] Epoch 975/4000: train_loss=0.0293  test_loss=3.5378  λ_max=48.3006\n",
      "[SGD | lr=0.1] Epoch 976/4000: train_loss=0.0292  test_loss=3.5391  λ_max=49.2825\n",
      "[SGD | lr=0.1] Epoch 977/4000: train_loss=0.0292  test_loss=3.5398  λ_max=51.7045\n",
      "[SGD | lr=0.1] Epoch 978/4000: train_loss=0.0291  test_loss=3.5404  λ_max=49.9990\n",
      "[SGD | lr=0.1] Epoch 979/4000: train_loss=0.0291  test_loss=3.5417  λ_max=49.0752\n",
      "[SGD | lr=0.1] Epoch 980/4000: train_loss=0.0290  test_loss=3.5424  λ_max=48.9734\n",
      "[SGD | lr=0.1] Epoch 981/4000: train_loss=0.0290  test_loss=3.5433  λ_max=48.2623\n",
      "[SGD | lr=0.1] Iter 15700: loss=0.0285\n",
      "[SGD | lr=0.1] Epoch 982/4000: train_loss=0.0289  test_loss=3.5443  λ_max=50.7365\n",
      "[SGD | lr=0.1] Epoch 983/4000: train_loss=0.0289  test_loss=3.5446  λ_max=48.6101\n",
      "[SGD | lr=0.1] Epoch 984/4000: train_loss=0.0288  test_loss=3.5453  λ_max=50.0728\n",
      "[SGD | lr=0.1] Epoch 985/4000: train_loss=0.0288  test_loss=3.5463  λ_max=49.8357\n",
      "[SGD | lr=0.1] Epoch 986/4000: train_loss=0.0287  test_loss=3.5473  λ_max=49.5190\n",
      "[SGD | lr=0.1] Epoch 987/4000: train_loss=0.0287  test_loss=3.5480  λ_max=51.0991\n",
      "[SGD | lr=0.1] Iter 15800: loss=0.0288\n",
      "[SGD | lr=0.1] Epoch 988/4000: train_loss=0.0287  test_loss=3.5492  λ_max=50.6829\n",
      "[SGD | lr=0.1] Epoch 989/4000: train_loss=0.0286  test_loss=3.5498  λ_max=50.8186\n",
      "[SGD | lr=0.1] Epoch 990/4000: train_loss=0.0285  test_loss=3.5503  λ_max=50.6860\n",
      "[SGD | lr=0.1] Epoch 991/4000: train_loss=0.0285  test_loss=3.5514  λ_max=49.9414\n",
      "[SGD | lr=0.1] Epoch 992/4000: train_loss=0.0284  test_loss=3.5524  λ_max=49.2475\n",
      "[SGD | lr=0.1] Epoch 993/4000: train_loss=0.0284  test_loss=3.5532  λ_max=51.2715\n",
      "[SGD | lr=0.1] Iter 15900: loss=0.0284\n",
      "[SGD | lr=0.1] Epoch 994/4000: train_loss=0.0284  test_loss=3.5542  λ_max=48.9589\n",
      "[SGD | lr=0.1] Epoch 995/4000: train_loss=0.0283  test_loss=3.5546  λ_max=51.6948\n",
      "[SGD | lr=0.1] Epoch 996/4000: train_loss=0.0283  test_loss=3.5561  λ_max=50.0464\n",
      "[SGD | lr=0.1] Epoch 997/4000: train_loss=0.0282  test_loss=3.5568  λ_max=52.5077\n",
      "[SGD | lr=0.1] Epoch 998/4000: train_loss=0.0282  test_loss=3.5573  λ_max=50.7021\n",
      "[SGD | lr=0.1] Epoch 999/4000: train_loss=0.0281  test_loss=3.5583  λ_max=50.7337\n",
      "[SGD | lr=0.1] Iter 16000: loss=0.0282\n",
      "[SGD | lr=0.1] Epoch 1000/4000: train_loss=0.0281  test_loss=3.5588  λ_max=51.8134\n",
      "[SGD | lr=0.1] Epoch 1001/4000: train_loss=0.0280  test_loss=3.5601  λ_max=50.6726\n",
      "[SGD | lr=0.1] Epoch 1002/4000: train_loss=0.0280  test_loss=3.5607  λ_max=50.1873\n",
      "[SGD | lr=0.1] Epoch 1003/4000: train_loss=0.0279  test_loss=3.5615  λ_max=52.4443\n",
      "[SGD | lr=0.1] Epoch 1004/4000: train_loss=0.0279  test_loss=3.5629  λ_max=51.6977\n",
      "[SGD | lr=0.1] Epoch 1005/4000: train_loss=0.0278  test_loss=3.5629  λ_max=51.0094\n",
      "[SGD | lr=0.1] Epoch 1006/4000: train_loss=0.0278  test_loss=3.5640  λ_max=51.2026\n",
      "[SGD | lr=0.1] Iter 16100: loss=0.0279\n",
      "[SGD | lr=0.1] Epoch 1007/4000: train_loss=0.0277  test_loss=3.5647  λ_max=50.8333\n",
      "[SGD | lr=0.1] Epoch 1008/4000: train_loss=0.0277  test_loss=3.5657  λ_max=51.5206\n",
      "[SGD | lr=0.1] Epoch 1009/4000: train_loss=0.0277  test_loss=3.5665  λ_max=50.8134\n",
      "[SGD | lr=0.1] Epoch 1010/4000: train_loss=0.0276  test_loss=3.5672  λ_max=49.4277\n",
      "[SGD | lr=0.1] Epoch 1011/4000: train_loss=0.0276  test_loss=3.5683  λ_max=51.0216\n",
      "[SGD | lr=0.1] Epoch 1012/4000: train_loss=0.0275  test_loss=3.5693  λ_max=50.5351\n",
      "[SGD | lr=0.1] Iter 16200: loss=0.0273\n",
      "[SGD | lr=0.1] Epoch 1013/4000: train_loss=0.0275  test_loss=3.5698  λ_max=50.4299\n",
      "[SGD | lr=0.1] Epoch 1014/4000: train_loss=0.0274  test_loss=3.5710  λ_max=50.6774\n",
      "[SGD | lr=0.1] Epoch 1015/4000: train_loss=0.0274  test_loss=3.5713  λ_max=50.7496\n",
      "[SGD | lr=0.1] Epoch 1016/4000: train_loss=0.0273  test_loss=3.5724  λ_max=49.1562\n",
      "[SGD | lr=0.1] Epoch 1017/4000: train_loss=0.0273  test_loss=3.5730  λ_max=49.9762\n",
      "[SGD | lr=0.1] Epoch 1018/4000: train_loss=0.0273  test_loss=3.5739  λ_max=50.7929\n",
      "[SGD | lr=0.1] Iter 16300: loss=0.0271\n",
      "[SGD | lr=0.1] Epoch 1019/4000: train_loss=0.0272  test_loss=3.5746  λ_max=50.6157\n",
      "[SGD | lr=0.1] Epoch 1020/4000: train_loss=0.0272  test_loss=3.5757  λ_max=52.0101\n",
      "[SGD | lr=0.1] Epoch 1021/4000: train_loss=0.0271  test_loss=3.5759  λ_max=48.9531\n",
      "[SGD | lr=0.1] Epoch 1022/4000: train_loss=0.0271  test_loss=3.5771  λ_max=51.2761\n",
      "[SGD | lr=0.1] Epoch 1023/4000: train_loss=0.0271  test_loss=3.5781  λ_max=49.9602\n",
      "[SGD | lr=0.1] Epoch 1024/4000: train_loss=0.0270  test_loss=3.5786  λ_max=51.4876\n",
      "[SGD | lr=0.1] Iter 16400: loss=0.0272\n",
      "[SGD | lr=0.1] Epoch 1025/4000: train_loss=0.0270  test_loss=3.5799  λ_max=51.5747\n",
      "[SGD | lr=0.1] Epoch 1026/4000: train_loss=0.0269  test_loss=3.5805  λ_max=51.4670\n",
      "[SGD | lr=0.1] Epoch 1027/4000: train_loss=0.0269  test_loss=3.5811  λ_max=51.3478\n",
      "[SGD | lr=0.1] Epoch 1028/4000: train_loss=0.0268  test_loss=3.5818  λ_max=51.6502\n",
      "[SGD | lr=0.1] Epoch 1029/4000: train_loss=0.0268  test_loss=3.5830  λ_max=51.4846\n",
      "[SGD | lr=0.1] Epoch 1030/4000: train_loss=0.0268  test_loss=3.5835  λ_max=51.4752\n",
      "[SGD | lr=0.1] Epoch 1031/4000: train_loss=0.0267  test_loss=3.5848  λ_max=50.0510\n",
      "[SGD | lr=0.1] Iter 16500: loss=0.0263\n",
      "[SGD | lr=0.1] Epoch 1032/4000: train_loss=0.0266  test_loss=3.5852  λ_max=52.3108\n",
      "[SGD | lr=0.1] Epoch 1033/4000: train_loss=0.0266  test_loss=3.5866  λ_max=52.5839\n",
      "[SGD | lr=0.1] Epoch 1034/4000: train_loss=0.0266  test_loss=3.5869  λ_max=50.8851\n",
      "[SGD | lr=0.1] Epoch 1035/4000: train_loss=0.0265  test_loss=3.5876  λ_max=51.7250\n",
      "[SGD | lr=0.1] Epoch 1036/4000: train_loss=0.0265  test_loss=3.5887  λ_max=50.8448\n",
      "[SGD | lr=0.1] Epoch 1037/4000: train_loss=0.0265  test_loss=3.5894  λ_max=50.2091\n",
      "[SGD | lr=0.1] Iter 16600: loss=0.0268\n",
      "[SGD | lr=0.1] Epoch 1038/4000: train_loss=0.0264  test_loss=3.5902  λ_max=53.7083\n",
      "[SGD | lr=0.1] Epoch 1039/4000: train_loss=0.0264  test_loss=3.5908  λ_max=50.0348\n",
      "[SGD | lr=0.1] Epoch 1040/4000: train_loss=0.0263  test_loss=3.5918  λ_max=49.8558\n",
      "[SGD | lr=0.1] Epoch 1041/4000: train_loss=0.0263  test_loss=3.5924  λ_max=51.5029\n",
      "[SGD | lr=0.1] Epoch 1042/4000: train_loss=0.0262  test_loss=3.5931  λ_max=52.3356\n",
      "[SGD | lr=0.1] Epoch 1043/4000: train_loss=0.0262  test_loss=3.5941  λ_max=49.2090\n",
      "[SGD | lr=0.1] Iter 16700: loss=0.0269\n",
      "[SGD | lr=0.1] Epoch 1044/4000: train_loss=0.0262  test_loss=3.5952  λ_max=51.3222\n",
      "[SGD | lr=0.1] Epoch 1045/4000: train_loss=0.0261  test_loss=3.5959  λ_max=50.4158\n",
      "[SGD | lr=0.1] Epoch 1046/4000: train_loss=0.0261  test_loss=3.5964  λ_max=51.8734\n",
      "[SGD | lr=0.1] Epoch 1047/4000: train_loss=0.0261  test_loss=3.5970  λ_max=52.7903\n",
      "[SGD | lr=0.1] Epoch 1048/4000: train_loss=0.0260  test_loss=3.5979  λ_max=51.1211\n",
      "[SGD | lr=0.1] Epoch 1049/4000: train_loss=0.0260  test_loss=3.5983  λ_max=51.4474\n",
      "[SGD | lr=0.1] Iter 16800: loss=0.0259\n",
      "[SGD | lr=0.1] Epoch 1050/4000: train_loss=0.0259  test_loss=3.5992  λ_max=51.4116\n",
      "[SGD | lr=0.1] Epoch 1051/4000: train_loss=0.0259  test_loss=3.6004  λ_max=52.8802\n",
      "[SGD | lr=0.1] Epoch 1052/4000: train_loss=0.0258  test_loss=3.6011  λ_max=52.8625\n",
      "[SGD | lr=0.1] Epoch 1053/4000: train_loss=0.0258  test_loss=3.6019  λ_max=51.1340\n",
      "[SGD | lr=0.1] Epoch 1054/4000: train_loss=0.0258  test_loss=3.6027  λ_max=51.6054\n",
      "[SGD | lr=0.1] Epoch 1055/4000: train_loss=0.0257  test_loss=3.6042  λ_max=52.0930\n",
      "[SGD | lr=0.1] Epoch 1056/4000: train_loss=0.0257  test_loss=3.6045  λ_max=52.0982\n",
      "[SGD | lr=0.1] Iter 16900: loss=0.0252\n",
      "[SGD | lr=0.1] Epoch 1057/4000: train_loss=0.0257  test_loss=3.6048  λ_max=51.4591\n",
      "[SGD | lr=0.1] Epoch 1058/4000: train_loss=0.0256  test_loss=3.6059  λ_max=52.4480\n",
      "[SGD | lr=0.1] Epoch 1059/4000: train_loss=0.0256  test_loss=3.6068  λ_max=52.4217\n",
      "[SGD | lr=0.1] Epoch 1060/4000: train_loss=0.0255  test_loss=3.6074  λ_max=52.3766\n",
      "[SGD | lr=0.1] Epoch 1061/4000: train_loss=0.0255  test_loss=3.6081  λ_max=52.0609\n",
      "[SGD | lr=0.1] Epoch 1062/4000: train_loss=0.0255  test_loss=3.6094  λ_max=53.0218\n",
      "[SGD | lr=0.1] Iter 17000: loss=0.0252\n",
      "[SGD | lr=0.1] Epoch 1063/4000: train_loss=0.0254  test_loss=3.6097  λ_max=50.5598\n",
      "[SGD | lr=0.1] Epoch 1064/4000: train_loss=0.0254  test_loss=3.6104  λ_max=51.2858\n",
      "[SGD | lr=0.1] Epoch 1065/4000: train_loss=0.0253  test_loss=3.6113  λ_max=48.3685\n",
      "[SGD | lr=0.1] Epoch 1066/4000: train_loss=0.0253  test_loss=3.6125  λ_max=53.1604\n",
      "[SGD | lr=0.1] Epoch 1067/4000: train_loss=0.0252  test_loss=3.6128  λ_max=51.9110\n",
      "[SGD | lr=0.1] Epoch 1068/4000: train_loss=0.0252  test_loss=3.6135  λ_max=52.4055\n",
      "[SGD | lr=0.1] Iter 17100: loss=0.0252\n",
      "[SGD | lr=0.1] Epoch 1069/4000: train_loss=0.0252  test_loss=3.6142  λ_max=52.7967\n",
      "[SGD | lr=0.1] Epoch 1070/4000: train_loss=0.0252  test_loss=3.6157  λ_max=50.9874\n",
      "[SGD | lr=0.1] Epoch 1071/4000: train_loss=0.0251  test_loss=3.6160  λ_max=53.0531\n",
      "[SGD | lr=0.1] Epoch 1072/4000: train_loss=0.0251  test_loss=3.6167  λ_max=50.9732\n",
      "[SGD | lr=0.1] Epoch 1073/4000: train_loss=0.0250  test_loss=3.6178  λ_max=52.1776\n",
      "[SGD | lr=0.1] Epoch 1074/4000: train_loss=0.0250  test_loss=3.6183  λ_max=51.2798\n",
      "[SGD | lr=0.1] Iter 17200: loss=0.0248\n",
      "[SGD | lr=0.1] Epoch 1075/4000: train_loss=0.0250  test_loss=3.6191  λ_max=52.6058\n",
      "[SGD | lr=0.1] Epoch 1076/4000: train_loss=0.0249  test_loss=3.6201  λ_max=52.3970\n",
      "[SGD | lr=0.1] Epoch 1077/4000: train_loss=0.0249  test_loss=3.6207  λ_max=50.8879\n",
      "[SGD | lr=0.1] Epoch 1078/4000: train_loss=0.0249  test_loss=3.6217  λ_max=51.3130\n",
      "[SGD | lr=0.1] Epoch 1079/4000: train_loss=0.0248  test_loss=3.6223  λ_max=51.2913\n",
      "[SGD | lr=0.1] Epoch 1080/4000: train_loss=0.0248  test_loss=3.6230  λ_max=51.7657\n",
      "[SGD | lr=0.1] Epoch 1081/4000: train_loss=0.0247  test_loss=3.6235  λ_max=50.3794\n",
      "[SGD | lr=0.1] Iter 17300: loss=0.0245\n",
      "[SGD | lr=0.1] Epoch 1082/4000: train_loss=0.0247  test_loss=3.6245  λ_max=50.6070\n",
      "[SGD | lr=0.1] Epoch 1083/4000: train_loss=0.0247  test_loss=3.6251  λ_max=51.7252\n",
      "[SGD | lr=0.1] Epoch 1084/4000: train_loss=0.0246  test_loss=3.6256  λ_max=53.4597\n",
      "[SGD | lr=0.1] Epoch 1085/4000: train_loss=0.0246  test_loss=3.6265  λ_max=52.6042\n",
      "[SGD | lr=0.1] Epoch 1086/4000: train_loss=0.0246  test_loss=3.6271  λ_max=51.8007\n",
      "[SGD | lr=0.1] Epoch 1087/4000: train_loss=0.0245  test_loss=3.6281  λ_max=53.3164\n",
      "[SGD | lr=0.1] Iter 17400: loss=0.0242\n",
      "[SGD | lr=0.1] Epoch 1088/4000: train_loss=0.0245  test_loss=3.6284  λ_max=50.8042\n",
      "[SGD | lr=0.1] Epoch 1089/4000: train_loss=0.0244  test_loss=3.6297  λ_max=53.9422\n",
      "[SGD | lr=0.1] Epoch 1090/4000: train_loss=0.0244  test_loss=3.6304  λ_max=51.6105\n",
      "[SGD | lr=0.1] Epoch 1091/4000: train_loss=0.0244  test_loss=3.6311  λ_max=51.3841\n",
      "[SGD | lr=0.1] Epoch 1092/4000: train_loss=0.0243  test_loss=3.6319  λ_max=53.9522\n",
      "[SGD | lr=0.1] Epoch 1093/4000: train_loss=0.0243  test_loss=3.6327  λ_max=52.3816\n",
      "[SGD | lr=0.1] Iter 17500: loss=0.0245\n",
      "[SGD | lr=0.1] Epoch 1094/4000: train_loss=0.0243  test_loss=3.6331  λ_max=51.5412\n",
      "[SGD | lr=0.1] Epoch 1095/4000: train_loss=0.0242  test_loss=3.6341  λ_max=52.6911\n",
      "[SGD | lr=0.1] Epoch 1096/4000: train_loss=0.0242  test_loss=3.6354  λ_max=51.8269\n",
      "[SGD | lr=0.1] Epoch 1097/4000: train_loss=0.0242  test_loss=3.6358  λ_max=53.6634\n",
      "[SGD | lr=0.1] Epoch 1098/4000: train_loss=0.0241  test_loss=3.6365  λ_max=51.8717\n",
      "[SGD | lr=0.1] Epoch 1099/4000: train_loss=0.0241  test_loss=3.6371  λ_max=53.2880\n",
      "[SGD | lr=0.1] Iter 17600: loss=0.0247\n",
      "[SGD | lr=0.1] Epoch 1100/4000: train_loss=0.0241  test_loss=3.6379  λ_max=51.4317\n",
      "[SGD | lr=0.1] Epoch 1101/4000: train_loss=0.0240  test_loss=3.6385  λ_max=52.8460\n",
      "[SGD | lr=0.1] Epoch 1102/4000: train_loss=0.0240  test_loss=3.6391  λ_max=53.9936\n",
      "[SGD | lr=0.1] Epoch 1103/4000: train_loss=0.0239  test_loss=3.6399  λ_max=50.8510\n",
      "[SGD | lr=0.1] Epoch 1104/4000: train_loss=0.0239  test_loss=3.6408  λ_max=51.8212\n",
      "[SGD | lr=0.1] Epoch 1105/4000: train_loss=0.0239  test_loss=3.6417  λ_max=52.6425\n",
      "[SGD | lr=0.1] Epoch 1106/4000: train_loss=0.0238  test_loss=3.6422  λ_max=52.5758\n",
      "[SGD | lr=0.1] Iter 17700: loss=0.0238\n",
      "[SGD | lr=0.1] Epoch 1107/4000: train_loss=0.0238  test_loss=3.6434  λ_max=52.0633\n",
      "[SGD | lr=0.1] Epoch 1108/4000: train_loss=0.0238  test_loss=3.6437  λ_max=51.0576\n",
      "[SGD | lr=0.1] Epoch 1109/4000: train_loss=0.0237  test_loss=3.6449  λ_max=52.2335\n",
      "[SGD | lr=0.1] Epoch 1110/4000: train_loss=0.0237  test_loss=3.6457  λ_max=52.4070\n",
      "[SGD | lr=0.1] Epoch 1111/4000: train_loss=0.0237  test_loss=3.6462  λ_max=51.2527\n",
      "[SGD | lr=0.1] Epoch 1112/4000: train_loss=0.0236  test_loss=3.6467  λ_max=52.7980\n",
      "[SGD | lr=0.1] Iter 17800: loss=0.0239\n",
      "[SGD | lr=0.1] Epoch 1113/4000: train_loss=0.0236  test_loss=3.6473  λ_max=52.8615\n",
      "[SGD | lr=0.1] Epoch 1114/4000: train_loss=0.0236  test_loss=3.6483  λ_max=52.3180\n",
      "[SGD | lr=0.1] Epoch 1115/4000: train_loss=0.0235  test_loss=3.6492  λ_max=51.1588\n",
      "[SGD | lr=0.1] Epoch 1116/4000: train_loss=0.0235  test_loss=3.6496  λ_max=50.8905\n",
      "[SGD | lr=0.1] Epoch 1117/4000: train_loss=0.0235  test_loss=3.6504  λ_max=52.8102\n",
      "[SGD | lr=0.1] Epoch 1118/4000: train_loss=0.0234  test_loss=3.6513  λ_max=52.1259\n",
      "[SGD | lr=0.1] Iter 17900: loss=0.0228\n",
      "[SGD | lr=0.1] Epoch 1119/4000: train_loss=0.0234  test_loss=3.6517  λ_max=53.5643\n",
      "[SGD | lr=0.1] Epoch 1120/4000: train_loss=0.0234  test_loss=3.6527  λ_max=52.2673\n",
      "[SGD | lr=0.1] Epoch 1121/4000: train_loss=0.0233  test_loss=3.6533  λ_max=52.9949\n",
      "[SGD | lr=0.1] Epoch 1122/4000: train_loss=0.0233  test_loss=3.6538  λ_max=51.3808\n",
      "[SGD | lr=0.1] Epoch 1123/4000: train_loss=0.0233  test_loss=3.6547  λ_max=53.6534\n",
      "[SGD | lr=0.1] Epoch 1124/4000: train_loss=0.0232  test_loss=3.6557  λ_max=53.6206\n",
      "[SGD | lr=0.1] Iter 18000: loss=0.0240\n",
      "[SGD | lr=0.1] Epoch 1125/4000: train_loss=0.0232  test_loss=3.6568  λ_max=51.6361\n",
      "[SGD | lr=0.1] Epoch 1126/4000: train_loss=0.0232  test_loss=3.6571  λ_max=51.5586\n",
      "[SGD | lr=0.1] Epoch 1127/4000: train_loss=0.0231  test_loss=3.6578  λ_max=53.4858\n",
      "[SGD | lr=0.1] Epoch 1128/4000: train_loss=0.0231  test_loss=3.6580  λ_max=51.8883\n",
      "[SGD | lr=0.1] Epoch 1129/4000: train_loss=0.0231  test_loss=3.6592  λ_max=52.1659\n",
      "[SGD | lr=0.1] Epoch 1130/4000: train_loss=0.0230  test_loss=3.6600  λ_max=52.0823\n",
      "[SGD | lr=0.1] Epoch 1131/4000: train_loss=0.0230  test_loss=3.6605  λ_max=51.7292\n",
      "[SGD | lr=0.1] Iter 18100: loss=0.0227\n",
      "[SGD | lr=0.1] Epoch 1132/4000: train_loss=0.0230  test_loss=3.6612  λ_max=51.9032\n",
      "[SGD | lr=0.1] Epoch 1133/4000: train_loss=0.0229  test_loss=3.6623  λ_max=52.0468\n",
      "[SGD | lr=0.1] Epoch 1134/4000: train_loss=0.0229  test_loss=3.6626  λ_max=53.2287\n",
      "[SGD | lr=0.1] Epoch 1135/4000: train_loss=0.0229  test_loss=3.6638  λ_max=52.1106\n",
      "[SGD | lr=0.1] Epoch 1136/4000: train_loss=0.0229  test_loss=3.6643  λ_max=53.0248\n",
      "[SGD | lr=0.1] Epoch 1137/4000: train_loss=0.0228  test_loss=3.6649  λ_max=52.0058\n",
      "[SGD | lr=0.1] Iter 18200: loss=0.0227\n",
      "[SGD | lr=0.1] Epoch 1138/4000: train_loss=0.0228  test_loss=3.6658  λ_max=54.7765\n",
      "[SGD | lr=0.1] Epoch 1139/4000: train_loss=0.0228  test_loss=3.6662  λ_max=54.4353\n",
      "[SGD | lr=0.1] Epoch 1140/4000: train_loss=0.0227  test_loss=3.6669  λ_max=53.5777\n",
      "[SGD | lr=0.1] Epoch 1141/4000: train_loss=0.0227  test_loss=3.6677  λ_max=52.4769\n",
      "[SGD | lr=0.1] Epoch 1142/4000: train_loss=0.0227  test_loss=3.6686  λ_max=53.6171\n",
      "[SGD | lr=0.1] Epoch 1143/4000: train_loss=0.0226  test_loss=3.6689  λ_max=53.4124\n",
      "[SGD | lr=0.1] Iter 18300: loss=0.0226\n",
      "[SGD | lr=0.1] Epoch 1144/4000: train_loss=0.0226  test_loss=3.6698  λ_max=53.3055\n",
      "[SGD | lr=0.1] Epoch 1145/4000: train_loss=0.0226  test_loss=3.6704  λ_max=53.8981\n",
      "[SGD | lr=0.1] Epoch 1146/4000: train_loss=0.0225  test_loss=3.6713  λ_max=53.5925\n",
      "[SGD | lr=0.1] Epoch 1147/4000: train_loss=0.0225  test_loss=3.6721  λ_max=53.1660\n",
      "[SGD | lr=0.1] Epoch 1148/4000: train_loss=0.0225  test_loss=3.6726  λ_max=52.5475\n",
      "[SGD | lr=0.1] Epoch 1149/4000: train_loss=0.0224  test_loss=3.6739  λ_max=51.9259\n",
      "[SGD | lr=0.1] Iter 18400: loss=0.0221\n",
      "[SGD | lr=0.1] Epoch 1150/4000: train_loss=0.0224  test_loss=3.6745  λ_max=54.8219\n",
      "[SGD | lr=0.1] Epoch 1151/4000: train_loss=0.0224  test_loss=3.6747  λ_max=52.4655\n",
      "[SGD | lr=0.1] Epoch 1152/4000: train_loss=0.0223  test_loss=3.6758  λ_max=52.5194\n",
      "[SGD | lr=0.1] Epoch 1153/4000: train_loss=0.0223  test_loss=3.6763  λ_max=53.3698\n",
      "[SGD | lr=0.1] Epoch 1154/4000: train_loss=0.0223  test_loss=3.6769  λ_max=52.8840\n",
      "[SGD | lr=0.1] Epoch 1155/4000: train_loss=0.0223  test_loss=3.6775  λ_max=54.5943\n",
      "[SGD | lr=0.1] Epoch 1156/4000: train_loss=0.0222  test_loss=3.6783  λ_max=55.4469\n",
      "[SGD | lr=0.1] Iter 18500: loss=0.0223\n",
      "[SGD | lr=0.1] Epoch 1157/4000: train_loss=0.0222  test_loss=3.6793  λ_max=53.4725\n",
      "[SGD | lr=0.1] Epoch 1158/4000: train_loss=0.0222  test_loss=3.6798  λ_max=53.2216\n",
      "[SGD | lr=0.1] Epoch 1159/4000: train_loss=0.0221  test_loss=3.6806  λ_max=53.2582\n",
      "[SGD | lr=0.1] Epoch 1160/4000: train_loss=0.0221  test_loss=3.6807  λ_max=52.0473\n",
      "[SGD | lr=0.1] Epoch 1161/4000: train_loss=0.0221  test_loss=3.6818  λ_max=52.5635\n",
      "[SGD | lr=0.1] Epoch 1162/4000: train_loss=0.0220  test_loss=3.6827  λ_max=53.4265\n",
      "[SGD | lr=0.1] Iter 18600: loss=0.0224\n",
      "[SGD | lr=0.1] Epoch 1163/4000: train_loss=0.0220  test_loss=3.6833  λ_max=52.3511\n",
      "[SGD | lr=0.1] Epoch 1164/4000: train_loss=0.0220  test_loss=3.6838  λ_max=52.5799\n",
      "[SGD | lr=0.1] Epoch 1165/4000: train_loss=0.0220  test_loss=3.6849  λ_max=53.7372\n",
      "[SGD | lr=0.1] Epoch 1166/4000: train_loss=0.0219  test_loss=3.6852  λ_max=53.8610\n",
      "[SGD | lr=0.1] Epoch 1167/4000: train_loss=0.0219  test_loss=3.6859  λ_max=54.5073\n",
      "[SGD | lr=0.1] Epoch 1168/4000: train_loss=0.0219  test_loss=3.6866  λ_max=53.8690\n",
      "[SGD | lr=0.1] Iter 18700: loss=0.0217\n",
      "[SGD | lr=0.1] Epoch 1169/4000: train_loss=0.0218  test_loss=3.6871  λ_max=52.1062\n",
      "[SGD | lr=0.1] Epoch 1170/4000: train_loss=0.0218  test_loss=3.6883  λ_max=54.0790\n",
      "[SGD | lr=0.1] Epoch 1171/4000: train_loss=0.0218  test_loss=3.6890  λ_max=54.0050\n",
      "[SGD | lr=0.1] Epoch 1172/4000: train_loss=0.0218  test_loss=3.6898  λ_max=53.9270\n",
      "[SGD | lr=0.1] Epoch 1173/4000: train_loss=0.0217  test_loss=3.6902  λ_max=54.1616\n",
      "[SGD | lr=0.1] Epoch 1174/4000: train_loss=0.0217  test_loss=3.6907  λ_max=52.1047\n",
      "[SGD | lr=0.1] Iter 18800: loss=0.0212\n",
      "[SGD | lr=0.1] Epoch 1175/4000: train_loss=0.0217  test_loss=3.6916  λ_max=54.4403\n",
      "[SGD | lr=0.1] Epoch 1176/4000: train_loss=0.0216  test_loss=3.6919  λ_max=53.9579\n",
      "[SGD | lr=0.1] Epoch 1177/4000: train_loss=0.0216  test_loss=3.6934  λ_max=54.0453\n",
      "[SGD | lr=0.1] Epoch 1178/4000: train_loss=0.0216  test_loss=3.6938  λ_max=54.6490\n",
      "[SGD | lr=0.1] Epoch 1179/4000: train_loss=0.0215  test_loss=3.6944  λ_max=54.2977\n",
      "[SGD | lr=0.1] Epoch 1180/4000: train_loss=0.0215  test_loss=3.6950  λ_max=54.6102\n",
      "[SGD | lr=0.1] Epoch 1181/4000: train_loss=0.0215  test_loss=3.6960  λ_max=54.0937\n",
      "[SGD | lr=0.1] Iter 18900: loss=0.0213\n",
      "[SGD | lr=0.1] Epoch 1182/4000: train_loss=0.0215  test_loss=3.6966  λ_max=54.0489\n",
      "[SGD | lr=0.1] Epoch 1183/4000: train_loss=0.0214  test_loss=3.6971  λ_max=54.4675\n",
      "[SGD | lr=0.1] Epoch 1184/4000: train_loss=0.0214  test_loss=3.6980  λ_max=53.8939\n",
      "[SGD | lr=0.1] Epoch 1185/4000: train_loss=0.0214  test_loss=3.6986  λ_max=54.3694\n",
      "[SGD | lr=0.1] Epoch 1186/4000: train_loss=0.0213  test_loss=3.6989  λ_max=55.5075\n",
      "[SGD | lr=0.1] Epoch 1187/4000: train_loss=0.0213  test_loss=3.6998  λ_max=53.4833\n",
      "[SGD | lr=0.1] Iter 19000: loss=0.0218\n",
      "[SGD | lr=0.1] Epoch 1188/4000: train_loss=0.0213  test_loss=3.7002  λ_max=54.7456\n",
      "[SGD | lr=0.1] Epoch 1189/4000: train_loss=0.0213  test_loss=3.7012  λ_max=53.8378\n",
      "[SGD | lr=0.1] Epoch 1190/4000: train_loss=0.0212  test_loss=3.7020  λ_max=53.9220\n",
      "[SGD | lr=0.1] Epoch 1191/4000: train_loss=0.0212  test_loss=3.7023  λ_max=54.1890\n",
      "[SGD | lr=0.1] Epoch 1192/4000: train_loss=0.0212  test_loss=3.7033  λ_max=55.3304\n",
      "[SGD | lr=0.1] Epoch 1193/4000: train_loss=0.0212  test_loss=3.7040  λ_max=53.3211\n",
      "[SGD | lr=0.1] Iter 19100: loss=0.0208\n",
      "[SGD | lr=0.1] Epoch 1194/4000: train_loss=0.0211  test_loss=3.7047  λ_max=53.4280\n",
      "[SGD | lr=0.1] Epoch 1195/4000: train_loss=0.0211  test_loss=3.7053  λ_max=55.9655\n",
      "[SGD | lr=0.1] Epoch 1196/4000: train_loss=0.0211  test_loss=3.7060  λ_max=54.1983\n",
      "[SGD | lr=0.1] Epoch 1197/4000: train_loss=0.0211  test_loss=3.7062  λ_max=53.3229\n",
      "[SGD | lr=0.1] Epoch 1198/4000: train_loss=0.0210  test_loss=3.7078  λ_max=53.7984\n",
      "[SGD | lr=0.1] Epoch 1199/4000: train_loss=0.0210  test_loss=3.7082  λ_max=53.8612\n",
      "[SGD | lr=0.1] Iter 19200: loss=0.0209\n",
      "[SGD | lr=0.1] Epoch 1200/4000: train_loss=0.0210  test_loss=3.7087  λ_max=55.0353\n",
      "[SGD | lr=0.1] Epoch 1201/4000: train_loss=0.0209  test_loss=3.7092  λ_max=52.5258\n",
      "[SGD | lr=0.1] Epoch 1202/4000: train_loss=0.0209  test_loss=3.7104  λ_max=55.9775\n",
      "[SGD | lr=0.1] Epoch 1203/4000: train_loss=0.0209  test_loss=3.7105  λ_max=55.4986\n",
      "[SGD | lr=0.1] Epoch 1204/4000: train_loss=0.0209  test_loss=3.7116  λ_max=54.3567\n",
      "[SGD | lr=0.1] Epoch 1205/4000: train_loss=0.0208  test_loss=3.7119  λ_max=53.5864\n",
      "[SGD | lr=0.1] Epoch 1206/4000: train_loss=0.0208  test_loss=3.7121  λ_max=53.8537\n",
      "[SGD | lr=0.1] Iter 19300: loss=0.0207\n",
      "[SGD | lr=0.1] Epoch 1207/4000: train_loss=0.0208  test_loss=3.7130  λ_max=55.0080\n",
      "[SGD | lr=0.1] Epoch 1208/4000: train_loss=0.0207  test_loss=3.7138  λ_max=56.5312\n",
      "[SGD | lr=0.1] Epoch 1209/4000: train_loss=0.0207  test_loss=3.7150  λ_max=52.2994\n",
      "[SGD | lr=0.1] Epoch 1210/4000: train_loss=0.0207  test_loss=3.7152  λ_max=53.6324\n",
      "[SGD | lr=0.1] Epoch 1211/4000: train_loss=0.0207  test_loss=3.7159  λ_max=52.4864\n",
      "[SGD | lr=0.1] Epoch 1212/4000: train_loss=0.0206  test_loss=3.7167  λ_max=53.7862\n",
      "[SGD | lr=0.1] Iter 19400: loss=0.0202\n",
      "[SGD | lr=0.1] Epoch 1213/4000: train_loss=0.0206  test_loss=3.7173  λ_max=54.4079\n",
      "[SGD | lr=0.1] Epoch 1214/4000: train_loss=0.0206  test_loss=3.7181  λ_max=54.4237\n",
      "[SGD | lr=0.1] Epoch 1215/4000: train_loss=0.0206  test_loss=3.7188  λ_max=55.2196\n",
      "[SGD | lr=0.1] Epoch 1216/4000: train_loss=0.0205  test_loss=3.7192  λ_max=53.7007\n",
      "[SGD | lr=0.1] Epoch 1217/4000: train_loss=0.0205  test_loss=3.7198  λ_max=54.9340\n",
      "[SGD | lr=0.1] Epoch 1218/4000: train_loss=0.0205  test_loss=3.7204  λ_max=54.2447\n",
      "[SGD | lr=0.1] Iter 19500: loss=0.0206\n",
      "[SGD | lr=0.1] Epoch 1219/4000: train_loss=0.0204  test_loss=3.7209  λ_max=55.2893\n",
      "[SGD | lr=0.1] Epoch 1220/4000: train_loss=0.0204  test_loss=3.7217  λ_max=53.9433\n",
      "[SGD | lr=0.1] Epoch 1221/4000: train_loss=0.0204  test_loss=3.7223  λ_max=52.6172\n",
      "[SGD | lr=0.1] Epoch 1222/4000: train_loss=0.0204  test_loss=3.7230  λ_max=54.6872\n",
      "[SGD | lr=0.1] Epoch 1223/4000: train_loss=0.0203  test_loss=3.7237  λ_max=55.0755\n",
      "[SGD | lr=0.1] Epoch 1224/4000: train_loss=0.0203  test_loss=3.7243  λ_max=54.4076\n",
      "[SGD | lr=0.1] Iter 19600: loss=0.0204\n",
      "[SGD | lr=0.1] Epoch 1225/4000: train_loss=0.0203  test_loss=3.7254  λ_max=54.3290\n",
      "[SGD | lr=0.1] Epoch 1226/4000: train_loss=0.0203  test_loss=3.7256  λ_max=54.3617\n",
      "[SGD | lr=0.1] Epoch 1227/4000: train_loss=0.0202  test_loss=3.7265  λ_max=55.4716\n",
      "[SGD | lr=0.1] Epoch 1228/4000: train_loss=0.0202  test_loss=3.7271  λ_max=56.1293\n",
      "[SGD | lr=0.1] Epoch 1229/4000: train_loss=0.0202  test_loss=3.7278  λ_max=55.1578\n",
      "[SGD | lr=0.1] Epoch 1230/4000: train_loss=0.0202  test_loss=3.7285  λ_max=53.6081\n",
      "[SGD | lr=0.1] Epoch 1231/4000: train_loss=0.0202  test_loss=3.7291  λ_max=54.3633\n",
      "[SGD | lr=0.1] Iter 19700: loss=0.0201\n",
      "[SGD | lr=0.1] Epoch 1232/4000: train_loss=0.0201  test_loss=3.7297  λ_max=53.9479\n",
      "[SGD | lr=0.1] Epoch 1233/4000: train_loss=0.0201  test_loss=3.7303  λ_max=55.0072\n",
      "[SGD | lr=0.1] Epoch 1234/4000: train_loss=0.0201  test_loss=3.7308  λ_max=54.7872\n",
      "[SGD | lr=0.1] Epoch 1235/4000: train_loss=0.0200  test_loss=3.7317  λ_max=55.8837\n",
      "[SGD | lr=0.1] Epoch 1236/4000: train_loss=0.0200  test_loss=3.7326  λ_max=55.2341\n",
      "[SGD | lr=0.1] Epoch 1237/4000: train_loss=0.0200  test_loss=3.7327  λ_max=56.3093\n",
      "[SGD | lr=0.1] Iter 19800: loss=0.0205\n",
      "[SGD | lr=0.1] Epoch 1238/4000: train_loss=0.0200  test_loss=3.7332  λ_max=54.7357\n",
      "[SGD | lr=0.1] Epoch 1239/4000: train_loss=0.0200  test_loss=3.7343  λ_max=54.0774\n",
      "[SGD | lr=0.1] Epoch 1240/4000: train_loss=0.0199  test_loss=3.7347  λ_max=53.6332\n",
      "[SGD | lr=0.1] Epoch 1241/4000: train_loss=0.0199  test_loss=3.7356  λ_max=55.9417\n",
      "[SGD | lr=0.1] Epoch 1242/4000: train_loss=0.0199  test_loss=3.7363  λ_max=55.6407\n",
      "[SGD | lr=0.1] Epoch 1243/4000: train_loss=0.0198  test_loss=3.7367  λ_max=54.9464\n",
      "[SGD | lr=0.1] Iter 19900: loss=0.0197\n",
      "[SGD | lr=0.1] Epoch 1244/4000: train_loss=0.0198  test_loss=3.7373  λ_max=55.2473\n",
      "[SGD | lr=0.1] Epoch 1245/4000: train_loss=0.0198  test_loss=3.7382  λ_max=54.6162\n",
      "[SGD | lr=0.1] Epoch 1246/4000: train_loss=0.0198  test_loss=3.7389  λ_max=54.8369\n",
      "[SGD | lr=0.1] Epoch 1247/4000: train_loss=0.0197  test_loss=3.7393  λ_max=55.2622\n",
      "[SGD | lr=0.1] Epoch 1248/4000: train_loss=0.0197  test_loss=3.7403  λ_max=54.9331\n",
      "[SGD | lr=0.1] Epoch 1249/4000: train_loss=0.0197  test_loss=3.7409  λ_max=54.5294\n",
      "[SGD | lr=0.1] Iter 20000: loss=0.0201\n",
      "[SGD | lr=0.1] Epoch 1250/4000: train_loss=0.0197  test_loss=3.7415  λ_max=54.7878\n",
      "[SGD | lr=0.1] Epoch 1251/4000: train_loss=0.0197  test_loss=3.7424  λ_max=54.8806\n",
      "[SGD | lr=0.1] Epoch 1252/4000: train_loss=0.0196  test_loss=3.7429  λ_max=54.2978\n",
      "[SGD | lr=0.1] Epoch 1253/4000: train_loss=0.0196  test_loss=3.7430  λ_max=54.7701\n",
      "[SGD | lr=0.1] Epoch 1254/4000: train_loss=0.0196  test_loss=3.7439  λ_max=54.3401\n",
      "[SGD | lr=0.1] Epoch 1255/4000: train_loss=0.0196  test_loss=3.7446  λ_max=55.0276\n",
      "[SGD | lr=0.1] Epoch 1256/4000: train_loss=0.0195  test_loss=3.7450  λ_max=55.8988\n",
      "[SGD | lr=0.1] Iter 20100: loss=0.0198\n",
      "[SGD | lr=0.1] Epoch 1257/4000: train_loss=0.0195  test_loss=3.7457  λ_max=54.3495\n",
      "[SGD | lr=0.1] Epoch 1258/4000: train_loss=0.0195  test_loss=3.7463  λ_max=57.0296\n",
      "[SGD | lr=0.1] Epoch 1259/4000: train_loss=0.0195  test_loss=3.7467  λ_max=55.3911\n",
      "[SGD | lr=0.1] Epoch 1260/4000: train_loss=0.0194  test_loss=3.7473  λ_max=56.0021\n",
      "[SGD | lr=0.1] Epoch 1261/4000: train_loss=0.0194  test_loss=3.7485  λ_max=56.4571\n",
      "[SGD | lr=0.1] Epoch 1262/4000: train_loss=0.0194  test_loss=3.7486  λ_max=54.1808\n",
      "[SGD | lr=0.1] Iter 20200: loss=0.0198\n",
      "[SGD | lr=0.1] Epoch 1263/4000: train_loss=0.0194  test_loss=3.7493  λ_max=55.6374\n",
      "[SGD | lr=0.1] Epoch 1264/4000: train_loss=0.0193  test_loss=3.7501  λ_max=55.3259\n",
      "[SGD | lr=0.1] Epoch 1265/4000: train_loss=0.0193  test_loss=3.7504  λ_max=56.2190\n",
      "[SGD | lr=0.1] Epoch 1266/4000: train_loss=0.0193  test_loss=3.7514  λ_max=54.6466\n",
      "[SGD | lr=0.1] Epoch 1267/4000: train_loss=0.0193  test_loss=3.7519  λ_max=56.7409\n",
      "[SGD | lr=0.1] Epoch 1268/4000: train_loss=0.0192  test_loss=3.7528  λ_max=57.2825\n",
      "[SGD | lr=0.1] Iter 20300: loss=0.0195\n",
      "[SGD | lr=0.1] Epoch 1269/4000: train_loss=0.0192  test_loss=3.7529  λ_max=53.3158\n",
      "[SGD | lr=0.1] Epoch 1270/4000: train_loss=0.0192  test_loss=3.7543  λ_max=54.3193\n",
      "[SGD | lr=0.1] Epoch 1271/4000: train_loss=0.0192  test_loss=3.7544  λ_max=55.1355\n",
      "[SGD | lr=0.1] Epoch 1272/4000: train_loss=0.0191  test_loss=3.7550  λ_max=56.4272\n",
      "[SGD | lr=0.1] Epoch 1273/4000: train_loss=0.0191  test_loss=3.7559  λ_max=53.6667\n",
      "[SGD | lr=0.1] Epoch 1274/4000: train_loss=0.0191  test_loss=3.7560  λ_max=56.2969\n",
      "[SGD | lr=0.1] Iter 20400: loss=0.0189\n",
      "[SGD | lr=0.1] Epoch 1275/4000: train_loss=0.0191  test_loss=3.7572  λ_max=56.4072\n",
      "[SGD | lr=0.1] Epoch 1276/4000: train_loss=0.0191  test_loss=3.7578  λ_max=56.0918\n",
      "[SGD | lr=0.1] Epoch 1277/4000: train_loss=0.0190  test_loss=3.7582  λ_max=57.7556\n",
      "[SGD | lr=0.1] Epoch 1278/4000: train_loss=0.0190  test_loss=3.7589  λ_max=56.3411\n",
      "[SGD | lr=0.1] Epoch 1279/4000: train_loss=0.0190  test_loss=3.7595  λ_max=56.1459\n",
      "[SGD | lr=0.1] Epoch 1280/4000: train_loss=0.0190  test_loss=3.7601  λ_max=56.0495\n",
      "[SGD | lr=0.1] Epoch 1281/4000: train_loss=0.0189  test_loss=3.7605  λ_max=53.0477\n",
      "[SGD | lr=0.1] Iter 20500: loss=0.0189\n",
      "[SGD | lr=0.1] Epoch 1282/4000: train_loss=0.0189  test_loss=3.7615  λ_max=55.3648\n",
      "[SGD | lr=0.1] Epoch 1283/4000: train_loss=0.0189  test_loss=3.7619  λ_max=55.6180\n",
      "[SGD | lr=0.1] Epoch 1284/4000: train_loss=0.0189  test_loss=3.7626  λ_max=55.0608\n",
      "[SGD | lr=0.1] Epoch 1285/4000: train_loss=0.0189  test_loss=3.7631  λ_max=54.4415\n",
      "[SGD | lr=0.1] Epoch 1286/4000: train_loss=0.0188  test_loss=3.7638  λ_max=54.9815\n",
      "[SGD | lr=0.1] Epoch 1287/4000: train_loss=0.0188  test_loss=3.7645  λ_max=55.5313\n",
      "[SGD | lr=0.1] Iter 20600: loss=0.0191\n",
      "[SGD | lr=0.1] Epoch 1288/4000: train_loss=0.0188  test_loss=3.7649  λ_max=55.2690\n",
      "[SGD | lr=0.1] Epoch 1289/4000: train_loss=0.0188  test_loss=3.7659  λ_max=55.2062\n",
      "[SGD | lr=0.1] Epoch 1290/4000: train_loss=0.0187  test_loss=3.7663  λ_max=57.2303\n",
      "[SGD | lr=0.1] Epoch 1291/4000: train_loss=0.0187  test_loss=3.7670  λ_max=54.6695\n",
      "[SGD | lr=0.1] Epoch 1292/4000: train_loss=0.0187  test_loss=3.7674  λ_max=53.9159\n",
      "[SGD | lr=0.1] Epoch 1293/4000: train_loss=0.0187  test_loss=3.7681  λ_max=56.4748\n",
      "[SGD | lr=0.1] Iter 20700: loss=0.0185\n",
      "[SGD | lr=0.1] Epoch 1294/4000: train_loss=0.0187  test_loss=3.7691  λ_max=54.6673\n",
      "[SGD | lr=0.1] Epoch 1295/4000: train_loss=0.0186  test_loss=3.7696  λ_max=57.3946\n",
      "[SGD | lr=0.1] Epoch 1296/4000: train_loss=0.0186  test_loss=3.7698  λ_max=54.8148\n",
      "[SGD | lr=0.1] Epoch 1297/4000: train_loss=0.0186  test_loss=3.7706  λ_max=56.2585\n",
      "[SGD | lr=0.1] Epoch 1298/4000: train_loss=0.0186  test_loss=3.7715  λ_max=56.2835\n",
      "[SGD | lr=0.1] Epoch 1299/4000: train_loss=0.0185  test_loss=3.7715  λ_max=55.7467\n",
      "[SGD | lr=0.1] Iter 20800: loss=0.0193\n",
      "[SGD | lr=0.1] Epoch 1300/4000: train_loss=0.0185  test_loss=3.7724  λ_max=54.6454\n",
      "[SGD | lr=0.1] Epoch 1301/4000: train_loss=0.0185  test_loss=3.7733  λ_max=57.5741\n",
      "[SGD | lr=0.1] Epoch 1302/4000: train_loss=0.0185  test_loss=3.7736  λ_max=55.8208\n",
      "[SGD | lr=0.1] Epoch 1303/4000: train_loss=0.0185  test_loss=3.7741  λ_max=58.1700\n",
      "[SGD | lr=0.1] Epoch 1304/4000: train_loss=0.0184  test_loss=3.7747  λ_max=54.9430\n",
      "[SGD | lr=0.1] Epoch 1305/4000: train_loss=0.0184  test_loss=3.7754  λ_max=57.2764\n",
      "[SGD | lr=0.1] Epoch 1306/4000: train_loss=0.0184  test_loss=3.7762  λ_max=54.2369\n",
      "[SGD | lr=0.1] Iter 20900: loss=0.0183\n",
      "[SGD | lr=0.1] Epoch 1307/4000: train_loss=0.0184  test_loss=3.7764  λ_max=55.2724\n",
      "[SGD | lr=0.1] Epoch 1308/4000: train_loss=0.0184  test_loss=3.7777  λ_max=57.8829\n",
      "[SGD | lr=0.1] Epoch 1309/4000: train_loss=0.0183  test_loss=3.7779  λ_max=56.0343\n",
      "[SGD | lr=0.1] Epoch 1310/4000: train_loss=0.0183  test_loss=3.7783  λ_max=55.8717\n",
      "[SGD | lr=0.1] Epoch 1311/4000: train_loss=0.0183  test_loss=3.7791  λ_max=57.1969\n",
      "[SGD | lr=0.1] Epoch 1312/4000: train_loss=0.0183  test_loss=3.7801  λ_max=56.0254\n",
      "[SGD | lr=0.1] Iter 21000: loss=0.0180\n",
      "[SGD | lr=0.1] Epoch 1313/4000: train_loss=0.0182  test_loss=3.7807  λ_max=55.6177\n",
      "[SGD | lr=0.1] Epoch 1314/4000: train_loss=0.0182  test_loss=3.7810  λ_max=54.6680\n",
      "[SGD | lr=0.1] Epoch 1315/4000: train_loss=0.0182  test_loss=3.7815  λ_max=56.4749\n",
      "[SGD | lr=0.1] Epoch 1316/4000: train_loss=0.0182  test_loss=3.7818  λ_max=55.7033\n",
      "[SGD | lr=0.1] Epoch 1317/4000: train_loss=0.0181  test_loss=3.7826  λ_max=55.5804\n",
      "[SGD | lr=0.1] Epoch 1318/4000: train_loss=0.0181  test_loss=3.7831  λ_max=56.3666\n",
      "[SGD | lr=0.1] Iter 21100: loss=0.0182\n",
      "[SGD | lr=0.1] Epoch 1319/4000: train_loss=0.0181  test_loss=3.7837  λ_max=56.7664\n",
      "[SGD | lr=0.1] Epoch 1320/4000: train_loss=0.0181  test_loss=3.7845  λ_max=56.8959\n",
      "[SGD | lr=0.1] Epoch 1321/4000: train_loss=0.0181  test_loss=3.7853  λ_max=54.5622\n",
      "[SGD | lr=0.1] Epoch 1322/4000: train_loss=0.0181  test_loss=3.7854  λ_max=57.4602\n",
      "[SGD | lr=0.1] Epoch 1323/4000: train_loss=0.0180  test_loss=3.7862  λ_max=55.9309\n",
      "[SGD | lr=0.1] Epoch 1324/4000: train_loss=0.0180  test_loss=3.7870  λ_max=54.9784\n",
      "[SGD | lr=0.1] Iter 21200: loss=0.0178\n",
      "[SGD | lr=0.1] Epoch 1325/4000: train_loss=0.0180  test_loss=3.7874  λ_max=54.2904\n",
      "[SGD | lr=0.1] Epoch 1326/4000: train_loss=0.0180  test_loss=3.7881  λ_max=57.9391\n",
      "[SGD | lr=0.1] Epoch 1327/4000: train_loss=0.0180  test_loss=3.7881  λ_max=54.8908\n",
      "[SGD | lr=0.1] Epoch 1328/4000: train_loss=0.0179  test_loss=3.7896  λ_max=56.9647\n",
      "[SGD | lr=0.1] Epoch 1329/4000: train_loss=0.0179  test_loss=3.7900  λ_max=55.1919\n",
      "[SGD | lr=0.1] Epoch 1330/4000: train_loss=0.0179  test_loss=3.7903  λ_max=57.3827\n",
      "[SGD | lr=0.1] Epoch 1331/4000: train_loss=0.0179  test_loss=3.7911  λ_max=55.5772\n",
      "[SGD | lr=0.1] Iter 21300: loss=0.0182\n",
      "[SGD | lr=0.1] Epoch 1332/4000: train_loss=0.0178  test_loss=3.7916  λ_max=58.6742\n",
      "[SGD | lr=0.1] Epoch 1333/4000: train_loss=0.0178  test_loss=3.7921  λ_max=57.1017\n",
      "[SGD | lr=0.1] Epoch 1334/4000: train_loss=0.0178  test_loss=3.7927  λ_max=55.0009\n",
      "[SGD | lr=0.1] Epoch 1335/4000: train_loss=0.0178  test_loss=3.7932  λ_max=56.7959\n",
      "[SGD | lr=0.1] Epoch 1336/4000: train_loss=0.0178  test_loss=3.7940  λ_max=55.8283\n",
      "[SGD | lr=0.1] Epoch 1337/4000: train_loss=0.0177  test_loss=3.7943  λ_max=57.6530\n",
      "[SGD | lr=0.1] Iter 21400: loss=0.0177\n",
      "[SGD | lr=0.1] Epoch 1338/4000: train_loss=0.0177  test_loss=3.7951  λ_max=55.3904\n",
      "[SGD | lr=0.1] Epoch 1339/4000: train_loss=0.0177  test_loss=3.7955  λ_max=56.0146\n",
      "[SGD | lr=0.1] Epoch 1340/4000: train_loss=0.0177  test_loss=3.7963  λ_max=55.9551\n",
      "[SGD | lr=0.1] Epoch 1341/4000: train_loss=0.0177  test_loss=3.7969  λ_max=54.5897\n",
      "[SGD | lr=0.1] Epoch 1342/4000: train_loss=0.0176  test_loss=3.7975  λ_max=56.2148\n",
      "[SGD | lr=0.1] Epoch 1343/4000: train_loss=0.0176  test_loss=3.7982  λ_max=57.8905\n",
      "[SGD | lr=0.1] Iter 21500: loss=0.0180\n",
      "[SGD | lr=0.1] Epoch 1344/4000: train_loss=0.0176  test_loss=3.7985  λ_max=57.6079\n",
      "[SGD | lr=0.1] Epoch 1345/4000: train_loss=0.0176  test_loss=3.7994  λ_max=56.3464\n",
      "[SGD | lr=0.1] Epoch 1346/4000: train_loss=0.0176  test_loss=3.7996  λ_max=57.2916\n",
      "[SGD | lr=0.1] Epoch 1347/4000: train_loss=0.0175  test_loss=3.8004  λ_max=57.5933\n",
      "[SGD | lr=0.1] Epoch 1348/4000: train_loss=0.0175  test_loss=3.8011  λ_max=56.5489\n",
      "[SGD | lr=0.1] Epoch 1349/4000: train_loss=0.0175  test_loss=3.8016  λ_max=55.9814\n",
      "[SGD | lr=0.1] Iter 21600: loss=0.0177\n",
      "[SGD | lr=0.1] Epoch 1350/4000: train_loss=0.0175  test_loss=3.8022  λ_max=54.3091\n",
      "[SGD | lr=0.1] Epoch 1351/4000: train_loss=0.0175  test_loss=3.8029  λ_max=54.9954\n",
      "[SGD | lr=0.1] Epoch 1352/4000: train_loss=0.0174  test_loss=3.8032  λ_max=57.2186\n",
      "[SGD | lr=0.1] Epoch 1353/4000: train_loss=0.0174  test_loss=3.8037  λ_max=56.7244\n",
      "[SGD | lr=0.1] Epoch 1354/4000: train_loss=0.0174  test_loss=3.8046  λ_max=58.3861\n",
      "[SGD | lr=0.1] Epoch 1355/4000: train_loss=0.0174  test_loss=3.8050  λ_max=56.6564\n",
      "[SGD | lr=0.1] Epoch 1356/4000: train_loss=0.0174  test_loss=3.8056  λ_max=56.4517\n",
      "[SGD | lr=0.1] Iter 21700: loss=0.0175\n",
      "[SGD | lr=0.1] Epoch 1357/4000: train_loss=0.0174  test_loss=3.8063  λ_max=55.8563\n",
      "[SGD | lr=0.1] Epoch 1358/4000: train_loss=0.0173  test_loss=3.8068  λ_max=58.0294\n",
      "[SGD | lr=0.1] Epoch 1359/4000: train_loss=0.0173  test_loss=3.8074  λ_max=55.4039\n",
      "[SGD | lr=0.1] Epoch 1360/4000: train_loss=0.0173  test_loss=3.8076  λ_max=55.3385\n",
      "[SGD | lr=0.1] Epoch 1361/4000: train_loss=0.0173  test_loss=3.8083  λ_max=56.9533\n",
      "[SGD | lr=0.1] Epoch 1362/4000: train_loss=0.0173  test_loss=3.8090  λ_max=55.4336\n",
      "[SGD | lr=0.1] Iter 21800: loss=0.0170\n",
      "[SGD | lr=0.1] Epoch 1363/4000: train_loss=0.0172  test_loss=3.8096  λ_max=57.3983\n",
      "[SGD | lr=0.1] Epoch 1364/4000: train_loss=0.0172  test_loss=3.8102  λ_max=56.9355\n",
      "[SGD | lr=0.1] Epoch 1365/4000: train_loss=0.0172  test_loss=3.8106  λ_max=56.0019\n",
      "[SGD | lr=0.1] Epoch 1366/4000: train_loss=0.0172  test_loss=3.8115  λ_max=57.6208\n",
      "[SGD | lr=0.1] Epoch 1367/4000: train_loss=0.0172  test_loss=3.8119  λ_max=55.6392\n",
      "[SGD | lr=0.1] Epoch 1368/4000: train_loss=0.0171  test_loss=3.8122  λ_max=59.1971\n",
      "[SGD | lr=0.1] Iter 21900: loss=0.0169\n",
      "[SGD | lr=0.1] Epoch 1369/4000: train_loss=0.0171  test_loss=3.8130  λ_max=57.5891\n",
      "[SGD | lr=0.1] Epoch 1370/4000: train_loss=0.0171  test_loss=3.8137  λ_max=57.5270\n",
      "[SGD | lr=0.1] Epoch 1371/4000: train_loss=0.0171  test_loss=3.8143  λ_max=55.2525\n",
      "[SGD | lr=0.1] Epoch 1372/4000: train_loss=0.0171  test_loss=3.8149  λ_max=58.0403\n",
      "[SGD | lr=0.1] Epoch 1373/4000: train_loss=0.0170  test_loss=3.8152  λ_max=58.5146\n",
      "[SGD | lr=0.1] Epoch 1374/4000: train_loss=0.0170  test_loss=3.8159  λ_max=55.9675\n",
      "[SGD | lr=0.1] Iter 22000: loss=0.0170\n",
      "[SGD | lr=0.1] Epoch 1375/4000: train_loss=0.0170  test_loss=3.8165  λ_max=58.1383\n",
      "[SGD | lr=0.1] Epoch 1376/4000: train_loss=0.0170  test_loss=3.8170  λ_max=56.3898\n",
      "[SGD | lr=0.1] Epoch 1377/4000: train_loss=0.0170  test_loss=3.8179  λ_max=56.8078\n",
      "[SGD | lr=0.1] Epoch 1378/4000: train_loss=0.0169  test_loss=3.8181  λ_max=57.7826\n",
      "[SGD | lr=0.1] Epoch 1379/4000: train_loss=0.0169  test_loss=3.8188  λ_max=55.3311\n",
      "[SGD | lr=0.1] Epoch 1380/4000: train_loss=0.0169  test_loss=3.8190  λ_max=55.0643\n",
      "[SGD | lr=0.1] Epoch 1381/4000: train_loss=0.0169  test_loss=3.8201  λ_max=57.5205\n",
      "[SGD | lr=0.1] Iter 22100: loss=0.0171\n",
      "[SGD | lr=0.1] Epoch 1382/4000: train_loss=0.0169  test_loss=3.8205  λ_max=54.9401\n",
      "[SGD | lr=0.1] Epoch 1383/4000: train_loss=0.0169  test_loss=3.8209  λ_max=58.3496\n",
      "[SGD | lr=0.1] Epoch 1384/4000: train_loss=0.0169  test_loss=3.8214  λ_max=57.4878\n",
      "[SGD | lr=0.1] Epoch 1385/4000: train_loss=0.0168  test_loss=3.8220  λ_max=57.9140\n",
      "[SGD | lr=0.1] Epoch 1386/4000: train_loss=0.0168  test_loss=3.8227  λ_max=57.6148\n",
      "[SGD | lr=0.1] Epoch 1387/4000: train_loss=0.0168  test_loss=3.8234  λ_max=58.0487\n",
      "[SGD | lr=0.1] Iter 22200: loss=0.0167\n",
      "[SGD | lr=0.1] Epoch 1388/4000: train_loss=0.0168  test_loss=3.8239  λ_max=56.6279\n",
      "[SGD | lr=0.1] Epoch 1389/4000: train_loss=0.0168  test_loss=3.8242  λ_max=57.2383\n",
      "[SGD | lr=0.1] Epoch 1390/4000: train_loss=0.0167  test_loss=3.8250  λ_max=56.3722\n",
      "[SGD | lr=0.1] Epoch 1391/4000: train_loss=0.0167  test_loss=3.8253  λ_max=56.2313\n",
      "[SGD | lr=0.1] Epoch 1392/4000: train_loss=0.0167  test_loss=3.8258  λ_max=58.4139\n",
      "[SGD | lr=0.1] Epoch 1393/4000: train_loss=0.0167  test_loss=3.8267  λ_max=57.4815\n",
      "[SGD | lr=0.1] Iter 22300: loss=0.0169\n",
      "[SGD | lr=0.1] Epoch 1394/4000: train_loss=0.0167  test_loss=3.8272  λ_max=56.3513\n",
      "[SGD | lr=0.1] Epoch 1395/4000: train_loss=0.0166  test_loss=3.8278  λ_max=57.7697\n",
      "[SGD | lr=0.1] Epoch 1396/4000: train_loss=0.0166  test_loss=3.8282  λ_max=56.5569\n",
      "[SGD | lr=0.1] Epoch 1397/4000: train_loss=0.0166  test_loss=3.8288  λ_max=55.6916\n",
      "[SGD | lr=0.1] Epoch 1398/4000: train_loss=0.0166  test_loss=3.8295  λ_max=57.5097\n",
      "[SGD | lr=0.1] Epoch 1399/4000: train_loss=0.0166  test_loss=3.8303  λ_max=58.3960\n",
      "[SGD | lr=0.1] Iter 22400: loss=0.0159\n",
      "[SGD | lr=0.1] Epoch 1400/4000: train_loss=0.0165  test_loss=3.8304  λ_max=58.0314\n",
      "[SGD | lr=0.1] Epoch 1401/4000: train_loss=0.0165  test_loss=3.8310  λ_max=57.7628\n",
      "[SGD | lr=0.1] Epoch 1402/4000: train_loss=0.0165  test_loss=3.8314  λ_max=58.8084\n",
      "[SGD | lr=0.1] Epoch 1403/4000: train_loss=0.0165  test_loss=3.8322  λ_max=57.2206\n",
      "[SGD | lr=0.1] Epoch 1404/4000: train_loss=0.0165  test_loss=3.8328  λ_max=59.0522\n",
      "[SGD | lr=0.1] Epoch 1405/4000: train_loss=0.0165  test_loss=3.8329  λ_max=55.9568\n",
      "[SGD | lr=0.1] Epoch 1406/4000: train_loss=0.0164  test_loss=3.8336  λ_max=55.8439\n",
      "[SGD | lr=0.1] Iter 22500: loss=0.0162\n",
      "[SGD | lr=0.1] Epoch 1407/4000: train_loss=0.0164  test_loss=3.8345  λ_max=57.0760\n",
      "[SGD | lr=0.1] Epoch 1408/4000: train_loss=0.0164  test_loss=3.8350  λ_max=56.9164\n",
      "[SGD | lr=0.1] Epoch 1409/4000: train_loss=0.0164  test_loss=3.8355  λ_max=56.9207\n",
      "[SGD | lr=0.1] Epoch 1410/4000: train_loss=0.0164  test_loss=3.8357  λ_max=54.7722\n",
      "[SGD | lr=0.1] Epoch 1411/4000: train_loss=0.0164  test_loss=3.8363  λ_max=58.2273\n",
      "[SGD | lr=0.1] Epoch 1412/4000: train_loss=0.0163  test_loss=3.8371  λ_max=56.7901\n",
      "[SGD | lr=0.1] Iter 22600: loss=0.0162\n",
      "[SGD | lr=0.1] Epoch 1413/4000: train_loss=0.0163  test_loss=3.8377  λ_max=57.6889\n",
      "[SGD | lr=0.1] Epoch 1414/4000: train_loss=0.0163  test_loss=3.8383  λ_max=58.3267\n",
      "[SGD | lr=0.1] Epoch 1415/4000: train_loss=0.0163  test_loss=3.8389  λ_max=57.5055\n",
      "[SGD | lr=0.1] Epoch 1416/4000: train_loss=0.0163  test_loss=3.8396  λ_max=55.9127\n",
      "[SGD | lr=0.1] Epoch 1417/4000: train_loss=0.0163  test_loss=3.8399  λ_max=57.4515\n",
      "[SGD | lr=0.1] Epoch 1418/4000: train_loss=0.0162  test_loss=3.8405  λ_max=57.6615\n",
      "[SGD | lr=0.1] Iter 22700: loss=0.0163\n",
      "[SGD | lr=0.1] Epoch 1419/4000: train_loss=0.0162  test_loss=3.8408  λ_max=57.1815\n",
      "[SGD | lr=0.1] Epoch 1420/4000: train_loss=0.0162  test_loss=3.8417  λ_max=58.9036\n",
      "[SGD | lr=0.1] Epoch 1421/4000: train_loss=0.0162  test_loss=3.8421  λ_max=58.4071\n",
      "[SGD | lr=0.1] Epoch 1422/4000: train_loss=0.0162  test_loss=3.8429  λ_max=59.6543\n",
      "[SGD | lr=0.1] Epoch 1423/4000: train_loss=0.0162  test_loss=3.8433  λ_max=57.3275\n",
      "[SGD | lr=0.1] Epoch 1424/4000: train_loss=0.0161  test_loss=3.8441  λ_max=57.6012\n",
      "[SGD | lr=0.1] Iter 22800: loss=0.0159\n",
      "[SGD | lr=0.1] Epoch 1425/4000: train_loss=0.0161  test_loss=3.8442  λ_max=57.0599\n",
      "[SGD | lr=0.1] Epoch 1426/4000: train_loss=0.0161  test_loss=3.8448  λ_max=58.9891\n",
      "[SGD | lr=0.1] Epoch 1427/4000: train_loss=0.0161  test_loss=3.8454  λ_max=57.3684\n",
      "[SGD | lr=0.1] Epoch 1428/4000: train_loss=0.0161  test_loss=3.8462  λ_max=58.0321\n",
      "[SGD | lr=0.1] Epoch 1429/4000: train_loss=0.0160  test_loss=3.8467  λ_max=57.0803\n",
      "[SGD | lr=0.1] Epoch 1430/4000: train_loss=0.0160  test_loss=3.8468  λ_max=58.2461\n",
      "[SGD | lr=0.1] Epoch 1431/4000: train_loss=0.0160  test_loss=3.8475  λ_max=57.3130\n",
      "[SGD | lr=0.1] Iter 22900: loss=0.0162\n",
      "[SGD | lr=0.1] Epoch 1432/4000: train_loss=0.0160  test_loss=3.8480  λ_max=57.1736\n",
      "[SGD | lr=0.1] Epoch 1433/4000: train_loss=0.0160  test_loss=3.8486  λ_max=59.4200\n",
      "[SGD | lr=0.1] Epoch 1434/4000: train_loss=0.0160  test_loss=3.8494  λ_max=58.9854\n",
      "[SGD | lr=0.1] Epoch 1435/4000: train_loss=0.0159  test_loss=3.8498  λ_max=58.2776\n",
      "[SGD | lr=0.1] Epoch 1436/4000: train_loss=0.0159  test_loss=3.8506  λ_max=57.2865\n",
      "[SGD | lr=0.1] Epoch 1437/4000: train_loss=0.0159  test_loss=3.8507  λ_max=58.2066\n",
      "[SGD | lr=0.1] Iter 23000: loss=0.0158\n",
      "[SGD | lr=0.1] Epoch 1438/4000: train_loss=0.0159  test_loss=3.8511  λ_max=59.8622\n",
      "[SGD | lr=0.1] Epoch 1439/4000: train_loss=0.0159  test_loss=3.8520  λ_max=56.6804\n",
      "[SGD | lr=0.1] Epoch 1440/4000: train_loss=0.0159  test_loss=3.8526  λ_max=58.8139\n",
      "[SGD | lr=0.1] Epoch 1441/4000: train_loss=0.0159  test_loss=3.8530  λ_max=59.1226\n",
      "[SGD | lr=0.1] Epoch 1442/4000: train_loss=0.0158  test_loss=3.8536  λ_max=57.1050\n",
      "[SGD | lr=0.1] Epoch 1443/4000: train_loss=0.0158  test_loss=3.8539  λ_max=58.1790\n",
      "[SGD | lr=0.1] Iter 23100: loss=0.0160\n",
      "[SGD | lr=0.1] Epoch 1444/4000: train_loss=0.0158  test_loss=3.8544  λ_max=57.4664\n",
      "[SGD | lr=0.1] Epoch 1445/4000: train_loss=0.0158  test_loss=3.8553  λ_max=57.6638\n",
      "[SGD | lr=0.1] Epoch 1446/4000: train_loss=0.0158  test_loss=3.8557  λ_max=58.8361\n",
      "[SGD | lr=0.1] Epoch 1447/4000: train_loss=0.0157  test_loss=3.8562  λ_max=57.5280\n",
      "[SGD | lr=0.1] Epoch 1448/4000: train_loss=0.0157  test_loss=3.8566  λ_max=56.8553\n",
      "[SGD | lr=0.1] Epoch 1449/4000: train_loss=0.0157  test_loss=3.8576  λ_max=57.5113\n",
      "[SGD | lr=0.1] Iter 23200: loss=0.0158\n",
      "[SGD | lr=0.1] Epoch 1450/4000: train_loss=0.0157  test_loss=3.8579  λ_max=56.8873\n",
      "[SGD | lr=0.1] Epoch 1451/4000: train_loss=0.0157  test_loss=3.8583  λ_max=58.1537\n",
      "[SGD | lr=0.1] Epoch 1452/4000: train_loss=0.0157  test_loss=3.8592  λ_max=58.0020\n",
      "[SGD | lr=0.1] Epoch 1453/4000: train_loss=0.0156  test_loss=3.8595  λ_max=59.1894\n",
      "[SGD | lr=0.1] Epoch 1454/4000: train_loss=0.0156  test_loss=3.8602  λ_max=57.8912\n",
      "[SGD | lr=0.1] Epoch 1455/4000: train_loss=0.0156  test_loss=3.8603  λ_max=57.3109\n",
      "[SGD | lr=0.1] Epoch 1456/4000: train_loss=0.0156  test_loss=3.8613  λ_max=59.5990\n",
      "[SGD | lr=0.1] Iter 23300: loss=0.0157\n",
      "[SGD | lr=0.1] Epoch 1457/4000: train_loss=0.0156  test_loss=3.8616  λ_max=56.7367\n",
      "[SGD | lr=0.1] Epoch 1458/4000: train_loss=0.0156  test_loss=3.8620  λ_max=57.7128\n",
      "[SGD | lr=0.1] Epoch 1459/4000: train_loss=0.0156  test_loss=3.8626  λ_max=58.7561\n",
      "[SGD | lr=0.1] Epoch 1460/4000: train_loss=0.0155  test_loss=3.8631  λ_max=59.9382\n",
      "[SGD | lr=0.1] Epoch 1461/4000: train_loss=0.0155  test_loss=3.8638  λ_max=60.1272\n",
      "[SGD | lr=0.1] Epoch 1462/4000: train_loss=0.0155  test_loss=3.8646  λ_max=56.1208\n",
      "[SGD | lr=0.1] Iter 23400: loss=0.0156\n",
      "[SGD | lr=0.1] Epoch 1463/4000: train_loss=0.0155  test_loss=3.8650  λ_max=56.2820\n",
      "[SGD | lr=0.1] Epoch 1464/4000: train_loss=0.0155  test_loss=3.8654  λ_max=57.8268\n",
      "[SGD | lr=0.1] Epoch 1465/4000: train_loss=0.0155  test_loss=3.8659  λ_max=58.5484\n",
      "[SGD | lr=0.1] Epoch 1466/4000: train_loss=0.0155  test_loss=3.8663  λ_max=56.4973\n",
      "[SGD | lr=0.1] Epoch 1467/4000: train_loss=0.0154  test_loss=3.8670  λ_max=57.7419\n",
      "[SGD | lr=0.1] Epoch 1468/4000: train_loss=0.0154  test_loss=3.8674  λ_max=57.8325\n",
      "[SGD | lr=0.1] Iter 23500: loss=0.0158\n",
      "[SGD | lr=0.1] Epoch 1469/4000: train_loss=0.0154  test_loss=3.8682  λ_max=58.2329\n",
      "[SGD | lr=0.1] Epoch 1470/4000: train_loss=0.0154  test_loss=3.8689  λ_max=58.4744\n",
      "[SGD | lr=0.1] Epoch 1471/4000: train_loss=0.0154  test_loss=3.8691  λ_max=57.2248\n",
      "[SGD | lr=0.1] Epoch 1472/4000: train_loss=0.0154  test_loss=3.8699  λ_max=57.7068\n",
      "[SGD | lr=0.1] Epoch 1473/4000: train_loss=0.0153  test_loss=3.8705  λ_max=59.3988\n",
      "[SGD | lr=0.1] Epoch 1474/4000: train_loss=0.0153  test_loss=3.8708  λ_max=58.8177\n",
      "[SGD | lr=0.1] Iter 23600: loss=0.0156\n",
      "[SGD | lr=0.1] Epoch 1475/4000: train_loss=0.0153  test_loss=3.8714  λ_max=57.9757\n",
      "[SGD | lr=0.1] Epoch 1476/4000: train_loss=0.0153  test_loss=3.8716  λ_max=58.2295\n",
      "[SGD | lr=0.1] Epoch 1477/4000: train_loss=0.0153  test_loss=3.8722  λ_max=59.0463\n",
      "[SGD | lr=0.1] Epoch 1478/4000: train_loss=0.0153  test_loss=3.8729  λ_max=60.3831\n",
      "[SGD | lr=0.1] Epoch 1479/4000: train_loss=0.0152  test_loss=3.8736  λ_max=59.3281\n",
      "[SGD | lr=0.1] Epoch 1480/4000: train_loss=0.0152  test_loss=3.8738  λ_max=57.6961\n",
      "[SGD | lr=0.1] Epoch 1481/4000: train_loss=0.0152  test_loss=3.8743  λ_max=58.2552\n",
      "[SGD | lr=0.1] Iter 23700: loss=0.0152\n",
      "[SGD | lr=0.1] Epoch 1482/4000: train_loss=0.0152  test_loss=3.8746  λ_max=55.8893\n",
      "[SGD | lr=0.1] Epoch 1483/4000: train_loss=0.0152  test_loss=3.8755  λ_max=56.1639\n",
      "[SGD | lr=0.1] Epoch 1484/4000: train_loss=0.0152  test_loss=3.8761  λ_max=56.9128\n",
      "[SGD | lr=0.1] Epoch 1485/4000: train_loss=0.0152  test_loss=3.8768  λ_max=58.6534\n",
      "[SGD | lr=0.1] Epoch 1486/4000: train_loss=0.0151  test_loss=3.8768  λ_max=58.3279\n",
      "[SGD | lr=0.1] Epoch 1487/4000: train_loss=0.0151  test_loss=3.8773  λ_max=57.5667\n",
      "[SGD | lr=0.1] Iter 23800: loss=0.0150\n",
      "[SGD | lr=0.1] Epoch 1488/4000: train_loss=0.0151  test_loss=3.8779  λ_max=57.2609\n",
      "[SGD | lr=0.1] Epoch 1489/4000: train_loss=0.0151  test_loss=3.8785  λ_max=57.2841\n",
      "[SGD | lr=0.1] Epoch 1490/4000: train_loss=0.0151  test_loss=3.8794  λ_max=57.4344\n",
      "[SGD | lr=0.1] Epoch 1491/4000: train_loss=0.0151  test_loss=3.8799  λ_max=57.3013\n",
      "[SGD | lr=0.1] Epoch 1492/4000: train_loss=0.0150  test_loss=3.8800  λ_max=57.4611\n",
      "[SGD | lr=0.1] Epoch 1493/4000: train_loss=0.0150  test_loss=3.8806  λ_max=57.8038\n",
      "[SGD | lr=0.1] Iter 23900: loss=0.0151\n",
      "[SGD | lr=0.1] Epoch 1494/4000: train_loss=0.0150  test_loss=3.8812  λ_max=58.9476\n",
      "[SGD | lr=0.1] Epoch 1495/4000: train_loss=0.0150  test_loss=3.8816  λ_max=58.8010\n",
      "[SGD | lr=0.1] Epoch 1496/4000: train_loss=0.0150  test_loss=3.8822  λ_max=58.7179\n",
      "[SGD | lr=0.1] Epoch 1497/4000: train_loss=0.0150  test_loss=3.8827  λ_max=60.4406\n",
      "[SGD | lr=0.1] Epoch 1498/4000: train_loss=0.0150  test_loss=3.8833  λ_max=59.3523\n",
      "[SGD | lr=0.1] Epoch 1499/4000: train_loss=0.0149  test_loss=3.8838  λ_max=56.5619\n",
      "[SGD | lr=0.1] Iter 24000: loss=0.0153\n",
      "[SGD | lr=0.1] Epoch 1500/4000: train_loss=0.0149  test_loss=3.8844  λ_max=59.6814\n",
      "[SGD | lr=0.1] Epoch 1501/4000: train_loss=0.0149  test_loss=3.8850  λ_max=59.5944\n",
      "[SGD | lr=0.1] Epoch 1502/4000: train_loss=0.0149  test_loss=3.8856  λ_max=55.7859\n",
      "[SGD | lr=0.1] Epoch 1503/4000: train_loss=0.0149  test_loss=3.8860  λ_max=57.8805\n",
      "[SGD | lr=0.1] Epoch 1504/4000: train_loss=0.0149  test_loss=3.8866  λ_max=58.3879\n",
      "[SGD | lr=0.1] Epoch 1505/4000: train_loss=0.0149  test_loss=3.8868  λ_max=58.3346\n",
      "[SGD | lr=0.1] Epoch 1506/4000: train_loss=0.0148  test_loss=3.8876  λ_max=59.3578\n",
      "[SGD | lr=0.1] Iter 24100: loss=0.0147\n",
      "[SGD | lr=0.1] Epoch 1507/4000: train_loss=0.0148  test_loss=3.8881  λ_max=58.1663\n",
      "[SGD | lr=0.1] Epoch 1508/4000: train_loss=0.0148  test_loss=3.8885  λ_max=58.2070\n",
      "[SGD | lr=0.1] Epoch 1509/4000: train_loss=0.0148  test_loss=3.8889  λ_max=58.5025\n",
      "[SGD | lr=0.1] Epoch 1510/4000: train_loss=0.0148  test_loss=3.8893  λ_max=58.9282\n",
      "[SGD | lr=0.1] Epoch 1511/4000: train_loss=0.0148  test_loss=3.8903  λ_max=59.1289\n",
      "[SGD | lr=0.1] Epoch 1512/4000: train_loss=0.0147  test_loss=3.8905  λ_max=58.0238\n",
      "[SGD | lr=0.1] Iter 24200: loss=0.0147\n",
      "[SGD | lr=0.1] Epoch 1513/4000: train_loss=0.0147  test_loss=3.8909  λ_max=59.7263\n",
      "[SGD | lr=0.1] Epoch 1514/4000: train_loss=0.0147  test_loss=3.8915  λ_max=58.1349\n",
      "[SGD | lr=0.1] Epoch 1515/4000: train_loss=0.0147  test_loss=3.8920  λ_max=58.6168\n",
      "[SGD | lr=0.1] Epoch 1516/4000: train_loss=0.0147  test_loss=3.8924  λ_max=58.0509\n",
      "[SGD | lr=0.1] Epoch 1517/4000: train_loss=0.0147  test_loss=3.8929  λ_max=58.0856\n",
      "[SGD | lr=0.1] Epoch 1518/4000: train_loss=0.0147  test_loss=3.8936  λ_max=58.9082\n",
      "[SGD | lr=0.1] Iter 24300: loss=0.0147\n",
      "[SGD | lr=0.1] Epoch 1519/4000: train_loss=0.0147  test_loss=3.8940  λ_max=58.3074\n",
      "[SGD | lr=0.1] Epoch 1520/4000: train_loss=0.0146  test_loss=3.8946  λ_max=57.9240\n",
      "[SGD | lr=0.1] Epoch 1521/4000: train_loss=0.0146  test_loss=3.8950  λ_max=58.4948\n",
      "[SGD | lr=0.1] Epoch 1522/4000: train_loss=0.0146  test_loss=3.8961  λ_max=58.0999\n",
      "[SGD | lr=0.1] Epoch 1523/4000: train_loss=0.0146  test_loss=3.8962  λ_max=58.8027\n",
      "[SGD | lr=0.1] Epoch 1524/4000: train_loss=0.0146  test_loss=3.8965  λ_max=58.2189\n",
      "[SGD | lr=0.1] Iter 24400: loss=0.0143\n",
      "[SGD | lr=0.1] Epoch 1525/4000: train_loss=0.0146  test_loss=3.8972  λ_max=59.0190\n",
      "[SGD | lr=0.1] Epoch 1526/4000: train_loss=0.0145  test_loss=3.8979  λ_max=59.1495\n",
      "[SGD | lr=0.1] Epoch 1527/4000: train_loss=0.0145  test_loss=3.8981  λ_max=59.3581\n",
      "[SGD | lr=0.1] Epoch 1528/4000: train_loss=0.0145  test_loss=3.8990  λ_max=58.9800\n",
      "[SGD | lr=0.1] Epoch 1529/4000: train_loss=0.0145  test_loss=3.8992  λ_max=58.0967\n",
      "[SGD | lr=0.1] Epoch 1530/4000: train_loss=0.0145  test_loss=3.8998  λ_max=59.0879\n",
      "[SGD | lr=0.1] Epoch 1531/4000: train_loss=0.0145  test_loss=3.9003  λ_max=60.0259\n",
      "[SGD | lr=0.1] Iter 24500: loss=0.0143\n",
      "[SGD | lr=0.1] Epoch 1532/4000: train_loss=0.0145  test_loss=3.9005  λ_max=58.4415\n",
      "[SGD | lr=0.1] Epoch 1533/4000: train_loss=0.0145  test_loss=3.9011  λ_max=58.1916\n",
      "[SGD | lr=0.1] Epoch 1534/4000: train_loss=0.0144  test_loss=3.9017  λ_max=58.4891\n",
      "[SGD | lr=0.1] Epoch 1535/4000: train_loss=0.0144  test_loss=3.9022  λ_max=57.5526\n",
      "[SGD | lr=0.1] Epoch 1536/4000: train_loss=0.0144  test_loss=3.9026  λ_max=59.3214\n",
      "[SGD | lr=0.1] Epoch 1537/4000: train_loss=0.0144  test_loss=3.9030  λ_max=58.3538\n",
      "[SGD | lr=0.1] Iter 24600: loss=0.0144\n",
      "[SGD | lr=0.1] Epoch 1538/4000: train_loss=0.0144  test_loss=3.9040  λ_max=58.3693\n",
      "[SGD | lr=0.1] Epoch 1539/4000: train_loss=0.0144  test_loss=3.9040  λ_max=58.0390\n",
      "[SGD | lr=0.1] Epoch 1540/4000: train_loss=0.0144  test_loss=3.9048  λ_max=60.1239\n",
      "[SGD | lr=0.1] Epoch 1541/4000: train_loss=0.0143  test_loss=3.9052  λ_max=57.1049\n",
      "[SGD | lr=0.1] Epoch 1542/4000: train_loss=0.0143  test_loss=3.9058  λ_max=60.1473\n",
      "[SGD | lr=0.1] Epoch 1543/4000: train_loss=0.0143  test_loss=3.9063  λ_max=57.8356\n",
      "[SGD | lr=0.1] Iter 24700: loss=0.0143\n",
      "[SGD | lr=0.1] Epoch 1544/4000: train_loss=0.0143  test_loss=3.9068  λ_max=58.3153\n",
      "[SGD | lr=0.1] Epoch 1545/4000: train_loss=0.0143  test_loss=3.9071  λ_max=59.6642\n",
      "[SGD | lr=0.1] Epoch 1546/4000: train_loss=0.0143  test_loss=3.9077  λ_max=60.1807\n",
      "[SGD | lr=0.1] Epoch 1547/4000: train_loss=0.0143  test_loss=3.9081  λ_max=58.5426\n",
      "[SGD | lr=0.1] Epoch 1548/4000: train_loss=0.0143  test_loss=3.9089  λ_max=59.0436\n",
      "[SGD | lr=0.1] Epoch 1549/4000: train_loss=0.0142  test_loss=3.9093  λ_max=59.0829\n",
      "[SGD | lr=0.1] Iter 24800: loss=0.0140\n",
      "[SGD | lr=0.1] Epoch 1550/4000: train_loss=0.0142  test_loss=3.9099  λ_max=59.0972\n",
      "[SGD | lr=0.1] Epoch 1551/4000: train_loss=0.0142  test_loss=3.9102  λ_max=61.6800\n",
      "[SGD | lr=0.1] Epoch 1552/4000: train_loss=0.0142  test_loss=3.9106  λ_max=58.0421\n",
      "[SGD | lr=0.1] Epoch 1553/4000: train_loss=0.0142  test_loss=3.9114  λ_max=57.0144\n",
      "[SGD | lr=0.1] Epoch 1554/4000: train_loss=0.0142  test_loss=3.9119  λ_max=58.3885\n",
      "[SGD | lr=0.1] Epoch 1555/4000: train_loss=0.0141  test_loss=3.9121  λ_max=59.4114\n",
      "[SGD | lr=0.1] Epoch 1556/4000: train_loss=0.0141  test_loss=3.9128  λ_max=58.0200\n",
      "[SGD | lr=0.1] Iter 24900: loss=0.0144\n",
      "[SGD | lr=0.1] Epoch 1557/4000: train_loss=0.0141  test_loss=3.9132  λ_max=61.3861\n",
      "[SGD | lr=0.1] Epoch 1558/4000: train_loss=0.0141  test_loss=3.9137  λ_max=60.6486\n",
      "[SGD | lr=0.1] Epoch 1559/4000: train_loss=0.0141  test_loss=3.9143  λ_max=59.2522\n",
      "[SGD | lr=0.1] Epoch 1560/4000: train_loss=0.0141  test_loss=3.9147  λ_max=60.0814\n",
      "[SGD | lr=0.1] Epoch 1561/4000: train_loss=0.0141  test_loss=3.9149  λ_max=59.6793\n",
      "[SGD | lr=0.1] Epoch 1562/4000: train_loss=0.0141  test_loss=3.9159  λ_max=59.9693\n",
      "[SGD | lr=0.1] Iter 25000: loss=0.0139\n",
      "[SGD | lr=0.1] Epoch 1563/4000: train_loss=0.0140  test_loss=3.9164  λ_max=62.1932\n",
      "[SGD | lr=0.1] Epoch 1564/4000: train_loss=0.0140  test_loss=3.9167  λ_max=59.9551\n",
      "[SGD | lr=0.1] Epoch 1565/4000: train_loss=0.0140  test_loss=3.9174  λ_max=59.2594\n",
      "[SGD | lr=0.1] Epoch 1566/4000: train_loss=0.0140  test_loss=3.9179  λ_max=59.6728\n",
      "[SGD | lr=0.1] Epoch 1567/4000: train_loss=0.0140  test_loss=3.9182  λ_max=59.8041\n",
      "[SGD | lr=0.1] Epoch 1568/4000: train_loss=0.0140  test_loss=3.9185  λ_max=58.3904\n",
      "[SGD | lr=0.1] Iter 25100: loss=0.0138\n",
      "[SGD | lr=0.1] Epoch 1569/4000: train_loss=0.0140  test_loss=3.9192  λ_max=60.3063\n",
      "[SGD | lr=0.1] Epoch 1570/4000: train_loss=0.0140  test_loss=3.9197  λ_max=60.1452\n",
      "[SGD | lr=0.1] Epoch 1571/4000: train_loss=0.0139  test_loss=3.9201  λ_max=59.8597\n",
      "[SGD | lr=0.1] Epoch 1572/4000: train_loss=0.0139  test_loss=3.9207  λ_max=58.8599\n",
      "[SGD | lr=0.1] Epoch 1573/4000: train_loss=0.0139  test_loss=3.9209  λ_max=59.8094\n",
      "[SGD | lr=0.1] Epoch 1574/4000: train_loss=0.0139  test_loss=3.9218  λ_max=59.2450\n",
      "[SGD | lr=0.1] Iter 25200: loss=0.0142\n",
      "[SGD | lr=0.1] Epoch 1575/4000: train_loss=0.0139  test_loss=3.9222  λ_max=59.9354\n",
      "[SGD | lr=0.1] Epoch 1576/4000: train_loss=0.0139  test_loss=3.9227  λ_max=60.8256\n",
      "[SGD | lr=0.1] Epoch 1577/4000: train_loss=0.0139  test_loss=3.9232  λ_max=59.2040\n",
      "[SGD | lr=0.1] Epoch 1578/4000: train_loss=0.0138  test_loss=3.9235  λ_max=59.3897\n",
      "[SGD | lr=0.1] Epoch 1579/4000: train_loss=0.0138  test_loss=3.9241  λ_max=57.7440\n",
      "[SGD | lr=0.1] Epoch 1580/4000: train_loss=0.0138  test_loss=3.9245  λ_max=59.9294\n",
      "[SGD | lr=0.1] Epoch 1581/4000: train_loss=0.0138  test_loss=3.9251  λ_max=58.6798\n",
      "[SGD | lr=0.1] Iter 25300: loss=0.0139\n",
      "[SGD | lr=0.1] Epoch 1582/4000: train_loss=0.0138  test_loss=3.9257  λ_max=60.3649\n",
      "[SGD | lr=0.1] Epoch 1583/4000: train_loss=0.0138  test_loss=3.9261  λ_max=58.8943\n",
      "[SGD | lr=0.1] Epoch 1584/4000: train_loss=0.0138  test_loss=3.9265  λ_max=58.5868\n",
      "[SGD | lr=0.1] Epoch 1585/4000: train_loss=0.0138  test_loss=3.9271  λ_max=60.4284\n",
      "[SGD | lr=0.1] Epoch 1586/4000: train_loss=0.0138  test_loss=3.9276  λ_max=57.4314\n",
      "[SGD | lr=0.1] Epoch 1587/4000: train_loss=0.0137  test_loss=3.9279  λ_max=60.6163\n",
      "[SGD | lr=0.1] Iter 25400: loss=0.0136\n",
      "[SGD | lr=0.1] Epoch 1588/4000: train_loss=0.0137  test_loss=3.9287  λ_max=59.0263\n",
      "[SGD | lr=0.1] Epoch 1589/4000: train_loss=0.0137  test_loss=3.9291  λ_max=56.9481\n",
      "[SGD | lr=0.1] Epoch 1590/4000: train_loss=0.0137  test_loss=3.9292  λ_max=59.0517\n",
      "[SGD | lr=0.1] Epoch 1591/4000: train_loss=0.0137  test_loss=3.9300  λ_max=58.9759\n",
      "[SGD | lr=0.1] Epoch 1592/4000: train_loss=0.0137  test_loss=3.9304  λ_max=57.6788\n",
      "[SGD | lr=0.1] Epoch 1593/4000: train_loss=0.0137  test_loss=3.9310  λ_max=59.5111\n",
      "[SGD | lr=0.1] Iter 25500: loss=0.0138\n",
      "[SGD | lr=0.1] Epoch 1594/4000: train_loss=0.0136  test_loss=3.9314  λ_max=60.8707\n",
      "[SGD | lr=0.1] Epoch 1595/4000: train_loss=0.0136  test_loss=3.9318  λ_max=59.8859\n",
      "[SGD | lr=0.1] Epoch 1596/4000: train_loss=0.0136  test_loss=3.9325  λ_max=61.1602\n",
      "[SGD | lr=0.1] Epoch 1597/4000: train_loss=0.0136  test_loss=3.9330  λ_max=60.7693\n",
      "[SGD | lr=0.1] Epoch 1598/4000: train_loss=0.0136  test_loss=3.9335  λ_max=59.4732\n",
      "[SGD | lr=0.1] Epoch 1599/4000: train_loss=0.0136  test_loss=3.9337  λ_max=60.1122\n",
      "[SGD | lr=0.1] Iter 25600: loss=0.0134\n",
      "[SGD | lr=0.1] Epoch 1600/4000: train_loss=0.0136  test_loss=3.9346  λ_max=58.7146\n",
      "[SGD | lr=0.1] Epoch 1601/4000: train_loss=0.0136  test_loss=3.9350  λ_max=61.3681\n",
      "[SGD | lr=0.1] Epoch 1602/4000: train_loss=0.0136  test_loss=3.9353  λ_max=60.9523\n",
      "[SGD | lr=0.1] Epoch 1603/4000: train_loss=0.0135  test_loss=3.9359  λ_max=60.1278\n",
      "[SGD | lr=0.1] Epoch 1604/4000: train_loss=0.0135  test_loss=3.9364  λ_max=59.2907\n",
      "[SGD | lr=0.1] Epoch 1605/4000: train_loss=0.0135  test_loss=3.9368  λ_max=61.5872\n",
      "[SGD | lr=0.1] Epoch 1606/4000: train_loss=0.0135  test_loss=3.9374  λ_max=60.0112\n",
      "[SGD | lr=0.1] Iter 25700: loss=0.0137\n",
      "[SGD | lr=0.1] Epoch 1607/4000: train_loss=0.0135  test_loss=3.9377  λ_max=61.4501\n",
      "[SGD | lr=0.1] Epoch 1608/4000: train_loss=0.0135  test_loss=3.9381  λ_max=61.7140\n",
      "[SGD | lr=0.1] Epoch 1609/4000: train_loss=0.0135  test_loss=3.9386  λ_max=58.0117\n",
      "[SGD | lr=0.1] Epoch 1610/4000: train_loss=0.0135  test_loss=3.9394  λ_max=60.9948\n",
      "[SGD | lr=0.1] Epoch 1611/4000: train_loss=0.0134  test_loss=3.9395  λ_max=59.0276\n",
      "[SGD | lr=0.1] Epoch 1612/4000: train_loss=0.0134  test_loss=3.9402  λ_max=60.1349\n",
      "[SGD | lr=0.1] Iter 25800: loss=0.0135\n",
      "[SGD | lr=0.1] Epoch 1613/4000: train_loss=0.0134  test_loss=3.9407  λ_max=60.3374\n",
      "[SGD | lr=0.1] Epoch 1614/4000: train_loss=0.0134  test_loss=3.9410  λ_max=58.7828\n",
      "[SGD | lr=0.1] Epoch 1615/4000: train_loss=0.0134  test_loss=3.9417  λ_max=59.3391\n",
      "[SGD | lr=0.1] Epoch 1616/4000: train_loss=0.0134  test_loss=3.9418  λ_max=59.9816\n",
      "[SGD | lr=0.1] Epoch 1617/4000: train_loss=0.0134  test_loss=3.9423  λ_max=61.4446\n",
      "[SGD | lr=0.1] Epoch 1618/4000: train_loss=0.0134  test_loss=3.9430  λ_max=61.2532\n",
      "[SGD | lr=0.1] Iter 25900: loss=0.0134\n",
      "[SGD | lr=0.1] Epoch 1619/4000: train_loss=0.0133  test_loss=3.9435  λ_max=60.3987\n",
      "[SGD | lr=0.1] Epoch 1620/4000: train_loss=0.0133  test_loss=3.9439  λ_max=61.4169\n",
      "[SGD | lr=0.1] Epoch 1621/4000: train_loss=0.0133  test_loss=3.9444  λ_max=59.3451\n",
      "[SGD | lr=0.1] Epoch 1622/4000: train_loss=0.0133  test_loss=3.9448  λ_max=59.6598\n",
      "[SGD | lr=0.1] Epoch 1623/4000: train_loss=0.0133  test_loss=3.9455  λ_max=58.2595\n",
      "[SGD | lr=0.1] Epoch 1624/4000: train_loss=0.0133  test_loss=3.9459  λ_max=60.8300\n",
      "[SGD | lr=0.1] Iter 26000: loss=0.0133\n",
      "[SGD | lr=0.1] Epoch 1625/4000: train_loss=0.0133  test_loss=3.9462  λ_max=60.4339\n",
      "[SGD | lr=0.1] Epoch 1626/4000: train_loss=0.0133  test_loss=3.9468  λ_max=60.8172\n",
      "[SGD | lr=0.1] Epoch 1627/4000: train_loss=0.0133  test_loss=3.9472  λ_max=60.3437\n",
      "[SGD | lr=0.1] Epoch 1628/4000: train_loss=0.0132  test_loss=3.9477  λ_max=62.2939\n",
      "[SGD | lr=0.1] Epoch 1629/4000: train_loss=0.0132  test_loss=3.9482  λ_max=63.2740\n",
      "[SGD | lr=0.1] Epoch 1630/4000: train_loss=0.0132  test_loss=3.9487  λ_max=59.6678\n",
      "[SGD | lr=0.1] Epoch 1631/4000: train_loss=0.0132  test_loss=3.9491  λ_max=61.9981\n",
      "[SGD | lr=0.1] Iter 26100: loss=0.0129\n",
      "[SGD | lr=0.1] Epoch 1632/4000: train_loss=0.0132  test_loss=3.9495  λ_max=59.0669\n",
      "[SGD | lr=0.1] Epoch 1633/4000: train_loss=0.0132  test_loss=3.9501  λ_max=59.8652\n",
      "[SGD | lr=0.1] Epoch 1634/4000: train_loss=0.0132  test_loss=3.9505  λ_max=59.4146\n",
      "[SGD | lr=0.1] Epoch 1635/4000: train_loss=0.0131  test_loss=3.9512  λ_max=62.0820\n",
      "[SGD | lr=0.1] Epoch 1636/4000: train_loss=0.0131  test_loss=3.9514  λ_max=60.2460\n",
      "[SGD | lr=0.1] Epoch 1637/4000: train_loss=0.0131  test_loss=3.9520  λ_max=61.6056\n",
      "[SGD | lr=0.1] Iter 26200: loss=0.0129\n",
      "[SGD | lr=0.1] Epoch 1638/4000: train_loss=0.0131  test_loss=3.9523  λ_max=61.3257\n",
      "[SGD | lr=0.1] Epoch 1639/4000: train_loss=0.0131  test_loss=3.9530  λ_max=60.1749\n",
      "[SGD | lr=0.1] Epoch 1640/4000: train_loss=0.0131  test_loss=3.9536  λ_max=60.7043\n",
      "[SGD | lr=0.1] Epoch 1641/4000: train_loss=0.0131  test_loss=3.9538  λ_max=61.3723\n",
      "[SGD | lr=0.1] Epoch 1642/4000: train_loss=0.0131  test_loss=3.9546  λ_max=61.6245\n",
      "[SGD | lr=0.1] Epoch 1643/4000: train_loss=0.0131  test_loss=3.9550  λ_max=60.5955\n",
      "[SGD | lr=0.1] Iter 26300: loss=0.0132\n",
      "[SGD | lr=0.1] Epoch 1644/4000: train_loss=0.0130  test_loss=3.9553  λ_max=59.3880\n",
      "[SGD | lr=0.1] Epoch 1645/4000: train_loss=0.0130  test_loss=3.9559  λ_max=60.3193\n",
      "[SGD | lr=0.1] Epoch 1646/4000: train_loss=0.0130  test_loss=3.9561  λ_max=61.4980\n",
      "[SGD | lr=0.1] Epoch 1647/4000: train_loss=0.0130  test_loss=3.9566  λ_max=62.1971\n",
      "[SGD | lr=0.1] Epoch 1648/4000: train_loss=0.0130  test_loss=3.9572  λ_max=60.4664\n",
      "[SGD | lr=0.1] Epoch 1649/4000: train_loss=0.0130  test_loss=3.9575  λ_max=59.2044\n",
      "[SGD | lr=0.1] Iter 26400: loss=0.0126\n",
      "[SGD | lr=0.1] Epoch 1650/4000: train_loss=0.0130  test_loss=3.9580  λ_max=61.1885\n",
      "[SGD | lr=0.1] Epoch 1651/4000: train_loss=0.0130  test_loss=3.9584  λ_max=59.4642\n",
      "[SGD | lr=0.1] Epoch 1652/4000: train_loss=0.0130  test_loss=3.9589  λ_max=60.8338\n",
      "[SGD | lr=0.1] Epoch 1653/4000: train_loss=0.0129  test_loss=3.9594  λ_max=59.4721\n",
      "[SGD | lr=0.1] Epoch 1654/4000: train_loss=0.0129  test_loss=3.9599  λ_max=58.8217\n",
      "[SGD | lr=0.1] Epoch 1655/4000: train_loss=0.0129  test_loss=3.9602  λ_max=60.8382\n",
      "[SGD | lr=0.1] Epoch 1656/4000: train_loss=0.0129  test_loss=3.9606  λ_max=61.4690\n",
      "[SGD | lr=0.1] Iter 26500: loss=0.0127\n",
      "[SGD | lr=0.1] Epoch 1657/4000: train_loss=0.0129  test_loss=3.9616  λ_max=59.7327\n",
      "[SGD | lr=0.1] Epoch 1658/4000: train_loss=0.0129  test_loss=3.9615  λ_max=60.7298\n",
      "[SGD | lr=0.1] Epoch 1659/4000: train_loss=0.0129  test_loss=3.9621  λ_max=60.5391\n",
      "[SGD | lr=0.1] Epoch 1660/4000: train_loss=0.0129  test_loss=3.9626  λ_max=58.6293\n",
      "[SGD | lr=0.1] Epoch 1661/4000: train_loss=0.0129  test_loss=3.9631  λ_max=59.3645\n",
      "[SGD | lr=0.1] Epoch 1662/4000: train_loss=0.0129  test_loss=3.9636  λ_max=61.6486\n",
      "[SGD | lr=0.1] Iter 26600: loss=0.0129\n",
      "[SGD | lr=0.1] Epoch 1663/4000: train_loss=0.0128  test_loss=3.9641  λ_max=61.2371\n",
      "[SGD | lr=0.1] Epoch 1664/4000: train_loss=0.0128  test_loss=3.9648  λ_max=60.2260\n",
      "[SGD | lr=0.1] Epoch 1665/4000: train_loss=0.0128  test_loss=3.9650  λ_max=59.8832\n",
      "[SGD | lr=0.1] Epoch 1666/4000: train_loss=0.0128  test_loss=3.9653  λ_max=60.9958\n",
      "[SGD | lr=0.1] Epoch 1667/4000: train_loss=0.0128  test_loss=3.9658  λ_max=61.2091\n",
      "[SGD | lr=0.1] Epoch 1668/4000: train_loss=0.0128  test_loss=3.9664  λ_max=60.7637\n",
      "[SGD | lr=0.1] Iter 26700: loss=0.0127\n",
      "[SGD | lr=0.1] Epoch 1669/4000: train_loss=0.0128  test_loss=3.9668  λ_max=59.4172\n",
      "[SGD | lr=0.1] Epoch 1670/4000: train_loss=0.0127  test_loss=3.9673  λ_max=59.4482\n",
      "[SGD | lr=0.1] Epoch 1671/4000: train_loss=0.0127  test_loss=3.9679  λ_max=60.1975\n",
      "[SGD | lr=0.1] Epoch 1672/4000: train_loss=0.0127  test_loss=3.9683  λ_max=61.3531\n",
      "[SGD | lr=0.1] Epoch 1673/4000: train_loss=0.0127  test_loss=3.9686  λ_max=61.0471\n",
      "[SGD | lr=0.1] Epoch 1674/4000: train_loss=0.0127  test_loss=3.9690  λ_max=58.7608\n",
      "[SGD | lr=0.1] Iter 26800: loss=0.0127\n",
      "[SGD | lr=0.1] Epoch 1675/4000: train_loss=0.0127  test_loss=3.9697  λ_max=59.0990\n",
      "[SGD | lr=0.1] Epoch 1676/4000: train_loss=0.0127  test_loss=3.9700  λ_max=59.7017\n",
      "[SGD | lr=0.1] Epoch 1677/4000: train_loss=0.0127  test_loss=3.9704  λ_max=58.5040\n",
      "[SGD | lr=0.1] Epoch 1678/4000: train_loss=0.0127  test_loss=3.9711  λ_max=60.9542\n",
      "[SGD | lr=0.1] Epoch 1679/4000: train_loss=0.0127  test_loss=3.9713  λ_max=62.5461\n",
      "[SGD | lr=0.1] Epoch 1680/4000: train_loss=0.0126  test_loss=3.9719  λ_max=63.1872\n",
      "[SGD | lr=0.1] Epoch 1681/4000: train_loss=0.0126  test_loss=3.9723  λ_max=59.6539\n",
      "[SGD | lr=0.1] Iter 26900: loss=0.0125\n",
      "[SGD | lr=0.1] Epoch 1682/4000: train_loss=0.0126  test_loss=3.9725  λ_max=61.3768\n",
      "[SGD | lr=0.1] Epoch 1683/4000: train_loss=0.0126  test_loss=3.9732  λ_max=61.2615\n",
      "[SGD | lr=0.1] Epoch 1684/4000: train_loss=0.0126  test_loss=3.9734  λ_max=60.3245\n",
      "[SGD | lr=0.1] Epoch 1685/4000: train_loss=0.0126  test_loss=3.9740  λ_max=61.0367\n",
      "[SGD | lr=0.1] Epoch 1686/4000: train_loss=0.0126  test_loss=3.9748  λ_max=61.4163\n",
      "[SGD | lr=0.1] Epoch 1687/4000: train_loss=0.0126  test_loss=3.9749  λ_max=61.7856\n",
      "[SGD | lr=0.1] Iter 27000: loss=0.0124\n",
      "[SGD | lr=0.1] Epoch 1688/4000: train_loss=0.0126  test_loss=3.9757  λ_max=60.4316\n",
      "[SGD | lr=0.1] Epoch 1689/4000: train_loss=0.0125  test_loss=3.9757  λ_max=60.9996\n",
      "[SGD | lr=0.1] Epoch 1690/4000: train_loss=0.0125  test_loss=3.9764  λ_max=63.3595\n",
      "[SGD | lr=0.1] Epoch 1691/4000: train_loss=0.0125  test_loss=3.9768  λ_max=61.2768\n",
      "[SGD | lr=0.1] Epoch 1692/4000: train_loss=0.0125  test_loss=3.9773  λ_max=61.5997\n",
      "[SGD | lr=0.1] Epoch 1693/4000: train_loss=0.0125  test_loss=3.9780  λ_max=61.0192\n",
      "[SGD | lr=0.1] Iter 27100: loss=0.0125\n",
      "[SGD | lr=0.1] Epoch 1694/4000: train_loss=0.0125  test_loss=3.9783  λ_max=61.5199\n",
      "[SGD | lr=0.1] Epoch 1695/4000: train_loss=0.0125  test_loss=3.9785  λ_max=61.4277\n",
      "[SGD | lr=0.1] Epoch 1696/4000: train_loss=0.0125  test_loss=3.9790  λ_max=60.2576\n",
      "[SGD | lr=0.1] Epoch 1697/4000: train_loss=0.0125  test_loss=3.9795  λ_max=61.4847\n",
      "[SGD | lr=0.1] Epoch 1698/4000: train_loss=0.0125  test_loss=3.9801  λ_max=60.5544\n",
      "[SGD | lr=0.1] Epoch 1699/4000: train_loss=0.0124  test_loss=3.9808  λ_max=61.7798\n",
      "[SGD | lr=0.1] Iter 27200: loss=0.0120\n",
      "[SGD | lr=0.1] Epoch 1700/4000: train_loss=0.0124  test_loss=3.9811  λ_max=61.2091\n",
      "[SGD | lr=0.1] Epoch 1701/4000: train_loss=0.0124  test_loss=3.9816  λ_max=58.5983\n",
      "[SGD | lr=0.1] Epoch 1702/4000: train_loss=0.0124  test_loss=3.9817  λ_max=60.0261\n",
      "[SGD | lr=0.1] Epoch 1703/4000: train_loss=0.0124  test_loss=3.9822  λ_max=60.2274\n",
      "[SGD | lr=0.1] Epoch 1704/4000: train_loss=0.0124  test_loss=3.9826  λ_max=60.8945\n",
      "[SGD | lr=0.1] Epoch 1705/4000: train_loss=0.0124  test_loss=3.9831  λ_max=59.9482\n",
      "[SGD | lr=0.1] Epoch 1706/4000: train_loss=0.0124  test_loss=3.9835  λ_max=61.3489\n",
      "[SGD | lr=0.1] Iter 27300: loss=0.0125\n",
      "[SGD | lr=0.1] Epoch 1707/4000: train_loss=0.0124  test_loss=3.9843  λ_max=59.2243\n",
      "[SGD | lr=0.1] Epoch 1708/4000: train_loss=0.0123  test_loss=3.9844  λ_max=61.3746\n",
      "[SGD | lr=0.1] Epoch 1709/4000: train_loss=0.0123  test_loss=3.9849  λ_max=61.8028\n",
      "[SGD | lr=0.1] Epoch 1710/4000: train_loss=0.0123  test_loss=3.9853  λ_max=61.1925\n",
      "[SGD | lr=0.1] Epoch 1711/4000: train_loss=0.0123  test_loss=3.9859  λ_max=60.4396\n",
      "[SGD | lr=0.1] Epoch 1712/4000: train_loss=0.0123  test_loss=3.9864  λ_max=61.4592\n",
      "[SGD | lr=0.1] Iter 27400: loss=0.0123\n",
      "[SGD | lr=0.1] Epoch 1713/4000: train_loss=0.0123  test_loss=3.9867  λ_max=61.1570\n",
      "[SGD | lr=0.1] Epoch 1714/4000: train_loss=0.0123  test_loss=3.9872  λ_max=62.6708\n",
      "[SGD | lr=0.1] Epoch 1715/4000: train_loss=0.0123  test_loss=3.9874  λ_max=61.7617\n",
      "[SGD | lr=0.1] Epoch 1716/4000: train_loss=0.0123  test_loss=3.9883  λ_max=62.2067\n",
      "[SGD | lr=0.1] Epoch 1717/4000: train_loss=0.0123  test_loss=3.9883  λ_max=59.1656\n",
      "[SGD | lr=0.1] Epoch 1718/4000: train_loss=0.0122  test_loss=3.9889  λ_max=59.7162\n",
      "[SGD | lr=0.1] Iter 27500: loss=0.0125\n",
      "[SGD | lr=0.1] Epoch 1719/4000: train_loss=0.0122  test_loss=3.9894  λ_max=62.5871\n",
      "[SGD | lr=0.1] Epoch 1720/4000: train_loss=0.0122  test_loss=3.9898  λ_max=59.9715\n",
      "[SGD | lr=0.1] Epoch 1721/4000: train_loss=0.0122  test_loss=3.9902  λ_max=61.2726\n",
      "[SGD | lr=0.1] Epoch 1722/4000: train_loss=0.0122  test_loss=3.9907  λ_max=59.7813\n",
      "[SGD | lr=0.1] Epoch 1723/4000: train_loss=0.0122  test_loss=3.9912  λ_max=62.1520\n",
      "[SGD | lr=0.1] Epoch 1724/4000: train_loss=0.0122  test_loss=3.9916  λ_max=62.6712\n",
      "[SGD | lr=0.1] Iter 27600: loss=0.0125\n",
      "[SGD | lr=0.1] Epoch 1725/4000: train_loss=0.0122  test_loss=3.9920  λ_max=61.3226\n",
      "[SGD | lr=0.1] Epoch 1726/4000: train_loss=0.0122  test_loss=3.9923  λ_max=62.1126\n",
      "[SGD | lr=0.1] Epoch 1727/4000: train_loss=0.0121  test_loss=3.9925  λ_max=62.0593\n",
      "[SGD | lr=0.1] Epoch 1728/4000: train_loss=0.0121  test_loss=3.9934  λ_max=60.9939\n",
      "[SGD | lr=0.1] Epoch 1729/4000: train_loss=0.0121  test_loss=3.9939  λ_max=61.0551\n",
      "[SGD | lr=0.1] Epoch 1730/4000: train_loss=0.0121  test_loss=3.9943  λ_max=61.2235\n",
      "[SGD | lr=0.1] Epoch 1731/4000: train_loss=0.0121  test_loss=3.9949  λ_max=60.8881\n",
      "[SGD | lr=0.1] Iter 27700: loss=0.0120\n",
      "[SGD | lr=0.1] Epoch 1732/4000: train_loss=0.0121  test_loss=3.9949  λ_max=60.0009\n",
      "[SGD | lr=0.1] Epoch 1733/4000: train_loss=0.0121  test_loss=3.9954  λ_max=61.9223\n",
      "[SGD | lr=0.1] Epoch 1734/4000: train_loss=0.0121  test_loss=3.9960  λ_max=61.1066\n",
      "[SGD | lr=0.1] Epoch 1735/4000: train_loss=0.0121  test_loss=3.9963  λ_max=60.4758\n",
      "[SGD | lr=0.1] Epoch 1736/4000: train_loss=0.0121  test_loss=3.9969  λ_max=63.5708\n",
      "[SGD | lr=0.1] Epoch 1737/4000: train_loss=0.0120  test_loss=3.9975  λ_max=58.8093\n",
      "[SGD | lr=0.1] Iter 27800: loss=0.0119\n",
      "[SGD | lr=0.1] Epoch 1738/4000: train_loss=0.0120  test_loss=3.9977  λ_max=61.7630\n",
      "[SGD | lr=0.1] Epoch 1739/4000: train_loss=0.0120  test_loss=3.9983  λ_max=63.3885\n",
      "[SGD | lr=0.1] Epoch 1740/4000: train_loss=0.0120  test_loss=3.9985  λ_max=61.3572\n",
      "[SGD | lr=0.1] Epoch 1741/4000: train_loss=0.0120  test_loss=3.9990  λ_max=60.7011\n",
      "[SGD | lr=0.1] Epoch 1742/4000: train_loss=0.0120  test_loss=3.9997  λ_max=61.6652\n",
      "[SGD | lr=0.1] Epoch 1743/4000: train_loss=0.0120  test_loss=4.0001  λ_max=61.1366\n",
      "[SGD | lr=0.1] Iter 27900: loss=0.0121\n",
      "[SGD | lr=0.1] Epoch 1744/4000: train_loss=0.0120  test_loss=4.0005  λ_max=60.3064\n",
      "[SGD | lr=0.1] Epoch 1745/4000: train_loss=0.0120  test_loss=4.0009  λ_max=61.1797\n",
      "[SGD | lr=0.1] Epoch 1746/4000: train_loss=0.0120  test_loss=4.0014  λ_max=60.3490\n",
      "[SGD | lr=0.1] Epoch 1747/4000: train_loss=0.0120  test_loss=4.0017  λ_max=61.5064\n",
      "[SGD | lr=0.1] Epoch 1748/4000: train_loss=0.0119  test_loss=4.0023  λ_max=63.9354\n",
      "[SGD | lr=0.1] Epoch 1749/4000: train_loss=0.0119  test_loss=4.0025  λ_max=62.6632\n",
      "[SGD | lr=0.1] Iter 28000: loss=0.0119\n",
      "[SGD | lr=0.1] Epoch 1750/4000: train_loss=0.0119  test_loss=4.0029  λ_max=60.6429\n",
      "[SGD | lr=0.1] Epoch 1751/4000: train_loss=0.0119  test_loss=4.0033  λ_max=60.8083\n",
      "[SGD | lr=0.1] Epoch 1752/4000: train_loss=0.0119  test_loss=4.0042  λ_max=63.3061\n",
      "[SGD | lr=0.1] Epoch 1753/4000: train_loss=0.0119  test_loss=4.0044  λ_max=62.8454\n",
      "[SGD | lr=0.1] Epoch 1754/4000: train_loss=0.0119  test_loss=4.0049  λ_max=61.9265\n",
      "[SGD | lr=0.1] Epoch 1755/4000: train_loss=0.0119  test_loss=4.0051  λ_max=62.3009\n",
      "[SGD | lr=0.1] Epoch 1756/4000: train_loss=0.0119  test_loss=4.0055  λ_max=61.5531\n",
      "[SGD | lr=0.1] Iter 28100: loss=0.0118\n",
      "[SGD | lr=0.1] Epoch 1757/4000: train_loss=0.0119  test_loss=4.0061  λ_max=63.2958\n",
      "[SGD | lr=0.1] Epoch 1758/4000: train_loss=0.0118  test_loss=4.0066  λ_max=60.1547\n",
      "[SGD | lr=0.1] Epoch 1759/4000: train_loss=0.0118  test_loss=4.0069  λ_max=60.8876\n",
      "[SGD | lr=0.1] Epoch 1760/4000: train_loss=0.0118  test_loss=4.0074  λ_max=62.3620\n",
      "[SGD | lr=0.1] Epoch 1761/4000: train_loss=0.0118  test_loss=4.0077  λ_max=61.5578\n",
      "[SGD | lr=0.1] Epoch 1762/4000: train_loss=0.0118  test_loss=4.0083  λ_max=62.7490\n",
      "[SGD | lr=0.1] Iter 28200: loss=0.0116\n",
      "[SGD | lr=0.1] Epoch 1763/4000: train_loss=0.0118  test_loss=4.0085  λ_max=61.2612\n",
      "[SGD | lr=0.1] Epoch 1764/4000: train_loss=0.0118  test_loss=4.0090  λ_max=61.1491\n",
      "[SGD | lr=0.1] Epoch 1765/4000: train_loss=0.0118  test_loss=4.0094  λ_max=62.2286\n",
      "[SGD | lr=0.1] Epoch 1766/4000: train_loss=0.0118  test_loss=4.0098  λ_max=62.1127\n",
      "[SGD | lr=0.1] Epoch 1767/4000: train_loss=0.0118  test_loss=4.0103  λ_max=60.5984\n",
      "[SGD | lr=0.1] Epoch 1768/4000: train_loss=0.0117  test_loss=4.0106  λ_max=59.1601\n",
      "[SGD | lr=0.1] Iter 28300: loss=0.0117\n",
      "[SGD | lr=0.1] Epoch 1769/4000: train_loss=0.0117  test_loss=4.0111  λ_max=61.9237\n",
      "[SGD | lr=0.1] Epoch 1770/4000: train_loss=0.0117  test_loss=4.0115  λ_max=60.3949\n",
      "[SGD | lr=0.1] Epoch 1771/4000: train_loss=0.0117  test_loss=4.0120  λ_max=63.4669\n",
      "[SGD | lr=0.1] Epoch 1772/4000: train_loss=0.0117  test_loss=4.0125  λ_max=61.1142\n",
      "[SGD | lr=0.1] Epoch 1773/4000: train_loss=0.0117  test_loss=4.0129  λ_max=61.7327\n",
      "[SGD | lr=0.1] Epoch 1774/4000: train_loss=0.0117  test_loss=4.0134  λ_max=61.9158\n",
      "[SGD | lr=0.1] Iter 28400: loss=0.0116\n",
      "[SGD | lr=0.1] Epoch 1775/4000: train_loss=0.0117  test_loss=4.0136  λ_max=61.5534\n",
      "[SGD | lr=0.1] Epoch 1776/4000: train_loss=0.0117  test_loss=4.0143  λ_max=62.1948\n",
      "[SGD | lr=0.1] Epoch 1777/4000: train_loss=0.0117  test_loss=4.0145  λ_max=61.7161\n",
      "[SGD | lr=0.1] Epoch 1778/4000: train_loss=0.0117  test_loss=4.0151  λ_max=64.1289\n",
      "[SGD | lr=0.1] Epoch 1779/4000: train_loss=0.0116  test_loss=4.0155  λ_max=62.3373\n",
      "[SGD | lr=0.1] Epoch 1780/4000: train_loss=0.0116  test_loss=4.0159  λ_max=61.3513\n",
      "[SGD | lr=0.1] Epoch 1781/4000: train_loss=0.0116  test_loss=4.0164  λ_max=61.8013\n",
      "[SGD | lr=0.1] Iter 28500: loss=0.0116\n",
      "[SGD | lr=0.1] Epoch 1782/4000: train_loss=0.0116  test_loss=4.0166  λ_max=61.4274\n",
      "[SGD | lr=0.1] Epoch 1783/4000: train_loss=0.0116  test_loss=4.0173  λ_max=63.4274\n",
      "[SGD | lr=0.1] Epoch 1784/4000: train_loss=0.0116  test_loss=4.0177  λ_max=61.8759\n",
      "[SGD | lr=0.1] Epoch 1785/4000: train_loss=0.0116  test_loss=4.0180  λ_max=62.7298\n",
      "[SGD | lr=0.1] Epoch 1786/4000: train_loss=0.0116  test_loss=4.0183  λ_max=62.4960\n",
      "[SGD | lr=0.1] Epoch 1787/4000: train_loss=0.0116  test_loss=4.0190  λ_max=62.8914\n",
      "[SGD | lr=0.1] Iter 28600: loss=0.0114\n",
      "[SGD | lr=0.1] Epoch 1788/4000: train_loss=0.0116  test_loss=4.0192  λ_max=62.7171\n",
      "[SGD | lr=0.1] Epoch 1789/4000: train_loss=0.0115  test_loss=4.0197  λ_max=62.8613\n",
      "[SGD | lr=0.1] Epoch 1790/4000: train_loss=0.0115  test_loss=4.0202  λ_max=63.5398\n",
      "[SGD | lr=0.1] Epoch 1791/4000: train_loss=0.0115  test_loss=4.0205  λ_max=63.7144\n",
      "[SGD | lr=0.1] Epoch 1792/4000: train_loss=0.0115  test_loss=4.0212  λ_max=59.3894\n",
      "[SGD | lr=0.1] Epoch 1793/4000: train_loss=0.0115  test_loss=4.0214  λ_max=60.5961\n",
      "[SGD | lr=0.1] Iter 28700: loss=0.0115\n",
      "[SGD | lr=0.1] Epoch 1794/4000: train_loss=0.0115  test_loss=4.0220  λ_max=60.1484\n",
      "[SGD | lr=0.1] Epoch 1795/4000: train_loss=0.0115  test_loss=4.0223  λ_max=63.5629\n",
      "[SGD | lr=0.1] Epoch 1796/4000: train_loss=0.0115  test_loss=4.0227  λ_max=62.1968\n",
      "[SGD | lr=0.1] Epoch 1797/4000: train_loss=0.0115  test_loss=4.0231  λ_max=62.2612\n",
      "[SGD | lr=0.1] Epoch 1798/4000: train_loss=0.0115  test_loss=4.0235  λ_max=63.1107\n",
      "[SGD | lr=0.1] Epoch 1799/4000: train_loss=0.0115  test_loss=4.0239  λ_max=61.8417\n",
      "[SGD | lr=0.1] Iter 28800: loss=0.0115\n",
      "[SGD | lr=0.1] Epoch 1800/4000: train_loss=0.0114  test_loss=4.0245  λ_max=61.1332\n",
      "[SGD | lr=0.1] Epoch 1801/4000: train_loss=0.0114  test_loss=4.0247  λ_max=61.3670\n",
      "[SGD | lr=0.1] Epoch 1802/4000: train_loss=0.0114  test_loss=4.0255  λ_max=63.1618\n",
      "[SGD | lr=0.1] Epoch 1803/4000: train_loss=0.0114  test_loss=4.0256  λ_max=61.1954\n",
      "[SGD | lr=0.1] Epoch 1804/4000: train_loss=0.0114  test_loss=4.0259  λ_max=62.2311\n",
      "[SGD | lr=0.1] Epoch 1805/4000: train_loss=0.0114  test_loss=4.0265  λ_max=62.9497\n",
      "[SGD | lr=0.1] Epoch 1806/4000: train_loss=0.0114  test_loss=4.0268  λ_max=63.8435\n",
      "[SGD | lr=0.1] Iter 28900: loss=0.0112\n",
      "[SGD | lr=0.1] Epoch 1807/4000: train_loss=0.0114  test_loss=4.0274  λ_max=61.7143\n",
      "[SGD | lr=0.1] Epoch 1808/4000: train_loss=0.0114  test_loss=4.0277  λ_max=61.3037\n",
      "[SGD | lr=0.1] Epoch 1809/4000: train_loss=0.0114  test_loss=4.0282  λ_max=64.5422\n",
      "[SGD | lr=0.1] Epoch 1810/4000: train_loss=0.0114  test_loss=4.0286  λ_max=63.3499\n",
      "[SGD | lr=0.1] Epoch 1811/4000: train_loss=0.0113  test_loss=4.0291  λ_max=62.6392\n",
      "[SGD | lr=0.1] Epoch 1812/4000: train_loss=0.0113  test_loss=4.0295  λ_max=59.4613\n",
      "[SGD | lr=0.1] Iter 29000: loss=0.0112\n",
      "[SGD | lr=0.1] Epoch 1813/4000: train_loss=0.0113  test_loss=4.0296  λ_max=63.5655\n",
      "[SGD | lr=0.1] Epoch 1814/4000: train_loss=0.0113  test_loss=4.0302  λ_max=61.8934\n",
      "[SGD | lr=0.1] Epoch 1815/4000: train_loss=0.0113  test_loss=4.0304  λ_max=62.8513\n",
      "[SGD | lr=0.1] Epoch 1816/4000: train_loss=0.0113  test_loss=4.0312  λ_max=63.4924\n",
      "[SGD | lr=0.1] Epoch 1817/4000: train_loss=0.0113  test_loss=4.0315  λ_max=62.7237\n",
      "[SGD | lr=0.1] Epoch 1818/4000: train_loss=0.0113  test_loss=4.0320  λ_max=63.3421\n",
      "[SGD | lr=0.1] Iter 29100: loss=0.0113\n",
      "[SGD | lr=0.1] Epoch 1819/4000: train_loss=0.0113  test_loss=4.0320  λ_max=62.7365\n",
      "[SGD | lr=0.1] Epoch 1820/4000: train_loss=0.0113  test_loss=4.0329  λ_max=61.8140\n",
      "[SGD | lr=0.1] Epoch 1821/4000: train_loss=0.0113  test_loss=4.0331  λ_max=62.6572\n",
      "[SGD | lr=0.1] Epoch 1822/4000: train_loss=0.0113  test_loss=4.0335  λ_max=61.6372\n",
      "[SGD | lr=0.1] Epoch 1823/4000: train_loss=0.0112  test_loss=4.0339  λ_max=60.8207\n",
      "[SGD | lr=0.1] Epoch 1824/4000: train_loss=0.0112  test_loss=4.0344  λ_max=61.7126\n",
      "[SGD | lr=0.1] Iter 29200: loss=0.0110\n",
      "[SGD | lr=0.1] Epoch 1825/4000: train_loss=0.0112  test_loss=4.0347  λ_max=62.3843\n",
      "[SGD | lr=0.1] Epoch 1826/4000: train_loss=0.0112  test_loss=4.0353  λ_max=61.4624\n",
      "[SGD | lr=0.1] Epoch 1827/4000: train_loss=0.0112  test_loss=4.0358  λ_max=63.6475\n",
      "[SGD | lr=0.1] Epoch 1828/4000: train_loss=0.0112  test_loss=4.0361  λ_max=60.9818\n",
      "[SGD | lr=0.1] Epoch 1829/4000: train_loss=0.0112  test_loss=4.0365  λ_max=61.4908\n",
      "[SGD | lr=0.1] Epoch 1830/4000: train_loss=0.0112  test_loss=4.0369  λ_max=60.8932\n",
      "[SGD | lr=0.1] Epoch 1831/4000: train_loss=0.0112  test_loss=4.0371  λ_max=63.8172\n",
      "[SGD | lr=0.1] Iter 29300: loss=0.0112\n",
      "[SGD | lr=0.1] Epoch 1832/4000: train_loss=0.0112  test_loss=4.0375  λ_max=61.9852\n",
      "[SGD | lr=0.1] Epoch 1833/4000: train_loss=0.0112  test_loss=4.0380  λ_max=64.1833\n",
      "[SGD | lr=0.1] Epoch 1834/4000: train_loss=0.0111  test_loss=4.0385  λ_max=63.7078\n",
      "[SGD | lr=0.1] Epoch 1835/4000: train_loss=0.0111  test_loss=4.0390  λ_max=63.6390\n",
      "[SGD | lr=0.1] Epoch 1836/4000: train_loss=0.0111  test_loss=4.0393  λ_max=61.5546\n",
      "[SGD | lr=0.1] Epoch 1837/4000: train_loss=0.0111  test_loss=4.0399  λ_max=61.1840\n",
      "[SGD | lr=0.1] Iter 29400: loss=0.0113\n",
      "[SGD | lr=0.1] Epoch 1838/4000: train_loss=0.0111  test_loss=4.0402  λ_max=63.3059\n",
      "[SGD | lr=0.1] Epoch 1839/4000: train_loss=0.0111  test_loss=4.0408  λ_max=63.2796\n",
      "[SGD | lr=0.1] Epoch 1840/4000: train_loss=0.0111  test_loss=4.0409  λ_max=63.4966\n",
      "[SGD | lr=0.1] Epoch 1841/4000: train_loss=0.0111  test_loss=4.0415  λ_max=61.7904\n",
      "[SGD | lr=0.1] Epoch 1842/4000: train_loss=0.0111  test_loss=4.0420  λ_max=64.0619\n",
      "[SGD | lr=0.1] Epoch 1843/4000: train_loss=0.0111  test_loss=4.0425  λ_max=64.1114\n",
      "[SGD | lr=0.1] Iter 29500: loss=0.0110\n",
      "[SGD | lr=0.1] Epoch 1844/4000: train_loss=0.0111  test_loss=4.0426  λ_max=60.6859\n",
      "[SGD | lr=0.1] Epoch 1845/4000: train_loss=0.0111  test_loss=4.0431  λ_max=62.8397\n",
      "[SGD | lr=0.1] Epoch 1846/4000: train_loss=0.0110  test_loss=4.0434  λ_max=62.0907\n",
      "[SGD | lr=0.1] Epoch 1847/4000: train_loss=0.0110  test_loss=4.0439  λ_max=64.1477\n",
      "[SGD | lr=0.1] Epoch 1848/4000: train_loss=0.0110  test_loss=4.0441  λ_max=61.6041\n",
      "[SGD | lr=0.1] Epoch 1849/4000: train_loss=0.0110  test_loss=4.0446  λ_max=62.6353\n",
      "[SGD | lr=0.1] Iter 29600: loss=0.0110\n",
      "[SGD | lr=0.1] Epoch 1850/4000: train_loss=0.0110  test_loss=4.0451  λ_max=62.2129\n",
      "[SGD | lr=0.1] Epoch 1851/4000: train_loss=0.0110  test_loss=4.0453  λ_max=61.6457\n",
      "[SGD | lr=0.1] Epoch 1852/4000: train_loss=0.0110  test_loss=4.0458  λ_max=62.1930\n",
      "[SGD | lr=0.1] Epoch 1853/4000: train_loss=0.0110  test_loss=4.0463  λ_max=61.5426\n",
      "[SGD | lr=0.1] Epoch 1854/4000: train_loss=0.0110  test_loss=4.0467  λ_max=63.9589\n",
      "[SGD | lr=0.1] Epoch 1855/4000: train_loss=0.0110  test_loss=4.0470  λ_max=62.5230\n",
      "[SGD | lr=0.1] Epoch 1856/4000: train_loss=0.0110  test_loss=4.0474  λ_max=62.9596\n",
      "[SGD | lr=0.1] Iter 29700: loss=0.0109\n",
      "[SGD | lr=0.1] Epoch 1857/4000: train_loss=0.0109  test_loss=4.0480  λ_max=62.4986\n",
      "[SGD | lr=0.1] Epoch 1858/4000: train_loss=0.0109  test_loss=4.0484  λ_max=64.8868\n",
      "[SGD | lr=0.1] Epoch 1859/4000: train_loss=0.0109  test_loss=4.0487  λ_max=62.1583\n",
      "[SGD | lr=0.1] Epoch 1860/4000: train_loss=0.0109  test_loss=4.0491  λ_max=63.7243\n",
      "[SGD | lr=0.1] Epoch 1861/4000: train_loss=0.0109  test_loss=4.0496  λ_max=63.0844\n",
      "[SGD | lr=0.1] Epoch 1862/4000: train_loss=0.0109  test_loss=4.0501  λ_max=62.2770\n",
      "[SGD | lr=0.1] Iter 29800: loss=0.0109\n",
      "[SGD | lr=0.1] Epoch 1863/4000: train_loss=0.0109  test_loss=4.0502  λ_max=62.2742\n",
      "[SGD | lr=0.1] Epoch 1864/4000: train_loss=0.0109  test_loss=4.0508  λ_max=64.5456\n",
      "[SGD | lr=0.1] Epoch 1865/4000: train_loss=0.0109  test_loss=4.0511  λ_max=63.4944\n",
      "[SGD | lr=0.1] Epoch 1866/4000: train_loss=0.0109  test_loss=4.0517  λ_max=61.6788\n",
      "[SGD | lr=0.1] Epoch 1867/4000: train_loss=0.0109  test_loss=4.0519  λ_max=63.4109\n",
      "[SGD | lr=0.1] Epoch 1868/4000: train_loss=0.0109  test_loss=4.0522  λ_max=62.2454\n",
      "[SGD | lr=0.1] Iter 29900: loss=0.0109\n",
      "[SGD | lr=0.1] Epoch 1869/4000: train_loss=0.0109  test_loss=4.0528  λ_max=63.0554\n",
      "[SGD | lr=0.1] Epoch 1870/4000: train_loss=0.0108  test_loss=4.0534  λ_max=61.9243\n",
      "[SGD | lr=0.1] Epoch 1871/4000: train_loss=0.0108  test_loss=4.0538  λ_max=64.5132\n",
      "[SGD | lr=0.1] Epoch 1872/4000: train_loss=0.0108  test_loss=4.0539  λ_max=62.1368\n",
      "[SGD | lr=0.1] Epoch 1873/4000: train_loss=0.0108  test_loss=4.0544  λ_max=63.7697\n",
      "[SGD | lr=0.1] Epoch 1874/4000: train_loss=0.0108  test_loss=4.0548  λ_max=62.9816\n",
      "[SGD | lr=0.1] Iter 30000: loss=0.0108\n",
      "[SGD | lr=0.1] Epoch 1875/4000: train_loss=0.0108  test_loss=4.0554  λ_max=62.8461\n",
      "[SGD | lr=0.1] Epoch 1876/4000: train_loss=0.0108  test_loss=4.0555  λ_max=63.3849\n",
      "[SGD | lr=0.1] Epoch 1877/4000: train_loss=0.0108  test_loss=4.0561  λ_max=63.2771\n",
      "[SGD | lr=0.1] Epoch 1878/4000: train_loss=0.0108  test_loss=4.0565  λ_max=65.5251\n",
      "[SGD | lr=0.1] Epoch 1879/4000: train_loss=0.0108  test_loss=4.0571  λ_max=63.6426\n",
      "[SGD | lr=0.1] Epoch 1880/4000: train_loss=0.0108  test_loss=4.0574  λ_max=64.5790\n",
      "[SGD | lr=0.1] Epoch 1881/4000: train_loss=0.0108  test_loss=4.0576  λ_max=63.5726\n",
      "[SGD | lr=0.1] Iter 30100: loss=0.0108\n",
      "[SGD | lr=0.1] Epoch 1882/4000: train_loss=0.0107  test_loss=4.0581  λ_max=63.6167\n",
      "[SGD | lr=0.1] Epoch 1883/4000: train_loss=0.0107  test_loss=4.0585  λ_max=63.6987\n",
      "[SGD | lr=0.1] Epoch 1884/4000: train_loss=0.0107  test_loss=4.0590  λ_max=62.5403\n",
      "[SGD | lr=0.1] Epoch 1885/4000: train_loss=0.0107  test_loss=4.0590  λ_max=63.5742\n",
      "[SGD | lr=0.1] Epoch 1886/4000: train_loss=0.0107  test_loss=4.0597  λ_max=63.7576\n",
      "[SGD | lr=0.1] Epoch 1887/4000: train_loss=0.0107  test_loss=4.0598  λ_max=62.9184\n",
      "[SGD | lr=0.1] Iter 30200: loss=0.0105\n",
      "[SGD | lr=0.1] Epoch 1888/4000: train_loss=0.0107  test_loss=4.0603  λ_max=63.7317\n",
      "[SGD | lr=0.1] Epoch 1889/4000: train_loss=0.0107  test_loss=4.0610  λ_max=62.7238\n",
      "[SGD | lr=0.1] Epoch 1890/4000: train_loss=0.0107  test_loss=4.0613  λ_max=64.4276\n",
      "[SGD | lr=0.1] Epoch 1891/4000: train_loss=0.0107  test_loss=4.0616  λ_max=61.3700\n",
      "[SGD | lr=0.1] Epoch 1892/4000: train_loss=0.0107  test_loss=4.0621  λ_max=63.4320\n",
      "[SGD | lr=0.1] Epoch 1893/4000: train_loss=0.0107  test_loss=4.0625  λ_max=64.7750\n",
      "[SGD | lr=0.1] Iter 30300: loss=0.0109\n",
      "[SGD | lr=0.1] Epoch 1894/4000: train_loss=0.0106  test_loss=4.0628  λ_max=61.2204\n",
      "[SGD | lr=0.1] Epoch 1895/4000: train_loss=0.0106  test_loss=4.0633  λ_max=64.6382\n",
      "[SGD | lr=0.1] Epoch 1896/4000: train_loss=0.0106  test_loss=4.0637  λ_max=63.1862\n",
      "[SGD | lr=0.1] Epoch 1897/4000: train_loss=0.0106  test_loss=4.0640  λ_max=63.9798\n",
      "[SGD | lr=0.1] Epoch 1898/4000: train_loss=0.0106  test_loss=4.0645  λ_max=63.0861\n",
      "[SGD | lr=0.1] Epoch 1899/4000: train_loss=0.0106  test_loss=4.0649  λ_max=63.6543\n",
      "[SGD | lr=0.1] Iter 30400: loss=0.0107\n",
      "[SGD | lr=0.1] Epoch 1900/4000: train_loss=0.0106  test_loss=4.0653  λ_max=65.5319\n",
      "[SGD | lr=0.1] Epoch 1901/4000: train_loss=0.0106  test_loss=4.0656  λ_max=61.7645\n",
      "[SGD | lr=0.1] Epoch 1902/4000: train_loss=0.0106  test_loss=4.0660  λ_max=61.8715\n",
      "[SGD | lr=0.1] Epoch 1903/4000: train_loss=0.0106  test_loss=4.0664  λ_max=60.6900\n",
      "[SGD | lr=0.1] Epoch 1904/4000: train_loss=0.0106  test_loss=4.0669  λ_max=63.3551\n",
      "[SGD | lr=0.1] Epoch 1905/4000: train_loss=0.0106  test_loss=4.0672  λ_max=63.8442\n",
      "[SGD | lr=0.1] Epoch 1906/4000: train_loss=0.0106  test_loss=4.0676  λ_max=65.3084\n",
      "[SGD | lr=0.1] Iter 30500: loss=0.0106\n",
      "[SGD | lr=0.1] Epoch 1907/4000: train_loss=0.0105  test_loss=4.0679  λ_max=64.2436\n",
      "[SGD | lr=0.1] Epoch 1908/4000: train_loss=0.0105  test_loss=4.0685  λ_max=65.3283\n",
      "[SGD | lr=0.1] Epoch 1909/4000: train_loss=0.0105  test_loss=4.0685  λ_max=61.8838\n",
      "[SGD | lr=0.1] Epoch 1910/4000: train_loss=0.0105  test_loss=4.0692  λ_max=63.9712\n",
      "[SGD | lr=0.1] Epoch 1911/4000: train_loss=0.0105  test_loss=4.0696  λ_max=63.3745\n",
      "[SGD | lr=0.1] Epoch 1912/4000: train_loss=0.0105  test_loss=4.0698  λ_max=64.9374\n",
      "[SGD | lr=0.1] Iter 30600: loss=0.0105\n",
      "[SGD | lr=0.1] Epoch 1913/4000: train_loss=0.0105  test_loss=4.0703  λ_max=63.1495\n",
      "[SGD | lr=0.1] Epoch 1914/4000: train_loss=0.0105  test_loss=4.0706  λ_max=61.7394\n",
      "[SGD | lr=0.1] Epoch 1915/4000: train_loss=0.0105  test_loss=4.0714  λ_max=63.3577\n",
      "[SGD | lr=0.1] Epoch 1916/4000: train_loss=0.0105  test_loss=4.0715  λ_max=63.6191\n",
      "[SGD | lr=0.1] Epoch 1917/4000: train_loss=0.0105  test_loss=4.0719  λ_max=62.6841\n",
      "[SGD | lr=0.1] Epoch 1918/4000: train_loss=0.0105  test_loss=4.0721  λ_max=61.0461\n",
      "[SGD | lr=0.1] Iter 30700: loss=0.0106\n",
      "[SGD | lr=0.1] Epoch 1919/4000: train_loss=0.0104  test_loss=4.0726  λ_max=62.8717\n",
      "[SGD | lr=0.1] Epoch 1920/4000: train_loss=0.0104  test_loss=4.0731  λ_max=62.3945\n",
      "[SGD | lr=0.1] Epoch 1921/4000: train_loss=0.0104  test_loss=4.0734  λ_max=63.2707\n",
      "[SGD | lr=0.1] Epoch 1922/4000: train_loss=0.0104  test_loss=4.0740  λ_max=63.3202\n",
      "[SGD | lr=0.1] Epoch 1923/4000: train_loss=0.0104  test_loss=4.0743  λ_max=63.5762\n",
      "[SGD | lr=0.1] Epoch 1924/4000: train_loss=0.0104  test_loss=4.0747  λ_max=61.3076\n",
      "[SGD | lr=0.1] Iter 30800: loss=0.0103\n",
      "[SGD | lr=0.1] Epoch 1925/4000: train_loss=0.0104  test_loss=4.0752  λ_max=63.7612\n",
      "[SGD | lr=0.1] Epoch 1926/4000: train_loss=0.0104  test_loss=4.0755  λ_max=64.6079\n",
      "[SGD | lr=0.1] Epoch 1927/4000: train_loss=0.0104  test_loss=4.0759  λ_max=63.7894\n",
      "[SGD | lr=0.1] Epoch 1928/4000: train_loss=0.0104  test_loss=4.0762  λ_max=65.4947\n",
      "[SGD | lr=0.1] Epoch 1929/4000: train_loss=0.0104  test_loss=4.0766  λ_max=65.0880\n",
      "[SGD | lr=0.1] Epoch 1930/4000: train_loss=0.0104  test_loss=4.0769  λ_max=62.0916\n",
      "[SGD | lr=0.1] Epoch 1931/4000: train_loss=0.0104  test_loss=4.0772  λ_max=64.5480\n",
      "[SGD | lr=0.1] Iter 30900: loss=0.0103\n",
      "[SGD | lr=0.1] Epoch 1932/4000: train_loss=0.0104  test_loss=4.0777  λ_max=63.4903\n",
      "[SGD | lr=0.1] Epoch 1933/4000: train_loss=0.0103  test_loss=4.0783  λ_max=65.4828\n",
      "[SGD | lr=0.1] Epoch 1934/4000: train_loss=0.0103  test_loss=4.0787  λ_max=61.8480\n",
      "[SGD | lr=0.1] Epoch 1935/4000: train_loss=0.0103  test_loss=4.0790  λ_max=63.3926\n",
      "[SGD | lr=0.1] Epoch 1936/4000: train_loss=0.0103  test_loss=4.0795  λ_max=64.6475\n",
      "[SGD | lr=0.1] Epoch 1937/4000: train_loss=0.0103  test_loss=4.0796  λ_max=64.5359\n",
      "[SGD | lr=0.1] Iter 31000: loss=0.0102\n",
      "[SGD | lr=0.1] Epoch 1938/4000: train_loss=0.0103  test_loss=4.0802  λ_max=64.6797\n",
      "[SGD | lr=0.1] Epoch 1939/4000: train_loss=0.0103  test_loss=4.0803  λ_max=63.9161\n",
      "[SGD | lr=0.1] Epoch 1940/4000: train_loss=0.0103  test_loss=4.0808  λ_max=63.7176\n",
      "[SGD | lr=0.1] Epoch 1941/4000: train_loss=0.0103  test_loss=4.0813  λ_max=64.9909\n",
      "[SGD | lr=0.1] Epoch 1942/4000: train_loss=0.0103  test_loss=4.0816  λ_max=63.8792\n",
      "[SGD | lr=0.1] Epoch 1943/4000: train_loss=0.0103  test_loss=4.0819  λ_max=62.6195\n",
      "[SGD | lr=0.1] Iter 31100: loss=0.0104\n",
      "[SGD | lr=0.1] Epoch 1944/4000: train_loss=0.0103  test_loss=4.0824  λ_max=64.4786\n",
      "[SGD | lr=0.1] Epoch 1945/4000: train_loss=0.0103  test_loss=4.0828  λ_max=61.8413\n",
      "[SGD | lr=0.1] Epoch 1946/4000: train_loss=0.0103  test_loss=4.0831  λ_max=63.5431\n",
      "[SGD | lr=0.1] Epoch 1947/4000: train_loss=0.0102  test_loss=4.0833  λ_max=63.7209\n",
      "[SGD | lr=0.1] Epoch 1948/4000: train_loss=0.0102  test_loss=4.0839  λ_max=64.6176\n",
      "[SGD | lr=0.1] Epoch 1949/4000: train_loss=0.0102  test_loss=4.0844  λ_max=61.6207\n",
      "[SGD | lr=0.1] Iter 31200: loss=0.0103\n",
      "[SGD | lr=0.1] Epoch 1950/4000: train_loss=0.0102  test_loss=4.0847  λ_max=65.1673\n",
      "[SGD | lr=0.1] Epoch 1951/4000: train_loss=0.0102  test_loss=4.0851  λ_max=64.2531\n",
      "[SGD | lr=0.1] Epoch 1952/4000: train_loss=0.0102  test_loss=4.0855  λ_max=64.1983\n",
      "[SGD | lr=0.1] Epoch 1953/4000: train_loss=0.0102  test_loss=4.0860  λ_max=65.0348\n",
      "[SGD | lr=0.1] Epoch 1954/4000: train_loss=0.0102  test_loss=4.0862  λ_max=61.7976\n",
      "[SGD | lr=0.1] Epoch 1955/4000: train_loss=0.0102  test_loss=4.0867  λ_max=61.8507\n",
      "[SGD | lr=0.1] Epoch 1956/4000: train_loss=0.0102  test_loss=4.0870  λ_max=64.5537\n",
      "[SGD | lr=0.1] Iter 31300: loss=0.0101\n",
      "[SGD | lr=0.1] Epoch 1957/4000: train_loss=0.0102  test_loss=4.0875  λ_max=64.1607\n",
      "[SGD | lr=0.1] Epoch 1958/4000: train_loss=0.0102  test_loss=4.0877  λ_max=66.2610\n",
      "[SGD | lr=0.1] Epoch 1959/4000: train_loss=0.0102  test_loss=4.0881  λ_max=63.5453\n",
      "[SGD | lr=0.1] Epoch 1960/4000: train_loss=0.0101  test_loss=4.0885  λ_max=65.5998\n",
      "[SGD | lr=0.1] Epoch 1961/4000: train_loss=0.0101  test_loss=4.0892  λ_max=64.4060\n",
      "[SGD | lr=0.1] Epoch 1962/4000: train_loss=0.0101  test_loss=4.0895  λ_max=63.1489\n",
      "[SGD | lr=0.1] Iter 31400: loss=0.0101\n",
      "[SGD | lr=0.1] Epoch 1963/4000: train_loss=0.0101  test_loss=4.0898  λ_max=64.0355\n",
      "[SGD | lr=0.1] Epoch 1964/4000: train_loss=0.0101  test_loss=4.0900  λ_max=65.3822\n",
      "[SGD | lr=0.1] Epoch 1965/4000: train_loss=0.0101  test_loss=4.0905  λ_max=65.2197\n",
      "[SGD | lr=0.1] Epoch 1966/4000: train_loss=0.0101  test_loss=4.0907  λ_max=62.0880\n",
      "[SGD | lr=0.1] Epoch 1967/4000: train_loss=0.0101  test_loss=4.0911  λ_max=62.6322\n",
      "[SGD | lr=0.1] Epoch 1968/4000: train_loss=0.0101  test_loss=4.0916  λ_max=62.7190\n",
      "[SGD | lr=0.1] Iter 31500: loss=0.0101\n",
      "[SGD | lr=0.1] Epoch 1969/4000: train_loss=0.0101  test_loss=4.0920  λ_max=63.3651\n",
      "[SGD | lr=0.1] Epoch 1970/4000: train_loss=0.0101  test_loss=4.0925  λ_max=62.0333\n",
      "[SGD | lr=0.1] Epoch 1971/4000: train_loss=0.0101  test_loss=4.0927  λ_max=64.0045\n",
      "[SGD | lr=0.1] Epoch 1972/4000: train_loss=0.0101  test_loss=4.0931  λ_max=63.7482\n",
      "[SGD | lr=0.1] Epoch 1973/4000: train_loss=0.0101  test_loss=4.0936  λ_max=64.2434\n",
      "[SGD | lr=0.1] Epoch 1974/4000: train_loss=0.0100  test_loss=4.0940  λ_max=62.2162\n",
      "[SGD | lr=0.1] Iter 31600: loss=0.0103\n",
      "[SGD | lr=0.1] Epoch 1975/4000: train_loss=0.0100  test_loss=4.0942  λ_max=63.9001\n",
      "[SGD | lr=0.1] Epoch 1976/4000: train_loss=0.0100  test_loss=4.0947  λ_max=64.9205\n",
      "[SGD | lr=0.1] Epoch 1977/4000: train_loss=0.0100  test_loss=4.0951  λ_max=65.4409\n",
      "[SGD | lr=0.1] Epoch 1978/4000: train_loss=0.0100  test_loss=4.0954  λ_max=64.5969\n",
      "[SGD | lr=0.1] Epoch 1979/4000: train_loss=0.0100  test_loss=4.0958  λ_max=65.6379\n",
      "[SGD | lr=0.1] Epoch 1980/4000: train_loss=0.0100  test_loss=4.0962  λ_max=63.4746\n",
      "[SGD | lr=0.1] Epoch 1981/4000: train_loss=0.0100  test_loss=4.0967  λ_max=63.8917\n",
      "[SGD | lr=0.1] Iter 31700: loss=0.0100\n",
      "[SGD | lr=0.1] Epoch 1982/4000: train_loss=0.0100  test_loss=4.0971  λ_max=64.5482\n",
      "[SGD | lr=0.1] Epoch 1983/4000: train_loss=0.0100  test_loss=4.0974  λ_max=63.4165\n",
      "[SGD | lr=0.1] Epoch 1984/4000: train_loss=0.0100  test_loss=4.0978  λ_max=63.5950\n",
      "[SGD | lr=0.1] Epoch 1985/4000: train_loss=0.0100  test_loss=4.0981  λ_max=65.3593\n",
      "[SGD | lr=0.1] Epoch 1986/4000: train_loss=0.0100  test_loss=4.0984  λ_max=64.5583\n",
      "[SGD | lr=0.1] Epoch 1987/4000: train_loss=0.0100  test_loss=4.0990  λ_max=62.7603\n",
      "[SGD | lr=0.1] Iter 31800: loss=0.0100\n",
      "[SGD | lr=0.1] Epoch 1988/4000: train_loss=0.0099  test_loss=4.0994  λ_max=64.4666\n",
      "[SGD | lr=0.1] Epoch 1989/4000: train_loss=0.0099  test_loss=4.0995  λ_max=61.1455\n",
      "[SGD | lr=0.1] Epoch 1990/4000: train_loss=0.0099  test_loss=4.0999  λ_max=63.4907\n",
      "[SGD | lr=0.1] Epoch 1991/4000: train_loss=0.0099  test_loss=4.1005  λ_max=64.0175\n",
      "[SGD | lr=0.1] Epoch 1992/4000: train_loss=0.0099  test_loss=4.1008  λ_max=64.7218\n",
      "[SGD | lr=0.1] Epoch 1993/4000: train_loss=0.0099  test_loss=4.1012  λ_max=64.1583\n",
      "[SGD | lr=0.1] Iter 31900: loss=0.0098\n",
      "[SGD | lr=0.1] Epoch 1994/4000: train_loss=0.0099  test_loss=4.1014  λ_max=64.4725\n",
      "[SGD | lr=0.1] Epoch 1995/4000: train_loss=0.0099  test_loss=4.1018  λ_max=63.9440\n",
      "[SGD | lr=0.1] Epoch 1996/4000: train_loss=0.0099  test_loss=4.1021  λ_max=63.8912\n",
      "[SGD | lr=0.1] Epoch 1997/4000: train_loss=0.0099  test_loss=4.1025  λ_max=65.4667\n",
      "[SGD | lr=0.1] Epoch 1998/4000: train_loss=0.0099  test_loss=4.1032  λ_max=64.7576\n",
      "[SGD | lr=0.1] Epoch 1999/4000: train_loss=0.0099  test_loss=4.1034  λ_max=64.1099\n",
      "[SGD | lr=0.1] Iter 32000: loss=0.0096\n",
      "[SGD | lr=0.1] Epoch 2000/4000: train_loss=0.0099  test_loss=4.1037  λ_max=64.7529\n",
      "[SGD | lr=0.1] Epoch 2001/4000: train_loss=0.0098  test_loss=4.1041  λ_max=65.4194\n",
      "[SGD | lr=0.1] Epoch 2002/4000: train_loss=0.0098  test_loss=4.1044  λ_max=64.2919\n",
      "[SGD | lr=0.1] Epoch 2003/4000: train_loss=0.0098  test_loss=4.1050  λ_max=65.3968\n",
      "[SGD | lr=0.1] Epoch 2004/4000: train_loss=0.0098  test_loss=4.1052  λ_max=64.5270\n",
      "[SGD | lr=0.1] Epoch 2005/4000: train_loss=0.0098  test_loss=4.1057  λ_max=65.6200\n",
      "[SGD | lr=0.1] Epoch 2006/4000: train_loss=0.0098  test_loss=4.1057  λ_max=63.9611\n",
      "[SGD | lr=0.1] Iter 32100: loss=0.0098\n",
      "[SGD | lr=0.1] Epoch 2007/4000: train_loss=0.0098  test_loss=4.1064  λ_max=63.3170\n",
      "[SGD | lr=0.1] Epoch 2008/4000: train_loss=0.0098  test_loss=4.1070  λ_max=65.3237\n",
      "[SGD | lr=0.1] Epoch 2009/4000: train_loss=0.0098  test_loss=4.1073  λ_max=64.0139\n",
      "[SGD | lr=0.1] Epoch 2010/4000: train_loss=0.0098  test_loss=4.1075  λ_max=64.0244\n",
      "[SGD | lr=0.1] Epoch 2011/4000: train_loss=0.0098  test_loss=4.1079  λ_max=65.5771\n",
      "[SGD | lr=0.1] Epoch 2012/4000: train_loss=0.0098  test_loss=4.1083  λ_max=62.6467\n",
      "[SGD | lr=0.1] Iter 32200: loss=0.0097\n",
      "[SGD | lr=0.1] Epoch 2013/4000: train_loss=0.0098  test_loss=4.1087  λ_max=66.5407\n",
      "[SGD | lr=0.1] Epoch 2014/4000: train_loss=0.0098  test_loss=4.1090  λ_max=66.0946\n",
      "[SGD | lr=0.1] Epoch 2015/4000: train_loss=0.0098  test_loss=4.1094  λ_max=65.0916\n",
      "[SGD | lr=0.1] Epoch 2016/4000: train_loss=0.0098  test_loss=4.1096  λ_max=62.9091\n",
      "[SGD | lr=0.1] Epoch 2017/4000: train_loss=0.0097  test_loss=4.1103  λ_max=65.5214\n",
      "[SGD | lr=0.1] Epoch 2018/4000: train_loss=0.0097  test_loss=4.1105  λ_max=63.7681\n",
      "[SGD | lr=0.1] Iter 32300: loss=0.0099\n",
      "[SGD | lr=0.1] Epoch 2019/4000: train_loss=0.0097  test_loss=4.1107  λ_max=62.4115\n",
      "[SGD | lr=0.1] Epoch 2020/4000: train_loss=0.0097  test_loss=4.1112  λ_max=63.6428\n",
      "[SGD | lr=0.1] Epoch 2021/4000: train_loss=0.0097  test_loss=4.1116  λ_max=65.6433\n",
      "[SGD | lr=0.1] Epoch 2022/4000: train_loss=0.0097  test_loss=4.1120  λ_max=62.5361\n",
      "[SGD | lr=0.1] Epoch 2023/4000: train_loss=0.0097  test_loss=4.1124  λ_max=65.6372\n",
      "[SGD | lr=0.1] Epoch 2024/4000: train_loss=0.0097  test_loss=4.1127  λ_max=66.0081\n",
      "[SGD | lr=0.1] Iter 32400: loss=0.0098\n",
      "[SGD | lr=0.1] Epoch 2025/4000: train_loss=0.0097  test_loss=4.1131  λ_max=63.6248\n",
      "[SGD | lr=0.1] Epoch 2026/4000: train_loss=0.0097  test_loss=4.1134  λ_max=62.3639\n",
      "[SGD | lr=0.1] Epoch 2027/4000: train_loss=0.0097  test_loss=4.1138  λ_max=64.9407\n",
      "[SGD | lr=0.1] Epoch 2028/4000: train_loss=0.0097  test_loss=4.1142  λ_max=63.5352\n",
      "[SGD | lr=0.1] Epoch 2029/4000: train_loss=0.0097  test_loss=4.1144  λ_max=64.8026\n",
      "[SGD | lr=0.1] Epoch 2030/4000: train_loss=0.0097  test_loss=4.1148  λ_max=65.1232\n",
      "[SGD | lr=0.1] Epoch 2031/4000: train_loss=0.0096  test_loss=4.1152  λ_max=63.7447\n",
      "[SGD | lr=0.1] Iter 32500: loss=0.0098\n",
      "[SGD | lr=0.1] Epoch 2032/4000: train_loss=0.0096  test_loss=4.1156  λ_max=63.6079\n",
      "[SGD | lr=0.1] Epoch 2033/4000: train_loss=0.0096  test_loss=4.1161  λ_max=64.6666\n",
      "[SGD | lr=0.1] Epoch 2034/4000: train_loss=0.0096  test_loss=4.1163  λ_max=62.7938\n",
      "[SGD | lr=0.1] Epoch 2035/4000: train_loss=0.0096  test_loss=4.1166  λ_max=65.8575\n",
      "[SGD | lr=0.1] Epoch 2036/4000: train_loss=0.0096  test_loss=4.1173  λ_max=64.1122\n",
      "[SGD | lr=0.1] Epoch 2037/4000: train_loss=0.0096  test_loss=4.1174  λ_max=65.9294\n",
      "[SGD | lr=0.1] Iter 32600: loss=0.0096\n",
      "[SGD | lr=0.1] Epoch 2038/4000: train_loss=0.0096  test_loss=4.1178  λ_max=65.1400\n",
      "[SGD | lr=0.1] Epoch 2039/4000: train_loss=0.0096  test_loss=4.1180  λ_max=65.0998\n",
      "[SGD | lr=0.1] Epoch 2040/4000: train_loss=0.0096  test_loss=4.1186  λ_max=62.9149\n",
      "[SGD | lr=0.1] Epoch 2041/4000: train_loss=0.0096  test_loss=4.1189  λ_max=66.2805\n",
      "[SGD | lr=0.1] Epoch 2042/4000: train_loss=0.0096  test_loss=4.1193  λ_max=64.7910\n",
      "[SGD | lr=0.1] Epoch 2043/4000: train_loss=0.0096  test_loss=4.1198  λ_max=64.2503\n",
      "[SGD | lr=0.1] Iter 32700: loss=0.0097\n",
      "[SGD | lr=0.1] Epoch 2044/4000: train_loss=0.0096  test_loss=4.1200  λ_max=65.8373\n",
      "[SGD | lr=0.1] Epoch 2045/4000: train_loss=0.0096  test_loss=4.1205  λ_max=63.1917\n",
      "[SGD | lr=0.1] Epoch 2046/4000: train_loss=0.0095  test_loss=4.1205  λ_max=64.8012\n",
      "[SGD | lr=0.1] Epoch 2047/4000: train_loss=0.0095  test_loss=4.1211  λ_max=64.4170\n",
      "[SGD | lr=0.1] Epoch 2048/4000: train_loss=0.0095  test_loss=4.1214  λ_max=63.7085\n",
      "[SGD | lr=0.1] Epoch 2049/4000: train_loss=0.0095  test_loss=4.1219  λ_max=65.5574\n",
      "[SGD | lr=0.1] Iter 32800: loss=0.0097\n",
      "[SGD | lr=0.1] Epoch 2050/4000: train_loss=0.0095  test_loss=4.1221  λ_max=65.4796\n",
      "[SGD | lr=0.1] Epoch 2051/4000: train_loss=0.0095  test_loss=4.1226  λ_max=64.8575\n",
      "[SGD | lr=0.1] Epoch 2052/4000: train_loss=0.0095  test_loss=4.1229  λ_max=64.2945\n",
      "[SGD | lr=0.1] Epoch 2053/4000: train_loss=0.0095  test_loss=4.1233  λ_max=64.3861\n",
      "[SGD | lr=0.1] Epoch 2054/4000: train_loss=0.0095  test_loss=4.1234  λ_max=65.6510\n",
      "[SGD | lr=0.1] Epoch 2055/4000: train_loss=0.0095  test_loss=4.1240  λ_max=64.8852\n",
      "[SGD | lr=0.1] Epoch 2056/4000: train_loss=0.0095  test_loss=4.1244  λ_max=64.7886\n",
      "[SGD | lr=0.1] Iter 32900: loss=0.0094\n",
      "[SGD | lr=0.1] Epoch 2057/4000: train_loss=0.0095  test_loss=4.1246  λ_max=64.1456\n",
      "[SGD | lr=0.1] Epoch 2058/4000: train_loss=0.0095  test_loss=4.1251  λ_max=64.4297\n",
      "[SGD | lr=0.1] Epoch 2059/4000: train_loss=0.0095  test_loss=4.1254  λ_max=63.3085\n",
      "[SGD | lr=0.1] Epoch 2060/4000: train_loss=0.0095  test_loss=4.1259  λ_max=64.3746\n",
      "[SGD | lr=0.1] Epoch 2061/4000: train_loss=0.0095  test_loss=4.1261  λ_max=66.4019\n",
      "[SGD | lr=0.1] Epoch 2062/4000: train_loss=0.0094  test_loss=4.1266  λ_max=64.8597\n",
      "[SGD | lr=0.1] Iter 33000: loss=0.0097\n",
      "[SGD | lr=0.1] Epoch 2063/4000: train_loss=0.0094  test_loss=4.1269  λ_max=65.7324\n",
      "[SGD | lr=0.1] Epoch 2064/4000: train_loss=0.0094  test_loss=4.1273  λ_max=65.6796\n",
      "[SGD | lr=0.1] Epoch 2065/4000: train_loss=0.0094  test_loss=4.1275  λ_max=65.8118\n",
      "[SGD | lr=0.1] Epoch 2066/4000: train_loss=0.0094  test_loss=4.1281  λ_max=64.7905\n",
      "[SGD | lr=0.1] Epoch 2067/4000: train_loss=0.0094  test_loss=4.1282  λ_max=65.6930\n",
      "[SGD | lr=0.1] Epoch 2068/4000: train_loss=0.0094  test_loss=4.1289  λ_max=66.1546\n",
      "[SGD | lr=0.1] Iter 33100: loss=0.0095\n",
      "[SGD | lr=0.1] Epoch 2069/4000: train_loss=0.0094  test_loss=4.1292  λ_max=64.5828\n",
      "[SGD | lr=0.1] Epoch 2070/4000: train_loss=0.0094  test_loss=4.1295  λ_max=64.0640\n",
      "[SGD | lr=0.1] Epoch 2071/4000: train_loss=0.0094  test_loss=4.1298  λ_max=65.5412\n",
      "[SGD | lr=0.1] Epoch 2072/4000: train_loss=0.0094  test_loss=4.1301  λ_max=64.1494\n",
      "[SGD | lr=0.1] Epoch 2073/4000: train_loss=0.0094  test_loss=4.1305  λ_max=65.8178\n",
      "[SGD | lr=0.1] Epoch 2074/4000: train_loss=0.0094  test_loss=4.1310  λ_max=65.4596\n",
      "[SGD | lr=0.1] Iter 33200: loss=0.0096\n",
      "[SGD | lr=0.1] Epoch 2075/4000: train_loss=0.0094  test_loss=4.1312  λ_max=66.3407\n",
      "[SGD | lr=0.1] Epoch 2076/4000: train_loss=0.0094  test_loss=4.1316  λ_max=63.8972\n",
      "[SGD | lr=0.1] Epoch 2077/4000: train_loss=0.0094  test_loss=4.1321  λ_max=66.0062\n",
      "[SGD | lr=0.1] Epoch 2078/4000: train_loss=0.0093  test_loss=4.1323  λ_max=66.0966\n",
      "[SGD | lr=0.1] Epoch 2079/4000: train_loss=0.0093  test_loss=4.1324  λ_max=65.4930\n",
      "[SGD | lr=0.1] Epoch 2080/4000: train_loss=0.0093  test_loss=4.1331  λ_max=64.9110\n",
      "[SGD | lr=0.1] Epoch 2081/4000: train_loss=0.0093  test_loss=4.1333  λ_max=64.9287\n",
      "[SGD | lr=0.1] Iter 33300: loss=0.0093\n",
      "[SGD | lr=0.1] Epoch 2082/4000: train_loss=0.0093  test_loss=4.1338  λ_max=64.2524\n",
      "[SGD | lr=0.1] Epoch 2083/4000: train_loss=0.0093  test_loss=4.1341  λ_max=66.0142\n",
      "[SGD | lr=0.1] Epoch 2084/4000: train_loss=0.0093  test_loss=4.1346  λ_max=64.2754\n",
      "[SGD | lr=0.1] Epoch 2085/4000: train_loss=0.0093  test_loss=4.1349  λ_max=65.5799\n",
      "[SGD | lr=0.1] Epoch 2086/4000: train_loss=0.0093  test_loss=4.1353  λ_max=66.0467\n",
      "[SGD | lr=0.1] Epoch 2087/4000: train_loss=0.0093  test_loss=4.1353  λ_max=63.4018\n",
      "[SGD | lr=0.1] Iter 33400: loss=0.0094\n",
      "[SGD | lr=0.1] Epoch 2088/4000: train_loss=0.0093  test_loss=4.1358  λ_max=64.3062\n",
      "[SGD | lr=0.1] Epoch 2089/4000: train_loss=0.0093  test_loss=4.1362  λ_max=63.8349\n",
      "[SGD | lr=0.1] Epoch 2090/4000: train_loss=0.0093  test_loss=4.1366  λ_max=64.8009\n",
      "[SGD | lr=0.1] Epoch 2091/4000: train_loss=0.0093  test_loss=4.1371  λ_max=66.3940\n",
      "[SGD | lr=0.1] Epoch 2092/4000: train_loss=0.0093  test_loss=4.1370  λ_max=65.3123\n",
      "[SGD | lr=0.1] Epoch 2093/4000: train_loss=0.0093  test_loss=4.1378  λ_max=65.8823\n",
      "[SGD | lr=0.1] Iter 33500: loss=0.0093\n",
      "[SGD | lr=0.1] Epoch 2094/4000: train_loss=0.0092  test_loss=4.1379  λ_max=65.8050\n",
      "[SGD | lr=0.1] Epoch 2095/4000: train_loss=0.0092  test_loss=4.1383  λ_max=64.5722\n",
      "[SGD | lr=0.1] Epoch 2096/4000: train_loss=0.0092  test_loss=4.1387  λ_max=65.2333\n",
      "[SGD | lr=0.1] Epoch 2097/4000: train_loss=0.0092  test_loss=4.1391  λ_max=65.2670\n",
      "[SGD | lr=0.1] Epoch 2098/4000: train_loss=0.0092  test_loss=4.1394  λ_max=66.3411\n",
      "[SGD | lr=0.1] Epoch 2099/4000: train_loss=0.0092  test_loss=4.1397  λ_max=66.3167\n",
      "[SGD | lr=0.1] Iter 33600: loss=0.0093\n",
      "[SGD | lr=0.1] Epoch 2100/4000: train_loss=0.0092  test_loss=4.1400  λ_max=65.8907\n",
      "[SGD | lr=0.1] Epoch 2101/4000: train_loss=0.0092  test_loss=4.1405  λ_max=65.3730\n",
      "[SGD | lr=0.1] Epoch 2102/4000: train_loss=0.0092  test_loss=4.1410  λ_max=66.0527\n",
      "[SGD | lr=0.1] Epoch 2103/4000: train_loss=0.0092  test_loss=4.1410  λ_max=63.6614\n",
      "[SGD | lr=0.1] Epoch 2104/4000: train_loss=0.0092  test_loss=4.1415  λ_max=65.6194\n",
      "[SGD | lr=0.1] Epoch 2105/4000: train_loss=0.0092  test_loss=4.1418  λ_max=67.6067\n",
      "[SGD | lr=0.1] Epoch 2106/4000: train_loss=0.0092  test_loss=4.1422  λ_max=64.2634\n",
      "[SGD | lr=0.1] Iter 33700: loss=0.0091\n",
      "[SGD | lr=0.1] Epoch 2107/4000: train_loss=0.0092  test_loss=4.1425  λ_max=65.9234\n",
      "[SGD | lr=0.1] Epoch 2108/4000: train_loss=0.0092  test_loss=4.1429  λ_max=68.1257\n",
      "[SGD | lr=0.1] Epoch 2109/4000: train_loss=0.0092  test_loss=4.1433  λ_max=66.5247\n",
      "[SGD | lr=0.1] Epoch 2110/4000: train_loss=0.0091  test_loss=4.1436  λ_max=65.0439\n",
      "[SGD | lr=0.1] Epoch 2111/4000: train_loss=0.0091  test_loss=4.1439  λ_max=67.0089\n",
      "[SGD | lr=0.1] Epoch 2112/4000: train_loss=0.0091  test_loss=4.1443  λ_max=67.1658\n",
      "[SGD | lr=0.1] Iter 33800: loss=0.0090\n",
      "[SGD | lr=0.1] Epoch 2113/4000: train_loss=0.0091  test_loss=4.1447  λ_max=64.8005\n",
      "[SGD | lr=0.1] Epoch 2114/4000: train_loss=0.0091  test_loss=4.1451  λ_max=65.3779\n",
      "[SGD | lr=0.1] Epoch 2115/4000: train_loss=0.0091  test_loss=4.1454  λ_max=66.4310\n",
      "[SGD | lr=0.1] Epoch 2116/4000: train_loss=0.0091  test_loss=4.1457  λ_max=63.8316\n",
      "[SGD | lr=0.1] Epoch 2117/4000: train_loss=0.0091  test_loss=4.1462  λ_max=64.9502\n",
      "[SGD | lr=0.1] Epoch 2118/4000: train_loss=0.0091  test_loss=4.1465  λ_max=65.1720\n",
      "[SGD | lr=0.1] Iter 33900: loss=0.0092\n",
      "[SGD | lr=0.1] Epoch 2119/4000: train_loss=0.0091  test_loss=4.1466  λ_max=67.5412\n",
      "[SGD | lr=0.1] Epoch 2120/4000: train_loss=0.0091  test_loss=4.1469  λ_max=66.8280\n",
      "[SGD | lr=0.1] Epoch 2121/4000: train_loss=0.0091  test_loss=4.1475  λ_max=64.9461\n",
      "[SGD | lr=0.1] Epoch 2122/4000: train_loss=0.0091  test_loss=4.1478  λ_max=65.1754\n",
      "[SGD | lr=0.1] Epoch 2123/4000: train_loss=0.0091  test_loss=4.1481  λ_max=66.0090\n",
      "[SGD | lr=0.1] Epoch 2124/4000: train_loss=0.0091  test_loss=4.1487  λ_max=62.9832\n",
      "[SGD | lr=0.1] Iter 34000: loss=0.0093\n",
      "[SGD | lr=0.1] Epoch 2125/4000: train_loss=0.0091  test_loss=4.1491  λ_max=66.1634\n",
      "[SGD | lr=0.1] Epoch 2126/4000: train_loss=0.0091  test_loss=4.1493  λ_max=63.6242\n",
      "[SGD | lr=0.1] Epoch 2127/4000: train_loss=0.0090  test_loss=4.1497  λ_max=66.1740\n",
      "[SGD | lr=0.1] Epoch 2128/4000: train_loss=0.0090  test_loss=4.1500  λ_max=66.3152\n",
      "[SGD | lr=0.1] Epoch 2129/4000: train_loss=0.0090  test_loss=4.1503  λ_max=66.3458\n",
      "[SGD | lr=0.1] Epoch 2130/4000: train_loss=0.0090  test_loss=4.1508  λ_max=65.2435\n",
      "[SGD | lr=0.1] Epoch 2131/4000: train_loss=0.0090  test_loss=4.1511  λ_max=65.3122\n",
      "[SGD | lr=0.1] Iter 34100: loss=0.0090\n",
      "[SGD | lr=0.1] Epoch 2132/4000: train_loss=0.0090  test_loss=4.1512  λ_max=66.3404\n",
      "[SGD | lr=0.1] Epoch 2133/4000: train_loss=0.0090  test_loss=4.1516  λ_max=66.0386\n",
      "[SGD | lr=0.1] Epoch 2134/4000: train_loss=0.0090  test_loss=4.1520  λ_max=66.6966\n",
      "[SGD | lr=0.1] Epoch 2135/4000: train_loss=0.0090  test_loss=4.1526  λ_max=67.4082\n",
      "[SGD | lr=0.1] Epoch 2136/4000: train_loss=0.0090  test_loss=4.1528  λ_max=63.6600\n",
      "[SGD | lr=0.1] Epoch 2137/4000: train_loss=0.0090  test_loss=4.1531  λ_max=68.4003\n",
      "[SGD | lr=0.1] Iter 34200: loss=0.0091\n",
      "[SGD | lr=0.1] Epoch 2138/4000: train_loss=0.0090  test_loss=4.1535  λ_max=66.1158\n",
      "[SGD | lr=0.1] Epoch 2139/4000: train_loss=0.0090  test_loss=4.1539  λ_max=66.6007\n",
      "[SGD | lr=0.1] Epoch 2140/4000: train_loss=0.0090  test_loss=4.1541  λ_max=64.2188\n",
      "[SGD | lr=0.1] Epoch 2141/4000: train_loss=0.0090  test_loss=4.1545  λ_max=66.9983\n",
      "[SGD | lr=0.1] Epoch 2142/4000: train_loss=0.0090  test_loss=4.1548  λ_max=66.5122\n",
      "[SGD | lr=0.1] Epoch 2143/4000: train_loss=0.0090  test_loss=4.1552  λ_max=66.3502\n",
      "[SGD | lr=0.1] Iter 34300: loss=0.0089\n",
      "[SGD | lr=0.1] Epoch 2144/4000: train_loss=0.0089  test_loss=4.1556  λ_max=66.0318\n",
      "[SGD | lr=0.1] Epoch 2145/4000: train_loss=0.0089  test_loss=4.1559  λ_max=65.5177\n",
      "[SGD | lr=0.1] Epoch 2146/4000: train_loss=0.0089  test_loss=4.1562  λ_max=65.8747\n",
      "[SGD | lr=0.1] Epoch 2147/4000: train_loss=0.0089  test_loss=4.1565  λ_max=65.4662\n",
      "[SGD | lr=0.1] Epoch 2148/4000: train_loss=0.0089  test_loss=4.1570  λ_max=64.0081\n",
      "[SGD | lr=0.1] Epoch 2149/4000: train_loss=0.0089  test_loss=4.1571  λ_max=65.0243\n",
      "[SGD | lr=0.1] Iter 34400: loss=0.0089\n",
      "[SGD | lr=0.1] Epoch 2150/4000: train_loss=0.0089  test_loss=4.1576  λ_max=66.2228\n",
      "[SGD | lr=0.1] Epoch 2151/4000: train_loss=0.0089  test_loss=4.1578  λ_max=66.7259\n",
      "[SGD | lr=0.1] Epoch 2152/4000: train_loss=0.0089  test_loss=4.1584  λ_max=64.5640\n",
      "[SGD | lr=0.1] Epoch 2153/4000: train_loss=0.0089  test_loss=4.1586  λ_max=65.5341\n",
      "[SGD | lr=0.1] Epoch 2154/4000: train_loss=0.0089  test_loss=4.1590  λ_max=65.8316\n",
      "[SGD | lr=0.1] Epoch 2155/4000: train_loss=0.0089  test_loss=4.1592  λ_max=66.5763\n",
      "[SGD | lr=0.1] Epoch 2156/4000: train_loss=0.0089  test_loss=4.1596  λ_max=65.7844\n",
      "[SGD | lr=0.1] Iter 34500: loss=0.0088\n",
      "[SGD | lr=0.1] Epoch 2157/4000: train_loss=0.0089  test_loss=4.1599  λ_max=67.5490\n",
      "[SGD | lr=0.1] Epoch 2158/4000: train_loss=0.0089  test_loss=4.1604  λ_max=67.4710\n",
      "[SGD | lr=0.1] Epoch 2159/4000: train_loss=0.0089  test_loss=4.1607  λ_max=64.2644\n",
      "[SGD | lr=0.1] Epoch 2160/4000: train_loss=0.0089  test_loss=4.1610  λ_max=66.7028\n",
      "[SGD | lr=0.1] Epoch 2161/4000: train_loss=0.0089  test_loss=4.1613  λ_max=65.5839\n",
      "[SGD | lr=0.1] Epoch 2162/4000: train_loss=0.0088  test_loss=4.1617  λ_max=67.9860\n",
      "[SGD | lr=0.1] Iter 34600: loss=0.0089\n",
      "[SGD | lr=0.1] Epoch 2163/4000: train_loss=0.0088  test_loss=4.1620  λ_max=65.5188\n",
      "[SGD | lr=0.1] Epoch 2164/4000: train_loss=0.0088  test_loss=4.1625  λ_max=66.1111\n",
      "[SGD | lr=0.1] Epoch 2165/4000: train_loss=0.0088  test_loss=4.1627  λ_max=65.2682\n",
      "[SGD | lr=0.1] Epoch 2166/4000: train_loss=0.0088  test_loss=4.1631  λ_max=64.9179\n",
      "[SGD | lr=0.1] Epoch 2167/4000: train_loss=0.0088  test_loss=4.1636  λ_max=65.4740\n",
      "[SGD | lr=0.1] Epoch 2168/4000: train_loss=0.0088  test_loss=4.1637  λ_max=66.7024\n",
      "[SGD | lr=0.1] Iter 34700: loss=0.0088\n",
      "[SGD | lr=0.1] Epoch 2169/4000: train_loss=0.0088  test_loss=4.1642  λ_max=66.2263\n",
      "[SGD | lr=0.1] Epoch 2170/4000: train_loss=0.0088  test_loss=4.1645  λ_max=66.7032\n",
      "[SGD | lr=0.1] Epoch 2171/4000: train_loss=0.0088  test_loss=4.1648  λ_max=65.8915\n",
      "[SGD | lr=0.1] Epoch 2172/4000: train_loss=0.0088  test_loss=4.1651  λ_max=65.3795\n",
      "[SGD | lr=0.1] Epoch 2173/4000: train_loss=0.0088  test_loss=4.1654  λ_max=66.7820\n",
      "[SGD | lr=0.1] Epoch 2174/4000: train_loss=0.0088  test_loss=4.1659  λ_max=67.3335\n",
      "[SGD | lr=0.1] Iter 34800: loss=0.0086\n",
      "[SGD | lr=0.1] Epoch 2175/4000: train_loss=0.0088  test_loss=4.1662  λ_max=66.5686\n",
      "[SGD | lr=0.1] Epoch 2176/4000: train_loss=0.0088  test_loss=4.1664  λ_max=64.4444\n",
      "[SGD | lr=0.1] Epoch 2177/4000: train_loss=0.0088  test_loss=4.1669  λ_max=67.1768\n",
      "[SGD | lr=0.1] Epoch 2178/4000: train_loss=0.0088  test_loss=4.1671  λ_max=68.1107\n",
      "[SGD | lr=0.1] Epoch 2179/4000: train_loss=0.0088  test_loss=4.1675  λ_max=66.7985\n",
      "[SGD | lr=0.1] Epoch 2180/4000: train_loss=0.0087  test_loss=4.1678  λ_max=68.3865\n",
      "[SGD | lr=0.1] Epoch 2181/4000: train_loss=0.0087  test_loss=4.1683  λ_max=65.7636\n",
      "[SGD | lr=0.1] Iter 34900: loss=0.0087\n",
      "[SGD | lr=0.1] Epoch 2182/4000: train_loss=0.0087  test_loss=4.1687  λ_max=65.8720\n",
      "[SGD | lr=0.1] Epoch 2183/4000: train_loss=0.0087  test_loss=4.1687  λ_max=64.2874\n",
      "[SGD | lr=0.1] Epoch 2184/4000: train_loss=0.0087  test_loss=4.1692  λ_max=65.9314\n",
      "[SGD | lr=0.1] Epoch 2185/4000: train_loss=0.0087  test_loss=4.1696  λ_max=65.8602\n",
      "[SGD | lr=0.1] Epoch 2186/4000: train_loss=0.0087  test_loss=4.1698  λ_max=65.7255\n",
      "[SGD | lr=0.1] Epoch 2187/4000: train_loss=0.0087  test_loss=4.1701  λ_max=65.5165\n",
      "[SGD | lr=0.1] Iter 35000: loss=0.0088\n",
      "[SGD | lr=0.1] Epoch 2188/4000: train_loss=0.0087  test_loss=4.1706  λ_max=66.5146\n",
      "[SGD | lr=0.1] Epoch 2189/4000: train_loss=0.0087  test_loss=4.1709  λ_max=65.3127\n",
      "[SGD | lr=0.1] Epoch 2190/4000: train_loss=0.0087  test_loss=4.1712  λ_max=66.5176\n",
      "[SGD | lr=0.1] Epoch 2191/4000: train_loss=0.0087  test_loss=4.1714  λ_max=66.3997\n",
      "[SGD | lr=0.1] Epoch 2192/4000: train_loss=0.0087  test_loss=4.1719  λ_max=66.2145\n",
      "[SGD | lr=0.1] Epoch 2193/4000: train_loss=0.0087  test_loss=4.1721  λ_max=66.3091\n",
      "[SGD | lr=0.1] Iter 35100: loss=0.0087\n",
      "[SGD | lr=0.1] Epoch 2194/4000: train_loss=0.0087  test_loss=4.1726  λ_max=66.0743\n",
      "[SGD | lr=0.1] Epoch 2195/4000: train_loss=0.0087  test_loss=4.1728  λ_max=66.7302\n",
      "[SGD | lr=0.1] Epoch 2196/4000: train_loss=0.0087  test_loss=4.1733  λ_max=65.7867\n",
      "[SGD | lr=0.1] Epoch 2197/4000: train_loss=0.0087  test_loss=4.1736  λ_max=67.6589\n",
      "[SGD | lr=0.1] Epoch 2198/4000: train_loss=0.0086  test_loss=4.1739  λ_max=65.5316\n",
      "[SGD | lr=0.1] Epoch 2199/4000: train_loss=0.0086  test_loss=4.1740  λ_max=66.2578\n",
      "[SGD | lr=0.1] Iter 35200: loss=0.0086\n",
      "[SGD | lr=0.1] Epoch 2200/4000: train_loss=0.0086  test_loss=4.1744  λ_max=65.7689\n",
      "[SGD | lr=0.1] Epoch 2201/4000: train_loss=0.0086  test_loss=4.1748  λ_max=65.6079\n",
      "[SGD | lr=0.1] Epoch 2202/4000: train_loss=0.0086  test_loss=4.1752  λ_max=64.1933\n",
      "[SGD | lr=0.1] Epoch 2203/4000: train_loss=0.0086  test_loss=4.1755  λ_max=67.8889\n",
      "[SGD | lr=0.1] Epoch 2204/4000: train_loss=0.0086  test_loss=4.1759  λ_max=66.2884\n",
      "[SGD | lr=0.1] Epoch 2205/4000: train_loss=0.0086  test_loss=4.1762  λ_max=66.7328\n",
      "[SGD | lr=0.1] Epoch 2206/4000: train_loss=0.0086  test_loss=4.1766  λ_max=63.9040\n",
      "[SGD | lr=0.1] Iter 35300: loss=0.0086\n",
      "[SGD | lr=0.1] Epoch 2207/4000: train_loss=0.0086  test_loss=4.1768  λ_max=65.9440\n",
      "[SGD | lr=0.1] Epoch 2208/4000: train_loss=0.0086  test_loss=4.1774  λ_max=67.0398\n",
      "[SGD | lr=0.1] Epoch 2209/4000: train_loss=0.0086  test_loss=4.1777  λ_max=66.9364\n",
      "[SGD | lr=0.1] Epoch 2210/4000: train_loss=0.0086  test_loss=4.1778  λ_max=68.2060\n",
      "[SGD | lr=0.1] Epoch 2211/4000: train_loss=0.0086  test_loss=4.1782  λ_max=66.6276\n",
      "[SGD | lr=0.1] Epoch 2212/4000: train_loss=0.0086  test_loss=4.1785  λ_max=66.7925\n",
      "[SGD | lr=0.1] Iter 35400: loss=0.0087\n",
      "[SGD | lr=0.1] Epoch 2213/4000: train_loss=0.0086  test_loss=4.1790  λ_max=66.4698\n",
      "[SGD | lr=0.1] Epoch 2214/4000: train_loss=0.0086  test_loss=4.1794  λ_max=65.7390\n",
      "[SGD | lr=0.1] Epoch 2215/4000: train_loss=0.0086  test_loss=4.1794  λ_max=66.9422\n",
      "[SGD | lr=0.1] Epoch 2216/4000: train_loss=0.0085  test_loss=4.1801  λ_max=67.9698\n",
      "[SGD | lr=0.1] Epoch 2217/4000: train_loss=0.0085  test_loss=4.1802  λ_max=65.7076\n",
      "[SGD | lr=0.1] Epoch 2218/4000: train_loss=0.0085  test_loss=4.1804  λ_max=66.7467\n",
      "[SGD | lr=0.1] Iter 35500: loss=0.0085\n",
      "[SGD | lr=0.1] Epoch 2219/4000: train_loss=0.0085  test_loss=4.1810  λ_max=66.0616\n",
      "[SGD | lr=0.1] Epoch 2220/4000: train_loss=0.0085  test_loss=4.1811  λ_max=65.2622\n",
      "[SGD | lr=0.1] Epoch 2221/4000: train_loss=0.0085  test_loss=4.1816  λ_max=66.2816\n",
      "[SGD | lr=0.1] Epoch 2222/4000: train_loss=0.0085  test_loss=4.1819  λ_max=66.2066\n",
      "[SGD | lr=0.1] Epoch 2223/4000: train_loss=0.0085  test_loss=4.1823  λ_max=68.1774\n",
      "[SGD | lr=0.1] Epoch 2224/4000: train_loss=0.0085  test_loss=4.1826  λ_max=64.8337\n",
      "[SGD | lr=0.1] Iter 35600: loss=0.0088\n",
      "[SGD | lr=0.1] Epoch 2225/4000: train_loss=0.0085  test_loss=4.1827  λ_max=66.2895\n",
      "[SGD | lr=0.1] Epoch 2226/4000: train_loss=0.0085  test_loss=4.1831  λ_max=65.9525\n",
      "[SGD | lr=0.1] Epoch 2227/4000: train_loss=0.0085  test_loss=4.1837  λ_max=64.5468\n",
      "[SGD | lr=0.1] Epoch 2228/4000: train_loss=0.0085  test_loss=4.1838  λ_max=67.5519\n",
      "[SGD | lr=0.1] Epoch 2229/4000: train_loss=0.0085  test_loss=4.1842  λ_max=67.8303\n",
      "[SGD | lr=0.1] Epoch 2230/4000: train_loss=0.0085  test_loss=4.1844  λ_max=65.1585\n",
      "[SGD | lr=0.1] Epoch 2231/4000: train_loss=0.0085  test_loss=4.1849  λ_max=66.2761\n",
      "[SGD | lr=0.1] Iter 35700: loss=0.0084\n",
      "[SGD | lr=0.1] Epoch 2232/4000: train_loss=0.0085  test_loss=4.1852  λ_max=66.6846\n",
      "[SGD | lr=0.1] Epoch 2233/4000: train_loss=0.0085  test_loss=4.1855  λ_max=66.3146\n",
      "[SGD | lr=0.1] Epoch 2234/4000: train_loss=0.0085  test_loss=4.1859  λ_max=67.3130\n",
      "[SGD | lr=0.1] Epoch 2235/4000: train_loss=0.0084  test_loss=4.1863  λ_max=66.3283\n",
      "[SGD | lr=0.1] Epoch 2236/4000: train_loss=0.0084  test_loss=4.1865  λ_max=67.7986\n",
      "[SGD | lr=0.1] Epoch 2237/4000: train_loss=0.0084  test_loss=4.1868  λ_max=66.5361\n",
      "[SGD | lr=0.1] Iter 35800: loss=0.0084\n",
      "[SGD | lr=0.1] Epoch 2238/4000: train_loss=0.0084  test_loss=4.1872  λ_max=65.5617\n",
      "[SGD | lr=0.1] Epoch 2239/4000: train_loss=0.0084  test_loss=4.1876  λ_max=67.9717\n",
      "[SGD | lr=0.1] Epoch 2240/4000: train_loss=0.0084  test_loss=4.1878  λ_max=67.2943\n",
      "[SGD | lr=0.1] Epoch 2241/4000: train_loss=0.0084  test_loss=4.1884  λ_max=66.6078\n",
      "[SGD | lr=0.1] Epoch 2242/4000: train_loss=0.0084  test_loss=4.1886  λ_max=65.2508\n",
      "[SGD | lr=0.1] Epoch 2243/4000: train_loss=0.0084  test_loss=4.1890  λ_max=65.0494\n",
      "[SGD | lr=0.1] Iter 35900: loss=0.0084\n",
      "[SGD | lr=0.1] Epoch 2244/4000: train_loss=0.0084  test_loss=4.1894  λ_max=66.5191\n",
      "[SGD | lr=0.1] Epoch 2245/4000: train_loss=0.0084  test_loss=4.1895  λ_max=67.4719\n",
      "[SGD | lr=0.1] Epoch 2246/4000: train_loss=0.0084  test_loss=4.1898  λ_max=66.2935\n",
      "[SGD | lr=0.1] Epoch 2247/4000: train_loss=0.0084  test_loss=4.1902  λ_max=65.5947\n",
      "[SGD | lr=0.1] Epoch 2248/4000: train_loss=0.0084  test_loss=4.1904  λ_max=67.0384\n",
      "[SGD | lr=0.1] Epoch 2249/4000: train_loss=0.0084  test_loss=4.1907  λ_max=65.0157\n",
      "[SGD | lr=0.1] Iter 36000: loss=0.0085\n",
      "[SGD | lr=0.1] Epoch 2250/4000: train_loss=0.0084  test_loss=4.1911  λ_max=67.3814\n",
      "[SGD | lr=0.1] Epoch 2251/4000: train_loss=0.0084  test_loss=4.1913  λ_max=66.6324\n",
      "[SGD | lr=0.1] Epoch 2252/4000: train_loss=0.0084  test_loss=4.1919  λ_max=66.3924\n",
      "[SGD | lr=0.1] Epoch 2253/4000: train_loss=0.0084  test_loss=4.1921  λ_max=65.4138\n",
      "[SGD | lr=0.1] Epoch 2254/4000: train_loss=0.0084  test_loss=4.1925  λ_max=66.1599\n",
      "[SGD | lr=0.1] Epoch 2255/4000: train_loss=0.0083  test_loss=4.1926  λ_max=67.2261\n",
      "[SGD | lr=0.1] Epoch 2256/4000: train_loss=0.0083  test_loss=4.1930  λ_max=66.4005\n",
      "[SGD | lr=0.1] Iter 36100: loss=0.0083\n",
      "[SGD | lr=0.1] Epoch 2257/4000: train_loss=0.0083  test_loss=4.1935  λ_max=67.8955\n",
      "[SGD | lr=0.1] Epoch 2258/4000: train_loss=0.0083  test_loss=4.1937  λ_max=66.7577\n",
      "[SGD | lr=0.1] Epoch 2259/4000: train_loss=0.0083  test_loss=4.1941  λ_max=65.2333\n",
      "[SGD | lr=0.1] Epoch 2260/4000: train_loss=0.0083  test_loss=4.1943  λ_max=66.6037\n",
      "[SGD | lr=0.1] Epoch 2261/4000: train_loss=0.0083  test_loss=4.1948  λ_max=67.0163\n",
      "[SGD | lr=0.1] Epoch 2262/4000: train_loss=0.0083  test_loss=4.1950  λ_max=67.1811\n",
      "[SGD | lr=0.1] Iter 36200: loss=0.0083\n",
      "[SGD | lr=0.1] Epoch 2263/4000: train_loss=0.0083  test_loss=4.1953  λ_max=65.7477\n",
      "[SGD | lr=0.1] Epoch 2264/4000: train_loss=0.0083  test_loss=4.1956  λ_max=66.7728\n",
      "[SGD | lr=0.1] Epoch 2265/4000: train_loss=0.0083  test_loss=4.1959  λ_max=65.9163\n",
      "[SGD | lr=0.1] Epoch 2266/4000: train_loss=0.0083  test_loss=4.1963  λ_max=66.7661\n",
      "[SGD | lr=0.1] Epoch 2267/4000: train_loss=0.0083  test_loss=4.1966  λ_max=64.6994\n",
      "[SGD | lr=0.1] Epoch 2268/4000: train_loss=0.0083  test_loss=4.1970  λ_max=67.8223\n",
      "[SGD | lr=0.1] Iter 36300: loss=0.0082\n",
      "[SGD | lr=0.1] Epoch 2269/4000: train_loss=0.0083  test_loss=4.1974  λ_max=66.3815\n",
      "[SGD | lr=0.1] Epoch 2270/4000: train_loss=0.0083  test_loss=4.1976  λ_max=67.1793\n",
      "[SGD | lr=0.1] Epoch 2271/4000: train_loss=0.0083  test_loss=4.1980  λ_max=68.3648\n",
      "[SGD | lr=0.1] Epoch 2272/4000: train_loss=0.0083  test_loss=4.1982  λ_max=64.2842\n",
      "[SGD | lr=0.1] Epoch 2273/4000: train_loss=0.0083  test_loss=4.1986  λ_max=68.6237\n",
      "[SGD | lr=0.1] Epoch 2274/4000: train_loss=0.0083  test_loss=4.1989  λ_max=66.4055\n",
      "[SGD | lr=0.1] Iter 36400: loss=0.0083\n",
      "[SGD | lr=0.1] Epoch 2275/4000: train_loss=0.0082  test_loss=4.1992  λ_max=66.1686\n",
      "[SGD | lr=0.1] Epoch 2276/4000: train_loss=0.0082  test_loss=4.1995  λ_max=68.1458\n",
      "[SGD | lr=0.1] Epoch 2277/4000: train_loss=0.0082  test_loss=4.1999  λ_max=67.7825\n",
      "[SGD | lr=0.1] Epoch 2278/4000: train_loss=0.0082  test_loss=4.2002  λ_max=67.2307\n",
      "[SGD | lr=0.1] Epoch 2279/4000: train_loss=0.0082  test_loss=4.2006  λ_max=63.7183\n",
      "[SGD | lr=0.1] Epoch 2280/4000: train_loss=0.0082  test_loss=4.2007  λ_max=67.8555\n",
      "[SGD | lr=0.1] Epoch 2281/4000: train_loss=0.0082  test_loss=4.2011  λ_max=68.5844\n",
      "[SGD | lr=0.1] Iter 36500: loss=0.0083\n",
      "[SGD | lr=0.1] Epoch 2282/4000: train_loss=0.0082  test_loss=4.2013  λ_max=67.8469\n",
      "[SGD | lr=0.1] Epoch 2283/4000: train_loss=0.0082  test_loss=4.2017  λ_max=68.5037\n",
      "[SGD | lr=0.1] Epoch 2284/4000: train_loss=0.0082  test_loss=4.2022  λ_max=64.9623\n",
      "[SGD | lr=0.1] Epoch 2285/4000: train_loss=0.0082  test_loss=4.2023  λ_max=67.5343\n",
      "[SGD | lr=0.1] Epoch 2286/4000: train_loss=0.0082  test_loss=4.2026  λ_max=67.2455\n",
      "[SGD | lr=0.1] Epoch 2287/4000: train_loss=0.0082  test_loss=4.2030  λ_max=64.5328\n",
      "[SGD | lr=0.1] Iter 36600: loss=0.0082\n",
      "[SGD | lr=0.1] Epoch 2288/4000: train_loss=0.0082  test_loss=4.2035  λ_max=67.8612\n",
      "[SGD | lr=0.1] Epoch 2289/4000: train_loss=0.0082  test_loss=4.2038  λ_max=66.6473\n",
      "[SGD | lr=0.1] Epoch 2290/4000: train_loss=0.0082  test_loss=4.2041  λ_max=66.2724\n",
      "[SGD | lr=0.1] Epoch 2291/4000: train_loss=0.0082  test_loss=4.2043  λ_max=65.3242\n",
      "[SGD | lr=0.1] Epoch 2292/4000: train_loss=0.0082  test_loss=4.2046  λ_max=66.8815\n",
      "[SGD | lr=0.1] Epoch 2293/4000: train_loss=0.0082  test_loss=4.2050  λ_max=68.5494\n",
      "[SGD | lr=0.1] Iter 36700: loss=0.0081\n",
      "[SGD | lr=0.1] Epoch 2294/4000: train_loss=0.0082  test_loss=4.2053  λ_max=67.9864\n",
      "[SGD | lr=0.1] Epoch 2295/4000: train_loss=0.0081  test_loss=4.2056  λ_max=69.4979\n",
      "[SGD | lr=0.1] Epoch 2296/4000: train_loss=0.0081  test_loss=4.2061  λ_max=65.5434\n",
      "[SGD | lr=0.1] Epoch 2297/4000: train_loss=0.0081  test_loss=4.2064  λ_max=67.5368\n",
      "[SGD | lr=0.1] Epoch 2298/4000: train_loss=0.0081  test_loss=4.2066  λ_max=68.6715\n",
      "[SGD | lr=0.1] Epoch 2299/4000: train_loss=0.0081  test_loss=4.2069  λ_max=67.0287\n",
      "[SGD | lr=0.1] Iter 36800: loss=0.0081\n",
      "[SGD | lr=0.1] Epoch 2300/4000: train_loss=0.0081  test_loss=4.2072  λ_max=65.8551\n",
      "[SGD | lr=0.1] Epoch 2301/4000: train_loss=0.0081  test_loss=4.2075  λ_max=66.1356\n",
      "[SGD | lr=0.1] Epoch 2302/4000: train_loss=0.0081  test_loss=4.2077  λ_max=68.9657\n",
      "[SGD | lr=0.1] Epoch 2303/4000: train_loss=0.0081  test_loss=4.2083  λ_max=67.0203\n",
      "[SGD | lr=0.1] Epoch 2304/4000: train_loss=0.0081  test_loss=4.2084  λ_max=67.6066\n",
      "[SGD | lr=0.1] Epoch 2305/4000: train_loss=0.0081  test_loss=4.2088  λ_max=66.7904\n",
      "[SGD | lr=0.1] Epoch 2306/4000: train_loss=0.0081  test_loss=4.2090  λ_max=68.2696\n",
      "[SGD | lr=0.1] Iter 36900: loss=0.0081\n",
      "[SGD | lr=0.1] Epoch 2307/4000: train_loss=0.0081  test_loss=4.2096  λ_max=70.3652\n",
      "[SGD | lr=0.1] Epoch 2308/4000: train_loss=0.0081  test_loss=4.2098  λ_max=65.8714\n",
      "[SGD | lr=0.1] Epoch 2309/4000: train_loss=0.0081  test_loss=4.2102  λ_max=66.5270\n",
      "[SGD | lr=0.1] Epoch 2310/4000: train_loss=0.0081  test_loss=4.2104  λ_max=68.0059\n",
      "[SGD | lr=0.1] Epoch 2311/4000: train_loss=0.0081  test_loss=4.2108  λ_max=68.5740\n",
      "[SGD | lr=0.1] Epoch 2312/4000: train_loss=0.0081  test_loss=4.2110  λ_max=66.9602\n",
      "[SGD | lr=0.1] Iter 37000: loss=0.0081\n",
      "[SGD | lr=0.1] Epoch 2313/4000: train_loss=0.0081  test_loss=4.2113  λ_max=67.2591\n",
      "[SGD | lr=0.1] Epoch 2314/4000: train_loss=0.0081  test_loss=4.2117  λ_max=68.3725\n",
      "[SGD | lr=0.1] Epoch 2315/4000: train_loss=0.0080  test_loss=4.2123  λ_max=67.8798\n",
      "[SGD | lr=0.1] Epoch 2316/4000: train_loss=0.0080  test_loss=4.2123  λ_max=68.7353\n",
      "[SGD | lr=0.1] Epoch 2317/4000: train_loss=0.0080  test_loss=4.2126  λ_max=68.4877\n",
      "[SGD | lr=0.1] Epoch 2318/4000: train_loss=0.0080  test_loss=4.2129  λ_max=66.0168\n",
      "[SGD | lr=0.1] Iter 37100: loss=0.0079\n",
      "[SGD | lr=0.1] Epoch 2319/4000: train_loss=0.0080  test_loss=4.2133  λ_max=66.2317\n",
      "[SGD | lr=0.1] Epoch 2320/4000: train_loss=0.0080  test_loss=4.2135  λ_max=67.0346\n",
      "[SGD | lr=0.1] Epoch 2321/4000: train_loss=0.0080  test_loss=4.2140  λ_max=67.2633\n",
      "[SGD | lr=0.1] Epoch 2322/4000: train_loss=0.0080  test_loss=4.2142  λ_max=66.9173\n",
      "[SGD | lr=0.1] Epoch 2323/4000: train_loss=0.0080  test_loss=4.2145  λ_max=69.4613\n",
      "[SGD | lr=0.1] Epoch 2324/4000: train_loss=0.0080  test_loss=4.2150  λ_max=66.9845\n",
      "[SGD | lr=0.1] Iter 37200: loss=0.0079\n",
      "[SGD | lr=0.1] Epoch 2325/4000: train_loss=0.0080  test_loss=4.2152  λ_max=66.9548\n",
      "[SGD | lr=0.1] Epoch 2326/4000: train_loss=0.0080  test_loss=4.2154  λ_max=67.0161\n",
      "[SGD | lr=0.1] Epoch 2327/4000: train_loss=0.0080  test_loss=4.2157  λ_max=66.8239\n",
      "[SGD | lr=0.1] Epoch 2328/4000: train_loss=0.0080  test_loss=4.2161  λ_max=66.9897\n",
      "[SGD | lr=0.1] Epoch 2329/4000: train_loss=0.0080  test_loss=4.2165  λ_max=67.9707\n",
      "[SGD | lr=0.1] Epoch 2330/4000: train_loss=0.0080  test_loss=4.2167  λ_max=68.6543\n",
      "[SGD | lr=0.1] Epoch 2331/4000: train_loss=0.0080  test_loss=4.2170  λ_max=66.9772\n",
      "[SGD | lr=0.1] Iter 37300: loss=0.0080\n",
      "[SGD | lr=0.1] Epoch 2332/4000: train_loss=0.0080  test_loss=4.2172  λ_max=68.9852\n",
      "[SGD | lr=0.1] Epoch 2333/4000: train_loss=0.0080  test_loss=4.2178  λ_max=69.8538\n",
      "[SGD | lr=0.1] Epoch 2334/4000: train_loss=0.0080  test_loss=4.2181  λ_max=67.7495\n",
      "[SGD | lr=0.1] Epoch 2335/4000: train_loss=0.0080  test_loss=4.2183  λ_max=68.1073\n",
      "[SGD | lr=0.1] Epoch 2336/4000: train_loss=0.0079  test_loss=4.2186  λ_max=68.6132\n",
      "[SGD | lr=0.1] Epoch 2337/4000: train_loss=0.0079  test_loss=4.2190  λ_max=67.7606\n",
      "[SGD | lr=0.1] Iter 37400: loss=0.0077\n",
      "[SGD | lr=0.1] Epoch 2338/4000: train_loss=0.0079  test_loss=4.2192  λ_max=65.8313\n",
      "[SGD | lr=0.1] Epoch 2339/4000: train_loss=0.0079  test_loss=4.2197  λ_max=66.0381\n",
      "[SGD | lr=0.1] Epoch 2340/4000: train_loss=0.0079  test_loss=4.2201  λ_max=66.2785\n",
      "[SGD | lr=0.1] Epoch 2341/4000: train_loss=0.0079  test_loss=4.2202  λ_max=68.7782\n",
      "[SGD | lr=0.1] Epoch 2342/4000: train_loss=0.0079  test_loss=4.2205  λ_max=65.3841\n",
      "[SGD | lr=0.1] Epoch 2343/4000: train_loss=0.0079  test_loss=4.2208  λ_max=68.3586\n",
      "[SGD | lr=0.1] Iter 37500: loss=0.0078\n",
      "[SGD | lr=0.1] Epoch 2344/4000: train_loss=0.0079  test_loss=4.2213  λ_max=67.4124\n",
      "[SGD | lr=0.1] Epoch 2345/4000: train_loss=0.0079  test_loss=4.2215  λ_max=66.8871\n",
      "[SGD | lr=0.1] Epoch 2346/4000: train_loss=0.0079  test_loss=4.2219  λ_max=68.5195\n",
      "[SGD | lr=0.1] Epoch 2347/4000: train_loss=0.0079  test_loss=4.2221  λ_max=67.6401\n",
      "[SGD | lr=0.1] Epoch 2348/4000: train_loss=0.0079  test_loss=4.2225  λ_max=68.1362\n",
      "[SGD | lr=0.1] Epoch 2349/4000: train_loss=0.0079  test_loss=4.2228  λ_max=68.5456\n",
      "[SGD | lr=0.1] Iter 37600: loss=0.0080\n",
      "[SGD | lr=0.1] Epoch 2350/4000: train_loss=0.0079  test_loss=4.2230  λ_max=65.6363\n",
      "[SGD | lr=0.1] Epoch 2351/4000: train_loss=0.0079  test_loss=4.2235  λ_max=67.6879\n",
      "[SGD | lr=0.1] Epoch 2352/4000: train_loss=0.0079  test_loss=4.2237  λ_max=67.4124\n",
      "[SGD | lr=0.1] Epoch 2353/4000: train_loss=0.0079  test_loss=4.2240  λ_max=69.4710\n",
      "[SGD | lr=0.1] Epoch 2354/4000: train_loss=0.0079  test_loss=4.2244  λ_max=67.9098\n",
      "[SGD | lr=0.1] Epoch 2355/4000: train_loss=0.0079  test_loss=4.2247  λ_max=67.6876\n",
      "[SGD | lr=0.1] Epoch 2356/4000: train_loss=0.0079  test_loss=4.2247  λ_max=66.8290\n",
      "[SGD | lr=0.1] Iter 37700: loss=0.0078\n",
      "[SGD | lr=0.1] Epoch 2357/4000: train_loss=0.0079  test_loss=4.2253  λ_max=65.5524\n",
      "[SGD | lr=0.1] Epoch 2358/4000: train_loss=0.0079  test_loss=4.2255  λ_max=68.5021\n",
      "[SGD | lr=0.1] Epoch 2359/4000: train_loss=0.0078  test_loss=4.2258  λ_max=66.9308\n",
      "[SGD | lr=0.1] Epoch 2360/4000: train_loss=0.0078  test_loss=4.2262  λ_max=69.9824\n",
      "[SGD | lr=0.1] Epoch 2361/4000: train_loss=0.0078  test_loss=4.2265  λ_max=68.1282\n",
      "[SGD | lr=0.1] Epoch 2362/4000: train_loss=0.0078  test_loss=4.2270  λ_max=67.7147\n",
      "[SGD | lr=0.1] Iter 37800: loss=0.0078\n",
      "[SGD | lr=0.1] Epoch 2363/4000: train_loss=0.0078  test_loss=4.2272  λ_max=67.0843\n",
      "[SGD | lr=0.1] Epoch 2364/4000: train_loss=0.0078  test_loss=4.2273  λ_max=69.6269\n",
      "[SGD | lr=0.1] Epoch 2365/4000: train_loss=0.0078  test_loss=4.2277  λ_max=68.2534\n",
      "[SGD | lr=0.1] Epoch 2366/4000: train_loss=0.0078  test_loss=4.2280  λ_max=68.4344\n",
      "[SGD | lr=0.1] Epoch 2367/4000: train_loss=0.0078  test_loss=4.2284  λ_max=67.2985\n",
      "[SGD | lr=0.1] Epoch 2368/4000: train_loss=0.0078  test_loss=4.2286  λ_max=68.7673\n",
      "[SGD | lr=0.1] Iter 37900: loss=0.0079\n",
      "[SGD | lr=0.1] Epoch 2369/4000: train_loss=0.0078  test_loss=4.2289  λ_max=65.4763\n",
      "[SGD | lr=0.1] Epoch 2370/4000: train_loss=0.0078  test_loss=4.2292  λ_max=68.3048\n",
      "[SGD | lr=0.1] Epoch 2371/4000: train_loss=0.0078  test_loss=4.2295  λ_max=67.4870\n",
      "[SGD | lr=0.1] Epoch 2372/4000: train_loss=0.0078  test_loss=4.2299  λ_max=66.6817\n",
      "[SGD | lr=0.1] Epoch 2373/4000: train_loss=0.0078  test_loss=4.2302  λ_max=67.1046\n",
      "[SGD | lr=0.1] Epoch 2374/4000: train_loss=0.0078  test_loss=4.2305  λ_max=67.9821\n",
      "[SGD | lr=0.1] Iter 38000: loss=0.0077\n",
      "[SGD | lr=0.1] Epoch 2375/4000: train_loss=0.0078  test_loss=4.2307  λ_max=67.7903\n",
      "[SGD | lr=0.1] Epoch 2376/4000: train_loss=0.0078  test_loss=4.2311  λ_max=68.2395\n",
      "[SGD | lr=0.1] Epoch 2377/4000: train_loss=0.0078  test_loss=4.2314  λ_max=68.8443\n",
      "[SGD | lr=0.1] Epoch 2378/4000: train_loss=0.0078  test_loss=4.2317  λ_max=69.0237\n",
      "[SGD | lr=0.1] Epoch 2379/4000: train_loss=0.0078  test_loss=4.2319  λ_max=68.8494\n",
      "[SGD | lr=0.1] Epoch 2380/4000: train_loss=0.0078  test_loss=4.2323  λ_max=68.8485\n",
      "[SGD | lr=0.1] Epoch 2381/4000: train_loss=0.0077  test_loss=4.2327  λ_max=69.1174\n",
      "[SGD | lr=0.1] Iter 38100: loss=0.0078\n",
      "[SGD | lr=0.1] Epoch 2382/4000: train_loss=0.0077  test_loss=4.2330  λ_max=67.1909\n",
      "[SGD | lr=0.1] Epoch 2383/4000: train_loss=0.0077  test_loss=4.2333  λ_max=68.5126\n",
      "[SGD | lr=0.1] Epoch 2384/4000: train_loss=0.0077  test_loss=4.2335  λ_max=67.6332\n",
      "[SGD | lr=0.1] Epoch 2385/4000: train_loss=0.0077  test_loss=4.2336  λ_max=67.8937\n",
      "[SGD | lr=0.1] Epoch 2386/4000: train_loss=0.0077  test_loss=4.2341  λ_max=69.0823\n",
      "[SGD | lr=0.1] Epoch 2387/4000: train_loss=0.0077  test_loss=4.2346  λ_max=67.8636\n",
      "[SGD | lr=0.1] Iter 38200: loss=0.0077\n",
      "[SGD | lr=0.1] Epoch 2388/4000: train_loss=0.0077  test_loss=4.2349  λ_max=69.2435\n",
      "[SGD | lr=0.1] Epoch 2389/4000: train_loss=0.0077  test_loss=4.2350  λ_max=66.1437\n",
      "[SGD | lr=0.1] Epoch 2390/4000: train_loss=0.0077  test_loss=4.2356  λ_max=69.1692\n",
      "[SGD | lr=0.1] Epoch 2391/4000: train_loss=0.0077  test_loss=4.2355  λ_max=67.4021\n",
      "[SGD | lr=0.1] Epoch 2392/4000: train_loss=0.0077  test_loss=4.2359  λ_max=70.1130\n",
      "[SGD | lr=0.1] Epoch 2393/4000: train_loss=0.0077  test_loss=4.2364  λ_max=68.2413\n",
      "[SGD | lr=0.1] Iter 38300: loss=0.0076\n",
      "[SGD | lr=0.1] Epoch 2394/4000: train_loss=0.0077  test_loss=4.2365  λ_max=66.6869\n",
      "[SGD | lr=0.1] Epoch 2395/4000: train_loss=0.0077  test_loss=4.2371  λ_max=67.9458\n",
      "[SGD | lr=0.1] Epoch 2396/4000: train_loss=0.0077  test_loss=4.2374  λ_max=68.6388\n",
      "[SGD | lr=0.1] Epoch 2397/4000: train_loss=0.0077  test_loss=4.2374  λ_max=68.3339\n",
      "[SGD | lr=0.1] Epoch 2398/4000: train_loss=0.0077  test_loss=4.2379  λ_max=68.1739\n",
      "[SGD | lr=0.1] Epoch 2399/4000: train_loss=0.0077  test_loss=4.2382  λ_max=66.8674\n",
      "[SGD | lr=0.1] Iter 38400: loss=0.0078\n",
      "[SGD | lr=0.1] Epoch 2400/4000: train_loss=0.0077  test_loss=4.2385  λ_max=67.2655\n",
      "[SGD | lr=0.1] Epoch 2401/4000: train_loss=0.0077  test_loss=4.2387  λ_max=68.9950\n",
      "[SGD | lr=0.1] Epoch 2402/4000: train_loss=0.0077  test_loss=4.2392  λ_max=68.8875\n",
      "[SGD | lr=0.1] Epoch 2403/4000: train_loss=0.0076  test_loss=4.2394  λ_max=68.2162\n",
      "[SGD | lr=0.1] Epoch 2404/4000: train_loss=0.0076  test_loss=4.2397  λ_max=68.5008\n",
      "[SGD | lr=0.1] Epoch 2405/4000: train_loss=0.0076  test_loss=4.2400  λ_max=68.0108\n",
      "[SGD | lr=0.1] Epoch 2406/4000: train_loss=0.0076  test_loss=4.2404  λ_max=67.4680\n",
      "[SGD | lr=0.1] Iter 38500: loss=0.0077\n",
      "[SGD | lr=0.1] Epoch 2407/4000: train_loss=0.0076  test_loss=4.2407  λ_max=66.5364\n",
      "[SGD | lr=0.1] Epoch 2408/4000: train_loss=0.0076  test_loss=4.2411  λ_max=67.7174\n",
      "[SGD | lr=0.1] Epoch 2409/4000: train_loss=0.0076  test_loss=4.2412  λ_max=68.0975\n",
      "[SGD | lr=0.1] Epoch 2410/4000: train_loss=0.0076  test_loss=4.2414  λ_max=68.1516\n",
      "[SGD | lr=0.1] Epoch 2411/4000: train_loss=0.0076  test_loss=4.2419  λ_max=67.4317\n",
      "[SGD | lr=0.1] Epoch 2412/4000: train_loss=0.0076  test_loss=4.2422  λ_max=68.6731\n",
      "[SGD | lr=0.1] Iter 38600: loss=0.0076\n",
      "[SGD | lr=0.1] Epoch 2413/4000: train_loss=0.0076  test_loss=4.2424  λ_max=68.7385\n",
      "[SGD | lr=0.1] Epoch 2414/4000: train_loss=0.0076  test_loss=4.2427  λ_max=68.2953\n",
      "[SGD | lr=0.1] Epoch 2415/4000: train_loss=0.0076  test_loss=4.2430  λ_max=66.7100\n",
      "[SGD | lr=0.1] Epoch 2416/4000: train_loss=0.0076  test_loss=4.2434  λ_max=68.3803\n",
      "[SGD | lr=0.1] Epoch 2417/4000: train_loss=0.0076  test_loss=4.2437  λ_max=67.8729\n",
      "[SGD | lr=0.1] Epoch 2418/4000: train_loss=0.0076  test_loss=4.2439  λ_max=67.8391\n",
      "[SGD | lr=0.1] Iter 38700: loss=0.0074\n",
      "[SGD | lr=0.1] Epoch 2419/4000: train_loss=0.0076  test_loss=4.2441  λ_max=70.4213\n",
      "[SGD | lr=0.1] Epoch 2420/4000: train_loss=0.0076  test_loss=4.2446  λ_max=70.4859\n",
      "[SGD | lr=0.1] Epoch 2421/4000: train_loss=0.0076  test_loss=4.2447  λ_max=67.4619\n",
      "[SGD | lr=0.1] Epoch 2422/4000: train_loss=0.0076  test_loss=4.2451  λ_max=70.3004\n",
      "[SGD | lr=0.1] Epoch 2423/4000: train_loss=0.0076  test_loss=4.2453  λ_max=67.7807\n",
      "[SGD | lr=0.1] Epoch 2424/4000: train_loss=0.0076  test_loss=4.2457  λ_max=68.5875\n",
      "[SGD | lr=0.1] Iter 38800: loss=0.0076\n",
      "[SGD | lr=0.1] Epoch 2425/4000: train_loss=0.0076  test_loss=4.2460  λ_max=69.4165\n",
      "[SGD | lr=0.1] Epoch 2426/4000: train_loss=0.0076  test_loss=4.2464  λ_max=69.2174\n",
      "[SGD | lr=0.1] Epoch 2427/4000: train_loss=0.0075  test_loss=4.2466  λ_max=69.4263\n",
      "[SGD | lr=0.1] Epoch 2428/4000: train_loss=0.0075  test_loss=4.2469  λ_max=68.9919\n",
      "[SGD | lr=0.1] Epoch 2429/4000: train_loss=0.0075  test_loss=4.2473  λ_max=69.0807\n",
      "[SGD | lr=0.1] Epoch 2430/4000: train_loss=0.0075  test_loss=4.2474  λ_max=67.1534\n",
      "[SGD | lr=0.1] Epoch 2431/4000: train_loss=0.0075  test_loss=4.2478  λ_max=70.6747\n",
      "[SGD | lr=0.1] Iter 38900: loss=0.0075\n",
      "[SGD | lr=0.1] Epoch 2432/4000: train_loss=0.0075  test_loss=4.2481  λ_max=68.3806\n",
      "[SGD | lr=0.1] Epoch 2433/4000: train_loss=0.0075  test_loss=4.2484  λ_max=67.7446\n",
      "[SGD | lr=0.1] Epoch 2434/4000: train_loss=0.0075  test_loss=4.2487  λ_max=67.5876\n",
      "[SGD | lr=0.1] Epoch 2435/4000: train_loss=0.0075  test_loss=4.2490  λ_max=66.7565\n",
      "[SGD | lr=0.1] Epoch 2436/4000: train_loss=0.0075  test_loss=4.2493  λ_max=69.2513\n",
      "[SGD | lr=0.1] Epoch 2437/4000: train_loss=0.0075  test_loss=4.2495  λ_max=70.2341\n",
      "[SGD | lr=0.1] Iter 39000: loss=0.0076\n",
      "[SGD | lr=0.1] Epoch 2438/4000: train_loss=0.0075  test_loss=4.2499  λ_max=66.3503\n",
      "[SGD | lr=0.1] Epoch 2439/4000: train_loss=0.0075  test_loss=4.2503  λ_max=69.5934\n",
      "[SGD | lr=0.1] Epoch 2440/4000: train_loss=0.0075  test_loss=4.2505  λ_max=69.0325\n",
      "[SGD | lr=0.1] Epoch 2441/4000: train_loss=0.0075  test_loss=4.2507  λ_max=67.0400\n",
      "[SGD | lr=0.1] Epoch 2442/4000: train_loss=0.0075  test_loss=4.2512  λ_max=69.6722\n",
      "[SGD | lr=0.1] Epoch 2443/4000: train_loss=0.0075  test_loss=4.2514  λ_max=68.8069\n",
      "[SGD | lr=0.1] Iter 39100: loss=0.0076\n",
      "[SGD | lr=0.1] Epoch 2444/4000: train_loss=0.0075  test_loss=4.2518  λ_max=67.2793\n",
      "[SGD | lr=0.1] Epoch 2445/4000: train_loss=0.0075  test_loss=4.2519  λ_max=69.0492\n",
      "[SGD | lr=0.1] Epoch 2446/4000: train_loss=0.0075  test_loss=4.2522  λ_max=69.0860\n",
      "[SGD | lr=0.1] Epoch 2447/4000: train_loss=0.0075  test_loss=4.2526  λ_max=69.2716\n",
      "[SGD | lr=0.1] Epoch 2448/4000: train_loss=0.0075  test_loss=4.2529  λ_max=66.3861\n",
      "[SGD | lr=0.1] Epoch 2449/4000: train_loss=0.0075  test_loss=4.2531  λ_max=68.0341\n",
      "[SGD | lr=0.1] Iter 39200: loss=0.0075\n",
      "[SGD | lr=0.1] Epoch 2450/4000: train_loss=0.0075  test_loss=4.2536  λ_max=69.6301\n",
      "[SGD | lr=0.1] Epoch 2451/4000: train_loss=0.0074  test_loss=4.2538  λ_max=68.3547\n",
      "[SGD | lr=0.1] Epoch 2452/4000: train_loss=0.0074  test_loss=4.2541  λ_max=69.5245\n",
      "[SGD | lr=0.1] Epoch 2453/4000: train_loss=0.0074  test_loss=4.2544  λ_max=67.2445\n",
      "[SGD | lr=0.1] Epoch 2454/4000: train_loss=0.0074  test_loss=4.2547  λ_max=69.0415\n",
      "[SGD | lr=0.1] Epoch 2455/4000: train_loss=0.0074  test_loss=4.2550  λ_max=69.1358\n",
      "[SGD | lr=0.1] Epoch 2456/4000: train_loss=0.0074  test_loss=4.2553  λ_max=69.9722\n",
      "[SGD | lr=0.1] Iter 39300: loss=0.0074\n",
      "[SGD | lr=0.1] Epoch 2457/4000: train_loss=0.0074  test_loss=4.2556  λ_max=67.9775\n",
      "[SGD | lr=0.1] Epoch 2458/4000: train_loss=0.0074  test_loss=4.2559  λ_max=69.3962\n",
      "[SGD | lr=0.1] Epoch 2459/4000: train_loss=0.0074  test_loss=4.2563  λ_max=69.8947\n",
      "[SGD | lr=0.1] Epoch 2460/4000: train_loss=0.0074  test_loss=4.2565  λ_max=69.1914\n",
      "[SGD | lr=0.1] Epoch 2461/4000: train_loss=0.0074  test_loss=4.2567  λ_max=66.7154\n",
      "[SGD | lr=0.1] Epoch 2462/4000: train_loss=0.0074  test_loss=4.2570  λ_max=68.1802\n",
      "[SGD | lr=0.1] Iter 39400: loss=0.0074\n",
      "[SGD | lr=0.1] Epoch 2463/4000: train_loss=0.0074  test_loss=4.2573  λ_max=69.3375\n",
      "[SGD | lr=0.1] Epoch 2464/4000: train_loss=0.0074  test_loss=4.2577  λ_max=68.5862\n",
      "[SGD | lr=0.1] Epoch 2465/4000: train_loss=0.0074  test_loss=4.2581  λ_max=67.7876\n",
      "[SGD | lr=0.1] Epoch 2466/4000: train_loss=0.0074  test_loss=4.2583  λ_max=69.5689\n",
      "[SGD | lr=0.1] Epoch 2467/4000: train_loss=0.0074  test_loss=4.2586  λ_max=68.0809\n",
      "[SGD | lr=0.1] Epoch 2468/4000: train_loss=0.0074  test_loss=4.2590  λ_max=69.1161\n",
      "[SGD | lr=0.1] Iter 39500: loss=0.0075\n",
      "[SGD | lr=0.1] Epoch 2469/4000: train_loss=0.0074  test_loss=4.2591  λ_max=68.7106\n",
      "[SGD | lr=0.1] Epoch 2470/4000: train_loss=0.0074  test_loss=4.2594  λ_max=70.2052\n",
      "[SGD | lr=0.1] Epoch 2471/4000: train_loss=0.0074  test_loss=4.2597  λ_max=70.2623\n",
      "[SGD | lr=0.1] Epoch 2472/4000: train_loss=0.0074  test_loss=4.2600  λ_max=70.0723\n",
      "[SGD | lr=0.1] Epoch 2473/4000: train_loss=0.0074  test_loss=4.2602  λ_max=66.6977\n",
      "[SGD | lr=0.1] Epoch 2474/4000: train_loss=0.0073  test_loss=4.2605  λ_max=69.2137\n",
      "[SGD | lr=0.1] Iter 39600: loss=0.0074\n",
      "[SGD | lr=0.1] Epoch 2475/4000: train_loss=0.0073  test_loss=4.2610  λ_max=69.1376\n",
      "[SGD | lr=0.1] Epoch 2476/4000: train_loss=0.0073  test_loss=4.2611  λ_max=69.5650\n",
      "[SGD | lr=0.1] Epoch 2477/4000: train_loss=0.0073  test_loss=4.2614  λ_max=70.2546\n",
      "[SGD | lr=0.1] Epoch 2478/4000: train_loss=0.0073  test_loss=4.2617  λ_max=68.4072\n",
      "[SGD | lr=0.1] Epoch 2479/4000: train_loss=0.0073  test_loss=4.2622  λ_max=67.3770\n",
      "[SGD | lr=0.1] Epoch 2480/4000: train_loss=0.0073  test_loss=4.2624  λ_max=69.0857\n",
      "[SGD | lr=0.1] Epoch 2481/4000: train_loss=0.0073  test_loss=4.2626  λ_max=66.5370\n",
      "[SGD | lr=0.1] Iter 39700: loss=0.0074\n",
      "[SGD | lr=0.1] Epoch 2482/4000: train_loss=0.0073  test_loss=4.2629  λ_max=69.6745\n",
      "[SGD | lr=0.1] Epoch 2483/4000: train_loss=0.0073  test_loss=4.2632  λ_max=69.5925\n",
      "[SGD | lr=0.1] Epoch 2484/4000: train_loss=0.0073  test_loss=4.2636  λ_max=69.2461\n",
      "[SGD | lr=0.1] Epoch 2485/4000: train_loss=0.0073  test_loss=4.2636  λ_max=67.4887\n",
      "[SGD | lr=0.1] Epoch 2486/4000: train_loss=0.0073  test_loss=4.2640  λ_max=68.9465\n",
      "[SGD | lr=0.1] Epoch 2487/4000: train_loss=0.0073  test_loss=4.2644  λ_max=68.6820\n",
      "[SGD | lr=0.1] Iter 39800: loss=0.0073\n",
      "[SGD | lr=0.1] Epoch 2488/4000: train_loss=0.0073  test_loss=4.2647  λ_max=67.6562\n",
      "[SGD | lr=0.1] Epoch 2489/4000: train_loss=0.0073  test_loss=4.2651  λ_max=70.1307\n",
      "[SGD | lr=0.1] Epoch 2490/4000: train_loss=0.0073  test_loss=4.2652  λ_max=67.5016\n",
      "[SGD | lr=0.1] Epoch 2491/4000: train_loss=0.0073  test_loss=4.2656  λ_max=68.6140\n",
      "[SGD | lr=0.1] Epoch 2492/4000: train_loss=0.0073  test_loss=4.2658  λ_max=70.6590\n",
      "[SGD | lr=0.1] Epoch 2493/4000: train_loss=0.0073  test_loss=4.2661  λ_max=69.5737\n",
      "[SGD | lr=0.1] Iter 39900: loss=0.0073\n",
      "[SGD | lr=0.1] Epoch 2494/4000: train_loss=0.0073  test_loss=4.2665  λ_max=69.2755\n",
      "[SGD | lr=0.1] Epoch 2495/4000: train_loss=0.0073  test_loss=4.2667  λ_max=65.7583\n",
      "[SGD | lr=0.1] Epoch 2496/4000: train_loss=0.0073  test_loss=4.2671  λ_max=66.6463\n",
      "[SGD | lr=0.1] Epoch 2497/4000: train_loss=0.0073  test_loss=4.2674  λ_max=70.6527\n",
      "[SGD | lr=0.1] Epoch 2498/4000: train_loss=0.0073  test_loss=4.2677  λ_max=69.4002\n",
      "[SGD | lr=0.1] Epoch 2499/4000: train_loss=0.0073  test_loss=4.2678  λ_max=70.0988\n",
      "[SGD | lr=0.1] Iter 40000: loss=0.0073\n",
      "[SGD | lr=0.1] Epoch 2500/4000: train_loss=0.0073  test_loss=4.2682  λ_max=68.1753\n",
      "[SGD | lr=0.1] Epoch 2501/4000: train_loss=0.0072  test_loss=4.2684  λ_max=69.4459\n",
      "[SGD | lr=0.1] Epoch 2502/4000: train_loss=0.0072  test_loss=4.2688  λ_max=70.7871\n",
      "[SGD | lr=0.1] Epoch 2503/4000: train_loss=0.0072  test_loss=4.2690  λ_max=68.0628\n",
      "[SGD | lr=0.1] Epoch 2504/4000: train_loss=0.0072  test_loss=4.2694  λ_max=70.6964\n",
      "[SGD | lr=0.1] Epoch 2505/4000: train_loss=0.0072  test_loss=4.2696  λ_max=67.4722\n",
      "[SGD | lr=0.1] Epoch 2506/4000: train_loss=0.0072  test_loss=4.2698  λ_max=69.6400\n",
      "[SGD | lr=0.1] Iter 40100: loss=0.0073\n",
      "[SGD | lr=0.1] Epoch 2507/4000: train_loss=0.0072  test_loss=4.2703  λ_max=69.6468\n",
      "[SGD | lr=0.1] Epoch 2508/4000: train_loss=0.0072  test_loss=4.2705  λ_max=67.4790\n",
      "[SGD | lr=0.1] Epoch 2509/4000: train_loss=0.0072  test_loss=4.2708  λ_max=69.2274\n",
      "[SGD | lr=0.1] Epoch 2510/4000: train_loss=0.0072  test_loss=4.2712  λ_max=68.7230\n",
      "[SGD | lr=0.1] Epoch 2511/4000: train_loss=0.0072  test_loss=4.2714  λ_max=66.7018\n",
      "[SGD | lr=0.1] Epoch 2512/4000: train_loss=0.0072  test_loss=4.2716  λ_max=67.8177\n",
      "[SGD | lr=0.1] Iter 40200: loss=0.0071\n",
      "[SGD | lr=0.1] Epoch 2513/4000: train_loss=0.0072  test_loss=4.2720  λ_max=69.2586\n",
      "[SGD | lr=0.1] Epoch 2514/4000: train_loss=0.0072  test_loss=4.2723  λ_max=70.6420\n",
      "[SGD | lr=0.1] Epoch 2515/4000: train_loss=0.0072  test_loss=4.2726  λ_max=68.0841\n",
      "[SGD | lr=0.1] Epoch 2516/4000: train_loss=0.0072  test_loss=4.2728  λ_max=70.9156\n",
      "[SGD | lr=0.1] Epoch 2517/4000: train_loss=0.0072  test_loss=4.2730  λ_max=68.8757\n",
      "[SGD | lr=0.1] Epoch 2518/4000: train_loss=0.0072  test_loss=4.2734  λ_max=67.8748\n",
      "[SGD | lr=0.1] Iter 40300: loss=0.0071\n",
      "[SGD | lr=0.1] Epoch 2519/4000: train_loss=0.0072  test_loss=4.2736  λ_max=70.0546\n",
      "[SGD | lr=0.1] Epoch 2520/4000: train_loss=0.0072  test_loss=4.2739  λ_max=68.5200\n",
      "[SGD | lr=0.1] Epoch 2521/4000: train_loss=0.0072  test_loss=4.2742  λ_max=68.7145\n",
      "[SGD | lr=0.1] Epoch 2522/4000: train_loss=0.0072  test_loss=4.2746  λ_max=69.6095\n",
      "[SGD | lr=0.1] Epoch 2523/4000: train_loss=0.0072  test_loss=4.2749  λ_max=69.0046\n",
      "[SGD | lr=0.1] Epoch 2524/4000: train_loss=0.0072  test_loss=4.2750  λ_max=68.8894\n",
      "[SGD | lr=0.1] Iter 40400: loss=0.0072\n",
      "[SGD | lr=0.1] Epoch 2525/4000: train_loss=0.0072  test_loss=4.2755  λ_max=69.3583\n",
      "[SGD | lr=0.1] Epoch 2526/4000: train_loss=0.0071  test_loss=4.2757  λ_max=69.0598\n",
      "[SGD | lr=0.1] Epoch 2527/4000: train_loss=0.0071  test_loss=4.2761  λ_max=70.6776\n",
      "[SGD | lr=0.1] Epoch 2528/4000: train_loss=0.0071  test_loss=4.2762  λ_max=71.0859\n",
      "[SGD | lr=0.1] Epoch 2529/4000: train_loss=0.0071  test_loss=4.2765  λ_max=67.8012\n",
      "[SGD | lr=0.1] Epoch 2530/4000: train_loss=0.0071  test_loss=4.2769  λ_max=69.6945\n",
      "[SGD | lr=0.1] Epoch 2531/4000: train_loss=0.0071  test_loss=4.2773  λ_max=68.8994\n",
      "[SGD | lr=0.1] Iter 40500: loss=0.0071\n",
      "[SGD | lr=0.1] Epoch 2532/4000: train_loss=0.0071  test_loss=4.2774  λ_max=68.4770\n",
      "[SGD | lr=0.1] Epoch 2533/4000: train_loss=0.0071  test_loss=4.2778  λ_max=69.5590\n",
      "[SGD | lr=0.1] Epoch 2534/4000: train_loss=0.0071  test_loss=4.2780  λ_max=70.7985\n",
      "[SGD | lr=0.1] Epoch 2535/4000: train_loss=0.0071  test_loss=4.2783  λ_max=66.5794\n",
      "[SGD | lr=0.1] Epoch 2536/4000: train_loss=0.0071  test_loss=4.2785  λ_max=69.8132\n",
      "[SGD | lr=0.1] Epoch 2537/4000: train_loss=0.0071  test_loss=4.2788  λ_max=70.3032\n",
      "[SGD | lr=0.1] Iter 40600: loss=0.0072\n",
      "[SGD | lr=0.1] Epoch 2538/4000: train_loss=0.0071  test_loss=4.2790  λ_max=68.2011\n",
      "[SGD | lr=0.1] Epoch 2539/4000: train_loss=0.0071  test_loss=4.2794  λ_max=68.9591\n",
      "[SGD | lr=0.1] Epoch 2540/4000: train_loss=0.0071  test_loss=4.2798  λ_max=70.1300\n",
      "[SGD | lr=0.1] Epoch 2541/4000: train_loss=0.0071  test_loss=4.2800  λ_max=69.3905\n",
      "[SGD | lr=0.1] Epoch 2542/4000: train_loss=0.0071  test_loss=4.2801  λ_max=69.6547\n",
      "[SGD | lr=0.1] Epoch 2543/4000: train_loss=0.0071  test_loss=4.2805  λ_max=68.7786\n",
      "[SGD | lr=0.1] Iter 40700: loss=0.0070\n",
      "[SGD | lr=0.1] Epoch 2544/4000: train_loss=0.0071  test_loss=4.2808  λ_max=67.9960\n",
      "[SGD | lr=0.1] Epoch 2545/4000: train_loss=0.0071  test_loss=4.2810  λ_max=69.8508\n",
      "[SGD | lr=0.1] Epoch 2546/4000: train_loss=0.0071  test_loss=4.2813  λ_max=71.0942\n",
      "[SGD | lr=0.1] Epoch 2547/4000: train_loss=0.0071  test_loss=4.2816  λ_max=69.7960\n",
      "[SGD | lr=0.1] Epoch 2548/4000: train_loss=0.0071  test_loss=4.2820  λ_max=71.5017\n",
      "[SGD | lr=0.1] Epoch 2549/4000: train_loss=0.0071  test_loss=4.2824  λ_max=67.9029\n",
      "[SGD | lr=0.1] Iter 40800: loss=0.0071\n",
      "[SGD | lr=0.1] Epoch 2550/4000: train_loss=0.0071  test_loss=4.2825  λ_max=68.3988\n",
      "[SGD | lr=0.1] Epoch 2551/4000: train_loss=0.0071  test_loss=4.2828  λ_max=69.3353\n",
      "[SGD | lr=0.1] Epoch 2552/4000: train_loss=0.0070  test_loss=4.2831  λ_max=70.0566\n",
      "[SGD | lr=0.1] Epoch 2553/4000: train_loss=0.0070  test_loss=4.2833  λ_max=68.1692\n",
      "[SGD | lr=0.1] Epoch 2554/4000: train_loss=0.0070  test_loss=4.2837  λ_max=67.3146\n",
      "[SGD | lr=0.1] Epoch 2555/4000: train_loss=0.0070  test_loss=4.2840  λ_max=69.3943\n",
      "[SGD | lr=0.1] Epoch 2556/4000: train_loss=0.0070  test_loss=4.2841  λ_max=67.6505\n",
      "[SGD | lr=0.1] Iter 40900: loss=0.0069\n",
      "[SGD | lr=0.1] Epoch 2557/4000: train_loss=0.0070  test_loss=4.2846  λ_max=68.7845\n",
      "[SGD | lr=0.1] Epoch 2558/4000: train_loss=0.0070  test_loss=4.2848  λ_max=69.0740\n",
      "[SGD | lr=0.1] Epoch 2559/4000: train_loss=0.0070  test_loss=4.2851  λ_max=68.2294\n",
      "[SGD | lr=0.1] Epoch 2560/4000: train_loss=0.0070  test_loss=4.2854  λ_max=69.9782\n",
      "[SGD | lr=0.1] Epoch 2561/4000: train_loss=0.0070  test_loss=4.2856  λ_max=67.0409\n",
      "[SGD | lr=0.1] Epoch 2562/4000: train_loss=0.0070  test_loss=4.2860  λ_max=69.8534\n",
      "[SGD | lr=0.1] Iter 41000: loss=0.0069\n",
      "[SGD | lr=0.1] Epoch 2563/4000: train_loss=0.0070  test_loss=4.2861  λ_max=69.2235\n",
      "[SGD | lr=0.1] Epoch 2564/4000: train_loss=0.0070  test_loss=4.2865  λ_max=69.6013\n",
      "[SGD | lr=0.1] Epoch 2565/4000: train_loss=0.0070  test_loss=4.2869  λ_max=69.2101\n",
      "[SGD | lr=0.1] Epoch 2566/4000: train_loss=0.0070  test_loss=4.2872  λ_max=69.2955\n",
      "[SGD | lr=0.1] Epoch 2567/4000: train_loss=0.0070  test_loss=4.2874  λ_max=70.1279\n",
      "[SGD | lr=0.1] Epoch 2568/4000: train_loss=0.0070  test_loss=4.2877  λ_max=70.2655\n",
      "[SGD | lr=0.1] Iter 41100: loss=0.0070\n",
      "[SGD | lr=0.1] Epoch 2569/4000: train_loss=0.0070  test_loss=4.2879  λ_max=71.2431\n",
      "[SGD | lr=0.1] Epoch 2570/4000: train_loss=0.0070  test_loss=4.2883  λ_max=69.4925\n",
      "[SGD | lr=0.1] Epoch 2571/4000: train_loss=0.0070  test_loss=4.2885  λ_max=68.8905\n",
      "[SGD | lr=0.1] Epoch 2572/4000: train_loss=0.0070  test_loss=4.2889  λ_max=68.4534\n",
      "[SGD | lr=0.1] Epoch 2573/4000: train_loss=0.0070  test_loss=4.2890  λ_max=69.0912\n",
      "[SGD | lr=0.1] Epoch 2574/4000: train_loss=0.0070  test_loss=4.2894  λ_max=69.8591\n",
      "[SGD | lr=0.1] Iter 41200: loss=0.0069\n",
      "[SGD | lr=0.1] Epoch 2575/4000: train_loss=0.0070  test_loss=4.2895  λ_max=70.3570\n",
      "[SGD | lr=0.1] Epoch 2576/4000: train_loss=0.0070  test_loss=4.2898  λ_max=68.4288\n",
      "[SGD | lr=0.1] Epoch 2577/4000: train_loss=0.0070  test_loss=4.2902  λ_max=67.7985\n",
      "[SGD | lr=0.1] Epoch 2578/4000: train_loss=0.0070  test_loss=4.2904  λ_max=67.6861\n",
      "[SGD | lr=0.1] Epoch 2579/4000: train_loss=0.0069  test_loss=4.2909  λ_max=68.3615\n",
      "[SGD | lr=0.1] Epoch 2580/4000: train_loss=0.0069  test_loss=4.2910  λ_max=69.6681\n",
      "[SGD | lr=0.1] Epoch 2581/4000: train_loss=0.0069  test_loss=4.2912  λ_max=70.8023\n",
      "[SGD | lr=0.1] Iter 41300: loss=0.0070\n",
      "[SGD | lr=0.1] Epoch 2582/4000: train_loss=0.0069  test_loss=4.2915  λ_max=70.5170\n",
      "[SGD | lr=0.1] Epoch 2583/4000: train_loss=0.0069  test_loss=4.2919  λ_max=69.7630\n",
      "[SGD | lr=0.1] Epoch 2584/4000: train_loss=0.0069  test_loss=4.2923  λ_max=70.1338\n",
      "[SGD | lr=0.1] Epoch 2585/4000: train_loss=0.0069  test_loss=4.2925  λ_max=72.0695\n",
      "[SGD | lr=0.1] Epoch 2586/4000: train_loss=0.0069  test_loss=4.2928  λ_max=70.8328\n",
      "[SGD | lr=0.1] Epoch 2587/4000: train_loss=0.0069  test_loss=4.2928  λ_max=69.7045\n",
      "[SGD | lr=0.1] Iter 41400: loss=0.0070\n",
      "[SGD | lr=0.1] Epoch 2588/4000: train_loss=0.0069  test_loss=4.2933  λ_max=70.0186\n",
      "[SGD | lr=0.1] Epoch 2589/4000: train_loss=0.0069  test_loss=4.2937  λ_max=69.8283\n",
      "[SGD | lr=0.1] Epoch 2590/4000: train_loss=0.0069  test_loss=4.2939  λ_max=71.4938\n",
      "[SGD | lr=0.1] Epoch 2591/4000: train_loss=0.0069  test_loss=4.2939  λ_max=71.3439\n",
      "[SGD | lr=0.1] Epoch 2592/4000: train_loss=0.0069  test_loss=4.2944  λ_max=69.5124\n",
      "[SGD | lr=0.1] Epoch 2593/4000: train_loss=0.0069  test_loss=4.2946  λ_max=67.1075\n",
      "[SGD | lr=0.1] Iter 41500: loss=0.0070\n",
      "[SGD | lr=0.1] Epoch 2594/4000: train_loss=0.0069  test_loss=4.2949  λ_max=69.9955\n",
      "[SGD | lr=0.1] Epoch 2595/4000: train_loss=0.0069  test_loss=4.2952  λ_max=68.5923\n",
      "[SGD | lr=0.1] Epoch 2596/4000: train_loss=0.0069  test_loss=4.2953  λ_max=69.8412\n",
      "[SGD | lr=0.1] Epoch 2597/4000: train_loss=0.0069  test_loss=4.2958  λ_max=68.7463\n",
      "[SGD | lr=0.1] Epoch 2598/4000: train_loss=0.0069  test_loss=4.2960  λ_max=69.2814\n",
      "[SGD | lr=0.1] Epoch 2599/4000: train_loss=0.0069  test_loss=4.2964  λ_max=67.4413\n",
      "[SGD | lr=0.1] Iter 41600: loss=0.0066\n",
      "[SGD | lr=0.1] Epoch 2600/4000: train_loss=0.0069  test_loss=4.2965  λ_max=71.4981\n",
      "[SGD | lr=0.1] Epoch 2601/4000: train_loss=0.0069  test_loss=4.2968  λ_max=71.0927\n",
      "[SGD | lr=0.1] Epoch 2602/4000: train_loss=0.0069  test_loss=4.2970  λ_max=69.9839\n",
      "[SGD | lr=0.1] Epoch 2603/4000: train_loss=0.0069  test_loss=4.2974  λ_max=70.9324\n",
      "[SGD | lr=0.1] Epoch 2604/4000: train_loss=0.0069  test_loss=4.2977  λ_max=71.4690\n",
      "[SGD | lr=0.1] Epoch 2605/4000: train_loss=0.0069  test_loss=4.2981  λ_max=71.5251\n",
      "[SGD | lr=0.1] Epoch 2606/4000: train_loss=0.0068  test_loss=4.2983  λ_max=72.6152\n",
      "[SGD | lr=0.1] Iter 41700: loss=0.0068\n",
      "[SGD | lr=0.1] Epoch 2607/4000: train_loss=0.0068  test_loss=4.2984  λ_max=70.3389\n",
      "[SGD | lr=0.1] Epoch 2608/4000: train_loss=0.0068  test_loss=4.2989  λ_max=71.9154\n",
      "[SGD | lr=0.1] Epoch 2609/4000: train_loss=0.0068  test_loss=4.2991  λ_max=69.7177\n",
      "[SGD | lr=0.1] Epoch 2610/4000: train_loss=0.0068  test_loss=4.2994  λ_max=70.6827\n",
      "[SGD | lr=0.1] Epoch 2611/4000: train_loss=0.0068  test_loss=4.2995  λ_max=69.2429\n",
      "[SGD | lr=0.1] Epoch 2612/4000: train_loss=0.0068  test_loss=4.2999  λ_max=67.6976\n",
      "[SGD | lr=0.1] Iter 41800: loss=0.0069\n",
      "[SGD | lr=0.1] Epoch 2613/4000: train_loss=0.0068  test_loss=4.3003  λ_max=69.7365\n",
      "[SGD | lr=0.1] Epoch 2614/4000: train_loss=0.0068  test_loss=4.3005  λ_max=71.8829\n",
      "[SGD | lr=0.1] Epoch 2615/4000: train_loss=0.0068  test_loss=4.3007  λ_max=68.3026\n",
      "[SGD | lr=0.1] Epoch 2616/4000: train_loss=0.0068  test_loss=4.3009  λ_max=70.0590\n",
      "[SGD | lr=0.1] Epoch 2617/4000: train_loss=0.0068  test_loss=4.3013  λ_max=70.6004\n",
      "[SGD | lr=0.1] Epoch 2618/4000: train_loss=0.0068  test_loss=4.3014  λ_max=69.6256\n",
      "[SGD | lr=0.1] Iter 41900: loss=0.0067\n",
      "[SGD | lr=0.1] Epoch 2619/4000: train_loss=0.0068  test_loss=4.3019  λ_max=69.4183\n",
      "[SGD | lr=0.1] Epoch 2620/4000: train_loss=0.0068  test_loss=4.3023  λ_max=70.8208\n",
      "[SGD | lr=0.1] Epoch 2621/4000: train_loss=0.0068  test_loss=4.3024  λ_max=67.2959\n",
      "[SGD | lr=0.1] Epoch 2622/4000: train_loss=0.0068  test_loss=4.3026  λ_max=69.9967\n",
      "[SGD | lr=0.1] Epoch 2623/4000: train_loss=0.0068  test_loss=4.3029  λ_max=70.8517\n",
      "[SGD | lr=0.1] Epoch 2624/4000: train_loss=0.0068  test_loss=4.3032  λ_max=69.4670\n",
      "[SGD | lr=0.1] Iter 42000: loss=0.0068\n",
      "[SGD | lr=0.1] Epoch 2625/4000: train_loss=0.0068  test_loss=4.3035  λ_max=71.2410\n",
      "[SGD | lr=0.1] Epoch 2626/4000: train_loss=0.0068  test_loss=4.3037  λ_max=71.7139\n",
      "[SGD | lr=0.1] Epoch 2627/4000: train_loss=0.0068  test_loss=4.3039  λ_max=71.1674\n",
      "[SGD | lr=0.1] Epoch 2628/4000: train_loss=0.0068  test_loss=4.3043  λ_max=70.4672\n",
      "[SGD | lr=0.1] Epoch 2629/4000: train_loss=0.0068  test_loss=4.3047  λ_max=69.5462\n",
      "[SGD | lr=0.1] Epoch 2630/4000: train_loss=0.0068  test_loss=4.3049  λ_max=71.0413\n",
      "[SGD | lr=0.1] Epoch 2631/4000: train_loss=0.0068  test_loss=4.3050  λ_max=68.4421\n",
      "[SGD | lr=0.1] Iter 42100: loss=0.0067\n",
      "[SGD | lr=0.1] Epoch 2632/4000: train_loss=0.0068  test_loss=4.3055  λ_max=69.1578\n",
      "[SGD | lr=0.1] Epoch 2633/4000: train_loss=0.0068  test_loss=4.3056  λ_max=69.1524\n",
      "[SGD | lr=0.1] Epoch 2634/4000: train_loss=0.0068  test_loss=4.3059  λ_max=69.2251\n",
      "[SGD | lr=0.1] Epoch 2635/4000: train_loss=0.0068  test_loss=4.3063  λ_max=72.6064\n",
      "[SGD | lr=0.1] Epoch 2636/4000: train_loss=0.0067  test_loss=4.3065  λ_max=69.9476\n",
      "[SGD | lr=0.1] Epoch 2637/4000: train_loss=0.0067  test_loss=4.3069  λ_max=67.8608\n",
      "[SGD | lr=0.1] Iter 42200: loss=0.0068\n",
      "[SGD | lr=0.1] Epoch 2638/4000: train_loss=0.0067  test_loss=4.3070  λ_max=71.1224\n",
      "[SGD | lr=0.1] Epoch 2639/4000: train_loss=0.0067  test_loss=4.3074  λ_max=71.0938\n",
      "[SGD | lr=0.1] Epoch 2640/4000: train_loss=0.0067  test_loss=4.3076  λ_max=70.0894\n",
      "[SGD | lr=0.1] Epoch 2641/4000: train_loss=0.0067  test_loss=4.3079  λ_max=71.5557\n",
      "[SGD | lr=0.1] Epoch 2642/4000: train_loss=0.0067  test_loss=4.3081  λ_max=68.9612\n",
      "[SGD | lr=0.1] Epoch 2643/4000: train_loss=0.0067  test_loss=4.3085  λ_max=72.1357\n",
      "[SGD | lr=0.1] Iter 42300: loss=0.0068\n",
      "[SGD | lr=0.1] Epoch 2644/4000: train_loss=0.0067  test_loss=4.3086  λ_max=66.7203\n",
      "[SGD | lr=0.1] Epoch 2645/4000: train_loss=0.0067  test_loss=4.3089  λ_max=69.9639\n",
      "[SGD | lr=0.1] Epoch 2646/4000: train_loss=0.0067  test_loss=4.3093  λ_max=71.0554\n",
      "[SGD | lr=0.1] Epoch 2647/4000: train_loss=0.0067  test_loss=4.3095  λ_max=70.1683\n",
      "[SGD | lr=0.1] Epoch 2648/4000: train_loss=0.0067  test_loss=4.3097  λ_max=67.6308\n",
      "[SGD | lr=0.1] Epoch 2649/4000: train_loss=0.0067  test_loss=4.3101  λ_max=71.6674\n",
      "[SGD | lr=0.1] Iter 42400: loss=0.0066\n",
      "[SGD | lr=0.1] Epoch 2650/4000: train_loss=0.0067  test_loss=4.3104  λ_max=72.9366\n",
      "[SGD | lr=0.1] Epoch 2651/4000: train_loss=0.0067  test_loss=4.3107  λ_max=69.9759\n",
      "[SGD | lr=0.1] Epoch 2652/4000: train_loss=0.0067  test_loss=4.3109  λ_max=68.8384\n",
      "[SGD | lr=0.1] Epoch 2653/4000: train_loss=0.0067  test_loss=4.3113  λ_max=72.1682\n",
      "[SGD | lr=0.1] Epoch 2654/4000: train_loss=0.0067  test_loss=4.3114  λ_max=70.3376\n",
      "[SGD | lr=0.1] Epoch 2655/4000: train_loss=0.0067  test_loss=4.3117  λ_max=70.7532\n",
      "[SGD | lr=0.1] Epoch 2656/4000: train_loss=0.0067  test_loss=4.3120  λ_max=68.6187\n",
      "[SGD | lr=0.1] Iter 42500: loss=0.0067\n",
      "[SGD | lr=0.1] Epoch 2657/4000: train_loss=0.0067  test_loss=4.3122  λ_max=69.3370\n",
      "[SGD | lr=0.1] Epoch 2658/4000: train_loss=0.0067  test_loss=4.3124  λ_max=72.2241\n",
      "[SGD | lr=0.1] Epoch 2659/4000: train_loss=0.0067  test_loss=4.3129  λ_max=69.3126\n",
      "[SGD | lr=0.1] Epoch 2660/4000: train_loss=0.0067  test_loss=4.3131  λ_max=70.6460\n",
      "[SGD | lr=0.1] Epoch 2661/4000: train_loss=0.0067  test_loss=4.3133  λ_max=70.8384\n",
      "[SGD | lr=0.1] Epoch 2662/4000: train_loss=0.0067  test_loss=4.3136  λ_max=71.4153\n",
      "[SGD | lr=0.1] Iter 42600: loss=0.0066\n",
      "[SGD | lr=0.1] Epoch 2663/4000: train_loss=0.0067  test_loss=4.3137  λ_max=69.9856\n",
      "[SGD | lr=0.1] Epoch 2664/4000: train_loss=0.0067  test_loss=4.3139  λ_max=67.5386\n",
      "[SGD | lr=0.1] Epoch 2665/4000: train_loss=0.0066  test_loss=4.3143  λ_max=69.1055\n",
      "[SGD | lr=0.1] Epoch 2666/4000: train_loss=0.0066  test_loss=4.3147  λ_max=70.6644\n",
      "[SGD | lr=0.1] Epoch 2667/4000: train_loss=0.0066  test_loss=4.3149  λ_max=69.1791\n",
      "[SGD | lr=0.1] Epoch 2668/4000: train_loss=0.0066  test_loss=4.3152  λ_max=72.4479\n",
      "[SGD | lr=0.1] Iter 42700: loss=0.0066\n",
      "[SGD | lr=0.1] Epoch 2669/4000: train_loss=0.0066  test_loss=4.3155  λ_max=72.3240\n",
      "[SGD | lr=0.1] Epoch 2670/4000: train_loss=0.0066  test_loss=4.3158  λ_max=70.9357\n",
      "[SGD | lr=0.1] Epoch 2671/4000: train_loss=0.0066  test_loss=4.3160  λ_max=68.8817\n",
      "[SGD | lr=0.1] Epoch 2672/4000: train_loss=0.0066  test_loss=4.3164  λ_max=71.6857\n",
      "[SGD | lr=0.1] Epoch 2673/4000: train_loss=0.0066  test_loss=4.3165  λ_max=69.5889\n",
      "[SGD | lr=0.1] Epoch 2674/4000: train_loss=0.0066  test_loss=4.3169  λ_max=70.1687\n",
      "[SGD | lr=0.1] Iter 42800: loss=0.0068\n",
      "[SGD | lr=0.1] Epoch 2675/4000: train_loss=0.0066  test_loss=4.3171  λ_max=67.9389\n",
      "[SGD | lr=0.1] Epoch 2676/4000: train_loss=0.0066  test_loss=4.3173  λ_max=69.4093\n",
      "[SGD | lr=0.1] Epoch 2677/4000: train_loss=0.0066  test_loss=4.3177  λ_max=70.2355\n",
      "[SGD | lr=0.1] Epoch 2678/4000: train_loss=0.0066  test_loss=4.3179  λ_max=70.2560\n",
      "[SGD | lr=0.1] Epoch 2679/4000: train_loss=0.0066  test_loss=4.3183  λ_max=70.3816\n",
      "[SGD | lr=0.1] Epoch 2680/4000: train_loss=0.0066  test_loss=4.3184  λ_max=69.3690\n",
      "[SGD | lr=0.1] Epoch 2681/4000: train_loss=0.0066  test_loss=4.3187  λ_max=70.5479\n",
      "[SGD | lr=0.1] Iter 42900: loss=0.0065\n",
      "[SGD | lr=0.1] Epoch 2682/4000: train_loss=0.0066  test_loss=4.3190  λ_max=71.3938\n",
      "[SGD | lr=0.1] Epoch 2683/4000: train_loss=0.0066  test_loss=4.3194  λ_max=69.9101\n",
      "[SGD | lr=0.1] Epoch 2684/4000: train_loss=0.0066  test_loss=4.3194  λ_max=70.6014\n",
      "[SGD | lr=0.1] Epoch 2685/4000: train_loss=0.0066  test_loss=4.3197  λ_max=68.5302\n",
      "[SGD | lr=0.1] Epoch 2686/4000: train_loss=0.0066  test_loss=4.3202  λ_max=69.8791\n",
      "[SGD | lr=0.1] Epoch 2687/4000: train_loss=0.0066  test_loss=4.3203  λ_max=68.6093\n",
      "[SGD | lr=0.1] Iter 43000: loss=0.0066\n",
      "[SGD | lr=0.1] Epoch 2688/4000: train_loss=0.0066  test_loss=4.3207  λ_max=69.4256\n",
      "[SGD | lr=0.1] Epoch 2689/4000: train_loss=0.0066  test_loss=4.3208  λ_max=69.3575\n",
      "[SGD | lr=0.1] Epoch 2690/4000: train_loss=0.0066  test_loss=4.3211  λ_max=70.6981\n",
      "[SGD | lr=0.1] Epoch 2691/4000: train_loss=0.0066  test_loss=4.3215  λ_max=71.1771\n",
      "[SGD | lr=0.1] Epoch 2692/4000: train_loss=0.0066  test_loss=4.3216  λ_max=69.8718\n",
      "[SGD | lr=0.1] Epoch 2693/4000: train_loss=0.0066  test_loss=4.3220  λ_max=70.1851\n",
      "[SGD | lr=0.1] Iter 43100: loss=0.0065\n",
      "[SGD | lr=0.1] Epoch 2694/4000: train_loss=0.0066  test_loss=4.3222  λ_max=72.1057\n",
      "[SGD | lr=0.1] Epoch 2695/4000: train_loss=0.0066  test_loss=4.3225  λ_max=72.3660\n",
      "[SGD | lr=0.1] Epoch 2696/4000: train_loss=0.0065  test_loss=4.3227  λ_max=72.6433\n",
      "[SGD | lr=0.1] Epoch 2697/4000: train_loss=0.0065  test_loss=4.3230  λ_max=70.0602\n",
      "[SGD | lr=0.1] Epoch 2698/4000: train_loss=0.0065  test_loss=4.3232  λ_max=68.0938\n",
      "[SGD | lr=0.1] Epoch 2699/4000: train_loss=0.0065  test_loss=4.3235  λ_max=72.6018\n",
      "[SGD | lr=0.1] Iter 43200: loss=0.0066\n",
      "[SGD | lr=0.1] Epoch 2700/4000: train_loss=0.0065  test_loss=4.3239  λ_max=70.3659\n",
      "[SGD | lr=0.1] Epoch 2701/4000: train_loss=0.0065  test_loss=4.3241  λ_max=69.9051\n",
      "[SGD | lr=0.1] Epoch 2702/4000: train_loss=0.0065  test_loss=4.3243  λ_max=71.2180\n",
      "[SGD | lr=0.1] Epoch 2703/4000: train_loss=0.0065  test_loss=4.3246  λ_max=71.1591\n",
      "[SGD | lr=0.1] Epoch 2704/4000: train_loss=0.0065  test_loss=4.3249  λ_max=68.5179\n",
      "[SGD | lr=0.1] Epoch 2705/4000: train_loss=0.0065  test_loss=4.3252  λ_max=69.6440\n",
      "[SGD | lr=0.1] Epoch 2706/4000: train_loss=0.0065  test_loss=4.3256  λ_max=68.5888\n",
      "[SGD | lr=0.1] Iter 43300: loss=0.0066\n",
      "[SGD | lr=0.1] Epoch 2707/4000: train_loss=0.0065  test_loss=4.3256  λ_max=69.4023\n",
      "[SGD | lr=0.1] Epoch 2708/4000: train_loss=0.0065  test_loss=4.3260  λ_max=72.4585\n",
      "[SGD | lr=0.1] Epoch 2709/4000: train_loss=0.0065  test_loss=4.3263  λ_max=70.4318\n",
      "[SGD | lr=0.1] Epoch 2710/4000: train_loss=0.0065  test_loss=4.3265  λ_max=70.8164\n",
      "[SGD | lr=0.1] Epoch 2711/4000: train_loss=0.0065  test_loss=4.3268  λ_max=70.5433\n",
      "[SGD | lr=0.1] Epoch 2712/4000: train_loss=0.0065  test_loss=4.3271  λ_max=72.7674\n",
      "[SGD | lr=0.1] Iter 43400: loss=0.0064\n",
      "[SGD | lr=0.1] Epoch 2713/4000: train_loss=0.0065  test_loss=4.3274  λ_max=69.8148\n",
      "[SGD | lr=0.1] Epoch 2714/4000: train_loss=0.0065  test_loss=4.3275  λ_max=69.7935\n",
      "[SGD | lr=0.1] Epoch 2715/4000: train_loss=0.0065  test_loss=4.3278  λ_max=70.0493\n",
      "[SGD | lr=0.1] Epoch 2716/4000: train_loss=0.0065  test_loss=4.3280  λ_max=72.4374\n",
      "[SGD | lr=0.1] Epoch 2717/4000: train_loss=0.0065  test_loss=4.3282  λ_max=71.8652\n",
      "[SGD | lr=0.1] Epoch 2718/4000: train_loss=0.0065  test_loss=4.3287  λ_max=71.3502\n",
      "[SGD | lr=0.1] Iter 43500: loss=0.0064\n",
      "[SGD | lr=0.1] Epoch 2719/4000: train_loss=0.0065  test_loss=4.3290  λ_max=70.7254\n",
      "[SGD | lr=0.1] Epoch 2720/4000: train_loss=0.0065  test_loss=4.3293  λ_max=68.7271\n",
      "[SGD | lr=0.1] Epoch 2721/4000: train_loss=0.0065  test_loss=4.3293  λ_max=70.7032\n",
      "[SGD | lr=0.1] Epoch 2722/4000: train_loss=0.0065  test_loss=4.3296  λ_max=68.6072\n",
      "[SGD | lr=0.1] Epoch 2723/4000: train_loss=0.0065  test_loss=4.3299  λ_max=72.8474\n",
      "[SGD | lr=0.1] Epoch 2724/4000: train_loss=0.0065  test_loss=4.3302  λ_max=69.4945\n",
      "[SGD | lr=0.1] Iter 43600: loss=0.0063\n",
      "[SGD | lr=0.1] Epoch 2725/4000: train_loss=0.0065  test_loss=4.3305  λ_max=71.7880\n",
      "[SGD | lr=0.1] Epoch 2726/4000: train_loss=0.0065  test_loss=4.3308  λ_max=70.6851\n",
      "[SGD | lr=0.1] Epoch 2727/4000: train_loss=0.0064  test_loss=4.3310  λ_max=69.8612\n",
      "[SGD | lr=0.1] Epoch 2728/4000: train_loss=0.0064  test_loss=4.3312  λ_max=69.6223\n",
      "[SGD | lr=0.1] Epoch 2729/4000: train_loss=0.0064  test_loss=4.3316  λ_max=71.2330\n",
      "[SGD | lr=0.1] Epoch 2730/4000: train_loss=0.0064  test_loss=4.3318  λ_max=70.2107\n",
      "[SGD | lr=0.1] Epoch 2731/4000: train_loss=0.0064  test_loss=4.3320  λ_max=71.0455\n",
      "[SGD | lr=0.1] Iter 43700: loss=0.0066\n",
      "[SGD | lr=0.1] Epoch 2732/4000: train_loss=0.0064  test_loss=4.3322  λ_max=69.6876\n",
      "[SGD | lr=0.1] Epoch 2733/4000: train_loss=0.0064  test_loss=4.3326  λ_max=69.7412\n",
      "[SGD | lr=0.1] Epoch 2734/4000: train_loss=0.0064  test_loss=4.3329  λ_max=72.1883\n",
      "[SGD | lr=0.1] Epoch 2735/4000: train_loss=0.0064  test_loss=4.3330  λ_max=73.1554\n",
      "[SGD | lr=0.1] Epoch 2736/4000: train_loss=0.0064  test_loss=4.3334  λ_max=69.8276\n",
      "[SGD | lr=0.1] Epoch 2737/4000: train_loss=0.0064  test_loss=4.3335  λ_max=71.7223\n",
      "[SGD | lr=0.1] Iter 43800: loss=0.0063\n",
      "[SGD | lr=0.1] Epoch 2738/4000: train_loss=0.0064  test_loss=4.3339  λ_max=72.3895\n",
      "[SGD | lr=0.1] Epoch 2739/4000: train_loss=0.0064  test_loss=4.3342  λ_max=68.8501\n",
      "[SGD | lr=0.1] Epoch 2740/4000: train_loss=0.0064  test_loss=4.3343  λ_max=71.5553\n",
      "[SGD | lr=0.1] Epoch 2741/4000: train_loss=0.0064  test_loss=4.3347  λ_max=70.2544\n",
      "[SGD | lr=0.1] Epoch 2742/4000: train_loss=0.0064  test_loss=4.3350  λ_max=70.6993\n",
      "[SGD | lr=0.1] Epoch 2743/4000: train_loss=0.0064  test_loss=4.3352  λ_max=70.4339\n",
      "[SGD | lr=0.1] Iter 43900: loss=0.0064\n",
      "[SGD | lr=0.1] Epoch 2744/4000: train_loss=0.0064  test_loss=4.3354  λ_max=70.5273\n",
      "[SGD | lr=0.1] Epoch 2745/4000: train_loss=0.0064  test_loss=4.3356  λ_max=71.1424\n",
      "[SGD | lr=0.1] Epoch 2746/4000: train_loss=0.0064  test_loss=4.3360  λ_max=73.7326\n",
      "[SGD | lr=0.1] Epoch 2747/4000: train_loss=0.0064  test_loss=4.3363  λ_max=72.1625\n",
      "[SGD | lr=0.1] Epoch 2748/4000: train_loss=0.0064  test_loss=4.3366  λ_max=72.6249\n",
      "[SGD | lr=0.1] Epoch 2749/4000: train_loss=0.0064  test_loss=4.3368  λ_max=69.0126\n",
      "[SGD | lr=0.1] Iter 44000: loss=0.0063\n",
      "[SGD | lr=0.1] Epoch 2750/4000: train_loss=0.0064  test_loss=4.3370  λ_max=70.9526\n",
      "[SGD | lr=0.1] Epoch 2751/4000: train_loss=0.0064  test_loss=4.3373  λ_max=72.3268\n",
      "[SGD | lr=0.1] Epoch 2752/4000: train_loss=0.0064  test_loss=4.3376  λ_max=70.4727\n",
      "[SGD | lr=0.1] Epoch 2753/4000: train_loss=0.0064  test_loss=4.3377  λ_max=71.9204\n",
      "[SGD | lr=0.1] Epoch 2754/4000: train_loss=0.0064  test_loss=4.3380  λ_max=69.8983\n",
      "[SGD | lr=0.1] Epoch 2755/4000: train_loss=0.0064  test_loss=4.3384  λ_max=70.1194\n",
      "[SGD | lr=0.1] Epoch 2756/4000: train_loss=0.0064  test_loss=4.3387  λ_max=71.0290\n",
      "[SGD | lr=0.1] Iter 44100: loss=0.0062\n",
      "[SGD | lr=0.1] Epoch 2757/4000: train_loss=0.0063  test_loss=4.3390  λ_max=71.8888\n",
      "[SGD | lr=0.1] Epoch 2758/4000: train_loss=0.0063  test_loss=4.3392  λ_max=69.5318\n",
      "[SGD | lr=0.1] Epoch 2759/4000: train_loss=0.0063  test_loss=4.3395  λ_max=71.4935\n",
      "[SGD | lr=0.1] Epoch 2760/4000: train_loss=0.0063  test_loss=4.3396  λ_max=70.8065\n",
      "[SGD | lr=0.1] Epoch 2761/4000: train_loss=0.0063  test_loss=4.3399  λ_max=72.1375\n",
      "[SGD | lr=0.1] Epoch 2762/4000: train_loss=0.0063  test_loss=4.3402  λ_max=71.8474\n",
      "[SGD | lr=0.1] Iter 44200: loss=0.0064\n",
      "[SGD | lr=0.1] Epoch 2763/4000: train_loss=0.0063  test_loss=4.3405  λ_max=71.3284\n",
      "[SGD | lr=0.1] Epoch 2764/4000: train_loss=0.0063  test_loss=4.3408  λ_max=72.8482\n",
      "[SGD | lr=0.1] Epoch 2765/4000: train_loss=0.0063  test_loss=4.3408  λ_max=72.8172\n",
      "[SGD | lr=0.1] Epoch 2766/4000: train_loss=0.0063  test_loss=4.3412  λ_max=73.5638\n",
      "[SGD | lr=0.1] Epoch 2767/4000: train_loss=0.0063  test_loss=4.3414  λ_max=71.7062\n",
      "[SGD | lr=0.1] Epoch 2768/4000: train_loss=0.0063  test_loss=4.3417  λ_max=72.7355\n",
      "[SGD | lr=0.1] Iter 44300: loss=0.0063\n",
      "[SGD | lr=0.1] Epoch 2769/4000: train_loss=0.0063  test_loss=4.3421  λ_max=72.8760\n",
      "[SGD | lr=0.1] Epoch 2770/4000: train_loss=0.0063  test_loss=4.3422  λ_max=71.1717\n",
      "[SGD | lr=0.1] Epoch 2771/4000: train_loss=0.0063  test_loss=4.3425  λ_max=71.2441\n",
      "[SGD | lr=0.1] Epoch 2772/4000: train_loss=0.0063  test_loss=4.3427  λ_max=69.9778\n",
      "[SGD | lr=0.1] Epoch 2773/4000: train_loss=0.0063  test_loss=4.3430  λ_max=70.3377\n",
      "[SGD | lr=0.1] Epoch 2774/4000: train_loss=0.0063  test_loss=4.3433  λ_max=71.3794\n",
      "[SGD | lr=0.1] Iter 44400: loss=0.0062\n",
      "[SGD | lr=0.1] Epoch 2775/4000: train_loss=0.0063  test_loss=4.3435  λ_max=68.8335\n",
      "[SGD | lr=0.1] Epoch 2776/4000: train_loss=0.0063  test_loss=4.3438  λ_max=69.4664\n",
      "[SGD | lr=0.1] Epoch 2777/4000: train_loss=0.0063  test_loss=4.3440  λ_max=70.8870\n",
      "[SGD | lr=0.1] Epoch 2778/4000: train_loss=0.0063  test_loss=4.3443  λ_max=71.8853\n",
      "[SGD | lr=0.1] Epoch 2779/4000: train_loss=0.0063  test_loss=4.3447  λ_max=68.8521\n",
      "[SGD | lr=0.1] Epoch 2780/4000: train_loss=0.0063  test_loss=4.3448  λ_max=71.2286\n",
      "[SGD | lr=0.1] Epoch 2781/4000: train_loss=0.0063  test_loss=4.3451  λ_max=69.4554\n",
      "[SGD | lr=0.1] Iter 44500: loss=0.0063\n",
      "[SGD | lr=0.1] Epoch 2782/4000: train_loss=0.0063  test_loss=4.3453  λ_max=71.2321\n",
      "[SGD | lr=0.1] Epoch 2783/4000: train_loss=0.0063  test_loss=4.3455  λ_max=71.3566\n",
      "[SGD | lr=0.1] Epoch 2784/4000: train_loss=0.0063  test_loss=4.3459  λ_max=70.7215\n",
      "[SGD | lr=0.1] Epoch 2785/4000: train_loss=0.0063  test_loss=4.3461  λ_max=73.7431\n",
      "[SGD | lr=0.1] Epoch 2786/4000: train_loss=0.0063  test_loss=4.3462  λ_max=70.5331\n",
      "[SGD | lr=0.1] Epoch 2787/4000: train_loss=0.0063  test_loss=4.3466  λ_max=73.2014\n",
      "[SGD | lr=0.1] Iter 44600: loss=0.0063\n",
      "[SGD | lr=0.1] Epoch 2788/4000: train_loss=0.0063  test_loss=4.3469  λ_max=69.6555\n",
      "[SGD | lr=0.1] Epoch 2789/4000: train_loss=0.0063  test_loss=4.3471  λ_max=69.3616\n",
      "[SGD | lr=0.1] Epoch 2790/4000: train_loss=0.0063  test_loss=4.3473  λ_max=73.5064\n",
      "[SGD | lr=0.1] Epoch 2791/4000: train_loss=0.0062  test_loss=4.3476  λ_max=70.0254\n",
      "[SGD | lr=0.1] Epoch 2792/4000: train_loss=0.0062  test_loss=4.3478  λ_max=72.3370\n",
      "[SGD | lr=0.1] Epoch 2793/4000: train_loss=0.0062  test_loss=4.3480  λ_max=70.3754\n",
      "[SGD | lr=0.1] Iter 44700: loss=0.0063\n",
      "[SGD | lr=0.1] Epoch 2794/4000: train_loss=0.0062  test_loss=4.3484  λ_max=70.6300\n",
      "[SGD | lr=0.1] Epoch 2795/4000: train_loss=0.0062  test_loss=4.3486  λ_max=71.7908\n",
      "[SGD | lr=0.1] Epoch 2796/4000: train_loss=0.0062  test_loss=4.3488  λ_max=71.6242\n",
      "[SGD | lr=0.1] Epoch 2797/4000: train_loss=0.0062  test_loss=4.3492  λ_max=73.0448\n",
      "[SGD | lr=0.1] Epoch 2798/4000: train_loss=0.0062  test_loss=4.3495  λ_max=70.3190\n",
      "[SGD | lr=0.1] Epoch 2799/4000: train_loss=0.0062  test_loss=4.3497  λ_max=72.6827\n",
      "[SGD | lr=0.1] Iter 44800: loss=0.0061\n",
      "[SGD | lr=0.1] Epoch 2800/4000: train_loss=0.0062  test_loss=4.3499  λ_max=69.5356\n",
      "[SGD | lr=0.1] Epoch 2801/4000: train_loss=0.0062  test_loss=4.3502  λ_max=73.2243\n",
      "[SGD | lr=0.1] Epoch 2802/4000: train_loss=0.0062  test_loss=4.3505  λ_max=71.7603\n",
      "[SGD | lr=0.1] Epoch 2803/4000: train_loss=0.0062  test_loss=4.3507  λ_max=70.3956\n",
      "[SGD | lr=0.1] Epoch 2804/4000: train_loss=0.0062  test_loss=4.3510  λ_max=72.5079\n",
      "[SGD | lr=0.1] Epoch 2805/4000: train_loss=0.0062  test_loss=4.3512  λ_max=70.6736\n",
      "[SGD | lr=0.1] Epoch 2806/4000: train_loss=0.0062  test_loss=4.3516  λ_max=72.1183\n",
      "[SGD | lr=0.1] Iter 44900: loss=0.0061\n",
      "[SGD | lr=0.1] Epoch 2807/4000: train_loss=0.0062  test_loss=4.3519  λ_max=73.4295\n",
      "[SGD | lr=0.1] Epoch 2808/4000: train_loss=0.0062  test_loss=4.3521  λ_max=70.9258\n",
      "[SGD | lr=0.1] Epoch 2809/4000: train_loss=0.0062  test_loss=4.3523  λ_max=70.7308\n",
      "[SGD | lr=0.1] Epoch 2810/4000: train_loss=0.0062  test_loss=4.3525  λ_max=71.1806\n",
      "[SGD | lr=0.1] Epoch 2811/4000: train_loss=0.0062  test_loss=4.3530  λ_max=72.4679\n",
      "[SGD | lr=0.1] Epoch 2812/4000: train_loss=0.0062  test_loss=4.3530  λ_max=72.5726\n",
      "[SGD | lr=0.1] Iter 45000: loss=0.0061\n",
      "[SGD | lr=0.1] Epoch 2813/4000: train_loss=0.0062  test_loss=4.3535  λ_max=69.6194\n",
      "[SGD | lr=0.1] Epoch 2814/4000: train_loss=0.0062  test_loss=4.3535  λ_max=70.9035\n",
      "[SGD | lr=0.1] Epoch 2815/4000: train_loss=0.0062  test_loss=4.3538  λ_max=71.2594\n",
      "[SGD | lr=0.1] Epoch 2816/4000: train_loss=0.0062  test_loss=4.3540  λ_max=72.4996\n",
      "[SGD | lr=0.1] Epoch 2817/4000: train_loss=0.0062  test_loss=4.3543  λ_max=72.6635\n",
      "[SGD | lr=0.1] Epoch 2818/4000: train_loss=0.0062  test_loss=4.3545  λ_max=70.6576\n",
      "[SGD | lr=0.1] Iter 45100: loss=0.0062\n",
      "[SGD | lr=0.1] Epoch 2819/4000: train_loss=0.0062  test_loss=4.3549  λ_max=71.7550\n",
      "[SGD | lr=0.1] Epoch 2820/4000: train_loss=0.0062  test_loss=4.3549  λ_max=69.8338\n",
      "[SGD | lr=0.1] Epoch 2821/4000: train_loss=0.0062  test_loss=4.3553  λ_max=72.5561\n",
      "[SGD | lr=0.1] Epoch 2822/4000: train_loss=0.0062  test_loss=4.3556  λ_max=72.3119\n",
      "[SGD | lr=0.1] Epoch 2823/4000: train_loss=0.0062  test_loss=4.3560  λ_max=71.0104\n",
      "[SGD | lr=0.1] Epoch 2824/4000: train_loss=0.0062  test_loss=4.3561  λ_max=69.8158\n",
      "[SGD | lr=0.1] Iter 45200: loss=0.0062\n",
      "[SGD | lr=0.1] Epoch 2825/4000: train_loss=0.0061  test_loss=4.3563  λ_max=70.9096\n",
      "[SGD | lr=0.1] Epoch 2826/4000: train_loss=0.0061  test_loss=4.3565  λ_max=72.6576\n",
      "[SGD | lr=0.1] Epoch 2827/4000: train_loss=0.0061  test_loss=4.3569  λ_max=69.9968\n",
      "[SGD | lr=0.1] Epoch 2828/4000: train_loss=0.0061  test_loss=4.3571  λ_max=70.4966\n",
      "[SGD | lr=0.1] Epoch 2829/4000: train_loss=0.0061  test_loss=4.3575  λ_max=71.3355\n",
      "[SGD | lr=0.1] Epoch 2830/4000: train_loss=0.0061  test_loss=4.3577  λ_max=71.5626\n",
      "[SGD | lr=0.1] Epoch 2831/4000: train_loss=0.0061  test_loss=4.3579  λ_max=70.5655\n",
      "[SGD | lr=0.1] Iter 45300: loss=0.0062\n",
      "[SGD | lr=0.1] Epoch 2832/4000: train_loss=0.0061  test_loss=4.3581  λ_max=69.1780\n",
      "[SGD | lr=0.1] Epoch 2833/4000: train_loss=0.0061  test_loss=4.3583  λ_max=71.2693\n",
      "[SGD | lr=0.1] Epoch 2834/4000: train_loss=0.0061  test_loss=4.3586  λ_max=73.1498\n",
      "[SGD | lr=0.1] Epoch 2835/4000: train_loss=0.0061  test_loss=4.3588  λ_max=70.7664\n",
      "[SGD | lr=0.1] Epoch 2836/4000: train_loss=0.0061  test_loss=4.3591  λ_max=71.5303\n",
      "[SGD | lr=0.1] Epoch 2837/4000: train_loss=0.0061  test_loss=4.3593  λ_max=71.5418\n",
      "[SGD | lr=0.1] Iter 45400: loss=0.0061\n",
      "[SGD | lr=0.1] Epoch 2838/4000: train_loss=0.0061  test_loss=4.3597  λ_max=74.4717\n",
      "[SGD | lr=0.1] Epoch 2839/4000: train_loss=0.0061  test_loss=4.3600  λ_max=69.2150\n",
      "[SGD | lr=0.1] Epoch 2840/4000: train_loss=0.0061  test_loss=4.3602  λ_max=71.8672\n",
      "[SGD | lr=0.1] Epoch 2841/4000: train_loss=0.0061  test_loss=4.3604  λ_max=69.4144\n",
      "[SGD | lr=0.1] Epoch 2842/4000: train_loss=0.0061  test_loss=4.3608  λ_max=71.3316\n",
      "[SGD | lr=0.1] Epoch 2843/4000: train_loss=0.0061  test_loss=4.3609  λ_max=69.6961\n",
      "[SGD | lr=0.1] Iter 45500: loss=0.0061\n",
      "[SGD | lr=0.1] Epoch 2844/4000: train_loss=0.0061  test_loss=4.3611  λ_max=72.3740\n",
      "[SGD | lr=0.1] Epoch 2845/4000: train_loss=0.0061  test_loss=4.3614  λ_max=72.1180\n",
      "[SGD | lr=0.1] Epoch 2846/4000: train_loss=0.0061  test_loss=4.3616  λ_max=71.8025\n",
      "[SGD | lr=0.1] Epoch 2847/4000: train_loss=0.0061  test_loss=4.3619  λ_max=71.5087\n",
      "[SGD | lr=0.1] Epoch 2848/4000: train_loss=0.0061  test_loss=4.3621  λ_max=71.5504\n",
      "[SGD | lr=0.1] Epoch 2849/4000: train_loss=0.0061  test_loss=4.3624  λ_max=72.3033\n",
      "[SGD | lr=0.1] Iter 45600: loss=0.0062\n",
      "[SGD | lr=0.1] Epoch 2850/4000: train_loss=0.0061  test_loss=4.3627  λ_max=71.1602\n",
      "[SGD | lr=0.1] Epoch 2851/4000: train_loss=0.0061  test_loss=4.3629  λ_max=70.4129\n",
      "[SGD | lr=0.1] Epoch 2852/4000: train_loss=0.0061  test_loss=4.3632  λ_max=73.2092\n",
      "[SGD | lr=0.1] Epoch 2853/4000: train_loss=0.0061  test_loss=4.3635  λ_max=71.2617\n",
      "[SGD | lr=0.1] Epoch 2854/4000: train_loss=0.0061  test_loss=4.3638  λ_max=70.6508\n",
      "[SGD | lr=0.1] Epoch 2855/4000: train_loss=0.0061  test_loss=4.3640  λ_max=74.3908\n",
      "[SGD | lr=0.1] Epoch 2856/4000: train_loss=0.0061  test_loss=4.3643  λ_max=70.8319\n",
      "[SGD | lr=0.1] Iter 45700: loss=0.0060\n",
      "[SGD | lr=0.1] Epoch 2857/4000: train_loss=0.0061  test_loss=4.3644  λ_max=73.4826\n",
      "[SGD | lr=0.1] Epoch 2858/4000: train_loss=0.0061  test_loss=4.3646  λ_max=72.3374\n",
      "[SGD | lr=0.1] Epoch 2859/4000: train_loss=0.0061  test_loss=4.3649  λ_max=70.6285\n",
      "[SGD | lr=0.1] Epoch 2860/4000: train_loss=0.0060  test_loss=4.3652  λ_max=71.6643\n",
      "[SGD | lr=0.1] Epoch 2861/4000: train_loss=0.0060  test_loss=4.3654  λ_max=70.8058\n",
      "[SGD | lr=0.1] Epoch 2862/4000: train_loss=0.0060  test_loss=4.3657  λ_max=72.5763\n",
      "[SGD | lr=0.1] Iter 45800: loss=0.0060\n",
      "[SGD | lr=0.1] Epoch 2863/4000: train_loss=0.0060  test_loss=4.3660  λ_max=72.7576\n",
      "[SGD | lr=0.1] Epoch 2864/4000: train_loss=0.0060  test_loss=4.3662  λ_max=72.9403\n",
      "[SGD | lr=0.1] Epoch 2865/4000: train_loss=0.0060  test_loss=4.3664  λ_max=69.9690\n",
      "[SGD | lr=0.1] Epoch 2866/4000: train_loss=0.0060  test_loss=4.3666  λ_max=71.8707\n",
      "[SGD | lr=0.1] Epoch 2867/4000: train_loss=0.0060  test_loss=4.3670  λ_max=70.1196\n",
      "[SGD | lr=0.1] Epoch 2868/4000: train_loss=0.0060  test_loss=4.3672  λ_max=72.2152\n",
      "[SGD | lr=0.1] Iter 45900: loss=0.0059\n",
      "[SGD | lr=0.1] Epoch 2869/4000: train_loss=0.0060  test_loss=4.3675  λ_max=71.6797\n",
      "[SGD | lr=0.1] Epoch 2870/4000: train_loss=0.0060  test_loss=4.3678  λ_max=72.1329\n",
      "[SGD | lr=0.1] Epoch 2871/4000: train_loss=0.0060  test_loss=4.3679  λ_max=72.7045\n",
      "[SGD | lr=0.1] Epoch 2872/4000: train_loss=0.0060  test_loss=4.3683  λ_max=70.9039\n",
      "[SGD | lr=0.1] Epoch 2873/4000: train_loss=0.0060  test_loss=4.3684  λ_max=72.3779\n",
      "[SGD | lr=0.1] Epoch 2874/4000: train_loss=0.0060  test_loss=4.3686  λ_max=70.6922\n",
      "[SGD | lr=0.1] Iter 46000: loss=0.0062\n",
      "[SGD | lr=0.1] Epoch 2875/4000: train_loss=0.0060  test_loss=4.3690  λ_max=71.4622\n",
      "[SGD | lr=0.1] Epoch 2876/4000: train_loss=0.0060  test_loss=4.3693  λ_max=71.9990\n",
      "[SGD | lr=0.1] Epoch 2877/4000: train_loss=0.0060  test_loss=4.3694  λ_max=71.7090\n",
      "[SGD | lr=0.1] Epoch 2878/4000: train_loss=0.0060  test_loss=4.3696  λ_max=74.7077\n",
      "[SGD | lr=0.1] Epoch 2879/4000: train_loss=0.0060  test_loss=4.3699  λ_max=70.3088\n",
      "[SGD | lr=0.1] Epoch 2880/4000: train_loss=0.0060  test_loss=4.3700  λ_max=73.6745\n",
      "[SGD | lr=0.1] Epoch 2881/4000: train_loss=0.0060  test_loss=4.3704  λ_max=70.3778\n",
      "[SGD | lr=0.1] Iter 46100: loss=0.0060\n",
      "[SGD | lr=0.1] Epoch 2882/4000: train_loss=0.0060  test_loss=4.3705  λ_max=72.0709\n",
      "[SGD | lr=0.1] Epoch 2883/4000: train_loss=0.0060  test_loss=4.3709  λ_max=73.2089\n",
      "[SGD | lr=0.1] Epoch 2884/4000: train_loss=0.0060  test_loss=4.3712  λ_max=73.1768\n",
      "[SGD | lr=0.1] Epoch 2885/4000: train_loss=0.0060  test_loss=4.3715  λ_max=70.8571\n",
      "[SGD | lr=0.1] Epoch 2886/4000: train_loss=0.0060  test_loss=4.3717  λ_max=70.9261\n",
      "[SGD | lr=0.1] Epoch 2887/4000: train_loss=0.0060  test_loss=4.3718  λ_max=70.6579\n",
      "[SGD | lr=0.1] Iter 46200: loss=0.0060\n",
      "[SGD | lr=0.1] Epoch 2888/4000: train_loss=0.0060  test_loss=4.3722  λ_max=71.2045\n",
      "[SGD | lr=0.1] Epoch 2889/4000: train_loss=0.0060  test_loss=4.3724  λ_max=69.1058\n",
      "[SGD | lr=0.1] Epoch 2890/4000: train_loss=0.0060  test_loss=4.3727  λ_max=69.8246\n",
      "[SGD | lr=0.1] Epoch 2891/4000: train_loss=0.0060  test_loss=4.3729  λ_max=74.3771\n",
      "[SGD | lr=0.1] Epoch 2892/4000: train_loss=0.0060  test_loss=4.3732  λ_max=72.5411\n",
      "[SGD | lr=0.1] Epoch 2893/4000: train_loss=0.0060  test_loss=4.3734  λ_max=71.0978\n",
      "[SGD | lr=0.1] Iter 46300: loss=0.0061\n",
      "[SGD | lr=0.1] Epoch 2894/4000: train_loss=0.0060  test_loss=4.3736  λ_max=66.6717\n",
      "[SGD | lr=0.1] Epoch 2895/4000: train_loss=0.0060  test_loss=4.3738  λ_max=72.9368\n",
      "[SGD | lr=0.1] Epoch 2896/4000: train_loss=0.0059  test_loss=4.3742  λ_max=71.7375\n",
      "[SGD | lr=0.1] Epoch 2897/4000: train_loss=0.0059  test_loss=4.3744  λ_max=70.0147\n",
      "[SGD | lr=0.1] Epoch 2898/4000: train_loss=0.0059  test_loss=4.3746  λ_max=74.0792\n",
      "[SGD | lr=0.1] Epoch 2899/4000: train_loss=0.0059  test_loss=4.3750  λ_max=69.1922\n",
      "[SGD | lr=0.1] Iter 46400: loss=0.0060\n",
      "[SGD | lr=0.1] Epoch 2900/4000: train_loss=0.0059  test_loss=4.3751  λ_max=71.4913\n",
      "[SGD | lr=0.1] Epoch 2901/4000: train_loss=0.0059  test_loss=4.3754  λ_max=72.5231\n",
      "[SGD | lr=0.1] Epoch 2902/4000: train_loss=0.0059  test_loss=4.3756  λ_max=72.6675\n",
      "[SGD | lr=0.1] Epoch 2903/4000: train_loss=0.0059  test_loss=4.3758  λ_max=72.6638\n",
      "[SGD | lr=0.1] Epoch 2904/4000: train_loss=0.0059  test_loss=4.3760  λ_max=73.1794\n",
      "[SGD | lr=0.1] Epoch 2905/4000: train_loss=0.0059  test_loss=4.3764  λ_max=71.8815\n",
      "[SGD | lr=0.1] Epoch 2906/4000: train_loss=0.0059  test_loss=4.3767  λ_max=72.2095\n",
      "[SGD | lr=0.1] Iter 46500: loss=0.0059\n",
      "[SGD | lr=0.1] Epoch 2907/4000: train_loss=0.0059  test_loss=4.3768  λ_max=72.1663\n",
      "[SGD | lr=0.1] Epoch 2908/4000: train_loss=0.0059  test_loss=4.3772  λ_max=73.9372\n",
      "[SGD | lr=0.1] Epoch 2909/4000: train_loss=0.0059  test_loss=4.3774  λ_max=71.3764\n",
      "[SGD | lr=0.1] Epoch 2910/4000: train_loss=0.0059  test_loss=4.3776  λ_max=72.5912\n",
      "[SGD | lr=0.1] Epoch 2911/4000: train_loss=0.0059  test_loss=4.3779  λ_max=73.7143\n",
      "[SGD | lr=0.1] Epoch 2912/4000: train_loss=0.0059  test_loss=4.3781  λ_max=69.5704\n",
      "[SGD | lr=0.1] Iter 46600: loss=0.0061\n",
      "[SGD | lr=0.1] Epoch 2913/4000: train_loss=0.0059  test_loss=4.3782  λ_max=71.7753\n",
      "[SGD | lr=0.1] Epoch 2914/4000: train_loss=0.0059  test_loss=4.3788  λ_max=72.2824\n",
      "[SGD | lr=0.1] Epoch 2915/4000: train_loss=0.0059  test_loss=4.3787  λ_max=71.6666\n",
      "[SGD | lr=0.1] Epoch 2916/4000: train_loss=0.0059  test_loss=4.3791  λ_max=71.9605\n",
      "[SGD | lr=0.1] Epoch 2917/4000: train_loss=0.0059  test_loss=4.3793  λ_max=71.9139\n",
      "[SGD | lr=0.1] Epoch 2918/4000: train_loss=0.0059  test_loss=4.3794  λ_max=71.6546\n",
      "[SGD | lr=0.1] Iter 46700: loss=0.0059\n",
      "[SGD | lr=0.1] Epoch 2919/4000: train_loss=0.0059  test_loss=4.3800  λ_max=73.5295\n",
      "[SGD | lr=0.1] Epoch 2920/4000: train_loss=0.0059  test_loss=4.3801  λ_max=72.5617\n",
      "[SGD | lr=0.1] Epoch 2921/4000: train_loss=0.0059  test_loss=4.3804  λ_max=71.6567\n",
      "[SGD | lr=0.1] Epoch 2922/4000: train_loss=0.0059  test_loss=4.3805  λ_max=72.5559\n",
      "[SGD | lr=0.1] Epoch 2923/4000: train_loss=0.0059  test_loss=4.3808  λ_max=73.3114\n",
      "[SGD | lr=0.1] Epoch 2924/4000: train_loss=0.0059  test_loss=4.3810  λ_max=70.6636\n",
      "[SGD | lr=0.1] Iter 46800: loss=0.0060\n",
      "[SGD | lr=0.1] Epoch 2925/4000: train_loss=0.0059  test_loss=4.3812  λ_max=72.2580\n",
      "[SGD | lr=0.1] Epoch 2926/4000: train_loss=0.0059  test_loss=4.3816  λ_max=73.2006\n",
      "[SGD | lr=0.1] Epoch 2927/4000: train_loss=0.0059  test_loss=4.3818  λ_max=71.4969\n",
      "[SGD | lr=0.1] Epoch 2928/4000: train_loss=0.0059  test_loss=4.3820  λ_max=70.8233\n",
      "[SGD | lr=0.1] Epoch 2929/4000: train_loss=0.0059  test_loss=4.3823  λ_max=69.4998\n",
      "[SGD | lr=0.1] Epoch 2930/4000: train_loss=0.0059  test_loss=4.3824  λ_max=71.1899\n",
      "[SGD | lr=0.1] Epoch 2931/4000: train_loss=0.0059  test_loss=4.3828  λ_max=73.8796\n",
      "[SGD | lr=0.1] Iter 46900: loss=0.0058\n",
      "[SGD | lr=0.1] Epoch 2932/4000: train_loss=0.0059  test_loss=4.3830  λ_max=71.0822\n",
      "[SGD | lr=0.1] Epoch 2933/4000: train_loss=0.0058  test_loss=4.3833  λ_max=73.2507\n",
      "[SGD | lr=0.1] Epoch 2934/4000: train_loss=0.0058  test_loss=4.3834  λ_max=73.8591\n",
      "[SGD | lr=0.1] Epoch 2935/4000: train_loss=0.0058  test_loss=4.3837  λ_max=71.5969\n",
      "[SGD | lr=0.1] Epoch 2936/4000: train_loss=0.0058  test_loss=4.3839  λ_max=74.1301\n",
      "[SGD | lr=0.1] Epoch 2937/4000: train_loss=0.0058  test_loss=4.3841  λ_max=72.1933\n",
      "[SGD | lr=0.1] Iter 47000: loss=0.0057\n",
      "[SGD | lr=0.1] Epoch 2938/4000: train_loss=0.0058  test_loss=4.3845  λ_max=73.4457\n",
      "[SGD | lr=0.1] Epoch 2939/4000: train_loss=0.0058  test_loss=4.3847  λ_max=74.3423\n",
      "[SGD | lr=0.1] Epoch 2940/4000: train_loss=0.0058  test_loss=4.3849  λ_max=71.8913\n",
      "[SGD | lr=0.1] Epoch 2941/4000: train_loss=0.0058  test_loss=4.3852  λ_max=74.3587\n",
      "[SGD | lr=0.1] Epoch 2942/4000: train_loss=0.0058  test_loss=4.3855  λ_max=72.1543\n",
      "[SGD | lr=0.1] Epoch 2943/4000: train_loss=0.0058  test_loss=4.3856  λ_max=70.7729\n",
      "[SGD | lr=0.1] Iter 47100: loss=0.0058\n",
      "[SGD | lr=0.1] Epoch 2944/4000: train_loss=0.0058  test_loss=4.3858  λ_max=71.6306\n",
      "[SGD | lr=0.1] Epoch 2945/4000: train_loss=0.0058  test_loss=4.3861  λ_max=70.2044\n",
      "[SGD | lr=0.1] Epoch 2946/4000: train_loss=0.0058  test_loss=4.3864  λ_max=70.5712\n",
      "[SGD | lr=0.1] Epoch 2947/4000: train_loss=0.0058  test_loss=4.3867  λ_max=73.7466\n",
      "[SGD | lr=0.1] Epoch 2948/4000: train_loss=0.0058  test_loss=4.3868  λ_max=71.5901\n",
      "[SGD | lr=0.1] Epoch 2949/4000: train_loss=0.0058  test_loss=4.3870  λ_max=72.3365\n",
      "[SGD | lr=0.1] Iter 47200: loss=0.0058\n",
      "[SGD | lr=0.1] Epoch 2950/4000: train_loss=0.0058  test_loss=4.3874  λ_max=73.8609\n",
      "[SGD | lr=0.1] Epoch 2951/4000: train_loss=0.0058  test_loss=4.3876  λ_max=71.2656\n",
      "[SGD | lr=0.1] Epoch 2952/4000: train_loss=0.0058  test_loss=4.3878  λ_max=72.7518\n",
      "[SGD | lr=0.1] Epoch 2953/4000: train_loss=0.0058  test_loss=4.3881  λ_max=71.6689\n",
      "[SGD | lr=0.1] Epoch 2954/4000: train_loss=0.0058  test_loss=4.3882  λ_max=73.2421\n",
      "[SGD | lr=0.1] Epoch 2955/4000: train_loss=0.0058  test_loss=4.3887  λ_max=72.2676\n",
      "[SGD | lr=0.1] Epoch 2956/4000: train_loss=0.0058  test_loss=4.3887  λ_max=69.6215\n",
      "[SGD | lr=0.1] Iter 47300: loss=0.0058\n",
      "[SGD | lr=0.1] Epoch 2957/4000: train_loss=0.0058  test_loss=4.3890  λ_max=71.7300\n",
      "[SGD | lr=0.1] Epoch 2958/4000: train_loss=0.0058  test_loss=4.3892  λ_max=73.1446\n",
      "[SGD | lr=0.1] Epoch 2959/4000: train_loss=0.0058  test_loss=4.3895  λ_max=73.5251\n",
      "[SGD | lr=0.1] Epoch 2960/4000: train_loss=0.0058  test_loss=4.3897  λ_max=69.9433\n",
      "[SGD | lr=0.1] Epoch 2961/4000: train_loss=0.0058  test_loss=4.3900  λ_max=72.0898\n",
      "[SGD | lr=0.1] Epoch 2962/4000: train_loss=0.0058  test_loss=4.3902  λ_max=70.7924\n",
      "[SGD | lr=0.1] Iter 47400: loss=0.0057\n",
      "[SGD | lr=0.1] Epoch 2963/4000: train_loss=0.0058  test_loss=4.3905  λ_max=72.8600\n",
      "[SGD | lr=0.1] Epoch 2964/4000: train_loss=0.0058  test_loss=4.3907  λ_max=72.7923\n",
      "[SGD | lr=0.1] Epoch 2965/4000: train_loss=0.0058  test_loss=4.3909  λ_max=74.1909\n",
      "[SGD | lr=0.1] Epoch 2966/4000: train_loss=0.0058  test_loss=4.3911  λ_max=73.8126\n",
      "[SGD | lr=0.1] Epoch 2967/4000: train_loss=0.0058  test_loss=4.3914  λ_max=71.3376\n",
      "[SGD | lr=0.1] Epoch 2968/4000: train_loss=0.0058  test_loss=4.3916  λ_max=73.4481\n",
      "[SGD | lr=0.1] Iter 47500: loss=0.0058\n",
      "[SGD | lr=0.1] Epoch 2969/4000: train_loss=0.0058  test_loss=4.3919  λ_max=71.8194\n",
      "[SGD | lr=0.1] Epoch 2970/4000: train_loss=0.0058  test_loss=4.3921  λ_max=71.7530\n",
      "[SGD | lr=0.1] Epoch 2971/4000: train_loss=0.0057  test_loss=4.3924  λ_max=69.7751\n",
      "[SGD | lr=0.1] Epoch 2972/4000: train_loss=0.0057  test_loss=4.3928  λ_max=69.8784\n",
      "[SGD | lr=0.1] Epoch 2973/4000: train_loss=0.0057  test_loss=4.3929  λ_max=72.7155\n",
      "[SGD | lr=0.1] Epoch 2974/4000: train_loss=0.0057  test_loss=4.3932  λ_max=73.3368\n",
      "[SGD | lr=0.1] Iter 47600: loss=0.0057\n",
      "[SGD | lr=0.1] Epoch 2975/4000: train_loss=0.0057  test_loss=4.3933  λ_max=73.3383\n",
      "[SGD | lr=0.1] Epoch 2976/4000: train_loss=0.0057  test_loss=4.3936  λ_max=72.7725\n",
      "[SGD | lr=0.1] Epoch 2977/4000: train_loss=0.0057  test_loss=4.3938  λ_max=72.7770\n",
      "[SGD | lr=0.1] Epoch 2978/4000: train_loss=0.0057  test_loss=4.3941  λ_max=72.6517\n",
      "[SGD | lr=0.1] Epoch 2979/4000: train_loss=0.0057  test_loss=4.3942  λ_max=73.2762\n",
      "[SGD | lr=0.1] Epoch 2980/4000: train_loss=0.0057  test_loss=4.3945  λ_max=71.5314\n",
      "[SGD | lr=0.1] Epoch 2981/4000: train_loss=0.0057  test_loss=4.3948  λ_max=74.3713\n",
      "[SGD | lr=0.1] Iter 47700: loss=0.0057\n",
      "[SGD | lr=0.1] Epoch 2982/4000: train_loss=0.0057  test_loss=4.3951  λ_max=72.8618\n",
      "[SGD | lr=0.1] Epoch 2983/4000: train_loss=0.0057  test_loss=4.3951  λ_max=74.0074\n",
      "[SGD | lr=0.1] Epoch 2984/4000: train_loss=0.0057  test_loss=4.3955  λ_max=71.6947\n",
      "[SGD | lr=0.1] Epoch 2985/4000: train_loss=0.0057  test_loss=4.3958  λ_max=73.1760\n",
      "[SGD | lr=0.1] Epoch 2986/4000: train_loss=0.0057  test_loss=4.3960  λ_max=71.9467\n",
      "[SGD | lr=0.1] Epoch 2987/4000: train_loss=0.0057  test_loss=4.3962  λ_max=73.7022\n",
      "[SGD | lr=0.1] Iter 47800: loss=0.0057\n",
      "[SGD | lr=0.1] Epoch 2988/4000: train_loss=0.0057  test_loss=4.3965  λ_max=75.2874\n",
      "[SGD | lr=0.1] Epoch 2989/4000: train_loss=0.0057  test_loss=4.3969  λ_max=71.7828\n",
      "[SGD | lr=0.1] Epoch 2990/4000: train_loss=0.0057  test_loss=4.3970  λ_max=73.7993\n",
      "[SGD | lr=0.1] Epoch 2991/4000: train_loss=0.0057  test_loss=4.3971  λ_max=73.2578\n",
      "[SGD | lr=0.1] Epoch 2992/4000: train_loss=0.0057  test_loss=4.3975  λ_max=74.1843\n",
      "[SGD | lr=0.1] Epoch 2993/4000: train_loss=0.0057  test_loss=4.3976  λ_max=73.4821\n",
      "[SGD | lr=0.1] Iter 47900: loss=0.0057\n",
      "[SGD | lr=0.1] Epoch 2994/4000: train_loss=0.0057  test_loss=4.3979  λ_max=73.3599\n",
      "[SGD | lr=0.1] Epoch 2995/4000: train_loss=0.0057  test_loss=4.3981  λ_max=72.5642\n",
      "[SGD | lr=0.1] Epoch 2996/4000: train_loss=0.0057  test_loss=4.3982  λ_max=72.8976\n",
      "[SGD | lr=0.1] Epoch 2997/4000: train_loss=0.0057  test_loss=4.3985  λ_max=75.6810\n",
      "[SGD | lr=0.1] Epoch 2998/4000: train_loss=0.0057  test_loss=4.3988  λ_max=70.0080\n",
      "[SGD | lr=0.1] Epoch 2999/4000: train_loss=0.0057  test_loss=4.3993  λ_max=73.5752\n",
      "[SGD | lr=0.1] Iter 48000: loss=0.0057\n",
      "[SGD | lr=0.1] Epoch 3000/4000: train_loss=0.0057  test_loss=4.3994  λ_max=72.8175\n",
      "[SGD | lr=0.1] Epoch 3001/4000: train_loss=0.0057  test_loss=4.3996  λ_max=70.9921\n",
      "[SGD | lr=0.1] Epoch 3002/4000: train_loss=0.0057  test_loss=4.3998  λ_max=70.9695\n",
      "[SGD | lr=0.1] Epoch 3003/4000: train_loss=0.0057  test_loss=4.4001  λ_max=70.7242\n",
      "[SGD | lr=0.1] Epoch 3004/4000: train_loss=0.0057  test_loss=4.4001  λ_max=71.4670\n",
      "[SGD | lr=0.1] Epoch 3005/4000: train_loss=0.0057  test_loss=4.4005  λ_max=74.8764\n",
      "[SGD | lr=0.1] Epoch 3006/4000: train_loss=0.0057  test_loss=4.4007  λ_max=73.3810\n",
      "[SGD | lr=0.1] Iter 48100: loss=0.0057\n",
      "[SGD | lr=0.1] Epoch 3007/4000: train_loss=0.0057  test_loss=4.4009  λ_max=73.6027\n",
      "[SGD | lr=0.1] Epoch 3008/4000: train_loss=0.0057  test_loss=4.4013  λ_max=70.7456\n",
      "[SGD | lr=0.1] Epoch 3009/4000: train_loss=0.0057  test_loss=4.4014  λ_max=72.2112\n",
      "[SGD | lr=0.1] Epoch 3010/4000: train_loss=0.0057  test_loss=4.4018  λ_max=72.3731\n",
      "[SGD | lr=0.1] Epoch 3011/4000: train_loss=0.0057  test_loss=4.4019  λ_max=72.9231\n",
      "[SGD | lr=0.1] Epoch 3012/4000: train_loss=0.0056  test_loss=4.4021  λ_max=71.7580\n",
      "[SGD | lr=0.1] Iter 48200: loss=0.0057\n",
      "[SGD | lr=0.1] Epoch 3013/4000: train_loss=0.0056  test_loss=4.4025  λ_max=73.8741\n",
      "[SGD | lr=0.1] Epoch 3014/4000: train_loss=0.0056  test_loss=4.4027  λ_max=74.7750\n",
      "[SGD | lr=0.1] Epoch 3015/4000: train_loss=0.0056  test_loss=4.4029  λ_max=74.3068\n",
      "[SGD | lr=0.1] Epoch 3016/4000: train_loss=0.0056  test_loss=4.4031  λ_max=71.5744\n",
      "[SGD | lr=0.1] Epoch 3017/4000: train_loss=0.0056  test_loss=4.4034  λ_max=72.5956\n",
      "[SGD | lr=0.1] Epoch 3018/4000: train_loss=0.0056  test_loss=4.4036  λ_max=70.8748\n",
      "[SGD | lr=0.1] Iter 48300: loss=0.0057\n",
      "[SGD | lr=0.1] Epoch 3019/4000: train_loss=0.0056  test_loss=4.4038  λ_max=73.2768\n",
      "[SGD | lr=0.1] Epoch 3020/4000: train_loss=0.0056  test_loss=4.4041  λ_max=72.8453\n",
      "[SGD | lr=0.1] Epoch 3021/4000: train_loss=0.0056  test_loss=4.4042  λ_max=71.5121\n",
      "[SGD | lr=0.1] Epoch 3022/4000: train_loss=0.0056  test_loss=4.4045  λ_max=71.4991\n",
      "[SGD | lr=0.1] Epoch 3023/4000: train_loss=0.0056  test_loss=4.4048  λ_max=73.8266\n",
      "[SGD | lr=0.1] Epoch 3024/4000: train_loss=0.0056  test_loss=4.4050  λ_max=72.1555\n",
      "[SGD | lr=0.1] Iter 48400: loss=0.0056\n",
      "[SGD | lr=0.1] Epoch 3025/4000: train_loss=0.0056  test_loss=4.4054  λ_max=74.4126\n",
      "[SGD | lr=0.1] Epoch 3026/4000: train_loss=0.0056  test_loss=4.4055  λ_max=71.5859\n",
      "[SGD | lr=0.1] Epoch 3027/4000: train_loss=0.0056  test_loss=4.4058  λ_max=73.0428\n",
      "[SGD | lr=0.1] Epoch 3028/4000: train_loss=0.0056  test_loss=4.4060  λ_max=71.2370\n",
      "[SGD | lr=0.1] Epoch 3029/4000: train_loss=0.0056  test_loss=4.4061  λ_max=72.9063\n",
      "[SGD | lr=0.1] Epoch 3030/4000: train_loss=0.0056  test_loss=4.4064  λ_max=73.6312\n",
      "[SGD | lr=0.1] Epoch 3031/4000: train_loss=0.0056  test_loss=4.4066  λ_max=74.2137\n",
      "[SGD | lr=0.1] Iter 48500: loss=0.0056\n",
      "[SGD | lr=0.1] Epoch 3032/4000: train_loss=0.0056  test_loss=4.4069  λ_max=71.7648\n",
      "[SGD | lr=0.1] Epoch 3033/4000: train_loss=0.0056  test_loss=4.4072  λ_max=73.2825\n",
      "[SGD | lr=0.1] Epoch 3034/4000: train_loss=0.0056  test_loss=4.4074  λ_max=72.4549\n",
      "[SGD | lr=0.1] Epoch 3035/4000: train_loss=0.0056  test_loss=4.4076  λ_max=72.7980\n",
      "[SGD | lr=0.1] Epoch 3036/4000: train_loss=0.0056  test_loss=4.4080  λ_max=74.3719\n",
      "[SGD | lr=0.1] Epoch 3037/4000: train_loss=0.0056  test_loss=4.4081  λ_max=73.7280\n",
      "[SGD | lr=0.1] Iter 48600: loss=0.0056\n",
      "[SGD | lr=0.1] Epoch 3038/4000: train_loss=0.0056  test_loss=4.4084  λ_max=73.1301\n",
      "[SGD | lr=0.1] Epoch 3039/4000: train_loss=0.0056  test_loss=4.4085  λ_max=73.7107\n",
      "[SGD | lr=0.1] Epoch 3040/4000: train_loss=0.0056  test_loss=4.4088  λ_max=71.9160\n",
      "[SGD | lr=0.1] Epoch 3041/4000: train_loss=0.0056  test_loss=4.4090  λ_max=73.8419\n",
      "[SGD | lr=0.1] Epoch 3042/4000: train_loss=0.0056  test_loss=4.4092  λ_max=72.7842\n",
      "[SGD | lr=0.1] Epoch 3043/4000: train_loss=0.0056  test_loss=4.4095  λ_max=72.7020\n",
      "[SGD | lr=0.1] Iter 48700: loss=0.0056\n",
      "[SGD | lr=0.1] Epoch 3044/4000: train_loss=0.0056  test_loss=4.4097  λ_max=71.3711\n",
      "[SGD | lr=0.1] Epoch 3045/4000: train_loss=0.0056  test_loss=4.4099  λ_max=73.7918\n",
      "[SGD | lr=0.1] Epoch 3046/4000: train_loss=0.0056  test_loss=4.4102  λ_max=74.5910\n",
      "[SGD | lr=0.1] Epoch 3047/4000: train_loss=0.0056  test_loss=4.4104  λ_max=72.0189\n",
      "[SGD | lr=0.1] Epoch 3048/4000: train_loss=0.0056  test_loss=4.4106  λ_max=72.5611\n",
      "[SGD | lr=0.1] Epoch 3049/4000: train_loss=0.0056  test_loss=4.4109  λ_max=74.4369\n",
      "[SGD | lr=0.1] Iter 48800: loss=0.0056\n",
      "[SGD | lr=0.1] Epoch 3050/4000: train_loss=0.0056  test_loss=4.4112  λ_max=71.4232\n",
      "[SGD | lr=0.1] Epoch 3051/4000: train_loss=0.0056  test_loss=4.4114  λ_max=74.9738\n",
      "[SGD | lr=0.1] Epoch 3052/4000: train_loss=0.0055  test_loss=4.4117  λ_max=74.5100\n",
      "[SGD | lr=0.1] Epoch 3053/4000: train_loss=0.0055  test_loss=4.4118  λ_max=72.0203\n",
      "[SGD | lr=0.1] Epoch 3054/4000: train_loss=0.0055  test_loss=4.4120  λ_max=73.4736\n",
      "[SGD | lr=0.1] Epoch 3055/4000: train_loss=0.0055  test_loss=4.4124  λ_max=71.3376\n",
      "[SGD | lr=0.1] Epoch 3056/4000: train_loss=0.0055  test_loss=4.4125  λ_max=72.3719\n",
      "[SGD | lr=0.1] Iter 48900: loss=0.0055\n",
      "[SGD | lr=0.1] Epoch 3057/4000: train_loss=0.0055  test_loss=4.4127  λ_max=74.9548\n",
      "[SGD | lr=0.1] Epoch 3058/4000: train_loss=0.0055  test_loss=4.4130  λ_max=70.6291\n",
      "[SGD | lr=0.1] Epoch 3059/4000: train_loss=0.0055  test_loss=4.4132  λ_max=73.5716\n",
      "[SGD | lr=0.1] Epoch 3060/4000: train_loss=0.0055  test_loss=4.4134  λ_max=73.3627\n",
      "[SGD | lr=0.1] Epoch 3061/4000: train_loss=0.0055  test_loss=4.4137  λ_max=70.8832\n",
      "[SGD | lr=0.1] Epoch 3062/4000: train_loss=0.0055  test_loss=4.4139  λ_max=75.6351\n",
      "[SGD | lr=0.1] Iter 49000: loss=0.0055\n",
      "[SGD | lr=0.1] Epoch 3063/4000: train_loss=0.0055  test_loss=4.4144  λ_max=73.0323\n",
      "[SGD | lr=0.1] Epoch 3064/4000: train_loss=0.0055  test_loss=4.4145  λ_max=72.3261\n",
      "[SGD | lr=0.1] Epoch 3065/4000: train_loss=0.0055  test_loss=4.4145  λ_max=72.3795\n",
      "[SGD | lr=0.1] Epoch 3066/4000: train_loss=0.0055  test_loss=4.4149  λ_max=74.8637\n",
      "[SGD | lr=0.1] Epoch 3067/4000: train_loss=0.0055  test_loss=4.4151  λ_max=72.1717\n",
      "[SGD | lr=0.1] Epoch 3068/4000: train_loss=0.0055  test_loss=4.4152  λ_max=71.3535\n",
      "[SGD | lr=0.1] Iter 49100: loss=0.0055\n",
      "[SGD | lr=0.1] Epoch 3069/4000: train_loss=0.0055  test_loss=4.4155  λ_max=73.0633\n",
      "[SGD | lr=0.1] Epoch 3070/4000: train_loss=0.0055  test_loss=4.4157  λ_max=72.0360\n",
      "[SGD | lr=0.1] Epoch 3071/4000: train_loss=0.0055  test_loss=4.4159  λ_max=73.4809\n",
      "[SGD | lr=0.1] Epoch 3072/4000: train_loss=0.0055  test_loss=4.4163  λ_max=72.4836\n",
      "[SGD | lr=0.1] Epoch 3073/4000: train_loss=0.0055  test_loss=4.4164  λ_max=72.1911\n",
      "[SGD | lr=0.1] Epoch 3074/4000: train_loss=0.0055  test_loss=4.4168  λ_max=70.2068\n",
      "[SGD | lr=0.1] Iter 49200: loss=0.0055\n",
      "[SGD | lr=0.1] Epoch 3075/4000: train_loss=0.0055  test_loss=4.4169  λ_max=72.5516\n",
      "[SGD | lr=0.1] Epoch 3076/4000: train_loss=0.0055  test_loss=4.4171  λ_max=73.5268\n",
      "[SGD | lr=0.1] Epoch 3077/4000: train_loss=0.0055  test_loss=4.4172  λ_max=74.4907\n",
      "[SGD | lr=0.1] Epoch 3078/4000: train_loss=0.0055  test_loss=4.4175  λ_max=73.0368\n",
      "[SGD | lr=0.1] Epoch 3079/4000: train_loss=0.0055  test_loss=4.4178  λ_max=74.5911\n",
      "[SGD | lr=0.1] Epoch 3080/4000: train_loss=0.0055  test_loss=4.4181  λ_max=73.1174\n",
      "[SGD | lr=0.1] Epoch 3081/4000: train_loss=0.0055  test_loss=4.4184  λ_max=73.6753\n",
      "[SGD | lr=0.1] Iter 49300: loss=0.0055\n",
      "[SGD | lr=0.1] Epoch 3082/4000: train_loss=0.0055  test_loss=4.4185  λ_max=71.6795\n",
      "[SGD | lr=0.1] Epoch 3083/4000: train_loss=0.0055  test_loss=4.4188  λ_max=72.8389\n",
      "[SGD | lr=0.1] Epoch 3084/4000: train_loss=0.0055  test_loss=4.4190  λ_max=71.8334\n",
      "[SGD | lr=0.1] Epoch 3085/4000: train_loss=0.0055  test_loss=4.4193  λ_max=71.8075\n",
      "[SGD | lr=0.1] Epoch 3086/4000: train_loss=0.0055  test_loss=4.4194  λ_max=73.7177\n",
      "[SGD | lr=0.1] Epoch 3087/4000: train_loss=0.0055  test_loss=4.4197  λ_max=74.0371\n",
      "[SGD | lr=0.1] Iter 49400: loss=0.0056\n",
      "[SGD | lr=0.1] Epoch 3088/4000: train_loss=0.0055  test_loss=4.4199  λ_max=73.4712\n",
      "[SGD | lr=0.1] Epoch 3089/4000: train_loss=0.0055  test_loss=4.4201  λ_max=75.7309\n",
      "[SGD | lr=0.1] Epoch 3090/4000: train_loss=0.0055  test_loss=4.4204  λ_max=72.9184\n",
      "[SGD | lr=0.1] Epoch 3091/4000: train_loss=0.0055  test_loss=4.4206  λ_max=75.0597\n",
      "[SGD | lr=0.1] Epoch 3092/4000: train_loss=0.0055  test_loss=4.4209  λ_max=75.2374\n",
      "[SGD | lr=0.1] Epoch 3093/4000: train_loss=0.0054  test_loss=4.4212  λ_max=74.1580\n",
      "[SGD | lr=0.1] Iter 49500: loss=0.0054\n",
      "[SGD | lr=0.1] Epoch 3094/4000: train_loss=0.0054  test_loss=4.4214  λ_max=74.4884\n",
      "[SGD | lr=0.1] Epoch 3095/4000: train_loss=0.0054  test_loss=4.4215  λ_max=72.9067\n",
      "[SGD | lr=0.1] Epoch 3096/4000: train_loss=0.0054  test_loss=4.4219  λ_max=74.7151\n",
      "[SGD | lr=0.1] Epoch 3097/4000: train_loss=0.0054  test_loss=4.4220  λ_max=73.8060\n",
      "[SGD | lr=0.1] Epoch 3098/4000: train_loss=0.0054  test_loss=4.4223  λ_max=73.8325\n",
      "[SGD | lr=0.1] Epoch 3099/4000: train_loss=0.0054  test_loss=4.4226  λ_max=71.9476\n",
      "[SGD | lr=0.1] Iter 49600: loss=0.0056\n",
      "[SGD | lr=0.1] Epoch 3100/4000: train_loss=0.0054  test_loss=4.4228  λ_max=73.5719\n",
      "[SGD | lr=0.1] Epoch 3101/4000: train_loss=0.0054  test_loss=4.4230  λ_max=73.1613\n",
      "[SGD | lr=0.1] Epoch 3102/4000: train_loss=0.0054  test_loss=4.4231  λ_max=75.0547\n",
      "[SGD | lr=0.1] Epoch 3103/4000: train_loss=0.0054  test_loss=4.4234  λ_max=75.2298\n",
      "[SGD | lr=0.1] Epoch 3104/4000: train_loss=0.0054  test_loss=4.4236  λ_max=73.2663\n",
      "[SGD | lr=0.1] Epoch 3105/4000: train_loss=0.0054  test_loss=4.4238  λ_max=73.8083\n",
      "[SGD | lr=0.1] Epoch 3106/4000: train_loss=0.0054  test_loss=4.4242  λ_max=74.0755\n",
      "[SGD | lr=0.1] Iter 49700: loss=0.0053\n",
      "[SGD | lr=0.1] Epoch 3107/4000: train_loss=0.0054  test_loss=4.4243  λ_max=74.9855\n",
      "[SGD | lr=0.1] Epoch 3108/4000: train_loss=0.0054  test_loss=4.4246  λ_max=71.7411\n",
      "[SGD | lr=0.1] Epoch 3109/4000: train_loss=0.0054  test_loss=4.4247  λ_max=72.1731\n",
      "[SGD | lr=0.1] Epoch 3110/4000: train_loss=0.0054  test_loss=4.4250  λ_max=73.7869\n",
      "[SGD | lr=0.1] Epoch 3111/4000: train_loss=0.0054  test_loss=4.4252  λ_max=75.1172\n",
      "[SGD | lr=0.1] Epoch 3112/4000: train_loss=0.0054  test_loss=4.4253  λ_max=71.8245\n",
      "[SGD | lr=0.1] Iter 49800: loss=0.0053\n",
      "[SGD | lr=0.1] Epoch 3113/4000: train_loss=0.0054  test_loss=4.4257  λ_max=75.6536\n",
      "[SGD | lr=0.1] Epoch 3114/4000: train_loss=0.0054  test_loss=4.4261  λ_max=74.3413\n",
      "[SGD | lr=0.1] Epoch 3115/4000: train_loss=0.0054  test_loss=4.4262  λ_max=74.1987\n",
      "[SGD | lr=0.1] Epoch 3116/4000: train_loss=0.0054  test_loss=4.4264  λ_max=73.2695\n",
      "[SGD | lr=0.1] Epoch 3117/4000: train_loss=0.0054  test_loss=4.4265  λ_max=73.6487\n",
      "[SGD | lr=0.1] Epoch 3118/4000: train_loss=0.0054  test_loss=4.4269  λ_max=75.1652\n",
      "[SGD | lr=0.1] Iter 49900: loss=0.0054\n",
      "[SGD | lr=0.1] Epoch 3119/4000: train_loss=0.0054  test_loss=4.4270  λ_max=75.7430\n",
      "[SGD | lr=0.1] Epoch 3120/4000: train_loss=0.0054  test_loss=4.4274  λ_max=72.9535\n",
      "[SGD | lr=0.1] Epoch 3121/4000: train_loss=0.0054  test_loss=4.4274  λ_max=76.5933\n",
      "[SGD | lr=0.1] Epoch 3122/4000: train_loss=0.0054  test_loss=4.4277  λ_max=72.7247\n",
      "[SGD | lr=0.1] Epoch 3123/4000: train_loss=0.0054  test_loss=4.4281  λ_max=73.8787\n",
      "[SGD | lr=0.1] Epoch 3124/4000: train_loss=0.0054  test_loss=4.4281  λ_max=72.3934\n",
      "[SGD | lr=0.1] Iter 50000: loss=0.0054\n",
      "[SGD | lr=0.1] Epoch 3125/4000: train_loss=0.0054  test_loss=4.4284  λ_max=75.9769\n",
      "[SGD | lr=0.1] Epoch 3126/4000: train_loss=0.0054  test_loss=4.4286  λ_max=69.5708\n",
      "[SGD | lr=0.1] Epoch 3127/4000: train_loss=0.0054  test_loss=4.4289  λ_max=75.3905\n",
      "[SGD | lr=0.1] Epoch 3128/4000: train_loss=0.0054  test_loss=4.4292  λ_max=73.9071\n",
      "[SGD | lr=0.1] Epoch 3129/4000: train_loss=0.0054  test_loss=4.4294  λ_max=73.8776\n",
      "[SGD | lr=0.1] Epoch 3130/4000: train_loss=0.0054  test_loss=4.4297  λ_max=73.7706\n",
      "[SGD | lr=0.1] Epoch 3131/4000: train_loss=0.0054  test_loss=4.4299  λ_max=73.5405\n",
      "[SGD | lr=0.1] Iter 50100: loss=0.0054\n",
      "[SGD | lr=0.1] Epoch 3132/4000: train_loss=0.0054  test_loss=4.4301  λ_max=72.9309\n",
      "[SGD | lr=0.1] Epoch 3133/4000: train_loss=0.0054  test_loss=4.4304  λ_max=71.9588\n",
      "[SGD | lr=0.1] Epoch 3134/4000: train_loss=0.0054  test_loss=4.4305  λ_max=72.6265\n",
      "[SGD | lr=0.1] Epoch 3135/4000: train_loss=0.0054  test_loss=4.4307  λ_max=71.6005\n",
      "[SGD | lr=0.1] Epoch 3136/4000: train_loss=0.0054  test_loss=4.4309  λ_max=75.2861\n",
      "[SGD | lr=0.1] Epoch 3137/4000: train_loss=0.0054  test_loss=4.4312  λ_max=72.9453\n",
      "[SGD | lr=0.1] Iter 50200: loss=0.0054\n",
      "[SGD | lr=0.1] Epoch 3138/4000: train_loss=0.0053  test_loss=4.4314  λ_max=72.6411\n",
      "[SGD | lr=0.1] Epoch 3139/4000: train_loss=0.0053  test_loss=4.4316  λ_max=72.9062\n",
      "[SGD | lr=0.1] Epoch 3140/4000: train_loss=0.0053  test_loss=4.4319  λ_max=72.5574\n",
      "[SGD | lr=0.1] Epoch 3141/4000: train_loss=0.0053  test_loss=4.4321  λ_max=71.7942\n",
      "[SGD | lr=0.1] Epoch 3142/4000: train_loss=0.0053  test_loss=4.4322  λ_max=72.6530\n",
      "[SGD | lr=0.1] Epoch 3143/4000: train_loss=0.0053  test_loss=4.4326  λ_max=73.6021\n",
      "[SGD | lr=0.1] Iter 50300: loss=0.0054\n",
      "[SGD | lr=0.1] Epoch 3144/4000: train_loss=0.0053  test_loss=4.4327  λ_max=75.0137\n",
      "[SGD | lr=0.1] Epoch 3145/4000: train_loss=0.0053  test_loss=4.4330  λ_max=71.8359\n",
      "[SGD | lr=0.1] Epoch 3146/4000: train_loss=0.0053  test_loss=4.4332  λ_max=74.4219\n",
      "[SGD | lr=0.1] Epoch 3147/4000: train_loss=0.0053  test_loss=4.4335  λ_max=72.7174\n",
      "[SGD | lr=0.1] Epoch 3148/4000: train_loss=0.0053  test_loss=4.4336  λ_max=75.6586\n",
      "[SGD | lr=0.1] Epoch 3149/4000: train_loss=0.0053  test_loss=4.4339  λ_max=73.7753\n",
      "[SGD | lr=0.1] Iter 50400: loss=0.0053\n",
      "[SGD | lr=0.1] Epoch 3150/4000: train_loss=0.0053  test_loss=4.4341  λ_max=72.9712\n",
      "[SGD | lr=0.1] Epoch 3151/4000: train_loss=0.0053  test_loss=4.4344  λ_max=74.4981\n",
      "[SGD | lr=0.1] Epoch 3152/4000: train_loss=0.0053  test_loss=4.4345  λ_max=72.5202\n",
      "[SGD | lr=0.1] Epoch 3153/4000: train_loss=0.0053  test_loss=4.4349  λ_max=73.2833\n",
      "[SGD | lr=0.1] Epoch 3154/4000: train_loss=0.0053  test_loss=4.4350  λ_max=71.9809\n",
      "[SGD | lr=0.1] Epoch 3155/4000: train_loss=0.0053  test_loss=4.4352  λ_max=75.9298\n",
      "[SGD | lr=0.1] Epoch 3156/4000: train_loss=0.0053  test_loss=4.4355  λ_max=73.8662\n",
      "[SGD | lr=0.1] Iter 50500: loss=0.0053\n",
      "[SGD | lr=0.1] Epoch 3157/4000: train_loss=0.0053  test_loss=4.4357  λ_max=72.8587\n",
      "[SGD | lr=0.1] Epoch 3158/4000: train_loss=0.0053  test_loss=4.4359  λ_max=72.1940\n",
      "[SGD | lr=0.1] Epoch 3159/4000: train_loss=0.0053  test_loss=4.4362  λ_max=71.3226\n",
      "[SGD | lr=0.1] Epoch 3160/4000: train_loss=0.0053  test_loss=4.4363  λ_max=74.1763\n",
      "[SGD | lr=0.1] Epoch 3161/4000: train_loss=0.0053  test_loss=4.4366  λ_max=73.4820\n",
      "[SGD | lr=0.1] Epoch 3162/4000: train_loss=0.0053  test_loss=4.4368  λ_max=73.1253\n",
      "[SGD | lr=0.1] Iter 50600: loss=0.0053\n",
      "[SGD | lr=0.1] Epoch 3163/4000: train_loss=0.0053  test_loss=4.4370  λ_max=72.5347\n",
      "[SGD | lr=0.1] Epoch 3164/4000: train_loss=0.0053  test_loss=4.4372  λ_max=73.0441\n",
      "[SGD | lr=0.1] Epoch 3165/4000: train_loss=0.0053  test_loss=4.4375  λ_max=74.3557\n",
      "[SGD | lr=0.1] Epoch 3166/4000: train_loss=0.0053  test_loss=4.4377  λ_max=72.8550\n",
      "[SGD | lr=0.1] Epoch 3167/4000: train_loss=0.0053  test_loss=4.4379  λ_max=74.7225\n",
      "[SGD | lr=0.1] Epoch 3168/4000: train_loss=0.0053  test_loss=4.4381  λ_max=73.7552\n",
      "[SGD | lr=0.1] Iter 50700: loss=0.0052\n",
      "[SGD | lr=0.1] Epoch 3169/4000: train_loss=0.0053  test_loss=4.4383  λ_max=73.8737\n",
      "[SGD | lr=0.1] Epoch 3170/4000: train_loss=0.0053  test_loss=4.4387  λ_max=73.0474\n",
      "[SGD | lr=0.1] Epoch 3171/4000: train_loss=0.0053  test_loss=4.4388  λ_max=72.9609\n",
      "[SGD | lr=0.1] Epoch 3172/4000: train_loss=0.0053  test_loss=4.4390  λ_max=74.5088\n",
      "[SGD | lr=0.1] Epoch 3173/4000: train_loss=0.0053  test_loss=4.4393  λ_max=75.8049\n",
      "[SGD | lr=0.1] Epoch 3174/4000: train_loss=0.0053  test_loss=4.4395  λ_max=75.4040\n",
      "[SGD | lr=0.1] Iter 50800: loss=0.0051\n",
      "[SGD | lr=0.1] Epoch 3175/4000: train_loss=0.0053  test_loss=4.4397  λ_max=74.6347\n",
      "[SGD | lr=0.1] Epoch 3176/4000: train_loss=0.0053  test_loss=4.4398  λ_max=74.6912\n",
      "[SGD | lr=0.1] Epoch 3177/4000: train_loss=0.0053  test_loss=4.4402  λ_max=75.0368\n",
      "[SGD | lr=0.1] Epoch 3178/4000: train_loss=0.0053  test_loss=4.4403  λ_max=75.6005\n",
      "[SGD | lr=0.1] Epoch 3179/4000: train_loss=0.0053  test_loss=4.4405  λ_max=73.8620\n",
      "[SGD | lr=0.1] Epoch 3180/4000: train_loss=0.0053  test_loss=4.4409  λ_max=74.3082\n",
      "[SGD | lr=0.1] Epoch 3181/4000: train_loss=0.0053  test_loss=4.4412  λ_max=73.6357\n",
      "[SGD | lr=0.1] Iter 50900: loss=0.0052\n",
      "[SGD | lr=0.1] Epoch 3182/4000: train_loss=0.0053  test_loss=4.4413  λ_max=74.3766\n",
      "[SGD | lr=0.1] Epoch 3183/4000: train_loss=0.0053  test_loss=4.4415  λ_max=73.4296\n",
      "[SGD | lr=0.1] Epoch 3184/4000: train_loss=0.0052  test_loss=4.4417  λ_max=74.0762\n",
      "[SGD | lr=0.1] Epoch 3185/4000: train_loss=0.0052  test_loss=4.4418  λ_max=74.2543\n",
      "[SGD | lr=0.1] Epoch 3186/4000: train_loss=0.0052  test_loss=4.4422  λ_max=74.7955\n",
      "[SGD | lr=0.1] Epoch 3187/4000: train_loss=0.0052  test_loss=4.4423  λ_max=75.2864\n",
      "[SGD | lr=0.1] Iter 51000: loss=0.0053\n",
      "[SGD | lr=0.1] Epoch 3188/4000: train_loss=0.0052  test_loss=4.4425  λ_max=73.7345\n",
      "[SGD | lr=0.1] Epoch 3189/4000: train_loss=0.0052  test_loss=4.4429  λ_max=73.6044\n",
      "[SGD | lr=0.1] Epoch 3190/4000: train_loss=0.0052  test_loss=4.4430  λ_max=72.8093\n",
      "[SGD | lr=0.1] Epoch 3191/4000: train_loss=0.0052  test_loss=4.4432  λ_max=71.7872\n",
      "[SGD | lr=0.1] Epoch 3192/4000: train_loss=0.0052  test_loss=4.4434  λ_max=74.6659\n",
      "[SGD | lr=0.1] Epoch 3193/4000: train_loss=0.0052  test_loss=4.4437  λ_max=73.1443\n",
      "[SGD | lr=0.1] Iter 51100: loss=0.0052\n",
      "[SGD | lr=0.1] Epoch 3194/4000: train_loss=0.0052  test_loss=4.4439  λ_max=74.4962\n",
      "[SGD | lr=0.1] Epoch 3195/4000: train_loss=0.0052  test_loss=4.4441  λ_max=72.4316\n",
      "[SGD | lr=0.1] Epoch 3196/4000: train_loss=0.0052  test_loss=4.4443  λ_max=74.3326\n",
      "[SGD | lr=0.1] Epoch 3197/4000: train_loss=0.0052  test_loss=4.4445  λ_max=72.5513\n",
      "[SGD | lr=0.1] Epoch 3198/4000: train_loss=0.0052  test_loss=4.4448  λ_max=75.5368\n",
      "[SGD | lr=0.1] Epoch 3199/4000: train_loss=0.0052  test_loss=4.4451  λ_max=74.3560\n",
      "[SGD | lr=0.1] Iter 51200: loss=0.0052\n",
      "[SGD | lr=0.1] Epoch 3200/4000: train_loss=0.0052  test_loss=4.4453  λ_max=75.4696\n",
      "[SGD | lr=0.1] Epoch 3201/4000: train_loss=0.0052  test_loss=4.4454  λ_max=75.4110\n",
      "[SGD | lr=0.1] Epoch 3202/4000: train_loss=0.0052  test_loss=4.4456  λ_max=74.7504\n",
      "[SGD | lr=0.1] Epoch 3203/4000: train_loss=0.0052  test_loss=4.4460  λ_max=73.7945\n",
      "[SGD | lr=0.1] Epoch 3204/4000: train_loss=0.0052  test_loss=4.4462  λ_max=75.4568\n",
      "[SGD | lr=0.1] Epoch 3205/4000: train_loss=0.0052  test_loss=4.4463  λ_max=74.6108\n",
      "[SGD | lr=0.1] Epoch 3206/4000: train_loss=0.0052  test_loss=4.4465  λ_max=74.8718\n",
      "[SGD | lr=0.1] Iter 51300: loss=0.0052\n",
      "[SGD | lr=0.1] Epoch 3207/4000: train_loss=0.0052  test_loss=4.4467  λ_max=73.8159\n",
      "[SGD | lr=0.1] Epoch 3208/4000: train_loss=0.0052  test_loss=4.4470  λ_max=75.6139\n",
      "[SGD | lr=0.1] Epoch 3209/4000: train_loss=0.0052  test_loss=4.4473  λ_max=73.4361\n",
      "[SGD | lr=0.1] Epoch 3210/4000: train_loss=0.0052  test_loss=4.4474  λ_max=73.1201\n",
      "[SGD | lr=0.1] Epoch 3211/4000: train_loss=0.0052  test_loss=4.4476  λ_max=76.3875\n",
      "[SGD | lr=0.1] Epoch 3212/4000: train_loss=0.0052  test_loss=4.4478  λ_max=72.3376\n",
      "[SGD | lr=0.1] Iter 51400: loss=0.0052\n",
      "[SGD | lr=0.1] Epoch 3213/4000: train_loss=0.0052  test_loss=4.4480  λ_max=70.8955\n",
      "[SGD | lr=0.1] Epoch 3214/4000: train_loss=0.0052  test_loss=4.4483  λ_max=76.1496\n",
      "[SGD | lr=0.1] Epoch 3215/4000: train_loss=0.0052  test_loss=4.4486  λ_max=75.2796\n",
      "[SGD | lr=0.1] Epoch 3216/4000: train_loss=0.0052  test_loss=4.4488  λ_max=73.3639\n",
      "[SGD | lr=0.1] Epoch 3217/4000: train_loss=0.0052  test_loss=4.4489  λ_max=74.4385\n",
      "[SGD | lr=0.1] Epoch 3218/4000: train_loss=0.0052  test_loss=4.4492  λ_max=74.4252\n",
      "[SGD | lr=0.1] Iter 51500: loss=0.0052\n",
      "[SGD | lr=0.1] Epoch 3219/4000: train_loss=0.0052  test_loss=4.4493  λ_max=73.9195\n",
      "[SGD | lr=0.1] Epoch 3220/4000: train_loss=0.0052  test_loss=4.4495  λ_max=74.2993\n",
      "[SGD | lr=0.1] Epoch 3221/4000: train_loss=0.0052  test_loss=4.4498  λ_max=73.8949\n",
      "[SGD | lr=0.1] Epoch 3222/4000: train_loss=0.0052  test_loss=4.4501  λ_max=72.6634\n",
      "[SGD | lr=0.1] Epoch 3223/4000: train_loss=0.0052  test_loss=4.4503  λ_max=75.3946\n",
      "[SGD | lr=0.1] Epoch 3224/4000: train_loss=0.0052  test_loss=4.4506  λ_max=73.9049\n",
      "[SGD | lr=0.1] Iter 51600: loss=0.0052\n",
      "[SGD | lr=0.1] Epoch 3225/4000: train_loss=0.0052  test_loss=4.4508  λ_max=72.8775\n",
      "[SGD | lr=0.1] Epoch 3226/4000: train_loss=0.0052  test_loss=4.4509  λ_max=72.6703\n",
      "[SGD | lr=0.1] Epoch 3227/4000: train_loss=0.0052  test_loss=4.4510  λ_max=71.4927\n",
      "[SGD | lr=0.1] Epoch 3228/4000: train_loss=0.0052  test_loss=4.4514  λ_max=75.1350\n",
      "[SGD | lr=0.1] Epoch 3229/4000: train_loss=0.0052  test_loss=4.4517  λ_max=75.2217\n",
      "[SGD | lr=0.1] Epoch 3230/4000: train_loss=0.0051  test_loss=4.4519  λ_max=75.9384\n",
      "[SGD | lr=0.1] Epoch 3231/4000: train_loss=0.0052  test_loss=4.4521  λ_max=72.5106\n",
      "[SGD | lr=0.1] Iter 51700: loss=0.0051\n",
      "[SGD | lr=0.1] Epoch 3232/4000: train_loss=0.0051  test_loss=4.4522  λ_max=73.7520\n",
      "[SGD | lr=0.1] Epoch 3233/4000: train_loss=0.0051  test_loss=4.4524  λ_max=74.1692\n",
      "[SGD | lr=0.1] Epoch 3234/4000: train_loss=0.0051  test_loss=4.4528  λ_max=75.3146\n",
      "[SGD | lr=0.1] Epoch 3235/4000: train_loss=0.0051  test_loss=4.4528  λ_max=73.8352\n",
      "[SGD | lr=0.1] Epoch 3236/4000: train_loss=0.0051  test_loss=4.4532  λ_max=74.7778\n",
      "[SGD | lr=0.1] Epoch 3237/4000: train_loss=0.0051  test_loss=4.4533  λ_max=74.3142\n",
      "[SGD | lr=0.1] Iter 51800: loss=0.0052\n",
      "[SGD | lr=0.1] Epoch 3238/4000: train_loss=0.0051  test_loss=4.4536  λ_max=74.6188\n",
      "[SGD | lr=0.1] Epoch 3239/4000: train_loss=0.0051  test_loss=4.4539  λ_max=73.7693\n",
      "[SGD | lr=0.1] Epoch 3240/4000: train_loss=0.0051  test_loss=4.4540  λ_max=75.0126\n",
      "[SGD | lr=0.1] Epoch 3241/4000: train_loss=0.0051  test_loss=4.4541  λ_max=73.5900\n",
      "[SGD | lr=0.1] Epoch 3242/4000: train_loss=0.0051  test_loss=4.4544  λ_max=75.3023\n",
      "[SGD | lr=0.1] Epoch 3243/4000: train_loss=0.0051  test_loss=4.4546  λ_max=76.4000\n",
      "[SGD | lr=0.1] Iter 51900: loss=0.0050\n",
      "[SGD | lr=0.1] Epoch 3244/4000: train_loss=0.0051  test_loss=4.4550  λ_max=76.0942\n",
      "[SGD | lr=0.1] Epoch 3245/4000: train_loss=0.0051  test_loss=4.4550  λ_max=73.4747\n",
      "[SGD | lr=0.1] Epoch 3246/4000: train_loss=0.0051  test_loss=4.4553  λ_max=72.0820\n",
      "[SGD | lr=0.1] Epoch 3247/4000: train_loss=0.0051  test_loss=4.4556  λ_max=73.5529\n",
      "[SGD | lr=0.1] Epoch 3248/4000: train_loss=0.0051  test_loss=4.4558  λ_max=74.3054\n",
      "[SGD | lr=0.1] Epoch 3249/4000: train_loss=0.0051  test_loss=4.4560  λ_max=72.8250\n",
      "[SGD | lr=0.1] Iter 52000: loss=0.0051\n",
      "[SGD | lr=0.1] Epoch 3250/4000: train_loss=0.0051  test_loss=4.4560  λ_max=74.3085\n",
      "[SGD | lr=0.1] Epoch 3251/4000: train_loss=0.0051  test_loss=4.4563  λ_max=74.3861\n",
      "[SGD | lr=0.1] Epoch 3252/4000: train_loss=0.0051  test_loss=4.4568  λ_max=74.8276\n",
      "[SGD | lr=0.1] Epoch 3253/4000: train_loss=0.0051  test_loss=4.4569  λ_max=72.2181\n",
      "[SGD | lr=0.1] Epoch 3254/4000: train_loss=0.0051  test_loss=4.4571  λ_max=74.2179\n",
      "[SGD | lr=0.1] Epoch 3255/4000: train_loss=0.0051  test_loss=4.4574  λ_max=76.1951\n",
      "[SGD | lr=0.1] Epoch 3256/4000: train_loss=0.0051  test_loss=4.4576  λ_max=74.5547\n",
      "[SGD | lr=0.1] Iter 52100: loss=0.0051\n",
      "[SGD | lr=0.1] Epoch 3257/4000: train_loss=0.0051  test_loss=4.4577  λ_max=75.0291\n",
      "[SGD | lr=0.1] Epoch 3258/4000: train_loss=0.0051  test_loss=4.4580  λ_max=73.2451\n",
      "[SGD | lr=0.1] Epoch 3259/4000: train_loss=0.0051  test_loss=4.4581  λ_max=73.4976\n",
      "[SGD | lr=0.1] Epoch 3260/4000: train_loss=0.0051  test_loss=4.4583  λ_max=72.3661\n",
      "[SGD | lr=0.1] Epoch 3261/4000: train_loss=0.0051  test_loss=4.4585  λ_max=74.4003\n",
      "[SGD | lr=0.1] Epoch 3262/4000: train_loss=0.0051  test_loss=4.4587  λ_max=74.0067\n",
      "[SGD | lr=0.1] Iter 52200: loss=0.0051\n",
      "[SGD | lr=0.1] Epoch 3263/4000: train_loss=0.0051  test_loss=4.4591  λ_max=74.3480\n",
      "[SGD | lr=0.1] Epoch 3264/4000: train_loss=0.0051  test_loss=4.4593  λ_max=72.7576\n",
      "[SGD | lr=0.1] Epoch 3265/4000: train_loss=0.0051  test_loss=4.4594  λ_max=74.4796\n",
      "[SGD | lr=0.1] Epoch 3266/4000: train_loss=0.0051  test_loss=4.4596  λ_max=74.9423\n",
      "[SGD | lr=0.1] Epoch 3267/4000: train_loss=0.0051  test_loss=4.4597  λ_max=71.3265\n",
      "[SGD | lr=0.1] Epoch 3268/4000: train_loss=0.0051  test_loss=4.4601  λ_max=74.7481\n",
      "[SGD | lr=0.1] Iter 52300: loss=0.0051\n",
      "[SGD | lr=0.1] Epoch 3269/4000: train_loss=0.0051  test_loss=4.4603  λ_max=74.1882\n",
      "[SGD | lr=0.1] Epoch 3270/4000: train_loss=0.0051  test_loss=4.4606  λ_max=74.8188\n",
      "[SGD | lr=0.1] Epoch 3271/4000: train_loss=0.0051  test_loss=4.4607  λ_max=72.8087\n",
      "[SGD | lr=0.1] Epoch 3272/4000: train_loss=0.0051  test_loss=4.4610  λ_max=75.7972\n",
      "[SGD | lr=0.1] Epoch 3273/4000: train_loss=0.0051  test_loss=4.4612  λ_max=75.5261\n",
      "[SGD | lr=0.1] Epoch 3274/4000: train_loss=0.0051  test_loss=4.4614  λ_max=74.6940\n",
      "[SGD | lr=0.1] Iter 52400: loss=0.0051\n",
      "[SGD | lr=0.1] Epoch 3275/4000: train_loss=0.0051  test_loss=4.4616  λ_max=74.4389\n",
      "[SGD | lr=0.1] Epoch 3276/4000: train_loss=0.0051  test_loss=4.4619  λ_max=75.2383\n",
      "[SGD | lr=0.1] Epoch 3277/4000: train_loss=0.0051  test_loss=4.4621  λ_max=74.0251\n",
      "[SGD | lr=0.1] Epoch 3278/4000: train_loss=0.0051  test_loss=4.4622  λ_max=75.0564\n",
      "[SGD | lr=0.1] Epoch 3279/4000: train_loss=0.0050  test_loss=4.4625  λ_max=75.7734\n",
      "[SGD | lr=0.1] Epoch 3280/4000: train_loss=0.0050  test_loss=4.4628  λ_max=75.3940\n",
      "[SGD | lr=0.1] Epoch 3281/4000: train_loss=0.0050  test_loss=4.4629  λ_max=74.7478\n",
      "[SGD | lr=0.1] Iter 52500: loss=0.0050\n",
      "[SGD | lr=0.1] Epoch 3282/4000: train_loss=0.0050  test_loss=4.4632  λ_max=73.4918\n",
      "[SGD | lr=0.1] Epoch 3283/4000: train_loss=0.0050  test_loss=4.4634  λ_max=74.9964\n",
      "[SGD | lr=0.1] Epoch 3284/4000: train_loss=0.0050  test_loss=4.4636  λ_max=74.7873\n",
      "[SGD | lr=0.1] Epoch 3285/4000: train_loss=0.0050  test_loss=4.4638  λ_max=73.8882\n",
      "[SGD | lr=0.1] Epoch 3286/4000: train_loss=0.0050  test_loss=4.4641  λ_max=75.3911\n",
      "[SGD | lr=0.1] Epoch 3287/4000: train_loss=0.0050  test_loss=4.4642  λ_max=73.2607\n",
      "[SGD | lr=0.1] Iter 52600: loss=0.0051\n",
      "[SGD | lr=0.1] Epoch 3288/4000: train_loss=0.0050  test_loss=4.4645  λ_max=74.1875\n",
      "[SGD | lr=0.1] Epoch 3289/4000: train_loss=0.0050  test_loss=4.4647  λ_max=72.6922\n",
      "[SGD | lr=0.1] Epoch 3290/4000: train_loss=0.0050  test_loss=4.4649  λ_max=75.3972\n",
      "[SGD | lr=0.1] Epoch 3291/4000: train_loss=0.0050  test_loss=4.4652  λ_max=73.4287\n",
      "[SGD | lr=0.1] Epoch 3292/4000: train_loss=0.0050  test_loss=4.4652  λ_max=76.0922\n",
      "[SGD | lr=0.1] Epoch 3293/4000: train_loss=0.0050  test_loss=4.4655  λ_max=73.7254\n",
      "[SGD | lr=0.1] Iter 52700: loss=0.0050\n",
      "[SGD | lr=0.1] Epoch 3294/4000: train_loss=0.0050  test_loss=4.4658  λ_max=74.7542\n",
      "[SGD | lr=0.1] Epoch 3295/4000: train_loss=0.0050  test_loss=4.4660  λ_max=75.8529\n",
      "[SGD | lr=0.1] Epoch 3296/4000: train_loss=0.0050  test_loss=4.4661  λ_max=77.1412\n",
      "[SGD | lr=0.1] Epoch 3297/4000: train_loss=0.0050  test_loss=4.4664  λ_max=74.8728\n",
      "[SGD | lr=0.1] Epoch 3298/4000: train_loss=0.0050  test_loss=4.4667  λ_max=73.8393\n",
      "[SGD | lr=0.1] Epoch 3299/4000: train_loss=0.0050  test_loss=4.4668  λ_max=74.7965\n",
      "[SGD | lr=0.1] Iter 52800: loss=0.0050\n",
      "[SGD | lr=0.1] Epoch 3300/4000: train_loss=0.0050  test_loss=4.4670  λ_max=73.8052\n",
      "[SGD | lr=0.1] Epoch 3301/4000: train_loss=0.0050  test_loss=4.4672  λ_max=74.3720\n",
      "[SGD | lr=0.1] Epoch 3302/4000: train_loss=0.0050  test_loss=4.4675  λ_max=73.2895\n",
      "[SGD | lr=0.1] Epoch 3303/4000: train_loss=0.0050  test_loss=4.4676  λ_max=73.3912\n",
      "[SGD | lr=0.1] Epoch 3304/4000: train_loss=0.0050  test_loss=4.4679  λ_max=73.9939\n",
      "[SGD | lr=0.1] Epoch 3305/4000: train_loss=0.0050  test_loss=4.4682  λ_max=74.8840\n",
      "[SGD | lr=0.1] Epoch 3306/4000: train_loss=0.0050  test_loss=4.4683  λ_max=75.8549\n",
      "[SGD | lr=0.1] Iter 52900: loss=0.0051\n",
      "[SGD | lr=0.1] Epoch 3307/4000: train_loss=0.0050  test_loss=4.4685  λ_max=74.8604\n",
      "[SGD | lr=0.1] Epoch 3308/4000: train_loss=0.0050  test_loss=4.4687  λ_max=70.9926\n",
      "[SGD | lr=0.1] Epoch 3309/4000: train_loss=0.0050  test_loss=4.4689  λ_max=75.2741\n",
      "[SGD | lr=0.1] Epoch 3310/4000: train_loss=0.0050  test_loss=4.4692  λ_max=76.2120\n",
      "[SGD | lr=0.1] Epoch 3311/4000: train_loss=0.0050  test_loss=4.4694  λ_max=74.0733\n",
      "[SGD | lr=0.1] Epoch 3312/4000: train_loss=0.0050  test_loss=4.4695  λ_max=73.5750\n",
      "[SGD | lr=0.1] Iter 53000: loss=0.0049\n",
      "[SGD | lr=0.1] Epoch 3313/4000: train_loss=0.0050  test_loss=4.4698  λ_max=73.4589\n",
      "[SGD | lr=0.1] Epoch 3314/4000: train_loss=0.0050  test_loss=4.4699  λ_max=73.9585\n",
      "[SGD | lr=0.1] Epoch 3315/4000: train_loss=0.0050  test_loss=4.4702  λ_max=75.0937\n",
      "[SGD | lr=0.1] Epoch 3316/4000: train_loss=0.0050  test_loss=4.4703  λ_max=75.5369\n",
      "[SGD | lr=0.1] Epoch 3317/4000: train_loss=0.0050  test_loss=4.4706  λ_max=73.9072\n",
      "[SGD | lr=0.1] Epoch 3318/4000: train_loss=0.0050  test_loss=4.4709  λ_max=76.4433\n",
      "[SGD | lr=0.1] Iter 53100: loss=0.0050\n",
      "[SGD | lr=0.1] Epoch 3319/4000: train_loss=0.0050  test_loss=4.4712  λ_max=76.1544\n",
      "[SGD | lr=0.1] Epoch 3320/4000: train_loss=0.0050  test_loss=4.4713  λ_max=76.4164\n",
      "[SGD | lr=0.1] Epoch 3321/4000: train_loss=0.0050  test_loss=4.4714  λ_max=75.1347\n",
      "[SGD | lr=0.1] Epoch 3322/4000: train_loss=0.0050  test_loss=4.4717  λ_max=74.5669\n",
      "[SGD | lr=0.1] Epoch 3323/4000: train_loss=0.0050  test_loss=4.4719  λ_max=75.5788\n",
      "[SGD | lr=0.1] Epoch 3324/4000: train_loss=0.0050  test_loss=4.4722  λ_max=73.4495\n",
      "[SGD | lr=0.1] Iter 53200: loss=0.0050\n",
      "[SGD | lr=0.1] Epoch 3325/4000: train_loss=0.0050  test_loss=4.4724  λ_max=73.1081\n",
      "[SGD | lr=0.1] Epoch 3326/4000: train_loss=0.0050  test_loss=4.4725  λ_max=74.8526\n",
      "[SGD | lr=0.1] Epoch 3327/4000: train_loss=0.0050  test_loss=4.4728  λ_max=75.2518\n",
      "[SGD | lr=0.1] Epoch 3328/4000: train_loss=0.0050  test_loss=4.4730  λ_max=76.4958\n",
      "[SGD | lr=0.1] Epoch 3329/4000: train_loss=0.0050  test_loss=4.4731  λ_max=76.6187\n",
      "[SGD | lr=0.1] Epoch 3330/4000: train_loss=0.0050  test_loss=4.4735  λ_max=75.1546\n",
      "[SGD | lr=0.1] Epoch 3331/4000: train_loss=0.0049  test_loss=4.4736  λ_max=76.1361\n",
      "[SGD | lr=0.1] Iter 53300: loss=0.0049\n",
      "[SGD | lr=0.1] Epoch 3332/4000: train_loss=0.0049  test_loss=4.4738  λ_max=75.0638\n",
      "[SGD | lr=0.1] Epoch 3333/4000: train_loss=0.0049  test_loss=4.4740  λ_max=72.5673\n",
      "[SGD | lr=0.1] Epoch 3334/4000: train_loss=0.0049  test_loss=4.4742  λ_max=72.3825\n",
      "[SGD | lr=0.1] Epoch 3335/4000: train_loss=0.0049  test_loss=4.4744  λ_max=75.5961\n",
      "[SGD | lr=0.1] Epoch 3336/4000: train_loss=0.0049  test_loss=4.4747  λ_max=75.0576\n",
      "[SGD | lr=0.1] Epoch 3337/4000: train_loss=0.0049  test_loss=4.4748  λ_max=74.2163\n",
      "[SGD | lr=0.1] Iter 53400: loss=0.0049\n",
      "[SGD | lr=0.1] Epoch 3338/4000: train_loss=0.0049  test_loss=4.4752  λ_max=74.4516\n",
      "[SGD | lr=0.1] Epoch 3339/4000: train_loss=0.0049  test_loss=4.4754  λ_max=75.6752\n",
      "[SGD | lr=0.1] Epoch 3340/4000: train_loss=0.0049  test_loss=4.4755  λ_max=73.2844\n",
      "[SGD | lr=0.1] Epoch 3341/4000: train_loss=0.0049  test_loss=4.4757  λ_max=76.5165\n",
      "[SGD | lr=0.1] Epoch 3342/4000: train_loss=0.0049  test_loss=4.4759  λ_max=73.1268\n",
      "[SGD | lr=0.1] Epoch 3343/4000: train_loss=0.0049  test_loss=4.4761  λ_max=75.2685\n",
      "[SGD | lr=0.1] Iter 53500: loss=0.0050\n",
      "[SGD | lr=0.1] Epoch 3344/4000: train_loss=0.0049  test_loss=4.4764  λ_max=74.3583\n",
      "[SGD | lr=0.1] Epoch 3345/4000: train_loss=0.0049  test_loss=4.4766  λ_max=74.1476\n",
      "[SGD | lr=0.1] Epoch 3346/4000: train_loss=0.0049  test_loss=4.4768  λ_max=75.9965\n",
      "[SGD | lr=0.1] Epoch 3347/4000: train_loss=0.0049  test_loss=4.4770  λ_max=75.1270\n",
      "[SGD | lr=0.1] Epoch 3348/4000: train_loss=0.0049  test_loss=4.4771  λ_max=74.8710\n",
      "[SGD | lr=0.1] Epoch 3349/4000: train_loss=0.0049  test_loss=4.4774  λ_max=74.6831\n",
      "[SGD | lr=0.1] Iter 53600: loss=0.0049\n",
      "[SGD | lr=0.1] Epoch 3350/4000: train_loss=0.0049  test_loss=4.4776  λ_max=74.8234\n",
      "[SGD | lr=0.1] Epoch 3351/4000: train_loss=0.0049  test_loss=4.4779  λ_max=74.1152\n",
      "[SGD | lr=0.1] Epoch 3352/4000: train_loss=0.0049  test_loss=4.4780  λ_max=74.0038\n",
      "[SGD | lr=0.1] Epoch 3353/4000: train_loss=0.0049  test_loss=4.4782  λ_max=75.8345\n",
      "[SGD | lr=0.1] Epoch 3354/4000: train_loss=0.0049  test_loss=4.4784  λ_max=74.8609\n",
      "[SGD | lr=0.1] Epoch 3355/4000: train_loss=0.0049  test_loss=4.4786  λ_max=75.5502\n",
      "[SGD | lr=0.1] Epoch 3356/4000: train_loss=0.0049  test_loss=4.4789  λ_max=73.6861\n",
      "[SGD | lr=0.1] Iter 53700: loss=0.0049\n",
      "[SGD | lr=0.1] Epoch 3357/4000: train_loss=0.0049  test_loss=4.4793  λ_max=73.5939\n",
      "[SGD | lr=0.1] Epoch 3358/4000: train_loss=0.0049  test_loss=4.4793  λ_max=75.1721\n",
      "[SGD | lr=0.1] Epoch 3359/4000: train_loss=0.0049  test_loss=4.4796  λ_max=76.2468\n",
      "[SGD | lr=0.1] Epoch 3360/4000: train_loss=0.0049  test_loss=4.4797  λ_max=75.8485\n",
      "[SGD | lr=0.1] Epoch 3361/4000: train_loss=0.0049  test_loss=4.4798  λ_max=77.2082\n",
      "[SGD | lr=0.1] Epoch 3362/4000: train_loss=0.0049  test_loss=4.4801  λ_max=72.5034\n",
      "[SGD | lr=0.1] Iter 53800: loss=0.0049\n",
      "[SGD | lr=0.1] Epoch 3363/4000: train_loss=0.0049  test_loss=4.4804  λ_max=73.3393\n",
      "[SGD | lr=0.1] Epoch 3364/4000: train_loss=0.0049  test_loss=4.4805  λ_max=74.6890\n",
      "[SGD | lr=0.1] Epoch 3365/4000: train_loss=0.0049  test_loss=4.4806  λ_max=74.8468\n",
      "[SGD | lr=0.1] Epoch 3366/4000: train_loss=0.0049  test_loss=4.4809  λ_max=75.1368\n",
      "[SGD | lr=0.1] Epoch 3367/4000: train_loss=0.0049  test_loss=4.4812  λ_max=73.5770\n",
      "[SGD | lr=0.1] Epoch 3368/4000: train_loss=0.0049  test_loss=4.4814  λ_max=75.7979\n",
      "[SGD | lr=0.1] Iter 53900: loss=0.0049\n",
      "[SGD | lr=0.1] Epoch 3369/4000: train_loss=0.0049  test_loss=4.4816  λ_max=74.4023\n",
      "[SGD | lr=0.1] Epoch 3370/4000: train_loss=0.0049  test_loss=4.4819  λ_max=76.3793\n",
      "[SGD | lr=0.1] Epoch 3371/4000: train_loss=0.0049  test_loss=4.4821  λ_max=76.6252\n",
      "[SGD | lr=0.1] Epoch 3372/4000: train_loss=0.0049  test_loss=4.4822  λ_max=73.8662\n",
      "[SGD | lr=0.1] Epoch 3373/4000: train_loss=0.0049  test_loss=4.4824  λ_max=73.9698\n",
      "[SGD | lr=0.1] Epoch 3374/4000: train_loss=0.0049  test_loss=4.4827  λ_max=76.2995\n",
      "[SGD | lr=0.1] Iter 54000: loss=0.0047\n",
      "[SGD | lr=0.1] Epoch 3375/4000: train_loss=0.0049  test_loss=4.4828  λ_max=76.3567\n",
      "[SGD | lr=0.1] Epoch 3376/4000: train_loss=0.0049  test_loss=4.4830  λ_max=74.5459\n",
      "[SGD | lr=0.1] Epoch 3377/4000: train_loss=0.0049  test_loss=4.4832  λ_max=74.3909\n",
      "[SGD | lr=0.1] Epoch 3378/4000: train_loss=0.0049  test_loss=4.4835  λ_max=76.8799\n",
      "[SGD | lr=0.1] Epoch 3379/4000: train_loss=0.0049  test_loss=4.4837  λ_max=74.6470\n",
      "[SGD | lr=0.1] Epoch 3380/4000: train_loss=0.0049  test_loss=4.4840  λ_max=75.0469\n",
      "[SGD | lr=0.1] Epoch 3381/4000: train_loss=0.0049  test_loss=4.4841  λ_max=74.9392\n",
      "[SGD | lr=0.1] Iter 54100: loss=0.0048\n",
      "[SGD | lr=0.1] Epoch 3382/4000: train_loss=0.0048  test_loss=4.4843  λ_max=76.6705\n",
      "[SGD | lr=0.1] Epoch 3383/4000: train_loss=0.0048  test_loss=4.4846  λ_max=72.3622\n",
      "[SGD | lr=0.1] Epoch 3384/4000: train_loss=0.0048  test_loss=4.4848  λ_max=74.2935\n",
      "[SGD | lr=0.1] Epoch 3385/4000: train_loss=0.0048  test_loss=4.4850  λ_max=76.9114\n",
      "[SGD | lr=0.1] Epoch 3386/4000: train_loss=0.0048  test_loss=4.4852  λ_max=75.1060\n",
      "[SGD | lr=0.1] Epoch 3387/4000: train_loss=0.0048  test_loss=4.4853  λ_max=73.6477\n",
      "[SGD | lr=0.1] Iter 54200: loss=0.0048\n",
      "[SGD | lr=0.1] Epoch 3388/4000: train_loss=0.0048  test_loss=4.4856  λ_max=76.0459\n",
      "[SGD | lr=0.1] Epoch 3389/4000: train_loss=0.0048  test_loss=4.4857  λ_max=74.1746\n",
      "[SGD | lr=0.1] Epoch 3390/4000: train_loss=0.0048  test_loss=4.4861  λ_max=74.5758\n",
      "[SGD | lr=0.1] Epoch 3391/4000: train_loss=0.0048  test_loss=4.4863  λ_max=76.6934\n",
      "[SGD | lr=0.1] Epoch 3392/4000: train_loss=0.0048  test_loss=4.4863  λ_max=74.2188\n",
      "[SGD | lr=0.1] Epoch 3393/4000: train_loss=0.0048  test_loss=4.4867  λ_max=72.8937\n",
      "[SGD | lr=0.1] Iter 54300: loss=0.0048\n",
      "[SGD | lr=0.1] Epoch 3394/4000: train_loss=0.0048  test_loss=4.4869  λ_max=73.1987\n",
      "[SGD | lr=0.1] Epoch 3395/4000: train_loss=0.0048  test_loss=4.4870  λ_max=77.0102\n",
      "[SGD | lr=0.1] Epoch 3396/4000: train_loss=0.0048  test_loss=4.4872  λ_max=75.0296\n",
      "[SGD | lr=0.1] Epoch 3397/4000: train_loss=0.0048  test_loss=4.4875  λ_max=74.4372\n",
      "[SGD | lr=0.1] Epoch 3398/4000: train_loss=0.0048  test_loss=4.4876  λ_max=74.8697\n",
      "[SGD | lr=0.1] Epoch 3399/4000: train_loss=0.0048  test_loss=4.4879  λ_max=76.6890\n",
      "[SGD | lr=0.1] Iter 54400: loss=0.0047\n",
      "[SGD | lr=0.1] Epoch 3400/4000: train_loss=0.0048  test_loss=4.4881  λ_max=75.2377\n",
      "[SGD | lr=0.1] Epoch 3401/4000: train_loss=0.0048  test_loss=4.4882  λ_max=76.0978\n",
      "[SGD | lr=0.1] Epoch 3402/4000: train_loss=0.0048  test_loss=4.4885  λ_max=75.6131\n",
      "[SGD | lr=0.1] Epoch 3403/4000: train_loss=0.0048  test_loss=4.4885  λ_max=76.8170\n",
      "[SGD | lr=0.1] Epoch 3404/4000: train_loss=0.0048  test_loss=4.4890  λ_max=76.0739\n",
      "[SGD | lr=0.1] Epoch 3405/4000: train_loss=0.0048  test_loss=4.4892  λ_max=73.8986\n",
      "[SGD | lr=0.1] Epoch 3406/4000: train_loss=0.0048  test_loss=4.4894  λ_max=75.5830\n",
      "[SGD | lr=0.1] Iter 54500: loss=0.0048\n",
      "[SGD | lr=0.1] Epoch 3407/4000: train_loss=0.0048  test_loss=4.4895  λ_max=74.4266\n",
      "[SGD | lr=0.1] Epoch 3408/4000: train_loss=0.0048  test_loss=4.4898  λ_max=76.1645\n",
      "[SGD | lr=0.1] Epoch 3409/4000: train_loss=0.0048  test_loss=4.4900  λ_max=73.9998\n",
      "[SGD | lr=0.1] Epoch 3410/4000: train_loss=0.0048  test_loss=4.4901  λ_max=76.3005\n",
      "[SGD | lr=0.1] Epoch 3411/4000: train_loss=0.0048  test_loss=4.4904  λ_max=74.5929\n",
      "[SGD | lr=0.1] Epoch 3412/4000: train_loss=0.0048  test_loss=4.4906  λ_max=76.5855\n",
      "[SGD | lr=0.1] Iter 54600: loss=0.0049\n",
      "[SGD | lr=0.1] Epoch 3413/4000: train_loss=0.0048  test_loss=4.4909  λ_max=76.5869\n",
      "[SGD | lr=0.1] Epoch 3414/4000: train_loss=0.0048  test_loss=4.4909  λ_max=73.5354\n",
      "[SGD | lr=0.1] Epoch 3415/4000: train_loss=0.0048  test_loss=4.4913  λ_max=74.6916\n",
      "[SGD | lr=0.1] Epoch 3416/4000: train_loss=0.0048  test_loss=4.4914  λ_max=75.3446\n",
      "[SGD | lr=0.1] Epoch 3417/4000: train_loss=0.0048  test_loss=4.4916  λ_max=75.7538\n",
      "[SGD | lr=0.1] Epoch 3418/4000: train_loss=0.0048  test_loss=4.4918  λ_max=76.9193\n",
      "[SGD | lr=0.1] Iter 54700: loss=0.0047\n",
      "[SGD | lr=0.1] Epoch 3419/4000: train_loss=0.0048  test_loss=4.4920  λ_max=72.7381\n",
      "[SGD | lr=0.1] Epoch 3420/4000: train_loss=0.0048  test_loss=4.4921  λ_max=74.9465\n",
      "[SGD | lr=0.1] Epoch 3421/4000: train_loss=0.0048  test_loss=4.4925  λ_max=73.8793\n",
      "[SGD | lr=0.1] Epoch 3422/4000: train_loss=0.0048  test_loss=4.4928  λ_max=77.7667\n",
      "[SGD | lr=0.1] Epoch 3423/4000: train_loss=0.0048  test_loss=4.4930  λ_max=76.2329\n",
      "[SGD | lr=0.1] Epoch 3424/4000: train_loss=0.0048  test_loss=4.4930  λ_max=74.4677\n",
      "[SGD | lr=0.1] Iter 54800: loss=0.0049\n",
      "[SGD | lr=0.1] Epoch 3425/4000: train_loss=0.0048  test_loss=4.4933  λ_max=74.9137\n",
      "[SGD | lr=0.1] Epoch 3426/4000: train_loss=0.0048  test_loss=4.4936  λ_max=75.2562\n",
      "[SGD | lr=0.1] Epoch 3427/4000: train_loss=0.0048  test_loss=4.4937  λ_max=75.6995\n",
      "[SGD | lr=0.1] Epoch 3428/4000: train_loss=0.0048  test_loss=4.4939  λ_max=74.6366\n",
      "[SGD | lr=0.1] Epoch 3429/4000: train_loss=0.0048  test_loss=4.4942  λ_max=77.2364\n",
      "[SGD | lr=0.1] Epoch 3430/4000: train_loss=0.0048  test_loss=4.4943  λ_max=73.9163\n",
      "[SGD | lr=0.1] Epoch 3431/4000: train_loss=0.0048  test_loss=4.4945  λ_max=76.6588\n",
      "[SGD | lr=0.1] Iter 54900: loss=0.0048\n",
      "[SGD | lr=0.1] Epoch 3432/4000: train_loss=0.0048  test_loss=4.4946  λ_max=76.4999\n",
      "[SGD | lr=0.1] Epoch 3433/4000: train_loss=0.0048  test_loss=4.4949  λ_max=75.7400\n",
      "[SGD | lr=0.1] Epoch 3434/4000: train_loss=0.0048  test_loss=4.4952  λ_max=74.7399\n",
      "[SGD | lr=0.1] Epoch 3435/4000: train_loss=0.0048  test_loss=4.4953  λ_max=74.7680\n",
      "[SGD | lr=0.1] Epoch 3436/4000: train_loss=0.0047  test_loss=4.4956  λ_max=75.6409\n",
      "[SGD | lr=0.1] Epoch 3437/4000: train_loss=0.0047  test_loss=4.4957  λ_max=76.7705\n",
      "[SGD | lr=0.1] Iter 55000: loss=0.0048\n",
      "[SGD | lr=0.1] Epoch 3438/4000: train_loss=0.0047  test_loss=4.4961  λ_max=75.7682\n",
      "[SGD | lr=0.1] Epoch 3439/4000: train_loss=0.0047  test_loss=4.4961  λ_max=75.1455\n",
      "[SGD | lr=0.1] Epoch 3440/4000: train_loss=0.0047  test_loss=4.4963  λ_max=75.8501\n",
      "[SGD | lr=0.1] Epoch 3441/4000: train_loss=0.0047  test_loss=4.4965  λ_max=77.0275\n",
      "[SGD | lr=0.1] Epoch 3442/4000: train_loss=0.0047  test_loss=4.4969  λ_max=74.7414\n",
      "[SGD | lr=0.1] Epoch 3443/4000: train_loss=0.0047  test_loss=4.4969  λ_max=75.3645\n",
      "[SGD | lr=0.1] Iter 55100: loss=0.0048\n",
      "[SGD | lr=0.1] Epoch 3444/4000: train_loss=0.0047  test_loss=4.4972  λ_max=72.0011\n",
      "[SGD | lr=0.1] Epoch 3445/4000: train_loss=0.0047  test_loss=4.4976  λ_max=76.4098\n",
      "[SGD | lr=0.1] Epoch 3446/4000: train_loss=0.0047  test_loss=4.4975  λ_max=74.9816\n",
      "[SGD | lr=0.1] Epoch 3447/4000: train_loss=0.0047  test_loss=4.4978  λ_max=75.8648\n",
      "[SGD | lr=0.1] Epoch 3448/4000: train_loss=0.0047  test_loss=4.4980  λ_max=75.4059\n",
      "[SGD | lr=0.1] Epoch 3449/4000: train_loss=0.0047  test_loss=4.4983  λ_max=74.9669\n",
      "[SGD | lr=0.1] Iter 55200: loss=0.0048\n",
      "[SGD | lr=0.1] Epoch 3450/4000: train_loss=0.0047  test_loss=4.4984  λ_max=75.6379\n",
      "[SGD | lr=0.1] Epoch 3451/4000: train_loss=0.0047  test_loss=4.4987  λ_max=74.3554\n",
      "[SGD | lr=0.1] Epoch 3452/4000: train_loss=0.0047  test_loss=4.4987  λ_max=76.8012\n",
      "[SGD | lr=0.1] Epoch 3453/4000: train_loss=0.0047  test_loss=4.4990  λ_max=74.7073\n",
      "[SGD | lr=0.1] Epoch 3454/4000: train_loss=0.0047  test_loss=4.4992  λ_max=76.7627\n",
      "[SGD | lr=0.1] Epoch 3455/4000: train_loss=0.0047  test_loss=4.4995  λ_max=72.6177\n",
      "[SGD | lr=0.1] Epoch 3456/4000: train_loss=0.0047  test_loss=4.4997  λ_max=76.8517\n",
      "[SGD | lr=0.1] Iter 55300: loss=0.0048\n",
      "[SGD | lr=0.1] Epoch 3457/4000: train_loss=0.0047  test_loss=4.4998  λ_max=76.8904\n",
      "[SGD | lr=0.1] Epoch 3458/4000: train_loss=0.0047  test_loss=4.5000  λ_max=76.2464\n",
      "[SGD | lr=0.1] Epoch 3459/4000: train_loss=0.0047  test_loss=4.5002  λ_max=76.0062\n",
      "[SGD | lr=0.1] Epoch 3460/4000: train_loss=0.0047  test_loss=4.5005  λ_max=77.1731\n",
      "[SGD | lr=0.1] Epoch 3461/4000: train_loss=0.0047  test_loss=4.5006  λ_max=73.6707\n",
      "[SGD | lr=0.1] Epoch 3462/4000: train_loss=0.0047  test_loss=4.5009  λ_max=74.9395\n",
      "[SGD | lr=0.1] Iter 55400: loss=0.0048\n",
      "[SGD | lr=0.1] Epoch 3463/4000: train_loss=0.0047  test_loss=4.5011  λ_max=74.0508\n",
      "[SGD | lr=0.1] Epoch 3464/4000: train_loss=0.0047  test_loss=4.5013  λ_max=74.3947\n",
      "[SGD | lr=0.1] Epoch 3465/4000: train_loss=0.0047  test_loss=4.5014  λ_max=75.4322\n",
      "[SGD | lr=0.1] Epoch 3466/4000: train_loss=0.0047  test_loss=4.5017  λ_max=75.6117\n",
      "[SGD | lr=0.1] Epoch 3467/4000: train_loss=0.0047  test_loss=4.5018  λ_max=76.2658\n",
      "[SGD | lr=0.1] Epoch 3468/4000: train_loss=0.0047  test_loss=4.5021  λ_max=75.9005\n",
      "[SGD | lr=0.1] Iter 55500: loss=0.0047\n",
      "[SGD | lr=0.1] Epoch 3469/4000: train_loss=0.0047  test_loss=4.5023  λ_max=75.0351\n",
      "[SGD | lr=0.1] Epoch 3470/4000: train_loss=0.0047  test_loss=4.5024  λ_max=73.7858\n",
      "[SGD | lr=0.1] Epoch 3471/4000: train_loss=0.0047  test_loss=4.5027  λ_max=75.9190\n",
      "[SGD | lr=0.1] Epoch 3472/4000: train_loss=0.0047  test_loss=4.5031  λ_max=73.8836\n",
      "[SGD | lr=0.1] Epoch 3473/4000: train_loss=0.0047  test_loss=4.5031  λ_max=75.3400\n",
      "[SGD | lr=0.1] Epoch 3474/4000: train_loss=0.0047  test_loss=4.5033  λ_max=76.8149\n",
      "[SGD | lr=0.1] Iter 55600: loss=0.0046\n",
      "[SGD | lr=0.1] Epoch 3475/4000: train_loss=0.0047  test_loss=4.5035  λ_max=75.2355\n",
      "[SGD | lr=0.1] Epoch 3476/4000: train_loss=0.0047  test_loss=4.5037  λ_max=76.0404\n",
      "[SGD | lr=0.1] Epoch 3477/4000: train_loss=0.0047  test_loss=4.5038  λ_max=74.7502\n",
      "[SGD | lr=0.1] Epoch 3478/4000: train_loss=0.0047  test_loss=4.5042  λ_max=73.7809\n",
      "[SGD | lr=0.1] Epoch 3479/4000: train_loss=0.0047  test_loss=4.5043  λ_max=76.3757\n",
      "[SGD | lr=0.1] Epoch 3480/4000: train_loss=0.0047  test_loss=4.5045  λ_max=75.9756\n",
      "[SGD | lr=0.1] Epoch 3481/4000: train_loss=0.0047  test_loss=4.5049  λ_max=74.1684\n",
      "[SGD | lr=0.1] Iter 55700: loss=0.0046\n",
      "[SGD | lr=0.1] Epoch 3482/4000: train_loss=0.0047  test_loss=4.5049  λ_max=75.4619\n",
      "[SGD | lr=0.1] Epoch 3483/4000: train_loss=0.0047  test_loss=4.5051  λ_max=76.1115\n",
      "[SGD | lr=0.1] Epoch 3484/4000: train_loss=0.0047  test_loss=4.5053  λ_max=76.0325\n",
      "[SGD | lr=0.1] Epoch 3485/4000: train_loss=0.0047  test_loss=4.5056  λ_max=75.2650\n",
      "[SGD | lr=0.1] Epoch 3486/4000: train_loss=0.0047  test_loss=4.5058  λ_max=74.6503\n",
      "[SGD | lr=0.1] Epoch 3487/4000: train_loss=0.0047  test_loss=4.5059  λ_max=75.5533\n",
      "[SGD | lr=0.1] Iter 55800: loss=0.0047\n",
      "[SGD | lr=0.1] Epoch 3488/4000: train_loss=0.0047  test_loss=4.5062  λ_max=75.1856\n",
      "[SGD | lr=0.1] Epoch 3489/4000: train_loss=0.0047  test_loss=4.5065  λ_max=76.2044\n",
      "[SGD | lr=0.1] Epoch 3490/4000: train_loss=0.0047  test_loss=4.5067  λ_max=74.8920\n",
      "[SGD | lr=0.1] Epoch 3491/4000: train_loss=0.0047  test_loss=4.5068  λ_max=76.6934\n",
      "[SGD | lr=0.1] Epoch 3492/4000: train_loss=0.0047  test_loss=4.5069  λ_max=77.7550\n",
      "[SGD | lr=0.1] Epoch 3493/4000: train_loss=0.0046  test_loss=4.5072  λ_max=76.8749\n",
      "[SGD | lr=0.1] Iter 55900: loss=0.0047\n",
      "[SGD | lr=0.1] Epoch 3494/4000: train_loss=0.0046  test_loss=4.5073  λ_max=73.1634\n",
      "[SGD | lr=0.1] Epoch 3495/4000: train_loss=0.0046  test_loss=4.5076  λ_max=77.1058\n",
      "[SGD | lr=0.1] Epoch 3496/4000: train_loss=0.0046  test_loss=4.5077  λ_max=75.0208\n",
      "[SGD | lr=0.1] Epoch 3497/4000: train_loss=0.0046  test_loss=4.5080  λ_max=76.9202\n",
      "[SGD | lr=0.1] Epoch 3498/4000: train_loss=0.0046  test_loss=4.5082  λ_max=76.2354\n",
      "[SGD | lr=0.1] Epoch 3499/4000: train_loss=0.0046  test_loss=4.5084  λ_max=74.2984\n",
      "[SGD | lr=0.1] Iter 56000: loss=0.0046\n",
      "[SGD | lr=0.1] Epoch 3500/4000: train_loss=0.0046  test_loss=4.5085  λ_max=73.0344\n",
      "[SGD | lr=0.1] Epoch 3501/4000: train_loss=0.0046  test_loss=4.5088  λ_max=74.8486\n",
      "[SGD | lr=0.1] Epoch 3502/4000: train_loss=0.0046  test_loss=4.5091  λ_max=72.4413\n",
      "[SGD | lr=0.1] Epoch 3503/4000: train_loss=0.0046  test_loss=4.5093  λ_max=77.5294\n",
      "[SGD | lr=0.1] Epoch 3504/4000: train_loss=0.0046  test_loss=4.5094  λ_max=76.7007\n",
      "[SGD | lr=0.1] Epoch 3505/4000: train_loss=0.0046  test_loss=4.5097  λ_max=75.3755\n",
      "[SGD | lr=0.1] Epoch 3506/4000: train_loss=0.0046  test_loss=4.5098  λ_max=74.1358\n",
      "[SGD | lr=0.1] Iter 56100: loss=0.0046\n",
      "[SGD | lr=0.1] Epoch 3507/4000: train_loss=0.0046  test_loss=4.5100  λ_max=74.6499\n",
      "[SGD | lr=0.1] Epoch 3508/4000: train_loss=0.0046  test_loss=4.5102  λ_max=77.2210\n",
      "[SGD | lr=0.1] Epoch 3509/4000: train_loss=0.0046  test_loss=4.5105  λ_max=74.1171\n",
      "[SGD | lr=0.1] Epoch 3510/4000: train_loss=0.0046  test_loss=4.5106  λ_max=78.0788\n",
      "[SGD | lr=0.1] Epoch 3511/4000: train_loss=0.0046  test_loss=4.5109  λ_max=75.4131\n",
      "[SGD | lr=0.1] Epoch 3512/4000: train_loss=0.0046  test_loss=4.5110  λ_max=74.6658\n",
      "[SGD | lr=0.1] Iter 56200: loss=0.0047\n",
      "[SGD | lr=0.1] Epoch 3513/4000: train_loss=0.0046  test_loss=4.5112  λ_max=72.8792\n",
      "[SGD | lr=0.1] Epoch 3514/4000: train_loss=0.0046  test_loss=4.5115  λ_max=75.5550\n",
      "[SGD | lr=0.1] Epoch 3515/4000: train_loss=0.0046  test_loss=4.5117  λ_max=74.4871\n",
      "[SGD | lr=0.1] Epoch 3516/4000: train_loss=0.0046  test_loss=4.5118  λ_max=76.7717\n",
      "[SGD | lr=0.1] Epoch 3517/4000: train_loss=0.0046  test_loss=4.5120  λ_max=77.4497\n",
      "[SGD | lr=0.1] Epoch 3518/4000: train_loss=0.0046  test_loss=4.5122  λ_max=78.1054\n",
      "[SGD | lr=0.1] Iter 56300: loss=0.0047\n",
      "[SGD | lr=0.1] Epoch 3519/4000: train_loss=0.0046  test_loss=4.5124  λ_max=77.8065\n",
      "[SGD | lr=0.1] Epoch 3520/4000: train_loss=0.0046  test_loss=4.5127  λ_max=77.7472\n",
      "[SGD | lr=0.1] Epoch 3521/4000: train_loss=0.0046  test_loss=4.5129  λ_max=75.9666\n",
      "[SGD | lr=0.1] Epoch 3522/4000: train_loss=0.0046  test_loss=4.5130  λ_max=73.7533\n",
      "[SGD | lr=0.1] Epoch 3523/4000: train_loss=0.0046  test_loss=4.5132  λ_max=77.4871\n",
      "[SGD | lr=0.1] Epoch 3524/4000: train_loss=0.0046  test_loss=4.5134  λ_max=75.4744\n",
      "[SGD | lr=0.1] Iter 56400: loss=0.0047\n",
      "[SGD | lr=0.1] Epoch 3525/4000: train_loss=0.0046  test_loss=4.5136  λ_max=77.0412\n",
      "[SGD | lr=0.1] Epoch 3526/4000: train_loss=0.0046  test_loss=4.5138  λ_max=76.4610\n",
      "[SGD | lr=0.1] Epoch 3527/4000: train_loss=0.0046  test_loss=4.5141  λ_max=75.2953\n",
      "[SGD | lr=0.1] Epoch 3528/4000: train_loss=0.0046  test_loss=4.5141  λ_max=77.1943\n",
      "[SGD | lr=0.1] Epoch 3529/4000: train_loss=0.0046  test_loss=4.5144  λ_max=78.2054\n",
      "[SGD | lr=0.1] Epoch 3530/4000: train_loss=0.0046  test_loss=4.5147  λ_max=74.7889\n",
      "[SGD | lr=0.1] Epoch 3531/4000: train_loss=0.0046  test_loss=4.5147  λ_max=75.9133\n",
      "[SGD | lr=0.1] Iter 56500: loss=0.0047\n",
      "[SGD | lr=0.1] Epoch 3532/4000: train_loss=0.0046  test_loss=4.5151  λ_max=77.1172\n",
      "[SGD | lr=0.1] Epoch 3533/4000: train_loss=0.0046  test_loss=4.5152  λ_max=74.8083\n",
      "[SGD | lr=0.1] Epoch 3534/4000: train_loss=0.0046  test_loss=4.5154  λ_max=77.8173\n",
      "[SGD | lr=0.1] Epoch 3535/4000: train_loss=0.0046  test_loss=4.5155  λ_max=76.5533\n",
      "[SGD | lr=0.1] Epoch 3536/4000: train_loss=0.0046  test_loss=4.5158  λ_max=77.7176\n",
      "[SGD | lr=0.1] Epoch 3537/4000: train_loss=0.0046  test_loss=4.5160  λ_max=75.9033\n",
      "[SGD | lr=0.1] Iter 56600: loss=0.0046\n",
      "[SGD | lr=0.1] Epoch 3538/4000: train_loss=0.0046  test_loss=4.5161  λ_max=73.6608\n",
      "[SGD | lr=0.1] Epoch 3539/4000: train_loss=0.0046  test_loss=4.5164  λ_max=76.3135\n",
      "[SGD | lr=0.1] Epoch 3540/4000: train_loss=0.0046  test_loss=4.5166  λ_max=76.5301\n",
      "[SGD | lr=0.1] Epoch 3541/4000: train_loss=0.0046  test_loss=4.5168  λ_max=74.0222\n",
      "[SGD | lr=0.1] Epoch 3542/4000: train_loss=0.0046  test_loss=4.5172  λ_max=77.8459\n",
      "[SGD | lr=0.1] Epoch 3543/4000: train_loss=0.0046  test_loss=4.5172  λ_max=75.4381\n",
      "[SGD | lr=0.1] Iter 56700: loss=0.0046\n",
      "[SGD | lr=0.1] Epoch 3544/4000: train_loss=0.0046  test_loss=4.5174  λ_max=75.4133\n",
      "[SGD | lr=0.1] Epoch 3545/4000: train_loss=0.0046  test_loss=4.5176  λ_max=77.2167\n",
      "[SGD | lr=0.1] Epoch 3546/4000: train_loss=0.0046  test_loss=4.5178  λ_max=74.9197\n",
      "[SGD | lr=0.1] Epoch 3547/4000: train_loss=0.0046  test_loss=4.5181  λ_max=74.7633\n",
      "[SGD | lr=0.1] Epoch 3548/4000: train_loss=0.0046  test_loss=4.5181  λ_max=75.4367\n",
      "[SGD | lr=0.1] Epoch 3549/4000: train_loss=0.0046  test_loss=4.5184  λ_max=75.8120\n",
      "[SGD | lr=0.1] Iter 56800: loss=0.0046\n",
      "[SGD | lr=0.1] Epoch 3550/4000: train_loss=0.0046  test_loss=4.5186  λ_max=76.2603\n",
      "[SGD | lr=0.1] Epoch 3551/4000: train_loss=0.0045  test_loss=4.5188  λ_max=77.6708\n",
      "[SGD | lr=0.1] Epoch 3552/4000: train_loss=0.0045  test_loss=4.5190  λ_max=76.3380\n",
      "[SGD | lr=0.1] Epoch 3553/4000: train_loss=0.0045  test_loss=4.5191  λ_max=76.5431\n",
      "[SGD | lr=0.1] Epoch 3554/4000: train_loss=0.0045  test_loss=4.5194  λ_max=76.3976\n",
      "[SGD | lr=0.1] Epoch 3555/4000: train_loss=0.0045  test_loss=4.5196  λ_max=76.1774\n",
      "[SGD | lr=0.1] Epoch 3556/4000: train_loss=0.0045  test_loss=4.5198  λ_max=75.0251\n",
      "[SGD | lr=0.1] Iter 56900: loss=0.0045\n",
      "[SGD | lr=0.1] Epoch 3557/4000: train_loss=0.0045  test_loss=4.5199  λ_max=77.0076\n",
      "[SGD | lr=0.1] Epoch 3558/4000: train_loss=0.0045  test_loss=4.5202  λ_max=72.9683\n",
      "[SGD | lr=0.1] Epoch 3559/4000: train_loss=0.0045  test_loss=4.5204  λ_max=75.0088\n",
      "[SGD | lr=0.1] Epoch 3560/4000: train_loss=0.0045  test_loss=4.5206  λ_max=77.7671\n",
      "[SGD | lr=0.1] Epoch 3561/4000: train_loss=0.0045  test_loss=4.5207  λ_max=75.3892\n",
      "[SGD | lr=0.1] Epoch 3562/4000: train_loss=0.0045  test_loss=4.5209  λ_max=76.5225\n",
      "[SGD | lr=0.1] Iter 57000: loss=0.0046\n",
      "[SGD | lr=0.1] Epoch 3563/4000: train_loss=0.0045  test_loss=4.5213  λ_max=73.6650\n",
      "[SGD | lr=0.1] Epoch 3564/4000: train_loss=0.0045  test_loss=4.5214  λ_max=75.2347\n",
      "[SGD | lr=0.1] Epoch 3565/4000: train_loss=0.0045  test_loss=4.5215  λ_max=78.1129\n",
      "[SGD | lr=0.1] Epoch 3566/4000: train_loss=0.0045  test_loss=4.5218  λ_max=77.1123\n",
      "[SGD | lr=0.1] Epoch 3567/4000: train_loss=0.0045  test_loss=4.5220  λ_max=76.5345\n",
      "[SGD | lr=0.1] Epoch 3568/4000: train_loss=0.0045  test_loss=4.5221  λ_max=74.5545\n",
      "[SGD | lr=0.1] Iter 57100: loss=0.0044\n",
      "[SGD | lr=0.1] Epoch 3569/4000: train_loss=0.0045  test_loss=4.5224  λ_max=77.1123\n",
      "[SGD | lr=0.1] Epoch 3570/4000: train_loss=0.0045  test_loss=4.5225  λ_max=76.9208\n",
      "[SGD | lr=0.1] Epoch 3571/4000: train_loss=0.0045  test_loss=4.5227  λ_max=76.6315\n",
      "[SGD | lr=0.1] Epoch 3572/4000: train_loss=0.0045  test_loss=4.5228  λ_max=77.0268\n",
      "[SGD | lr=0.1] Epoch 3573/4000: train_loss=0.0045  test_loss=4.5232  λ_max=75.7722\n",
      "[SGD | lr=0.1] Epoch 3574/4000: train_loss=0.0045  test_loss=4.5234  λ_max=78.6740\n",
      "[SGD | lr=0.1] Iter 57200: loss=0.0046\n",
      "[SGD | lr=0.1] Epoch 3575/4000: train_loss=0.0045  test_loss=4.5236  λ_max=75.5944\n",
      "[SGD | lr=0.1] Epoch 3576/4000: train_loss=0.0045  test_loss=4.5238  λ_max=76.3561\n",
      "[SGD | lr=0.1] Epoch 3577/4000: train_loss=0.0045  test_loss=4.5239  λ_max=73.2902\n",
      "[SGD | lr=0.1] Epoch 3578/4000: train_loss=0.0045  test_loss=4.5241  λ_max=76.9014\n",
      "[SGD | lr=0.1] Epoch 3579/4000: train_loss=0.0045  test_loss=4.5244  λ_max=75.7565\n",
      "[SGD | lr=0.1] Epoch 3580/4000: train_loss=0.0045  test_loss=4.5245  λ_max=77.9403\n",
      "[SGD | lr=0.1] Epoch 3581/4000: train_loss=0.0045  test_loss=4.5248  λ_max=74.5236\n",
      "[SGD | lr=0.1] Iter 57300: loss=0.0047\n",
      "[SGD | lr=0.1] Epoch 3582/4000: train_loss=0.0045  test_loss=4.5249  λ_max=76.0490\n",
      "[SGD | lr=0.1] Epoch 3583/4000: train_loss=0.0045  test_loss=4.5251  λ_max=76.0204\n",
      "[SGD | lr=0.1] Epoch 3584/4000: train_loss=0.0045  test_loss=4.5253  λ_max=77.8029\n",
      "[SGD | lr=0.1] Epoch 3585/4000: train_loss=0.0045  test_loss=4.5256  λ_max=76.4141\n",
      "[SGD | lr=0.1] Epoch 3586/4000: train_loss=0.0045  test_loss=4.5257  λ_max=78.5763\n",
      "[SGD | lr=0.1] Epoch 3587/4000: train_loss=0.0045  test_loss=4.5259  λ_max=75.3130\n",
      "[SGD | lr=0.1] Iter 57400: loss=0.0045\n",
      "[SGD | lr=0.1] Epoch 3588/4000: train_loss=0.0045  test_loss=4.5261  λ_max=73.8208\n",
      "[SGD | lr=0.1] Epoch 3589/4000: train_loss=0.0045  test_loss=4.5263  λ_max=79.2608\n",
      "[SGD | lr=0.1] Epoch 3590/4000: train_loss=0.0045  test_loss=4.5265  λ_max=74.1079\n",
      "[SGD | lr=0.1] Epoch 3591/4000: train_loss=0.0045  test_loss=4.5266  λ_max=76.8683\n",
      "[SGD | lr=0.1] Epoch 3592/4000: train_loss=0.0045  test_loss=4.5269  λ_max=77.7846\n",
      "[SGD | lr=0.1] Epoch 3593/4000: train_loss=0.0045  test_loss=4.5271  λ_max=74.5954\n",
      "[SGD | lr=0.1] Iter 57500: loss=0.0045\n",
      "[SGD | lr=0.1] Epoch 3594/4000: train_loss=0.0045  test_loss=4.5272  λ_max=76.1764\n",
      "[SGD | lr=0.1] Epoch 3595/4000: train_loss=0.0045  test_loss=4.5274  λ_max=77.7445\n",
      "[SGD | lr=0.1] Epoch 3596/4000: train_loss=0.0045  test_loss=4.5276  λ_max=76.3442\n",
      "[SGD | lr=0.1] Epoch 3597/4000: train_loss=0.0045  test_loss=4.5279  λ_max=77.6762\n",
      "[SGD | lr=0.1] Epoch 3598/4000: train_loss=0.0045  test_loss=4.5280  λ_max=77.9721\n",
      "[SGD | lr=0.1] Epoch 3599/4000: train_loss=0.0045  test_loss=4.5282  λ_max=75.0993\n",
      "[SGD | lr=0.1] Iter 57600: loss=0.0046\n",
      "[SGD | lr=0.1] Epoch 3600/4000: train_loss=0.0045  test_loss=4.5285  λ_max=75.7010\n",
      "[SGD | lr=0.1] Epoch 3601/4000: train_loss=0.0045  test_loss=4.5287  λ_max=75.0188\n",
      "[SGD | lr=0.1] Epoch 3602/4000: train_loss=0.0045  test_loss=4.5289  λ_max=78.0847\n",
      "[SGD | lr=0.1] Epoch 3603/4000: train_loss=0.0045  test_loss=4.5291  λ_max=77.5689\n",
      "[SGD | lr=0.1] Epoch 3604/4000: train_loss=0.0045  test_loss=4.5293  λ_max=76.9807\n",
      "[SGD | lr=0.1] Epoch 3605/4000: train_loss=0.0045  test_loss=4.5294  λ_max=75.3402\n",
      "[SGD | lr=0.1] Epoch 3606/4000: train_loss=0.0045  test_loss=4.5297  λ_max=76.2833\n",
      "[SGD | lr=0.1] Iter 57700: loss=0.0045\n",
      "[SGD | lr=0.1] Epoch 3607/4000: train_loss=0.0045  test_loss=4.5299  λ_max=76.0894\n",
      "[SGD | lr=0.1] Epoch 3608/4000: train_loss=0.0045  test_loss=4.5300  λ_max=74.4979\n",
      "[SGD | lr=0.1] Epoch 3609/4000: train_loss=0.0045  test_loss=4.5301  λ_max=78.2097\n",
      "[SGD | lr=0.1] Epoch 3610/4000: train_loss=0.0045  test_loss=4.5304  λ_max=76.7179\n",
      "[SGD | lr=0.1] Epoch 3611/4000: train_loss=0.0045  test_loss=4.5306  λ_max=78.3593\n",
      "[SGD | lr=0.1] Epoch 3612/4000: train_loss=0.0045  test_loss=4.5308  λ_max=78.0463\n",
      "[SGD | lr=0.1] Iter 57800: loss=0.0044\n",
      "[SGD | lr=0.1] Epoch 3613/4000: train_loss=0.0045  test_loss=4.5309  λ_max=77.5720\n",
      "[SGD | lr=0.1] Epoch 3614/4000: train_loss=0.0044  test_loss=4.5312  λ_max=76.9250\n",
      "[SGD | lr=0.1] Epoch 3615/4000: train_loss=0.0044  test_loss=4.5314  λ_max=77.3359\n",
      "[SGD | lr=0.1] Epoch 3616/4000: train_loss=0.0044  test_loss=4.5317  λ_max=78.3090\n",
      "[SGD | lr=0.1] Epoch 3617/4000: train_loss=0.0044  test_loss=4.5317  λ_max=77.8013\n",
      "[SGD | lr=0.1] Epoch 3618/4000: train_loss=0.0044  test_loss=4.5319  λ_max=77.1121\n",
      "[SGD | lr=0.1] Iter 57900: loss=0.0044\n",
      "[SGD | lr=0.1] Epoch 3619/4000: train_loss=0.0044  test_loss=4.5321  λ_max=77.9297\n",
      "[SGD | lr=0.1] Epoch 3620/4000: train_loss=0.0044  test_loss=4.5323  λ_max=76.8141\n",
      "[SGD | lr=0.1] Epoch 3621/4000: train_loss=0.0044  test_loss=4.5324  λ_max=76.9986\n",
      "[SGD | lr=0.1] Epoch 3622/4000: train_loss=0.0044  test_loss=4.5328  λ_max=74.9641\n",
      "[SGD | lr=0.1] Epoch 3623/4000: train_loss=0.0044  test_loss=4.5329  λ_max=76.9556\n",
      "[SGD | lr=0.1] Epoch 3624/4000: train_loss=0.0044  test_loss=4.5331  λ_max=74.3335\n",
      "[SGD | lr=0.1] Iter 58000: loss=0.0045\n",
      "[SGD | lr=0.1] Epoch 3625/4000: train_loss=0.0044  test_loss=4.5333  λ_max=75.0293\n",
      "[SGD | lr=0.1] Epoch 3626/4000: train_loss=0.0044  test_loss=4.5335  λ_max=76.4756\n",
      "[SGD | lr=0.1] Epoch 3627/4000: train_loss=0.0044  test_loss=4.5337  λ_max=74.0474\n",
      "[SGD | lr=0.1] Epoch 3628/4000: train_loss=0.0044  test_loss=4.5340  λ_max=75.1177\n",
      "[SGD | lr=0.1] Epoch 3629/4000: train_loss=0.0044  test_loss=4.5341  λ_max=75.2981\n",
      "[SGD | lr=0.1] Epoch 3630/4000: train_loss=0.0044  test_loss=4.5342  λ_max=76.8081\n",
      "[SGD | lr=0.1] Epoch 3631/4000: train_loss=0.0044  test_loss=4.5345  λ_max=77.0956\n",
      "[SGD | lr=0.1] Iter 58100: loss=0.0044\n",
      "[SGD | lr=0.1] Epoch 3632/4000: train_loss=0.0044  test_loss=4.5346  λ_max=74.0510\n",
      "[SGD | lr=0.1] Epoch 3633/4000: train_loss=0.0044  test_loss=4.5349  λ_max=74.4093\n",
      "[SGD | lr=0.1] Epoch 3634/4000: train_loss=0.0044  test_loss=4.5350  λ_max=76.2041\n",
      "[SGD | lr=0.1] Epoch 3635/4000: train_loss=0.0044  test_loss=4.5352  λ_max=75.0232\n",
      "[SGD | lr=0.1] Epoch 3636/4000: train_loss=0.0044  test_loss=4.5355  λ_max=74.6270\n",
      "[SGD | lr=0.1] Epoch 3637/4000: train_loss=0.0044  test_loss=4.5357  λ_max=78.1019\n",
      "[SGD | lr=0.1] Iter 58200: loss=0.0044\n",
      "[SGD | lr=0.1] Epoch 3638/4000: train_loss=0.0044  test_loss=4.5359  λ_max=77.9223\n",
      "[SGD | lr=0.1] Epoch 3639/4000: train_loss=0.0044  test_loss=4.5359  λ_max=75.0989\n",
      "[SGD | lr=0.1] Epoch 3640/4000: train_loss=0.0044  test_loss=4.5362  λ_max=76.0786\n",
      "[SGD | lr=0.1] Epoch 3641/4000: train_loss=0.0044  test_loss=4.5364  λ_max=74.9807\n",
      "[SGD | lr=0.1] Epoch 3642/4000: train_loss=0.0044  test_loss=4.5366  λ_max=75.2469\n",
      "[SGD | lr=0.1] Epoch 3643/4000: train_loss=0.0044  test_loss=4.5368  λ_max=76.4094\n",
      "[SGD | lr=0.1] Iter 58300: loss=0.0045\n",
      "[SGD | lr=0.1] Epoch 3644/4000: train_loss=0.0044  test_loss=4.5370  λ_max=75.8971\n",
      "[SGD | lr=0.1] Epoch 3645/4000: train_loss=0.0044  test_loss=4.5372  λ_max=76.9786\n",
      "[SGD | lr=0.1] Epoch 3646/4000: train_loss=0.0044  test_loss=4.5373  λ_max=75.1125\n",
      "[SGD | lr=0.1] Epoch 3647/4000: train_loss=0.0044  test_loss=4.5374  λ_max=73.5171\n",
      "[SGD | lr=0.1] Epoch 3648/4000: train_loss=0.0044  test_loss=4.5378  λ_max=74.4811\n",
      "[SGD | lr=0.1] Epoch 3649/4000: train_loss=0.0044  test_loss=4.5380  λ_max=78.0794\n",
      "[SGD | lr=0.1] Iter 58400: loss=0.0045\n",
      "[SGD | lr=0.1] Epoch 3650/4000: train_loss=0.0044  test_loss=4.5381  λ_max=75.8773\n",
      "[SGD | lr=0.1] Epoch 3651/4000: train_loss=0.0044  test_loss=4.5384  λ_max=77.0228\n",
      "[SGD | lr=0.1] Epoch 3652/4000: train_loss=0.0044  test_loss=4.5384  λ_max=74.5669\n",
      "[SGD | lr=0.1] Epoch 3653/4000: train_loss=0.0044  test_loss=4.5386  λ_max=76.6309\n",
      "[SGD | lr=0.1] Epoch 3654/4000: train_loss=0.0044  test_loss=4.5388  λ_max=77.6230\n",
      "[SGD | lr=0.1] Epoch 3655/4000: train_loss=0.0044  test_loss=4.5390  λ_max=78.3047\n",
      "[SGD | lr=0.1] Epoch 3656/4000: train_loss=0.0044  test_loss=4.5393  λ_max=75.7557\n",
      "[SGD | lr=0.1] Iter 58500: loss=0.0045\n",
      "[SGD | lr=0.1] Epoch 3657/4000: train_loss=0.0044  test_loss=4.5395  λ_max=76.0575\n",
      "[SGD | lr=0.1] Epoch 3658/4000: train_loss=0.0044  test_loss=4.5397  λ_max=78.4586\n",
      "[SGD | lr=0.1] Epoch 3659/4000: train_loss=0.0044  test_loss=4.5399  λ_max=75.1831\n",
      "[SGD | lr=0.1] Epoch 3660/4000: train_loss=0.0044  test_loss=4.5400  λ_max=75.9503\n",
      "[SGD | lr=0.1] Epoch 3661/4000: train_loss=0.0044  test_loss=4.5403  λ_max=77.8732\n",
      "[SGD | lr=0.1] Epoch 3662/4000: train_loss=0.0044  test_loss=4.5405  λ_max=76.6562\n",
      "[SGD | lr=0.1] Iter 58600: loss=0.0044\n",
      "[SGD | lr=0.1] Epoch 3663/4000: train_loss=0.0044  test_loss=4.5406  λ_max=78.6684\n",
      "[SGD | lr=0.1] Epoch 3664/4000: train_loss=0.0044  test_loss=4.5408  λ_max=78.7276\n",
      "[SGD | lr=0.1] Epoch 3665/4000: train_loss=0.0044  test_loss=4.5410  λ_max=76.4714\n",
      "[SGD | lr=0.1] Epoch 3666/4000: train_loss=0.0044  test_loss=4.5411  λ_max=77.6960\n",
      "[SGD | lr=0.1] Epoch 3667/4000: train_loss=0.0044  test_loss=4.5414  λ_max=76.6345\n",
      "[SGD | lr=0.1] Epoch 3668/4000: train_loss=0.0044  test_loss=4.5415  λ_max=76.6401\n",
      "[SGD | lr=0.1] Iter 58700: loss=0.0043\n",
      "[SGD | lr=0.1] Epoch 3669/4000: train_loss=0.0044  test_loss=4.5418  λ_max=77.8481\n",
      "[SGD | lr=0.1] Epoch 3670/4000: train_loss=0.0044  test_loss=4.5420  λ_max=77.4951\n",
      "[SGD | lr=0.1] Epoch 3671/4000: train_loss=0.0044  test_loss=4.5422  λ_max=76.5561\n",
      "[SGD | lr=0.1] Epoch 3672/4000: train_loss=0.0044  test_loss=4.5424  λ_max=76.3931\n",
      "[SGD | lr=0.1] Epoch 3673/4000: train_loss=0.0044  test_loss=4.5426  λ_max=77.9821\n",
      "[SGD | lr=0.1] Epoch 3674/4000: train_loss=0.0044  test_loss=4.5426  λ_max=74.9475\n",
      "[SGD | lr=0.1] Iter 58800: loss=0.0044\n",
      "[SGD | lr=0.1] Epoch 3675/4000: train_loss=0.0044  test_loss=4.5430  λ_max=78.6538\n",
      "[SGD | lr=0.1] Epoch 3676/4000: train_loss=0.0044  test_loss=4.5431  λ_max=73.8101\n",
      "[SGD | lr=0.1] Epoch 3677/4000: train_loss=0.0044  test_loss=4.5434  λ_max=75.9529\n",
      "[SGD | lr=0.1] Epoch 3678/4000: train_loss=0.0043  test_loss=4.5433  λ_max=77.0315\n",
      "[SGD | lr=0.1] Epoch 3679/4000: train_loss=0.0043  test_loss=4.5437  λ_max=75.7618\n",
      "[SGD | lr=0.1] Epoch 3680/4000: train_loss=0.0043  test_loss=4.5439  λ_max=77.6011\n",
      "[SGD | lr=0.1] Epoch 3681/4000: train_loss=0.0043  test_loss=4.5441  λ_max=78.7356\n",
      "[SGD | lr=0.1] Iter 58900: loss=0.0044\n",
      "[SGD | lr=0.1] Epoch 3682/4000: train_loss=0.0043  test_loss=4.5443  λ_max=77.5686\n",
      "[SGD | lr=0.1] Epoch 3683/4000: train_loss=0.0043  test_loss=4.5444  λ_max=77.5065\n",
      "[SGD | lr=0.1] Epoch 3684/4000: train_loss=0.0043  test_loss=4.5446  λ_max=75.5580\n",
      "[SGD | lr=0.1] Epoch 3685/4000: train_loss=0.0043  test_loss=4.5448  λ_max=77.8708\n",
      "[SGD | lr=0.1] Epoch 3686/4000: train_loss=0.0043  test_loss=4.5450  λ_max=76.9940\n",
      "[SGD | lr=0.1] Epoch 3687/4000: train_loss=0.0043  test_loss=4.5453  λ_max=77.5590\n",
      "[SGD | lr=0.1] Iter 59000: loss=0.0043\n",
      "[SGD | lr=0.1] Epoch 3688/4000: train_loss=0.0043  test_loss=4.5455  λ_max=78.4544\n",
      "[SGD | lr=0.1] Epoch 3689/4000: train_loss=0.0043  test_loss=4.5456  λ_max=78.4898\n",
      "[SGD | lr=0.1] Epoch 3690/4000: train_loss=0.0043  test_loss=4.5458  λ_max=76.6115\n",
      "[SGD | lr=0.1] Epoch 3691/4000: train_loss=0.0043  test_loss=4.5459  λ_max=73.8242\n",
      "[SGD | lr=0.1] Epoch 3692/4000: train_loss=0.0043  test_loss=4.5461  λ_max=75.4111\n",
      "[SGD | lr=0.1] Epoch 3693/4000: train_loss=0.0043  test_loss=4.5463  λ_max=76.6678\n",
      "[SGD | lr=0.1] Iter 59100: loss=0.0045\n",
      "[SGD | lr=0.1] Epoch 3694/4000: train_loss=0.0043  test_loss=4.5465  λ_max=78.5126\n",
      "[SGD | lr=0.1] Epoch 3695/4000: train_loss=0.0043  test_loss=4.5468  λ_max=75.1665\n",
      "[SGD | lr=0.1] Epoch 3696/4000: train_loss=0.0043  test_loss=4.5469  λ_max=74.9625\n",
      "[SGD | lr=0.1] Epoch 3697/4000: train_loss=0.0043  test_loss=4.5470  λ_max=78.3875\n",
      "[SGD | lr=0.1] Epoch 3698/4000: train_loss=0.0043  test_loss=4.5472  λ_max=78.6528\n",
      "[SGD | lr=0.1] Epoch 3699/4000: train_loss=0.0043  test_loss=4.5474  λ_max=76.6578\n",
      "[SGD | lr=0.1] Iter 59200: loss=0.0044\n",
      "[SGD | lr=0.1] Epoch 3700/4000: train_loss=0.0043  test_loss=4.5476  λ_max=76.2952\n",
      "[SGD | lr=0.1] Epoch 3701/4000: train_loss=0.0043  test_loss=4.5480  λ_max=77.7814\n",
      "[SGD | lr=0.1] Epoch 3702/4000: train_loss=0.0043  test_loss=4.5480  λ_max=77.9437\n",
      "[SGD | lr=0.1] Epoch 3703/4000: train_loss=0.0043  test_loss=4.5482  λ_max=77.5786\n",
      "[SGD | lr=0.1] Epoch 3704/4000: train_loss=0.0043  test_loss=4.5484  λ_max=77.9860\n",
      "[SGD | lr=0.1] Epoch 3705/4000: train_loss=0.0043  test_loss=4.5486  λ_max=75.8979\n",
      "[SGD | lr=0.1] Epoch 3706/4000: train_loss=0.0043  test_loss=4.5489  λ_max=78.6414\n",
      "[SGD | lr=0.1] Iter 59300: loss=0.0043\n",
      "[SGD | lr=0.1] Epoch 3707/4000: train_loss=0.0043  test_loss=4.5490  λ_max=76.9036\n",
      "[SGD | lr=0.1] Epoch 3708/4000: train_loss=0.0043  test_loss=4.5491  λ_max=78.3236\n",
      "[SGD | lr=0.1] Epoch 3709/4000: train_loss=0.0043  test_loss=4.5492  λ_max=76.7763\n",
      "[SGD | lr=0.1] Epoch 3710/4000: train_loss=0.0043  test_loss=4.5496  λ_max=76.0875\n",
      "[SGD | lr=0.1] Epoch 3711/4000: train_loss=0.0043  test_loss=4.5498  λ_max=76.2540\n",
      "[SGD | lr=0.1] Epoch 3712/4000: train_loss=0.0043  test_loss=4.5500  λ_max=74.6746\n",
      "[SGD | lr=0.1] Iter 59400: loss=0.0043\n",
      "[SGD | lr=0.1] Epoch 3713/4000: train_loss=0.0043  test_loss=4.5500  λ_max=76.4101\n",
      "[SGD | lr=0.1] Epoch 3714/4000: train_loss=0.0043  test_loss=4.5503  λ_max=76.6982\n",
      "[SGD | lr=0.1] Epoch 3715/4000: train_loss=0.0043  test_loss=4.5505  λ_max=78.0469\n",
      "[SGD | lr=0.1] Epoch 3716/4000: train_loss=0.0043  test_loss=4.5507  λ_max=76.1659\n",
      "[SGD | lr=0.1] Epoch 3717/4000: train_loss=0.0043  test_loss=4.5509  λ_max=75.3301\n",
      "[SGD | lr=0.1] Epoch 3718/4000: train_loss=0.0043  test_loss=4.5511  λ_max=75.4444\n",
      "[SGD | lr=0.1] Iter 59500: loss=0.0042\n",
      "[SGD | lr=0.1] Epoch 3719/4000: train_loss=0.0043  test_loss=4.5512  λ_max=75.2669\n",
      "[SGD | lr=0.1] Epoch 3720/4000: train_loss=0.0043  test_loss=4.5514  λ_max=79.2320\n",
      "[SGD | lr=0.1] Epoch 3721/4000: train_loss=0.0043  test_loss=4.5516  λ_max=76.0916\n",
      "[SGD | lr=0.1] Epoch 3722/4000: train_loss=0.0043  test_loss=4.5519  λ_max=74.5872\n",
      "[SGD | lr=0.1] Epoch 3723/4000: train_loss=0.0043  test_loss=4.5519  λ_max=78.7104\n",
      "[SGD | lr=0.1] Epoch 3724/4000: train_loss=0.0043  test_loss=4.5521  λ_max=79.0903\n",
      "[SGD | lr=0.1] Iter 59600: loss=0.0042\n",
      "[SGD | lr=0.1] Epoch 3725/4000: train_loss=0.0043  test_loss=4.5523  λ_max=78.1108\n",
      "[SGD | lr=0.1] Epoch 3726/4000: train_loss=0.0043  test_loss=4.5526  λ_max=74.7463\n",
      "[SGD | lr=0.1] Epoch 3727/4000: train_loss=0.0043  test_loss=4.5527  λ_max=73.5129\n",
      "[SGD | lr=0.1] Epoch 3728/4000: train_loss=0.0043  test_loss=4.5529  λ_max=75.0132\n",
      "[SGD | lr=0.1] Epoch 3729/4000: train_loss=0.0043  test_loss=4.5532  λ_max=75.1002\n",
      "[SGD | lr=0.1] Epoch 3730/4000: train_loss=0.0043  test_loss=4.5532  λ_max=78.3485\n",
      "[SGD | lr=0.1] Epoch 3731/4000: train_loss=0.0043  test_loss=4.5534  λ_max=76.1261\n",
      "[SGD | lr=0.1] Iter 59700: loss=0.0043\n",
      "[SGD | lr=0.1] Epoch 3732/4000: train_loss=0.0043  test_loss=4.5538  λ_max=75.1386\n",
      "[SGD | lr=0.1] Epoch 3733/4000: train_loss=0.0043  test_loss=4.5538  λ_max=77.0563\n",
      "[SGD | lr=0.1] Epoch 3734/4000: train_loss=0.0043  test_loss=4.5540  λ_max=76.9791\n",
      "[SGD | lr=0.1] Epoch 3735/4000: train_loss=0.0043  test_loss=4.5542  λ_max=79.1310\n",
      "[SGD | lr=0.1] Epoch 3736/4000: train_loss=0.0043  test_loss=4.5544  λ_max=76.5009\n",
      "[SGD | lr=0.1] Epoch 3737/4000: train_loss=0.0043  test_loss=4.5546  λ_max=76.9618\n",
      "[SGD | lr=0.1] Iter 59800: loss=0.0044\n",
      "[SGD | lr=0.1] Epoch 3738/4000: train_loss=0.0043  test_loss=4.5550  λ_max=76.2218\n",
      "[SGD | lr=0.1] Epoch 3739/4000: train_loss=0.0043  test_loss=4.5550  λ_max=78.7180\n",
      "[SGD | lr=0.1] Epoch 3740/4000: train_loss=0.0043  test_loss=4.5552  λ_max=76.4870\n",
      "[SGD | lr=0.1] Epoch 3741/4000: train_loss=0.0043  test_loss=4.5554  λ_max=76.8288\n",
      "[SGD | lr=0.1] Epoch 3742/4000: train_loss=0.0043  test_loss=4.5556  λ_max=77.8739\n",
      "[SGD | lr=0.1] Epoch 3743/4000: train_loss=0.0043  test_loss=4.5557  λ_max=76.7646\n",
      "[SGD | lr=0.1] Iter 59900: loss=0.0042\n",
      "[SGD | lr=0.1] Epoch 3744/4000: train_loss=0.0043  test_loss=4.5559  λ_max=75.0418\n",
      "[SGD | lr=0.1] Epoch 3745/4000: train_loss=0.0042  test_loss=4.5561  λ_max=77.3376\n",
      "[SGD | lr=0.1] Epoch 3746/4000: train_loss=0.0042  test_loss=4.5563  λ_max=78.1221\n",
      "[SGD | lr=0.1] Epoch 3747/4000: train_loss=0.0042  test_loss=4.5565  λ_max=75.2132\n",
      "[SGD | lr=0.1] Epoch 3748/4000: train_loss=0.0042  test_loss=4.5566  λ_max=78.9713\n",
      "[SGD | lr=0.1] Epoch 3749/4000: train_loss=0.0042  test_loss=4.5568  λ_max=76.1286\n",
      "[SGD | lr=0.1] Iter 60000: loss=0.0043\n",
      "[SGD | lr=0.1] Epoch 3750/4000: train_loss=0.0042  test_loss=4.5573  λ_max=74.5367\n",
      "[SGD | lr=0.1] Epoch 3751/4000: train_loss=0.0042  test_loss=4.5573  λ_max=73.9670\n",
      "[SGD | lr=0.1] Epoch 3752/4000: train_loss=0.0042  test_loss=4.5575  λ_max=78.9432\n",
      "[SGD | lr=0.1] Epoch 3753/4000: train_loss=0.0042  test_loss=4.5576  λ_max=79.5324\n",
      "[SGD | lr=0.1] Epoch 3754/4000: train_loss=0.0042  test_loss=4.5578  λ_max=78.0511\n",
      "[SGD | lr=0.1] Epoch 3755/4000: train_loss=0.0042  test_loss=4.5581  λ_max=76.1019\n",
      "[SGD | lr=0.1] Epoch 3756/4000: train_loss=0.0042  test_loss=4.5581  λ_max=78.2111\n",
      "[SGD | lr=0.1] Iter 60100: loss=0.0043\n",
      "[SGD | lr=0.1] Epoch 3757/4000: train_loss=0.0042  test_loss=4.5583  λ_max=77.8548\n",
      "[SGD | lr=0.1] Epoch 3758/4000: train_loss=0.0042  test_loss=4.5587  λ_max=76.8054\n",
      "[SGD | lr=0.1] Epoch 3759/4000: train_loss=0.0042  test_loss=4.5587  λ_max=78.2540\n",
      "[SGD | lr=0.1] Epoch 3760/4000: train_loss=0.0042  test_loss=4.5590  λ_max=77.3884\n",
      "[SGD | lr=0.1] Epoch 3761/4000: train_loss=0.0042  test_loss=4.5590  λ_max=75.4025\n",
      "[SGD | lr=0.1] Epoch 3762/4000: train_loss=0.0042  test_loss=4.5593  λ_max=76.3729\n",
      "[SGD | lr=0.1] Iter 60200: loss=0.0042\n",
      "[SGD | lr=0.1] Epoch 3763/4000: train_loss=0.0042  test_loss=4.5596  λ_max=77.8693\n",
      "[SGD | lr=0.1] Epoch 3764/4000: train_loss=0.0042  test_loss=4.5597  λ_max=78.1275\n",
      "[SGD | lr=0.1] Epoch 3765/4000: train_loss=0.0042  test_loss=4.5599  λ_max=78.9195\n",
      "[SGD | lr=0.1] Epoch 3766/4000: train_loss=0.0042  test_loss=4.5600  λ_max=77.6653\n",
      "[SGD | lr=0.1] Epoch 3767/4000: train_loss=0.0042  test_loss=4.5602  λ_max=78.7310\n",
      "[SGD | lr=0.1] Epoch 3768/4000: train_loss=0.0042  test_loss=4.5605  λ_max=77.4981\n",
      "[SGD | lr=0.1] Iter 60300: loss=0.0042\n",
      "[SGD | lr=0.1] Epoch 3769/4000: train_loss=0.0042  test_loss=4.5606  λ_max=78.4843\n",
      "[SGD | lr=0.1] Epoch 3770/4000: train_loss=0.0042  test_loss=4.5607  λ_max=75.6794\n",
      "[SGD | lr=0.1] Epoch 3771/4000: train_loss=0.0042  test_loss=4.5609  λ_max=78.7512\n",
      "[SGD | lr=0.1] Epoch 3772/4000: train_loss=0.0042  test_loss=4.5612  λ_max=77.2534\n",
      "[SGD | lr=0.1] Epoch 3773/4000: train_loss=0.0042  test_loss=4.5614  λ_max=77.6168\n",
      "[SGD | lr=0.1] Epoch 3774/4000: train_loss=0.0042  test_loss=4.5615  λ_max=74.1722\n",
      "[SGD | lr=0.1] Iter 60400: loss=0.0042\n",
      "[SGD | lr=0.1] Epoch 3775/4000: train_loss=0.0042  test_loss=4.5617  λ_max=75.9446\n",
      "[SGD | lr=0.1] Epoch 3776/4000: train_loss=0.0042  test_loss=4.5619  λ_max=76.1898\n",
      "[SGD | lr=0.1] Epoch 3777/4000: train_loss=0.0042  test_loss=4.5621  λ_max=77.8592\n",
      "[SGD | lr=0.1] Epoch 3778/4000: train_loss=0.0042  test_loss=4.5623  λ_max=75.4822\n",
      "[SGD | lr=0.1] Epoch 3779/4000: train_loss=0.0042  test_loss=4.5625  λ_max=78.8202\n",
      "[SGD | lr=0.1] Epoch 3780/4000: train_loss=0.0042  test_loss=4.5626  λ_max=79.9078\n",
      "[SGD | lr=0.1] Epoch 3781/4000: train_loss=0.0042  test_loss=4.5629  λ_max=80.1305\n",
      "[SGD | lr=0.1] Iter 60500: loss=0.0043\n",
      "[SGD | lr=0.1] Epoch 3782/4000: train_loss=0.0042  test_loss=4.5630  λ_max=75.8089\n",
      "[SGD | lr=0.1] Epoch 3783/4000: train_loss=0.0042  test_loss=4.5632  λ_max=77.2033\n",
      "[SGD | lr=0.1] Epoch 3784/4000: train_loss=0.0042  test_loss=4.5634  λ_max=78.3392\n",
      "[SGD | lr=0.1] Epoch 3785/4000: train_loss=0.0042  test_loss=4.5635  λ_max=78.8588\n",
      "[SGD | lr=0.1] Epoch 3786/4000: train_loss=0.0042  test_loss=4.5637  λ_max=77.7709\n",
      "[SGD | lr=0.1] Epoch 3787/4000: train_loss=0.0042  test_loss=4.5640  λ_max=77.4056\n",
      "[SGD | lr=0.1] Iter 60600: loss=0.0042\n",
      "[SGD | lr=0.1] Epoch 3788/4000: train_loss=0.0042  test_loss=4.5641  λ_max=77.5273\n",
      "[SGD | lr=0.1] Epoch 3789/4000: train_loss=0.0042  test_loss=4.5644  λ_max=75.5262\n",
      "[SGD | lr=0.1] Epoch 3790/4000: train_loss=0.0042  test_loss=4.5645  λ_max=77.8220\n",
      "[SGD | lr=0.1] Epoch 3791/4000: train_loss=0.0042  test_loss=4.5646  λ_max=78.6328\n",
      "[SGD | lr=0.1] Epoch 3792/4000: train_loss=0.0042  test_loss=4.5648  λ_max=78.0664\n",
      "[SGD | lr=0.1] Epoch 3793/4000: train_loss=0.0042  test_loss=4.5651  λ_max=77.4202\n",
      "[SGD | lr=0.1] Iter 60700: loss=0.0041\n",
      "[SGD | lr=0.1] Epoch 3794/4000: train_loss=0.0042  test_loss=4.5652  λ_max=78.8427\n",
      "[SGD | lr=0.1] Epoch 3795/4000: train_loss=0.0042  test_loss=4.5654  λ_max=76.5748\n",
      "[SGD | lr=0.1] Epoch 3796/4000: train_loss=0.0042  test_loss=4.5656  λ_max=77.0253\n",
      "[SGD | lr=0.1] Epoch 3797/4000: train_loss=0.0042  test_loss=4.5658  λ_max=76.0762\n",
      "[SGD | lr=0.1] Epoch 3798/4000: train_loss=0.0042  test_loss=4.5660  λ_max=79.2016\n",
      "[SGD | lr=0.1] Epoch 3799/4000: train_loss=0.0042  test_loss=4.5663  λ_max=75.6458\n",
      "[SGD | lr=0.1] Iter 60800: loss=0.0041\n",
      "[SGD | lr=0.1] Epoch 3800/4000: train_loss=0.0042  test_loss=4.5663  λ_max=78.6163\n",
      "[SGD | lr=0.1] Epoch 3801/4000: train_loss=0.0042  test_loss=4.5665  λ_max=77.9459\n",
      "[SGD | lr=0.1] Epoch 3802/4000: train_loss=0.0042  test_loss=4.5667  λ_max=77.9076\n",
      "[SGD | lr=0.1] Epoch 3803/4000: train_loss=0.0042  test_loss=4.5668  λ_max=79.5281\n",
      "[SGD | lr=0.1] Epoch 3804/4000: train_loss=0.0042  test_loss=4.5671  λ_max=78.4539\n",
      "[SGD | lr=0.1] Epoch 3805/4000: train_loss=0.0042  test_loss=4.5672  λ_max=80.5135\n",
      "[SGD | lr=0.1] Epoch 3806/4000: train_loss=0.0042  test_loss=4.5673  λ_max=77.1495\n",
      "[SGD | lr=0.1] Iter 60900: loss=0.0041\n",
      "[SGD | lr=0.1] Epoch 3807/4000: train_loss=0.0042  test_loss=4.5677  λ_max=76.7185\n",
      "[SGD | lr=0.1] Epoch 3808/4000: train_loss=0.0042  test_loss=4.5678  λ_max=78.5969\n",
      "[SGD | lr=0.1] Epoch 3809/4000: train_loss=0.0042  test_loss=4.5680  λ_max=78.0334\n",
      "[SGD | lr=0.1] Epoch 3810/4000: train_loss=0.0042  test_loss=4.5682  λ_max=78.7147\n",
      "[SGD | lr=0.1] Epoch 3811/4000: train_loss=0.0042  test_loss=4.5684  λ_max=79.3624\n",
      "[SGD | lr=0.1] Epoch 3812/4000: train_loss=0.0042  test_loss=4.5686  λ_max=77.8100\n",
      "[SGD | lr=0.1] Iter 61000: loss=0.0041\n",
      "[SGD | lr=0.1] Epoch 3813/4000: train_loss=0.0042  test_loss=4.5688  λ_max=77.0894\n",
      "[SGD | lr=0.1] Epoch 3814/4000: train_loss=0.0042  test_loss=4.5690  λ_max=79.9812\n",
      "[SGD | lr=0.1] Epoch 3815/4000: train_loss=0.0041  test_loss=4.5692  λ_max=78.5025\n",
      "[SGD | lr=0.1] Epoch 3816/4000: train_loss=0.0041  test_loss=4.5692  λ_max=80.1661\n",
      "[SGD | lr=0.1] Epoch 3817/4000: train_loss=0.0041  test_loss=4.5695  λ_max=77.5065\n",
      "[SGD | lr=0.1] Epoch 3818/4000: train_loss=0.0041  test_loss=4.5696  λ_max=75.6175\n",
      "[SGD | lr=0.1] Iter 61100: loss=0.0041\n",
      "[SGD | lr=0.1] Epoch 3819/4000: train_loss=0.0041  test_loss=4.5699  λ_max=77.9209\n",
      "[SGD | lr=0.1] Epoch 3820/4000: train_loss=0.0041  test_loss=4.5700  λ_max=77.3744\n",
      "[SGD | lr=0.1] Epoch 3821/4000: train_loss=0.0041  test_loss=4.5703  λ_max=78.0553\n",
      "[SGD | lr=0.1] Epoch 3822/4000: train_loss=0.0041  test_loss=4.5704  λ_max=75.2434\n",
      "[SGD | lr=0.1] Epoch 3823/4000: train_loss=0.0041  test_loss=4.5706  λ_max=78.6184\n",
      "[SGD | lr=0.1] Epoch 3824/4000: train_loss=0.0041  test_loss=4.5708  λ_max=76.2890\n",
      "[SGD | lr=0.1] Iter 61200: loss=0.0042\n",
      "[SGD | lr=0.1] Epoch 3825/4000: train_loss=0.0041  test_loss=4.5709  λ_max=78.1115\n",
      "[SGD | lr=0.1] Epoch 3826/4000: train_loss=0.0041  test_loss=4.5711  λ_max=79.5843\n",
      "[SGD | lr=0.1] Epoch 3827/4000: train_loss=0.0041  test_loss=4.5713  λ_max=76.0769\n",
      "[SGD | lr=0.1] Epoch 3828/4000: train_loss=0.0041  test_loss=4.5715  λ_max=79.4853\n",
      "[SGD | lr=0.1] Epoch 3829/4000: train_loss=0.0041  test_loss=4.5717  λ_max=78.5993\n",
      "[SGD | lr=0.1] Epoch 3830/4000: train_loss=0.0041  test_loss=4.5718  λ_max=76.9589\n",
      "[SGD | lr=0.1] Epoch 3831/4000: train_loss=0.0041  test_loss=4.5720  λ_max=77.7763\n",
      "[SGD | lr=0.1] Iter 61300: loss=0.0042\n",
      "[SGD | lr=0.1] Epoch 3832/4000: train_loss=0.0041  test_loss=4.5723  λ_max=76.7043\n",
      "[SGD | lr=0.1] Epoch 3833/4000: train_loss=0.0041  test_loss=4.5724  λ_max=79.6507\n",
      "[SGD | lr=0.1] Epoch 3834/4000: train_loss=0.0041  test_loss=4.5726  λ_max=76.9052\n",
      "[SGD | lr=0.1] Epoch 3835/4000: train_loss=0.0041  test_loss=4.5728  λ_max=77.7551\n",
      "[SGD | lr=0.1] Epoch 3836/4000: train_loss=0.0041  test_loss=4.5729  λ_max=80.2168\n",
      "[SGD | lr=0.1] Epoch 3837/4000: train_loss=0.0041  test_loss=4.5731  λ_max=78.6190\n",
      "[SGD | lr=0.1] Iter 61400: loss=0.0042\n",
      "[SGD | lr=0.1] Epoch 3838/4000: train_loss=0.0041  test_loss=4.5735  λ_max=76.7170\n",
      "[SGD | lr=0.1] Epoch 3839/4000: train_loss=0.0041  test_loss=4.5735  λ_max=78.2189\n",
      "[SGD | lr=0.1] Epoch 3840/4000: train_loss=0.0041  test_loss=4.5737  λ_max=77.8147\n",
      "[SGD | lr=0.1] Epoch 3841/4000: train_loss=0.0041  test_loss=4.5739  λ_max=78.2026\n",
      "[SGD | lr=0.1] Epoch 3842/4000: train_loss=0.0041  test_loss=4.5739  λ_max=76.5526\n",
      "[SGD | lr=0.1] Epoch 3843/4000: train_loss=0.0041  test_loss=4.5742  λ_max=77.5756\n",
      "[SGD | lr=0.1] Iter 61500: loss=0.0041\n",
      "[SGD | lr=0.1] Epoch 3844/4000: train_loss=0.0041  test_loss=4.5743  λ_max=78.0534\n",
      "[SGD | lr=0.1] Epoch 3845/4000: train_loss=0.0041  test_loss=4.5746  λ_max=77.0647\n",
      "[SGD | lr=0.1] Epoch 3846/4000: train_loss=0.0041  test_loss=4.5748  λ_max=76.8936\n",
      "[SGD | lr=0.1] Epoch 3847/4000: train_loss=0.0041  test_loss=4.5749  λ_max=76.9143\n",
      "[SGD | lr=0.1] Epoch 3848/4000: train_loss=0.0041  test_loss=4.5752  λ_max=76.3658\n",
      "[SGD | lr=0.1] Epoch 3849/4000: train_loss=0.0041  test_loss=4.5753  λ_max=76.7503\n",
      "[SGD | lr=0.1] Iter 61600: loss=0.0041\n",
      "[SGD | lr=0.1] Epoch 3850/4000: train_loss=0.0041  test_loss=4.5754  λ_max=78.4447\n",
      "[SGD | lr=0.1] Epoch 3851/4000: train_loss=0.0041  test_loss=4.5757  λ_max=77.4162\n",
      "[SGD | lr=0.1] Epoch 3852/4000: train_loss=0.0041  test_loss=4.5758  λ_max=75.6959\n",
      "[SGD | lr=0.1] Epoch 3853/4000: train_loss=0.0041  test_loss=4.5761  λ_max=75.5509\n",
      "[SGD | lr=0.1] Epoch 3854/4000: train_loss=0.0041  test_loss=4.5762  λ_max=77.0165\n",
      "[SGD | lr=0.1] Epoch 3855/4000: train_loss=0.0041  test_loss=4.5764  λ_max=76.7116\n",
      "[SGD | lr=0.1] Epoch 3856/4000: train_loss=0.0041  test_loss=4.5765  λ_max=78.6753\n",
      "[SGD | lr=0.1] Iter 61700: loss=0.0041\n",
      "[SGD | lr=0.1] Epoch 3857/4000: train_loss=0.0041  test_loss=4.5768  λ_max=76.9221\n",
      "[SGD | lr=0.1] Epoch 3858/4000: train_loss=0.0041  test_loss=4.5769  λ_max=79.1218\n",
      "[SGD | lr=0.1] Epoch 3859/4000: train_loss=0.0041  test_loss=4.5771  λ_max=78.5820\n",
      "[SGD | lr=0.1] Epoch 3860/4000: train_loss=0.0041  test_loss=4.5773  λ_max=76.1024\n",
      "[SGD | lr=0.1] Epoch 3861/4000: train_loss=0.0041  test_loss=4.5774  λ_max=75.8538\n",
      "[SGD | lr=0.1] Epoch 3862/4000: train_loss=0.0041  test_loss=4.5777  λ_max=75.3901\n",
      "[SGD | lr=0.1] Iter 61800: loss=0.0040\n",
      "[SGD | lr=0.1] Epoch 3863/4000: train_loss=0.0041  test_loss=4.5778  λ_max=77.5489\n",
      "[SGD | lr=0.1] Epoch 3864/4000: train_loss=0.0041  test_loss=4.5780  λ_max=76.4346\n",
      "[SGD | lr=0.1] Epoch 3865/4000: train_loss=0.0041  test_loss=4.5781  λ_max=78.5212\n",
      "[SGD | lr=0.1] Epoch 3866/4000: train_loss=0.0041  test_loss=4.5783  λ_max=79.4048\n",
      "[SGD | lr=0.1] Epoch 3867/4000: train_loss=0.0041  test_loss=4.5786  λ_max=78.4932\n",
      "[SGD | lr=0.1] Epoch 3868/4000: train_loss=0.0041  test_loss=4.5788  λ_max=78.6483\n",
      "[SGD | lr=0.1] Iter 61900: loss=0.0040\n",
      "[SGD | lr=0.1] Epoch 3869/4000: train_loss=0.0041  test_loss=4.5790  λ_max=79.8523\n",
      "[SGD | lr=0.1] Epoch 3870/4000: train_loss=0.0041  test_loss=4.5791  λ_max=79.4510\n",
      "[SGD | lr=0.1] Epoch 3871/4000: train_loss=0.0041  test_loss=4.5793  λ_max=77.6652\n",
      "[SGD | lr=0.1] Epoch 3872/4000: train_loss=0.0041  test_loss=4.5795  λ_max=77.6563\n",
      "[SGD | lr=0.1] Epoch 3873/4000: train_loss=0.0041  test_loss=4.5797  λ_max=79.2095\n",
      "[SGD | lr=0.1] Epoch 3874/4000: train_loss=0.0041  test_loss=4.5797  λ_max=76.8115\n",
      "[SGD | lr=0.1] Iter 62000: loss=0.0042\n",
      "[SGD | lr=0.1] Epoch 3875/4000: train_loss=0.0041  test_loss=4.5801  λ_max=79.8377\n",
      "[SGD | lr=0.1] Epoch 3876/4000: train_loss=0.0041  test_loss=4.5801  λ_max=80.1510\n",
      "[SGD | lr=0.1] Epoch 3877/4000: train_loss=0.0041  test_loss=4.5804  λ_max=80.7086\n",
      "[SGD | lr=0.1] Epoch 3878/4000: train_loss=0.0041  test_loss=4.5806  λ_max=80.2255\n",
      "[SGD | lr=0.1] Epoch 3879/4000: train_loss=0.0041  test_loss=4.5807  λ_max=77.4241\n",
      "[SGD | lr=0.1] Epoch 3880/4000: train_loss=0.0041  test_loss=4.5810  λ_max=79.2377\n",
      "[SGD | lr=0.1] Epoch 3881/4000: train_loss=0.0041  test_loss=4.5811  λ_max=76.2846\n",
      "[SGD | lr=0.1] Iter 62100: loss=0.0040\n",
      "[SGD | lr=0.1] Epoch 3882/4000: train_loss=0.0041  test_loss=4.5813  λ_max=78.7191\n",
      "[SGD | lr=0.1] Epoch 3883/4000: train_loss=0.0041  test_loss=4.5814  λ_max=76.4157\n",
      "[SGD | lr=0.1] Epoch 3884/4000: train_loss=0.0041  test_loss=4.5817  λ_max=78.1084\n",
      "[SGD | lr=0.1] Epoch 3885/4000: train_loss=0.0041  test_loss=4.5818  λ_max=79.7542\n",
      "[SGD | lr=0.1] Epoch 3886/4000: train_loss=0.0041  test_loss=4.5820  λ_max=78.3835\n",
      "[SGD | lr=0.1] Epoch 3887/4000: train_loss=0.0040  test_loss=4.5823  λ_max=77.5743\n",
      "[SGD | lr=0.1] Iter 62200: loss=0.0041\n",
      "[SGD | lr=0.1] Epoch 3888/4000: train_loss=0.0040  test_loss=4.5824  λ_max=78.9442\n",
      "[SGD | lr=0.1] Epoch 3889/4000: train_loss=0.0040  test_loss=4.5826  λ_max=79.5908\n",
      "[SGD | lr=0.1] Epoch 3890/4000: train_loss=0.0040  test_loss=4.5828  λ_max=78.0437\n",
      "[SGD | lr=0.1] Epoch 3891/4000: train_loss=0.0040  test_loss=4.5829  λ_max=76.4259\n",
      "[SGD | lr=0.1] Epoch 3892/4000: train_loss=0.0040  test_loss=4.5830  λ_max=80.5466\n",
      "[SGD | lr=0.1] Epoch 3893/4000: train_loss=0.0040  test_loss=4.5833  λ_max=78.1399\n",
      "[SGD | lr=0.1] Iter 62300: loss=0.0041\n",
      "[SGD | lr=0.1] Epoch 3894/4000: train_loss=0.0040  test_loss=4.5835  λ_max=78.2128\n",
      "[SGD | lr=0.1] Epoch 3895/4000: train_loss=0.0040  test_loss=4.5837  λ_max=78.3593\n",
      "[SGD | lr=0.1] Epoch 3896/4000: train_loss=0.0040  test_loss=4.5838  λ_max=78.1801\n",
      "[SGD | lr=0.1] Epoch 3897/4000: train_loss=0.0040  test_loss=4.5840  λ_max=79.1153\n",
      "[SGD | lr=0.1] Epoch 3898/4000: train_loss=0.0040  test_loss=4.5842  λ_max=77.0700\n",
      "[SGD | lr=0.1] Epoch 3899/4000: train_loss=0.0040  test_loss=4.5843  λ_max=76.6019\n",
      "[SGD | lr=0.1] Iter 62400: loss=0.0040\n",
      "[SGD | lr=0.1] Epoch 3900/4000: train_loss=0.0040  test_loss=4.5845  λ_max=78.0874\n",
      "[SGD | lr=0.1] Epoch 3901/4000: train_loss=0.0040  test_loss=4.5847  λ_max=76.6848\n",
      "[SGD | lr=0.1] Epoch 3902/4000: train_loss=0.0040  test_loss=4.5850  λ_max=79.2817\n",
      "[SGD | lr=0.1] Epoch 3903/4000: train_loss=0.0040  test_loss=4.5851  λ_max=76.0774\n",
      "[SGD | lr=0.1] Epoch 3904/4000: train_loss=0.0040  test_loss=4.5853  λ_max=75.5252\n",
      "[SGD | lr=0.1] Epoch 3905/4000: train_loss=0.0040  test_loss=4.5855  λ_max=79.0768\n",
      "[SGD | lr=0.1] Epoch 3906/4000: train_loss=0.0040  test_loss=4.5856  λ_max=78.4314\n",
      "[SGD | lr=0.1] Iter 62500: loss=0.0040\n",
      "[SGD | lr=0.1] Epoch 3907/4000: train_loss=0.0040  test_loss=4.5857  λ_max=78.5409\n",
      "[SGD | lr=0.1] Epoch 3908/4000: train_loss=0.0040  test_loss=4.5860  λ_max=79.5018\n",
      "[SGD | lr=0.1] Epoch 3909/4000: train_loss=0.0040  test_loss=4.5862  λ_max=78.1248\n",
      "[SGD | lr=0.1] Epoch 3910/4000: train_loss=0.0040  test_loss=4.5864  λ_max=76.9192\n",
      "[SGD | lr=0.1] Epoch 3911/4000: train_loss=0.0040  test_loss=4.5865  λ_max=78.0998\n",
      "[SGD | lr=0.1] Epoch 3912/4000: train_loss=0.0040  test_loss=4.5868  λ_max=79.7817\n",
      "[SGD | lr=0.1] Iter 62600: loss=0.0041\n",
      "[SGD | lr=0.1] Epoch 3913/4000: train_loss=0.0040  test_loss=4.5868  λ_max=76.8915\n",
      "[SGD | lr=0.1] Epoch 3914/4000: train_loss=0.0040  test_loss=4.5870  λ_max=79.4995\n",
      "[SGD | lr=0.1] Epoch 3915/4000: train_loss=0.0040  test_loss=4.5871  λ_max=77.3694\n",
      "[SGD | lr=0.1] Epoch 3916/4000: train_loss=0.0040  test_loss=4.5874  λ_max=78.8712\n",
      "[SGD | lr=0.1] Epoch 3917/4000: train_loss=0.0040  test_loss=4.5876  λ_max=78.0792\n",
      "[SGD | lr=0.1] Epoch 3918/4000: train_loss=0.0040  test_loss=4.5877  λ_max=74.5979\n",
      "[SGD | lr=0.1] Iter 62700: loss=0.0040\n",
      "[SGD | lr=0.1] Epoch 3919/4000: train_loss=0.0040  test_loss=4.5880  λ_max=76.6246\n",
      "[SGD | lr=0.1] Epoch 3920/4000: train_loss=0.0040  test_loss=4.5881  λ_max=78.4498\n",
      "[SGD | lr=0.1] Epoch 3921/4000: train_loss=0.0040  test_loss=4.5883  λ_max=80.0309\n",
      "[SGD | lr=0.1] Epoch 3922/4000: train_loss=0.0040  test_loss=4.5884  λ_max=78.1825\n",
      "[SGD | lr=0.1] Epoch 3923/4000: train_loss=0.0040  test_loss=4.5886  λ_max=78.6543\n",
      "[SGD | lr=0.1] Epoch 3924/4000: train_loss=0.0040  test_loss=4.5888  λ_max=79.2889\n",
      "[SGD | lr=0.1] Iter 62800: loss=0.0040\n",
      "[SGD | lr=0.1] Epoch 3925/4000: train_loss=0.0040  test_loss=4.5890  λ_max=78.7111\n",
      "[SGD | lr=0.1] Epoch 3926/4000: train_loss=0.0040  test_loss=4.5892  λ_max=77.3563\n",
      "[SGD | lr=0.1] Epoch 3927/4000: train_loss=0.0040  test_loss=4.5894  λ_max=76.8723\n",
      "[SGD | lr=0.1] Epoch 3928/4000: train_loss=0.0040  test_loss=4.5894  λ_max=76.3465\n",
      "[SGD | lr=0.1] Epoch 3929/4000: train_loss=0.0040  test_loss=4.5898  λ_max=78.9977\n",
      "[SGD | lr=0.1] Epoch 3930/4000: train_loss=0.0040  test_loss=4.5899  λ_max=78.2347\n",
      "[SGD | lr=0.1] Epoch 3931/4000: train_loss=0.0040  test_loss=4.5900  λ_max=77.2079\n",
      "[SGD | lr=0.1] Iter 62900: loss=0.0040\n",
      "[SGD | lr=0.1] Epoch 3932/4000: train_loss=0.0040  test_loss=4.5902  λ_max=77.5152\n",
      "[SGD | lr=0.1] Epoch 3933/4000: train_loss=0.0040  test_loss=4.5904  λ_max=80.1415\n",
      "[SGD | lr=0.1] Epoch 3934/4000: train_loss=0.0040  test_loss=4.5906  λ_max=75.9879\n",
      "[SGD | lr=0.1] Epoch 3935/4000: train_loss=0.0040  test_loss=4.5908  λ_max=78.7928\n",
      "[SGD | lr=0.1] Epoch 3936/4000: train_loss=0.0040  test_loss=4.5909  λ_max=77.7000\n",
      "[SGD | lr=0.1] Epoch 3937/4000: train_loss=0.0040  test_loss=4.5911  λ_max=76.2550\n",
      "[SGD | lr=0.1] Iter 63000: loss=0.0040\n",
      "[SGD | lr=0.1] Epoch 3938/4000: train_loss=0.0040  test_loss=4.5912  λ_max=77.9723\n",
      "[SGD | lr=0.1] Epoch 3939/4000: train_loss=0.0040  test_loss=4.5915  λ_max=76.5630\n",
      "[SGD | lr=0.1] Epoch 3940/4000: train_loss=0.0040  test_loss=4.5916  λ_max=78.6423\n",
      "[SGD | lr=0.1] Epoch 3941/4000: train_loss=0.0040  test_loss=4.5919  λ_max=77.8623\n",
      "[SGD | lr=0.1] Epoch 3942/4000: train_loss=0.0040  test_loss=4.5921  λ_max=79.9225\n",
      "[SGD | lr=0.1] Epoch 3943/4000: train_loss=0.0040  test_loss=4.5923  λ_max=77.8931\n",
      "[SGD | lr=0.1] Iter 63100: loss=0.0039\n",
      "[SGD | lr=0.1] Epoch 3944/4000: train_loss=0.0040  test_loss=4.5924  λ_max=78.0282\n",
      "[SGD | lr=0.1] Epoch 3945/4000: train_loss=0.0040  test_loss=4.5925  λ_max=78.4181\n",
      "[SGD | lr=0.1] Epoch 3946/4000: train_loss=0.0040  test_loss=4.5927  λ_max=80.3355\n",
      "[SGD | lr=0.1] Epoch 3947/4000: train_loss=0.0040  test_loss=4.5930  λ_max=76.9625\n",
      "[SGD | lr=0.1] Epoch 3948/4000: train_loss=0.0040  test_loss=4.5931  λ_max=80.0569\n",
      "[SGD | lr=0.1] Epoch 3949/4000: train_loss=0.0040  test_loss=4.5933  λ_max=78.1997\n",
      "[SGD | lr=0.1] Iter 63200: loss=0.0039\n",
      "[SGD | lr=0.1] Epoch 3950/4000: train_loss=0.0040  test_loss=4.5934  λ_max=78.5863\n",
      "[SGD | lr=0.1] Epoch 3951/4000: train_loss=0.0040  test_loss=4.5936  λ_max=80.7881\n",
      "[SGD | lr=0.1] Epoch 3952/4000: train_loss=0.0040  test_loss=4.5938  λ_max=77.0738\n",
      "[SGD | lr=0.1] Epoch 3953/4000: train_loss=0.0040  test_loss=4.5940  λ_max=79.5430\n",
      "[SGD | lr=0.1] Epoch 3954/4000: train_loss=0.0040  test_loss=4.5942  λ_max=78.0628\n",
      "[SGD | lr=0.1] Epoch 3955/4000: train_loss=0.0040  test_loss=4.5944  λ_max=79.0278\n",
      "[SGD | lr=0.1] Epoch 3956/4000: train_loss=0.0040  test_loss=4.5945  λ_max=77.0931\n",
      "[SGD | lr=0.1] Iter 63300: loss=0.0040\n",
      "[SGD | lr=0.1] Epoch 3957/4000: train_loss=0.0040  test_loss=4.5947  λ_max=79.4593\n",
      "[SGD | lr=0.1] Epoch 3958/4000: train_loss=0.0040  test_loss=4.5948  λ_max=76.0632\n",
      "[SGD | lr=0.1] Epoch 3959/4000: train_loss=0.0040  test_loss=4.5950  λ_max=78.7290\n",
      "[SGD | lr=0.1] Epoch 3960/4000: train_loss=0.0040  test_loss=4.5952  λ_max=81.7835\n",
      "[SGD | lr=0.1] Epoch 3961/4000: train_loss=0.0040  test_loss=4.5954  λ_max=78.6257\n",
      "[SGD | lr=0.1] Epoch 3962/4000: train_loss=0.0040  test_loss=4.5956  λ_max=78.6633\n",
      "[SGD | lr=0.1] Iter 63400: loss=0.0040\n",
      "[SGD | lr=0.1] Epoch 3963/4000: train_loss=0.0040  test_loss=4.5957  λ_max=77.7742\n",
      "[SGD | lr=0.1] Epoch 3964/4000: train_loss=0.0039  test_loss=4.5961  λ_max=80.4590\n",
      "[SGD | lr=0.1] Epoch 3965/4000: train_loss=0.0039  test_loss=4.5961  λ_max=75.6308\n",
      "[SGD | lr=0.1] Epoch 3966/4000: train_loss=0.0039  test_loss=4.5963  λ_max=79.3097\n",
      "[SGD | lr=0.1] Epoch 3967/4000: train_loss=0.0039  test_loss=4.5964  λ_max=77.4315\n",
      "[SGD | lr=0.1] Epoch 3968/4000: train_loss=0.0039  test_loss=4.5967  λ_max=78.6995\n",
      "[SGD | lr=0.1] Iter 63500: loss=0.0039\n",
      "[SGD | lr=0.1] Epoch 3969/4000: train_loss=0.0039  test_loss=4.5968  λ_max=78.0349\n",
      "[SGD | lr=0.1] Epoch 3970/4000: train_loss=0.0039  test_loss=4.5970  λ_max=80.1968\n",
      "[SGD | lr=0.1] Epoch 3971/4000: train_loss=0.0039  test_loss=4.5972  λ_max=79.0572\n",
      "[SGD | lr=0.1] Epoch 3972/4000: train_loss=0.0039  test_loss=4.5974  λ_max=80.2501\n",
      "[SGD | lr=0.1] Epoch 3973/4000: train_loss=0.0039  test_loss=4.5976  λ_max=77.8252\n",
      "[SGD | lr=0.1] Epoch 3974/4000: train_loss=0.0039  test_loss=4.5978  λ_max=75.9940\n",
      "[SGD | lr=0.1] Iter 63600: loss=0.0041\n",
      "[SGD | lr=0.1] Epoch 3975/4000: train_loss=0.0039  test_loss=4.5978  λ_max=77.1526\n",
      "[SGD | lr=0.1] Epoch 3976/4000: train_loss=0.0039  test_loss=4.5981  λ_max=78.4317\n",
      "[SGD | lr=0.1] Epoch 3977/4000: train_loss=0.0039  test_loss=4.5982  λ_max=80.6985\n",
      "[SGD | lr=0.1] Epoch 3978/4000: train_loss=0.0039  test_loss=4.5984  λ_max=77.0417\n",
      "[SGD | lr=0.1] Epoch 3979/4000: train_loss=0.0039  test_loss=4.5986  λ_max=75.9361\n",
      "[SGD | lr=0.1] Epoch 3980/4000: train_loss=0.0039  test_loss=4.5987  λ_max=78.7416\n",
      "[SGD | lr=0.1] Epoch 3981/4000: train_loss=0.0039  test_loss=4.5989  λ_max=78.3928\n",
      "[SGD | lr=0.1] Iter 63700: loss=0.0038\n",
      "[SGD | lr=0.1] Epoch 3982/4000: train_loss=0.0039  test_loss=4.5991  λ_max=78.7666\n",
      "[SGD | lr=0.1] Epoch 3983/4000: train_loss=0.0039  test_loss=4.5993  λ_max=78.6501\n",
      "[SGD | lr=0.1] Epoch 3984/4000: train_loss=0.0039  test_loss=4.5995  λ_max=80.7548\n",
      "[SGD | lr=0.1] Epoch 3985/4000: train_loss=0.0039  test_loss=4.5997  λ_max=76.8904\n",
      "[SGD | lr=0.1] Epoch 3986/4000: train_loss=0.0039  test_loss=4.5999  λ_max=77.5023\n",
      "[SGD | lr=0.1] Epoch 3987/4000: train_loss=0.0039  test_loss=4.6000  λ_max=77.2010\n",
      "[SGD | lr=0.1] Iter 63800: loss=0.0039\n",
      "[SGD | lr=0.1] Epoch 3988/4000: train_loss=0.0039  test_loss=4.6002  λ_max=79.2515\n",
      "[SGD | lr=0.1] Epoch 3989/4000: train_loss=0.0039  test_loss=4.6003  λ_max=75.2607\n",
      "[SGD | lr=0.1] Epoch 3990/4000: train_loss=0.0039  test_loss=4.6005  λ_max=77.2682\n",
      "[SGD | lr=0.1] Epoch 3991/4000: train_loss=0.0039  test_loss=4.6006  λ_max=75.8071\n",
      "[SGD | lr=0.1] Epoch 3992/4000: train_loss=0.0039  test_loss=4.6009  λ_max=78.1722\n",
      "[SGD | lr=0.1] Epoch 3993/4000: train_loss=0.0039  test_loss=4.6009  λ_max=75.7818\n",
      "[SGD | lr=0.1] Iter 63900: loss=0.0039\n",
      "[SGD | lr=0.1] Epoch 3994/4000: train_loss=0.0039  test_loss=4.6012  λ_max=77.6823\n",
      "[SGD | lr=0.1] Epoch 3995/4000: train_loss=0.0039  test_loss=4.6013  λ_max=77.9171\n",
      "[SGD | lr=0.1] Epoch 3996/4000: train_loss=0.0039  test_loss=4.6016  λ_max=77.3543\n",
      "[SGD | lr=0.1] Epoch 3997/4000: train_loss=0.0039  test_loss=4.6018  λ_max=75.5758\n",
      "[SGD | lr=0.1] Epoch 3998/4000: train_loss=0.0039  test_loss=4.6019  λ_max=75.3250\n",
      "[SGD | lr=0.1] Epoch 3999/4000: train_loss=0.0039  test_loss=4.6021  λ_max=80.8241\n",
      "[SGD | lr=0.1] Iter 64000: loss=0.0039\n",
      "[SGD | lr=0.1] Epoch 4000/4000: train_loss=0.0039  test_loss=4.6022  λ_max=78.1670\n",
      "Saved data → results/SGD_lr0.1.npz\n",
      "Saved plot → results/SGD_lr0.1_sharpness.png\n",
      "\n",
      "### Running SGD with lr=0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (/home/aradilla/.cache/huggingface/datasets/sapientinc___csv/sapientinc--sudoku-extreme-798989c95bd556dd/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n",
      "Found cached dataset csv (/home/aradilla/.cache/huggingface/datasets/sapientinc___csv/sapientinc--sudoku-extreme-798989c95bd556dd/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SGD | lr=0.05] Epoch 1/4000: train_loss=2.3162  test_loss=2.2764  λ_max=4.6661\n",
      "[SGD | lr=0.05] Epoch 2/4000: train_loss=2.2591  test_loss=2.2396  λ_max=4.1736\n",
      "[SGD | lr=0.05] Epoch 3/4000: train_loss=2.2273  test_loss=2.2211  λ_max=3.6976\n",
      "[SGD | lr=0.05] Epoch 4/4000: train_loss=2.2118  test_loss=2.2129  λ_max=3.3372\n",
      "[SGD | lr=0.05] Epoch 5/4000: train_loss=2.2037  test_loss=2.2087  λ_max=3.1839\n",
      "[SGD | lr=0.05] Epoch 6/4000: train_loss=2.1992  test_loss=2.2064  λ_max=3.0555\n",
      "[SGD | lr=0.05] Iter 100: loss=2.1942\n",
      "[SGD | lr=0.05] Epoch 7/4000: train_loss=2.1964  test_loss=2.2049  λ_max=2.8254\n",
      "[SGD | lr=0.05] Epoch 8/4000: train_loss=2.1941  test_loss=2.2039  λ_max=2.7671\n",
      "[SGD | lr=0.05] Epoch 9/4000: train_loss=2.1924  test_loss=2.2031  λ_max=2.7491\n",
      "[SGD | lr=0.05] Epoch 10/4000: train_loss=2.1907  test_loss=2.2029  λ_max=2.6800\n",
      "[SGD | lr=0.05] Epoch 11/4000: train_loss=2.1893  test_loss=2.2021  λ_max=2.6311\n",
      "[SGD | lr=0.05] Epoch 12/4000: train_loss=2.1880  test_loss=2.2019  λ_max=2.6777\n",
      "[SGD | lr=0.05] Iter 200: loss=2.1869\n",
      "[SGD | lr=0.05] Epoch 13/4000: train_loss=2.1869  test_loss=2.2013  λ_max=2.5925\n",
      "[SGD | lr=0.05] Epoch 14/4000: train_loss=2.1857  test_loss=2.2011  λ_max=2.6229\n",
      "[SGD | lr=0.05] Epoch 15/4000: train_loss=2.1845  test_loss=2.2007  λ_max=2.6183\n",
      "[SGD | lr=0.05] Epoch 16/4000: train_loss=2.1833  test_loss=2.2004  λ_max=2.6469\n",
      "[SGD | lr=0.05] Epoch 17/4000: train_loss=2.1820  test_loss=2.2002  λ_max=2.7062\n",
      "[SGD | lr=0.05] Epoch 18/4000: train_loss=2.1807  test_loss=2.1998  λ_max=2.8035\n",
      "[SGD | lr=0.05] Iter 300: loss=2.1830\n",
      "[SGD | lr=0.05] Epoch 19/4000: train_loss=2.1794  test_loss=2.1997  λ_max=2.7822\n",
      "[SGD | lr=0.05] Epoch 20/4000: train_loss=2.1781  test_loss=2.1995  λ_max=2.8322\n",
      "[SGD | lr=0.05] Epoch 21/4000: train_loss=2.1766  test_loss=2.1995  λ_max=2.8568\n",
      "[SGD | lr=0.05] Epoch 22/4000: train_loss=2.1750  test_loss=2.1993  λ_max=2.9575\n",
      "[SGD | lr=0.05] Epoch 23/4000: train_loss=2.1734  test_loss=2.1995  λ_max=3.0027\n",
      "[SGD | lr=0.05] Epoch 24/4000: train_loss=2.1717  test_loss=2.1994  λ_max=3.1687\n",
      "[SGD | lr=0.05] Iter 400: loss=2.1713\n",
      "[SGD | lr=0.05] Epoch 25/4000: train_loss=2.1699  test_loss=2.1991  λ_max=3.2051\n",
      "[SGD | lr=0.05] Epoch 26/4000: train_loss=2.1678  test_loss=2.1993  λ_max=3.4280\n",
      "[SGD | lr=0.05] Epoch 27/4000: train_loss=2.1657  test_loss=2.1998  λ_max=3.5144\n",
      "[SGD | lr=0.05] Epoch 28/4000: train_loss=2.1633  test_loss=2.2004  λ_max=3.7091\n",
      "[SGD | lr=0.05] Epoch 29/4000: train_loss=2.1607  test_loss=2.2000  λ_max=3.9773\n",
      "[SGD | lr=0.05] Epoch 30/4000: train_loss=2.1583  test_loss=2.2002  λ_max=3.8973\n",
      "[SGD | lr=0.05] Epoch 31/4000: train_loss=2.1551  test_loss=2.2006  λ_max=4.4106\n",
      "[SGD | lr=0.05] Iter 500: loss=2.1493\n",
      "[SGD | lr=0.05] Epoch 32/4000: train_loss=2.1520  test_loss=2.2012  λ_max=4.3889\n",
      "[SGD | lr=0.05] Epoch 33/4000: train_loss=2.1485  test_loss=2.2014  λ_max=4.6186\n",
      "[SGD | lr=0.05] Epoch 34/4000: train_loss=2.1448  test_loss=2.2022  λ_max=4.9230\n",
      "[SGD | lr=0.05] Epoch 35/4000: train_loss=2.1410  test_loss=2.2030  λ_max=5.2668\n",
      "[SGD | lr=0.05] Epoch 36/4000: train_loss=2.1367  test_loss=2.2034  λ_max=5.5363\n",
      "[SGD | lr=0.05] Epoch 37/4000: train_loss=2.1323  test_loss=2.2039  λ_max=5.7710\n",
      "[SGD | lr=0.05] Iter 600: loss=2.1223\n",
      "[SGD | lr=0.05] Epoch 38/4000: train_loss=2.1276  test_loss=2.2045  λ_max=6.2287\n",
      "[SGD | lr=0.05] Epoch 39/4000: train_loss=2.1225  test_loss=2.2062  λ_max=6.2924\n",
      "[SGD | lr=0.05] Epoch 40/4000: train_loss=2.1173  test_loss=2.2057  λ_max=6.6561\n",
      "[SGD | lr=0.05] Epoch 41/4000: train_loss=2.1115  test_loss=2.2068  λ_max=6.8211\n",
      "[SGD | lr=0.05] Epoch 42/4000: train_loss=2.1056  test_loss=2.2065  λ_max=7.3182\n",
      "[SGD | lr=0.05] Epoch 43/4000: train_loss=2.0997  test_loss=2.2068  λ_max=7.7352\n",
      "[SGD | lr=0.05] Iter 700: loss=2.0891\n",
      "[SGD | lr=0.05] Epoch 44/4000: train_loss=2.0929  test_loss=2.2080  λ_max=7.6775\n",
      "[SGD | lr=0.05] Epoch 45/4000: train_loss=2.0862  test_loss=2.2071  λ_max=8.4159\n",
      "[SGD | lr=0.05] Epoch 46/4000: train_loss=2.0795  test_loss=2.2080  λ_max=7.8970\n",
      "[SGD | lr=0.05] Epoch 47/4000: train_loss=2.0724  test_loss=2.2069  λ_max=8.9484\n",
      "[SGD | lr=0.05] Epoch 48/4000: train_loss=2.0656  test_loss=2.2068  λ_max=8.5558\n",
      "[SGD | lr=0.05] Epoch 49/4000: train_loss=2.0580  test_loss=2.2062  λ_max=9.4587\n",
      "[SGD | lr=0.05] Iter 800: loss=2.0543\n",
      "[SGD | lr=0.05] Epoch 50/4000: train_loss=2.0508  test_loss=2.2048  λ_max=9.7461\n",
      "[SGD | lr=0.05] Epoch 51/4000: train_loss=2.0432  test_loss=2.2039  λ_max=9.3744\n",
      "[SGD | lr=0.05] Epoch 52/4000: train_loss=2.0355  test_loss=2.2021  λ_max=9.5625\n",
      "[SGD | lr=0.05] Epoch 53/4000: train_loss=2.0282  test_loss=2.2017  λ_max=10.3105\n",
      "[SGD | lr=0.05] Epoch 54/4000: train_loss=2.0204  test_loss=2.2008  λ_max=9.4225\n",
      "[SGD | lr=0.05] Epoch 55/4000: train_loss=2.0128  test_loss=2.1995  λ_max=11.0010\n",
      "[SGD | lr=0.05] Epoch 56/4000: train_loss=2.0051  test_loss=2.1983  λ_max=10.1470\n",
      "[SGD | lr=0.05] Iter 900: loss=1.9986\n",
      "[SGD | lr=0.05] Epoch 57/4000: train_loss=1.9974  test_loss=2.1969  λ_max=11.4183\n",
      "[SGD | lr=0.05] Epoch 58/4000: train_loss=1.9895  test_loss=2.1952  λ_max=11.4308\n",
      "[SGD | lr=0.05] Epoch 59/4000: train_loss=1.9824  test_loss=2.1940  λ_max=11.5796\n",
      "[SGD | lr=0.05] Epoch 60/4000: train_loss=1.9747  test_loss=2.1927  λ_max=11.9763\n",
      "[SGD | lr=0.05] Epoch 61/4000: train_loss=1.9675  test_loss=2.1909  λ_max=11.7491\n",
      "[SGD | lr=0.05] Epoch 62/4000: train_loss=1.9601  test_loss=2.1889  λ_max=11.1239\n",
      "[SGD | lr=0.05] Iter 1000: loss=1.9506\n",
      "[SGD | lr=0.05] Epoch 63/4000: train_loss=1.9525  test_loss=2.1885  λ_max=12.0769\n",
      "[SGD | lr=0.05] Epoch 64/4000: train_loss=1.9452  test_loss=2.1856  λ_max=12.0191\n",
      "[SGD | lr=0.05] Epoch 65/4000: train_loss=1.9379  test_loss=2.1853  λ_max=11.7154\n",
      "[SGD | lr=0.05] Epoch 66/4000: train_loss=1.9305  test_loss=2.1834  λ_max=12.5479\n",
      "[SGD | lr=0.05] Epoch 67/4000: train_loss=1.9231  test_loss=2.1824  λ_max=11.8451\n",
      "[SGD | lr=0.05] Epoch 68/4000: train_loss=1.9163  test_loss=2.1806  λ_max=12.1489\n",
      "[SGD | lr=0.05] Iter 1100: loss=1.9089\n",
      "[SGD | lr=0.05] Epoch 69/4000: train_loss=1.9092  test_loss=2.1781  λ_max=12.9576\n",
      "[SGD | lr=0.05] Epoch 70/4000: train_loss=1.9019  test_loss=2.1768  λ_max=13.2019\n",
      "[SGD | lr=0.05] Epoch 71/4000: train_loss=1.8950  test_loss=2.1759  λ_max=13.5569\n",
      "[SGD | lr=0.05] Epoch 72/4000: train_loss=1.8881  test_loss=2.1747  λ_max=13.4056\n",
      "[SGD | lr=0.05] Epoch 73/4000: train_loss=1.8813  test_loss=2.1730  λ_max=13.5234\n",
      "[SGD | lr=0.05] Epoch 74/4000: train_loss=1.8745  test_loss=2.1718  λ_max=13.9594\n",
      "[SGD | lr=0.05] Iter 1200: loss=1.8708\n",
      "[SGD | lr=0.05] Epoch 75/4000: train_loss=1.8678  test_loss=2.1693  λ_max=13.9902\n",
      "[SGD | lr=0.05] Epoch 76/4000: train_loss=1.8610  test_loss=2.1684  λ_max=14.0919\n",
      "[SGD | lr=0.05] Epoch 77/4000: train_loss=1.8543  test_loss=2.1659  λ_max=13.3969\n",
      "[SGD | lr=0.05] Epoch 78/4000: train_loss=1.8478  test_loss=2.1647  λ_max=13.8608\n",
      "[SGD | lr=0.05] Epoch 79/4000: train_loss=1.8411  test_loss=2.1638  λ_max=14.7215\n",
      "[SGD | lr=0.05] Epoch 80/4000: train_loss=1.8346  test_loss=2.1612  λ_max=15.4175\n",
      "[SGD | lr=0.05] Epoch 81/4000: train_loss=1.8280  test_loss=2.1621  λ_max=14.6655\n",
      "[SGD | lr=0.05] Iter 1300: loss=1.8258\n",
      "[SGD | lr=0.05] Epoch 82/4000: train_loss=1.8215  test_loss=2.1602  λ_max=14.3070\n",
      "[SGD | lr=0.05] Epoch 83/4000: train_loss=1.8152  test_loss=2.1599  λ_max=15.6234\n",
      "[SGD | lr=0.05] Epoch 84/4000: train_loss=1.8093  test_loss=2.1582  λ_max=15.1193\n",
      "[SGD | lr=0.05] Epoch 85/4000: train_loss=1.8027  test_loss=2.1551  λ_max=15.3706\n",
      "[SGD | lr=0.05] Epoch 86/4000: train_loss=1.7961  test_loss=2.1563  λ_max=15.9834\n",
      "[SGD | lr=0.05] Epoch 87/4000: train_loss=1.7904  test_loss=2.1549  λ_max=16.6522\n",
      "[SGD | lr=0.05] Iter 1400: loss=1.7867\n",
      "[SGD | lr=0.05] Epoch 88/4000: train_loss=1.7841  test_loss=2.1537  λ_max=14.2345\n",
      "[SGD | lr=0.05] Epoch 89/4000: train_loss=1.7781  test_loss=2.1525  λ_max=16.6103\n",
      "[SGD | lr=0.05] Epoch 90/4000: train_loss=1.7722  test_loss=2.1508  λ_max=16.2600\n",
      "[SGD | lr=0.05] Epoch 91/4000: train_loss=1.7661  test_loss=2.1498  λ_max=16.9170\n",
      "[SGD | lr=0.05] Epoch 92/4000: train_loss=1.7600  test_loss=2.1515  λ_max=16.0357\n",
      "[SGD | lr=0.05] Epoch 93/4000: train_loss=1.7545  test_loss=2.1490  λ_max=17.4640\n",
      "[SGD | lr=0.05] Iter 1500: loss=1.7518\n",
      "[SGD | lr=0.05] Epoch 94/4000: train_loss=1.7490  test_loss=2.1474  λ_max=17.8997\n",
      "[SGD | lr=0.05] Epoch 95/4000: train_loss=1.7426  test_loss=2.1476  λ_max=16.5411\n",
      "[SGD | lr=0.05] Epoch 96/4000: train_loss=1.7366  test_loss=2.1466  λ_max=18.0930\n",
      "[SGD | lr=0.05] Epoch 97/4000: train_loss=1.7307  test_loss=2.1460  λ_max=17.4211\n",
      "[SGD | lr=0.05] Epoch 98/4000: train_loss=1.7258  test_loss=2.1441  λ_max=16.0375\n",
      "[SGD | lr=0.05] Epoch 99/4000: train_loss=1.7204  test_loss=2.1436  λ_max=17.6664\n",
      "[SGD | lr=0.05] Iter 1600: loss=1.7160\n",
      "[SGD | lr=0.05] Epoch 100/4000: train_loss=1.7148  test_loss=2.1411  λ_max=17.4009\n",
      "[SGD | lr=0.05] Epoch 101/4000: train_loss=1.7085  test_loss=2.1404  λ_max=18.1760\n",
      "[SGD | lr=0.05] Epoch 102/4000: train_loss=1.7046  test_loss=2.1408  λ_max=17.2837\n",
      "[SGD | lr=0.05] Epoch 103/4000: train_loss=1.6999  test_loss=2.1394  λ_max=17.6105\n",
      "[SGD | lr=0.05] Epoch 104/4000: train_loss=1.6921  test_loss=2.1405  λ_max=18.1201\n",
      "[SGD | lr=0.05] Epoch 105/4000: train_loss=1.6880  test_loss=2.1395  λ_max=18.1524\n",
      "[SGD | lr=0.05] Epoch 106/4000: train_loss=1.6827  test_loss=2.1384  λ_max=17.4326\n",
      "[SGD | lr=0.05] Iter 1700: loss=1.6795\n",
      "[SGD | lr=0.05] Epoch 107/4000: train_loss=1.6788  test_loss=2.1384  λ_max=17.4055\n",
      "[SGD | lr=0.05] Epoch 108/4000: train_loss=1.6724  test_loss=2.1382  λ_max=19.1310\n",
      "[SGD | lr=0.05] Epoch 109/4000: train_loss=1.6673  test_loss=2.1376  λ_max=19.3604\n",
      "[SGD | lr=0.05] Epoch 110/4000: train_loss=1.6627  test_loss=2.1329  λ_max=18.4114\n",
      "[SGD | lr=0.05] Epoch 111/4000: train_loss=1.6582  test_loss=2.1342  λ_max=17.7676\n",
      "[SGD | lr=0.05] Epoch 112/4000: train_loss=1.6531  test_loss=2.1347  λ_max=18.3271\n",
      "[SGD | lr=0.05] Iter 1800: loss=1.6405\n",
      "[SGD | lr=0.05] Epoch 113/4000: train_loss=1.6475  test_loss=2.1365  λ_max=19.3858\n",
      "[SGD | lr=0.05] Epoch 114/4000: train_loss=1.6447  test_loss=2.1324  λ_max=18.6525\n",
      "[SGD | lr=0.05] Epoch 115/4000: train_loss=1.6376  test_loss=2.1294  λ_max=18.8860\n",
      "[SGD | lr=0.05] Epoch 116/4000: train_loss=1.6321  test_loss=2.1309  λ_max=17.9468\n",
      "[SGD | lr=0.05] Epoch 117/4000: train_loss=1.6292  test_loss=2.1292  λ_max=19.4343\n",
      "[SGD | lr=0.05] Epoch 118/4000: train_loss=1.6225  test_loss=2.1300  λ_max=19.0058\n",
      "[SGD | lr=0.05] Iter 1900: loss=1.6187\n",
      "[SGD | lr=0.05] Epoch 119/4000: train_loss=1.6187  test_loss=2.1330  λ_max=19.6928\n",
      "[SGD | lr=0.05] Epoch 120/4000: train_loss=1.6151  test_loss=2.1315  λ_max=19.0432\n",
      "[SGD | lr=0.05] Epoch 121/4000: train_loss=1.6100  test_loss=2.1291  λ_max=19.3074\n",
      "[SGD | lr=0.05] Epoch 122/4000: train_loss=1.6043  test_loss=2.1304  λ_max=20.4704\n",
      "[SGD | lr=0.05] Epoch 123/4000: train_loss=1.5996  test_loss=2.1312  λ_max=18.8267\n",
      "[SGD | lr=0.05] Epoch 124/4000: train_loss=1.5930  test_loss=2.1289  λ_max=19.4284\n",
      "[SGD | lr=0.05] Iter 2000: loss=1.5995\n",
      "[SGD | lr=0.05] Epoch 125/4000: train_loss=1.5910  test_loss=2.1287  λ_max=19.0738\n",
      "[SGD | lr=0.05] Epoch 126/4000: train_loss=1.5859  test_loss=2.1316  λ_max=19.6732\n",
      "[SGD | lr=0.05] Epoch 127/4000: train_loss=1.5818  test_loss=2.1310  λ_max=18.9870\n",
      "[SGD | lr=0.05] Epoch 128/4000: train_loss=1.5742  test_loss=2.1266  λ_max=19.6609\n",
      "[SGD | lr=0.05] Epoch 129/4000: train_loss=1.5695  test_loss=2.1231  λ_max=19.6290\n",
      "[SGD | lr=0.05] Epoch 130/4000: train_loss=1.5668  test_loss=2.1257  λ_max=19.6163\n",
      "[SGD | lr=0.05] Epoch 131/4000: train_loss=1.5619  test_loss=2.1276  λ_max=20.2243\n",
      "[SGD | lr=0.05] Iter 2100: loss=1.5535\n",
      "[SGD | lr=0.05] Epoch 132/4000: train_loss=1.5572  test_loss=2.1277  λ_max=20.0604\n",
      "[SGD | lr=0.05] Epoch 133/4000: train_loss=1.5521  test_loss=2.1266  λ_max=19.4626\n",
      "[SGD | lr=0.05] Epoch 134/4000: train_loss=1.5482  test_loss=2.1283  λ_max=20.2338\n",
      "[SGD | lr=0.05] Epoch 135/4000: train_loss=1.5459  test_loss=2.1219  λ_max=20.4144\n",
      "[SGD | lr=0.05] Epoch 136/4000: train_loss=1.5388  test_loss=2.1259  λ_max=20.2129\n",
      "[SGD | lr=0.05] Epoch 137/4000: train_loss=1.5355  test_loss=2.1252  λ_max=21.0449\n",
      "[SGD | lr=0.05] Iter 2200: loss=1.5139\n",
      "[SGD | lr=0.05] Epoch 138/4000: train_loss=1.5280  test_loss=2.1250  λ_max=20.3439\n",
      "[SGD | lr=0.05] Epoch 139/4000: train_loss=1.5265  test_loss=2.1232  λ_max=20.8344\n",
      "[SGD | lr=0.05] Epoch 140/4000: train_loss=1.5214  test_loss=2.1268  λ_max=19.7083\n",
      "[SGD | lr=0.05] Epoch 141/4000: train_loss=1.5201  test_loss=2.1261  λ_max=20.6662\n",
      "[SGD | lr=0.05] Epoch 142/4000: train_loss=1.5157  test_loss=2.1239  λ_max=20.7732\n",
      "[SGD | lr=0.05] Epoch 143/4000: train_loss=1.5075  test_loss=2.1231  λ_max=20.7121\n",
      "[SGD | lr=0.05] Iter 2300: loss=1.5012\n",
      "[SGD | lr=0.05] Epoch 144/4000: train_loss=1.5032  test_loss=2.1231  λ_max=19.9428\n",
      "[SGD | lr=0.05] Epoch 145/4000: train_loss=1.5005  test_loss=2.1205  λ_max=20.1943\n",
      "[SGD | lr=0.05] Epoch 146/4000: train_loss=1.4963  test_loss=2.1259  λ_max=20.9391\n",
      "[SGD | lr=0.05] Epoch 147/4000: train_loss=1.4907  test_loss=2.1240  λ_max=20.1639\n",
      "[SGD | lr=0.05] Epoch 148/4000: train_loss=1.4914  test_loss=2.1253  λ_max=21.2815\n",
      "[SGD | lr=0.05] Epoch 149/4000: train_loss=1.4848  test_loss=2.1212  λ_max=21.2900\n",
      "[SGD | lr=0.05] Iter 2400: loss=1.4841\n",
      "[SGD | lr=0.05] Epoch 150/4000: train_loss=1.4788  test_loss=2.1205  λ_max=22.5784\n",
      "[SGD | lr=0.05] Epoch 151/4000: train_loss=1.4745  test_loss=2.1223  λ_max=21.0825\n",
      "[SGD | lr=0.05] Epoch 152/4000: train_loss=1.4681  test_loss=2.1231  λ_max=21.0735\n",
      "[SGD | lr=0.05] Epoch 153/4000: train_loss=1.4659  test_loss=2.1217  λ_max=20.7278\n",
      "[SGD | lr=0.05] Epoch 154/4000: train_loss=1.4616  test_loss=2.1231  λ_max=21.1288\n",
      "[SGD | lr=0.05] Epoch 155/4000: train_loss=1.4560  test_loss=2.1239  λ_max=20.6225\n",
      "[SGD | lr=0.05] Epoch 156/4000: train_loss=1.4545  test_loss=2.1190  λ_max=21.0006\n",
      "[SGD | lr=0.05] Iter 2500: loss=1.4457\n",
      "[SGD | lr=0.05] Epoch 157/4000: train_loss=1.4464  test_loss=2.1184  λ_max=21.4176\n",
      "[SGD | lr=0.05] Epoch 158/4000: train_loss=1.4421  test_loss=2.1198  λ_max=21.1920\n",
      "[SGD | lr=0.05] Epoch 159/4000: train_loss=1.4419  test_loss=2.1218  λ_max=22.0419\n",
      "[SGD | lr=0.05] Epoch 160/4000: train_loss=1.4380  test_loss=2.1198  λ_max=22.4196\n",
      "[SGD | lr=0.05] Epoch 161/4000: train_loss=1.4283  test_loss=2.1217  λ_max=21.5166\n",
      "[SGD | lr=0.05] Epoch 162/4000: train_loss=1.4255  test_loss=2.1176  λ_max=21.3555\n",
      "[SGD | lr=0.05] Iter 2600: loss=1.4241\n",
      "[SGD | lr=0.05] Epoch 163/4000: train_loss=1.4237  test_loss=2.1173  λ_max=22.5779\n",
      "[SGD | lr=0.05] Epoch 164/4000: train_loss=1.4174  test_loss=2.1193  λ_max=22.9324\n",
      "[SGD | lr=0.05] Epoch 165/4000: train_loss=1.4122  test_loss=2.1181  λ_max=22.0852\n",
      "[SGD | lr=0.05] Epoch 166/4000: train_loss=1.4127  test_loss=2.1189  λ_max=21.4764\n",
      "[SGD | lr=0.05] Epoch 167/4000: train_loss=1.4068  test_loss=2.1203  λ_max=22.2117\n",
      "[SGD | lr=0.05] Epoch 168/4000: train_loss=1.4023  test_loss=2.1199  λ_max=21.7347\n",
      "[SGD | lr=0.05] Iter 2700: loss=1.3926\n",
      "[SGD | lr=0.05] Epoch 169/4000: train_loss=1.3948  test_loss=2.1211  λ_max=22.6939\n",
      "[SGD | lr=0.05] Epoch 170/4000: train_loss=1.3927  test_loss=2.1214  λ_max=21.6416\n",
      "[SGD | lr=0.05] Epoch 171/4000: train_loss=1.3870  test_loss=2.1222  λ_max=22.7382\n",
      "[SGD | lr=0.05] Epoch 172/4000: train_loss=1.3827  test_loss=2.1216  λ_max=22.7394\n",
      "[SGD | lr=0.05] Epoch 173/4000: train_loss=1.3799  test_loss=2.1213  λ_max=22.6189\n",
      "[SGD | lr=0.05] Epoch 174/4000: train_loss=1.3752  test_loss=2.1253  λ_max=22.9070\n",
      "[SGD | lr=0.05] Iter 2800: loss=1.3703\n",
      "[SGD | lr=0.05] Epoch 175/4000: train_loss=1.3761  test_loss=2.1206  λ_max=22.6513\n",
      "[SGD | lr=0.05] Epoch 176/4000: train_loss=1.3697  test_loss=2.1218  λ_max=22.2078\n",
      "[SGD | lr=0.05] Epoch 177/4000: train_loss=1.3726  test_loss=2.1208  λ_max=23.5577\n",
      "[SGD | lr=0.05] Epoch 178/4000: train_loss=1.3626  test_loss=2.1175  λ_max=23.1119\n",
      "[SGD | lr=0.05] Epoch 179/4000: train_loss=1.3573  test_loss=2.1216  λ_max=22.8063\n",
      "[SGD | lr=0.05] Epoch 180/4000: train_loss=1.3524  test_loss=2.1245  λ_max=23.2213\n",
      "[SGD | lr=0.05] Epoch 181/4000: train_loss=1.3513  test_loss=2.1223  λ_max=24.7308\n",
      "[SGD | lr=0.05] Iter 2900: loss=1.3395\n",
      "[SGD | lr=0.05] Epoch 182/4000: train_loss=1.3447  test_loss=2.1190  λ_max=23.2947\n",
      "[SGD | lr=0.05] Epoch 183/4000: train_loss=1.3414  test_loss=2.1255  λ_max=24.7498\n",
      "[SGD | lr=0.05] Epoch 184/4000: train_loss=1.3357  test_loss=2.1221  λ_max=22.6455\n",
      "[SGD | lr=0.05] Epoch 185/4000: train_loss=1.3314  test_loss=2.1236  λ_max=23.1808\n",
      "[SGD | lr=0.05] Epoch 186/4000: train_loss=1.3284  test_loss=2.1247  λ_max=22.5489\n",
      "[SGD | lr=0.05] Epoch 187/4000: train_loss=1.3243  test_loss=2.1196  λ_max=24.5214\n",
      "[SGD | lr=0.05] Iter 3000: loss=1.3166\n",
      "[SGD | lr=0.05] Epoch 188/4000: train_loss=1.3241  test_loss=2.1244  λ_max=23.0413\n",
      "[SGD | lr=0.05] Epoch 189/4000: train_loss=1.3226  test_loss=2.1211  λ_max=24.2980\n",
      "[SGD | lr=0.05] Epoch 190/4000: train_loss=1.3092  test_loss=2.1176  λ_max=24.0347\n",
      "[SGD | lr=0.05] Epoch 191/4000: train_loss=1.3110  test_loss=2.1215  λ_max=24.3170\n",
      "[SGD | lr=0.05] Epoch 192/4000: train_loss=1.3056  test_loss=2.1262  λ_max=23.3905\n",
      "[SGD | lr=0.05] Epoch 193/4000: train_loss=1.3016  test_loss=2.1221  λ_max=23.6336\n",
      "[SGD | lr=0.05] Iter 3100: loss=1.3025\n",
      "[SGD | lr=0.05] Epoch 194/4000: train_loss=1.2980  test_loss=2.1251  λ_max=24.9138\n",
      "[SGD | lr=0.05] Epoch 195/4000: train_loss=1.2958  test_loss=2.1251  λ_max=23.5599\n",
      "[SGD | lr=0.05] Epoch 196/4000: train_loss=1.2904  test_loss=2.1280  λ_max=23.2300\n",
      "[SGD | lr=0.05] Epoch 197/4000: train_loss=1.2862  test_loss=2.1235  λ_max=24.4754\n",
      "[SGD | lr=0.05] Epoch 198/4000: train_loss=1.2869  test_loss=2.1196  λ_max=24.7353\n",
      "[SGD | lr=0.05] Epoch 199/4000: train_loss=1.2757  test_loss=2.1258  λ_max=23.0718\n",
      "[SGD | lr=0.05] Iter 3200: loss=1.2677\n",
      "[SGD | lr=0.05] Epoch 200/4000: train_loss=1.2726  test_loss=2.1247  λ_max=23.9108\n",
      "[SGD | lr=0.05] Epoch 201/4000: train_loss=1.2679  test_loss=2.1227  λ_max=25.0940\n",
      "[SGD | lr=0.05] Epoch 202/4000: train_loss=1.2666  test_loss=2.1216  λ_max=23.1633\n",
      "[SGD | lr=0.05] Epoch 203/4000: train_loss=1.2655  test_loss=2.1274  λ_max=22.9490\n",
      "[SGD | lr=0.05] Epoch 204/4000: train_loss=1.2603  test_loss=2.1249  λ_max=24.6786\n",
      "[SGD | lr=0.05] Epoch 205/4000: train_loss=1.2573  test_loss=2.1285  λ_max=24.7595\n",
      "[SGD | lr=0.05] Epoch 206/4000: train_loss=1.2503  test_loss=2.1239  λ_max=24.9189\n",
      "[SGD | lr=0.05] Iter 3300: loss=1.2352\n",
      "[SGD | lr=0.05] Epoch 207/4000: train_loss=1.2496  test_loss=2.1260  λ_max=24.2275\n",
      "[SGD | lr=0.05] Epoch 208/4000: train_loss=1.2454  test_loss=2.1318  λ_max=24.9281\n",
      "[SGD | lr=0.05] Epoch 209/4000: train_loss=1.2420  test_loss=2.1303  λ_max=24.8016\n",
      "[SGD | lr=0.05] Epoch 210/4000: train_loss=1.2368  test_loss=2.1288  λ_max=24.9321\n",
      "[SGD | lr=0.05] Epoch 211/4000: train_loss=1.2307  test_loss=2.1274  λ_max=25.0215\n",
      "[SGD | lr=0.05] Epoch 212/4000: train_loss=1.2311  test_loss=2.1285  λ_max=25.0830\n",
      "[SGD | lr=0.05] Iter 3400: loss=1.2347\n",
      "[SGD | lr=0.05] Epoch 213/4000: train_loss=1.2268  test_loss=2.1256  λ_max=25.3724\n",
      "[SGD | lr=0.05] Epoch 214/4000: train_loss=1.2225  test_loss=2.1257  λ_max=24.3644\n",
      "[SGD | lr=0.05] Epoch 215/4000: train_loss=1.2184  test_loss=2.1259  λ_max=24.2499\n",
      "[SGD | lr=0.05] Epoch 216/4000: train_loss=1.2129  test_loss=2.1306  λ_max=25.5949\n",
      "[SGD | lr=0.05] Epoch 217/4000: train_loss=1.2072  test_loss=2.1358  λ_max=24.2879\n",
      "[SGD | lr=0.05] Epoch 218/4000: train_loss=1.2032  test_loss=2.1314  λ_max=24.7824\n",
      "[SGD | lr=0.05] Iter 3500: loss=1.1847\n",
      "[SGD | lr=0.05] Epoch 219/4000: train_loss=1.2017  test_loss=2.1307  λ_max=24.2739\n",
      "[SGD | lr=0.05] Epoch 220/4000: train_loss=1.1981  test_loss=2.1313  λ_max=24.8594\n",
      "[SGD | lr=0.05] Epoch 221/4000: train_loss=1.1961  test_loss=2.1330  λ_max=25.4976\n",
      "[SGD | lr=0.05] Epoch 222/4000: train_loss=1.1900  test_loss=2.1295  λ_max=25.1196\n",
      "[SGD | lr=0.05] Epoch 223/4000: train_loss=1.1902  test_loss=2.1331  λ_max=25.2431\n",
      "[SGD | lr=0.05] Epoch 224/4000: train_loss=1.1850  test_loss=2.1308  λ_max=26.0360\n",
      "[SGD | lr=0.05] Iter 3600: loss=1.1720\n",
      "[SGD | lr=0.05] Epoch 225/4000: train_loss=1.1801  test_loss=2.1381  λ_max=25.6001\n",
      "[SGD | lr=0.05] Epoch 226/4000: train_loss=1.1801  test_loss=2.1389  λ_max=26.2286\n",
      "[SGD | lr=0.05] Epoch 227/4000: train_loss=1.1711  test_loss=2.1339  λ_max=25.3080\n",
      "[SGD | lr=0.05] Epoch 228/4000: train_loss=1.1697  test_loss=2.1296  λ_max=25.1017\n",
      "[SGD | lr=0.05] Epoch 229/4000: train_loss=1.1684  test_loss=2.1344  λ_max=23.9224\n",
      "[SGD | lr=0.05] Epoch 230/4000: train_loss=1.1593  test_loss=2.1361  λ_max=25.3951\n",
      "[SGD | lr=0.05] Epoch 231/4000: train_loss=1.1582  test_loss=2.1359  λ_max=27.1937\n",
      "[SGD | lr=0.05] Iter 3700: loss=1.1597\n",
      "[SGD | lr=0.05] Epoch 232/4000: train_loss=1.1551  test_loss=2.1310  λ_max=24.6440\n",
      "[SGD | lr=0.05] Epoch 233/4000: train_loss=1.1539  test_loss=2.1357  λ_max=25.4889\n",
      "[SGD | lr=0.05] Epoch 234/4000: train_loss=1.1447  test_loss=2.1368  λ_max=25.4735\n",
      "[SGD | lr=0.05] Epoch 235/4000: train_loss=1.1452  test_loss=2.1377  λ_max=26.4728\n",
      "[SGD | lr=0.05] Epoch 236/4000: train_loss=1.1434  test_loss=2.1418  λ_max=25.7842\n",
      "[SGD | lr=0.05] Epoch 237/4000: train_loss=1.1410  test_loss=2.1306  λ_max=25.1367\n",
      "[SGD | lr=0.05] Iter 3800: loss=1.1279\n",
      "[SGD | lr=0.05] Epoch 238/4000: train_loss=1.1306  test_loss=2.1379  λ_max=25.1833\n",
      "[SGD | lr=0.05] Epoch 239/4000: train_loss=1.1267  test_loss=2.1381  λ_max=25.7771\n",
      "[SGD | lr=0.05] Epoch 240/4000: train_loss=1.1261  test_loss=2.1433  λ_max=24.3008\n",
      "[SGD | lr=0.05] Epoch 241/4000: train_loss=1.1228  test_loss=2.1360  λ_max=24.7051\n",
      "[SGD | lr=0.05] Epoch 242/4000: train_loss=1.1175  test_loss=2.1459  λ_max=25.3767\n",
      "[SGD | lr=0.05] Epoch 243/4000: train_loss=1.1207  test_loss=2.1445  λ_max=26.9997\n",
      "[SGD | lr=0.05] Iter 3900: loss=1.1091\n",
      "[SGD | lr=0.05] Epoch 244/4000: train_loss=1.1087  test_loss=2.1435  λ_max=24.7039\n",
      "[SGD | lr=0.05] Epoch 245/4000: train_loss=1.1106  test_loss=2.1407  λ_max=25.2763\n",
      "[SGD | lr=0.05] Epoch 246/4000: train_loss=1.1015  test_loss=2.1391  λ_max=26.4506\n",
      "[SGD | lr=0.05] Epoch 247/4000: train_loss=1.1040  test_loss=2.1501  λ_max=27.3032\n",
      "[SGD | lr=0.05] Epoch 248/4000: train_loss=1.1011  test_loss=2.1428  λ_max=25.1485\n",
      "[SGD | lr=0.05] Epoch 249/4000: train_loss=1.0947  test_loss=2.1447  λ_max=25.4621\n",
      "[SGD | lr=0.05] Iter 4000: loss=1.0979\n",
      "[SGD | lr=0.05] Epoch 250/4000: train_loss=1.0941  test_loss=2.1555  λ_max=26.0280\n",
      "[SGD | lr=0.05] Epoch 251/4000: train_loss=1.0965  test_loss=2.1424  λ_max=27.4840\n",
      "[SGD | lr=0.05] Epoch 252/4000: train_loss=1.0854  test_loss=2.1447  λ_max=26.1078\n",
      "[SGD | lr=0.05] Epoch 253/4000: train_loss=1.0800  test_loss=2.1550  λ_max=28.1241\n",
      "[SGD | lr=0.05] Epoch 254/4000: train_loss=1.0815  test_loss=2.1473  λ_max=26.1495\n",
      "[SGD | lr=0.05] Epoch 255/4000: train_loss=1.0740  test_loss=2.1467  λ_max=26.9499\n",
      "[SGD | lr=0.05] Epoch 256/4000: train_loss=1.0716  test_loss=2.1447  λ_max=25.8128\n",
      "[SGD | lr=0.05] Iter 4100: loss=1.0713\n",
      "[SGD | lr=0.05] Epoch 257/4000: train_loss=1.0659  test_loss=2.1475  λ_max=26.5438\n",
      "[SGD | lr=0.05] Epoch 258/4000: train_loss=1.0591  test_loss=2.1502  λ_max=27.2365\n",
      "[SGD | lr=0.05] Epoch 259/4000: train_loss=1.0592  test_loss=2.1510  λ_max=26.0276\n",
      "[SGD | lr=0.05] Epoch 260/4000: train_loss=1.0561  test_loss=2.1482  λ_max=26.3304\n",
      "[SGD | lr=0.05] Epoch 261/4000: train_loss=1.0576  test_loss=2.1510  λ_max=26.5423\n",
      "[SGD | lr=0.05] Epoch 262/4000: train_loss=1.0516  test_loss=2.1460  λ_max=27.8745\n",
      "[SGD | lr=0.05] Iter 4200: loss=1.0449\n",
      "[SGD | lr=0.05] Epoch 263/4000: train_loss=1.0454  test_loss=2.1569  λ_max=26.2620\n",
      "[SGD | lr=0.05] Epoch 264/4000: train_loss=1.0372  test_loss=2.1523  λ_max=26.8960\n",
      "[SGD | lr=0.05] Epoch 265/4000: train_loss=1.0385  test_loss=2.1500  λ_max=25.8286\n",
      "[SGD | lr=0.05] Epoch 266/4000: train_loss=1.0379  test_loss=2.1590  λ_max=28.4629\n",
      "[SGD | lr=0.05] Epoch 267/4000: train_loss=1.0333  test_loss=2.1485  λ_max=26.8384\n",
      "[SGD | lr=0.05] Epoch 268/4000: train_loss=1.0311  test_loss=2.1515  λ_max=26.9675\n",
      "[SGD | lr=0.05] Iter 4300: loss=1.0364\n",
      "[SGD | lr=0.05] Epoch 269/4000: train_loss=1.0275  test_loss=2.1565  λ_max=28.5177\n",
      "[SGD | lr=0.05] Epoch 270/4000: train_loss=1.0245  test_loss=2.1470  λ_max=25.8427\n",
      "[SGD | lr=0.05] Epoch 271/4000: train_loss=1.0197  test_loss=2.1598  λ_max=27.6918\n",
      "[SGD | lr=0.05] Epoch 272/4000: train_loss=1.0213  test_loss=2.1578  λ_max=26.5129\n",
      "[SGD | lr=0.05] Epoch 273/4000: train_loss=1.0132  test_loss=2.1551  λ_max=28.2103\n",
      "[SGD | lr=0.05] Epoch 274/4000: train_loss=1.0087  test_loss=2.1597  λ_max=27.4029\n",
      "[SGD | lr=0.05] Iter 4400: loss=1.0099\n",
      "[SGD | lr=0.05] Epoch 275/4000: train_loss=1.0088  test_loss=2.1598  λ_max=27.7745\n",
      "[SGD | lr=0.05] Epoch 276/4000: train_loss=1.0066  test_loss=2.1551  λ_max=27.5687\n",
      "[SGD | lr=0.05] Epoch 277/4000: train_loss=1.0070  test_loss=2.1601  λ_max=27.9811\n",
      "[SGD | lr=0.05] Epoch 278/4000: train_loss=0.9930  test_loss=2.1610  λ_max=26.8937\n",
      "[SGD | lr=0.05] Epoch 279/4000: train_loss=0.9959  test_loss=2.1601  λ_max=27.8448\n",
      "[SGD | lr=0.05] Epoch 280/4000: train_loss=0.9874  test_loss=2.1586  λ_max=27.3823\n",
      "[SGD | lr=0.05] Epoch 281/4000: train_loss=0.9878  test_loss=2.1634  λ_max=28.7218\n",
      "[SGD | lr=0.05] Iter 4500: loss=0.9917\n",
      "[SGD | lr=0.05] Epoch 282/4000: train_loss=0.9880  test_loss=2.1612  λ_max=27.4250\n",
      "[SGD | lr=0.05] Epoch 283/4000: train_loss=0.9789  test_loss=2.1623  λ_max=27.2438\n",
      "[SGD | lr=0.05] Epoch 284/4000: train_loss=0.9764  test_loss=2.1713  λ_max=28.7762\n",
      "[SGD | lr=0.05] Epoch 285/4000: train_loss=0.9762  test_loss=2.1692  λ_max=26.4865\n",
      "[SGD | lr=0.05] Epoch 286/4000: train_loss=0.9779  test_loss=2.1690  λ_max=28.0561\n",
      "[SGD | lr=0.05] Epoch 287/4000: train_loss=0.9702  test_loss=2.1645  λ_max=27.7195\n",
      "[SGD | lr=0.05] Iter 4600: loss=0.9821\n",
      "[SGD | lr=0.05] Epoch 288/4000: train_loss=0.9714  test_loss=2.1698  λ_max=28.3771\n",
      "[SGD | lr=0.05] Epoch 289/4000: train_loss=0.9629  test_loss=2.1741  λ_max=29.5548\n",
      "[SGD | lr=0.05] Epoch 290/4000: train_loss=0.9621  test_loss=2.1680  λ_max=29.3367\n",
      "[SGD | lr=0.05] Epoch 291/4000: train_loss=0.9551  test_loss=2.1808  λ_max=28.0999\n",
      "[SGD | lr=0.05] Epoch 292/4000: train_loss=0.9521  test_loss=2.1702  λ_max=28.5245\n",
      "[SGD | lr=0.05] Epoch 293/4000: train_loss=0.9472  test_loss=2.1720  λ_max=28.8141\n",
      "[SGD | lr=0.05] Iter 4700: loss=0.9524\n",
      "[SGD | lr=0.05] Epoch 294/4000: train_loss=0.9454  test_loss=2.1735  λ_max=28.9325\n",
      "[SGD | lr=0.05] Epoch 295/4000: train_loss=0.9429  test_loss=2.1671  λ_max=28.3194\n",
      "[SGD | lr=0.05] Epoch 296/4000: train_loss=0.9387  test_loss=2.1778  λ_max=27.2798\n",
      "[SGD | lr=0.05] Epoch 297/4000: train_loss=0.9381  test_loss=2.1761  λ_max=29.1134\n",
      "[SGD | lr=0.05] Epoch 298/4000: train_loss=0.9324  test_loss=2.1780  λ_max=28.6776\n",
      "[SGD | lr=0.05] Epoch 299/4000: train_loss=0.9336  test_loss=2.1771  λ_max=28.3025\n",
      "[SGD | lr=0.05] Iter 4800: loss=0.9291\n",
      "[SGD | lr=0.05] Epoch 300/4000: train_loss=0.9267  test_loss=2.1752  λ_max=28.3673\n",
      "[SGD | lr=0.05] Epoch 301/4000: train_loss=0.9240  test_loss=2.1885  λ_max=29.8223\n",
      "[SGD | lr=0.05] Epoch 302/4000: train_loss=0.9213  test_loss=2.1805  λ_max=28.9276\n",
      "[SGD | lr=0.05] Epoch 303/4000: train_loss=0.9172  test_loss=2.1886  λ_max=28.8884\n",
      "[SGD | lr=0.05] Epoch 304/4000: train_loss=0.9178  test_loss=2.1880  λ_max=28.5582\n",
      "[SGD | lr=0.05] Epoch 305/4000: train_loss=0.9154  test_loss=2.1841  λ_max=28.9666\n",
      "[SGD | lr=0.05] Epoch 306/4000: train_loss=0.9116  test_loss=2.1812  λ_max=28.2833\n",
      "[SGD | lr=0.05] Iter 4900: loss=0.9071\n",
      "[SGD | lr=0.05] Epoch 307/4000: train_loss=0.9095  test_loss=2.1889  λ_max=29.9428\n",
      "[SGD | lr=0.05] Epoch 308/4000: train_loss=0.9026  test_loss=2.1882  λ_max=28.3443\n",
      "[SGD | lr=0.05] Epoch 309/4000: train_loss=0.9011  test_loss=2.1877  λ_max=27.4588\n",
      "[SGD | lr=0.05] Epoch 310/4000: train_loss=0.8998  test_loss=2.1880  λ_max=30.6483\n",
      "[SGD | lr=0.05] Epoch 311/4000: train_loss=0.8953  test_loss=2.1906  λ_max=28.7083\n",
      "[SGD | lr=0.05] Epoch 312/4000: train_loss=0.8934  test_loss=2.1930  λ_max=27.3212\n",
      "[SGD | lr=0.05] Iter 5000: loss=0.8779\n",
      "[SGD | lr=0.05] Epoch 313/4000: train_loss=0.8887  test_loss=2.1975  λ_max=28.6435\n",
      "[SGD | lr=0.05] Epoch 314/4000: train_loss=0.8807  test_loss=2.1874  λ_max=28.5373\n",
      "[SGD | lr=0.05] Epoch 315/4000: train_loss=0.8799  test_loss=2.1941  λ_max=29.0411\n",
      "[SGD | lr=0.05] Epoch 316/4000: train_loss=0.8815  test_loss=2.1885  λ_max=29.2773\n",
      "[SGD | lr=0.05] Epoch 317/4000: train_loss=0.8730  test_loss=2.1891  λ_max=30.0016\n",
      "[SGD | lr=0.05] Epoch 318/4000: train_loss=0.8715  test_loss=2.1937  λ_max=29.1541\n",
      "[SGD | lr=0.05] Iter 5100: loss=0.8873\n",
      "[SGD | lr=0.05] Epoch 319/4000: train_loss=0.8780  test_loss=2.2018  λ_max=27.9038\n",
      "[SGD | lr=0.05] Epoch 320/4000: train_loss=0.8708  test_loss=2.1921  λ_max=29.4297\n",
      "[SGD | lr=0.05] Epoch 321/4000: train_loss=0.8628  test_loss=2.1952  λ_max=30.0098\n",
      "[SGD | lr=0.05] Epoch 322/4000: train_loss=0.8599  test_loss=2.1959  λ_max=28.9149\n",
      "[SGD | lr=0.05] Epoch 323/4000: train_loss=0.8578  test_loss=2.1954  λ_max=29.4192\n",
      "[SGD | lr=0.05] Epoch 324/4000: train_loss=0.8527  test_loss=2.1947  λ_max=28.9042\n",
      "[SGD | lr=0.05] Iter 5200: loss=0.8544\n",
      "[SGD | lr=0.05] Epoch 325/4000: train_loss=0.8531  test_loss=2.1936  λ_max=29.4394\n",
      "[SGD | lr=0.05] Epoch 326/4000: train_loss=0.8546  test_loss=2.1966  λ_max=29.6802\n",
      "[SGD | lr=0.05] Epoch 327/4000: train_loss=0.8472  test_loss=2.2034  λ_max=29.9957\n",
      "[SGD | lr=0.05] Epoch 328/4000: train_loss=0.8440  test_loss=2.2099  λ_max=28.4183\n",
      "[SGD | lr=0.05] Epoch 329/4000: train_loss=0.8490  test_loss=2.2048  λ_max=29.6322\n",
      "[SGD | lr=0.05] Epoch 330/4000: train_loss=0.8389  test_loss=2.1987  λ_max=30.0996\n",
      "[SGD | lr=0.05] Epoch 331/4000: train_loss=0.8349  test_loss=2.2096  λ_max=30.2077\n",
      "[SGD | lr=0.05] Iter 5300: loss=0.8375\n",
      "[SGD | lr=0.05] Epoch 332/4000: train_loss=0.8374  test_loss=2.2096  λ_max=29.6040\n",
      "[SGD | lr=0.05] Epoch 333/4000: train_loss=0.8309  test_loss=2.2108  λ_max=30.0175\n",
      "[SGD | lr=0.05] Epoch 334/4000: train_loss=0.8328  test_loss=2.2083  λ_max=30.8682\n",
      "[SGD | lr=0.05] Epoch 335/4000: train_loss=0.8240  test_loss=2.2117  λ_max=28.7568\n",
      "[SGD | lr=0.05] Epoch 336/4000: train_loss=0.8242  test_loss=2.2183  λ_max=30.7118\n",
      "[SGD | lr=0.05] Epoch 337/4000: train_loss=0.8192  test_loss=2.2185  λ_max=30.4311\n",
      "[SGD | lr=0.05] Iter 5400: loss=0.8109\n",
      "[SGD | lr=0.05] Epoch 338/4000: train_loss=0.8160  test_loss=2.2104  λ_max=29.2569\n",
      "[SGD | lr=0.05] Epoch 339/4000: train_loss=0.8135  test_loss=2.2156  λ_max=29.0928\n",
      "[SGD | lr=0.05] Epoch 340/4000: train_loss=0.8097  test_loss=2.2089  λ_max=30.2789\n",
      "[SGD | lr=0.05] Epoch 341/4000: train_loss=0.8044  test_loss=2.2140  λ_max=29.6395\n",
      "[SGD | lr=0.05] Epoch 342/4000: train_loss=0.8045  test_loss=2.2180  λ_max=28.5466\n",
      "[SGD | lr=0.05] Epoch 343/4000: train_loss=0.8007  test_loss=2.2130  λ_max=29.5907\n",
      "[SGD | lr=0.05] Iter 5500: loss=0.8129\n",
      "[SGD | lr=0.05] Epoch 344/4000: train_loss=0.7988  test_loss=2.2231  λ_max=29.9842\n",
      "[SGD | lr=0.05] Epoch 345/4000: train_loss=0.7938  test_loss=2.2187  λ_max=30.8303\n",
      "[SGD | lr=0.05] Epoch 346/4000: train_loss=0.7967  test_loss=2.2189  λ_max=30.0952\n",
      "[SGD | lr=0.05] Epoch 347/4000: train_loss=0.7885  test_loss=2.2179  λ_max=30.3446\n",
      "[SGD | lr=0.05] Epoch 348/4000: train_loss=0.7857  test_loss=2.2249  λ_max=30.0679\n",
      "[SGD | lr=0.05] Epoch 349/4000: train_loss=0.7845  test_loss=2.2294  λ_max=30.1774\n",
      "[SGD | lr=0.05] Iter 5600: loss=0.7693\n",
      "[SGD | lr=0.05] Epoch 350/4000: train_loss=0.7874  test_loss=2.2205  λ_max=30.6977\n",
      "[SGD | lr=0.05] Epoch 351/4000: train_loss=0.7816  test_loss=2.2259  λ_max=28.9856\n",
      "[SGD | lr=0.05] Epoch 352/4000: train_loss=0.7824  test_loss=2.2219  λ_max=30.9296\n",
      "[SGD | lr=0.05] Epoch 353/4000: train_loss=0.7769  test_loss=2.2244  λ_max=29.8001\n",
      "[SGD | lr=0.05] Epoch 354/4000: train_loss=0.7712  test_loss=2.2236  λ_max=32.1693\n",
      "[SGD | lr=0.05] Epoch 355/4000: train_loss=0.7736  test_loss=2.2286  λ_max=31.0414\n",
      "[SGD | lr=0.05] Epoch 356/4000: train_loss=0.7694  test_loss=2.2257  λ_max=31.0617\n",
      "[SGD | lr=0.05] Iter 5700: loss=0.7535\n",
      "[SGD | lr=0.05] Epoch 357/4000: train_loss=0.7560  test_loss=2.2235  λ_max=31.4849\n",
      "[SGD | lr=0.05] Epoch 358/4000: train_loss=0.7558  test_loss=2.2337  λ_max=28.5571\n",
      "[SGD | lr=0.05] Epoch 359/4000: train_loss=0.7618  test_loss=2.2340  λ_max=31.1982\n",
      "[SGD | lr=0.05] Epoch 360/4000: train_loss=0.7603  test_loss=2.2361  λ_max=30.4638\n",
      "[SGD | lr=0.05] Epoch 361/4000: train_loss=0.7490  test_loss=2.2342  λ_max=30.5112\n",
      "[SGD | lr=0.05] Epoch 362/4000: train_loss=0.7510  test_loss=2.2409  λ_max=30.7775\n",
      "[SGD | lr=0.05] Iter 5800: loss=0.7507\n",
      "[SGD | lr=0.05] Epoch 363/4000: train_loss=0.7509  test_loss=2.2395  λ_max=30.2730\n",
      "[SGD | lr=0.05] Epoch 364/4000: train_loss=0.7457  test_loss=2.2469  λ_max=31.1374\n",
      "[SGD | lr=0.05] Epoch 365/4000: train_loss=0.7476  test_loss=2.2375  λ_max=30.9139\n",
      "[SGD | lr=0.05] Epoch 366/4000: train_loss=0.7406  test_loss=2.2468  λ_max=32.4637\n",
      "[SGD | lr=0.05] Epoch 367/4000: train_loss=0.7432  test_loss=2.2422  λ_max=31.8048\n",
      "[SGD | lr=0.05] Epoch 368/4000: train_loss=0.7353  test_loss=2.2553  λ_max=33.1123\n",
      "[SGD | lr=0.05] Iter 5900: loss=0.7416\n",
      "[SGD | lr=0.05] Epoch 369/4000: train_loss=0.7383  test_loss=2.2460  λ_max=32.2900\n",
      "[SGD | lr=0.05] Epoch 370/4000: train_loss=0.7266  test_loss=2.2521  λ_max=31.2250\n",
      "[SGD | lr=0.05] Epoch 371/4000: train_loss=0.7297  test_loss=2.2557  λ_max=32.5601\n",
      "[SGD | lr=0.05] Epoch 372/4000: train_loss=0.7323  test_loss=2.2521  λ_max=31.3031\n",
      "[SGD | lr=0.05] Epoch 373/4000: train_loss=0.7178  test_loss=2.2499  λ_max=30.3290\n",
      "[SGD | lr=0.05] Epoch 374/4000: train_loss=0.7191  test_loss=2.2458  λ_max=29.4022\n",
      "[SGD | lr=0.05] Iter 6000: loss=0.7227\n",
      "[SGD | lr=0.05] Epoch 375/4000: train_loss=0.7154  test_loss=2.2512  λ_max=30.8312\n",
      "[SGD | lr=0.05] Epoch 376/4000: train_loss=0.7170  test_loss=2.2502  λ_max=31.1009\n",
      "[SGD | lr=0.05] Epoch 377/4000: train_loss=0.7131  test_loss=2.2536  λ_max=31.5462\n",
      "[SGD | lr=0.05] Epoch 378/4000: train_loss=0.7129  test_loss=2.2528  λ_max=31.3712\n",
      "[SGD | lr=0.05] Epoch 379/4000: train_loss=0.7086  test_loss=2.2596  λ_max=32.6268\n",
      "[SGD | lr=0.05] Epoch 380/4000: train_loss=0.7105  test_loss=2.2575  λ_max=30.6346\n",
      "[SGD | lr=0.05] Epoch 381/4000: train_loss=0.7035  test_loss=2.2625  λ_max=33.3764\n",
      "[SGD | lr=0.05] Iter 6100: loss=0.7068\n",
      "[SGD | lr=0.05] Epoch 382/4000: train_loss=0.7056  test_loss=2.2666  λ_max=30.4661\n",
      "[SGD | lr=0.05] Epoch 383/4000: train_loss=0.6987  test_loss=2.2600  λ_max=30.6088\n",
      "[SGD | lr=0.05] Epoch 384/4000: train_loss=0.6959  test_loss=2.2628  λ_max=32.2310\n",
      "[SGD | lr=0.05] Epoch 385/4000: train_loss=0.6904  test_loss=2.2713  λ_max=32.5199\n",
      "[SGD | lr=0.05] Epoch 386/4000: train_loss=0.6932  test_loss=2.2676  λ_max=32.7751\n",
      "[SGD | lr=0.05] Epoch 387/4000: train_loss=0.6885  test_loss=2.2681  λ_max=30.6392\n",
      "[SGD | lr=0.05] Iter 6200: loss=0.6974\n",
      "[SGD | lr=0.05] Epoch 388/4000: train_loss=0.6885  test_loss=2.2633  λ_max=32.1142\n",
      "[SGD | lr=0.05] Epoch 389/4000: train_loss=0.6801  test_loss=2.2693  λ_max=29.7769\n",
      "[SGD | lr=0.05] Epoch 390/4000: train_loss=0.6791  test_loss=2.2720  λ_max=31.6957\n",
      "[SGD | lr=0.05] Epoch 391/4000: train_loss=0.6786  test_loss=2.2757  λ_max=30.4996\n",
      "[SGD | lr=0.05] Epoch 392/4000: train_loss=0.6807  test_loss=2.2759  λ_max=30.2600\n",
      "[SGD | lr=0.05] Epoch 393/4000: train_loss=0.6741  test_loss=2.2791  λ_max=31.0514\n",
      "[SGD | lr=0.05] Iter 6300: loss=0.6675\n",
      "[SGD | lr=0.05] Epoch 394/4000: train_loss=0.6719  test_loss=2.2693  λ_max=31.4994\n",
      "[SGD | lr=0.05] Epoch 395/4000: train_loss=0.6660  test_loss=2.2742  λ_max=31.3275\n",
      "[SGD | lr=0.05] Epoch 396/4000: train_loss=0.6645  test_loss=2.2742  λ_max=31.4335\n",
      "[SGD | lr=0.05] Epoch 397/4000: train_loss=0.6659  test_loss=2.2770  λ_max=31.6475\n",
      "[SGD | lr=0.05] Epoch 398/4000: train_loss=0.6555  test_loss=2.2776  λ_max=32.2144\n",
      "[SGD | lr=0.05] Epoch 399/4000: train_loss=0.6588  test_loss=2.2767  λ_max=30.9053\n",
      "[SGD | lr=0.05] Iter 6400: loss=0.6459\n",
      "[SGD | lr=0.05] Epoch 400/4000: train_loss=0.6519  test_loss=2.2870  λ_max=32.2526\n",
      "[SGD | lr=0.05] Epoch 401/4000: train_loss=0.6507  test_loss=2.2839  λ_max=32.9714\n",
      "[SGD | lr=0.05] Epoch 402/4000: train_loss=0.6517  test_loss=2.2834  λ_max=32.0183\n",
      "[SGD | lr=0.05] Epoch 403/4000: train_loss=0.6549  test_loss=2.2840  λ_max=32.8610\n",
      "[SGD | lr=0.05] Epoch 404/4000: train_loss=0.6484  test_loss=2.2956  λ_max=33.5196\n",
      "[SGD | lr=0.05] Epoch 405/4000: train_loss=0.6459  test_loss=2.2909  λ_max=32.0032\n",
      "[SGD | lr=0.05] Epoch 406/4000: train_loss=0.6410  test_loss=2.2836  λ_max=32.3210\n",
      "[SGD | lr=0.05] Iter 6500: loss=0.6291\n",
      "[SGD | lr=0.05] Epoch 407/4000: train_loss=0.6424  test_loss=2.2965  λ_max=32.1676\n",
      "[SGD | lr=0.05] Epoch 408/4000: train_loss=0.6451  test_loss=2.2878  λ_max=31.0575\n",
      "[SGD | lr=0.05] Epoch 409/4000: train_loss=0.6323  test_loss=2.2951  λ_max=31.5188\n",
      "[SGD | lr=0.05] Epoch 410/4000: train_loss=0.6345  test_loss=2.2953  λ_max=31.9666\n",
      "[SGD | lr=0.05] Epoch 411/4000: train_loss=0.6318  test_loss=2.2961  λ_max=32.8906\n",
      "[SGD | lr=0.05] Epoch 412/4000: train_loss=0.6274  test_loss=2.3018  λ_max=32.8891\n",
      "[SGD | lr=0.05] Iter 6600: loss=0.6172\n",
      "[SGD | lr=0.05] Epoch 413/4000: train_loss=0.6285  test_loss=2.2964  λ_max=33.0669\n",
      "[SGD | lr=0.05] Epoch 414/4000: train_loss=0.6291  test_loss=2.2980  λ_max=32.0641\n",
      "[SGD | lr=0.05] Epoch 415/4000: train_loss=0.6270  test_loss=2.3005  λ_max=31.8982\n",
      "[SGD | lr=0.05] Epoch 416/4000: train_loss=0.6218  test_loss=2.3013  λ_max=31.3841\n",
      "[SGD | lr=0.05] Epoch 417/4000: train_loss=0.6192  test_loss=2.3025  λ_max=32.4630\n",
      "[SGD | lr=0.05] Epoch 418/4000: train_loss=0.6191  test_loss=2.2926  λ_max=33.2945\n",
      "[SGD | lr=0.05] Iter 6700: loss=0.6101\n",
      "[SGD | lr=0.05] Epoch 419/4000: train_loss=0.6141  test_loss=2.3082  λ_max=32.9961\n",
      "[SGD | lr=0.05] Epoch 420/4000: train_loss=0.6151  test_loss=2.3095  λ_max=33.7775\n",
      "[SGD | lr=0.05] Epoch 421/4000: train_loss=0.6099  test_loss=2.3070  λ_max=31.5603\n",
      "[SGD | lr=0.05] Epoch 422/4000: train_loss=0.6051  test_loss=2.3101  λ_max=32.0558\n",
      "[SGD | lr=0.05] Epoch 423/4000: train_loss=0.6087  test_loss=2.3031  λ_max=32.0146\n",
      "[SGD | lr=0.05] Epoch 424/4000: train_loss=0.6042  test_loss=2.3216  λ_max=32.6630\n",
      "[SGD | lr=0.05] Iter 6800: loss=0.6091\n",
      "[SGD | lr=0.05] Epoch 425/4000: train_loss=0.6005  test_loss=2.3184  λ_max=32.9349\n",
      "[SGD | lr=0.05] Epoch 426/4000: train_loss=0.6002  test_loss=2.3155  λ_max=32.5291\n",
      "[SGD | lr=0.05] Epoch 427/4000: train_loss=0.6012  test_loss=2.3200  λ_max=33.8622\n",
      "[SGD | lr=0.05] Epoch 428/4000: train_loss=0.5991  test_loss=2.3227  λ_max=32.4343\n",
      "[SGD | lr=0.05] Epoch 429/4000: train_loss=0.5989  test_loss=2.3342  λ_max=33.2614\n",
      "[SGD | lr=0.05] Epoch 430/4000: train_loss=0.5995  test_loss=2.3299  λ_max=31.9431\n",
      "[SGD | lr=0.05] Epoch 431/4000: train_loss=0.5924  test_loss=2.3335  λ_max=34.7884\n",
      "[SGD | lr=0.05] Iter 6900: loss=0.6018\n",
      "[SGD | lr=0.05] Epoch 432/4000: train_loss=0.5892  test_loss=2.3275  λ_max=33.2537\n",
      "[SGD | lr=0.05] Epoch 433/4000: train_loss=0.5825  test_loss=2.3273  λ_max=31.7134\n",
      "[SGD | lr=0.05] Epoch 434/4000: train_loss=0.5804  test_loss=2.3229  λ_max=32.3162\n",
      "[SGD | lr=0.05] Epoch 435/4000: train_loss=0.5744  test_loss=2.3248  λ_max=31.5923\n",
      "[SGD | lr=0.05] Epoch 436/4000: train_loss=0.5848  test_loss=2.3277  λ_max=33.5143\n",
      "[SGD | lr=0.05] Epoch 437/4000: train_loss=0.5736  test_loss=2.3352  λ_max=32.3228\n",
      "[SGD | lr=0.05] Iter 7000: loss=0.5831\n",
      "[SGD | lr=0.05] Epoch 438/4000: train_loss=0.5733  test_loss=2.3387  λ_max=34.8124\n",
      "[SGD | lr=0.05] Epoch 439/4000: train_loss=0.5741  test_loss=2.3323  λ_max=32.7249\n",
      "[SGD | lr=0.05] Epoch 440/4000: train_loss=0.5729  test_loss=2.3376  λ_max=32.8471\n",
      "[SGD | lr=0.05] Epoch 441/4000: train_loss=0.5684  test_loss=2.3287  λ_max=32.2755\n",
      "[SGD | lr=0.05] Epoch 442/4000: train_loss=0.5654  test_loss=2.3327  λ_max=32.9582\n",
      "[SGD | lr=0.05] Epoch 443/4000: train_loss=0.5673  test_loss=2.3459  λ_max=32.8754\n",
      "[SGD | lr=0.05] Iter 7100: loss=0.5531\n",
      "[SGD | lr=0.05] Epoch 444/4000: train_loss=0.5599  test_loss=2.3399  λ_max=34.0331\n",
      "[SGD | lr=0.05] Epoch 445/4000: train_loss=0.5568  test_loss=2.3418  λ_max=33.0329\n",
      "[SGD | lr=0.05] Epoch 446/4000: train_loss=0.5529  test_loss=2.3424  λ_max=34.7730\n",
      "[SGD | lr=0.05] Epoch 447/4000: train_loss=0.5614  test_loss=2.3384  λ_max=32.5080\n",
      "[SGD | lr=0.05] Epoch 448/4000: train_loss=0.5470  test_loss=2.3416  λ_max=33.6991\n",
      "[SGD | lr=0.05] Epoch 449/4000: train_loss=0.5534  test_loss=2.3438  λ_max=33.7190\n",
      "[SGD | lr=0.05] Iter 7200: loss=0.5594\n",
      "[SGD | lr=0.05] Epoch 450/4000: train_loss=0.5476  test_loss=2.3448  λ_max=33.0205\n",
      "[SGD | lr=0.05] Epoch 451/4000: train_loss=0.5451  test_loss=2.3535  λ_max=32.4520\n",
      "[SGD | lr=0.05] Epoch 452/4000: train_loss=0.5463  test_loss=2.3487  λ_max=33.3594\n",
      "[SGD | lr=0.05] Epoch 453/4000: train_loss=0.5449  test_loss=2.3511  λ_max=32.4078\n",
      "[SGD | lr=0.05] Epoch 454/4000: train_loss=0.5385  test_loss=2.3572  λ_max=32.9349\n",
      "[SGD | lr=0.05] Epoch 455/4000: train_loss=0.5428  test_loss=2.3567  λ_max=33.1845\n",
      "[SGD | lr=0.05] Epoch 456/4000: train_loss=0.5382  test_loss=2.3599  λ_max=33.2896\n",
      "[SGD | lr=0.05] Iter 7300: loss=0.5416\n",
      "[SGD | lr=0.05] Epoch 457/4000: train_loss=0.5402  test_loss=2.3587  λ_max=35.4831\n",
      "[SGD | lr=0.05] Epoch 458/4000: train_loss=0.5384  test_loss=2.3627  λ_max=34.1348\n",
      "[SGD | lr=0.05] Epoch 459/4000: train_loss=0.5351  test_loss=2.3618  λ_max=32.5179\n",
      "[SGD | lr=0.05] Epoch 460/4000: train_loss=0.5338  test_loss=2.3554  λ_max=33.7788\n",
      "[SGD | lr=0.05] Epoch 461/4000: train_loss=0.5254  test_loss=2.3617  λ_max=33.5787\n",
      "[SGD | lr=0.05] Epoch 462/4000: train_loss=0.5324  test_loss=2.3682  λ_max=34.0937\n",
      "[SGD | lr=0.05] Iter 7400: loss=0.5182\n",
      "[SGD | lr=0.05] Epoch 463/4000: train_loss=0.5235  test_loss=2.3621  λ_max=33.4830\n",
      "[SGD | lr=0.05] Epoch 464/4000: train_loss=0.5141  test_loss=2.3708  λ_max=34.3232\n",
      "[SGD | lr=0.05] Epoch 465/4000: train_loss=0.5223  test_loss=2.3711  λ_max=33.0104\n",
      "[SGD | lr=0.05] Epoch 466/4000: train_loss=0.5145  test_loss=2.3684  λ_max=32.7204\n",
      "[SGD | lr=0.05] Epoch 467/4000: train_loss=0.5135  test_loss=2.3766  λ_max=34.0608\n",
      "[SGD | lr=0.05] Epoch 468/4000: train_loss=0.5104  test_loss=2.3724  λ_max=32.9471\n",
      "[SGD | lr=0.05] Iter 7500: loss=0.5148\n",
      "[SGD | lr=0.05] Epoch 469/4000: train_loss=0.5184  test_loss=2.3759  λ_max=33.0669\n",
      "[SGD | lr=0.05] Epoch 470/4000: train_loss=0.5089  test_loss=2.3874  λ_max=34.3851\n",
      "[SGD | lr=0.05] Epoch 471/4000: train_loss=0.5137  test_loss=2.3792  λ_max=34.2576\n",
      "[SGD | lr=0.05] Epoch 472/4000: train_loss=0.5105  test_loss=2.3749  λ_max=34.7464\n",
      "[SGD | lr=0.05] Epoch 473/4000: train_loss=0.5070  test_loss=2.3727  λ_max=33.0551\n",
      "[SGD | lr=0.05] Epoch 474/4000: train_loss=0.5017  test_loss=2.3834  λ_max=35.0841\n",
      "[SGD | lr=0.05] Iter 7600: loss=0.5149\n",
      "[SGD | lr=0.05] Epoch 475/4000: train_loss=0.5021  test_loss=2.3898  λ_max=33.2856\n",
      "[SGD | lr=0.05] Epoch 476/4000: train_loss=0.5038  test_loss=2.3874  λ_max=34.8279\n",
      "[SGD | lr=0.05] Epoch 477/4000: train_loss=0.4947  test_loss=2.3832  λ_max=34.8644\n",
      "[SGD | lr=0.05] Epoch 478/4000: train_loss=0.4954  test_loss=2.3782  λ_max=34.1010\n",
      "[SGD | lr=0.05] Epoch 479/4000: train_loss=0.4931  test_loss=2.3853  λ_max=33.5309\n",
      "[SGD | lr=0.05] Epoch 480/4000: train_loss=0.4891  test_loss=2.3956  λ_max=34.6035\n",
      "[SGD | lr=0.05] Epoch 481/4000: train_loss=0.4970  test_loss=2.3912  λ_max=34.3978\n",
      "[SGD | lr=0.05] Iter 7700: loss=0.4853\n",
      "[SGD | lr=0.05] Epoch 482/4000: train_loss=0.4864  test_loss=2.3905  λ_max=33.0511\n",
      "[SGD | lr=0.05] Epoch 483/4000: train_loss=0.4840  test_loss=2.3959  λ_max=34.5386\n",
      "[SGD | lr=0.05] Epoch 484/4000: train_loss=0.4869  test_loss=2.3983  λ_max=33.1603\n",
      "[SGD | lr=0.05] Epoch 485/4000: train_loss=0.4934  test_loss=2.4001  λ_max=33.6676\n",
      "[SGD | lr=0.05] Epoch 486/4000: train_loss=0.4850  test_loss=2.3994  λ_max=32.5452\n",
      "[SGD | lr=0.05] Epoch 487/4000: train_loss=0.4840  test_loss=2.3999  λ_max=33.7517\n",
      "[SGD | lr=0.05] Iter 7800: loss=0.4664\n",
      "[SGD | lr=0.05] Epoch 488/4000: train_loss=0.4711  test_loss=2.3998  λ_max=35.1721\n",
      "[SGD | lr=0.05] Epoch 489/4000: train_loss=0.4800  test_loss=2.3999  λ_max=34.2046\n",
      "[SGD | lr=0.05] Epoch 490/4000: train_loss=0.4706  test_loss=2.3994  λ_max=34.5801\n",
      "[SGD | lr=0.05] Epoch 491/4000: train_loss=0.4797  test_loss=2.4018  λ_max=33.6087\n",
      "[SGD | lr=0.05] Epoch 492/4000: train_loss=0.4760  test_loss=2.4013  λ_max=34.9692\n",
      "[SGD | lr=0.05] Epoch 493/4000: train_loss=0.4603  test_loss=2.4114  λ_max=34.8170\n",
      "[SGD | lr=0.05] Iter 7900: loss=0.4644\n",
      "[SGD | lr=0.05] Epoch 494/4000: train_loss=0.4654  test_loss=2.4095  λ_max=34.9839\n",
      "[SGD | lr=0.05] Epoch 495/4000: train_loss=0.4686  test_loss=2.4149  λ_max=36.0487\n",
      "[SGD | lr=0.05] Epoch 496/4000: train_loss=0.4567  test_loss=2.4157  λ_max=35.1096\n",
      "[SGD | lr=0.05] Epoch 497/4000: train_loss=0.4641  test_loss=2.4133  λ_max=35.8187\n",
      "[SGD | lr=0.05] Epoch 498/4000: train_loss=0.4643  test_loss=2.4207  λ_max=34.3283\n",
      "[SGD | lr=0.05] Epoch 499/4000: train_loss=0.4550  test_loss=2.4184  λ_max=37.4069\n",
      "[SGD | lr=0.05] Iter 8000: loss=0.4720\n",
      "[SGD | lr=0.05] Epoch 500/4000: train_loss=0.4664  test_loss=2.4262  λ_max=35.8960\n",
      "[SGD | lr=0.05] Epoch 501/4000: train_loss=0.4600  test_loss=2.4229  λ_max=36.4310\n",
      "[SGD | lr=0.05] Epoch 502/4000: train_loss=0.4577  test_loss=2.4197  λ_max=35.2603\n",
      "[SGD | lr=0.05] Epoch 503/4000: train_loss=0.4538  test_loss=2.4230  λ_max=35.8261\n",
      "[SGD | lr=0.05] Epoch 504/4000: train_loss=0.4484  test_loss=2.4219  λ_max=35.4648\n",
      "[SGD | lr=0.05] Epoch 505/4000: train_loss=0.4508  test_loss=2.4213  λ_max=33.9408\n",
      "[SGD | lr=0.05] Epoch 506/4000: train_loss=0.4501  test_loss=2.4313  λ_max=36.9035\n",
      "[SGD | lr=0.05] Iter 8100: loss=0.4589\n",
      "[SGD | lr=0.05] Epoch 507/4000: train_loss=0.4524  test_loss=2.4242  λ_max=35.0894\n",
      "[SGD | lr=0.05] Epoch 508/4000: train_loss=0.4449  test_loss=2.4267  λ_max=34.3392\n",
      "[SGD | lr=0.05] Epoch 509/4000: train_loss=0.4380  test_loss=2.4419  λ_max=34.4005\n",
      "[SGD | lr=0.05] Epoch 510/4000: train_loss=0.4506  test_loss=2.4328  λ_max=34.9448\n",
      "[SGD | lr=0.05] Epoch 511/4000: train_loss=0.4435  test_loss=2.4339  λ_max=35.7268\n",
      "[SGD | lr=0.05] Epoch 512/4000: train_loss=0.4447  test_loss=2.4309  λ_max=35.8571\n",
      "[SGD | lr=0.05] Iter 8200: loss=0.4303\n",
      "[SGD | lr=0.05] Epoch 513/4000: train_loss=0.4325  test_loss=2.4410  λ_max=36.6046\n",
      "[SGD | lr=0.05] Epoch 514/4000: train_loss=0.4355  test_loss=2.4350  λ_max=35.8161\n",
      "[SGD | lr=0.05] Epoch 515/4000: train_loss=0.4317  test_loss=2.4404  λ_max=36.3343\n",
      "[SGD | lr=0.05] Epoch 516/4000: train_loss=0.4247  test_loss=2.4437  λ_max=36.9681\n",
      "[SGD | lr=0.05] Epoch 517/4000: train_loss=0.4299  test_loss=2.4495  λ_max=34.0016\n",
      "[SGD | lr=0.05] Epoch 518/4000: train_loss=0.4414  test_loss=2.4416  λ_max=34.6798\n",
      "[SGD | lr=0.05] Iter 8300: loss=0.4217\n",
      "[SGD | lr=0.05] Epoch 519/4000: train_loss=0.4244  test_loss=2.4461  λ_max=35.8218\n",
      "[SGD | lr=0.05] Epoch 520/4000: train_loss=0.4300  test_loss=2.4528  λ_max=36.5114\n",
      "[SGD | lr=0.05] Epoch 521/4000: train_loss=0.4300  test_loss=2.4439  λ_max=35.9160\n",
      "[SGD | lr=0.05] Epoch 522/4000: train_loss=0.4270  test_loss=2.4547  λ_max=37.3098\n",
      "[SGD | lr=0.05] Epoch 523/4000: train_loss=0.4139  test_loss=2.4460  λ_max=33.5138\n",
      "[SGD | lr=0.05] Epoch 524/4000: train_loss=0.4111  test_loss=2.4613  λ_max=35.9875\n",
      "[SGD | lr=0.05] Iter 8400: loss=0.4252\n",
      "[SGD | lr=0.05] Epoch 525/4000: train_loss=0.4242  test_loss=2.4518  λ_max=35.6613\n",
      "[SGD | lr=0.05] Epoch 526/4000: train_loss=0.4161  test_loss=2.4587  λ_max=36.8502\n",
      "[SGD | lr=0.05] Epoch 527/4000: train_loss=0.4227  test_loss=2.4609  λ_max=37.0006\n",
      "[SGD | lr=0.05] Epoch 528/4000: train_loss=0.4099  test_loss=2.4536  λ_max=34.9670\n",
      "[SGD | lr=0.05] Epoch 529/4000: train_loss=0.4035  test_loss=2.4615  λ_max=36.2651\n",
      "[SGD | lr=0.05] Epoch 530/4000: train_loss=0.4085  test_loss=2.4629  λ_max=35.8462\n",
      "[SGD | lr=0.05] Epoch 531/4000: train_loss=0.4090  test_loss=2.4627  λ_max=37.4645\n",
      "[SGD | lr=0.05] Iter 8500: loss=0.4012\n",
      "[SGD | lr=0.05] Epoch 532/4000: train_loss=0.4035  test_loss=2.4669  λ_max=34.7852\n",
      "[SGD | lr=0.05] Epoch 533/4000: train_loss=0.4044  test_loss=2.4613  λ_max=35.3803\n",
      "[SGD | lr=0.05] Epoch 534/4000: train_loss=0.3998  test_loss=2.4681  λ_max=35.4581\n",
      "[SGD | lr=0.05] Epoch 535/4000: train_loss=0.4026  test_loss=2.4679  λ_max=35.7817\n",
      "[SGD | lr=0.05] Epoch 536/4000: train_loss=0.3963  test_loss=2.4643  λ_max=36.7027\n",
      "[SGD | lr=0.05] Epoch 537/4000: train_loss=0.4013  test_loss=2.4712  λ_max=36.9841\n",
      "[SGD | lr=0.05] Iter 8600: loss=0.3929\n",
      "[SGD | lr=0.05] Epoch 538/4000: train_loss=0.4000  test_loss=2.4766  λ_max=35.8353\n",
      "[SGD | lr=0.05] Epoch 539/4000: train_loss=0.3992  test_loss=2.4694  λ_max=35.1352\n",
      "[SGD | lr=0.05] Epoch 540/4000: train_loss=0.3926  test_loss=2.4806  λ_max=35.9164\n",
      "[SGD | lr=0.05] Epoch 541/4000: train_loss=0.4025  test_loss=2.4804  λ_max=35.0354\n",
      "[SGD | lr=0.05] Epoch 542/4000: train_loss=0.4000  test_loss=2.4735  λ_max=35.2000\n",
      "[SGD | lr=0.05] Epoch 543/4000: train_loss=0.3904  test_loss=2.4772  λ_max=36.0560\n",
      "[SGD | lr=0.05] Iter 8700: loss=0.3854\n",
      "[SGD | lr=0.05] Epoch 544/4000: train_loss=0.3879  test_loss=2.4858  λ_max=36.0162\n",
      "[SGD | lr=0.05] Epoch 545/4000: train_loss=0.3915  test_loss=2.4839  λ_max=34.6545\n",
      "[SGD | lr=0.05] Epoch 546/4000: train_loss=0.3850  test_loss=2.4864  λ_max=35.5365\n",
      "[SGD | lr=0.05] Epoch 547/4000: train_loss=0.3867  test_loss=2.4868  λ_max=35.3135\n",
      "[SGD | lr=0.05] Epoch 548/4000: train_loss=0.3819  test_loss=2.4875  λ_max=34.3055\n",
      "[SGD | lr=0.05] Epoch 549/4000: train_loss=0.3814  test_loss=2.4953  λ_max=35.8417\n",
      "[SGD | lr=0.05] Iter 8800: loss=0.3780\n",
      "[SGD | lr=0.05] Epoch 550/4000: train_loss=0.3857  test_loss=2.4903  λ_max=36.1877\n",
      "[SGD | lr=0.05] Epoch 551/4000: train_loss=0.3740  test_loss=2.4907  λ_max=35.4969\n",
      "[SGD | lr=0.05] Epoch 552/4000: train_loss=0.3862  test_loss=2.4977  λ_max=35.0731\n",
      "[SGD | lr=0.05] Epoch 553/4000: train_loss=0.3802  test_loss=2.4956  λ_max=36.6858\n",
      "[SGD | lr=0.05] Epoch 554/4000: train_loss=0.3713  test_loss=2.4955  λ_max=37.7107\n",
      "[SGD | lr=0.05] Epoch 555/4000: train_loss=0.3712  test_loss=2.5038  λ_max=37.6359\n",
      "[SGD | lr=0.05] Epoch 556/4000: train_loss=0.3772  test_loss=2.5102  λ_max=38.8293\n",
      "[SGD | lr=0.05] Iter 8900: loss=0.3710\n",
      "[SGD | lr=0.05] Epoch 557/4000: train_loss=0.3666  test_loss=2.5006  λ_max=36.8347\n",
      "[SGD | lr=0.05] Epoch 558/4000: train_loss=0.3659  test_loss=2.5006  λ_max=36.9895\n",
      "[SGD | lr=0.05] Epoch 559/4000: train_loss=0.3670  test_loss=2.5098  λ_max=34.9236\n",
      "[SGD | lr=0.05] Epoch 560/4000: train_loss=0.3722  test_loss=2.5066  λ_max=37.0607\n",
      "[SGD | lr=0.05] Epoch 561/4000: train_loss=0.3659  test_loss=2.5136  λ_max=37.4531\n",
      "[SGD | lr=0.05] Epoch 562/4000: train_loss=0.3803  test_loss=2.5125  λ_max=37.3680\n",
      "[SGD | lr=0.05] Iter 9000: loss=0.3638\n",
      "[SGD | lr=0.05] Epoch 563/4000: train_loss=0.3646  test_loss=2.5131  λ_max=38.5643\n",
      "[SGD | lr=0.05] Epoch 564/4000: train_loss=0.3564  test_loss=2.5110  λ_max=36.7498\n",
      "[SGD | lr=0.05] Epoch 565/4000: train_loss=0.3638  test_loss=2.5145  λ_max=36.9158\n",
      "[SGD | lr=0.05] Epoch 566/4000: train_loss=0.3533  test_loss=2.5211  λ_max=37.2597\n",
      "[SGD | lr=0.05] Epoch 567/4000: train_loss=0.3595  test_loss=2.5174  λ_max=34.9899\n",
      "[SGD | lr=0.05] Epoch 568/4000: train_loss=0.3607  test_loss=2.5148  λ_max=35.9241\n",
      "[SGD | lr=0.05] Iter 9100: loss=0.3608\n",
      "[SGD | lr=0.05] Epoch 569/4000: train_loss=0.3575  test_loss=2.5215  λ_max=38.0863\n",
      "[SGD | lr=0.05] Epoch 570/4000: train_loss=0.3565  test_loss=2.5187  λ_max=36.9064\n",
      "[SGD | lr=0.05] Epoch 571/4000: train_loss=0.3502  test_loss=2.5185  λ_max=36.4386\n",
      "[SGD | lr=0.05] Epoch 572/4000: train_loss=0.3526  test_loss=2.5271  λ_max=38.0060\n",
      "[SGD | lr=0.05] Epoch 573/4000: train_loss=0.3488  test_loss=2.5185  λ_max=37.0907\n",
      "[SGD | lr=0.05] Epoch 574/4000: train_loss=0.3449  test_loss=2.5297  λ_max=38.9317\n",
      "[SGD | lr=0.05] Iter 9200: loss=0.3575\n",
      "[SGD | lr=0.05] Epoch 575/4000: train_loss=0.3539  test_loss=2.5315  λ_max=36.4118\n",
      "[SGD | lr=0.05] Epoch 576/4000: train_loss=0.3526  test_loss=2.5312  λ_max=38.3371\n",
      "[SGD | lr=0.05] Epoch 577/4000: train_loss=0.3417  test_loss=2.5285  λ_max=37.7864\n",
      "[SGD | lr=0.05] Epoch 578/4000: train_loss=0.3398  test_loss=2.5352  λ_max=39.8135\n",
      "[SGD | lr=0.05] Epoch 579/4000: train_loss=0.3435  test_loss=2.5405  λ_max=39.1669\n",
      "[SGD | lr=0.05] Epoch 580/4000: train_loss=0.3470  test_loss=2.5433  λ_max=37.6503\n",
      "[SGD | lr=0.05] Epoch 581/4000: train_loss=0.3479  test_loss=2.5388  λ_max=37.9498\n",
      "[SGD | lr=0.05] Iter 9300: loss=0.3341\n",
      "[SGD | lr=0.05] Epoch 582/4000: train_loss=0.3342  test_loss=2.5311  λ_max=36.2069\n",
      "[SGD | lr=0.05] Epoch 583/4000: train_loss=0.3276  test_loss=2.5354  λ_max=38.2482\n",
      "[SGD | lr=0.05] Epoch 584/4000: train_loss=0.3391  test_loss=2.5465  λ_max=37.5142\n",
      "[SGD | lr=0.05] Epoch 585/4000: train_loss=0.3325  test_loss=2.5429  λ_max=37.6953\n",
      "[SGD | lr=0.05] Epoch 586/4000: train_loss=0.3321  test_loss=2.5432  λ_max=38.4646\n",
      "[SGD | lr=0.05] Epoch 587/4000: train_loss=0.3283  test_loss=2.5470  λ_max=36.2684\n",
      "[SGD | lr=0.05] Iter 9400: loss=0.3274\n",
      "[SGD | lr=0.05] Epoch 588/4000: train_loss=0.3299  test_loss=2.5433  λ_max=37.8885\n",
      "[SGD | lr=0.05] Epoch 589/4000: train_loss=0.3257  test_loss=2.5493  λ_max=36.1732\n",
      "[SGD | lr=0.05] Epoch 590/4000: train_loss=0.3209  test_loss=2.5465  λ_max=37.4461\n",
      "[SGD | lr=0.05] Epoch 591/4000: train_loss=0.3216  test_loss=2.5487  λ_max=36.8506\n",
      "[SGD | lr=0.05] Epoch 592/4000: train_loss=0.3283  test_loss=2.5520  λ_max=37.3313\n",
      "[SGD | lr=0.05] Epoch 593/4000: train_loss=0.3230  test_loss=2.5518  λ_max=37.8807\n",
      "[SGD | lr=0.05] Iter 9500: loss=0.3274\n",
      "[SGD | lr=0.05] Epoch 594/4000: train_loss=0.3273  test_loss=2.5626  λ_max=36.4729\n",
      "[SGD | lr=0.05] Epoch 595/4000: train_loss=0.3260  test_loss=2.5609  λ_max=37.7861\n",
      "[SGD | lr=0.05] Epoch 596/4000: train_loss=0.3241  test_loss=2.5605  λ_max=37.7791\n",
      "[SGD | lr=0.05] Epoch 597/4000: train_loss=0.3251  test_loss=2.5658  λ_max=37.3912\n",
      "[SGD | lr=0.05] Epoch 598/4000: train_loss=0.3210  test_loss=2.5603  λ_max=38.1181\n",
      "[SGD | lr=0.05] Epoch 599/4000: train_loss=0.3257  test_loss=2.5728  λ_max=38.1792\n",
      "[SGD | lr=0.05] Iter 9600: loss=0.3143\n",
      "[SGD | lr=0.05] Epoch 600/4000: train_loss=0.3237  test_loss=2.5645  λ_max=39.2852\n",
      "[SGD | lr=0.05] Epoch 601/4000: train_loss=0.3077  test_loss=2.5617  λ_max=38.3981\n",
      "[SGD | lr=0.05] Epoch 602/4000: train_loss=0.3071  test_loss=2.5676  λ_max=38.2495\n",
      "[SGD | lr=0.05] Epoch 603/4000: train_loss=0.3093  test_loss=2.5657  λ_max=37.0626\n",
      "[SGD | lr=0.05] Epoch 604/4000: train_loss=0.3153  test_loss=2.5813  λ_max=38.7797\n",
      "[SGD | lr=0.05] Epoch 605/4000: train_loss=0.3172  test_loss=2.5730  λ_max=41.4064\n",
      "[SGD | lr=0.05] Epoch 606/4000: train_loss=0.3120  test_loss=2.5678  λ_max=37.4472\n",
      "[SGD | lr=0.05] Iter 9700: loss=0.3111\n",
      "[SGD | lr=0.05] Epoch 607/4000: train_loss=0.3104  test_loss=2.5664  λ_max=38.0446\n",
      "[SGD | lr=0.05] Epoch 608/4000: train_loss=0.3104  test_loss=2.5735  λ_max=39.3333\n",
      "[SGD | lr=0.05] Epoch 609/4000: train_loss=0.3071  test_loss=2.5796  λ_max=38.7586\n",
      "[SGD | lr=0.05] Epoch 610/4000: train_loss=0.3172  test_loss=2.5825  λ_max=38.7464\n",
      "[SGD | lr=0.05] Epoch 611/4000: train_loss=0.3020  test_loss=2.5766  λ_max=39.1611\n",
      "[SGD | lr=0.05] Epoch 612/4000: train_loss=0.3010  test_loss=2.5770  λ_max=37.4607\n",
      "[SGD | lr=0.05] Iter 9800: loss=0.2994\n",
      "[SGD | lr=0.05] Epoch 613/4000: train_loss=0.3009  test_loss=2.5851  λ_max=37.5313\n",
      "[SGD | lr=0.05] Epoch 614/4000: train_loss=0.3076  test_loss=2.5904  λ_max=40.1119\n",
      "[SGD | lr=0.05] Epoch 615/4000: train_loss=0.3034  test_loss=2.5842  λ_max=37.2432\n",
      "[SGD | lr=0.05] Epoch 616/4000: train_loss=0.2906  test_loss=2.5904  λ_max=39.2086\n",
      "[SGD | lr=0.05] Epoch 617/4000: train_loss=0.3001  test_loss=2.5967  λ_max=40.3996\n",
      "[SGD | lr=0.05] Epoch 618/4000: train_loss=0.3014  test_loss=2.5857  λ_max=38.8999\n",
      "[SGD | lr=0.05] Iter 9900: loss=0.2946\n",
      "[SGD | lr=0.05] Epoch 619/4000: train_loss=0.2991  test_loss=2.5944  λ_max=38.1190\n",
      "[SGD | lr=0.05] Epoch 620/4000: train_loss=0.3030  test_loss=2.5879  λ_max=38.1038\n",
      "[SGD | lr=0.05] Epoch 621/4000: train_loss=0.2922  test_loss=2.5918  λ_max=38.9182\n",
      "[SGD | lr=0.05] Epoch 622/4000: train_loss=0.2984  test_loss=2.5984  λ_max=39.5118\n",
      "[SGD | lr=0.05] Epoch 623/4000: train_loss=0.2954  test_loss=2.5957  λ_max=40.3087\n",
      "[SGD | lr=0.05] Epoch 624/4000: train_loss=0.2867  test_loss=2.5985  λ_max=36.9035\n",
      "[SGD | lr=0.05] Iter 10000: loss=0.2779\n",
      "[SGD | lr=0.05] Epoch 625/4000: train_loss=0.2800  test_loss=2.5985  λ_max=37.6637\n",
      "[SGD | lr=0.05] Epoch 626/4000: train_loss=0.2906  test_loss=2.6070  λ_max=38.6553\n",
      "[SGD | lr=0.05] Epoch 627/4000: train_loss=0.2889  test_loss=2.6025  λ_max=38.4919\n",
      "[SGD | lr=0.05] Epoch 628/4000: train_loss=0.2852  test_loss=2.6022  λ_max=38.2365\n",
      "[SGD | lr=0.05] Epoch 629/4000: train_loss=0.2821  test_loss=2.6077  λ_max=38.8740\n",
      "[SGD | lr=0.05] Epoch 630/4000: train_loss=0.2811  test_loss=2.6099  λ_max=39.2797\n",
      "[SGD | lr=0.05] Epoch 631/4000: train_loss=0.2920  test_loss=2.6036  λ_max=39.6744\n",
      "[SGD | lr=0.05] Iter 10100: loss=0.2912\n",
      "[SGD | lr=0.05] Epoch 632/4000: train_loss=0.2881  test_loss=2.6143  λ_max=38.8985\n",
      "[SGD | lr=0.05] Epoch 633/4000: train_loss=0.2915  test_loss=2.6163  λ_max=39.2849\n",
      "[SGD | lr=0.05] Epoch 634/4000: train_loss=0.2813  test_loss=2.6116  λ_max=38.5318\n",
      "[SGD | lr=0.05] Epoch 635/4000: train_loss=0.2739  test_loss=2.6140  λ_max=39.5272\n",
      "[SGD | lr=0.05] Epoch 636/4000: train_loss=0.2704  test_loss=2.6184  λ_max=39.6876\n",
      "[SGD | lr=0.05] Epoch 637/4000: train_loss=0.2716  test_loss=2.6157  λ_max=38.1023\n",
      "[SGD | lr=0.05] Iter 10200: loss=0.2684\n",
      "[SGD | lr=0.05] Epoch 638/4000: train_loss=0.2671  test_loss=2.6139  λ_max=39.0189\n",
      "[SGD | lr=0.05] Epoch 639/4000: train_loss=0.2726  test_loss=2.6183  λ_max=39.1430\n",
      "[SGD | lr=0.05] Epoch 640/4000: train_loss=0.2874  test_loss=2.6231  λ_max=39.7405\n",
      "[SGD | lr=0.05] Epoch 641/4000: train_loss=0.2843  test_loss=2.6246  λ_max=40.6309\n",
      "[SGD | lr=0.05] Epoch 642/4000: train_loss=0.2822  test_loss=2.6230  λ_max=40.0883\n",
      "[SGD | lr=0.05] Epoch 643/4000: train_loss=0.2740  test_loss=2.6224  λ_max=37.1522\n",
      "[SGD | lr=0.05] Iter 10300: loss=0.2712\n",
      "[SGD | lr=0.05] Epoch 644/4000: train_loss=0.2717  test_loss=2.6284  λ_max=38.8065\n",
      "[SGD | lr=0.05] Epoch 645/4000: train_loss=0.2754  test_loss=2.6384  λ_max=39.4271\n",
      "[SGD | lr=0.05] Epoch 646/4000: train_loss=0.2737  test_loss=2.6271  λ_max=40.0719\n",
      "[SGD | lr=0.05] Epoch 647/4000: train_loss=0.2627  test_loss=2.6315  λ_max=38.3518\n",
      "[SGD | lr=0.05] Epoch 648/4000: train_loss=0.2697  test_loss=2.6338  λ_max=41.2609\n",
      "[SGD | lr=0.05] Epoch 649/4000: train_loss=0.2622  test_loss=2.6293  λ_max=40.1519\n",
      "[SGD | lr=0.05] Iter 10400: loss=0.2584\n",
      "[SGD | lr=0.05] Epoch 650/4000: train_loss=0.2578  test_loss=2.6348  λ_max=40.0611\n",
      "[SGD | lr=0.05] Epoch 651/4000: train_loss=0.2593  test_loss=2.6381  λ_max=39.8634\n",
      "[SGD | lr=0.05] Epoch 652/4000: train_loss=0.2568  test_loss=2.6393  λ_max=39.3657\n",
      "[SGD | lr=0.05] Epoch 653/4000: train_loss=0.2623  test_loss=2.6453  λ_max=39.9420\n",
      "[SGD | lr=0.05] Epoch 654/4000: train_loss=0.2762  test_loss=2.6436  λ_max=40.5677\n",
      "[SGD | lr=0.05] Epoch 655/4000: train_loss=0.2641  test_loss=2.6451  λ_max=40.9109\n",
      "[SGD | lr=0.05] Epoch 656/4000: train_loss=0.2694  test_loss=2.6389  λ_max=39.1809\n",
      "[SGD | lr=0.05] Iter 10500: loss=0.2565\n",
      "[SGD | lr=0.05] Epoch 657/4000: train_loss=0.2513  test_loss=2.6420  λ_max=39.9380\n",
      "[SGD | lr=0.05] Epoch 658/4000: train_loss=0.2492  test_loss=2.6452  λ_max=38.1420\n",
      "[SGD | lr=0.05] Epoch 659/4000: train_loss=0.2542  test_loss=2.6503  λ_max=39.7841\n",
      "[SGD | lr=0.05] Epoch 660/4000: train_loss=0.2585  test_loss=2.6521  λ_max=39.9506\n",
      "[SGD | lr=0.05] Epoch 661/4000: train_loss=0.2599  test_loss=2.6561  λ_max=41.1430\n",
      "[SGD | lr=0.05] Epoch 662/4000: train_loss=0.2557  test_loss=2.6495  λ_max=41.2846\n",
      "[SGD | lr=0.05] Iter 10600: loss=0.2540\n",
      "[SGD | lr=0.05] Epoch 663/4000: train_loss=0.2491  test_loss=2.6509  λ_max=39.9911\n",
      "[SGD | lr=0.05] Epoch 664/4000: train_loss=0.2456  test_loss=2.6543  λ_max=39.9110\n",
      "[SGD | lr=0.05] Epoch 665/4000: train_loss=0.2474  test_loss=2.6581  λ_max=40.7913\n",
      "[SGD | lr=0.05] Epoch 666/4000: train_loss=0.2519  test_loss=2.6653  λ_max=42.0951\n",
      "[SGD | lr=0.05] Epoch 667/4000: train_loss=0.2635  test_loss=2.6720  λ_max=41.7842\n",
      "[SGD | lr=0.05] Epoch 668/4000: train_loss=0.2522  test_loss=2.6611  λ_max=39.6718\n",
      "[SGD | lr=0.05] Iter 10700: loss=0.2378\n",
      "[SGD | lr=0.05] Epoch 669/4000: train_loss=0.2430  test_loss=2.6622  λ_max=40.7494\n",
      "[SGD | lr=0.05] Epoch 670/4000: train_loss=0.2483  test_loss=2.6699  λ_max=40.9673\n",
      "[SGD | lr=0.05] Epoch 671/4000: train_loss=0.2494  test_loss=2.6695  λ_max=42.0247\n",
      "[SGD | lr=0.05] Epoch 672/4000: train_loss=0.2472  test_loss=2.6721  λ_max=40.8127\n",
      "[SGD | lr=0.05] Epoch 673/4000: train_loss=0.2448  test_loss=2.6644  λ_max=42.7494\n",
      "[SGD | lr=0.05] Epoch 674/4000: train_loss=0.2458  test_loss=2.6701  λ_max=40.7898\n",
      "[SGD | lr=0.05] Iter 10800: loss=0.2398\n",
      "[SGD | lr=0.05] Epoch 675/4000: train_loss=0.2435  test_loss=2.6710  λ_max=41.4120\n",
      "[SGD | lr=0.05] Epoch 676/4000: train_loss=0.2421  test_loss=2.6732  λ_max=40.3113\n",
      "[SGD | lr=0.05] Epoch 677/4000: train_loss=0.2395  test_loss=2.6748  λ_max=39.9892\n",
      "[SGD | lr=0.05] Epoch 678/4000: train_loss=0.2445  test_loss=2.6779  λ_max=38.9364\n",
      "[SGD | lr=0.05] Epoch 679/4000: train_loss=0.2381  test_loss=2.6827  λ_max=41.5856\n",
      "[SGD | lr=0.05] Epoch 680/4000: train_loss=0.2406  test_loss=2.6791  λ_max=39.9770\n",
      "[SGD | lr=0.05] Epoch 681/4000: train_loss=0.2380  test_loss=2.6783  λ_max=41.2429\n",
      "[SGD | lr=0.05] Iter 10900: loss=0.2379\n",
      "[SGD | lr=0.05] Epoch 682/4000: train_loss=0.2375  test_loss=2.6793  λ_max=41.9644\n",
      "[SGD | lr=0.05] Epoch 683/4000: train_loss=0.2332  test_loss=2.6867  λ_max=40.9214\n",
      "[SGD | lr=0.05] Epoch 684/4000: train_loss=0.2333  test_loss=2.6843  λ_max=41.8243\n",
      "[SGD | lr=0.05] Epoch 685/4000: train_loss=0.2409  test_loss=2.6851  λ_max=41.3271\n",
      "[SGD | lr=0.05] Epoch 686/4000: train_loss=0.2409  test_loss=2.6830  λ_max=41.1094\n",
      "[SGD | lr=0.05] Epoch 687/4000: train_loss=0.2289  test_loss=2.6817  λ_max=40.8324\n",
      "[SGD | lr=0.05] Iter 11000: loss=0.2303\n",
      "[SGD | lr=0.05] Epoch 688/4000: train_loss=0.2284  test_loss=2.6871  λ_max=39.7971\n",
      "[SGD | lr=0.05] Epoch 689/4000: train_loss=0.2283  test_loss=2.6902  λ_max=41.8373\n",
      "[SGD | lr=0.05] Epoch 690/4000: train_loss=0.2258  test_loss=2.6894  λ_max=40.8690\n",
      "[SGD | lr=0.05] Epoch 691/4000: train_loss=0.2279  test_loss=2.6905  λ_max=41.2147\n",
      "[SGD | lr=0.05] Epoch 692/4000: train_loss=0.2266  test_loss=2.6940  λ_max=41.3567\n",
      "[SGD | lr=0.05] Epoch 693/4000: train_loss=0.2290  test_loss=2.6983  λ_max=42.3274\n",
      "[SGD | lr=0.05] Iter 11100: loss=0.2366\n",
      "[SGD | lr=0.05] Epoch 694/4000: train_loss=0.2350  test_loss=2.7068  λ_max=42.3290\n",
      "[SGD | lr=0.05] Epoch 695/4000: train_loss=0.2348  test_loss=2.7026  λ_max=41.7622\n",
      "[SGD | lr=0.05] Epoch 696/4000: train_loss=0.2219  test_loss=2.7010  λ_max=40.5989\n",
      "[SGD | lr=0.05] Epoch 697/4000: train_loss=0.2195  test_loss=2.6993  λ_max=41.3243\n",
      "[SGD | lr=0.05] Epoch 698/4000: train_loss=0.2171  test_loss=2.7022  λ_max=40.9970\n",
      "[SGD | lr=0.05] Epoch 699/4000: train_loss=0.2161  test_loss=2.7048  λ_max=41.1718\n",
      "[SGD | lr=0.05] Iter 11200: loss=0.2276\n",
      "[SGD | lr=0.05] Epoch 700/4000: train_loss=0.2204  test_loss=2.7093  λ_max=41.9143\n",
      "[SGD | lr=0.05] Epoch 701/4000: train_loss=0.2386  test_loss=2.7183  λ_max=41.4894\n",
      "[SGD | lr=0.05] Epoch 702/4000: train_loss=0.2219  test_loss=2.7138  λ_max=42.6373\n",
      "[SGD | lr=0.05] Epoch 703/4000: train_loss=0.2336  test_loss=2.7215  λ_max=42.7072\n",
      "[SGD | lr=0.05] Epoch 704/4000: train_loss=0.2362  test_loss=2.7232  λ_max=41.9478\n",
      "[SGD | lr=0.05] Epoch 705/4000: train_loss=0.2290  test_loss=2.7215  λ_max=43.5097\n",
      "[SGD | lr=0.05] Epoch 706/4000: train_loss=0.2232  test_loss=2.7182  λ_max=42.2793\n",
      "[SGD | lr=0.05] Iter 11300: loss=0.2182\n",
      "[SGD | lr=0.05] Epoch 707/4000: train_loss=0.2174  test_loss=2.7158  λ_max=42.8293\n",
      "[SGD | lr=0.05] Epoch 708/4000: train_loss=0.2157  test_loss=2.7134  λ_max=42.6478\n",
      "[SGD | lr=0.05] Epoch 709/4000: train_loss=0.2134  test_loss=2.7176  λ_max=42.0877\n",
      "[SGD | lr=0.05] Epoch 710/4000: train_loss=0.2109  test_loss=2.7209  λ_max=41.9467\n",
      "[SGD | lr=0.05] Epoch 711/4000: train_loss=0.2104  test_loss=2.7234  λ_max=41.9553\n",
      "[SGD | lr=0.05] Epoch 712/4000: train_loss=0.2086  test_loss=2.7222  λ_max=42.3660\n",
      "[SGD | lr=0.05] Iter 11400: loss=0.2091\n",
      "[SGD | lr=0.05] Epoch 713/4000: train_loss=0.2087  test_loss=2.7240  λ_max=42.8929\n",
      "[SGD | lr=0.05] Epoch 714/4000: train_loss=0.2098  test_loss=2.7280  λ_max=42.5420\n",
      "[SGD | lr=0.05] Epoch 715/4000: train_loss=0.2138  test_loss=2.7352  λ_max=44.2254\n",
      "[SGD | lr=0.05] Epoch 716/4000: train_loss=0.2255  test_loss=2.7346  λ_max=41.6113\n",
      "[SGD | lr=0.05] Epoch 717/4000: train_loss=0.2155  test_loss=2.7387  λ_max=41.7603\n",
      "[SGD | lr=0.05] Epoch 718/4000: train_loss=0.2138  test_loss=2.7334  λ_max=43.2831\n",
      "[SGD | lr=0.05] Iter 11500: loss=0.2029\n",
      "[SGD | lr=0.05] Epoch 719/4000: train_loss=0.2091  test_loss=2.7326  λ_max=42.5639\n",
      "[SGD | lr=0.05] Epoch 720/4000: train_loss=0.2061  test_loss=2.7345  λ_max=42.7326\n",
      "[SGD | lr=0.05] Epoch 721/4000: train_loss=0.2121  test_loss=2.7419  λ_max=41.1992\n",
      "[SGD | lr=0.05] Epoch 722/4000: train_loss=0.2111  test_loss=2.7398  λ_max=43.9646\n",
      "[SGD | lr=0.05] Epoch 723/4000: train_loss=0.2094  test_loss=2.7403  λ_max=42.8581\n",
      "[SGD | lr=0.05] Epoch 724/4000: train_loss=0.2059  test_loss=2.7460  λ_max=43.2451\n",
      "[SGD | lr=0.05] Iter 11600: loss=0.2022\n",
      "[SGD | lr=0.05] Epoch 725/4000: train_loss=0.2025  test_loss=2.7469  λ_max=42.0457\n",
      "[SGD | lr=0.05] Epoch 726/4000: train_loss=0.2049  test_loss=2.7430  λ_max=43.0788\n",
      "[SGD | lr=0.05] Epoch 727/4000: train_loss=0.2104  test_loss=2.7572  λ_max=43.3706\n",
      "[SGD | lr=0.05] Epoch 728/4000: train_loss=0.2209  test_loss=2.7510  λ_max=43.3850\n",
      "[SGD | lr=0.05] Epoch 729/4000: train_loss=0.2165  test_loss=2.7529  λ_max=42.9706\n",
      "[SGD | lr=0.05] Epoch 730/4000: train_loss=0.2080  test_loss=2.7526  λ_max=43.6876\n",
      "[SGD | lr=0.05] Epoch 731/4000: train_loss=0.2023  test_loss=2.7502  λ_max=44.0953\n",
      "[SGD | lr=0.05] Iter 11700: loss=0.1942\n",
      "[SGD | lr=0.05] Epoch 732/4000: train_loss=0.1963  test_loss=2.7496  λ_max=41.2152\n",
      "[SGD | lr=0.05] Epoch 733/4000: train_loss=0.1951  test_loss=2.7513  λ_max=42.8700\n",
      "[SGD | lr=0.05] Epoch 734/4000: train_loss=0.1936  test_loss=2.7509  λ_max=42.4923\n",
      "[SGD | lr=0.05] Epoch 735/4000: train_loss=0.1926  test_loss=2.7542  λ_max=41.8687\n",
      "[SGD | lr=0.05] Epoch 736/4000: train_loss=0.1931  test_loss=2.7554  λ_max=42.6133\n",
      "[SGD | lr=0.05] Epoch 737/4000: train_loss=0.1922  test_loss=2.7557  λ_max=41.5255\n",
      "[SGD | lr=0.05] Iter 11800: loss=0.1921\n",
      "[SGD | lr=0.05] Epoch 738/4000: train_loss=0.1927  test_loss=2.7593  λ_max=42.8064\n",
      "[SGD | lr=0.05] Epoch 739/4000: train_loss=0.1967  test_loss=2.7659  λ_max=43.8451\n",
      "[SGD | lr=0.05] Epoch 740/4000: train_loss=0.2039  test_loss=2.7665  λ_max=44.6054\n",
      "[SGD | lr=0.05] Epoch 741/4000: train_loss=0.2024  test_loss=2.7660  λ_max=42.6980\n",
      "[SGD | lr=0.05] Epoch 742/4000: train_loss=0.2038  test_loss=2.7679  λ_max=42.3664\n",
      "[SGD | lr=0.05] Epoch 743/4000: train_loss=0.1979  test_loss=2.7660  λ_max=42.4431\n",
      "[SGD | lr=0.05] Iter 11900: loss=0.1909\n",
      "[SGD | lr=0.05] Epoch 744/4000: train_loss=0.1917  test_loss=2.7649  λ_max=42.9806\n",
      "[SGD | lr=0.05] Epoch 745/4000: train_loss=0.1886  test_loss=2.7692  λ_max=43.7962\n",
      "[SGD | lr=0.05] Epoch 746/4000: train_loss=0.1878  test_loss=2.7708  λ_max=42.7822\n",
      "[SGD | lr=0.05] Epoch 747/4000: train_loss=0.1872  test_loss=2.7737  λ_max=43.8155\n",
      "[SGD | lr=0.05] Epoch 748/4000: train_loss=0.1879  test_loss=2.7745  λ_max=44.4971\n",
      "[SGD | lr=0.05] Epoch 749/4000: train_loss=0.1872  test_loss=2.7745  λ_max=43.9259\n",
      "[SGD | lr=0.05] Iter 12000: loss=0.1804\n",
      "[SGD | lr=0.05] Epoch 750/4000: train_loss=0.1871  test_loss=2.7745  λ_max=44.2266\n",
      "[SGD | lr=0.05] Epoch 751/4000: train_loss=0.1906  test_loss=2.7784  λ_max=45.3643\n",
      "[SGD | lr=0.05] Epoch 752/4000: train_loss=0.2051  test_loss=2.7828  λ_max=44.2117\n",
      "[SGD | lr=0.05] Epoch 753/4000: train_loss=0.2064  test_loss=2.7859  λ_max=44.0977\n",
      "[SGD | lr=0.05] Epoch 754/4000: train_loss=0.1997  test_loss=2.7830  λ_max=43.7437\n",
      "[SGD | lr=0.05] Epoch 755/4000: train_loss=0.1881  test_loss=2.7820  λ_max=43.7699\n",
      "[SGD | lr=0.05] Epoch 756/4000: train_loss=0.1831  test_loss=2.7840  λ_max=44.4749\n",
      "[SGD | lr=0.05] Iter 12100: loss=0.1783\n",
      "[SGD | lr=0.05] Epoch 757/4000: train_loss=0.1812  test_loss=2.7863  λ_max=43.2187\n",
      "[SGD | lr=0.05] Epoch 758/4000: train_loss=0.1809  test_loss=2.7847  λ_max=42.9383\n",
      "[SGD | lr=0.05] Epoch 759/4000: train_loss=0.1807  test_loss=2.7870  λ_max=44.1155\n",
      "[SGD | lr=0.05] Epoch 760/4000: train_loss=0.1797  test_loss=2.7899  λ_max=43.8429\n",
      "[SGD | lr=0.05] Epoch 761/4000: train_loss=0.1808  test_loss=2.7907  λ_max=44.1613\n",
      "[SGD | lr=0.05] Epoch 762/4000: train_loss=0.1823  test_loss=2.7927  λ_max=44.2716\n",
      "[SGD | lr=0.05] Iter 12200: loss=0.1851\n",
      "[SGD | lr=0.05] Epoch 763/4000: train_loss=0.1839  test_loss=2.7934  λ_max=45.2316\n",
      "[SGD | lr=0.05] Epoch 764/4000: train_loss=0.1871  test_loss=2.8019  λ_max=44.4270\n",
      "[SGD | lr=0.05] Epoch 765/4000: train_loss=0.1910  test_loss=2.8033  λ_max=43.1526\n",
      "[SGD | lr=0.05] Epoch 766/4000: train_loss=0.1839  test_loss=2.8015  λ_max=42.3126\n",
      "[SGD | lr=0.05] Epoch 767/4000: train_loss=0.1779  test_loss=2.8018  λ_max=43.5984\n",
      "[SGD | lr=0.05] Epoch 768/4000: train_loss=0.1763  test_loss=2.7996  λ_max=43.3444\n",
      "[SGD | lr=0.05] Iter 12300: loss=0.1741\n",
      "[SGD | lr=0.05] Epoch 769/4000: train_loss=0.1753  test_loss=2.8009  λ_max=43.1774\n",
      "[SGD | lr=0.05] Epoch 770/4000: train_loss=0.1758  test_loss=2.8034  λ_max=43.4091\n",
      "[SGD | lr=0.05] Epoch 771/4000: train_loss=0.1758  test_loss=2.8034  λ_max=44.8679\n",
      "[SGD | lr=0.05] Epoch 772/4000: train_loss=0.1771  test_loss=2.8067  λ_max=44.6623\n",
      "[SGD | lr=0.05] Epoch 773/4000: train_loss=0.1791  test_loss=2.8124  λ_max=45.3844\n",
      "[SGD | lr=0.05] Epoch 774/4000: train_loss=0.1772  test_loss=2.8123  λ_max=45.5013\n",
      "[SGD | lr=0.05] Iter 12400: loss=0.1719\n",
      "[SGD | lr=0.05] Epoch 775/4000: train_loss=0.1742  test_loss=2.8138  λ_max=44.5674\n",
      "[SGD | lr=0.05] Epoch 776/4000: train_loss=0.1746  test_loss=2.8141  λ_max=45.8928\n",
      "[SGD | lr=0.05] Epoch 777/4000: train_loss=0.1740  test_loss=2.8189  λ_max=45.1188\n",
      "[SGD | lr=0.05] Epoch 778/4000: train_loss=0.1768  test_loss=2.8227  λ_max=45.6258\n",
      "[SGD | lr=0.05] Epoch 779/4000: train_loss=0.1807  test_loss=2.8270  λ_max=44.3594\n",
      "[SGD | lr=0.05] Epoch 780/4000: train_loss=0.1792  test_loss=2.8218  λ_max=45.3153\n",
      "[SGD | lr=0.05] Epoch 781/4000: train_loss=0.1770  test_loss=2.8238  λ_max=47.3900\n",
      "[SGD | lr=0.05] Iter 12500: loss=0.1753\n",
      "[SGD | lr=0.05] Epoch 782/4000: train_loss=0.1747  test_loss=2.8217  λ_max=43.4191\n",
      "[SGD | lr=0.05] Epoch 783/4000: train_loss=0.1702  test_loss=2.8208  λ_max=46.0559\n",
      "[SGD | lr=0.05] Epoch 784/4000: train_loss=0.1690  test_loss=2.8227  λ_max=46.0914\n",
      "[SGD | lr=0.05] Epoch 785/4000: train_loss=0.1684  test_loss=2.8234  λ_max=44.5814\n",
      "[SGD | lr=0.05] Epoch 786/4000: train_loss=0.1697  test_loss=2.8226  λ_max=45.3347\n",
      "[SGD | lr=0.05] Epoch 787/4000: train_loss=0.1705  test_loss=2.8303  λ_max=44.8224\n",
      "[SGD | lr=0.05] Iter 12600: loss=0.1722\n",
      "[SGD | lr=0.05] Epoch 788/4000: train_loss=0.1699  test_loss=2.8309  λ_max=44.9558\n",
      "[SGD | lr=0.05] Epoch 789/4000: train_loss=0.1698  test_loss=2.8360  λ_max=44.5702\n",
      "[SGD | lr=0.05] Epoch 790/4000: train_loss=0.1718  test_loss=2.8358  λ_max=46.3225\n",
      "[SGD | lr=0.05] Epoch 791/4000: train_loss=0.1721  test_loss=2.8323  λ_max=45.6468\n",
      "[SGD | lr=0.05] Epoch 792/4000: train_loss=0.1717  test_loss=2.8301  λ_max=44.4578\n",
      "[SGD | lr=0.05] Epoch 793/4000: train_loss=0.1663  test_loss=2.8358  λ_max=44.9917\n",
      "[SGD | lr=0.05] Iter 12700: loss=0.1656\n",
      "[SGD | lr=0.05] Epoch 794/4000: train_loss=0.1635  test_loss=2.8349  λ_max=45.1564\n",
      "[SGD | lr=0.05] Epoch 795/4000: train_loss=0.1632  test_loss=2.8361  λ_max=46.4917\n",
      "[SGD | lr=0.05] Epoch 796/4000: train_loss=0.1623  test_loss=2.8370  λ_max=45.4327\n",
      "[SGD | lr=0.05] Epoch 797/4000: train_loss=0.1614  test_loss=2.8393  λ_max=46.1661\n",
      "[SGD | lr=0.05] Epoch 798/4000: train_loss=0.1615  test_loss=2.8406  λ_max=46.4380\n",
      "[SGD | lr=0.05] Epoch 799/4000: train_loss=0.1629  test_loss=2.8452  λ_max=46.3328\n",
      "[SGD | lr=0.05] Iter 12800: loss=0.1666\n",
      "[SGD | lr=0.05] Epoch 800/4000: train_loss=0.1644  test_loss=2.8469  λ_max=44.9987\n",
      "[SGD | lr=0.05] Epoch 801/4000: train_loss=0.1622  test_loss=2.8473  λ_max=46.2044\n",
      "[SGD | lr=0.05] Epoch 802/4000: train_loss=0.1613  test_loss=2.8480  λ_max=45.3145\n",
      "[SGD | lr=0.05] Epoch 803/4000: train_loss=0.1610  test_loss=2.8492  λ_max=45.1818\n",
      "[SGD | lr=0.05] Epoch 804/4000: train_loss=0.1617  test_loss=2.8522  λ_max=46.0267\n",
      "[SGD | lr=0.05] Epoch 805/4000: train_loss=0.1639  test_loss=2.8580  λ_max=46.4902\n",
      "[SGD | lr=0.05] Epoch 806/4000: train_loss=0.1633  test_loss=2.8582  λ_max=46.0814\n",
      "[SGD | lr=0.05] Iter 12900: loss=0.1565\n",
      "[SGD | lr=0.05] Epoch 807/4000: train_loss=0.1603  test_loss=2.8576  λ_max=46.6917\n",
      "[SGD | lr=0.05] Epoch 808/4000: train_loss=0.1593  test_loss=2.8574  λ_max=47.0528\n",
      "[SGD | lr=0.05] Epoch 809/4000: train_loss=0.1581  test_loss=2.8585  λ_max=47.2173\n",
      "[SGD | lr=0.05] Epoch 810/4000: train_loss=0.1569  test_loss=2.8589  λ_max=44.9008\n",
      "[SGD | lr=0.05] Epoch 811/4000: train_loss=0.1571  test_loss=2.8598  λ_max=45.4297\n",
      "[SGD | lr=0.05] Epoch 812/4000: train_loss=0.1573  test_loss=2.8634  λ_max=46.7807\n",
      "[SGD | lr=0.05] Iter 13000: loss=0.1601\n",
      "[SGD | lr=0.05] Epoch 813/4000: train_loss=0.1587  test_loss=2.8678  λ_max=47.9029\n",
      "[SGD | lr=0.05] Epoch 814/4000: train_loss=0.1595  test_loss=2.8662  λ_max=45.9973\n",
      "[SGD | lr=0.05] Epoch 815/4000: train_loss=0.1566  test_loss=2.8692  λ_max=47.0294\n",
      "[SGD | lr=0.05] Epoch 816/4000: train_loss=0.1569  test_loss=2.8696  λ_max=46.9102\n",
      "[SGD | lr=0.05] Epoch 817/4000: train_loss=0.1571  test_loss=2.8698  λ_max=44.9132\n",
      "[SGD | lr=0.05] Epoch 818/4000: train_loss=0.1555  test_loss=2.8699  λ_max=46.3263\n",
      "[SGD | lr=0.05] Iter 13100: loss=0.1518\n",
      "[SGD | lr=0.05] Epoch 819/4000: train_loss=0.1537  test_loss=2.8713  λ_max=46.6911\n",
      "[SGD | lr=0.05] Epoch 820/4000: train_loss=0.1531  test_loss=2.8712  λ_max=45.7911\n",
      "[SGD | lr=0.05] Epoch 821/4000: train_loss=0.1535  test_loss=2.8747  λ_max=47.7620\n",
      "[SGD | lr=0.05] Epoch 822/4000: train_loss=0.1542  test_loss=2.8717  λ_max=47.8326\n",
      "[SGD | lr=0.05] Epoch 823/4000: train_loss=0.1557  test_loss=2.8740  λ_max=46.1805\n",
      "[SGD | lr=0.05] Epoch 824/4000: train_loss=0.1529  test_loss=2.8743  λ_max=46.0428\n",
      "[SGD | lr=0.05] Iter 13200: loss=0.1484\n",
      "[SGD | lr=0.05] Epoch 825/4000: train_loss=0.1520  test_loss=2.8797  λ_max=47.8521\n",
      "[SGD | lr=0.05] Epoch 826/4000: train_loss=0.1522  test_loss=2.8815  λ_max=46.6174\n",
      "[SGD | lr=0.05] Epoch 827/4000: train_loss=0.1504  test_loss=2.8798  λ_max=46.7319\n",
      "[SGD | lr=0.05] Epoch 828/4000: train_loss=0.1492  test_loss=2.8803  λ_max=46.4800\n",
      "[SGD | lr=0.05] Epoch 829/4000: train_loss=0.1490  test_loss=2.8818  λ_max=46.0931\n",
      "[SGD | lr=0.05] Epoch 830/4000: train_loss=0.1487  test_loss=2.8839  λ_max=45.1081\n",
      "[SGD | lr=0.05] Epoch 831/4000: train_loss=0.1484  test_loss=2.8836  λ_max=46.1171\n",
      "[SGD | lr=0.05] Iter 13300: loss=0.1485\n",
      "[SGD | lr=0.05] Epoch 832/4000: train_loss=0.1479  test_loss=2.8840  λ_max=46.9775\n",
      "[SGD | lr=0.05] Epoch 833/4000: train_loss=0.1487  test_loss=2.8885  λ_max=46.8247\n",
      "[SGD | lr=0.05] Epoch 834/4000: train_loss=0.1497  test_loss=2.8885  λ_max=47.7084\n",
      "[SGD | lr=0.05] Epoch 835/4000: train_loss=0.1505  test_loss=2.8899  λ_max=47.6265\n",
      "[SGD | lr=0.05] Epoch 836/4000: train_loss=0.1480  test_loss=2.8907  λ_max=47.6293\n",
      "[SGD | lr=0.05] Epoch 837/4000: train_loss=0.1466  test_loss=2.8917  λ_max=48.2996\n",
      "[SGD | lr=0.05] Iter 13400: loss=0.1476\n",
      "[SGD | lr=0.05] Epoch 838/4000: train_loss=0.1466  test_loss=2.8938  λ_max=47.8342\n",
      "[SGD | lr=0.05] Epoch 839/4000: train_loss=0.1487  test_loss=2.8963  λ_max=46.4835\n",
      "[SGD | lr=0.05] Epoch 840/4000: train_loss=0.1492  test_loss=2.8988  λ_max=46.8726\n",
      "[SGD | lr=0.05] Epoch 841/4000: train_loss=0.1463  test_loss=2.8978  λ_max=46.5235\n",
      "[SGD | lr=0.05] Epoch 842/4000: train_loss=0.1440  test_loss=2.8975  λ_max=47.8315\n",
      "[SGD | lr=0.05] Epoch 843/4000: train_loss=0.1438  test_loss=2.9010  λ_max=46.2980\n",
      "[SGD | lr=0.05] Iter 13500: loss=0.1442\n",
      "[SGD | lr=0.05] Epoch 844/4000: train_loss=0.1443  test_loss=2.9008  λ_max=48.1418\n",
      "[SGD | lr=0.05] Epoch 845/4000: train_loss=0.1449  test_loss=2.9023  λ_max=47.4886\n",
      "[SGD | lr=0.05] Epoch 846/4000: train_loss=0.1473  test_loss=2.9034  λ_max=47.4968\n",
      "[SGD | lr=0.05] Epoch 847/4000: train_loss=0.1468  test_loss=2.9061  λ_max=48.6590\n",
      "[SGD | lr=0.05] Epoch 848/4000: train_loss=0.1438  test_loss=2.9080  λ_max=47.7747\n",
      "[SGD | lr=0.05] Epoch 849/4000: train_loss=0.1426  test_loss=2.9083  λ_max=47.0527\n",
      "[SGD | lr=0.05] Iter 13600: loss=0.1449\n",
      "[SGD | lr=0.05] Epoch 850/4000: train_loss=0.1410  test_loss=2.9095  λ_max=47.2760\n",
      "[SGD | lr=0.05] Epoch 851/4000: train_loss=0.1406  test_loss=2.9106  λ_max=47.1537\n",
      "[SGD | lr=0.05] Epoch 852/4000: train_loss=0.1402  test_loss=2.9123  λ_max=48.0364\n",
      "[SGD | lr=0.05] Epoch 853/4000: train_loss=0.1399  test_loss=2.9116  λ_max=46.1754\n",
      "[SGD | lr=0.05] Epoch 854/4000: train_loss=0.1399  test_loss=2.9145  λ_max=47.1971\n",
      "[SGD | lr=0.05] Epoch 855/4000: train_loss=0.1399  test_loss=2.9167  λ_max=48.3197\n",
      "[SGD | lr=0.05] Epoch 856/4000: train_loss=0.1410  test_loss=2.9193  λ_max=46.5430\n",
      "[SGD | lr=0.05] Iter 13700: loss=0.1401\n",
      "[SGD | lr=0.05] Epoch 857/4000: train_loss=0.1416  test_loss=2.9217  λ_max=47.5330\n",
      "[SGD | lr=0.05] Epoch 858/4000: train_loss=0.1401  test_loss=2.9225  λ_max=47.4914\n",
      "[SGD | lr=0.05] Epoch 859/4000: train_loss=0.1397  test_loss=2.9238  λ_max=46.5714\n",
      "[SGD | lr=0.05] Epoch 860/4000: train_loss=0.1398  test_loss=2.9238  λ_max=47.4837\n",
      "[SGD | lr=0.05] Epoch 861/4000: train_loss=0.1393  test_loss=2.9221  λ_max=47.1063\n",
      "[SGD | lr=0.05] Epoch 862/4000: train_loss=0.1376  test_loss=2.9253  λ_max=48.4719\n",
      "[SGD | lr=0.05] Iter 13800: loss=0.1351\n",
      "[SGD | lr=0.05] Epoch 863/4000: train_loss=0.1372  test_loss=2.9257  λ_max=48.0362\n",
      "[SGD | lr=0.05] Epoch 864/4000: train_loss=0.1372  test_loss=2.9275  λ_max=48.7251\n",
      "[SGD | lr=0.05] Epoch 865/4000: train_loss=0.1372  test_loss=2.9287  λ_max=49.4853\n",
      "[SGD | lr=0.05] Epoch 866/4000: train_loss=0.1370  test_loss=2.9317  λ_max=49.2031\n",
      "[SGD | lr=0.05] Epoch 867/4000: train_loss=0.1364  test_loss=2.9324  λ_max=47.2957\n",
      "[SGD | lr=0.05] Epoch 868/4000: train_loss=0.1360  test_loss=2.9347  λ_max=48.8809\n",
      "[SGD | lr=0.05] Iter 13900: loss=0.1353\n",
      "[SGD | lr=0.05] Epoch 869/4000: train_loss=0.1367  test_loss=2.9347  λ_max=47.2501\n",
      "[SGD | lr=0.05] Epoch 870/4000: train_loss=0.1364  test_loss=2.9374  λ_max=47.5494\n",
      "[SGD | lr=0.05] Epoch 871/4000: train_loss=0.1359  test_loss=2.9374  λ_max=48.1645\n",
      "[SGD | lr=0.05] Epoch 872/4000: train_loss=0.1352  test_loss=2.9397  λ_max=47.8448\n",
      "[SGD | lr=0.05] Epoch 873/4000: train_loss=0.1351  test_loss=2.9411  λ_max=47.9331\n",
      "[SGD | lr=0.05] Epoch 874/4000: train_loss=0.1368  test_loss=2.9427  λ_max=48.0233\n",
      "[SGD | lr=0.05] Iter 14000: loss=0.1350\n",
      "[SGD | lr=0.05] Epoch 875/4000: train_loss=0.1345  test_loss=2.9430  λ_max=47.0789\n",
      "[SGD | lr=0.05] Epoch 876/4000: train_loss=0.1324  test_loss=2.9416  λ_max=48.7045\n",
      "[SGD | lr=0.05] Epoch 877/4000: train_loss=0.1316  test_loss=2.9423  λ_max=49.0888\n",
      "[SGD | lr=0.05] Epoch 878/4000: train_loss=0.1315  test_loss=2.9447  λ_max=49.3781\n",
      "[SGD | lr=0.05] Epoch 879/4000: train_loss=0.1313  test_loss=2.9456  λ_max=49.0049\n",
      "[SGD | lr=0.05] Epoch 880/4000: train_loss=0.1310  test_loss=2.9465  λ_max=47.8883\n",
      "[SGD | lr=0.05] Epoch 881/4000: train_loss=0.1310  test_loss=2.9482  λ_max=49.7952\n",
      "[SGD | lr=0.05] Iter 14100: loss=0.1337\n",
      "[SGD | lr=0.05] Epoch 882/4000: train_loss=0.1312  test_loss=2.9498  λ_max=48.6548\n",
      "[SGD | lr=0.05] Epoch 883/4000: train_loss=0.1317  test_loss=2.9516  λ_max=48.3010\n",
      "[SGD | lr=0.05] Epoch 884/4000: train_loss=0.1345  test_loss=2.9544  λ_max=49.0996\n",
      "[SGD | lr=0.05] Epoch 885/4000: train_loss=0.1343  test_loss=2.9558  λ_max=49.5529\n",
      "[SGD | lr=0.05] Epoch 886/4000: train_loss=0.1324  test_loss=2.9576  λ_max=49.5965\n",
      "[SGD | lr=0.05] Epoch 887/4000: train_loss=0.1317  test_loss=2.9578  λ_max=48.7794\n",
      "[SGD | lr=0.05] Iter 14200: loss=0.1314\n",
      "[SGD | lr=0.05] Epoch 888/4000: train_loss=0.1296  test_loss=2.9573  λ_max=48.3377\n",
      "[SGD | lr=0.05] Epoch 889/4000: train_loss=0.1282  test_loss=2.9573  λ_max=48.3487\n",
      "[SGD | lr=0.05] Epoch 890/4000: train_loss=0.1279  test_loss=2.9575  λ_max=48.0817\n",
      "[SGD | lr=0.05] Epoch 891/4000: train_loss=0.1276  test_loss=2.9609  λ_max=48.5715\n",
      "[SGD | lr=0.05] Epoch 892/4000: train_loss=0.1272  test_loss=2.9600  λ_max=49.6137\n",
      "[SGD | lr=0.05] Epoch 893/4000: train_loss=0.1271  test_loss=2.9623  λ_max=49.0513\n",
      "[SGD | lr=0.05] Iter 14300: loss=0.1255\n",
      "[SGD | lr=0.05] Epoch 894/4000: train_loss=0.1269  test_loss=2.9644  λ_max=49.6067\n",
      "[SGD | lr=0.05] Epoch 895/4000: train_loss=0.1266  test_loss=2.9660  λ_max=48.8916\n",
      "[SGD | lr=0.05] Epoch 896/4000: train_loss=0.1271  test_loss=2.9684  λ_max=49.8848\n",
      "[SGD | lr=0.05] Epoch 897/4000: train_loss=0.1269  test_loss=2.9694  λ_max=49.3978\n",
      "[SGD | lr=0.05] Epoch 898/4000: train_loss=0.1261  test_loss=2.9700  λ_max=48.3416\n",
      "[SGD | lr=0.05] Epoch 899/4000: train_loss=0.1261  test_loss=2.9685  λ_max=49.3010\n",
      "[SGD | lr=0.05] Iter 14400: loss=0.1261\n",
      "[SGD | lr=0.05] Epoch 900/4000: train_loss=0.1263  test_loss=2.9707  λ_max=49.6851\n",
      "[SGD | lr=0.05] Epoch 901/4000: train_loss=0.1256  test_loss=2.9710  λ_max=49.1913\n",
      "[SGD | lr=0.05] Epoch 902/4000: train_loss=0.1261  test_loss=2.9734  λ_max=49.2328\n",
      "[SGD | lr=0.05] Epoch 903/4000: train_loss=0.1263  test_loss=2.9756  λ_max=50.3691\n",
      "[SGD | lr=0.05] Epoch 904/4000: train_loss=0.1253  test_loss=2.9773  λ_max=48.2549\n",
      "[SGD | lr=0.05] Epoch 905/4000: train_loss=0.1239  test_loss=2.9769  λ_max=50.6845\n",
      "[SGD | lr=0.05] Epoch 906/4000: train_loss=0.1231  test_loss=2.9795  λ_max=50.6573\n",
      "[SGD | lr=0.05] Iter 14500: loss=0.1222\n",
      "[SGD | lr=0.05] Epoch 907/4000: train_loss=0.1231  test_loss=2.9793  λ_max=50.1736\n",
      "[SGD | lr=0.05] Epoch 908/4000: train_loss=0.1227  test_loss=2.9800  λ_max=48.5649\n",
      "[SGD | lr=0.05] Epoch 909/4000: train_loss=0.1231  test_loss=2.9817  λ_max=48.5685\n",
      "[SGD | lr=0.05] Epoch 910/4000: train_loss=0.1231  test_loss=2.9817  λ_max=49.9216\n",
      "[SGD | lr=0.05] Epoch 911/4000: train_loss=0.1222  test_loss=2.9844  λ_max=49.1959\n",
      "[SGD | lr=0.05] Epoch 912/4000: train_loss=0.1216  test_loss=2.9851  λ_max=49.6987\n",
      "[SGD | lr=0.05] Iter 14600: loss=0.1204\n",
      "[SGD | lr=0.05] Epoch 913/4000: train_loss=0.1215  test_loss=2.9869  λ_max=50.4022\n",
      "[SGD | lr=0.05] Epoch 914/4000: train_loss=0.1219  test_loss=2.9882  λ_max=49.5635\n",
      "[SGD | lr=0.05] Epoch 915/4000: train_loss=0.1223  test_loss=2.9884  λ_max=51.3082\n",
      "[SGD | lr=0.05] Epoch 916/4000: train_loss=0.1219  test_loss=2.9904  λ_max=50.5692\n",
      "[SGD | lr=0.05] Epoch 917/4000: train_loss=0.1224  test_loss=2.9935  λ_max=48.8765\n",
      "[SGD | lr=0.05] Epoch 918/4000: train_loss=0.1207  test_loss=2.9943  λ_max=50.1071\n",
      "[SGD | lr=0.05] Iter 14700: loss=0.1199\n",
      "[SGD | lr=0.05] Epoch 919/4000: train_loss=0.1198  test_loss=2.9938  λ_max=50.0362\n",
      "[SGD | lr=0.05] Epoch 920/4000: train_loss=0.1196  test_loss=2.9954  λ_max=49.7956\n",
      "[SGD | lr=0.05] Epoch 921/4000: train_loss=0.1194  test_loss=2.9978  λ_max=49.8639\n",
      "[SGD | lr=0.05] Epoch 922/4000: train_loss=0.1190  test_loss=2.9977  λ_max=51.2321\n",
      "[SGD | lr=0.05] Epoch 923/4000: train_loss=0.1192  test_loss=2.9973  λ_max=49.4732\n",
      "[SGD | lr=0.05] Epoch 924/4000: train_loss=0.1191  test_loss=2.9993  λ_max=49.3707\n",
      "[SGD | lr=0.05] Iter 14800: loss=0.1202\n",
      "[SGD | lr=0.05] Epoch 925/4000: train_loss=0.1191  test_loss=3.0016  λ_max=50.7394\n",
      "[SGD | lr=0.05] Epoch 926/4000: train_loss=0.1186  test_loss=3.0016  λ_max=49.5116\n",
      "[SGD | lr=0.05] Epoch 927/4000: train_loss=0.1180  test_loss=3.0026  λ_max=49.0135\n",
      "[SGD | lr=0.05] Epoch 928/4000: train_loss=0.1178  test_loss=3.0054  λ_max=51.2103\n",
      "[SGD | lr=0.05] Epoch 929/4000: train_loss=0.1176  test_loss=3.0059  λ_max=51.3133\n",
      "[SGD | lr=0.05] Epoch 930/4000: train_loss=0.1175  test_loss=3.0063  λ_max=50.4346\n",
      "[SGD | lr=0.05] Epoch 931/4000: train_loss=0.1169  test_loss=3.0063  λ_max=50.5095\n",
      "[SGD | lr=0.05] Iter 14900: loss=0.1163\n",
      "[SGD | lr=0.05] Epoch 932/4000: train_loss=0.1165  test_loss=3.0085  λ_max=50.4685\n",
      "[SGD | lr=0.05] Epoch 933/4000: train_loss=0.1162  test_loss=3.0098  λ_max=48.3333\n",
      "[SGD | lr=0.05] Epoch 934/4000: train_loss=0.1158  test_loss=3.0107  λ_max=50.3581\n",
      "[SGD | lr=0.05] Epoch 935/4000: train_loss=0.1159  test_loss=3.0149  λ_max=51.2069\n",
      "[SGD | lr=0.05] Epoch 936/4000: train_loss=0.1165  test_loss=3.0170  λ_max=51.6375\n",
      "[SGD | lr=0.05] Epoch 937/4000: train_loss=0.1169  test_loss=3.0179  λ_max=52.4194\n",
      "[SGD | lr=0.05] Iter 15000: loss=0.1169\n",
      "[SGD | lr=0.05] Epoch 938/4000: train_loss=0.1164  test_loss=3.0149  λ_max=50.1621\n",
      "[SGD | lr=0.05] Epoch 939/4000: train_loss=0.1147  test_loss=3.0180  λ_max=50.0514\n",
      "[SGD | lr=0.05] Epoch 940/4000: train_loss=0.1144  test_loss=3.0188  λ_max=50.1659\n",
      "[SGD | lr=0.05] Epoch 941/4000: train_loss=0.1140  test_loss=3.0185  λ_max=49.6749\n",
      "[SGD | lr=0.05] Epoch 942/4000: train_loss=0.1137  test_loss=3.0195  λ_max=50.9250\n",
      "[SGD | lr=0.05] Epoch 943/4000: train_loss=0.1138  test_loss=3.0208  λ_max=51.2469\n",
      "[SGD | lr=0.05] Iter 15100: loss=0.1147\n",
      "[SGD | lr=0.05] Epoch 944/4000: train_loss=0.1137  test_loss=3.0219  λ_max=51.9617\n",
      "[SGD | lr=0.05] Epoch 945/4000: train_loss=0.1136  test_loss=3.0237  λ_max=51.6422\n",
      "[SGD | lr=0.05] Epoch 946/4000: train_loss=0.1130  test_loss=3.0237  λ_max=50.5552\n",
      "[SGD | lr=0.05] Epoch 947/4000: train_loss=0.1125  test_loss=3.0257  λ_max=49.5576\n",
      "[SGD | lr=0.05] Epoch 948/4000: train_loss=0.1120  test_loss=3.0269  λ_max=50.6412\n",
      "[SGD | lr=0.05] Epoch 949/4000: train_loss=0.1120  test_loss=3.0294  λ_max=50.9520\n",
      "[SGD | lr=0.05] Iter 15200: loss=0.1124\n",
      "[SGD | lr=0.05] Epoch 950/4000: train_loss=0.1122  test_loss=3.0330  λ_max=52.3268\n",
      "[SGD | lr=0.05] Epoch 951/4000: train_loss=0.1124  test_loss=3.0336  λ_max=52.0041\n",
      "[SGD | lr=0.05] Epoch 952/4000: train_loss=0.1118  test_loss=3.0335  λ_max=52.5930\n",
      "[SGD | lr=0.05] Epoch 953/4000: train_loss=0.1116  test_loss=3.0339  λ_max=51.2153\n",
      "[SGD | lr=0.05] Epoch 954/4000: train_loss=0.1109  test_loss=3.0344  λ_max=51.7147\n",
      "[SGD | lr=0.05] Epoch 955/4000: train_loss=0.1106  test_loss=3.0353  λ_max=51.2433\n",
      "[SGD | lr=0.05] Epoch 956/4000: train_loss=0.1104  test_loss=3.0362  λ_max=51.1235\n",
      "[SGD | lr=0.05] Iter 15300: loss=0.1110\n",
      "[SGD | lr=0.05] Epoch 957/4000: train_loss=0.1105  test_loss=3.0374  λ_max=52.1796\n",
      "[SGD | lr=0.05] Epoch 958/4000: train_loss=0.1100  test_loss=3.0384  λ_max=50.9669\n",
      "[SGD | lr=0.05] Epoch 959/4000: train_loss=0.1096  test_loss=3.0401  λ_max=52.9338\n",
      "[SGD | lr=0.05] Epoch 960/4000: train_loss=0.1096  test_loss=3.0419  λ_max=51.2719\n",
      "[SGD | lr=0.05] Epoch 961/4000: train_loss=0.1093  test_loss=3.0421  λ_max=52.7917\n",
      "[SGD | lr=0.05] Epoch 962/4000: train_loss=0.1091  test_loss=3.0435  λ_max=52.2806\n",
      "[SGD | lr=0.05] Iter 15400: loss=0.1116\n",
      "[SGD | lr=0.05] Epoch 963/4000: train_loss=0.1090  test_loss=3.0451  λ_max=50.7868\n",
      "[SGD | lr=0.05] Epoch 964/4000: train_loss=0.1090  test_loss=3.0448  λ_max=52.3003\n",
      "[SGD | lr=0.05] Epoch 965/4000: train_loss=0.1093  test_loss=3.0448  λ_max=51.5590\n",
      "[SGD | lr=0.05] Epoch 966/4000: train_loss=0.1087  test_loss=3.0469  λ_max=52.7696\n",
      "[SGD | lr=0.05] Epoch 967/4000: train_loss=0.1080  test_loss=3.0493  λ_max=52.4378\n",
      "[SGD | lr=0.05] Epoch 968/4000: train_loss=0.1077  test_loss=3.0495  λ_max=50.8261\n",
      "[SGD | lr=0.05] Iter 15500: loss=0.1074\n",
      "[SGD | lr=0.05] Epoch 969/4000: train_loss=0.1074  test_loss=3.0503  λ_max=53.2208\n",
      "[SGD | lr=0.05] Epoch 970/4000: train_loss=0.1073  test_loss=3.0513  λ_max=51.3218\n",
      "[SGD | lr=0.05] Epoch 971/4000: train_loss=0.1070  test_loss=3.0520  λ_max=50.3499\n",
      "[SGD | lr=0.05] Epoch 972/4000: train_loss=0.1068  test_loss=3.0535  λ_max=53.3273\n",
      "[SGD | lr=0.05] Epoch 973/4000: train_loss=0.1065  test_loss=3.0543  λ_max=52.5343\n",
      "[SGD | lr=0.05] Epoch 974/4000: train_loss=0.1063  test_loss=3.0550  λ_max=50.2193\n",
      "[SGD | lr=0.05] Iter 15600: loss=0.1052\n",
      "[SGD | lr=0.05] Epoch 975/4000: train_loss=0.1061  test_loss=3.0560  λ_max=52.9971\n",
      "[SGD | lr=0.05] Epoch 976/4000: train_loss=0.1060  test_loss=3.0583  λ_max=51.9962\n",
      "[SGD | lr=0.05] Epoch 977/4000: train_loss=0.1059  test_loss=3.0595  λ_max=53.8932\n",
      "[SGD | lr=0.05] Epoch 978/4000: train_loss=0.1057  test_loss=3.0604  λ_max=52.0418\n",
      "[SGD | lr=0.05] Epoch 979/4000: train_loss=0.1053  test_loss=3.0609  λ_max=51.1480\n",
      "[SGD | lr=0.05] Epoch 980/4000: train_loss=0.1051  test_loss=3.0630  λ_max=51.3349\n",
      "[SGD | lr=0.05] Epoch 981/4000: train_loss=0.1051  test_loss=3.0639  λ_max=52.7528\n",
      "[SGD | lr=0.05] Iter 15700: loss=0.1058\n",
      "[SGD | lr=0.05] Epoch 982/4000: train_loss=0.1056  test_loss=3.0630  λ_max=51.8728\n",
      "[SGD | lr=0.05] Epoch 983/4000: train_loss=0.1053  test_loss=3.0655  λ_max=52.6309\n",
      "[SGD | lr=0.05] Epoch 984/4000: train_loss=0.1046  test_loss=3.0666  λ_max=51.9655\n",
      "[SGD | lr=0.05] Epoch 985/4000: train_loss=0.1044  test_loss=3.0679  λ_max=50.9123\n",
      "[SGD | lr=0.05] Epoch 986/4000: train_loss=0.1037  test_loss=3.0677  λ_max=52.9909\n",
      "[SGD | lr=0.05] Epoch 987/4000: train_loss=0.1034  test_loss=3.0690  λ_max=52.8695\n",
      "[SGD | lr=0.05] Iter 15800: loss=0.1057\n",
      "[SGD | lr=0.05] Epoch 988/4000: train_loss=0.1031  test_loss=3.0702  λ_max=50.4852\n",
      "[SGD | lr=0.05] Epoch 989/4000: train_loss=0.1032  test_loss=3.0722  λ_max=52.9020\n",
      "[SGD | lr=0.05] Epoch 990/4000: train_loss=0.1033  test_loss=3.0743  λ_max=53.1588\n",
      "[SGD | lr=0.05] Epoch 991/4000: train_loss=0.1029  test_loss=3.0754  λ_max=53.7254\n",
      "[SGD | lr=0.05] Epoch 992/4000: train_loss=0.1026  test_loss=3.0750  λ_max=52.5983\n",
      "[SGD | lr=0.05] Epoch 993/4000: train_loss=0.1023  test_loss=3.0760  λ_max=53.1984\n",
      "[SGD | lr=0.05] Iter 15900: loss=0.1042\n",
      "[SGD | lr=0.05] Epoch 994/4000: train_loss=0.1021  test_loss=3.0766  λ_max=53.0184\n",
      "[SGD | lr=0.05] Epoch 995/4000: train_loss=0.1020  test_loss=3.0789  λ_max=51.7431\n",
      "[SGD | lr=0.05] Epoch 996/4000: train_loss=0.1015  test_loss=3.0792  λ_max=53.1747\n",
      "[SGD | lr=0.05] Epoch 997/4000: train_loss=0.1014  test_loss=3.0809  λ_max=53.4653\n",
      "[SGD | lr=0.05] Epoch 998/4000: train_loss=0.1011  test_loss=3.0813  λ_max=50.7031\n",
      "[SGD | lr=0.05] Epoch 999/4000: train_loss=0.1016  test_loss=3.0833  λ_max=53.2071\n",
      "[SGD | lr=0.05] Iter 16000: loss=0.0999\n",
      "[SGD | lr=0.05] Epoch 1000/4000: train_loss=0.1013  test_loss=3.0836  λ_max=52.7870\n",
      "[SGD | lr=0.05] Epoch 1001/4000: train_loss=0.1010  test_loss=3.0843  λ_max=53.5545\n",
      "[SGD | lr=0.05] Epoch 1002/4000: train_loss=0.1006  test_loss=3.0849  λ_max=53.8717\n",
      "[SGD | lr=0.05] Epoch 1003/4000: train_loss=0.1003  test_loss=3.0864  λ_max=55.1187\n",
      "[SGD | lr=0.05] Epoch 1004/4000: train_loss=0.1001  test_loss=3.0879  λ_max=51.7076\n",
      "[SGD | lr=0.05] Epoch 1005/4000: train_loss=0.0998  test_loss=3.0892  λ_max=53.3331\n",
      "[SGD | lr=0.05] Epoch 1006/4000: train_loss=0.0995  test_loss=3.0897  λ_max=55.1146\n",
      "[SGD | lr=0.05] Iter 16100: loss=0.0976\n",
      "[SGD | lr=0.05] Epoch 1007/4000: train_loss=0.0993  test_loss=3.0900  λ_max=54.1954\n",
      "[SGD | lr=0.05] Epoch 1008/4000: train_loss=0.0992  test_loss=3.0913  λ_max=52.4259\n",
      "[SGD | lr=0.05] Epoch 1009/4000: train_loss=0.0991  test_loss=3.0934  λ_max=52.9912\n",
      "[SGD | lr=0.05] Epoch 1010/4000: train_loss=0.0992  test_loss=3.0949  λ_max=53.6026\n",
      "[SGD | lr=0.05] Epoch 1011/4000: train_loss=0.0991  test_loss=3.0952  λ_max=53.3425\n",
      "[SGD | lr=0.05] Epoch 1012/4000: train_loss=0.0989  test_loss=3.0954  λ_max=53.2800\n",
      "[SGD | lr=0.05] Iter 16200: loss=0.0984\n",
      "[SGD | lr=0.05] Epoch 1013/4000: train_loss=0.0983  test_loss=3.0970  λ_max=53.3458\n",
      "[SGD | lr=0.05] Epoch 1014/4000: train_loss=0.0981  test_loss=3.0987  λ_max=53.1642\n",
      "[SGD | lr=0.05] Epoch 1015/4000: train_loss=0.0979  test_loss=3.1015  λ_max=52.7526\n",
      "[SGD | lr=0.05] Epoch 1016/4000: train_loss=0.0976  test_loss=3.1016  λ_max=52.2292\n",
      "[SGD | lr=0.05] Epoch 1017/4000: train_loss=0.0974  test_loss=3.1015  λ_max=53.7258\n",
      "[SGD | lr=0.05] Epoch 1018/4000: train_loss=0.0974  test_loss=3.1035  λ_max=53.9844\n",
      "[SGD | lr=0.05] Iter 16300: loss=0.0975\n",
      "[SGD | lr=0.05] Epoch 1019/4000: train_loss=0.0973  test_loss=3.1056  λ_max=54.0024\n",
      "[SGD | lr=0.05] Epoch 1020/4000: train_loss=0.0969  test_loss=3.1049  λ_max=54.8275\n",
      "[SGD | lr=0.05] Epoch 1021/4000: train_loss=0.0967  test_loss=3.1062  λ_max=54.6474\n",
      "[SGD | lr=0.05] Epoch 1022/4000: train_loss=0.0966  test_loss=3.1078  λ_max=53.3763\n",
      "[SGD | lr=0.05] Epoch 1023/4000: train_loss=0.0965  test_loss=3.1077  λ_max=54.9053\n",
      "[SGD | lr=0.05] Epoch 1024/4000: train_loss=0.0963  test_loss=3.1101  λ_max=53.6087\n",
      "[SGD | lr=0.05] Iter 16400: loss=0.0980\n",
      "[SGD | lr=0.05] Epoch 1025/4000: train_loss=0.0960  test_loss=3.1106  λ_max=54.4903\n",
      "[SGD | lr=0.05] Epoch 1026/4000: train_loss=0.0960  test_loss=3.1105  λ_max=53.9944\n",
      "[SGD | lr=0.05] Epoch 1027/4000: train_loss=0.0957  test_loss=3.1117  λ_max=52.6473\n",
      "[SGD | lr=0.05] Epoch 1028/4000: train_loss=0.0955  test_loss=3.1137  λ_max=53.5070\n",
      "[SGD | lr=0.05] Epoch 1029/4000: train_loss=0.0953  test_loss=3.1153  λ_max=52.2833\n",
      "[SGD | lr=0.05] Epoch 1030/4000: train_loss=0.0951  test_loss=3.1156  λ_max=53.9911\n",
      "[SGD | lr=0.05] Epoch 1031/4000: train_loss=0.0947  test_loss=3.1167  λ_max=52.7792\n",
      "[SGD | lr=0.05] Iter 16500: loss=0.0948\n",
      "[SGD | lr=0.05] Epoch 1032/4000: train_loss=0.0946  test_loss=3.1163  λ_max=54.7207\n",
      "[SGD | lr=0.05] Epoch 1033/4000: train_loss=0.0945  test_loss=3.1158  λ_max=53.4273\n",
      "[SGD | lr=0.05] Epoch 1034/4000: train_loss=0.0942  test_loss=3.1180  λ_max=54.9423\n",
      "[SGD | lr=0.05] Epoch 1035/4000: train_loss=0.0941  test_loss=3.1195  λ_max=54.8265\n",
      "[SGD | lr=0.05] Epoch 1036/4000: train_loss=0.0939  test_loss=3.1220  λ_max=52.1311\n",
      "[SGD | lr=0.05] Epoch 1037/4000: train_loss=0.0940  test_loss=3.1242  λ_max=54.0013\n",
      "[SGD | lr=0.05] Iter 16600: loss=0.0941\n",
      "[SGD | lr=0.05] Epoch 1038/4000: train_loss=0.0938  test_loss=3.1247  λ_max=54.0027\n",
      "[SGD | lr=0.05] Epoch 1039/4000: train_loss=0.0933  test_loss=3.1247  λ_max=54.4001\n",
      "[SGD | lr=0.05] Epoch 1040/4000: train_loss=0.0932  test_loss=3.1264  λ_max=52.6958\n",
      "[SGD | lr=0.05] Epoch 1041/4000: train_loss=0.0931  test_loss=3.1269  λ_max=52.9864\n",
      "[SGD | lr=0.05] Epoch 1042/4000: train_loss=0.0929  test_loss=3.1268  λ_max=55.3931\n",
      "[SGD | lr=0.05] Epoch 1043/4000: train_loss=0.0928  test_loss=3.1284  λ_max=53.3238\n",
      "[SGD | lr=0.05] Iter 16700: loss=0.0924\n",
      "[SGD | lr=0.05] Epoch 1044/4000: train_loss=0.0926  test_loss=3.1295  λ_max=55.1575\n",
      "[SGD | lr=0.05] Epoch 1045/4000: train_loss=0.0923  test_loss=3.1308  λ_max=53.9737\n",
      "[SGD | lr=0.05] Epoch 1046/4000: train_loss=0.0920  test_loss=3.1315  λ_max=54.9229\n",
      "[SGD | lr=0.05] Epoch 1047/4000: train_loss=0.0918  test_loss=3.1324  λ_max=55.2997\n",
      "[SGD | lr=0.05] Epoch 1048/4000: train_loss=0.0918  test_loss=3.1340  λ_max=54.6859\n",
      "[SGD | lr=0.05] Epoch 1049/4000: train_loss=0.0920  test_loss=3.1351  λ_max=55.0547\n",
      "[SGD | lr=0.05] Iter 16800: loss=0.0892\n",
      "[SGD | lr=0.05] Epoch 1050/4000: train_loss=0.0914  test_loss=3.1359  λ_max=54.4173\n",
      "[SGD | lr=0.05] Epoch 1051/4000: train_loss=0.0912  test_loss=3.1357  λ_max=55.0898\n",
      "[SGD | lr=0.05] Epoch 1052/4000: train_loss=0.0911  test_loss=3.1367  λ_max=54.9456\n",
      "[SGD | lr=0.05] Epoch 1053/4000: train_loss=0.0909  test_loss=3.1382  λ_max=54.0140\n",
      "[SGD | lr=0.05] Epoch 1054/4000: train_loss=0.0908  test_loss=3.1397  λ_max=55.0335\n",
      "[SGD | lr=0.05] Epoch 1055/4000: train_loss=0.0908  test_loss=3.1402  λ_max=55.5559\n",
      "[SGD | lr=0.05] Epoch 1056/4000: train_loss=0.0906  test_loss=3.1422  λ_max=55.2158\n",
      "[SGD | lr=0.05] Iter 16900: loss=0.0906\n",
      "[SGD | lr=0.05] Epoch 1057/4000: train_loss=0.0903  test_loss=3.1432  λ_max=55.0198\n",
      "[SGD | lr=0.05] Epoch 1058/4000: train_loss=0.0901  test_loss=3.1428  λ_max=55.5092\n",
      "[SGD | lr=0.05] Epoch 1059/4000: train_loss=0.0899  test_loss=3.1445  λ_max=55.5652\n",
      "[SGD | lr=0.05] Epoch 1060/4000: train_loss=0.0897  test_loss=3.1463  λ_max=54.2722\n",
      "[SGD | lr=0.05] Epoch 1061/4000: train_loss=0.0896  test_loss=3.1460  λ_max=56.0165\n",
      "[SGD | lr=0.05] Epoch 1062/4000: train_loss=0.0894  test_loss=3.1457  λ_max=55.9074\n",
      "[SGD | lr=0.05] Iter 17000: loss=0.0899\n",
      "[SGD | lr=0.05] Epoch 1063/4000: train_loss=0.0894  test_loss=3.1478  λ_max=55.7625\n",
      "[SGD | lr=0.05] Epoch 1064/4000: train_loss=0.0891  test_loss=3.1490  λ_max=54.6944\n",
      "[SGD | lr=0.05] Epoch 1065/4000: train_loss=0.0889  test_loss=3.1510  λ_max=54.7951\n",
      "[SGD | lr=0.05] Epoch 1066/4000: train_loss=0.0887  test_loss=3.1503  λ_max=55.3805\n",
      "[SGD | lr=0.05] Epoch 1067/4000: train_loss=0.0887  test_loss=3.1532  λ_max=57.1671\n",
      "[SGD | lr=0.05] Epoch 1068/4000: train_loss=0.0886  test_loss=3.1527  λ_max=55.3775\n",
      "[SGD | lr=0.05] Iter 17100: loss=0.0865\n",
      "[SGD | lr=0.05] Epoch 1069/4000: train_loss=0.0885  test_loss=3.1552  λ_max=53.6496\n",
      "[SGD | lr=0.05] Epoch 1070/4000: train_loss=0.0882  test_loss=3.1555  λ_max=53.6232\n",
      "[SGD | lr=0.05] Epoch 1071/4000: train_loss=0.0880  test_loss=3.1559  λ_max=54.8138\n",
      "[SGD | lr=0.05] Epoch 1072/4000: train_loss=0.0877  test_loss=3.1570  λ_max=56.2418\n",
      "[SGD | lr=0.05] Epoch 1073/4000: train_loss=0.0877  test_loss=3.1594  λ_max=54.7741\n",
      "[SGD | lr=0.05] Epoch 1074/4000: train_loss=0.0877  test_loss=3.1601  λ_max=57.0220\n",
      "[SGD | lr=0.05] Iter 17200: loss=0.0855\n",
      "[SGD | lr=0.05] Epoch 1075/4000: train_loss=0.0872  test_loss=3.1608  λ_max=54.7045\n",
      "[SGD | lr=0.05] Epoch 1076/4000: train_loss=0.0870  test_loss=3.1616  λ_max=55.2139\n",
      "[SGD | lr=0.05] Epoch 1077/4000: train_loss=0.0869  test_loss=3.1640  λ_max=56.1952\n",
      "[SGD | lr=0.05] Epoch 1078/4000: train_loss=0.0868  test_loss=3.1638  λ_max=54.5523\n",
      "[SGD | lr=0.05] Epoch 1079/4000: train_loss=0.0866  test_loss=3.1645  λ_max=55.3108\n",
      "[SGD | lr=0.05] Epoch 1080/4000: train_loss=0.0865  test_loss=3.1652  λ_max=54.9287\n",
      "[SGD | lr=0.05] Epoch 1081/4000: train_loss=0.0864  test_loss=3.1656  λ_max=56.1546\n",
      "[SGD | lr=0.05] Iter 17300: loss=0.0863\n",
      "[SGD | lr=0.05] Epoch 1082/4000: train_loss=0.0863  test_loss=3.1680  λ_max=57.3811\n",
      "[SGD | lr=0.05] Epoch 1083/4000: train_loss=0.0861  test_loss=3.1685  λ_max=54.0573\n",
      "[SGD | lr=0.05] Epoch 1084/4000: train_loss=0.0859  test_loss=3.1689  λ_max=57.2125\n",
      "[SGD | lr=0.05] Epoch 1085/4000: train_loss=0.0859  test_loss=3.1710  λ_max=55.4181\n",
      "[SGD | lr=0.05] Epoch 1086/4000: train_loss=0.0857  test_loss=3.1708  λ_max=54.1729\n",
      "[SGD | lr=0.05] Epoch 1087/4000: train_loss=0.0854  test_loss=3.1724  λ_max=55.9557\n",
      "[SGD | lr=0.05] Iter 17400: loss=0.0840\n",
      "[SGD | lr=0.05] Epoch 1088/4000: train_loss=0.0852  test_loss=3.1726  λ_max=56.9800\n",
      "[SGD | lr=0.05] Epoch 1089/4000: train_loss=0.0851  test_loss=3.1747  λ_max=56.0257\n",
      "[SGD | lr=0.05] Epoch 1090/4000: train_loss=0.0850  test_loss=3.1749  λ_max=56.2310\n",
      "[SGD | lr=0.05] Epoch 1091/4000: train_loss=0.0849  test_loss=3.1769  λ_max=55.3741\n",
      "[SGD | lr=0.05] Epoch 1092/4000: train_loss=0.0847  test_loss=3.1773  λ_max=54.9740\n",
      "[SGD | lr=0.05] Epoch 1093/4000: train_loss=0.0847  test_loss=3.1788  λ_max=56.5274\n",
      "[SGD | lr=0.05] Iter 17500: loss=0.0846\n",
      "[SGD | lr=0.05] Epoch 1094/4000: train_loss=0.0844  test_loss=3.1790  λ_max=55.9638\n",
      "[SGD | lr=0.05] Epoch 1095/4000: train_loss=0.0842  test_loss=3.1794  λ_max=55.8507\n",
      "[SGD | lr=0.05] Epoch 1096/4000: train_loss=0.0841  test_loss=3.1807  λ_max=57.8828\n",
      "[SGD | lr=0.05] Epoch 1097/4000: train_loss=0.0840  test_loss=3.1813  λ_max=56.1828\n",
      "[SGD | lr=0.05] Epoch 1098/4000: train_loss=0.0838  test_loss=3.1822  λ_max=55.9288\n",
      "[SGD | lr=0.05] Epoch 1099/4000: train_loss=0.0836  test_loss=3.1845  λ_max=56.5623\n",
      "[SGD | lr=0.05] Iter 17600: loss=0.0826\n",
      "[SGD | lr=0.05] Epoch 1100/4000: train_loss=0.0835  test_loss=3.1848  λ_max=57.4681\n",
      "[SGD | lr=0.05] Epoch 1101/4000: train_loss=0.0833  test_loss=3.1856  λ_max=56.7093\n",
      "[SGD | lr=0.05] Epoch 1102/4000: train_loss=0.0831  test_loss=3.1866  λ_max=57.0035\n",
      "[SGD | lr=0.05] Epoch 1103/4000: train_loss=0.0831  test_loss=3.1869  λ_max=57.9316\n",
      "[SGD | lr=0.05] Epoch 1104/4000: train_loss=0.0830  test_loss=3.1880  λ_max=58.0015\n",
      "[SGD | lr=0.05] Epoch 1105/4000: train_loss=0.0827  test_loss=3.1891  λ_max=56.3704\n",
      "[SGD | lr=0.05] Epoch 1106/4000: train_loss=0.0826  test_loss=3.1903  λ_max=57.9909\n",
      "[SGD | lr=0.05] Iter 17700: loss=0.0826\n",
      "[SGD | lr=0.05] Epoch 1107/4000: train_loss=0.0824  test_loss=3.1916  λ_max=56.9035\n",
      "[SGD | lr=0.05] Epoch 1108/4000: train_loss=0.0822  test_loss=3.1927  λ_max=56.8895\n",
      "[SGD | lr=0.05] Epoch 1109/4000: train_loss=0.0824  test_loss=3.1945  λ_max=55.6804\n",
      "[SGD | lr=0.05] Epoch 1110/4000: train_loss=0.0820  test_loss=3.1940  λ_max=57.4270\n",
      "[SGD | lr=0.05] Epoch 1111/4000: train_loss=0.0818  test_loss=3.1957  λ_max=58.5751\n",
      "[SGD | lr=0.05] Epoch 1112/4000: train_loss=0.0818  test_loss=3.1976  λ_max=56.3354\n",
      "[SGD | lr=0.05] Iter 17800: loss=0.0819\n",
      "[SGD | lr=0.05] Epoch 1113/4000: train_loss=0.0817  test_loss=3.1978  λ_max=58.5858\n",
      "[SGD | lr=0.05] Epoch 1114/4000: train_loss=0.0816  test_loss=3.1973  λ_max=56.3984\n",
      "[SGD | lr=0.05] Epoch 1115/4000: train_loss=0.0813  test_loss=3.1996  λ_max=57.3760\n",
      "[SGD | lr=0.05] Epoch 1116/4000: train_loss=0.0811  test_loss=3.2002  λ_max=54.5991\n",
      "[SGD | lr=0.05] Epoch 1117/4000: train_loss=0.0810  test_loss=3.2011  λ_max=58.3724\n",
      "[SGD | lr=0.05] Epoch 1118/4000: train_loss=0.0810  test_loss=3.2019  λ_max=57.1942\n",
      "[SGD | lr=0.05] Iter 17900: loss=0.0807\n",
      "[SGD | lr=0.05] Epoch 1119/4000: train_loss=0.0807  test_loss=3.2018  λ_max=57.6635\n",
      "[SGD | lr=0.05] Epoch 1120/4000: train_loss=0.0805  test_loss=3.2031  λ_max=58.6355\n",
      "[SGD | lr=0.05] Epoch 1121/4000: train_loss=0.0804  test_loss=3.2042  λ_max=57.3022\n",
      "[SGD | lr=0.05] Epoch 1122/4000: train_loss=0.0804  test_loss=3.2059  λ_max=56.9751\n",
      "[SGD | lr=0.05] Epoch 1123/4000: train_loss=0.0802  test_loss=3.2072  λ_max=55.6339\n",
      "[SGD | lr=0.05] Epoch 1124/4000: train_loss=0.0801  test_loss=3.2076  λ_max=55.7455\n",
      "[SGD | lr=0.05] Iter 18000: loss=0.0803\n",
      "[SGD | lr=0.05] Epoch 1125/4000: train_loss=0.0799  test_loss=3.2090  λ_max=56.9943\n",
      "[SGD | lr=0.05] Epoch 1126/4000: train_loss=0.0798  test_loss=3.2097  λ_max=57.3958\n",
      "[SGD | lr=0.05] Epoch 1127/4000: train_loss=0.0797  test_loss=3.2092  λ_max=56.6743\n",
      "[SGD | lr=0.05] Epoch 1128/4000: train_loss=0.0796  test_loss=3.2107  λ_max=55.5544\n",
      "[SGD | lr=0.05] Epoch 1129/4000: train_loss=0.0794  test_loss=3.2124  λ_max=55.5972\n",
      "[SGD | lr=0.05] Epoch 1130/4000: train_loss=0.0792  test_loss=3.2126  λ_max=57.9923\n",
      "[SGD | lr=0.05] Epoch 1131/4000: train_loss=0.0791  test_loss=3.2140  λ_max=55.6692\n",
      "[SGD | lr=0.05] Iter 18100: loss=0.0782\n",
      "[SGD | lr=0.05] Epoch 1132/4000: train_loss=0.0790  test_loss=3.2160  λ_max=58.0837\n",
      "[SGD | lr=0.05] Epoch 1133/4000: train_loss=0.0788  test_loss=3.2169  λ_max=57.7804\n",
      "[SGD | lr=0.05] Epoch 1134/4000: train_loss=0.0788  test_loss=3.2175  λ_max=55.9381\n",
      "[SGD | lr=0.05] Epoch 1135/4000: train_loss=0.0786  test_loss=3.2180  λ_max=55.3901\n",
      "[SGD | lr=0.05] Epoch 1136/4000: train_loss=0.0784  test_loss=3.2191  λ_max=56.9211\n",
      "[SGD | lr=0.05] Epoch 1137/4000: train_loss=0.0783  test_loss=3.2201  λ_max=56.2332\n",
      "[SGD | lr=0.05] Iter 18200: loss=0.0790\n",
      "[SGD | lr=0.05] Epoch 1138/4000: train_loss=0.0783  test_loss=3.2208  λ_max=57.0634\n",
      "[SGD | lr=0.05] Epoch 1139/4000: train_loss=0.0781  test_loss=3.2211  λ_max=58.2473\n",
      "[SGD | lr=0.05] Epoch 1140/4000: train_loss=0.0779  test_loss=3.2218  λ_max=56.4679\n",
      "[SGD | lr=0.05] Epoch 1141/4000: train_loss=0.0778  test_loss=3.2228  λ_max=57.9681\n",
      "[SGD | lr=0.05] Epoch 1142/4000: train_loss=0.0777  test_loss=3.2237  λ_max=56.0644\n",
      "[SGD | lr=0.05] Epoch 1143/4000: train_loss=0.0776  test_loss=3.2248  λ_max=57.5908\n",
      "[SGD | lr=0.05] Iter 18300: loss=0.0762\n",
      "[SGD | lr=0.05] Epoch 1144/4000: train_loss=0.0774  test_loss=3.2265  λ_max=58.8523\n",
      "[SGD | lr=0.05] Epoch 1145/4000: train_loss=0.0773  test_loss=3.2283  λ_max=57.6955\n",
      "[SGD | lr=0.05] Epoch 1146/4000: train_loss=0.0771  test_loss=3.2282  λ_max=57.2843\n",
      "[SGD | lr=0.05] Epoch 1147/4000: train_loss=0.0770  test_loss=3.2283  λ_max=58.1415\n",
      "[SGD | lr=0.05] Epoch 1148/4000: train_loss=0.0769  test_loss=3.2292  λ_max=59.0059\n",
      "[SGD | lr=0.05] Epoch 1149/4000: train_loss=0.0768  test_loss=3.2308  λ_max=58.1789\n",
      "[SGD | lr=0.05] Iter 18400: loss=0.0756\n",
      "[SGD | lr=0.05] Epoch 1150/4000: train_loss=0.0766  test_loss=3.2315  λ_max=58.4109\n",
      "[SGD | lr=0.05] Epoch 1151/4000: train_loss=0.0764  test_loss=3.2324  λ_max=57.6728\n",
      "[SGD | lr=0.05] Epoch 1152/4000: train_loss=0.0763  test_loss=3.2336  λ_max=56.3961\n",
      "[SGD | lr=0.05] Epoch 1153/4000: train_loss=0.0762  test_loss=3.2346  λ_max=58.7641\n",
      "[SGD | lr=0.05] Epoch 1154/4000: train_loss=0.0761  test_loss=3.2360  λ_max=57.3686\n",
      "[SGD | lr=0.05] Epoch 1155/4000: train_loss=0.0760  test_loss=3.2363  λ_max=57.0551\n",
      "[SGD | lr=0.05] Epoch 1156/4000: train_loss=0.0759  test_loss=3.2366  λ_max=58.8802\n",
      "[SGD | lr=0.05] Iter 18500: loss=0.0756\n",
      "[SGD | lr=0.05] Epoch 1157/4000: train_loss=0.0758  test_loss=3.2387  λ_max=58.1714\n",
      "[SGD | lr=0.05] Epoch 1158/4000: train_loss=0.0756  test_loss=3.2377  λ_max=58.8566\n",
      "[SGD | lr=0.05] Epoch 1159/4000: train_loss=0.0755  test_loss=3.2398  λ_max=59.8286\n",
      "[SGD | lr=0.05] Epoch 1160/4000: train_loss=0.0754  test_loss=3.2410  λ_max=58.5589\n",
      "[SGD | lr=0.05] Epoch 1161/4000: train_loss=0.0754  test_loss=3.2410  λ_max=58.4094\n",
      "[SGD | lr=0.05] Epoch 1162/4000: train_loss=0.0752  test_loss=3.2420  λ_max=58.5948\n",
      "[SGD | lr=0.05] Iter 18600: loss=0.0743\n",
      "[SGD | lr=0.05] Epoch 1163/4000: train_loss=0.0750  test_loss=3.2428  λ_max=58.2570\n",
      "[SGD | lr=0.05] Epoch 1164/4000: train_loss=0.0748  test_loss=3.2427  λ_max=55.0269\n",
      "[SGD | lr=0.05] Epoch 1165/4000: train_loss=0.0747  test_loss=3.2446  λ_max=59.0913\n",
      "[SGD | lr=0.05] Epoch 1166/4000: train_loss=0.0746  test_loss=3.2459  λ_max=59.2722\n",
      "[SGD | lr=0.05] Epoch 1167/4000: train_loss=0.0746  test_loss=3.2458  λ_max=58.4821\n",
      "[SGD | lr=0.05] Epoch 1168/4000: train_loss=0.0743  test_loss=3.2477  λ_max=58.9184\n",
      "[SGD | lr=0.05] Iter 18700: loss=0.0741\n",
      "[SGD | lr=0.05] Epoch 1169/4000: train_loss=0.0742  test_loss=3.2482  λ_max=59.0996\n",
      "[SGD | lr=0.05] Epoch 1170/4000: train_loss=0.0741  test_loss=3.2489  λ_max=58.5205\n",
      "[SGD | lr=0.05] Epoch 1171/4000: train_loss=0.0740  test_loss=3.2497  λ_max=59.0886\n",
      "[SGD | lr=0.05] Epoch 1172/4000: train_loss=0.0738  test_loss=3.2512  λ_max=57.8323\n",
      "[SGD | lr=0.05] Epoch 1173/4000: train_loss=0.0738  test_loss=3.2520  λ_max=58.4196\n",
      "[SGD | lr=0.05] Epoch 1174/4000: train_loss=0.0737  test_loss=3.2525  λ_max=56.0300\n",
      "[SGD | lr=0.05] Iter 18800: loss=0.0731\n",
      "[SGD | lr=0.05] Epoch 1175/4000: train_loss=0.0736  test_loss=3.2529  λ_max=59.4401\n",
      "[SGD | lr=0.05] Epoch 1176/4000: train_loss=0.0736  test_loss=3.2535  λ_max=58.6097\n",
      "[SGD | lr=0.05] Epoch 1177/4000: train_loss=0.0733  test_loss=3.2543  λ_max=58.2390\n",
      "[SGD | lr=0.05] Epoch 1178/4000: train_loss=0.0731  test_loss=3.2567  λ_max=56.1171\n",
      "[SGD | lr=0.05] Epoch 1179/4000: train_loss=0.0730  test_loss=3.2571  λ_max=58.9172\n",
      "[SGD | lr=0.05] Epoch 1180/4000: train_loss=0.0730  test_loss=3.2577  λ_max=58.6591\n",
      "[SGD | lr=0.05] Epoch 1181/4000: train_loss=0.0728  test_loss=3.2582  λ_max=57.9988\n",
      "[SGD | lr=0.05] Iter 18900: loss=0.0727\n",
      "[SGD | lr=0.05] Epoch 1182/4000: train_loss=0.0727  test_loss=3.2600  λ_max=57.6642\n",
      "[SGD | lr=0.05] Epoch 1183/4000: train_loss=0.0726  test_loss=3.2622  λ_max=56.4901\n",
      "[SGD | lr=0.05] Epoch 1184/4000: train_loss=0.0725  test_loss=3.2622  λ_max=58.8673\n",
      "[SGD | lr=0.05] Epoch 1185/4000: train_loss=0.0724  test_loss=3.2636  λ_max=56.7522\n",
      "[SGD | lr=0.05] Epoch 1186/4000: train_loss=0.0722  test_loss=3.2632  λ_max=60.1860\n",
      "[SGD | lr=0.05] Epoch 1187/4000: train_loss=0.0722  test_loss=3.2649  λ_max=59.6855\n",
      "[SGD | lr=0.05] Iter 19000: loss=0.0732\n",
      "[SGD | lr=0.05] Epoch 1188/4000: train_loss=0.0720  test_loss=3.2651  λ_max=59.9650\n",
      "[SGD | lr=0.05] Epoch 1189/4000: train_loss=0.0719  test_loss=3.2658  λ_max=56.7607\n",
      "[SGD | lr=0.05] Epoch 1190/4000: train_loss=0.0717  test_loss=3.2669  λ_max=60.5049\n",
      "[SGD | lr=0.05] Epoch 1191/4000: train_loss=0.0717  test_loss=3.2681  λ_max=59.8159\n",
      "[SGD | lr=0.05] Epoch 1192/4000: train_loss=0.0716  test_loss=3.2686  λ_max=58.8055\n",
      "[SGD | lr=0.05] Epoch 1193/4000: train_loss=0.0714  test_loss=3.2695  λ_max=59.0023\n",
      "[SGD | lr=0.05] Iter 19100: loss=0.0724\n",
      "[SGD | lr=0.05] Epoch 1194/4000: train_loss=0.0713  test_loss=3.2703  λ_max=59.0315\n",
      "[SGD | lr=0.05] Epoch 1195/4000: train_loss=0.0713  test_loss=3.2711  λ_max=58.6191\n",
      "[SGD | lr=0.05] Epoch 1196/4000: train_loss=0.0710  test_loss=3.2709  λ_max=59.9302\n",
      "[SGD | lr=0.05] Epoch 1197/4000: train_loss=0.0709  test_loss=3.2728  λ_max=59.5109\n",
      "[SGD | lr=0.05] Epoch 1198/4000: train_loss=0.0709  test_loss=3.2733  λ_max=60.6839\n",
      "[SGD | lr=0.05] Epoch 1199/4000: train_loss=0.0708  test_loss=3.2743  λ_max=57.6626\n",
      "[SGD | lr=0.05] Iter 19200: loss=0.0676\n",
      "[SGD | lr=0.05] Epoch 1200/4000: train_loss=0.0706  test_loss=3.2754  λ_max=57.9757\n",
      "[SGD | lr=0.05] Epoch 1201/4000: train_loss=0.0706  test_loss=3.2753  λ_max=60.4126\n",
      "[SGD | lr=0.05] Epoch 1202/4000: train_loss=0.0704  test_loss=3.2764  λ_max=58.8979\n",
      "[SGD | lr=0.05] Epoch 1203/4000: train_loss=0.0704  test_loss=3.2771  λ_max=59.4331\n",
      "[SGD | lr=0.05] Epoch 1204/4000: train_loss=0.0702  test_loss=3.2779  λ_max=58.7051\n",
      "[SGD | lr=0.05] Epoch 1205/4000: train_loss=0.0702  test_loss=3.2795  λ_max=57.7787\n",
      "[SGD | lr=0.05] Epoch 1206/4000: train_loss=0.0699  test_loss=3.2804  λ_max=59.7998\n",
      "[SGD | lr=0.05] Iter 19300: loss=0.0696\n",
      "[SGD | lr=0.05] Epoch 1207/4000: train_loss=0.0699  test_loss=3.2810  λ_max=59.3865\n",
      "[SGD | lr=0.05] Epoch 1208/4000: train_loss=0.0699  test_loss=3.2823  λ_max=58.6322\n",
      "[SGD | lr=0.05] Epoch 1209/4000: train_loss=0.0697  test_loss=3.2830  λ_max=58.2410\n",
      "[SGD | lr=0.05] Epoch 1210/4000: train_loss=0.0696  test_loss=3.2840  λ_max=60.4101\n",
      "[SGD | lr=0.05] Epoch 1211/4000: train_loss=0.0695  test_loss=3.2843  λ_max=59.1399\n",
      "[SGD | lr=0.05] Epoch 1212/4000: train_loss=0.0693  test_loss=3.2859  λ_max=60.6580\n",
      "[SGD | lr=0.05] Iter 19400: loss=0.0715\n",
      "[SGD | lr=0.05] Epoch 1213/4000: train_loss=0.0692  test_loss=3.2867  λ_max=61.7141\n",
      "[SGD | lr=0.05] Epoch 1214/4000: train_loss=0.0692  test_loss=3.2874  λ_max=59.4196\n",
      "[SGD | lr=0.05] Epoch 1215/4000: train_loss=0.0690  test_loss=3.2889  λ_max=57.8053\n",
      "[SGD | lr=0.05] Epoch 1216/4000: train_loss=0.0689  test_loss=3.2889  λ_max=59.6192\n",
      "[SGD | lr=0.05] Epoch 1217/4000: train_loss=0.0689  test_loss=3.2892  λ_max=59.7060\n",
      "[SGD | lr=0.05] Epoch 1218/4000: train_loss=0.0687  test_loss=3.2898  λ_max=60.2319\n",
      "[SGD | lr=0.05] Iter 19500: loss=0.0682\n",
      "[SGD | lr=0.05] Epoch 1219/4000: train_loss=0.0686  test_loss=3.2910  λ_max=61.1767\n",
      "[SGD | lr=0.05] Epoch 1220/4000: train_loss=0.0685  test_loss=3.2919  λ_max=57.8273\n",
      "[SGD | lr=0.05] Epoch 1221/4000: train_loss=0.0684  test_loss=3.2927  λ_max=59.5277\n",
      "[SGD | lr=0.05] Epoch 1222/4000: train_loss=0.0683  test_loss=3.2939  λ_max=57.7477\n",
      "[SGD | lr=0.05] Epoch 1223/4000: train_loss=0.0682  test_loss=3.2943  λ_max=57.3378\n",
      "[SGD | lr=0.05] Epoch 1224/4000: train_loss=0.0681  test_loss=3.2960  λ_max=59.9170\n",
      "[SGD | lr=0.05] Iter 19600: loss=0.0688\n",
      "[SGD | lr=0.05] Epoch 1225/4000: train_loss=0.0680  test_loss=3.2959  λ_max=60.0375\n",
      "[SGD | lr=0.05] Epoch 1226/4000: train_loss=0.0679  test_loss=3.2967  λ_max=58.4465\n",
      "[SGD | lr=0.05] Epoch 1227/4000: train_loss=0.0677  test_loss=3.2972  λ_max=61.2734\n",
      "[SGD | lr=0.05] Epoch 1228/4000: train_loss=0.0677  test_loss=3.2993  λ_max=61.5845\n",
      "[SGD | lr=0.05] Epoch 1229/4000: train_loss=0.0676  test_loss=3.2989  λ_max=61.1191\n",
      "[SGD | lr=0.05] Epoch 1230/4000: train_loss=0.0675  test_loss=3.3005  λ_max=59.6519\n",
      "[SGD | lr=0.05] Epoch 1231/4000: train_loss=0.0674  test_loss=3.3012  λ_max=59.1387\n",
      "[SGD | lr=0.05] Iter 19700: loss=0.0664\n",
      "[SGD | lr=0.05] Epoch 1232/4000: train_loss=0.0672  test_loss=3.3018  λ_max=60.1831\n",
      "[SGD | lr=0.05] Epoch 1233/4000: train_loss=0.0672  test_loss=3.3031  λ_max=60.8378\n",
      "[SGD | lr=0.05] Epoch 1234/4000: train_loss=0.0670  test_loss=3.3031  λ_max=58.4931\n",
      "[SGD | lr=0.05] Epoch 1235/4000: train_loss=0.0669  test_loss=3.3049  λ_max=60.7495\n",
      "[SGD | lr=0.05] Epoch 1236/4000: train_loss=0.0669  test_loss=3.3056  λ_max=58.8005\n",
      "[SGD | lr=0.05] Epoch 1237/4000: train_loss=0.0667  test_loss=3.3062  λ_max=58.7839\n",
      "[SGD | lr=0.05] Iter 19800: loss=0.0664\n",
      "[SGD | lr=0.05] Epoch 1238/4000: train_loss=0.0666  test_loss=3.3070  λ_max=60.0292\n",
      "[SGD | lr=0.05] Epoch 1239/4000: train_loss=0.0665  test_loss=3.3081  λ_max=60.1689\n",
      "[SGD | lr=0.05] Epoch 1240/4000: train_loss=0.0665  test_loss=3.3084  λ_max=59.8189\n",
      "[SGD | lr=0.05] Epoch 1241/4000: train_loss=0.0663  test_loss=3.3093  λ_max=59.7437\n",
      "[SGD | lr=0.05] Epoch 1242/4000: train_loss=0.0663  test_loss=3.3096  λ_max=61.6658\n",
      "[SGD | lr=0.05] Epoch 1243/4000: train_loss=0.0662  test_loss=3.3105  λ_max=58.4885\n",
      "[SGD | lr=0.05] Iter 19900: loss=0.0654\n",
      "[SGD | lr=0.05] Epoch 1244/4000: train_loss=0.0660  test_loss=3.3112  λ_max=60.3578\n",
      "[SGD | lr=0.05] Epoch 1245/4000: train_loss=0.0660  test_loss=3.3130  λ_max=60.6427\n",
      "[SGD | lr=0.05] Epoch 1246/4000: train_loss=0.0659  test_loss=3.3129  λ_max=59.4122\n",
      "[SGD | lr=0.05] Epoch 1247/4000: train_loss=0.0658  test_loss=3.3136  λ_max=61.0765\n",
      "[SGD | lr=0.05] Epoch 1248/4000: train_loss=0.0657  test_loss=3.3143  λ_max=60.8522\n",
      "[SGD | lr=0.05] Epoch 1249/4000: train_loss=0.0656  test_loss=3.3166  λ_max=59.3005\n",
      "[SGD | lr=0.05] Iter 20000: loss=0.0646\n",
      "[SGD | lr=0.05] Epoch 1250/4000: train_loss=0.0654  test_loss=3.3164  λ_max=59.3941\n",
      "[SGD | lr=0.05] Epoch 1251/4000: train_loss=0.0654  test_loss=3.3180  λ_max=59.7980\n",
      "[SGD | lr=0.05] Epoch 1252/4000: train_loss=0.0653  test_loss=3.3173  λ_max=60.2496\n",
      "[SGD | lr=0.05] Epoch 1253/4000: train_loss=0.0652  test_loss=3.3188  λ_max=62.0106\n",
      "[SGD | lr=0.05] Epoch 1254/4000: train_loss=0.0651  test_loss=3.3194  λ_max=62.3918\n",
      "[SGD | lr=0.05] Epoch 1255/4000: train_loss=0.0650  test_loss=3.3211  λ_max=60.1693\n",
      "[SGD | lr=0.05] Epoch 1256/4000: train_loss=0.0649  test_loss=3.3215  λ_max=60.2552\n",
      "[SGD | lr=0.05] Iter 20100: loss=0.0643\n",
      "[SGD | lr=0.05] Epoch 1257/4000: train_loss=0.0648  test_loss=3.3221  λ_max=60.7718\n",
      "[SGD | lr=0.05] Epoch 1258/4000: train_loss=0.0647  test_loss=3.3233  λ_max=60.1570\n",
      "[SGD | lr=0.05] Epoch 1259/4000: train_loss=0.0647  test_loss=3.3245  λ_max=61.8254\n",
      "[SGD | lr=0.05] Epoch 1260/4000: train_loss=0.0645  test_loss=3.3248  λ_max=61.1577\n",
      "[SGD | lr=0.05] Epoch 1261/4000: train_loss=0.0644  test_loss=3.3256  λ_max=59.7443\n",
      "[SGD | lr=0.05] Epoch 1262/4000: train_loss=0.0643  test_loss=3.3260  λ_max=61.4632\n",
      "[SGD | lr=0.05] Iter 20200: loss=0.0642\n",
      "[SGD | lr=0.05] Epoch 1263/4000: train_loss=0.0642  test_loss=3.3271  λ_max=60.9241\n",
      "[SGD | lr=0.05] Epoch 1264/4000: train_loss=0.0641  test_loss=3.3279  λ_max=59.7385\n",
      "[SGD | lr=0.05] Epoch 1265/4000: train_loss=0.0640  test_loss=3.3284  λ_max=60.8450\n",
      "[SGD | lr=0.05] Epoch 1266/4000: train_loss=0.0639  test_loss=3.3295  λ_max=59.5840\n",
      "[SGD | lr=0.05] Epoch 1267/4000: train_loss=0.0639  test_loss=3.3310  λ_max=61.8058\n",
      "[SGD | lr=0.05] Epoch 1268/4000: train_loss=0.0638  test_loss=3.3314  λ_max=59.6892\n",
      "[SGD | lr=0.05] Iter 20300: loss=0.0643\n",
      "[SGD | lr=0.05] Epoch 1269/4000: train_loss=0.0637  test_loss=3.3319  λ_max=60.0859\n",
      "[SGD | lr=0.05] Epoch 1270/4000: train_loss=0.0636  test_loss=3.3322  λ_max=59.0118\n",
      "[SGD | lr=0.05] Epoch 1271/4000: train_loss=0.0635  test_loss=3.3329  λ_max=62.2244\n",
      "[SGD | lr=0.05] Epoch 1272/4000: train_loss=0.0634  test_loss=3.3345  λ_max=60.2540\n",
      "[SGD | lr=0.05] Epoch 1273/4000: train_loss=0.0633  test_loss=3.3351  λ_max=60.7421\n",
      "[SGD | lr=0.05] Epoch 1274/4000: train_loss=0.0632  test_loss=3.3362  λ_max=61.5380\n",
      "[SGD | lr=0.05] Iter 20400: loss=0.0633\n",
      "[SGD | lr=0.05] Epoch 1275/4000: train_loss=0.0631  test_loss=3.3360  λ_max=59.6305\n",
      "[SGD | lr=0.05] Epoch 1276/4000: train_loss=0.0630  test_loss=3.3369  λ_max=60.7023\n",
      "[SGD | lr=0.05] Epoch 1277/4000: train_loss=0.0629  test_loss=3.3384  λ_max=61.6779\n",
      "[SGD | lr=0.05] Epoch 1278/4000: train_loss=0.0629  test_loss=3.3396  λ_max=60.8234\n",
      "[SGD | lr=0.05] Epoch 1279/4000: train_loss=0.0628  test_loss=3.3398  λ_max=60.1810\n",
      "[SGD | lr=0.05] Epoch 1280/4000: train_loss=0.0627  test_loss=3.3412  λ_max=60.8799\n",
      "[SGD | lr=0.05] Epoch 1281/4000: train_loss=0.0626  test_loss=3.3417  λ_max=58.9271\n",
      "[SGD | lr=0.05] Iter 20500: loss=0.0619\n",
      "[SGD | lr=0.05] Epoch 1282/4000: train_loss=0.0625  test_loss=3.3432  λ_max=61.9828\n",
      "[SGD | lr=0.05] Epoch 1283/4000: train_loss=0.0624  test_loss=3.3436  λ_max=62.4372\n",
      "[SGD | lr=0.05] Epoch 1284/4000: train_loss=0.0623  test_loss=3.3448  λ_max=61.8322\n",
      "[SGD | lr=0.05] Epoch 1285/4000: train_loss=0.0623  test_loss=3.3452  λ_max=61.4225\n",
      "[SGD | lr=0.05] Epoch 1286/4000: train_loss=0.0622  test_loss=3.3452  λ_max=63.6424\n",
      "[SGD | lr=0.05] Epoch 1287/4000: train_loss=0.0620  test_loss=3.3461  λ_max=61.2175\n",
      "[SGD | lr=0.05] Iter 20600: loss=0.0644\n",
      "[SGD | lr=0.05] Epoch 1288/4000: train_loss=0.0620  test_loss=3.3472  λ_max=62.8040\n",
      "[SGD | lr=0.05] Epoch 1289/4000: train_loss=0.0619  test_loss=3.3475  λ_max=62.8599\n",
      "[SGD | lr=0.05] Epoch 1290/4000: train_loss=0.0618  test_loss=3.3483  λ_max=62.0396\n",
      "[SGD | lr=0.05] Epoch 1291/4000: train_loss=0.0617  test_loss=3.3493  λ_max=62.1148\n",
      "[SGD | lr=0.05] Epoch 1292/4000: train_loss=0.0616  test_loss=3.3503  λ_max=59.6229\n",
      "[SGD | lr=0.05] Epoch 1293/4000: train_loss=0.0615  test_loss=3.3514  λ_max=60.7786\n",
      "[SGD | lr=0.05] Iter 20700: loss=0.0619\n",
      "[SGD | lr=0.05] Epoch 1294/4000: train_loss=0.0614  test_loss=3.3515  λ_max=62.9417\n",
      "[SGD | lr=0.05] Epoch 1295/4000: train_loss=0.0614  test_loss=3.3525  λ_max=62.9485\n",
      "[SGD | lr=0.05] Epoch 1296/4000: train_loss=0.0612  test_loss=3.3538  λ_max=61.3728\n",
      "[SGD | lr=0.05] Epoch 1297/4000: train_loss=0.0612  test_loss=3.3544  λ_max=61.9883\n",
      "[SGD | lr=0.05] Epoch 1298/4000: train_loss=0.0611  test_loss=3.3550  λ_max=61.7127\n",
      "[SGD | lr=0.05] Epoch 1299/4000: train_loss=0.0610  test_loss=3.3556  λ_max=62.9176\n",
      "[SGD | lr=0.05] Iter 20800: loss=0.0595\n",
      "[SGD | lr=0.05] Epoch 1300/4000: train_loss=0.0609  test_loss=3.3555  λ_max=61.3390\n",
      "[SGD | lr=0.05] Epoch 1301/4000: train_loss=0.0608  test_loss=3.3568  λ_max=62.2161\n",
      "[SGD | lr=0.05] Epoch 1302/4000: train_loss=0.0607  test_loss=3.3580  λ_max=63.0832\n",
      "[SGD | lr=0.05] Epoch 1303/4000: train_loss=0.0606  test_loss=3.3584  λ_max=63.7539\n",
      "[SGD | lr=0.05] Epoch 1304/4000: train_loss=0.0606  test_loss=3.3592  λ_max=61.1955\n",
      "[SGD | lr=0.05] Epoch 1305/4000: train_loss=0.0605  test_loss=3.3609  λ_max=61.4479\n",
      "[SGD | lr=0.05] Epoch 1306/4000: train_loss=0.0604  test_loss=3.3623  λ_max=61.2338\n",
      "[SGD | lr=0.05] Iter 20900: loss=0.0599\n",
      "[SGD | lr=0.05] Epoch 1307/4000: train_loss=0.0603  test_loss=3.3617  λ_max=61.9120\n",
      "[SGD | lr=0.05] Epoch 1308/4000: train_loss=0.0602  test_loss=3.3627  λ_max=62.7325\n",
      "[SGD | lr=0.05] Epoch 1309/4000: train_loss=0.0601  test_loss=3.3635  λ_max=58.9908\n",
      "[SGD | lr=0.05] Epoch 1310/4000: train_loss=0.0601  test_loss=3.3637  λ_max=62.3479\n",
      "[SGD | lr=0.05] Epoch 1311/4000: train_loss=0.0600  test_loss=3.3652  λ_max=62.5345\n",
      "[SGD | lr=0.05] Epoch 1312/4000: train_loss=0.0599  test_loss=3.3665  λ_max=61.3152\n",
      "[SGD | lr=0.05] Iter 21000: loss=0.0585\n",
      "[SGD | lr=0.05] Epoch 1313/4000: train_loss=0.0598  test_loss=3.3668  λ_max=61.1189\n",
      "[SGD | lr=0.05] Epoch 1314/4000: train_loss=0.0597  test_loss=3.3673  λ_max=63.3549\n",
      "[SGD | lr=0.05] Epoch 1315/4000: train_loss=0.0596  test_loss=3.3677  λ_max=62.8624\n",
      "[SGD | lr=0.05] Epoch 1316/4000: train_loss=0.0596  test_loss=3.3686  λ_max=60.9501\n",
      "[SGD | lr=0.05] Epoch 1317/4000: train_loss=0.0595  test_loss=3.3696  λ_max=63.1345\n",
      "[SGD | lr=0.05] Epoch 1318/4000: train_loss=0.0594  test_loss=3.3702  λ_max=63.3562\n",
      "[SGD | lr=0.05] Iter 21100: loss=0.0590\n",
      "[SGD | lr=0.05] Epoch 1319/4000: train_loss=0.0593  test_loss=3.3709  λ_max=63.6549\n",
      "[SGD | lr=0.05] Epoch 1320/4000: train_loss=0.0592  test_loss=3.3712  λ_max=61.4266\n",
      "[SGD | lr=0.05] Epoch 1321/4000: train_loss=0.0592  test_loss=3.3724  λ_max=62.0540\n",
      "[SGD | lr=0.05] Epoch 1322/4000: train_loss=0.0591  test_loss=3.3731  λ_max=63.6324\n",
      "[SGD | lr=0.05] Epoch 1323/4000: train_loss=0.0590  test_loss=3.3741  λ_max=61.9916\n",
      "[SGD | lr=0.05] Epoch 1324/4000: train_loss=0.0589  test_loss=3.3749  λ_max=63.0224\n",
      "[SGD | lr=0.05] Iter 21200: loss=0.0597\n",
      "[SGD | lr=0.05] Epoch 1325/4000: train_loss=0.0589  test_loss=3.3753  λ_max=63.7265\n",
      "[SGD | lr=0.05] Epoch 1326/4000: train_loss=0.0587  test_loss=3.3765  λ_max=62.5834\n",
      "[SGD | lr=0.05] Epoch 1327/4000: train_loss=0.0587  test_loss=3.3773  λ_max=62.4089\n",
      "[SGD | lr=0.05] Epoch 1328/4000: train_loss=0.0586  test_loss=3.3776  λ_max=62.2186\n",
      "[SGD | lr=0.05] Epoch 1329/4000: train_loss=0.0585  test_loss=3.3786  λ_max=62.6568\n",
      "[SGD | lr=0.05] Epoch 1330/4000: train_loss=0.0584  test_loss=3.3791  λ_max=61.9213\n",
      "[SGD | lr=0.05] Epoch 1331/4000: train_loss=0.0583  test_loss=3.3807  λ_max=63.0650\n",
      "[SGD | lr=0.05] Iter 21300: loss=0.0569\n",
      "[SGD | lr=0.05] Epoch 1332/4000: train_loss=0.0583  test_loss=3.3807  λ_max=63.0109\n",
      "[SGD | lr=0.05] Epoch 1333/4000: train_loss=0.0582  test_loss=3.3814  λ_max=63.1441\n",
      "[SGD | lr=0.05] Epoch 1334/4000: train_loss=0.0581  test_loss=3.3822  λ_max=63.5573\n",
      "[SGD | lr=0.05] Epoch 1335/4000: train_loss=0.0580  test_loss=3.3838  λ_max=63.0795\n",
      "[SGD | lr=0.05] Epoch 1336/4000: train_loss=0.0580  test_loss=3.3840  λ_max=61.6879\n",
      "[SGD | lr=0.05] Epoch 1337/4000: train_loss=0.0579  test_loss=3.3851  λ_max=62.7651\n",
      "[SGD | lr=0.05] Iter 21400: loss=0.0585\n",
      "[SGD | lr=0.05] Epoch 1338/4000: train_loss=0.0578  test_loss=3.3852  λ_max=62.6848\n",
      "[SGD | lr=0.05] Epoch 1339/4000: train_loss=0.0577  test_loss=3.3864  λ_max=62.2454\n",
      "[SGD | lr=0.05] Epoch 1340/4000: train_loss=0.0576  test_loss=3.3871  λ_max=63.8850\n",
      "[SGD | lr=0.05] Epoch 1341/4000: train_loss=0.0576  test_loss=3.3878  λ_max=64.0498\n",
      "[SGD | lr=0.05] Epoch 1342/4000: train_loss=0.0575  test_loss=3.3881  λ_max=61.9683\n",
      "[SGD | lr=0.05] Epoch 1343/4000: train_loss=0.0574  test_loss=3.3888  λ_max=62.0051\n",
      "[SGD | lr=0.05] Iter 21500: loss=0.0575\n",
      "[SGD | lr=0.05] Epoch 1344/4000: train_loss=0.0574  test_loss=3.3897  λ_max=63.7263\n",
      "[SGD | lr=0.05] Epoch 1345/4000: train_loss=0.0572  test_loss=3.3903  λ_max=62.6623\n",
      "[SGD | lr=0.05] Epoch 1346/4000: train_loss=0.0572  test_loss=3.3915  λ_max=63.3186\n",
      "[SGD | lr=0.05] Epoch 1347/4000: train_loss=0.0571  test_loss=3.3924  λ_max=61.4094\n",
      "[SGD | lr=0.05] Epoch 1348/4000: train_loss=0.0570  test_loss=3.3926  λ_max=63.2649\n",
      "[SGD | lr=0.05] Epoch 1349/4000: train_loss=0.0569  test_loss=3.3927  λ_max=63.1679\n",
      "[SGD | lr=0.05] Iter 21600: loss=0.0562\n",
      "[SGD | lr=0.05] Epoch 1350/4000: train_loss=0.0568  test_loss=3.3940  λ_max=64.5443\n",
      "[SGD | lr=0.05] Epoch 1351/4000: train_loss=0.0567  test_loss=3.3948  λ_max=62.6472\n",
      "[SGD | lr=0.05] Epoch 1352/4000: train_loss=0.0567  test_loss=3.3952  λ_max=64.3693\n",
      "[SGD | lr=0.05] Epoch 1353/4000: train_loss=0.0566  test_loss=3.3955  λ_max=64.4473\n",
      "[SGD | lr=0.05] Epoch 1354/4000: train_loss=0.0565  test_loss=3.3971  λ_max=63.3991\n",
      "[SGD | lr=0.05] Epoch 1355/4000: train_loss=0.0565  test_loss=3.3984  λ_max=62.5157\n",
      "[SGD | lr=0.05] Epoch 1356/4000: train_loss=0.0564  test_loss=3.3988  λ_max=63.0058\n",
      "[SGD | lr=0.05] Iter 21700: loss=0.0574\n",
      "[SGD | lr=0.05] Epoch 1357/4000: train_loss=0.0564  test_loss=3.3989  λ_max=64.0184\n",
      "[SGD | lr=0.05] Epoch 1358/4000: train_loss=0.0562  test_loss=3.4009  λ_max=62.7670\n",
      "[SGD | lr=0.05] Epoch 1359/4000: train_loss=0.0562  test_loss=3.4009  λ_max=63.2352\n",
      "[SGD | lr=0.05] Epoch 1360/4000: train_loss=0.0561  test_loss=3.4020  λ_max=64.2586\n",
      "[SGD | lr=0.05] Epoch 1361/4000: train_loss=0.0560  test_loss=3.4031  λ_max=61.0514\n",
      "[SGD | lr=0.05] Epoch 1362/4000: train_loss=0.0560  test_loss=3.4037  λ_max=63.6063\n",
      "[SGD | lr=0.05] Iter 21800: loss=0.0558\n",
      "[SGD | lr=0.05] Epoch 1363/4000: train_loss=0.0559  test_loss=3.4040  λ_max=64.2949\n",
      "[SGD | lr=0.05] Epoch 1364/4000: train_loss=0.0558  test_loss=3.4046  λ_max=64.3276\n",
      "[SGD | lr=0.05] Epoch 1365/4000: train_loss=0.0558  test_loss=3.4052  λ_max=64.3424\n",
      "[SGD | lr=0.05] Epoch 1366/4000: train_loss=0.0557  test_loss=3.4059  λ_max=63.8242\n",
      "[SGD | lr=0.05] Epoch 1367/4000: train_loss=0.0556  test_loss=3.4073  λ_max=64.2180\n",
      "[SGD | lr=0.05] Epoch 1368/4000: train_loss=0.0555  test_loss=3.4078  λ_max=64.9379\n",
      "[SGD | lr=0.05] Iter 21900: loss=0.0550\n",
      "[SGD | lr=0.05] Epoch 1369/4000: train_loss=0.0555  test_loss=3.4083  λ_max=65.3072\n",
      "[SGD | lr=0.05] Epoch 1370/4000: train_loss=0.0554  test_loss=3.4092  λ_max=64.6494\n",
      "[SGD | lr=0.05] Epoch 1371/4000: train_loss=0.0553  test_loss=3.4096  λ_max=64.7898\n",
      "[SGD | lr=0.05] Epoch 1372/4000: train_loss=0.0552  test_loss=3.4111  λ_max=61.4659\n",
      "[SGD | lr=0.05] Epoch 1373/4000: train_loss=0.0551  test_loss=3.4110  λ_max=62.7295\n",
      "[SGD | lr=0.05] Epoch 1374/4000: train_loss=0.0551  test_loss=3.4114  λ_max=63.9982\n",
      "[SGD | lr=0.05] Iter 22000: loss=0.0559\n",
      "[SGD | lr=0.05] Epoch 1375/4000: train_loss=0.0550  test_loss=3.4126  λ_max=63.2113\n",
      "[SGD | lr=0.05] Epoch 1376/4000: train_loss=0.0549  test_loss=3.4132  λ_max=65.3572\n",
      "[SGD | lr=0.05] Epoch 1377/4000: train_loss=0.0549  test_loss=3.4139  λ_max=61.3646\n",
      "[SGD | lr=0.05] Epoch 1378/4000: train_loss=0.0548  test_loss=3.4147  λ_max=62.7304\n",
      "[SGD | lr=0.05] Epoch 1379/4000: train_loss=0.0547  test_loss=3.4154  λ_max=62.5345\n",
      "[SGD | lr=0.05] Epoch 1380/4000: train_loss=0.0546  test_loss=3.4165  λ_max=63.7148\n",
      "[SGD | lr=0.05] Epoch 1381/4000: train_loss=0.0546  test_loss=3.4165  λ_max=62.8911\n",
      "[SGD | lr=0.05] Iter 22100: loss=0.0537\n",
      "[SGD | lr=0.05] Epoch 1382/4000: train_loss=0.0545  test_loss=3.4176  λ_max=64.0116\n",
      "[SGD | lr=0.05] Epoch 1383/4000: train_loss=0.0544  test_loss=3.4186  λ_max=61.1225\n",
      "[SGD | lr=0.05] Epoch 1384/4000: train_loss=0.0544  test_loss=3.4185  λ_max=64.0953\n",
      "[SGD | lr=0.05] Epoch 1385/4000: train_loss=0.0543  test_loss=3.4202  λ_max=65.5232\n",
      "[SGD | lr=0.05] Epoch 1386/4000: train_loss=0.0542  test_loss=3.4204  λ_max=64.2625\n",
      "[SGD | lr=0.05] Epoch 1387/4000: train_loss=0.0542  test_loss=3.4213  λ_max=65.4082\n",
      "[SGD | lr=0.05] Iter 22200: loss=0.0544\n",
      "[SGD | lr=0.05] Epoch 1388/4000: train_loss=0.0541  test_loss=3.4222  λ_max=64.8860\n",
      "[SGD | lr=0.05] Epoch 1389/4000: train_loss=0.0540  test_loss=3.4226  λ_max=62.7673\n",
      "[SGD | lr=0.05] Epoch 1390/4000: train_loss=0.0540  test_loss=3.4233  λ_max=64.2657\n",
      "[SGD | lr=0.05] Epoch 1391/4000: train_loss=0.0539  test_loss=3.4239  λ_max=62.5128\n",
      "[SGD | lr=0.05] Epoch 1392/4000: train_loss=0.0538  test_loss=3.4249  λ_max=63.5046\n",
      "[SGD | lr=0.05] Epoch 1393/4000: train_loss=0.0538  test_loss=3.4261  λ_max=65.4371\n",
      "[SGD | lr=0.05] Iter 22300: loss=0.0541\n",
      "[SGD | lr=0.05] Epoch 1394/4000: train_loss=0.0537  test_loss=3.4268  λ_max=65.4678\n",
      "[SGD | lr=0.05] Epoch 1395/4000: train_loss=0.0536  test_loss=3.4268  λ_max=64.8250\n",
      "[SGD | lr=0.05] Epoch 1396/4000: train_loss=0.0535  test_loss=3.4276  λ_max=65.6006\n",
      "[SGD | lr=0.05] Epoch 1397/4000: train_loss=0.0535  test_loss=3.4281  λ_max=65.0836\n",
      "[SGD | lr=0.05] Epoch 1398/4000: train_loss=0.0534  test_loss=3.4288  λ_max=64.5580\n",
      "[SGD | lr=0.05] Epoch 1399/4000: train_loss=0.0533  test_loss=3.4300  λ_max=62.3703\n",
      "[SGD | lr=0.05] Iter 22400: loss=0.0534\n",
      "[SGD | lr=0.05] Epoch 1400/4000: train_loss=0.0533  test_loss=3.4307  λ_max=63.9623\n",
      "[SGD | lr=0.05] Epoch 1401/4000: train_loss=0.0532  test_loss=3.4312  λ_max=64.1102\n",
      "[SGD | lr=0.05] Epoch 1402/4000: train_loss=0.0531  test_loss=3.4318  λ_max=62.7910\n",
      "[SGD | lr=0.05] Epoch 1403/4000: train_loss=0.0531  test_loss=3.4334  λ_max=66.4224\n",
      "[SGD | lr=0.05] Epoch 1404/4000: train_loss=0.0530  test_loss=3.4333  λ_max=64.4920\n",
      "[SGD | lr=0.05] Epoch 1405/4000: train_loss=0.0529  test_loss=3.4344  λ_max=64.1530\n",
      "[SGD | lr=0.05] Epoch 1406/4000: train_loss=0.0529  test_loss=3.4348  λ_max=64.0231\n",
      "[SGD | lr=0.05] Iter 22500: loss=0.0530\n",
      "[SGD | lr=0.05] Epoch 1407/4000: train_loss=0.0528  test_loss=3.4357  λ_max=65.1800\n",
      "[SGD | lr=0.05] Epoch 1408/4000: train_loss=0.0527  test_loss=3.4360  λ_max=65.5877\n",
      "[SGD | lr=0.05] Epoch 1409/4000: train_loss=0.0527  test_loss=3.4364  λ_max=65.1371\n",
      "[SGD | lr=0.05] Epoch 1410/4000: train_loss=0.0526  test_loss=3.4373  λ_max=63.5107\n",
      "[SGD | lr=0.05] Epoch 1411/4000: train_loss=0.0525  test_loss=3.4380  λ_max=65.2137\n",
      "[SGD | lr=0.05] Epoch 1412/4000: train_loss=0.0524  test_loss=3.4386  λ_max=64.1437\n",
      "[SGD | lr=0.05] Iter 22600: loss=0.0523\n",
      "[SGD | lr=0.05] Epoch 1413/4000: train_loss=0.0524  test_loss=3.4402  λ_max=63.7601\n",
      "[SGD | lr=0.05] Epoch 1414/4000: train_loss=0.0524  test_loss=3.4402  λ_max=63.4634\n",
      "[SGD | lr=0.05] Epoch 1415/4000: train_loss=0.0523  test_loss=3.4415  λ_max=63.5414\n",
      "[SGD | lr=0.05] Epoch 1416/4000: train_loss=0.0522  test_loss=3.4422  λ_max=64.3072\n",
      "[SGD | lr=0.05] Epoch 1417/4000: train_loss=0.0521  test_loss=3.4428  λ_max=65.4737\n",
      "[SGD | lr=0.05] Epoch 1418/4000: train_loss=0.0521  test_loss=3.4432  λ_max=65.2333\n",
      "[SGD | lr=0.05] Iter 22700: loss=0.0511\n",
      "[SGD | lr=0.05] Epoch 1419/4000: train_loss=0.0520  test_loss=3.4442  λ_max=64.9054\n",
      "[SGD | lr=0.05] Epoch 1420/4000: train_loss=0.0519  test_loss=3.4446  λ_max=63.6107\n",
      "[SGD | lr=0.05] Epoch 1421/4000: train_loss=0.0519  test_loss=3.4447  λ_max=65.7526\n",
      "[SGD | lr=0.05] Epoch 1422/4000: train_loss=0.0518  test_loss=3.4460  λ_max=65.9070\n",
      "[SGD | lr=0.05] Epoch 1423/4000: train_loss=0.0517  test_loss=3.4467  λ_max=62.7218\n",
      "[SGD | lr=0.05] Epoch 1424/4000: train_loss=0.0517  test_loss=3.4472  λ_max=64.2254\n",
      "[SGD | lr=0.05] Iter 22800: loss=0.0521\n",
      "[SGD | lr=0.05] Epoch 1425/4000: train_loss=0.0516  test_loss=3.4489  λ_max=64.3958\n",
      "[SGD | lr=0.05] Epoch 1426/4000: train_loss=0.0515  test_loss=3.4489  λ_max=65.1975\n",
      "[SGD | lr=0.05] Epoch 1427/4000: train_loss=0.0515  test_loss=3.4489  λ_max=67.2369\n",
      "[SGD | lr=0.05] Epoch 1428/4000: train_loss=0.0514  test_loss=3.4497  λ_max=63.3111\n",
      "[SGD | lr=0.05] Epoch 1429/4000: train_loss=0.0513  test_loss=3.4511  λ_max=64.5683\n",
      "[SGD | lr=0.05] Epoch 1430/4000: train_loss=0.0513  test_loss=3.4514  λ_max=63.4326\n",
      "[SGD | lr=0.05] Epoch 1431/4000: train_loss=0.0512  test_loss=3.4518  λ_max=63.7066\n",
      "[SGD | lr=0.05] Iter 22900: loss=0.0522\n",
      "[SGD | lr=0.05] Epoch 1432/4000: train_loss=0.0511  test_loss=3.4529  λ_max=64.5274\n",
      "[SGD | lr=0.05] Epoch 1433/4000: train_loss=0.0511  test_loss=3.4537  λ_max=66.3530\n",
      "[SGD | lr=0.05] Epoch 1434/4000: train_loss=0.0510  test_loss=3.4536  λ_max=64.3786\n",
      "[SGD | lr=0.05] Epoch 1435/4000: train_loss=0.0510  test_loss=3.4551  λ_max=65.3219\n",
      "[SGD | lr=0.05] Epoch 1436/4000: train_loss=0.0509  test_loss=3.4559  λ_max=65.7356\n",
      "[SGD | lr=0.05] Epoch 1437/4000: train_loss=0.0508  test_loss=3.4567  λ_max=65.0230\n",
      "[SGD | lr=0.05] Iter 23000: loss=0.0508\n",
      "[SGD | lr=0.05] Epoch 1438/4000: train_loss=0.0508  test_loss=3.4574  λ_max=65.3666\n",
      "[SGD | lr=0.05] Epoch 1439/4000: train_loss=0.0507  test_loss=3.4575  λ_max=63.8673\n",
      "[SGD | lr=0.05] Epoch 1440/4000: train_loss=0.0506  test_loss=3.4582  λ_max=64.1578\n",
      "[SGD | lr=0.05] Epoch 1441/4000: train_loss=0.0506  test_loss=3.4591  λ_max=66.3453\n",
      "[SGD | lr=0.05] Epoch 1442/4000: train_loss=0.0505  test_loss=3.4589  λ_max=65.3723\n",
      "[SGD | lr=0.05] Epoch 1443/4000: train_loss=0.0505  test_loss=3.4606  λ_max=67.1411\n",
      "[SGD | lr=0.05] Iter 23100: loss=0.0503\n",
      "[SGD | lr=0.05] Epoch 1444/4000: train_loss=0.0504  test_loss=3.4606  λ_max=65.8548\n",
      "[SGD | lr=0.05] Epoch 1445/4000: train_loss=0.0503  test_loss=3.4612  λ_max=65.5225\n",
      "[SGD | lr=0.05] Epoch 1446/4000: train_loss=0.0503  test_loss=3.4623  λ_max=64.3991\n",
      "[SGD | lr=0.05] Epoch 1447/4000: train_loss=0.0503  test_loss=3.4631  λ_max=65.7003\n",
      "[SGD | lr=0.05] Epoch 1448/4000: train_loss=0.0502  test_loss=3.4635  λ_max=66.2997\n",
      "[SGD | lr=0.05] Epoch 1449/4000: train_loss=0.0501  test_loss=3.4642  λ_max=64.6323\n",
      "[SGD | lr=0.05] Iter 23200: loss=0.0495\n",
      "[SGD | lr=0.05] Epoch 1450/4000: train_loss=0.0500  test_loss=3.4651  λ_max=67.2323\n",
      "[SGD | lr=0.05] Epoch 1451/4000: train_loss=0.0500  test_loss=3.4661  λ_max=65.7420\n",
      "[SGD | lr=0.05] Epoch 1452/4000: train_loss=0.0499  test_loss=3.4665  λ_max=65.7261\n",
      "[SGD | lr=0.05] Epoch 1453/4000: train_loss=0.0499  test_loss=3.4670  λ_max=66.4046\n",
      "[SGD | lr=0.05] Epoch 1454/4000: train_loss=0.0498  test_loss=3.4682  λ_max=66.0695\n",
      "[SGD | lr=0.05] Epoch 1455/4000: train_loss=0.0497  test_loss=3.4689  λ_max=66.0312\n",
      "[SGD | lr=0.05] Epoch 1456/4000: train_loss=0.0497  test_loss=3.4692  λ_max=66.1443\n",
      "[SGD | lr=0.05] Iter 23300: loss=0.0498\n",
      "[SGD | lr=0.05] Epoch 1457/4000: train_loss=0.0496  test_loss=3.4694  λ_max=65.2474\n",
      "[SGD | lr=0.05] Epoch 1458/4000: train_loss=0.0496  test_loss=3.4700  λ_max=65.2507\n",
      "[SGD | lr=0.05] Epoch 1459/4000: train_loss=0.0495  test_loss=3.4711  λ_max=62.7954\n",
      "[SGD | lr=0.05] Epoch 1460/4000: train_loss=0.0494  test_loss=3.4719  λ_max=67.2758\n",
      "[SGD | lr=0.05] Epoch 1461/4000: train_loss=0.0494  test_loss=3.4726  λ_max=64.8930\n",
      "[SGD | lr=0.05] Epoch 1462/4000: train_loss=0.0493  test_loss=3.4737  λ_max=66.9232\n",
      "[SGD | lr=0.05] Iter 23400: loss=0.0491\n",
      "[SGD | lr=0.05] Epoch 1463/4000: train_loss=0.0493  test_loss=3.4740  λ_max=65.9629\n",
      "[SGD | lr=0.05] Epoch 1464/4000: train_loss=0.0492  test_loss=3.4749  λ_max=64.7655\n",
      "[SGD | lr=0.05] Epoch 1465/4000: train_loss=0.0491  test_loss=3.4754  λ_max=68.3612\n",
      "[SGD | lr=0.05] Epoch 1466/4000: train_loss=0.0491  test_loss=3.4767  λ_max=66.5683\n",
      "[SGD | lr=0.05] Epoch 1467/4000: train_loss=0.0490  test_loss=3.4767  λ_max=65.9565\n",
      "[SGD | lr=0.05] Epoch 1468/4000: train_loss=0.0490  test_loss=3.4778  λ_max=66.1219\n",
      "[SGD | lr=0.05] Iter 23500: loss=0.0489\n",
      "[SGD | lr=0.05] Epoch 1469/4000: train_loss=0.0489  test_loss=3.4787  λ_max=66.1687\n",
      "[SGD | lr=0.05] Epoch 1470/4000: train_loss=0.0489  test_loss=3.4793  λ_max=67.3239\n",
      "[SGD | lr=0.05] Epoch 1471/4000: train_loss=0.0488  test_loss=3.4794  λ_max=68.0454\n",
      "[SGD | lr=0.05] Epoch 1472/4000: train_loss=0.0487  test_loss=3.4798  λ_max=63.4026\n",
      "[SGD | lr=0.05] Epoch 1473/4000: train_loss=0.0487  test_loss=3.4804  λ_max=65.6041\n",
      "[SGD | lr=0.05] Epoch 1474/4000: train_loss=0.0486  test_loss=3.4815  λ_max=65.0776\n",
      "[SGD | lr=0.05] Iter 23600: loss=0.0483\n",
      "[SGD | lr=0.05] Epoch 1475/4000: train_loss=0.0486  test_loss=3.4824  λ_max=66.4073\n",
      "[SGD | lr=0.05] Epoch 1476/4000: train_loss=0.0485  test_loss=3.4829  λ_max=67.1434\n",
      "[SGD | lr=0.05] Epoch 1477/4000: train_loss=0.0485  test_loss=3.4842  λ_max=65.7929\n",
      "[SGD | lr=0.05] Epoch 1478/4000: train_loss=0.0484  test_loss=3.4843  λ_max=68.6756\n",
      "[SGD | lr=0.05] Epoch 1479/4000: train_loss=0.0483  test_loss=3.4847  λ_max=67.4032\n",
      "[SGD | lr=0.05] Epoch 1480/4000: train_loss=0.0483  test_loss=3.4854  λ_max=66.2451\n",
      "[SGD | lr=0.05] Epoch 1481/4000: train_loss=0.0482  test_loss=3.4859  λ_max=65.3510\n",
      "[SGD | lr=0.05] Iter 23700: loss=0.0492\n",
      "[SGD | lr=0.05] Epoch 1482/4000: train_loss=0.0482  test_loss=3.4864  λ_max=66.0499\n",
      "[SGD | lr=0.05] Epoch 1483/4000: train_loss=0.0481  test_loss=3.4874  λ_max=65.9970\n",
      "[SGD | lr=0.05] Epoch 1484/4000: train_loss=0.0480  test_loss=3.4879  λ_max=67.9697\n",
      "[SGD | lr=0.05] Epoch 1485/4000: train_loss=0.0480  test_loss=3.4886  λ_max=65.8159\n",
      "[SGD | lr=0.05] Epoch 1486/4000: train_loss=0.0479  test_loss=3.4888  λ_max=66.5806\n",
      "[SGD | lr=0.05] Epoch 1487/4000: train_loss=0.0479  test_loss=3.4897  λ_max=66.9337\n",
      "[SGD | lr=0.05] Iter 23800: loss=0.0478\n",
      "[SGD | lr=0.05] Epoch 1488/4000: train_loss=0.0478  test_loss=3.4903  λ_max=66.1971\n",
      "[SGD | lr=0.05] Epoch 1489/4000: train_loss=0.0478  test_loss=3.4910  λ_max=66.5701\n",
      "[SGD | lr=0.05] Epoch 1490/4000: train_loss=0.0477  test_loss=3.4917  λ_max=64.8465\n",
      "[SGD | lr=0.05] Epoch 1491/4000: train_loss=0.0477  test_loss=3.4924  λ_max=68.2339\n",
      "[SGD | lr=0.05] Epoch 1492/4000: train_loss=0.0476  test_loss=3.4938  λ_max=67.7552\n",
      "[SGD | lr=0.05] Epoch 1493/4000: train_loss=0.0475  test_loss=3.4939  λ_max=65.8238\n",
      "[SGD | lr=0.05] Iter 23900: loss=0.0471\n",
      "[SGD | lr=0.05] Epoch 1494/4000: train_loss=0.0475  test_loss=3.4946  λ_max=68.5541\n",
      "[SGD | lr=0.05] Epoch 1495/4000: train_loss=0.0474  test_loss=3.4954  λ_max=65.0270\n",
      "[SGD | lr=0.05] Epoch 1496/4000: train_loss=0.0474  test_loss=3.4959  λ_max=64.7479\n",
      "[SGD | lr=0.05] Epoch 1497/4000: train_loss=0.0473  test_loss=3.4962  λ_max=66.2522\n",
      "[SGD | lr=0.05] Epoch 1498/4000: train_loss=0.0472  test_loss=3.4972  λ_max=66.9084\n",
      "[SGD | lr=0.05] Epoch 1499/4000: train_loss=0.0472  test_loss=3.4972  λ_max=66.4712\n",
      "[SGD | lr=0.05] Iter 24000: loss=0.0485\n",
      "[SGD | lr=0.05] Epoch 1500/4000: train_loss=0.0472  test_loss=3.4985  λ_max=66.5113\n",
      "[SGD | lr=0.05] Epoch 1501/4000: train_loss=0.0471  test_loss=3.4993  λ_max=64.2985\n",
      "[SGD | lr=0.05] Epoch 1502/4000: train_loss=0.0470  test_loss=3.4997  λ_max=67.7974\n",
      "[SGD | lr=0.05] Epoch 1503/4000: train_loss=0.0470  test_loss=3.5005  λ_max=64.7754\n",
      "[SGD | lr=0.05] Epoch 1504/4000: train_loss=0.0469  test_loss=3.5013  λ_max=65.8563\n",
      "[SGD | lr=0.05] Epoch 1505/4000: train_loss=0.0469  test_loss=3.5021  λ_max=65.9968\n",
      "[SGD | lr=0.05] Epoch 1506/4000: train_loss=0.0468  test_loss=3.5021  λ_max=65.5289\n",
      "[SGD | lr=0.05] Iter 24100: loss=0.0463\n",
      "[SGD | lr=0.05] Epoch 1507/4000: train_loss=0.0468  test_loss=3.5030  λ_max=65.7626\n",
      "[SGD | lr=0.05] Epoch 1508/4000: train_loss=0.0467  test_loss=3.5034  λ_max=65.5174\n",
      "[SGD | lr=0.05] Epoch 1509/4000: train_loss=0.0467  test_loss=3.5043  λ_max=67.2617\n",
      "[SGD | lr=0.05] Epoch 1510/4000: train_loss=0.0466  test_loss=3.5046  λ_max=65.9820\n",
      "[SGD | lr=0.05] Epoch 1511/4000: train_loss=0.0465  test_loss=3.5054  λ_max=68.1371\n",
      "[SGD | lr=0.05] Epoch 1512/4000: train_loss=0.0465  test_loss=3.5062  λ_max=67.3424\n",
      "[SGD | lr=0.05] Iter 24200: loss=0.0454\n",
      "[SGD | lr=0.05] Epoch 1513/4000: train_loss=0.0464  test_loss=3.5070  λ_max=67.3903\n",
      "[SGD | lr=0.05] Epoch 1514/4000: train_loss=0.0464  test_loss=3.5071  λ_max=66.2766\n",
      "[SGD | lr=0.05] Epoch 1515/4000: train_loss=0.0463  test_loss=3.5074  λ_max=67.1616\n",
      "[SGD | lr=0.05] Epoch 1516/4000: train_loss=0.0463  test_loss=3.5092  λ_max=65.5023\n",
      "[SGD | lr=0.05] Epoch 1517/4000: train_loss=0.0462  test_loss=3.5090  λ_max=65.8450\n",
      "[SGD | lr=0.05] Epoch 1518/4000: train_loss=0.0462  test_loss=3.5099  λ_max=66.9465\n",
      "[SGD | lr=0.05] Iter 24300: loss=0.0468\n",
      "[SGD | lr=0.05] Epoch 1519/4000: train_loss=0.0461  test_loss=3.5109  λ_max=64.0699\n",
      "[SGD | lr=0.05] Epoch 1520/4000: train_loss=0.0461  test_loss=3.5110  λ_max=66.6826\n",
      "[SGD | lr=0.05] Epoch 1521/4000: train_loss=0.0460  test_loss=3.5112  λ_max=66.9296\n",
      "[SGD | lr=0.05] Epoch 1522/4000: train_loss=0.0460  test_loss=3.5128  λ_max=66.7184\n",
      "[SGD | lr=0.05] Epoch 1523/4000: train_loss=0.0459  test_loss=3.5137  λ_max=66.6191\n",
      "[SGD | lr=0.05] Epoch 1524/4000: train_loss=0.0459  test_loss=3.5139  λ_max=67.5776\n",
      "[SGD | lr=0.05] Iter 24400: loss=0.0463\n",
      "[SGD | lr=0.05] Epoch 1525/4000: train_loss=0.0458  test_loss=3.5145  λ_max=68.5162\n",
      "[SGD | lr=0.05] Epoch 1526/4000: train_loss=0.0457  test_loss=3.5152  λ_max=67.3692\n",
      "[SGD | lr=0.05] Epoch 1527/4000: train_loss=0.0457  test_loss=3.5152  λ_max=68.5567\n",
      "[SGD | lr=0.05] Epoch 1528/4000: train_loss=0.0457  test_loss=3.5162  λ_max=68.2885\n",
      "[SGD | lr=0.05] Epoch 1529/4000: train_loss=0.0456  test_loss=3.5166  λ_max=64.8248\n",
      "[SGD | lr=0.05] Epoch 1530/4000: train_loss=0.0455  test_loss=3.5171  λ_max=68.3225\n",
      "[SGD | lr=0.05] Epoch 1531/4000: train_loss=0.0455  test_loss=3.5184  λ_max=67.1113\n",
      "[SGD | lr=0.05] Iter 24500: loss=0.0455\n",
      "[SGD | lr=0.05] Epoch 1532/4000: train_loss=0.0455  test_loss=3.5191  λ_max=68.7782\n",
      "[SGD | lr=0.05] Epoch 1533/4000: train_loss=0.0454  test_loss=3.5195  λ_max=66.3153\n",
      "[SGD | lr=0.05] Epoch 1534/4000: train_loss=0.0454  test_loss=3.5197  λ_max=67.9285\n",
      "[SGD | lr=0.05] Epoch 1535/4000: train_loss=0.0453  test_loss=3.5214  λ_max=67.1057\n",
      "[SGD | lr=0.05] Epoch 1536/4000: train_loss=0.0452  test_loss=3.5210  λ_max=65.2295\n",
      "[SGD | lr=0.05] Epoch 1537/4000: train_loss=0.0452  test_loss=3.5218  λ_max=66.5909\n",
      "[SGD | lr=0.05] Iter 24600: loss=0.0452\n",
      "[SGD | lr=0.05] Epoch 1538/4000: train_loss=0.0452  test_loss=3.5223  λ_max=67.6798\n",
      "[SGD | lr=0.05] Epoch 1539/4000: train_loss=0.0451  test_loss=3.5231  λ_max=66.7173\n",
      "[SGD | lr=0.05] Epoch 1540/4000: train_loss=0.0450  test_loss=3.5239  λ_max=67.1609\n",
      "[SGD | lr=0.05] Epoch 1541/4000: train_loss=0.0450  test_loss=3.5245  λ_max=65.4679\n",
      "[SGD | lr=0.05] Epoch 1542/4000: train_loss=0.0449  test_loss=3.5251  λ_max=65.8981\n",
      "[SGD | lr=0.05] Epoch 1543/4000: train_loss=0.0449  test_loss=3.5258  λ_max=66.1552\n",
      "[SGD | lr=0.05] Iter 24700: loss=0.0448\n",
      "[SGD | lr=0.05] Epoch 1544/4000: train_loss=0.0448  test_loss=3.5261  λ_max=66.8306\n",
      "[SGD | lr=0.05] Epoch 1545/4000: train_loss=0.0448  test_loss=3.5270  λ_max=68.6370\n",
      "[SGD | lr=0.05] Epoch 1546/4000: train_loss=0.0447  test_loss=3.5274  λ_max=68.8869\n",
      "[SGD | lr=0.05] Epoch 1547/4000: train_loss=0.0447  test_loss=3.5279  λ_max=67.6129\n",
      "[SGD | lr=0.05] Epoch 1548/4000: train_loss=0.0446  test_loss=3.5290  λ_max=65.9982\n",
      "[SGD | lr=0.05] Epoch 1549/4000: train_loss=0.0446  test_loss=3.5294  λ_max=68.0892\n",
      "[SGD | lr=0.05] Iter 24800: loss=0.0437\n",
      "[SGD | lr=0.05] Epoch 1550/4000: train_loss=0.0445  test_loss=3.5298  λ_max=67.1043\n",
      "[SGD | lr=0.05] Epoch 1551/4000: train_loss=0.0445  test_loss=3.5309  λ_max=66.2664\n",
      "[SGD | lr=0.05] Epoch 1552/4000: train_loss=0.0444  test_loss=3.5317  λ_max=65.5878\n",
      "[SGD | lr=0.05] Epoch 1553/4000: train_loss=0.0444  test_loss=3.5323  λ_max=66.6186\n",
      "[SGD | lr=0.05] Epoch 1554/4000: train_loss=0.0443  test_loss=3.5331  λ_max=68.2292\n",
      "[SGD | lr=0.05] Epoch 1555/4000: train_loss=0.0443  test_loss=3.5340  λ_max=67.9742\n",
      "[SGD | lr=0.05] Epoch 1556/4000: train_loss=0.0442  test_loss=3.5338  λ_max=68.0385\n",
      "[SGD | lr=0.05] Iter 24900: loss=0.0443\n",
      "[SGD | lr=0.05] Epoch 1557/4000: train_loss=0.0442  test_loss=3.5344  λ_max=67.7178\n",
      "[SGD | lr=0.05] Epoch 1558/4000: train_loss=0.0441  test_loss=3.5350  λ_max=68.0714\n",
      "[SGD | lr=0.05] Epoch 1559/4000: train_loss=0.0441  test_loss=3.5355  λ_max=67.3820\n",
      "[SGD | lr=0.05] Epoch 1560/4000: train_loss=0.0440  test_loss=3.5365  λ_max=69.0163\n",
      "[SGD | lr=0.05] Epoch 1561/4000: train_loss=0.0440  test_loss=3.5365  λ_max=66.9195\n",
      "[SGD | lr=0.05] Epoch 1562/4000: train_loss=0.0440  test_loss=3.5372  λ_max=69.1386\n",
      "[SGD | lr=0.05] Iter 25000: loss=0.0440\n",
      "[SGD | lr=0.05] Epoch 1563/4000: train_loss=0.0439  test_loss=3.5382  λ_max=68.6832\n",
      "[SGD | lr=0.05] Epoch 1564/4000: train_loss=0.0439  test_loss=3.5389  λ_max=67.0053\n",
      "[SGD | lr=0.05] Epoch 1565/4000: train_loss=0.0438  test_loss=3.5394  λ_max=68.9892\n",
      "[SGD | lr=0.05] Epoch 1566/4000: train_loss=0.0438  test_loss=3.5403  λ_max=67.8132\n",
      "[SGD | lr=0.05] Epoch 1567/4000: train_loss=0.0437  test_loss=3.5408  λ_max=68.5350\n",
      "[SGD | lr=0.05] Epoch 1568/4000: train_loss=0.0436  test_loss=3.5412  λ_max=69.1036\n",
      "[SGD | lr=0.05] Iter 25100: loss=0.0431\n",
      "[SGD | lr=0.05] Epoch 1569/4000: train_loss=0.0436  test_loss=3.5424  λ_max=66.3868\n",
      "[SGD | lr=0.05] Epoch 1570/4000: train_loss=0.0436  test_loss=3.5426  λ_max=67.5527\n",
      "[SGD | lr=0.05] Epoch 1571/4000: train_loss=0.0435  test_loss=3.5433  λ_max=66.7110\n",
      "[SGD | lr=0.05] Epoch 1572/4000: train_loss=0.0435  test_loss=3.5443  λ_max=68.8116\n",
      "[SGD | lr=0.05] Epoch 1573/4000: train_loss=0.0434  test_loss=3.5445  λ_max=68.3807\n",
      "[SGD | lr=0.05] Epoch 1574/4000: train_loss=0.0433  test_loss=3.5453  λ_max=67.3816\n",
      "[SGD | lr=0.05] Iter 25200: loss=0.0437\n",
      "[SGD | lr=0.05] Epoch 1575/4000: train_loss=0.0433  test_loss=3.5461  λ_max=69.3008\n",
      "[SGD | lr=0.05] Epoch 1576/4000: train_loss=0.0433  test_loss=3.5463  λ_max=67.0873\n",
      "[SGD | lr=0.05] Epoch 1577/4000: train_loss=0.0432  test_loss=3.5468  λ_max=68.1141\n",
      "[SGD | lr=0.05] Epoch 1578/4000: train_loss=0.0432  test_loss=3.5477  λ_max=67.1343\n",
      "[SGD | lr=0.05] Epoch 1579/4000: train_loss=0.0431  test_loss=3.5481  λ_max=69.5009\n",
      "[SGD | lr=0.05] Epoch 1580/4000: train_loss=0.0431  test_loss=3.5493  λ_max=66.3356\n",
      "[SGD | lr=0.05] Epoch 1581/4000: train_loss=0.0431  test_loss=3.5494  λ_max=67.9111\n",
      "[SGD | lr=0.05] Iter 25300: loss=0.0435\n",
      "[SGD | lr=0.05] Epoch 1582/4000: train_loss=0.0430  test_loss=3.5497  λ_max=66.9033\n",
      "[SGD | lr=0.05] Epoch 1583/4000: train_loss=0.0429  test_loss=3.5510  λ_max=68.4849\n",
      "[SGD | lr=0.05] Epoch 1584/4000: train_loss=0.0429  test_loss=3.5517  λ_max=69.4355\n",
      "[SGD | lr=0.05] Epoch 1585/4000: train_loss=0.0429  test_loss=3.5522  λ_max=68.2514\n",
      "[SGD | lr=0.05] Epoch 1586/4000: train_loss=0.0428  test_loss=3.5522  λ_max=69.5817\n",
      "[SGD | lr=0.05] Epoch 1587/4000: train_loss=0.0428  test_loss=3.5534  λ_max=65.4747\n",
      "[SGD | lr=0.05] Iter 25400: loss=0.0425\n",
      "[SGD | lr=0.05] Epoch 1588/4000: train_loss=0.0427  test_loss=3.5537  λ_max=69.4631\n",
      "[SGD | lr=0.05] Epoch 1589/4000: train_loss=0.0427  test_loss=3.5544  λ_max=66.3461\n",
      "[SGD | lr=0.05] Epoch 1590/4000: train_loss=0.0426  test_loss=3.5549  λ_max=67.0590\n",
      "[SGD | lr=0.05] Epoch 1591/4000: train_loss=0.0426  test_loss=3.5556  λ_max=68.1417\n",
      "[SGD | lr=0.05] Epoch 1592/4000: train_loss=0.0425  test_loss=3.5560  λ_max=69.4920\n",
      "[SGD | lr=0.05] Epoch 1593/4000: train_loss=0.0425  test_loss=3.5567  λ_max=67.9402\n",
      "[SGD | lr=0.05] Iter 25500: loss=0.0422\n",
      "[SGD | lr=0.05] Epoch 1594/4000: train_loss=0.0424  test_loss=3.5576  λ_max=65.4846\n",
      "[SGD | lr=0.05] Epoch 1595/4000: train_loss=0.0424  test_loss=3.5580  λ_max=68.9506\n",
      "[SGD | lr=0.05] Epoch 1596/4000: train_loss=0.0423  test_loss=3.5582  λ_max=69.7438\n",
      "[SGD | lr=0.05] Epoch 1597/4000: train_loss=0.0423  test_loss=3.5589  λ_max=67.2526\n",
      "[SGD | lr=0.05] Epoch 1598/4000: train_loss=0.0422  test_loss=3.5597  λ_max=69.5466\n",
      "[SGD | lr=0.05] Epoch 1599/4000: train_loss=0.0422  test_loss=3.5604  λ_max=67.8230\n",
      "[SGD | lr=0.05] Iter 25600: loss=0.0413\n",
      "[SGD | lr=0.05] Epoch 1600/4000: train_loss=0.0421  test_loss=3.5607  λ_max=67.5218\n",
      "[SGD | lr=0.05] Epoch 1601/4000: train_loss=0.0421  test_loss=3.5611  λ_max=67.4130\n",
      "[SGD | lr=0.05] Epoch 1602/4000: train_loss=0.0421  test_loss=3.5623  λ_max=68.3007\n",
      "[SGD | lr=0.05] Epoch 1603/4000: train_loss=0.0420  test_loss=3.5622  λ_max=69.1650\n",
      "[SGD | lr=0.05] Epoch 1604/4000: train_loss=0.0420  test_loss=3.5635  λ_max=68.7179\n",
      "[SGD | lr=0.05] Epoch 1605/4000: train_loss=0.0419  test_loss=3.5637  λ_max=67.8164\n",
      "[SGD | lr=0.05] Epoch 1606/4000: train_loss=0.0419  test_loss=3.5641  λ_max=70.3374\n",
      "[SGD | lr=0.05] Iter 25700: loss=0.0424\n",
      "[SGD | lr=0.05] Epoch 1607/4000: train_loss=0.0418  test_loss=3.5649  λ_max=68.4522\n",
      "[SGD | lr=0.05] Epoch 1608/4000: train_loss=0.0418  test_loss=3.5657  λ_max=67.3611\n",
      "[SGD | lr=0.05] Epoch 1609/4000: train_loss=0.0418  test_loss=3.5659  λ_max=68.1670\n",
      "[SGD | lr=0.05] Epoch 1610/4000: train_loss=0.0417  test_loss=3.5669  λ_max=68.7253\n",
      "[SGD | lr=0.05] Epoch 1611/4000: train_loss=0.0417  test_loss=3.5672  λ_max=69.3393\n",
      "[SGD | lr=0.05] Epoch 1612/4000: train_loss=0.0416  test_loss=3.5674  λ_max=69.1333\n",
      "[SGD | lr=0.05] Iter 25800: loss=0.0420\n",
      "[SGD | lr=0.05] Epoch 1613/4000: train_loss=0.0416  test_loss=3.5686  λ_max=70.2960\n",
      "[SGD | lr=0.05] Epoch 1614/4000: train_loss=0.0415  test_loss=3.5696  λ_max=67.9936\n",
      "[SGD | lr=0.05] Epoch 1615/4000: train_loss=0.0415  test_loss=3.5699  λ_max=68.4970\n",
      "[SGD | lr=0.05] Epoch 1616/4000: train_loss=0.0415  test_loss=3.5707  λ_max=67.9803\n",
      "[SGD | lr=0.05] Epoch 1617/4000: train_loss=0.0414  test_loss=3.5710  λ_max=69.4821\n",
      "[SGD | lr=0.05] Epoch 1618/4000: train_loss=0.0414  test_loss=3.5720  λ_max=67.9965\n",
      "[SGD | lr=0.05] Iter 25900: loss=0.0413\n",
      "[SGD | lr=0.05] Epoch 1619/4000: train_loss=0.0413  test_loss=3.5721  λ_max=68.6135\n",
      "[SGD | lr=0.05] Epoch 1620/4000: train_loss=0.0412  test_loss=3.5730  λ_max=68.7236\n",
      "[SGD | lr=0.05] Epoch 1621/4000: train_loss=0.0412  test_loss=3.5737  λ_max=69.4091\n",
      "[SGD | lr=0.05] Epoch 1622/4000: train_loss=0.0412  test_loss=3.5740  λ_max=68.8057\n",
      "[SGD | lr=0.05] Epoch 1623/4000: train_loss=0.0412  test_loss=3.5747  λ_max=70.0596\n",
      "[SGD | lr=0.05] Epoch 1624/4000: train_loss=0.0411  test_loss=3.5751  λ_max=69.2594\n",
      "[SGD | lr=0.05] Iter 26000: loss=0.0408\n",
      "[SGD | lr=0.05] Epoch 1625/4000: train_loss=0.0411  test_loss=3.5759  λ_max=67.4872\n",
      "[SGD | lr=0.05] Epoch 1626/4000: train_loss=0.0410  test_loss=3.5764  λ_max=68.2796\n",
      "[SGD | lr=0.05] Epoch 1627/4000: train_loss=0.0410  test_loss=3.5770  λ_max=69.1157\n",
      "[SGD | lr=0.05] Epoch 1628/4000: train_loss=0.0409  test_loss=3.5779  λ_max=67.6185\n",
      "[SGD | lr=0.05] Epoch 1629/4000: train_loss=0.0409  test_loss=3.5786  λ_max=70.2294\n",
      "[SGD | lr=0.05] Epoch 1630/4000: train_loss=0.0408  test_loss=3.5787  λ_max=69.5406\n",
      "[SGD | lr=0.05] Epoch 1631/4000: train_loss=0.0408  test_loss=3.5794  λ_max=69.9116\n",
      "[SGD | lr=0.05] Iter 26100: loss=0.0412\n",
      "[SGD | lr=0.05] Epoch 1632/4000: train_loss=0.0407  test_loss=3.5804  λ_max=67.9946\n",
      "[SGD | lr=0.05] Epoch 1633/4000: train_loss=0.0407  test_loss=3.5804  λ_max=70.2365\n",
      "[SGD | lr=0.05] Epoch 1634/4000: train_loss=0.0407  test_loss=3.5811  λ_max=67.1625\n",
      "[SGD | lr=0.05] Epoch 1635/4000: train_loss=0.0406  test_loss=3.5817  λ_max=70.3686\n",
      "[SGD | lr=0.05] Epoch 1636/4000: train_loss=0.0406  test_loss=3.5822  λ_max=69.6725\n",
      "[SGD | lr=0.05] Epoch 1637/4000: train_loss=0.0406  test_loss=3.5829  λ_max=69.8367\n",
      "[SGD | lr=0.05] Iter 26200: loss=0.0394\n",
      "[SGD | lr=0.05] Epoch 1638/4000: train_loss=0.0405  test_loss=3.5835  λ_max=66.5349\n",
      "[SGD | lr=0.05] Epoch 1639/4000: train_loss=0.0405  test_loss=3.5845  λ_max=68.6790\n",
      "[SGD | lr=0.05] Epoch 1640/4000: train_loss=0.0405  test_loss=3.5852  λ_max=69.0794\n",
      "[SGD | lr=0.05] Epoch 1641/4000: train_loss=0.0404  test_loss=3.5853  λ_max=67.9876\n",
      "[SGD | lr=0.05] Epoch 1642/4000: train_loss=0.0404  test_loss=3.5861  λ_max=68.4959\n",
      "[SGD | lr=0.05] Epoch 1643/4000: train_loss=0.0403  test_loss=3.5862  λ_max=69.3169\n",
      "[SGD | lr=0.05] Iter 26300: loss=0.0409\n",
      "[SGD | lr=0.05] Epoch 1644/4000: train_loss=0.0402  test_loss=3.5870  λ_max=70.4797\n",
      "[SGD | lr=0.05] Epoch 1645/4000: train_loss=0.0402  test_loss=3.5881  λ_max=67.3659\n",
      "[SGD | lr=0.05] Epoch 1646/4000: train_loss=0.0402  test_loss=3.5881  λ_max=70.4350\n",
      "[SGD | lr=0.05] Epoch 1647/4000: train_loss=0.0401  test_loss=3.5884  λ_max=69.4839\n",
      "[SGD | lr=0.05] Epoch 1648/4000: train_loss=0.0401  test_loss=3.5895  λ_max=68.5470\n",
      "[SGD | lr=0.05] Epoch 1649/4000: train_loss=0.0400  test_loss=3.5896  λ_max=67.8151\n",
      "[SGD | lr=0.05] Iter 26400: loss=0.0401\n",
      "[SGD | lr=0.05] Epoch 1650/4000: train_loss=0.0400  test_loss=3.5903  λ_max=70.4963\n",
      "[SGD | lr=0.05] Epoch 1651/4000: train_loss=0.0400  test_loss=3.5913  λ_max=69.6374\n",
      "[SGD | lr=0.05] Epoch 1652/4000: train_loss=0.0399  test_loss=3.5914  λ_max=69.5600\n",
      "[SGD | lr=0.05] Epoch 1653/4000: train_loss=0.0399  test_loss=3.5919  λ_max=70.3457\n",
      "[SGD | lr=0.05] Epoch 1654/4000: train_loss=0.0398  test_loss=3.5927  λ_max=69.3417\n",
      "[SGD | lr=0.05] Epoch 1655/4000: train_loss=0.0398  test_loss=3.5935  λ_max=70.0003\n",
      "[SGD | lr=0.05] Epoch 1656/4000: train_loss=0.0398  test_loss=3.5938  λ_max=70.5738\n",
      "[SGD | lr=0.05] Iter 26500: loss=0.0399\n",
      "[SGD | lr=0.05] Epoch 1657/4000: train_loss=0.0397  test_loss=3.5947  λ_max=70.1587\n",
      "[SGD | lr=0.05] Epoch 1658/4000: train_loss=0.0397  test_loss=3.5949  λ_max=68.7079\n",
      "[SGD | lr=0.05] Epoch 1659/4000: train_loss=0.0396  test_loss=3.5957  λ_max=69.8868\n",
      "[SGD | lr=0.05] Epoch 1660/4000: train_loss=0.0396  test_loss=3.5957  λ_max=70.5061\n",
      "[SGD | lr=0.05] Epoch 1661/4000: train_loss=0.0396  test_loss=3.5970  λ_max=68.4308\n",
      "[SGD | lr=0.05] Epoch 1662/4000: train_loss=0.0395  test_loss=3.5972  λ_max=68.4950\n",
      "[SGD | lr=0.05] Iter 26600: loss=0.0398\n",
      "[SGD | lr=0.05] Epoch 1663/4000: train_loss=0.0395  test_loss=3.5980  λ_max=70.9054\n",
      "[SGD | lr=0.05] Epoch 1664/4000: train_loss=0.0395  test_loss=3.5984  λ_max=68.2234\n",
      "[SGD | lr=0.05] Epoch 1665/4000: train_loss=0.0394  test_loss=3.5989  λ_max=68.0810\n",
      "[SGD | lr=0.05] Epoch 1666/4000: train_loss=0.0394  test_loss=3.5995  λ_max=69.9943\n",
      "[SGD | lr=0.05] Epoch 1667/4000: train_loss=0.0393  test_loss=3.5999  λ_max=69.4562\n",
      "[SGD | lr=0.05] Epoch 1668/4000: train_loss=0.0393  test_loss=3.6010  λ_max=68.1811\n",
      "[SGD | lr=0.05] Iter 26700: loss=0.0397\n",
      "[SGD | lr=0.05] Epoch 1669/4000: train_loss=0.0392  test_loss=3.6013  λ_max=71.4869\n",
      "[SGD | lr=0.05] Epoch 1670/4000: train_loss=0.0392  test_loss=3.6020  λ_max=70.8873\n",
      "[SGD | lr=0.05] Epoch 1671/4000: train_loss=0.0391  test_loss=3.6023  λ_max=70.2723\n",
      "[SGD | lr=0.05] Epoch 1672/4000: train_loss=0.0391  test_loss=3.6029  λ_max=70.5387\n",
      "[SGD | lr=0.05] Epoch 1673/4000: train_loss=0.0391  test_loss=3.6034  λ_max=70.1814\n",
      "[SGD | lr=0.05] Epoch 1674/4000: train_loss=0.0390  test_loss=3.6044  λ_max=70.1197\n",
      "[SGD | lr=0.05] Iter 26800: loss=0.0390\n",
      "[SGD | lr=0.05] Epoch 1675/4000: train_loss=0.0390  test_loss=3.6044  λ_max=67.6680\n",
      "[SGD | lr=0.05] Epoch 1676/4000: train_loss=0.0390  test_loss=3.6048  λ_max=70.6487\n",
      "[SGD | lr=0.05] Epoch 1677/4000: train_loss=0.0389  test_loss=3.6056  λ_max=70.0905\n",
      "[SGD | lr=0.05] Epoch 1678/4000: train_loss=0.0389  test_loss=3.6068  λ_max=70.2680\n",
      "[SGD | lr=0.05] Epoch 1679/4000: train_loss=0.0388  test_loss=3.6076  λ_max=69.3988\n",
      "[SGD | lr=0.05] Epoch 1680/4000: train_loss=0.0388  test_loss=3.6078  λ_max=70.5037\n",
      "[SGD | lr=0.05] Epoch 1681/4000: train_loss=0.0388  test_loss=3.6083  λ_max=71.6846\n",
      "[SGD | lr=0.05] Iter 26900: loss=0.0380\n",
      "[SGD | lr=0.05] Epoch 1682/4000: train_loss=0.0387  test_loss=3.6089  λ_max=71.6850\n",
      "[SGD | lr=0.05] Epoch 1683/4000: train_loss=0.0387  test_loss=3.6087  λ_max=69.0999\n",
      "[SGD | lr=0.05] Epoch 1684/4000: train_loss=0.0386  test_loss=3.6101  λ_max=72.2241\n",
      "[SGD | lr=0.05] Epoch 1685/4000: train_loss=0.0386  test_loss=3.6106  λ_max=69.6373\n",
      "[SGD | lr=0.05] Epoch 1686/4000: train_loss=0.0386  test_loss=3.6103  λ_max=71.0697\n",
      "[SGD | lr=0.05] Epoch 1687/4000: train_loss=0.0385  test_loss=3.6117  λ_max=71.2927\n",
      "[SGD | lr=0.05] Iter 27000: loss=0.0391\n",
      "[SGD | lr=0.05] Epoch 1688/4000: train_loss=0.0385  test_loss=3.6123  λ_max=70.4903\n",
      "[SGD | lr=0.05] Epoch 1689/4000: train_loss=0.0385  test_loss=3.6126  λ_max=71.2165\n",
      "[SGD | lr=0.05] Epoch 1690/4000: train_loss=0.0384  test_loss=3.6136  λ_max=71.4234\n",
      "[SGD | lr=0.05] Epoch 1691/4000: train_loss=0.0384  test_loss=3.6141  λ_max=69.5430\n",
      "[SGD | lr=0.05] Epoch 1692/4000: train_loss=0.0383  test_loss=3.6141  λ_max=71.1817\n",
      "[SGD | lr=0.05] Epoch 1693/4000: train_loss=0.0383  test_loss=3.6151  λ_max=68.5492\n",
      "[SGD | lr=0.05] Iter 27100: loss=0.0393\n",
      "[SGD | lr=0.05] Epoch 1694/4000: train_loss=0.0383  test_loss=3.6154  λ_max=71.2446\n",
      "[SGD | lr=0.05] Epoch 1695/4000: train_loss=0.0382  test_loss=3.6160  λ_max=70.2514\n",
      "[SGD | lr=0.05] Epoch 1696/4000: train_loss=0.0382  test_loss=3.6168  λ_max=71.1047\n",
      "[SGD | lr=0.05] Epoch 1697/4000: train_loss=0.0381  test_loss=3.6172  λ_max=71.0581\n",
      "[SGD | lr=0.05] Epoch 1698/4000: train_loss=0.0381  test_loss=3.6173  λ_max=71.4240\n",
      "[SGD | lr=0.05] Epoch 1699/4000: train_loss=0.0381  test_loss=3.6182  λ_max=72.3886\n",
      "[SGD | lr=0.05] Iter 27200: loss=0.0377\n",
      "[SGD | lr=0.05] Epoch 1700/4000: train_loss=0.0380  test_loss=3.6189  λ_max=68.7864\n",
      "[SGD | lr=0.05] Epoch 1701/4000: train_loss=0.0380  test_loss=3.6197  λ_max=71.6998\n",
      "[SGD | lr=0.05] Epoch 1702/4000: train_loss=0.0379  test_loss=3.6200  λ_max=68.5159\n",
      "[SGD | lr=0.05] Epoch 1703/4000: train_loss=0.0379  test_loss=3.6208  λ_max=68.2276\n",
      "[SGD | lr=0.05] Epoch 1704/4000: train_loss=0.0379  test_loss=3.6211  λ_max=69.9328\n",
      "[SGD | lr=0.05] Epoch 1705/4000: train_loss=0.0378  test_loss=3.6221  λ_max=71.1828\n",
      "[SGD | lr=0.05] Epoch 1706/4000: train_loss=0.0378  test_loss=3.6220  λ_max=71.0402\n",
      "[SGD | lr=0.05] Iter 27300: loss=0.0380\n",
      "[SGD | lr=0.05] Epoch 1707/4000: train_loss=0.0378  test_loss=3.6228  λ_max=70.9075\n",
      "[SGD | lr=0.05] Epoch 1708/4000: train_loss=0.0377  test_loss=3.6234  λ_max=68.3513\n",
      "[SGD | lr=0.05] Epoch 1709/4000: train_loss=0.0377  test_loss=3.6241  λ_max=71.6395\n",
      "[SGD | lr=0.05] Epoch 1710/4000: train_loss=0.0377  test_loss=3.6245  λ_max=71.5414\n",
      "[SGD | lr=0.05] Epoch 1711/4000: train_loss=0.0376  test_loss=3.6250  λ_max=72.5445\n",
      "[SGD | lr=0.05] Epoch 1712/4000: train_loss=0.0376  test_loss=3.6253  λ_max=70.5613\n",
      "[SGD | lr=0.05] Iter 27400: loss=0.0375\n",
      "[SGD | lr=0.05] Epoch 1713/4000: train_loss=0.0375  test_loss=3.6259  λ_max=69.6965\n",
      "[SGD | lr=0.05] Epoch 1714/4000: train_loss=0.0375  test_loss=3.6264  λ_max=71.2153\n",
      "[SGD | lr=0.05] Epoch 1715/4000: train_loss=0.0375  test_loss=3.6276  λ_max=71.5561\n",
      "[SGD | lr=0.05] Epoch 1716/4000: train_loss=0.0374  test_loss=3.6278  λ_max=71.2382\n",
      "[SGD | lr=0.05] Epoch 1717/4000: train_loss=0.0374  test_loss=3.6286  λ_max=70.5612\n",
      "[SGD | lr=0.05] Epoch 1718/4000: train_loss=0.0374  test_loss=3.6290  λ_max=70.4740\n",
      "[SGD | lr=0.05] Iter 27500: loss=0.0366\n",
      "[SGD | lr=0.05] Epoch 1719/4000: train_loss=0.0373  test_loss=3.6296  λ_max=70.7919\n",
      "[SGD | lr=0.05] Epoch 1720/4000: train_loss=0.0373  test_loss=3.6302  λ_max=68.9364\n",
      "[SGD | lr=0.05] Epoch 1721/4000: train_loss=0.0373  test_loss=3.6309  λ_max=71.8954\n",
      "[SGD | lr=0.05] Epoch 1722/4000: train_loss=0.0372  test_loss=3.6308  λ_max=71.4894\n",
      "[SGD | lr=0.05] Epoch 1723/4000: train_loss=0.0372  test_loss=3.6315  λ_max=71.5117\n",
      "[SGD | lr=0.05] Epoch 1724/4000: train_loss=0.0372  test_loss=3.6319  λ_max=71.3657\n",
      "[SGD | lr=0.05] Iter 27600: loss=0.0375\n",
      "[SGD | lr=0.05] Epoch 1725/4000: train_loss=0.0371  test_loss=3.6332  λ_max=72.3128\n",
      "[SGD | lr=0.05] Epoch 1726/4000: train_loss=0.0370  test_loss=3.6333  λ_max=69.3664\n",
      "[SGD | lr=0.05] Epoch 1727/4000: train_loss=0.0370  test_loss=3.6341  λ_max=71.0138\n",
      "[SGD | lr=0.05] Epoch 1728/4000: train_loss=0.0370  test_loss=3.6347  λ_max=73.5189\n",
      "[SGD | lr=0.05] Epoch 1729/4000: train_loss=0.0370  test_loss=3.6355  λ_max=70.3593\n",
      "[SGD | lr=0.05] Epoch 1730/4000: train_loss=0.0369  test_loss=3.6356  λ_max=70.5171\n",
      "[SGD | lr=0.05] Epoch 1731/4000: train_loss=0.0369  test_loss=3.6356  λ_max=72.1092\n",
      "[SGD | lr=0.05] Iter 27700: loss=0.0362\n",
      "[SGD | lr=0.05] Epoch 1732/4000: train_loss=0.0369  test_loss=3.6364  λ_max=71.2925\n",
      "[SGD | lr=0.05] Epoch 1733/4000: train_loss=0.0368  test_loss=3.6374  λ_max=70.1197\n",
      "[SGD | lr=0.05] Epoch 1734/4000: train_loss=0.0368  test_loss=3.6376  λ_max=71.7238\n",
      "[SGD | lr=0.05] Epoch 1735/4000: train_loss=0.0367  test_loss=3.6381  λ_max=71.8486\n",
      "[SGD | lr=0.05] Epoch 1736/4000: train_loss=0.0367  test_loss=3.6392  λ_max=69.4485\n",
      "[SGD | lr=0.05] Epoch 1737/4000: train_loss=0.0367  test_loss=3.6395  λ_max=72.3693\n",
      "[SGD | lr=0.05] Iter 27800: loss=0.0369\n",
      "[SGD | lr=0.05] Epoch 1738/4000: train_loss=0.0366  test_loss=3.6404  λ_max=71.1608\n",
      "[SGD | lr=0.05] Epoch 1739/4000: train_loss=0.0366  test_loss=3.6407  λ_max=71.1323\n",
      "[SGD | lr=0.05] Epoch 1740/4000: train_loss=0.0366  test_loss=3.6408  λ_max=71.1136\n",
      "[SGD | lr=0.05] Epoch 1741/4000: train_loss=0.0365  test_loss=3.6413  λ_max=72.1501\n",
      "[SGD | lr=0.05] Epoch 1742/4000: train_loss=0.0365  test_loss=3.6423  λ_max=70.1539\n",
      "[SGD | lr=0.05] Epoch 1743/4000: train_loss=0.0365  test_loss=3.6426  λ_max=70.9132\n",
      "[SGD | lr=0.05] Iter 27900: loss=0.0355\n",
      "[SGD | lr=0.05] Epoch 1744/4000: train_loss=0.0364  test_loss=3.6430  λ_max=69.9867\n",
      "[SGD | lr=0.05] Epoch 1745/4000: train_loss=0.0364  test_loss=3.6437  λ_max=71.2419\n",
      "[SGD | lr=0.05] Epoch 1746/4000: train_loss=0.0364  test_loss=3.6441  λ_max=70.9651\n",
      "[SGD | lr=0.05] Epoch 1747/4000: train_loss=0.0363  test_loss=3.6447  λ_max=69.9126\n",
      "[SGD | lr=0.05] Epoch 1748/4000: train_loss=0.0363  test_loss=3.6449  λ_max=71.6462\n",
      "[SGD | lr=0.05] Epoch 1749/4000: train_loss=0.0363  test_loss=3.6458  λ_max=69.9467\n",
      "[SGD | lr=0.05] Iter 28000: loss=0.0359\n",
      "[SGD | lr=0.05] Epoch 1750/4000: train_loss=0.0362  test_loss=3.6464  λ_max=70.9399\n",
      "[SGD | lr=0.05] Epoch 1751/4000: train_loss=0.0362  test_loss=3.6468  λ_max=72.2162\n",
      "[SGD | lr=0.05] Epoch 1752/4000: train_loss=0.0361  test_loss=3.6473  λ_max=71.7287\n",
      "[SGD | lr=0.05] Epoch 1753/4000: train_loss=0.0361  test_loss=3.6480  λ_max=70.1804\n",
      "[SGD | lr=0.05] Epoch 1754/4000: train_loss=0.0361  test_loss=3.6485  λ_max=73.2963\n",
      "[SGD | lr=0.05] Epoch 1755/4000: train_loss=0.0361  test_loss=3.6491  λ_max=72.7669\n",
      "[SGD | lr=0.05] Epoch 1756/4000: train_loss=0.0360  test_loss=3.6499  λ_max=71.4100\n",
      "[SGD | lr=0.05] Iter 28100: loss=0.0354\n",
      "[SGD | lr=0.05] Epoch 1757/4000: train_loss=0.0360  test_loss=3.6495  λ_max=71.2857\n",
      "[SGD | lr=0.05] Epoch 1758/4000: train_loss=0.0360  test_loss=3.6508  λ_max=72.0115\n",
      "[SGD | lr=0.05] Epoch 1759/4000: train_loss=0.0359  test_loss=3.6514  λ_max=69.2718\n",
      "[SGD | lr=0.05] Epoch 1760/4000: train_loss=0.0359  test_loss=3.6515  λ_max=71.3329\n",
      "[SGD | lr=0.05] Epoch 1761/4000: train_loss=0.0359  test_loss=3.6521  λ_max=72.3290\n",
      "[SGD | lr=0.05] Epoch 1762/4000: train_loss=0.0358  test_loss=3.6524  λ_max=71.8575\n",
      "[SGD | lr=0.05] Iter 28200: loss=0.0351\n",
      "[SGD | lr=0.05] Epoch 1763/4000: train_loss=0.0358  test_loss=3.6535  λ_max=72.0738\n",
      "[SGD | lr=0.05] Epoch 1764/4000: train_loss=0.0357  test_loss=3.6539  λ_max=68.3371\n",
      "[SGD | lr=0.05] Epoch 1765/4000: train_loss=0.0357  test_loss=3.6543  λ_max=72.2000\n",
      "[SGD | lr=0.05] Epoch 1766/4000: train_loss=0.0357  test_loss=3.6549  λ_max=68.3715\n",
      "[SGD | lr=0.05] Epoch 1767/4000: train_loss=0.0356  test_loss=3.6553  λ_max=73.4743\n",
      "[SGD | lr=0.05] Epoch 1768/4000: train_loss=0.0356  test_loss=3.6560  λ_max=72.8291\n",
      "[SGD | lr=0.05] Iter 28300: loss=0.0356\n",
      "[SGD | lr=0.05] Epoch 1769/4000: train_loss=0.0356  test_loss=3.6565  λ_max=71.0743\n",
      "[SGD | lr=0.05] Epoch 1770/4000: train_loss=0.0355  test_loss=3.6567  λ_max=73.1138\n",
      "[SGD | lr=0.05] Epoch 1771/4000: train_loss=0.0355  test_loss=3.6578  λ_max=70.0951\n",
      "[SGD | lr=0.05] Epoch 1772/4000: train_loss=0.0355  test_loss=3.6579  λ_max=73.4212\n",
      "[SGD | lr=0.05] Epoch 1773/4000: train_loss=0.0354  test_loss=3.6587  λ_max=72.3095\n",
      "[SGD | lr=0.05] Epoch 1774/4000: train_loss=0.0354  test_loss=3.6591  λ_max=71.1163\n",
      "[SGD | lr=0.05] Iter 28400: loss=0.0349\n",
      "[SGD | lr=0.05] Epoch 1775/4000: train_loss=0.0354  test_loss=3.6594  λ_max=71.8677\n",
      "[SGD | lr=0.05] Epoch 1776/4000: train_loss=0.0353  test_loss=3.6604  λ_max=70.0906\n",
      "[SGD | lr=0.05] Epoch 1777/4000: train_loss=0.0353  test_loss=3.6605  λ_max=70.8482\n",
      "[SGD | lr=0.05] Epoch 1778/4000: train_loss=0.0353  test_loss=3.6615  λ_max=72.7931\n",
      "[SGD | lr=0.05] Epoch 1779/4000: train_loss=0.0352  test_loss=3.6617  λ_max=72.8267\n",
      "[SGD | lr=0.05] Epoch 1780/4000: train_loss=0.0352  test_loss=3.6623  λ_max=72.9897\n",
      "[SGD | lr=0.05] Epoch 1781/4000: train_loss=0.0352  test_loss=3.6626  λ_max=72.6018\n",
      "[SGD | lr=0.05] Iter 28500: loss=0.0347\n",
      "[SGD | lr=0.05] Epoch 1782/4000: train_loss=0.0351  test_loss=3.6632  λ_max=70.8024\n",
      "[SGD | lr=0.05] Epoch 1783/4000: train_loss=0.0351  test_loss=3.6641  λ_max=71.3820\n",
      "[SGD | lr=0.05] Epoch 1784/4000: train_loss=0.0351  test_loss=3.6648  λ_max=70.0681\n",
      "[SGD | lr=0.05] Epoch 1785/4000: train_loss=0.0350  test_loss=3.6649  λ_max=71.9553\n",
      "[SGD | lr=0.05] Epoch 1786/4000: train_loss=0.0350  test_loss=3.6655  λ_max=71.2925\n",
      "[SGD | lr=0.05] Epoch 1787/4000: train_loss=0.0350  test_loss=3.6658  λ_max=73.4647\n",
      "[SGD | lr=0.05] Iter 28600: loss=0.0352\n",
      "[SGD | lr=0.05] Epoch 1788/4000: train_loss=0.0350  test_loss=3.6663  λ_max=72.3980\n",
      "[SGD | lr=0.05] Epoch 1789/4000: train_loss=0.0349  test_loss=3.6673  λ_max=70.7171\n",
      "[SGD | lr=0.05] Epoch 1790/4000: train_loss=0.0349  test_loss=3.6670  λ_max=73.0323\n",
      "[SGD | lr=0.05] Epoch 1791/4000: train_loss=0.0349  test_loss=3.6681  λ_max=70.5456\n",
      "[SGD | lr=0.05] Epoch 1792/4000: train_loss=0.0348  test_loss=3.6689  λ_max=72.6545\n",
      "[SGD | lr=0.05] Epoch 1793/4000: train_loss=0.0348  test_loss=3.6692  λ_max=71.7746\n",
      "[SGD | lr=0.05] Iter 28700: loss=0.0351\n",
      "[SGD | lr=0.05] Epoch 1794/4000: train_loss=0.0348  test_loss=3.6696  λ_max=72.0897\n",
      "[SGD | lr=0.05] Epoch 1795/4000: train_loss=0.0347  test_loss=3.6698  λ_max=73.1029\n",
      "[SGD | lr=0.05] Epoch 1796/4000: train_loss=0.0347  test_loss=3.6704  λ_max=71.9029\n",
      "[SGD | lr=0.05] Epoch 1797/4000: train_loss=0.0347  test_loss=3.6711  λ_max=72.6133\n",
      "[SGD | lr=0.05] Epoch 1798/4000: train_loss=0.0346  test_loss=3.6717  λ_max=70.8744\n",
      "[SGD | lr=0.05] Epoch 1799/4000: train_loss=0.0346  test_loss=3.6720  λ_max=71.2648\n",
      "[SGD | lr=0.05] Iter 28800: loss=0.0338\n",
      "[SGD | lr=0.05] Epoch 1800/4000: train_loss=0.0345  test_loss=3.6731  λ_max=70.8769\n",
      "[SGD | lr=0.05] Epoch 1801/4000: train_loss=0.0345  test_loss=3.6733  λ_max=71.9667\n",
      "[SGD | lr=0.05] Epoch 1802/4000: train_loss=0.0345  test_loss=3.6734  λ_max=72.7139\n",
      "[SGD | lr=0.05] Epoch 1803/4000: train_loss=0.0345  test_loss=3.6745  λ_max=73.5993\n",
      "[SGD | lr=0.05] Epoch 1804/4000: train_loss=0.0344  test_loss=3.6750  λ_max=73.0376\n",
      "[SGD | lr=0.05] Epoch 1805/4000: train_loss=0.0344  test_loss=3.6756  λ_max=73.5921\n",
      "[SGD | lr=0.05] Epoch 1806/4000: train_loss=0.0344  test_loss=3.6758  λ_max=73.3021\n",
      "[SGD | lr=0.05] Iter 28900: loss=0.0342\n",
      "[SGD | lr=0.05] Epoch 1807/4000: train_loss=0.0343  test_loss=3.6766  λ_max=70.7836\n",
      "[SGD | lr=0.05] Epoch 1808/4000: train_loss=0.0343  test_loss=3.6769  λ_max=73.3908\n",
      "[SGD | lr=0.05] Epoch 1809/4000: train_loss=0.0343  test_loss=3.6776  λ_max=71.9605\n",
      "[SGD | lr=0.05] Epoch 1810/4000: train_loss=0.0342  test_loss=3.6780  λ_max=71.5709\n",
      "[SGD | lr=0.05] Epoch 1811/4000: train_loss=0.0342  test_loss=3.6784  λ_max=72.6037\n",
      "[SGD | lr=0.05] Epoch 1812/4000: train_loss=0.0342  test_loss=3.6789  λ_max=75.1127\n",
      "[SGD | lr=0.05] Iter 29000: loss=0.0345\n",
      "[SGD | lr=0.05] Epoch 1813/4000: train_loss=0.0342  test_loss=3.6792  λ_max=74.0396\n",
      "[SGD | lr=0.05] Epoch 1814/4000: train_loss=0.0341  test_loss=3.6799  λ_max=72.4481\n",
      "[SGD | lr=0.05] Epoch 1815/4000: train_loss=0.0341  test_loss=3.6806  λ_max=73.7128\n",
      "[SGD | lr=0.05] Epoch 1816/4000: train_loss=0.0341  test_loss=3.6813  λ_max=71.7838\n",
      "[SGD | lr=0.05] Epoch 1817/4000: train_loss=0.0340  test_loss=3.6816  λ_max=74.2717\n",
      "[SGD | lr=0.05] Epoch 1818/4000: train_loss=0.0340  test_loss=3.6821  λ_max=72.5035\n",
      "[SGD | lr=0.05] Iter 29100: loss=0.0338\n",
      "[SGD | lr=0.05] Epoch 1819/4000: train_loss=0.0340  test_loss=3.6829  λ_max=72.0734\n",
      "[SGD | lr=0.05] Epoch 1820/4000: train_loss=0.0339  test_loss=3.6832  λ_max=71.3832\n",
      "[SGD | lr=0.05] Epoch 1821/4000: train_loss=0.0339  test_loss=3.6838  λ_max=73.3394\n",
      "[SGD | lr=0.05] Epoch 1822/4000: train_loss=0.0339  test_loss=3.6844  λ_max=69.8696\n",
      "[SGD | lr=0.05] Epoch 1823/4000: train_loss=0.0338  test_loss=3.6850  λ_max=73.0205\n",
      "[SGD | lr=0.05] Epoch 1824/4000: train_loss=0.0338  test_loss=3.6852  λ_max=73.4519\n",
      "[SGD | lr=0.05] Iter 29200: loss=0.0341\n",
      "[SGD | lr=0.05] Epoch 1825/4000: train_loss=0.0338  test_loss=3.6857  λ_max=68.5174\n",
      "[SGD | lr=0.05] Epoch 1826/4000: train_loss=0.0338  test_loss=3.6863  λ_max=73.3577\n",
      "[SGD | lr=0.05] Epoch 1827/4000: train_loss=0.0337  test_loss=3.6866  λ_max=74.0126\n",
      "[SGD | lr=0.05] Epoch 1828/4000: train_loss=0.0337  test_loss=3.6871  λ_max=72.0696\n",
      "[SGD | lr=0.05] Epoch 1829/4000: train_loss=0.0337  test_loss=3.6881  λ_max=70.5735\n",
      "[SGD | lr=0.05] Epoch 1830/4000: train_loss=0.0336  test_loss=3.6881  λ_max=71.6932\n",
      "[SGD | lr=0.05] Epoch 1831/4000: train_loss=0.0336  test_loss=3.6895  λ_max=71.1189\n",
      "[SGD | lr=0.05] Iter 29300: loss=0.0328\n",
      "[SGD | lr=0.05] Epoch 1832/4000: train_loss=0.0336  test_loss=3.6894  λ_max=74.8075\n",
      "[SGD | lr=0.05] Epoch 1833/4000: train_loss=0.0335  test_loss=3.6902  λ_max=73.6151\n",
      "[SGD | lr=0.05] Epoch 1834/4000: train_loss=0.0335  test_loss=3.6901  λ_max=72.7729\n",
      "[SGD | lr=0.05] Epoch 1835/4000: train_loss=0.0335  test_loss=3.6909  λ_max=73.3468\n",
      "[SGD | lr=0.05] Epoch 1836/4000: train_loss=0.0334  test_loss=3.6915  λ_max=73.3982\n",
      "[SGD | lr=0.05] Epoch 1837/4000: train_loss=0.0334  test_loss=3.6919  λ_max=72.0290\n",
      "[SGD | lr=0.05] Iter 29400: loss=0.0330\n",
      "[SGD | lr=0.05] Epoch 1838/4000: train_loss=0.0334  test_loss=3.6921  λ_max=72.1642\n",
      "[SGD | lr=0.05] Epoch 1839/4000: train_loss=0.0334  test_loss=3.6929  λ_max=74.9044\n",
      "[SGD | lr=0.05] Epoch 1840/4000: train_loss=0.0333  test_loss=3.6937  λ_max=74.2560\n",
      "[SGD | lr=0.05] Epoch 1841/4000: train_loss=0.0333  test_loss=3.6939  λ_max=73.7394\n",
      "[SGD | lr=0.05] Epoch 1842/4000: train_loss=0.0333  test_loss=3.6943  λ_max=73.3766\n",
      "[SGD | lr=0.05] Epoch 1843/4000: train_loss=0.0332  test_loss=3.6948  λ_max=72.6227\n",
      "[SGD | lr=0.05] Iter 29500: loss=0.0336\n",
      "[SGD | lr=0.05] Epoch 1844/4000: train_loss=0.0332  test_loss=3.6953  λ_max=73.2761\n",
      "[SGD | lr=0.05] Epoch 1845/4000: train_loss=0.0332  test_loss=3.6959  λ_max=71.5846\n",
      "[SGD | lr=0.05] Epoch 1846/4000: train_loss=0.0332  test_loss=3.6967  λ_max=72.8812\n",
      "[SGD | lr=0.05] Epoch 1847/4000: train_loss=0.0331  test_loss=3.6968  λ_max=74.2060\n",
      "[SGD | lr=0.05] Epoch 1848/4000: train_loss=0.0331  test_loss=3.6975  λ_max=72.2740\n",
      "[SGD | lr=0.05] Epoch 1849/4000: train_loss=0.0331  test_loss=3.6978  λ_max=73.6131\n",
      "[SGD | lr=0.05] Iter 29600: loss=0.0339\n",
      "[SGD | lr=0.05] Epoch 1850/4000: train_loss=0.0331  test_loss=3.6984  λ_max=73.5140\n",
      "[SGD | lr=0.05] Epoch 1851/4000: train_loss=0.0330  test_loss=3.6991  λ_max=72.5006\n",
      "[SGD | lr=0.05] Epoch 1852/4000: train_loss=0.0330  test_loss=3.6995  λ_max=72.2588\n",
      "[SGD | lr=0.05] Epoch 1853/4000: train_loss=0.0329  test_loss=3.7002  λ_max=73.1030\n",
      "[SGD | lr=0.05] Epoch 1854/4000: train_loss=0.0329  test_loss=3.7005  λ_max=72.5988\n",
      "[SGD | lr=0.05] Epoch 1855/4000: train_loss=0.0329  test_loss=3.7011  λ_max=72.9560\n",
      "[SGD | lr=0.05] Epoch 1856/4000: train_loss=0.0329  test_loss=3.7016  λ_max=74.2154\n",
      "[SGD | lr=0.05] Iter 29700: loss=0.0330\n",
      "[SGD | lr=0.05] Epoch 1857/4000: train_loss=0.0328  test_loss=3.7017  λ_max=70.8710\n",
      "[SGD | lr=0.05] Epoch 1858/4000: train_loss=0.0328  test_loss=3.7026  λ_max=71.9944\n",
      "[SGD | lr=0.05] Epoch 1859/4000: train_loss=0.0328  test_loss=3.7031  λ_max=73.8279\n",
      "[SGD | lr=0.05] Epoch 1860/4000: train_loss=0.0327  test_loss=3.7035  λ_max=72.4906\n",
      "[SGD | lr=0.05] Epoch 1861/4000: train_loss=0.0327  test_loss=3.7043  λ_max=72.2968\n",
      "[SGD | lr=0.05] Epoch 1862/4000: train_loss=0.0327  test_loss=3.7045  λ_max=75.3839\n",
      "[SGD | lr=0.05] Iter 29800: loss=0.0330\n",
      "[SGD | lr=0.05] Epoch 1863/4000: train_loss=0.0326  test_loss=3.7055  λ_max=74.2641\n",
      "[SGD | lr=0.05] Epoch 1864/4000: train_loss=0.0326  test_loss=3.7057  λ_max=74.1974\n",
      "[SGD | lr=0.05] Epoch 1865/4000: train_loss=0.0326  test_loss=3.7058  λ_max=72.2488\n",
      "[SGD | lr=0.05] Epoch 1866/4000: train_loss=0.0326  test_loss=3.7069  λ_max=72.4280\n",
      "[SGD | lr=0.05] Epoch 1867/4000: train_loss=0.0326  test_loss=3.7073  λ_max=74.4599\n",
      "[SGD | lr=0.05] Epoch 1868/4000: train_loss=0.0325  test_loss=3.7070  λ_max=72.6686\n",
      "[SGD | lr=0.05] Iter 29900: loss=0.0329\n",
      "[SGD | lr=0.05] Epoch 1869/4000: train_loss=0.0325  test_loss=3.7083  λ_max=71.4572\n",
      "[SGD | lr=0.05] Epoch 1870/4000: train_loss=0.0325  test_loss=3.7084  λ_max=74.0135\n",
      "[SGD | lr=0.05] Epoch 1871/4000: train_loss=0.0324  test_loss=3.7091  λ_max=73.5867\n",
      "[SGD | lr=0.05] Epoch 1872/4000: train_loss=0.0324  test_loss=3.7095  λ_max=73.8280\n",
      "[SGD | lr=0.05] Epoch 1873/4000: train_loss=0.0324  test_loss=3.7102  λ_max=74.0263\n",
      "[SGD | lr=0.05] Epoch 1874/4000: train_loss=0.0323  test_loss=3.7105  λ_max=72.8230\n",
      "[SGD | lr=0.05] Iter 30000: loss=0.0333\n",
      "[SGD | lr=0.05] Epoch 1875/4000: train_loss=0.0323  test_loss=3.7112  λ_max=73.3558\n",
      "[SGD | lr=0.05] Epoch 1876/4000: train_loss=0.0323  test_loss=3.7114  λ_max=72.7667\n",
      "[SGD | lr=0.05] Epoch 1877/4000: train_loss=0.0323  test_loss=3.7123  λ_max=72.0130\n",
      "[SGD | lr=0.05] Epoch 1878/4000: train_loss=0.0322  test_loss=3.7130  λ_max=72.2942\n",
      "[SGD | lr=0.05] Epoch 1879/4000: train_loss=0.0322  test_loss=3.7131  λ_max=75.3387\n",
      "[SGD | lr=0.05] Epoch 1880/4000: train_loss=0.0322  test_loss=3.7136  λ_max=72.0090\n",
      "[SGD | lr=0.05] Epoch 1881/4000: train_loss=0.0321  test_loss=3.7141  λ_max=73.9896\n",
      "[SGD | lr=0.05] Iter 30100: loss=0.0322\n",
      "[SGD | lr=0.05] Epoch 1882/4000: train_loss=0.0321  test_loss=3.7146  λ_max=75.3661\n",
      "[SGD | lr=0.05] Epoch 1883/4000: train_loss=0.0321  test_loss=3.7150  λ_max=71.6991\n",
      "[SGD | lr=0.05] Epoch 1884/4000: train_loss=0.0321  test_loss=3.7153  λ_max=75.3195\n",
      "[SGD | lr=0.05] Epoch 1885/4000: train_loss=0.0320  test_loss=3.7163  λ_max=73.3063\n",
      "[SGD | lr=0.05] Epoch 1886/4000: train_loss=0.0320  test_loss=3.7163  λ_max=75.3805\n",
      "[SGD | lr=0.05] Epoch 1887/4000: train_loss=0.0320  test_loss=3.7169  λ_max=75.4090\n",
      "[SGD | lr=0.05] Iter 30200: loss=0.0325\n",
      "[SGD | lr=0.05] Epoch 1888/4000: train_loss=0.0320  test_loss=3.7177  λ_max=73.3381\n",
      "[SGD | lr=0.05] Epoch 1889/4000: train_loss=0.0319  test_loss=3.7177  λ_max=73.7863\n",
      "[SGD | lr=0.05] Epoch 1890/4000: train_loss=0.0319  test_loss=3.7185  λ_max=74.4565\n",
      "[SGD | lr=0.05] Epoch 1891/4000: train_loss=0.0319  test_loss=3.7191  λ_max=74.2016\n",
      "[SGD | lr=0.05] Epoch 1892/4000: train_loss=0.0318  test_loss=3.7196  λ_max=72.5506\n",
      "[SGD | lr=0.05] Epoch 1893/4000: train_loss=0.0318  test_loss=3.7198  λ_max=72.0858\n",
      "[SGD | lr=0.05] Iter 30300: loss=0.0323\n",
      "[SGD | lr=0.05] Epoch 1894/4000: train_loss=0.0318  test_loss=3.7202  λ_max=72.2397\n",
      "[SGD | lr=0.05] Epoch 1895/4000: train_loss=0.0318  test_loss=3.7207  λ_max=74.1709\n",
      "[SGD | lr=0.05] Epoch 1896/4000: train_loss=0.0317  test_loss=3.7211  λ_max=73.9622\n",
      "[SGD | lr=0.05] Epoch 1897/4000: train_loss=0.0317  test_loss=3.7222  λ_max=73.8394\n",
      "[SGD | lr=0.05] Epoch 1898/4000: train_loss=0.0317  test_loss=3.7222  λ_max=73.7048\n",
      "[SGD | lr=0.05] Epoch 1899/4000: train_loss=0.0316  test_loss=3.7228  λ_max=74.5605\n",
      "[SGD | lr=0.05] Iter 30400: loss=0.0310\n",
      "[SGD | lr=0.05] Epoch 1900/4000: train_loss=0.0316  test_loss=3.7234  λ_max=73.3416\n",
      "[SGD | lr=0.05] Epoch 1901/4000: train_loss=0.0316  test_loss=3.7239  λ_max=73.4175\n",
      "[SGD | lr=0.05] Epoch 1902/4000: train_loss=0.0316  test_loss=3.7248  λ_max=73.5991\n",
      "[SGD | lr=0.05] Epoch 1903/4000: train_loss=0.0315  test_loss=3.7248  λ_max=74.8359\n",
      "[SGD | lr=0.05] Epoch 1904/4000: train_loss=0.0315  test_loss=3.7255  λ_max=72.5474\n",
      "[SGD | lr=0.05] Epoch 1905/4000: train_loss=0.0315  test_loss=3.7262  λ_max=74.9385\n",
      "[SGD | lr=0.05] Epoch 1906/4000: train_loss=0.0315  test_loss=3.7265  λ_max=73.8801\n",
      "[SGD | lr=0.05] Iter 30500: loss=0.0316\n",
      "[SGD | lr=0.05] Epoch 1907/4000: train_loss=0.0314  test_loss=3.7268  λ_max=75.5916\n",
      "[SGD | lr=0.05] Epoch 1908/4000: train_loss=0.0314  test_loss=3.7267  λ_max=74.0611\n",
      "[SGD | lr=0.05] Epoch 1909/4000: train_loss=0.0314  test_loss=3.7279  λ_max=73.6656\n",
      "[SGD | lr=0.05] Epoch 1910/4000: train_loss=0.0314  test_loss=3.7281  λ_max=75.7708\n",
      "[SGD | lr=0.05] Epoch 1911/4000: train_loss=0.0313  test_loss=3.7287  λ_max=73.7964\n",
      "[SGD | lr=0.05] Epoch 1912/4000: train_loss=0.0313  test_loss=3.7291  λ_max=75.7223\n",
      "[SGD | lr=0.05] Iter 30600: loss=0.0322\n",
      "[SGD | lr=0.05] Epoch 1913/4000: train_loss=0.0313  test_loss=3.7297  λ_max=72.6353\n",
      "[SGD | lr=0.05] Epoch 1914/4000: train_loss=0.0313  test_loss=3.7300  λ_max=73.8900\n",
      "[SGD | lr=0.05] Epoch 1915/4000: train_loss=0.0312  test_loss=3.7307  λ_max=74.9568\n",
      "[SGD | lr=0.05] Epoch 1916/4000: train_loss=0.0312  test_loss=3.7314  λ_max=74.9967\n",
      "[SGD | lr=0.05] Epoch 1917/4000: train_loss=0.0312  test_loss=3.7314  λ_max=73.5634\n",
      "[SGD | lr=0.05] Epoch 1918/4000: train_loss=0.0312  test_loss=3.7322  λ_max=75.0040\n",
      "[SGD | lr=0.05] Iter 30700: loss=0.0308\n",
      "[SGD | lr=0.05] Epoch 1919/4000: train_loss=0.0311  test_loss=3.7328  λ_max=75.5501\n",
      "[SGD | lr=0.05] Epoch 1920/4000: train_loss=0.0311  test_loss=3.7331  λ_max=72.5463\n",
      "[SGD | lr=0.05] Epoch 1921/4000: train_loss=0.0311  test_loss=3.7338  λ_max=74.7196\n",
      "[SGD | lr=0.05] Epoch 1922/4000: train_loss=0.0310  test_loss=3.7346  λ_max=74.2801\n",
      "[SGD | lr=0.05] Epoch 1923/4000: train_loss=0.0310  test_loss=3.7346  λ_max=75.7212\n",
      "[SGD | lr=0.05] Epoch 1924/4000: train_loss=0.0310  test_loss=3.7352  λ_max=74.7666\n",
      "[SGD | lr=0.05] Iter 30800: loss=0.0311\n",
      "[SGD | lr=0.05] Epoch 1925/4000: train_loss=0.0310  test_loss=3.7354  λ_max=75.5413\n",
      "[SGD | lr=0.05] Epoch 1926/4000: train_loss=0.0309  test_loss=3.7360  λ_max=75.9548\n",
      "[SGD | lr=0.05] Epoch 1927/4000: train_loss=0.0309  test_loss=3.7367  λ_max=75.9818\n",
      "[SGD | lr=0.05] Epoch 1928/4000: train_loss=0.0309  test_loss=3.7374  λ_max=76.3450\n",
      "[SGD | lr=0.05] Epoch 1929/4000: train_loss=0.0309  test_loss=3.7374  λ_max=72.0440\n",
      "[SGD | lr=0.05] Epoch 1930/4000: train_loss=0.0308  test_loss=3.7380  λ_max=72.9405\n",
      "[SGD | lr=0.05] Epoch 1931/4000: train_loss=0.0308  test_loss=3.7389  λ_max=76.1385\n",
      "[SGD | lr=0.05] Iter 30900: loss=0.0313\n",
      "[SGD | lr=0.05] Epoch 1932/4000: train_loss=0.0308  test_loss=3.7388  λ_max=75.2132\n",
      "[SGD | lr=0.05] Epoch 1933/4000: train_loss=0.0308  test_loss=3.7390  λ_max=75.1269\n",
      "[SGD | lr=0.05] Epoch 1934/4000: train_loss=0.0307  test_loss=3.7401  λ_max=73.3454\n",
      "[SGD | lr=0.05] Epoch 1935/4000: train_loss=0.0307  test_loss=3.7403  λ_max=73.8319\n",
      "[SGD | lr=0.05] Epoch 1936/4000: train_loss=0.0307  test_loss=3.7408  λ_max=74.3838\n",
      "[SGD | lr=0.05] Epoch 1937/4000: train_loss=0.0306  test_loss=3.7412  λ_max=75.2944\n",
      "[SGD | lr=0.05] Iter 31000: loss=0.0304\n",
      "[SGD | lr=0.05] Epoch 1938/4000: train_loss=0.0306  test_loss=3.7416  λ_max=76.3406\n",
      "[SGD | lr=0.05] Epoch 1939/4000: train_loss=0.0306  test_loss=3.7424  λ_max=74.6602\n",
      "[SGD | lr=0.05] Epoch 1940/4000: train_loss=0.0306  test_loss=3.7430  λ_max=75.0870\n",
      "[SGD | lr=0.05] Epoch 1941/4000: train_loss=0.0305  test_loss=3.7431  λ_max=75.4823\n",
      "[SGD | lr=0.05] Epoch 1942/4000: train_loss=0.0305  test_loss=3.7435  λ_max=75.5987\n",
      "[SGD | lr=0.05] Epoch 1943/4000: train_loss=0.0305  test_loss=3.7440  λ_max=75.3568\n",
      "[SGD | lr=0.05] Iter 31100: loss=0.0305\n",
      "[SGD | lr=0.05] Epoch 1944/4000: train_loss=0.0304  test_loss=3.7445  λ_max=76.1071\n",
      "[SGD | lr=0.05] Epoch 1945/4000: train_loss=0.0304  test_loss=3.7452  λ_max=74.8753\n",
      "[SGD | lr=0.05] Epoch 1946/4000: train_loss=0.0304  test_loss=3.7455  λ_max=73.9726\n",
      "[SGD | lr=0.05] Epoch 1947/4000: train_loss=0.0304  test_loss=3.7462  λ_max=74.7378\n",
      "[SGD | lr=0.05] Epoch 1948/4000: train_loss=0.0304  test_loss=3.7469  λ_max=74.8894\n",
      "[SGD | lr=0.05] Epoch 1949/4000: train_loss=0.0304  test_loss=3.7468  λ_max=72.8224\n",
      "[SGD | lr=0.05] Iter 31200: loss=0.0296\n",
      "[SGD | lr=0.05] Epoch 1950/4000: train_loss=0.0303  test_loss=3.7475  λ_max=74.7889\n",
      "[SGD | lr=0.05] Epoch 1951/4000: train_loss=0.0303  test_loss=3.7477  λ_max=76.3744\n",
      "[SGD | lr=0.05] Epoch 1952/4000: train_loss=0.0303  test_loss=3.7483  λ_max=75.5878\n",
      "[SGD | lr=0.05] Epoch 1953/4000: train_loss=0.0302  test_loss=3.7487  λ_max=73.0097\n",
      "[SGD | lr=0.05] Epoch 1954/4000: train_loss=0.0302  test_loss=3.7492  λ_max=74.1300\n",
      "[SGD | lr=0.05] Epoch 1955/4000: train_loss=0.0302  test_loss=3.7495  λ_max=74.3896\n",
      "[SGD | lr=0.05] Epoch 1956/4000: train_loss=0.0302  test_loss=3.7502  λ_max=73.5160\n",
      "[SGD | lr=0.05] Iter 31300: loss=0.0299\n",
      "[SGD | lr=0.05] Epoch 1957/4000: train_loss=0.0301  test_loss=3.7508  λ_max=74.2774\n",
      "[SGD | lr=0.05] Epoch 1958/4000: train_loss=0.0301  test_loss=3.7512  λ_max=73.1001\n",
      "[SGD | lr=0.05] Epoch 1959/4000: train_loss=0.0301  test_loss=3.7517  λ_max=74.3710\n",
      "[SGD | lr=0.05] Epoch 1960/4000: train_loss=0.0301  test_loss=3.7522  λ_max=72.5178\n",
      "[SGD | lr=0.05] Epoch 1961/4000: train_loss=0.0300  test_loss=3.7520  λ_max=74.5871\n",
      "[SGD | lr=0.05] Epoch 1962/4000: train_loss=0.0300  test_loss=3.7530  λ_max=75.6856\n",
      "[SGD | lr=0.05] Iter 31400: loss=0.0290\n",
      "[SGD | lr=0.05] Epoch 1963/4000: train_loss=0.0300  test_loss=3.7533  λ_max=74.9245\n",
      "[SGD | lr=0.05] Epoch 1964/4000: train_loss=0.0300  test_loss=3.7541  λ_max=74.9376\n",
      "[SGD | lr=0.05] Epoch 1965/4000: train_loss=0.0300  test_loss=3.7545  λ_max=74.8329\n",
      "[SGD | lr=0.05] Epoch 1966/4000: train_loss=0.0299  test_loss=3.7553  λ_max=76.9394\n",
      "[SGD | lr=0.05] Epoch 1967/4000: train_loss=0.0299  test_loss=3.7552  λ_max=75.5391\n",
      "[SGD | lr=0.05] Epoch 1968/4000: train_loss=0.0299  test_loss=3.7559  λ_max=76.6037\n",
      "[SGD | lr=0.05] Iter 31500: loss=0.0303\n",
      "[SGD | lr=0.05] Epoch 1969/4000: train_loss=0.0299  test_loss=3.7562  λ_max=77.1153\n",
      "[SGD | lr=0.05] Epoch 1970/4000: train_loss=0.0298  test_loss=3.7568  λ_max=75.6420\n",
      "[SGD | lr=0.05] Epoch 1971/4000: train_loss=0.0298  test_loss=3.7574  λ_max=75.7755\n",
      "[SGD | lr=0.05] Epoch 1972/4000: train_loss=0.0298  test_loss=3.7577  λ_max=75.1336\n",
      "[SGD | lr=0.05] Epoch 1973/4000: train_loss=0.0297  test_loss=3.7581  λ_max=71.8530\n",
      "[SGD | lr=0.05] Epoch 1974/4000: train_loss=0.0297  test_loss=3.7590  λ_max=73.0334\n",
      "[SGD | lr=0.05] Iter 31600: loss=0.0300\n",
      "[SGD | lr=0.05] Epoch 1975/4000: train_loss=0.0297  test_loss=3.7590  λ_max=75.1962\n",
      "[SGD | lr=0.05] Epoch 1976/4000: train_loss=0.0297  test_loss=3.7594  λ_max=76.2356\n",
      "[SGD | lr=0.05] Epoch 1977/4000: train_loss=0.0296  test_loss=3.7601  λ_max=76.1093\n",
      "[SGD | lr=0.05] Epoch 1978/4000: train_loss=0.0296  test_loss=3.7608  λ_max=75.5527\n",
      "[SGD | lr=0.05] Epoch 1979/4000: train_loss=0.0296  test_loss=3.7609  λ_max=73.7478\n",
      "[SGD | lr=0.05] Epoch 1980/4000: train_loss=0.0296  test_loss=3.7617  λ_max=75.6674\n",
      "[SGD | lr=0.05] Epoch 1981/4000: train_loss=0.0295  test_loss=3.7621  λ_max=74.5548\n",
      "[SGD | lr=0.05] Iter 31700: loss=0.0292\n",
      "[SGD | lr=0.05] Epoch 1982/4000: train_loss=0.0295  test_loss=3.7623  λ_max=75.5054\n",
      "[SGD | lr=0.05] Epoch 1983/4000: train_loss=0.0295  test_loss=3.7631  λ_max=75.8509\n",
      "[SGD | lr=0.05] Epoch 1984/4000: train_loss=0.0295  test_loss=3.7636  λ_max=76.8123\n",
      "[SGD | lr=0.05] Epoch 1985/4000: train_loss=0.0295  test_loss=3.7640  λ_max=75.1799\n",
      "[SGD | lr=0.05] Epoch 1986/4000: train_loss=0.0294  test_loss=3.7644  λ_max=74.5558\n",
      "[SGD | lr=0.05] Epoch 1987/4000: train_loss=0.0294  test_loss=3.7645  λ_max=75.3996\n",
      "[SGD | lr=0.05] Iter 31800: loss=0.0291\n",
      "[SGD | lr=0.05] Epoch 1988/4000: train_loss=0.0294  test_loss=3.7653  λ_max=75.7865\n",
      "[SGD | lr=0.05] Epoch 1989/4000: train_loss=0.0294  test_loss=3.7657  λ_max=75.7758\n",
      "[SGD | lr=0.05] Epoch 1990/4000: train_loss=0.0294  test_loss=3.7658  λ_max=75.5616\n",
      "[SGD | lr=0.05] Epoch 1991/4000: train_loss=0.0293  test_loss=3.7668  λ_max=76.0168\n",
      "[SGD | lr=0.05] Epoch 1992/4000: train_loss=0.0293  test_loss=3.7673  λ_max=73.4663\n",
      "[SGD | lr=0.05] Epoch 1993/4000: train_loss=0.0293  test_loss=3.7672  λ_max=75.4296\n",
      "[SGD | lr=0.05] Iter 31900: loss=0.0295\n",
      "[SGD | lr=0.05] Epoch 1994/4000: train_loss=0.0292  test_loss=3.7679  λ_max=76.1188\n",
      "[SGD | lr=0.05] Epoch 1995/4000: train_loss=0.0292  test_loss=3.7681  λ_max=73.8004\n",
      "[SGD | lr=0.05] Epoch 1996/4000: train_loss=0.0292  test_loss=3.7688  λ_max=74.7528\n",
      "[SGD | lr=0.05] Epoch 1997/4000: train_loss=0.0292  test_loss=3.7694  λ_max=75.5350\n",
      "[SGD | lr=0.05] Epoch 1998/4000: train_loss=0.0292  test_loss=3.7698  λ_max=74.2651\n",
      "[SGD | lr=0.05] Epoch 1999/4000: train_loss=0.0291  test_loss=3.7700  λ_max=75.0356\n",
      "[SGD | lr=0.05] Iter 32000: loss=0.0293\n",
      "[SGD | lr=0.05] Epoch 2000/4000: train_loss=0.0291  test_loss=3.7708  λ_max=75.7216\n",
      "[SGD | lr=0.05] Epoch 2001/4000: train_loss=0.0291  test_loss=3.7711  λ_max=70.8828\n",
      "[SGD | lr=0.05] Epoch 2002/4000: train_loss=0.0291  test_loss=3.7718  λ_max=75.8985\n",
      "[SGD | lr=0.05] Epoch 2003/4000: train_loss=0.0290  test_loss=3.7719  λ_max=75.0726\n",
      "[SGD | lr=0.05] Epoch 2004/4000: train_loss=0.0290  test_loss=3.7728  λ_max=76.1180\n",
      "[SGD | lr=0.05] Epoch 2005/4000: train_loss=0.0290  test_loss=3.7726  λ_max=76.1934\n",
      "[SGD | lr=0.05] Epoch 2006/4000: train_loss=0.0290  test_loss=3.7737  λ_max=74.7151\n",
      "[SGD | lr=0.05] Iter 32100: loss=0.0293\n",
      "[SGD | lr=0.05] Epoch 2007/4000: train_loss=0.0289  test_loss=3.7739  λ_max=74.2106\n",
      "[SGD | lr=0.05] Epoch 2008/4000: train_loss=0.0289  test_loss=3.7743  λ_max=74.2227\n",
      "[SGD | lr=0.05] Epoch 2009/4000: train_loss=0.0289  test_loss=3.7746  λ_max=75.9690\n",
      "[SGD | lr=0.05] Epoch 2010/4000: train_loss=0.0289  test_loss=3.7752  λ_max=75.2679\n",
      "[SGD | lr=0.05] Epoch 2011/4000: train_loss=0.0288  test_loss=3.7756  λ_max=74.8254\n",
      "[SGD | lr=0.05] Epoch 2012/4000: train_loss=0.0288  test_loss=3.7762  λ_max=76.1057\n",
      "[SGD | lr=0.05] Iter 32200: loss=0.0284\n",
      "[SGD | lr=0.05] Epoch 2013/4000: train_loss=0.0288  test_loss=3.7762  λ_max=77.8426\n",
      "[SGD | lr=0.05] Epoch 2014/4000: train_loss=0.0288  test_loss=3.7771  λ_max=74.7446\n",
      "[SGD | lr=0.05] Epoch 2015/4000: train_loss=0.0288  test_loss=3.7772  λ_max=76.7164\n",
      "[SGD | lr=0.05] Epoch 2016/4000: train_loss=0.0287  test_loss=3.7780  λ_max=75.3812\n",
      "[SGD | lr=0.05] Epoch 2017/4000: train_loss=0.0287  test_loss=3.7786  λ_max=77.5372\n",
      "[SGD | lr=0.05] Epoch 2018/4000: train_loss=0.0287  test_loss=3.7789  λ_max=74.8526\n",
      "[SGD | lr=0.05] Iter 32300: loss=0.0286\n",
      "[SGD | lr=0.05] Epoch 2019/4000: train_loss=0.0287  test_loss=3.7794  λ_max=76.4673\n",
      "[SGD | lr=0.05] Epoch 2020/4000: train_loss=0.0286  test_loss=3.7797  λ_max=78.2020\n",
      "[SGD | lr=0.05] Epoch 2021/4000: train_loss=0.0286  test_loss=3.7804  λ_max=73.5477\n",
      "[SGD | lr=0.05] Epoch 2022/4000: train_loss=0.0286  test_loss=3.7808  λ_max=75.4446\n",
      "[SGD | lr=0.05] Epoch 2023/4000: train_loss=0.0286  test_loss=3.7811  λ_max=77.7470\n",
      "[SGD | lr=0.05] Epoch 2024/4000: train_loss=0.0285  test_loss=3.7821  λ_max=76.3760\n",
      "[SGD | lr=0.05] Iter 32400: loss=0.0280\n",
      "[SGD | lr=0.05] Epoch 2025/4000: train_loss=0.0285  test_loss=3.7824  λ_max=76.2729\n",
      "[SGD | lr=0.05] Epoch 2026/4000: train_loss=0.0285  test_loss=3.7829  λ_max=76.4411\n",
      "[SGD | lr=0.05] Epoch 2027/4000: train_loss=0.0285  test_loss=3.7826  λ_max=77.1740\n",
      "[SGD | lr=0.05] Epoch 2028/4000: train_loss=0.0285  test_loss=3.7835  λ_max=73.7436\n",
      "[SGD | lr=0.05] Epoch 2029/4000: train_loss=0.0284  test_loss=3.7842  λ_max=76.2496\n",
      "[SGD | lr=0.05] Epoch 2030/4000: train_loss=0.0284  test_loss=3.7842  λ_max=77.5249\n",
      "[SGD | lr=0.05] Epoch 2031/4000: train_loss=0.0284  test_loss=3.7847  λ_max=77.2364\n",
      "[SGD | lr=0.05] Iter 32500: loss=0.0277\n",
      "[SGD | lr=0.05] Epoch 2032/4000: train_loss=0.0284  test_loss=3.7854  λ_max=76.8042\n",
      "[SGD | lr=0.05] Epoch 2033/4000: train_loss=0.0284  test_loss=3.7857  λ_max=75.1920\n",
      "[SGD | lr=0.05] Epoch 2034/4000: train_loss=0.0283  test_loss=3.7862  λ_max=75.3528\n",
      "[SGD | lr=0.05] Epoch 2035/4000: train_loss=0.0283  test_loss=3.7868  λ_max=72.6576\n",
      "[SGD | lr=0.05] Epoch 2036/4000: train_loss=0.0283  test_loss=3.7869  λ_max=77.1870\n",
      "[SGD | lr=0.05] Epoch 2037/4000: train_loss=0.0283  test_loss=3.7874  λ_max=78.3591\n",
      "[SGD | lr=0.05] Iter 32600: loss=0.0278\n",
      "[SGD | lr=0.05] Epoch 2038/4000: train_loss=0.0283  test_loss=3.7878  λ_max=76.3528\n",
      "[SGD | lr=0.05] Epoch 2039/4000: train_loss=0.0282  test_loss=3.7882  λ_max=76.0179\n",
      "[SGD | lr=0.05] Epoch 2040/4000: train_loss=0.0282  test_loss=3.7888  λ_max=76.5838\n",
      "[SGD | lr=0.05] Epoch 2041/4000: train_loss=0.0282  test_loss=3.7892  λ_max=75.6218\n",
      "[SGD | lr=0.05] Epoch 2042/4000: train_loss=0.0281  test_loss=3.7895  λ_max=76.3285\n",
      "[SGD | lr=0.05] Epoch 2043/4000: train_loss=0.0281  test_loss=3.7902  λ_max=76.1017\n",
      "[SGD | lr=0.05] Iter 32700: loss=0.0280\n",
      "[SGD | lr=0.05] Epoch 2044/4000: train_loss=0.0281  test_loss=3.7908  λ_max=77.4762\n",
      "[SGD | lr=0.05] Epoch 2045/4000: train_loss=0.0281  test_loss=3.7914  λ_max=76.2002\n",
      "[SGD | lr=0.05] Epoch 2046/4000: train_loss=0.0281  test_loss=3.7915  λ_max=74.7768\n",
      "[SGD | lr=0.05] Epoch 2047/4000: train_loss=0.0280  test_loss=3.7919  λ_max=73.8416\n",
      "[SGD | lr=0.05] Epoch 2048/4000: train_loss=0.0280  test_loss=3.7923  λ_max=75.6888\n",
      "[SGD | lr=0.05] Epoch 2049/4000: train_loss=0.0280  test_loss=3.7929  λ_max=75.2437\n",
      "[SGD | lr=0.05] Iter 32800: loss=0.0287\n",
      "[SGD | lr=0.05] Epoch 2050/4000: train_loss=0.0280  test_loss=3.7932  λ_max=77.6955\n",
      "[SGD | lr=0.05] Epoch 2051/4000: train_loss=0.0279  test_loss=3.7941  λ_max=77.7352\n",
      "[SGD | lr=0.05] Epoch 2052/4000: train_loss=0.0279  test_loss=3.7946  λ_max=76.7682\n",
      "[SGD | lr=0.05] Epoch 2053/4000: train_loss=0.0279  test_loss=3.7948  λ_max=78.5773\n",
      "[SGD | lr=0.05] Epoch 2054/4000: train_loss=0.0279  test_loss=3.7951  λ_max=78.3847\n",
      "[SGD | lr=0.05] Epoch 2055/4000: train_loss=0.0279  test_loss=3.7961  λ_max=76.2114\n",
      "[SGD | lr=0.05] Epoch 2056/4000: train_loss=0.0278  test_loss=3.7962  λ_max=75.8469\n",
      "[SGD | lr=0.05] Iter 32900: loss=0.0271\n",
      "[SGD | lr=0.05] Epoch 2057/4000: train_loss=0.0278  test_loss=3.7964  λ_max=77.9074\n",
      "[SGD | lr=0.05] Epoch 2058/4000: train_loss=0.0278  test_loss=3.7968  λ_max=74.9730\n",
      "[SGD | lr=0.05] Epoch 2059/4000: train_loss=0.0278  test_loss=3.7974  λ_max=77.1218\n",
      "[SGD | lr=0.05] Epoch 2060/4000: train_loss=0.0278  test_loss=3.7977  λ_max=78.1211\n",
      "[SGD | lr=0.05] Epoch 2061/4000: train_loss=0.0277  test_loss=3.7983  λ_max=75.6397\n",
      "[SGD | lr=0.05] Epoch 2062/4000: train_loss=0.0277  test_loss=3.7987  λ_max=78.2368\n",
      "[SGD | lr=0.05] Iter 33000: loss=0.0277\n",
      "[SGD | lr=0.05] Epoch 2063/4000: train_loss=0.0277  test_loss=3.7993  λ_max=76.1738\n",
      "[SGD | lr=0.05] Epoch 2064/4000: train_loss=0.0277  test_loss=3.7995  λ_max=75.4919\n",
      "[SGD | lr=0.05] Epoch 2065/4000: train_loss=0.0277  test_loss=3.7996  λ_max=76.8578\n",
      "[SGD | lr=0.05] Epoch 2066/4000: train_loss=0.0276  test_loss=3.8005  λ_max=75.7600\n",
      "[SGD | lr=0.05] Epoch 2067/4000: train_loss=0.0276  test_loss=3.8009  λ_max=77.9793\n",
      "[SGD | lr=0.05] Epoch 2068/4000: train_loss=0.0276  test_loss=3.8014  λ_max=76.3495\n",
      "[SGD | lr=0.05] Iter 33100: loss=0.0273\n",
      "[SGD | lr=0.05] Epoch 2069/4000: train_loss=0.0276  test_loss=3.8016  λ_max=77.5265\n",
      "[SGD | lr=0.05] Epoch 2070/4000: train_loss=0.0276  test_loss=3.8025  λ_max=76.2824\n",
      "[SGD | lr=0.05] Epoch 2071/4000: train_loss=0.0275  test_loss=3.8027  λ_max=76.4977\n",
      "[SGD | lr=0.05] Epoch 2072/4000: train_loss=0.0275  test_loss=3.8033  λ_max=75.0184\n",
      "[SGD | lr=0.05] Epoch 2073/4000: train_loss=0.0275  test_loss=3.8035  λ_max=75.7670\n",
      "[SGD | lr=0.05] Epoch 2074/4000: train_loss=0.0274  test_loss=3.8041  λ_max=74.4804\n",
      "[SGD | lr=0.05] Iter 33200: loss=0.0271\n",
      "[SGD | lr=0.05] Epoch 2075/4000: train_loss=0.0274  test_loss=3.8044  λ_max=77.3651\n",
      "[SGD | lr=0.05] Epoch 2076/4000: train_loss=0.0274  test_loss=3.8048  λ_max=74.4337\n",
      "[SGD | lr=0.05] Epoch 2077/4000: train_loss=0.0274  test_loss=3.8053  λ_max=79.7606\n",
      "[SGD | lr=0.05] Epoch 2078/4000: train_loss=0.0274  test_loss=3.8061  λ_max=78.0625\n",
      "[SGD | lr=0.05] Epoch 2079/4000: train_loss=0.0274  test_loss=3.8064  λ_max=76.7531\n",
      "[SGD | lr=0.05] Epoch 2080/4000: train_loss=0.0273  test_loss=3.8068  λ_max=77.2303\n",
      "[SGD | lr=0.05] Epoch 2081/4000: train_loss=0.0273  test_loss=3.8071  λ_max=77.5809\n",
      "[SGD | lr=0.05] Iter 33300: loss=0.0274\n",
      "[SGD | lr=0.05] Epoch 2082/4000: train_loss=0.0273  test_loss=3.8073  λ_max=75.4784\n",
      "[SGD | lr=0.05] Epoch 2083/4000: train_loss=0.0273  test_loss=3.8079  λ_max=78.2121\n",
      "[SGD | lr=0.05] Epoch 2084/4000: train_loss=0.0272  test_loss=3.8085  λ_max=77.8509\n",
      "[SGD | lr=0.05] Epoch 2085/4000: train_loss=0.0272  test_loss=3.8088  λ_max=78.6266\n",
      "[SGD | lr=0.05] Epoch 2086/4000: train_loss=0.0272  test_loss=3.8098  λ_max=77.6688\n",
      "[SGD | lr=0.05] Epoch 2087/4000: train_loss=0.0272  test_loss=3.8094  λ_max=77.8841\n",
      "[SGD | lr=0.05] Iter 33400: loss=0.0269\n",
      "[SGD | lr=0.05] Epoch 2088/4000: train_loss=0.0272  test_loss=3.8101  λ_max=75.1047\n",
      "[SGD | lr=0.05] Epoch 2089/4000: train_loss=0.0271  test_loss=3.8105  λ_max=77.0834\n",
      "[SGD | lr=0.05] Epoch 2090/4000: train_loss=0.0271  test_loss=3.8109  λ_max=76.2169\n",
      "[SGD | lr=0.05] Epoch 2091/4000: train_loss=0.0271  test_loss=3.8115  λ_max=77.0280\n",
      "[SGD | lr=0.05] Epoch 2092/4000: train_loss=0.0271  test_loss=3.8119  λ_max=76.1511\n",
      "[SGD | lr=0.05] Epoch 2093/4000: train_loss=0.0271  test_loss=3.8120  λ_max=76.4558\n",
      "[SGD | lr=0.05] Iter 33500: loss=0.0267\n",
      "[SGD | lr=0.05] Epoch 2094/4000: train_loss=0.0271  test_loss=3.8129  λ_max=76.2444\n",
      "[SGD | lr=0.05] Epoch 2095/4000: train_loss=0.0270  test_loss=3.8133  λ_max=76.6156\n",
      "[SGD | lr=0.05] Epoch 2096/4000: train_loss=0.0270  test_loss=3.8137  λ_max=76.3715\n",
      "[SGD | lr=0.05] Epoch 2097/4000: train_loss=0.0270  test_loss=3.8139  λ_max=75.2923\n",
      "[SGD | lr=0.05] Epoch 2098/4000: train_loss=0.0269  test_loss=3.8144  λ_max=77.3493\n",
      "[SGD | lr=0.05] Epoch 2099/4000: train_loss=0.0269  test_loss=3.8146  λ_max=77.8288\n",
      "[SGD | lr=0.05] Iter 33600: loss=0.0266\n",
      "[SGD | lr=0.05] Epoch 2100/4000: train_loss=0.0269  test_loss=3.8152  λ_max=75.0401\n",
      "[SGD | lr=0.05] Epoch 2101/4000: train_loss=0.0269  test_loss=3.8156  λ_max=78.3040\n",
      "[SGD | lr=0.05] Epoch 2102/4000: train_loss=0.0269  test_loss=3.8162  λ_max=76.5531\n",
      "[SGD | lr=0.05] Epoch 2103/4000: train_loss=0.0269  test_loss=3.8166  λ_max=76.3751\n",
      "[SGD | lr=0.05] Epoch 2104/4000: train_loss=0.0268  test_loss=3.8169  λ_max=76.8655\n",
      "[SGD | lr=0.05] Epoch 2105/4000: train_loss=0.0268  test_loss=3.8173  λ_max=75.7761\n",
      "[SGD | lr=0.05] Epoch 2106/4000: train_loss=0.0268  test_loss=3.8179  λ_max=77.1984\n",
      "[SGD | lr=0.05] Iter 33700: loss=0.0262\n",
      "[SGD | lr=0.05] Epoch 2107/4000: train_loss=0.0268  test_loss=3.8180  λ_max=77.9303\n",
      "[SGD | lr=0.05] Epoch 2108/4000: train_loss=0.0268  test_loss=3.8185  λ_max=77.6123\n",
      "[SGD | lr=0.05] Epoch 2109/4000: train_loss=0.0267  test_loss=3.8191  λ_max=77.6453\n",
      "[SGD | lr=0.05] Epoch 2110/4000: train_loss=0.0267  test_loss=3.8195  λ_max=74.2572\n",
      "[SGD | lr=0.05] Epoch 2111/4000: train_loss=0.0267  test_loss=3.8198  λ_max=78.7994\n",
      "[SGD | lr=0.05] Epoch 2112/4000: train_loss=0.0267  test_loss=3.8206  λ_max=77.6838\n",
      "[SGD | lr=0.05] Iter 33800: loss=0.0265\n",
      "[SGD | lr=0.05] Epoch 2113/4000: train_loss=0.0266  test_loss=3.8209  λ_max=77.4337\n",
      "[SGD | lr=0.05] Epoch 2114/4000: train_loss=0.0266  test_loss=3.8211  λ_max=79.0414\n",
      "[SGD | lr=0.05] Epoch 2115/4000: train_loss=0.0266  test_loss=3.8223  λ_max=78.2176\n",
      "[SGD | lr=0.05] Epoch 2116/4000: train_loss=0.0266  test_loss=3.8223  λ_max=76.0229\n",
      "[SGD | lr=0.05] Epoch 2117/4000: train_loss=0.0266  test_loss=3.8224  λ_max=78.0215\n",
      "[SGD | lr=0.05] Epoch 2118/4000: train_loss=0.0265  test_loss=3.8231  λ_max=76.9532\n",
      "[SGD | lr=0.05] Iter 33900: loss=0.0268\n",
      "[SGD | lr=0.05] Epoch 2119/4000: train_loss=0.0265  test_loss=3.8232  λ_max=75.6508\n",
      "[SGD | lr=0.05] Epoch 2120/4000: train_loss=0.0265  test_loss=3.8238  λ_max=79.5725\n",
      "[SGD | lr=0.05] Epoch 2121/4000: train_loss=0.0265  test_loss=3.8244  λ_max=76.4041\n",
      "[SGD | lr=0.05] Epoch 2122/4000: train_loss=0.0265  test_loss=3.8249  λ_max=78.0807\n",
      "[SGD | lr=0.05] Epoch 2123/4000: train_loss=0.0265  test_loss=3.8250  λ_max=75.9497\n",
      "[SGD | lr=0.05] Epoch 2124/4000: train_loss=0.0264  test_loss=3.8258  λ_max=78.0919\n",
      "[SGD | lr=0.05] Iter 34000: loss=0.0269\n",
      "[SGD | lr=0.05] Epoch 2125/4000: train_loss=0.0264  test_loss=3.8262  λ_max=77.5316\n",
      "[SGD | lr=0.05] Epoch 2126/4000: train_loss=0.0264  test_loss=3.8265  λ_max=79.5363\n",
      "[SGD | lr=0.05] Epoch 2127/4000: train_loss=0.0264  test_loss=3.8271  λ_max=75.8999\n",
      "[SGD | lr=0.05] Epoch 2128/4000: train_loss=0.0263  test_loss=3.8274  λ_max=76.0680\n",
      "[SGD | lr=0.05] Epoch 2129/4000: train_loss=0.0263  test_loss=3.8276  λ_max=77.8579\n",
      "[SGD | lr=0.05] Epoch 2130/4000: train_loss=0.0263  test_loss=3.8278  λ_max=77.0969\n",
      "[SGD | lr=0.05] Epoch 2131/4000: train_loss=0.0263  test_loss=3.8285  λ_max=75.8441\n",
      "[SGD | lr=0.05] Iter 34100: loss=0.0261\n",
      "[SGD | lr=0.05] Epoch 2132/4000: train_loss=0.0263  test_loss=3.8289  λ_max=77.5487\n",
      "[SGD | lr=0.05] Epoch 2133/4000: train_loss=0.0263  test_loss=3.8292  λ_max=77.4045\n",
      "[SGD | lr=0.05] Epoch 2134/4000: train_loss=0.0262  test_loss=3.8298  λ_max=77.7526\n",
      "[SGD | lr=0.05] Epoch 2135/4000: train_loss=0.0262  test_loss=3.8300  λ_max=75.7746\n",
      "[SGD | lr=0.05] Epoch 2136/4000: train_loss=0.0262  test_loss=3.8305  λ_max=76.1558\n",
      "[SGD | lr=0.05] Epoch 2137/4000: train_loss=0.0262  test_loss=3.8310  λ_max=76.7138\n",
      "[SGD | lr=0.05] Iter 34200: loss=0.0260\n",
      "[SGD | lr=0.05] Epoch 2138/4000: train_loss=0.0262  test_loss=3.8317  λ_max=75.1949\n",
      "[SGD | lr=0.05] Epoch 2139/4000: train_loss=0.0261  test_loss=3.8322  λ_max=78.5695\n",
      "[SGD | lr=0.05] Epoch 2140/4000: train_loss=0.0261  test_loss=3.8325  λ_max=77.2548\n",
      "[SGD | lr=0.05] Epoch 2141/4000: train_loss=0.0261  test_loss=3.8330  λ_max=79.4166\n",
      "[SGD | lr=0.05] Epoch 2142/4000: train_loss=0.0261  test_loss=3.8336  λ_max=76.4883\n",
      "[SGD | lr=0.05] Epoch 2143/4000: train_loss=0.0261  test_loss=3.8335  λ_max=77.7389\n",
      "[SGD | lr=0.05] Iter 34300: loss=0.0265\n",
      "[SGD | lr=0.05] Epoch 2144/4000: train_loss=0.0260  test_loss=3.8341  λ_max=79.8792\n",
      "[SGD | lr=0.05] Epoch 2145/4000: train_loss=0.0260  test_loss=3.8345  λ_max=76.1656\n",
      "[SGD | lr=0.05] Epoch 2146/4000: train_loss=0.0260  test_loss=3.8347  λ_max=79.0640\n",
      "[SGD | lr=0.05] Epoch 2147/4000: train_loss=0.0260  test_loss=3.8354  λ_max=78.1872\n",
      "[SGD | lr=0.05] Epoch 2148/4000: train_loss=0.0260  test_loss=3.8356  λ_max=78.1620\n",
      "[SGD | lr=0.05] Epoch 2149/4000: train_loss=0.0260  test_loss=3.8360  λ_max=77.6550\n",
      "[SGD | lr=0.05] Iter 34400: loss=0.0267\n",
      "[SGD | lr=0.05] Epoch 2150/4000: train_loss=0.0259  test_loss=3.8365  λ_max=77.2364\n",
      "[SGD | lr=0.05] Epoch 2151/4000: train_loss=0.0259  test_loss=3.8369  λ_max=78.0300\n",
      "[SGD | lr=0.05] Epoch 2152/4000: train_loss=0.0259  test_loss=3.8377  λ_max=79.4294\n",
      "[SGD | lr=0.05] Epoch 2153/4000: train_loss=0.0259  test_loss=3.8377  λ_max=77.3591\n",
      "[SGD | lr=0.05] Epoch 2154/4000: train_loss=0.0259  test_loss=3.8380  λ_max=79.6262\n",
      "[SGD | lr=0.05] Epoch 2155/4000: train_loss=0.0258  test_loss=3.8386  λ_max=76.5358\n",
      "[SGD | lr=0.05] Epoch 2156/4000: train_loss=0.0258  test_loss=3.8393  λ_max=79.5456\n",
      "[SGD | lr=0.05] Iter 34500: loss=0.0255\n",
      "[SGD | lr=0.05] Epoch 2157/4000: train_loss=0.0258  test_loss=3.8394  λ_max=79.4447\n",
      "[SGD | lr=0.05] Epoch 2158/4000: train_loss=0.0258  test_loss=3.8399  λ_max=77.9247\n",
      "[SGD | lr=0.05] Epoch 2159/4000: train_loss=0.0258  test_loss=3.8402  λ_max=77.2049\n",
      "[SGD | lr=0.05] Epoch 2160/4000: train_loss=0.0258  test_loss=3.8408  λ_max=77.5808\n",
      "[SGD | lr=0.05] Epoch 2161/4000: train_loss=0.0257  test_loss=3.8410  λ_max=77.7444\n",
      "[SGD | lr=0.05] Epoch 2162/4000: train_loss=0.0257  test_loss=3.8419  λ_max=78.0613\n",
      "[SGD | lr=0.05] Iter 34600: loss=0.0260\n",
      "[SGD | lr=0.05] Epoch 2163/4000: train_loss=0.0257  test_loss=3.8420  λ_max=77.0256\n",
      "[SGD | lr=0.05] Epoch 2164/4000: train_loss=0.0257  test_loss=3.8425  λ_max=79.2303\n",
      "[SGD | lr=0.05] Epoch 2165/4000: train_loss=0.0257  test_loss=3.8430  λ_max=77.5574\n",
      "[SGD | lr=0.05] Epoch 2166/4000: train_loss=0.0256  test_loss=3.8434  λ_max=77.5752\n",
      "[SGD | lr=0.05] Epoch 2167/4000: train_loss=0.0256  test_loss=3.8435  λ_max=78.9968\n",
      "[SGD | lr=0.05] Epoch 2168/4000: train_loss=0.0256  test_loss=3.8441  λ_max=78.6259\n",
      "[SGD | lr=0.05] Iter 34700: loss=0.0259\n",
      "[SGD | lr=0.05] Epoch 2169/4000: train_loss=0.0256  test_loss=3.8447  λ_max=76.7264\n",
      "[SGD | lr=0.05] Epoch 2170/4000: train_loss=0.0256  test_loss=3.8450  λ_max=76.5223\n",
      "[SGD | lr=0.05] Epoch 2171/4000: train_loss=0.0255  test_loss=3.8457  λ_max=77.5355\n",
      "[SGD | lr=0.05] Epoch 2172/4000: train_loss=0.0255  test_loss=3.8458  λ_max=76.8384\n",
      "[SGD | lr=0.05] Epoch 2173/4000: train_loss=0.0255  test_loss=3.8461  λ_max=78.3390\n",
      "[SGD | lr=0.05] Epoch 2174/4000: train_loss=0.0255  test_loss=3.8463  λ_max=77.1842\n",
      "[SGD | lr=0.05] Iter 34800: loss=0.0250\n",
      "[SGD | lr=0.05] Epoch 2175/4000: train_loss=0.0255  test_loss=3.8471  λ_max=78.7868\n",
      "[SGD | lr=0.05] Epoch 2176/4000: train_loss=0.0254  test_loss=3.8474  λ_max=78.9366\n",
      "[SGD | lr=0.05] Epoch 2177/4000: train_loss=0.0254  test_loss=3.8479  λ_max=79.5288\n",
      "[SGD | lr=0.05] Epoch 2178/4000: train_loss=0.0254  test_loss=3.8487  λ_max=77.5822\n",
      "[SGD | lr=0.05] Epoch 2179/4000: train_loss=0.0254  test_loss=3.8488  λ_max=79.6079\n",
      "[SGD | lr=0.05] Epoch 2180/4000: train_loss=0.0254  test_loss=3.8492  λ_max=76.1444\n",
      "[SGD | lr=0.05] Epoch 2181/4000: train_loss=0.0254  test_loss=3.8492  λ_max=78.3290\n",
      "[SGD | lr=0.05] Iter 34900: loss=0.0254\n",
      "[SGD | lr=0.05] Epoch 2182/4000: train_loss=0.0253  test_loss=3.8497  λ_max=78.6812\n",
      "[SGD | lr=0.05] Epoch 2183/4000: train_loss=0.0253  test_loss=3.8504  λ_max=78.5971\n",
      "[SGD | lr=0.05] Epoch 2184/4000: train_loss=0.0253  test_loss=3.8506  λ_max=78.6772\n",
      "[SGD | lr=0.05] Epoch 2185/4000: train_loss=0.0253  test_loss=3.8512  λ_max=78.8005\n",
      "[SGD | lr=0.05] Epoch 2186/4000: train_loss=0.0253  test_loss=3.8516  λ_max=78.6639\n",
      "[SGD | lr=0.05] Epoch 2187/4000: train_loss=0.0252  test_loss=3.8522  λ_max=79.9447\n",
      "[SGD | lr=0.05] Iter 35000: loss=0.0255\n",
      "[SGD | lr=0.05] Epoch 2188/4000: train_loss=0.0252  test_loss=3.8525  λ_max=75.2997\n",
      "[SGD | lr=0.05] Epoch 2189/4000: train_loss=0.0252  test_loss=3.8529  λ_max=78.9689\n",
      "[SGD | lr=0.05] Epoch 2190/4000: train_loss=0.0252  test_loss=3.8532  λ_max=78.4847\n",
      "[SGD | lr=0.05] Epoch 2191/4000: train_loss=0.0252  test_loss=3.8534  λ_max=79.3488\n",
      "[SGD | lr=0.05] Epoch 2192/4000: train_loss=0.0252  test_loss=3.8543  λ_max=76.5173\n",
      "[SGD | lr=0.05] Epoch 2193/4000: train_loss=0.0251  test_loss=3.8547  λ_max=78.3866\n",
      "[SGD | lr=0.05] Iter 35100: loss=0.0249\n",
      "[SGD | lr=0.05] Epoch 2194/4000: train_loss=0.0251  test_loss=3.8554  λ_max=78.4780\n",
      "[SGD | lr=0.05] Epoch 2195/4000: train_loss=0.0251  test_loss=3.8552  λ_max=78.2757\n",
      "[SGD | lr=0.05] Epoch 2196/4000: train_loss=0.0251  test_loss=3.8558  λ_max=78.6127\n",
      "[SGD | lr=0.05] Epoch 2197/4000: train_loss=0.0250  test_loss=3.8560  λ_max=79.1846\n",
      "[SGD | lr=0.05] Epoch 2198/4000: train_loss=0.0250  test_loss=3.8564  λ_max=77.1560\n",
      "[SGD | lr=0.05] Epoch 2199/4000: train_loss=0.0250  test_loss=3.8569  λ_max=78.6703\n",
      "[SGD | lr=0.05] Iter 35200: loss=0.0248\n",
      "[SGD | lr=0.05] Epoch 2200/4000: train_loss=0.0250  test_loss=3.8573  λ_max=78.5274\n",
      "[SGD | lr=0.05] Epoch 2201/4000: train_loss=0.0250  test_loss=3.8579  λ_max=79.4205\n",
      "[SGD | lr=0.05] Epoch 2202/4000: train_loss=0.0250  test_loss=3.8583  λ_max=77.5484\n",
      "[SGD | lr=0.05] Epoch 2203/4000: train_loss=0.0250  test_loss=3.8584  λ_max=79.8645\n",
      "[SGD | lr=0.05] Epoch 2204/4000: train_loss=0.0249  test_loss=3.8590  λ_max=78.1435\n",
      "[SGD | lr=0.05] Epoch 2205/4000: train_loss=0.0249  test_loss=3.8595  λ_max=76.4127\n",
      "[SGD | lr=0.05] Epoch 2206/4000: train_loss=0.0249  test_loss=3.8598  λ_max=81.1805\n",
      "[SGD | lr=0.05] Iter 35300: loss=0.0246\n",
      "[SGD | lr=0.05] Epoch 2207/4000: train_loss=0.0249  test_loss=3.8600  λ_max=79.7085\n",
      "[SGD | lr=0.05] Epoch 2208/4000: train_loss=0.0249  test_loss=3.8606  λ_max=76.6109\n",
      "[SGD | lr=0.05] Epoch 2209/4000: train_loss=0.0248  test_loss=3.8609  λ_max=77.4114\n",
      "[SGD | lr=0.05] Epoch 2210/4000: train_loss=0.0248  test_loss=3.8618  λ_max=81.3951\n",
      "[SGD | lr=0.05] Epoch 2211/4000: train_loss=0.0248  test_loss=3.8621  λ_max=79.2398\n",
      "[SGD | lr=0.05] Epoch 2212/4000: train_loss=0.0248  test_loss=3.8625  λ_max=78.6533\n",
      "[SGD | lr=0.05] Iter 35400: loss=0.0247\n",
      "[SGD | lr=0.05] Epoch 2213/4000: train_loss=0.0248  test_loss=3.8629  λ_max=79.8389\n",
      "[SGD | lr=0.05] Epoch 2214/4000: train_loss=0.0248  test_loss=3.8632  λ_max=78.6403\n",
      "[SGD | lr=0.05] Epoch 2215/4000: train_loss=0.0247  test_loss=3.8637  λ_max=79.4078\n",
      "[SGD | lr=0.05] Epoch 2216/4000: train_loss=0.0247  test_loss=3.8638  λ_max=78.8988\n",
      "[SGD | lr=0.05] Epoch 2217/4000: train_loss=0.0247  test_loss=3.8640  λ_max=79.1532\n",
      "[SGD | lr=0.05] Epoch 2218/4000: train_loss=0.0247  test_loss=3.8645  λ_max=77.9796\n",
      "[SGD | lr=0.05] Iter 35500: loss=0.0244\n",
      "[SGD | lr=0.05] Epoch 2219/4000: train_loss=0.0247  test_loss=3.8651  λ_max=79.5417\n",
      "[SGD | lr=0.05] Epoch 2220/4000: train_loss=0.0247  test_loss=3.8653  λ_max=80.1869\n",
      "[SGD | lr=0.05] Epoch 2221/4000: train_loss=0.0246  test_loss=3.8655  λ_max=80.4981\n",
      "[SGD | lr=0.05] Epoch 2222/4000: train_loss=0.0246  test_loss=3.8664  λ_max=78.4642\n",
      "[SGD | lr=0.05] Epoch 2223/4000: train_loss=0.0246  test_loss=3.8666  λ_max=78.8060\n",
      "[SGD | lr=0.05] Epoch 2224/4000: train_loss=0.0246  test_loss=3.8671  λ_max=78.6519\n",
      "[SGD | lr=0.05] Iter 35600: loss=0.0253\n",
      "[SGD | lr=0.05] Epoch 2225/4000: train_loss=0.0246  test_loss=3.8675  λ_max=78.5491\n",
      "[SGD | lr=0.05] Epoch 2226/4000: train_loss=0.0245  test_loss=3.8680  λ_max=79.8356\n",
      "[SGD | lr=0.05] Epoch 2227/4000: train_loss=0.0246  test_loss=3.8683  λ_max=76.6477\n",
      "[SGD | lr=0.05] Epoch 2228/4000: train_loss=0.0245  test_loss=3.8689  λ_max=80.8416\n",
      "[SGD | lr=0.05] Epoch 2229/4000: train_loss=0.0245  test_loss=3.8692  λ_max=80.7312\n",
      "[SGD | lr=0.05] Epoch 2230/4000: train_loss=0.0245  test_loss=3.8699  λ_max=77.8906\n",
      "[SGD | lr=0.05] Epoch 2231/4000: train_loss=0.0245  test_loss=3.8701  λ_max=77.3080\n",
      "[SGD | lr=0.05] Iter 35700: loss=0.0247\n",
      "[SGD | lr=0.05] Epoch 2232/4000: train_loss=0.0244  test_loss=3.8705  λ_max=81.2682\n",
      "[SGD | lr=0.05] Epoch 2233/4000: train_loss=0.0244  test_loss=3.8711  λ_max=79.5457\n",
      "[SGD | lr=0.05] Epoch 2234/4000: train_loss=0.0244  test_loss=3.8713  λ_max=79.6523\n",
      "[SGD | lr=0.05] Epoch 2235/4000: train_loss=0.0244  test_loss=3.8716  λ_max=78.0169\n",
      "[SGD | lr=0.05] Epoch 2236/4000: train_loss=0.0244  test_loss=3.8718  λ_max=78.2831\n",
      "[SGD | lr=0.05] Epoch 2237/4000: train_loss=0.0243  test_loss=3.8726  λ_max=79.6400\n",
      "[SGD | lr=0.05] Iter 35800: loss=0.0245\n",
      "[SGD | lr=0.05] Epoch 2238/4000: train_loss=0.0243  test_loss=3.8728  λ_max=76.7495\n",
      "[SGD | lr=0.05] Epoch 2239/4000: train_loss=0.0243  test_loss=3.8730  λ_max=78.3628\n",
      "[SGD | lr=0.05] Epoch 2240/4000: train_loss=0.0243  test_loss=3.8737  λ_max=79.7127\n",
      "[SGD | lr=0.05] Epoch 2241/4000: train_loss=0.0243  test_loss=3.8743  λ_max=79.7012\n",
      "[SGD | lr=0.05] Epoch 2242/4000: train_loss=0.0243  test_loss=3.8744  λ_max=80.2318\n",
      "[SGD | lr=0.05] Epoch 2243/4000: train_loss=0.0243  test_loss=3.8748  λ_max=79.4781\n",
      "[SGD | lr=0.05] Iter 35900: loss=0.0239\n",
      "[SGD | lr=0.05] Epoch 2244/4000: train_loss=0.0242  test_loss=3.8749  λ_max=81.2844\n",
      "[SGD | lr=0.05] Epoch 2245/4000: train_loss=0.0242  test_loss=3.8757  λ_max=78.6647\n",
      "[SGD | lr=0.05] Epoch 2246/4000: train_loss=0.0242  test_loss=3.8759  λ_max=76.8945\n",
      "[SGD | lr=0.05] Epoch 2247/4000: train_loss=0.0242  test_loss=3.8766  λ_max=75.3370\n",
      "[SGD | lr=0.05] Epoch 2248/4000: train_loss=0.0242  test_loss=3.8766  λ_max=75.3273\n",
      "[SGD | lr=0.05] Epoch 2249/4000: train_loss=0.0242  test_loss=3.8772  λ_max=81.5303\n",
      "[SGD | lr=0.05] Iter 36000: loss=0.0242\n",
      "[SGD | lr=0.05] Epoch 2250/4000: train_loss=0.0241  test_loss=3.8774  λ_max=77.8966\n",
      "[SGD | lr=0.05] Epoch 2251/4000: train_loss=0.0241  test_loss=3.8781  λ_max=80.9936\n",
      "[SGD | lr=0.05] Epoch 2252/4000: train_loss=0.0241  test_loss=3.8780  λ_max=78.8456\n",
      "[SGD | lr=0.05] Epoch 2253/4000: train_loss=0.0241  test_loss=3.8792  λ_max=79.5008\n",
      "[SGD | lr=0.05] Epoch 2254/4000: train_loss=0.0241  test_loss=3.8790  λ_max=76.5040\n",
      "[SGD | lr=0.05] Epoch 2255/4000: train_loss=0.0241  test_loss=3.8794  λ_max=79.9022\n",
      "[SGD | lr=0.05] Epoch 2256/4000: train_loss=0.0240  test_loss=3.8800  λ_max=79.5853\n",
      "[SGD | lr=0.05] Iter 36100: loss=0.0243\n",
      "[SGD | lr=0.05] Epoch 2257/4000: train_loss=0.0240  test_loss=3.8804  λ_max=76.9405\n",
      "[SGD | lr=0.05] Epoch 2258/4000: train_loss=0.0240  test_loss=3.8809  λ_max=80.7530\n",
      "[SGD | lr=0.05] Epoch 2259/4000: train_loss=0.0240  test_loss=3.8816  λ_max=81.0295\n",
      "[SGD | lr=0.05] Epoch 2260/4000: train_loss=0.0240  test_loss=3.8813  λ_max=79.4431\n",
      "[SGD | lr=0.05] Epoch 2261/4000: train_loss=0.0240  test_loss=3.8818  λ_max=80.2678\n",
      "[SGD | lr=0.05] Epoch 2262/4000: train_loss=0.0239  test_loss=3.8826  λ_max=80.6069\n",
      "[SGD | lr=0.05] Iter 36200: loss=0.0238\n",
      "[SGD | lr=0.05] Epoch 2263/4000: train_loss=0.0239  test_loss=3.8826  λ_max=80.4246\n",
      "[SGD | lr=0.05] Epoch 2264/4000: train_loss=0.0239  test_loss=3.8829  λ_max=79.7584\n",
      "[SGD | lr=0.05] Epoch 2265/4000: train_loss=0.0239  test_loss=3.8837  λ_max=80.1688\n",
      "[SGD | lr=0.05] Epoch 2266/4000: train_loss=0.0239  test_loss=3.8838  λ_max=77.3542\n",
      "[SGD | lr=0.05] Epoch 2267/4000: train_loss=0.0239  test_loss=3.8842  λ_max=81.1675\n",
      "[SGD | lr=0.05] Epoch 2268/4000: train_loss=0.0238  test_loss=3.8847  λ_max=79.2516\n",
      "[SGD | lr=0.05] Iter 36300: loss=0.0235\n",
      "[SGD | lr=0.05] Epoch 2269/4000: train_loss=0.0238  test_loss=3.8848  λ_max=78.6899\n",
      "[SGD | lr=0.05] Epoch 2270/4000: train_loss=0.0238  test_loss=3.8858  λ_max=80.7804\n",
      "[SGD | lr=0.05] Epoch 2271/4000: train_loss=0.0238  test_loss=3.8861  λ_max=78.6039\n",
      "[SGD | lr=0.05] Epoch 2272/4000: train_loss=0.0238  test_loss=3.8864  λ_max=80.7980\n",
      "[SGD | lr=0.05] Epoch 2273/4000: train_loss=0.0238  test_loss=3.8870  λ_max=80.3421\n",
      "[SGD | lr=0.05] Epoch 2274/4000: train_loss=0.0238  test_loss=3.8870  λ_max=79.5555\n",
      "[SGD | lr=0.05] Iter 36400: loss=0.0234\n",
      "[SGD | lr=0.05] Epoch 2275/4000: train_loss=0.0237  test_loss=3.8874  λ_max=76.7098\n",
      "[SGD | lr=0.05] Epoch 2276/4000: train_loss=0.0237  test_loss=3.8879  λ_max=78.4831\n",
      "[SGD | lr=0.05] Epoch 2277/4000: train_loss=0.0237  test_loss=3.8883  λ_max=80.2316\n",
      "[SGD | lr=0.05] Epoch 2278/4000: train_loss=0.0237  test_loss=3.8888  λ_max=79.9694\n",
      "[SGD | lr=0.05] Epoch 2279/4000: train_loss=0.0237  test_loss=3.8891  λ_max=79.6697\n",
      "[SGD | lr=0.05] Epoch 2280/4000: train_loss=0.0236  test_loss=3.8896  λ_max=78.5122\n",
      "[SGD | lr=0.05] Epoch 2281/4000: train_loss=0.0236  test_loss=3.8898  λ_max=79.0866\n",
      "[SGD | lr=0.05] Iter 36500: loss=0.0233\n",
      "[SGD | lr=0.05] Epoch 2282/4000: train_loss=0.0236  test_loss=3.8904  λ_max=75.5608\n",
      "[SGD | lr=0.05] Epoch 2283/4000: train_loss=0.0236  test_loss=3.8910  λ_max=80.1861\n",
      "[SGD | lr=0.05] Epoch 2284/4000: train_loss=0.0236  test_loss=3.8913  λ_max=81.1510\n",
      "[SGD | lr=0.05] Epoch 2285/4000: train_loss=0.0236  test_loss=3.8915  λ_max=81.9508\n",
      "[SGD | lr=0.05] Epoch 2286/4000: train_loss=0.0236  test_loss=3.8919  λ_max=77.8661\n",
      "[SGD | lr=0.05] Epoch 2287/4000: train_loss=0.0235  test_loss=3.8924  λ_max=77.8685\n",
      "[SGD | lr=0.05] Iter 36600: loss=0.0240\n",
      "[SGD | lr=0.05] Epoch 2288/4000: train_loss=0.0235  test_loss=3.8929  λ_max=79.7862\n",
      "[SGD | lr=0.05] Epoch 2289/4000: train_loss=0.0235  test_loss=3.8931  λ_max=77.8009\n",
      "[SGD | lr=0.05] Epoch 2290/4000: train_loss=0.0235  test_loss=3.8934  λ_max=79.6669\n",
      "[SGD | lr=0.05] Epoch 2291/4000: train_loss=0.0235  test_loss=3.8938  λ_max=79.1930\n",
      "[SGD | lr=0.05] Epoch 2292/4000: train_loss=0.0235  test_loss=3.8944  λ_max=80.5982\n",
      "[SGD | lr=0.05] Epoch 2293/4000: train_loss=0.0234  test_loss=3.8946  λ_max=77.1913\n",
      "[SGD | lr=0.05] Iter 36700: loss=0.0229\n",
      "[SGD | lr=0.05] Epoch 2294/4000: train_loss=0.0234  test_loss=3.8950  λ_max=80.9111\n",
      "[SGD | lr=0.05] Epoch 2295/4000: train_loss=0.0234  test_loss=3.8952  λ_max=79.2180\n",
      "[SGD | lr=0.05] Epoch 2296/4000: train_loss=0.0234  test_loss=3.8956  λ_max=79.5013\n",
      "[SGD | lr=0.05] Epoch 2297/4000: train_loss=0.0234  test_loss=3.8960  λ_max=81.3378\n",
      "[SGD | lr=0.05] Epoch 2298/4000: train_loss=0.0234  test_loss=3.8964  λ_max=79.0688\n",
      "[SGD | lr=0.05] Epoch 2299/4000: train_loss=0.0233  test_loss=3.8972  λ_max=80.5394\n",
      "[SGD | lr=0.05] Iter 36800: loss=0.0230\n",
      "[SGD | lr=0.05] Epoch 2300/4000: train_loss=0.0233  test_loss=3.8972  λ_max=81.6761\n",
      "[SGD | lr=0.05] Epoch 2301/4000: train_loss=0.0233  test_loss=3.8976  λ_max=79.6509\n",
      "[SGD | lr=0.05] Epoch 2302/4000: train_loss=0.0233  test_loss=3.8981  λ_max=78.6318\n",
      "[SGD | lr=0.05] Epoch 2303/4000: train_loss=0.0233  test_loss=3.8984  λ_max=79.6316\n",
      "[SGD | lr=0.05] Epoch 2304/4000: train_loss=0.0233  test_loss=3.8990  λ_max=77.5857\n",
      "[SGD | lr=0.05] Epoch 2305/4000: train_loss=0.0232  test_loss=3.8996  λ_max=80.0215\n",
      "[SGD | lr=0.05] Epoch 2306/4000: train_loss=0.0232  test_loss=3.8995  λ_max=80.6815\n",
      "[SGD | lr=0.05] Iter 36900: loss=0.0234\n",
      "[SGD | lr=0.05] Epoch 2307/4000: train_loss=0.0232  test_loss=3.9002  λ_max=79.4561\n",
      "[SGD | lr=0.05] Epoch 2308/4000: train_loss=0.0232  test_loss=3.9004  λ_max=78.8086\n",
      "[SGD | lr=0.05] Epoch 2309/4000: train_loss=0.0232  test_loss=3.9008  λ_max=79.2118\n",
      "[SGD | lr=0.05] Epoch 2310/4000: train_loss=0.0232  test_loss=3.9013  λ_max=79.0367\n",
      "[SGD | lr=0.05] Epoch 2311/4000: train_loss=0.0231  test_loss=3.9017  λ_max=80.1873\n",
      "[SGD | lr=0.05] Epoch 2312/4000: train_loss=0.0231  test_loss=3.9018  λ_max=79.8975\n",
      "[SGD | lr=0.05] Iter 37000: loss=0.0232\n",
      "[SGD | lr=0.05] Epoch 2313/4000: train_loss=0.0231  test_loss=3.9023  λ_max=81.8696\n",
      "[SGD | lr=0.05] Epoch 2314/4000: train_loss=0.0231  test_loss=3.9028  λ_max=79.6842\n",
      "[SGD | lr=0.05] Epoch 2315/4000: train_loss=0.0231  test_loss=3.9032  λ_max=78.5545\n",
      "[SGD | lr=0.05] Epoch 2316/4000: train_loss=0.0231  test_loss=3.9034  λ_max=80.4262\n",
      "[SGD | lr=0.05] Epoch 2317/4000: train_loss=0.0231  test_loss=3.9038  λ_max=81.7692\n",
      "[SGD | lr=0.05] Epoch 2318/4000: train_loss=0.0231  test_loss=3.9043  λ_max=81.8142\n",
      "[SGD | lr=0.05] Iter 37100: loss=0.0229\n",
      "[SGD | lr=0.05] Epoch 2319/4000: train_loss=0.0230  test_loss=3.9048  λ_max=79.8399\n",
      "[SGD | lr=0.05] Epoch 2320/4000: train_loss=0.0230  test_loss=3.9054  λ_max=81.0036\n",
      "[SGD | lr=0.05] Epoch 2321/4000: train_loss=0.0230  test_loss=3.9056  λ_max=81.7203\n",
      "[SGD | lr=0.05] Epoch 2322/4000: train_loss=0.0230  test_loss=3.9059  λ_max=80.9409\n",
      "[SGD | lr=0.05] Epoch 2323/4000: train_loss=0.0230  test_loss=3.9064  λ_max=80.3944\n",
      "[SGD | lr=0.05] Epoch 2324/4000: train_loss=0.0229  test_loss=3.9062  λ_max=80.8848\n",
      "[SGD | lr=0.05] Iter 37200: loss=0.0225\n",
      "[SGD | lr=0.05] Epoch 2325/4000: train_loss=0.0229  test_loss=3.9070  λ_max=79.9254\n",
      "[SGD | lr=0.05] Epoch 2326/4000: train_loss=0.0229  test_loss=3.9075  λ_max=80.6830\n",
      "[SGD | lr=0.05] Epoch 2327/4000: train_loss=0.0229  test_loss=3.9078  λ_max=83.1573\n",
      "[SGD | lr=0.05] Epoch 2328/4000: train_loss=0.0229  test_loss=3.9081  λ_max=80.2371\n",
      "[SGD | lr=0.05] Epoch 2329/4000: train_loss=0.0229  test_loss=3.9085  λ_max=78.4785\n",
      "[SGD | lr=0.05] Epoch 2330/4000: train_loss=0.0229  test_loss=3.9087  λ_max=80.0671\n",
      "[SGD | lr=0.05] Epoch 2331/4000: train_loss=0.0229  test_loss=3.9092  λ_max=80.7964\n",
      "[SGD | lr=0.05] Iter 37300: loss=0.0227\n",
      "[SGD | lr=0.05] Epoch 2332/4000: train_loss=0.0228  test_loss=3.9100  λ_max=81.5530\n",
      "[SGD | lr=0.05] Epoch 2333/4000: train_loss=0.0228  test_loss=3.9101  λ_max=81.0089\n",
      "[SGD | lr=0.05] Epoch 2334/4000: train_loss=0.0228  test_loss=3.9105  λ_max=81.9579\n",
      "[SGD | lr=0.05] Epoch 2335/4000: train_loss=0.0228  test_loss=3.9108  λ_max=80.0908\n",
      "[SGD | lr=0.05] Epoch 2336/4000: train_loss=0.0228  test_loss=3.9112  λ_max=81.2017\n",
      "[SGD | lr=0.05] Epoch 2337/4000: train_loss=0.0228  test_loss=3.9115  λ_max=80.5159\n",
      "[SGD | lr=0.05] Iter 37400: loss=0.0224\n",
      "[SGD | lr=0.05] Epoch 2338/4000: train_loss=0.0227  test_loss=3.9121  λ_max=80.9183\n",
      "[SGD | lr=0.05] Epoch 2339/4000: train_loss=0.0227  test_loss=3.9123  λ_max=80.5141\n",
      "[SGD | lr=0.05] Epoch 2340/4000: train_loss=0.0227  test_loss=3.9125  λ_max=81.5673\n",
      "[SGD | lr=0.05] Epoch 2341/4000: train_loss=0.0227  test_loss=3.9130  λ_max=81.5005\n",
      "[SGD | lr=0.05] Epoch 2342/4000: train_loss=0.0227  test_loss=3.9136  λ_max=80.4180\n",
      "[SGD | lr=0.05] Epoch 2343/4000: train_loss=0.0227  test_loss=3.9139  λ_max=80.1513\n",
      "[SGD | lr=0.05] Iter 37500: loss=0.0226\n",
      "[SGD | lr=0.05] Epoch 2344/4000: train_loss=0.0227  test_loss=3.9140  λ_max=79.7401\n",
      "[SGD | lr=0.05] Epoch 2345/4000: train_loss=0.0226  test_loss=3.9146  λ_max=81.1837\n",
      "[SGD | lr=0.05] Epoch 2346/4000: train_loss=0.0226  test_loss=3.9151  λ_max=81.8386\n",
      "[SGD | lr=0.05] Epoch 2347/4000: train_loss=0.0226  test_loss=3.9153  λ_max=81.3001\n",
      "[SGD | lr=0.05] Epoch 2348/4000: train_loss=0.0226  test_loss=3.9160  λ_max=79.9334\n",
      "[SGD | lr=0.05] Epoch 2349/4000: train_loss=0.0226  test_loss=3.9165  λ_max=80.1148\n",
      "[SGD | lr=0.05] Iter 37600: loss=0.0230\n",
      "[SGD | lr=0.05] Epoch 2350/4000: train_loss=0.0226  test_loss=3.9164  λ_max=78.6859\n",
      "[SGD | lr=0.05] Epoch 2351/4000: train_loss=0.0225  test_loss=3.9171  λ_max=78.4085\n",
      "[SGD | lr=0.05] Epoch 2352/4000: train_loss=0.0225  test_loss=3.9174  λ_max=82.3522\n",
      "[SGD | lr=0.05] Epoch 2353/4000: train_loss=0.0225  test_loss=3.9177  λ_max=81.3268\n",
      "[SGD | lr=0.05] Epoch 2354/4000: train_loss=0.0225  test_loss=3.9181  λ_max=80.7618\n",
      "[SGD | lr=0.05] Epoch 2355/4000: train_loss=0.0225  test_loss=3.9188  λ_max=81.2127\n",
      "[SGD | lr=0.05] Epoch 2356/4000: train_loss=0.0225  test_loss=3.9188  λ_max=82.1141\n",
      "[SGD | lr=0.05] Iter 37700: loss=0.0229\n",
      "[SGD | lr=0.05] Epoch 2357/4000: train_loss=0.0225  test_loss=3.9192  λ_max=79.9743\n",
      "[SGD | lr=0.05] Epoch 2358/4000: train_loss=0.0224  test_loss=3.9196  λ_max=77.9219\n",
      "[SGD | lr=0.05] Epoch 2359/4000: train_loss=0.0224  test_loss=3.9200  λ_max=78.8520\n",
      "[SGD | lr=0.05] Epoch 2360/4000: train_loss=0.0224  test_loss=3.9205  λ_max=79.5712\n",
      "[SGD | lr=0.05] Epoch 2361/4000: train_loss=0.0224  test_loss=3.9207  λ_max=77.2076\n",
      "[SGD | lr=0.05] Epoch 2362/4000: train_loss=0.0224  test_loss=3.9213  λ_max=80.4153\n",
      "[SGD | lr=0.05] Iter 37800: loss=0.0220\n",
      "[SGD | lr=0.05] Epoch 2363/4000: train_loss=0.0224  test_loss=3.9215  λ_max=80.8723\n",
      "[SGD | lr=0.05] Epoch 2364/4000: train_loss=0.0224  test_loss=3.9218  λ_max=80.7389\n",
      "[SGD | lr=0.05] Epoch 2365/4000: train_loss=0.0223  test_loss=3.9223  λ_max=80.5126\n",
      "[SGD | lr=0.05] Epoch 2366/4000: train_loss=0.0223  test_loss=3.9225  λ_max=78.0559\n",
      "[SGD | lr=0.05] Epoch 2367/4000: train_loss=0.0223  test_loss=3.9230  λ_max=81.8905\n",
      "[SGD | lr=0.05] Epoch 2368/4000: train_loss=0.0223  test_loss=3.9236  λ_max=78.4263\n",
      "[SGD | lr=0.05] Iter 37900: loss=0.0224\n",
      "[SGD | lr=0.05] Epoch 2369/4000: train_loss=0.0223  test_loss=3.9236  λ_max=81.1744\n",
      "[SGD | lr=0.05] Epoch 2370/4000: train_loss=0.0223  test_loss=3.9242  λ_max=82.1969\n",
      "[SGD | lr=0.05] Epoch 2371/4000: train_loss=0.0223  test_loss=3.9241  λ_max=78.8923\n",
      "[SGD | lr=0.05] Epoch 2372/4000: train_loss=0.0222  test_loss=3.9250  λ_max=81.2898\n",
      "[SGD | lr=0.05] Epoch 2373/4000: train_loss=0.0222  test_loss=3.9254  λ_max=82.3458\n",
      "[SGD | lr=0.05] Epoch 2374/4000: train_loss=0.0222  test_loss=3.9254  λ_max=81.1151\n",
      "[SGD | lr=0.05] Iter 38000: loss=0.0214\n",
      "[SGD | lr=0.05] Epoch 2375/4000: train_loss=0.0222  test_loss=3.9260  λ_max=79.8730\n",
      "[SGD | lr=0.05] Epoch 2376/4000: train_loss=0.0222  test_loss=3.9263  λ_max=81.2010\n",
      "[SGD | lr=0.05] Epoch 2377/4000: train_loss=0.0222  test_loss=3.9268  λ_max=80.6721\n",
      "[SGD | lr=0.05] Epoch 2378/4000: train_loss=0.0221  test_loss=3.9274  λ_max=82.2382\n",
      "[SGD | lr=0.05] Epoch 2379/4000: train_loss=0.0221  test_loss=3.9276  λ_max=80.9870\n",
      "[SGD | lr=0.05] Epoch 2380/4000: train_loss=0.0221  test_loss=3.9280  λ_max=79.4978\n",
      "[SGD | lr=0.05] Epoch 2381/4000: train_loss=0.0221  test_loss=3.9286  λ_max=80.2460\n",
      "[SGD | lr=0.05] Iter 38100: loss=0.0215\n",
      "[SGD | lr=0.05] Epoch 2382/4000: train_loss=0.0221  test_loss=3.9287  λ_max=80.4504\n",
      "[SGD | lr=0.05] Epoch 2383/4000: train_loss=0.0221  test_loss=3.9290  λ_max=79.8610\n",
      "[SGD | lr=0.05] Epoch 2384/4000: train_loss=0.0221  test_loss=3.9293  λ_max=80.9390\n",
      "[SGD | lr=0.05] Epoch 2385/4000: train_loss=0.0220  test_loss=3.9298  λ_max=78.9030\n",
      "[SGD | lr=0.05] Epoch 2386/4000: train_loss=0.0220  test_loss=3.9302  λ_max=81.3843\n",
      "[SGD | lr=0.05] Epoch 2387/4000: train_loss=0.0220  test_loss=3.9305  λ_max=82.3959\n",
      "[SGD | lr=0.05] Iter 38200: loss=0.0221\n",
      "[SGD | lr=0.05] Epoch 2388/4000: train_loss=0.0220  test_loss=3.9311  λ_max=80.9230\n",
      "[SGD | lr=0.05] Epoch 2389/4000: train_loss=0.0220  test_loss=3.9313  λ_max=81.4240\n",
      "[SGD | lr=0.05] Epoch 2390/4000: train_loss=0.0220  test_loss=3.9317  λ_max=82.9077\n",
      "[SGD | lr=0.05] Epoch 2391/4000: train_loss=0.0220  test_loss=3.9319  λ_max=83.0955\n",
      "[SGD | lr=0.05] Epoch 2392/4000: train_loss=0.0219  test_loss=3.9322  λ_max=82.1389\n",
      "[SGD | lr=0.05] Epoch 2393/4000: train_loss=0.0219  test_loss=3.9327  λ_max=81.5971\n",
      "[SGD | lr=0.05] Iter 38300: loss=0.0218\n",
      "[SGD | lr=0.05] Epoch 2394/4000: train_loss=0.0219  test_loss=3.9333  λ_max=79.5497\n",
      "[SGD | lr=0.05] Epoch 2395/4000: train_loss=0.0219  test_loss=3.9335  λ_max=81.9645\n",
      "[SGD | lr=0.05] Epoch 2396/4000: train_loss=0.0219  test_loss=3.9337  λ_max=81.2771\n",
      "[SGD | lr=0.05] Epoch 2397/4000: train_loss=0.0219  test_loss=3.9340  λ_max=80.1836\n",
      "[SGD | lr=0.05] Epoch 2398/4000: train_loss=0.0219  test_loss=3.9348  λ_max=78.9777\n",
      "[SGD | lr=0.05] Epoch 2399/4000: train_loss=0.0219  test_loss=3.9351  λ_max=80.3239\n",
      "[SGD | lr=0.05] Iter 38400: loss=0.0214\n",
      "[SGD | lr=0.05] Epoch 2400/4000: train_loss=0.0218  test_loss=3.9354  λ_max=81.4947\n",
      "[SGD | lr=0.05] Epoch 2401/4000: train_loss=0.0218  test_loss=3.9354  λ_max=83.1346\n",
      "[SGD | lr=0.05] Epoch 2402/4000: train_loss=0.0218  test_loss=3.9363  λ_max=82.0917\n",
      "[SGD | lr=0.05] Epoch 2403/4000: train_loss=0.0218  test_loss=3.9363  λ_max=81.0594\n",
      "[SGD | lr=0.05] Epoch 2404/4000: train_loss=0.0218  test_loss=3.9369  λ_max=80.1389\n",
      "[SGD | lr=0.05] Epoch 2405/4000: train_loss=0.0218  test_loss=3.9373  λ_max=82.1343\n",
      "[SGD | lr=0.05] Epoch 2406/4000: train_loss=0.0218  test_loss=3.9375  λ_max=80.3084\n",
      "[SGD | lr=0.05] Iter 38500: loss=0.0223\n",
      "[SGD | lr=0.05] Epoch 2407/4000: train_loss=0.0217  test_loss=3.9381  λ_max=80.8898\n",
      "[SGD | lr=0.05] Epoch 2408/4000: train_loss=0.0217  test_loss=3.9382  λ_max=79.9999\n",
      "[SGD | lr=0.05] Epoch 2409/4000: train_loss=0.0217  test_loss=3.9391  λ_max=81.4790\n",
      "[SGD | lr=0.05] Epoch 2410/4000: train_loss=0.0217  test_loss=3.9390  λ_max=82.3645\n",
      "[SGD | lr=0.05] Epoch 2411/4000: train_loss=0.0217  test_loss=3.9394  λ_max=80.6612\n",
      "[SGD | lr=0.05] Epoch 2412/4000: train_loss=0.0217  test_loss=3.9398  λ_max=82.1494\n",
      "[SGD | lr=0.05] Iter 38600: loss=0.0214\n",
      "[SGD | lr=0.05] Epoch 2413/4000: train_loss=0.0217  test_loss=3.9402  λ_max=80.9539\n",
      "[SGD | lr=0.05] Epoch 2414/4000: train_loss=0.0216  test_loss=3.9403  λ_max=82.2771\n",
      "[SGD | lr=0.05] Epoch 2415/4000: train_loss=0.0216  test_loss=3.9412  λ_max=79.2226\n",
      "[SGD | lr=0.05] Epoch 2416/4000: train_loss=0.0216  test_loss=3.9413  λ_max=81.3523\n",
      "[SGD | lr=0.05] Epoch 2417/4000: train_loss=0.0216  test_loss=3.9415  λ_max=80.3642\n",
      "[SGD | lr=0.05] Epoch 2418/4000: train_loss=0.0216  test_loss=3.9420  λ_max=82.1535\n",
      "[SGD | lr=0.05] Iter 38700: loss=0.0213\n",
      "[SGD | lr=0.05] Epoch 2419/4000: train_loss=0.0216  test_loss=3.9424  λ_max=81.7846\n",
      "[SGD | lr=0.05] Epoch 2420/4000: train_loss=0.0216  test_loss=3.9428  λ_max=81.5025\n",
      "[SGD | lr=0.05] Epoch 2421/4000: train_loss=0.0215  test_loss=3.9432  λ_max=82.9367\n",
      "[SGD | lr=0.05] Epoch 2422/4000: train_loss=0.0215  test_loss=3.9436  λ_max=80.0116\n",
      "[SGD | lr=0.05] Epoch 2423/4000: train_loss=0.0215  test_loss=3.9440  λ_max=78.9303\n",
      "[SGD | lr=0.05] Epoch 2424/4000: train_loss=0.0215  test_loss=3.9443  λ_max=80.3204\n",
      "[SGD | lr=0.05] Iter 38800: loss=0.0215\n",
      "[SGD | lr=0.05] Epoch 2425/4000: train_loss=0.0215  test_loss=3.9444  λ_max=80.3308\n",
      "[SGD | lr=0.05] Epoch 2426/4000: train_loss=0.0215  test_loss=3.9452  λ_max=81.0879\n",
      "[SGD | lr=0.05] Epoch 2427/4000: train_loss=0.0215  test_loss=3.9453  λ_max=82.6748\n",
      "[SGD | lr=0.05] Epoch 2428/4000: train_loss=0.0215  test_loss=3.9457  λ_max=81.8566\n",
      "[SGD | lr=0.05] Epoch 2429/4000: train_loss=0.0214  test_loss=3.9460  λ_max=80.4041\n",
      "[SGD | lr=0.05] Epoch 2430/4000: train_loss=0.0214  test_loss=3.9463  λ_max=82.0699\n",
      "[SGD | lr=0.05] Epoch 2431/4000: train_loss=0.0214  test_loss=3.9468  λ_max=77.9451\n",
      "[SGD | lr=0.05] Iter 38900: loss=0.0212\n",
      "[SGD | lr=0.05] Epoch 2432/4000: train_loss=0.0214  test_loss=3.9474  λ_max=81.9419\n",
      "[SGD | lr=0.05] Epoch 2433/4000: train_loss=0.0214  test_loss=3.9475  λ_max=80.2296\n",
      "[SGD | lr=0.05] Epoch 2434/4000: train_loss=0.0214  test_loss=3.9481  λ_max=79.5793\n",
      "[SGD | lr=0.05] Epoch 2435/4000: train_loss=0.0214  test_loss=3.9483  λ_max=80.2070\n",
      "[SGD | lr=0.05] Epoch 2436/4000: train_loss=0.0213  test_loss=3.9486  λ_max=81.6180\n",
      "[SGD | lr=0.05] Epoch 2437/4000: train_loss=0.0213  test_loss=3.9487  λ_max=81.8446\n",
      "[SGD | lr=0.05] Iter 39000: loss=0.0213\n",
      "[SGD | lr=0.05] Epoch 2438/4000: train_loss=0.0213  test_loss=3.9493  λ_max=82.1430\n",
      "[SGD | lr=0.05] Epoch 2439/4000: train_loss=0.0213  test_loss=3.9498  λ_max=83.6785\n",
      "[SGD | lr=0.05] Epoch 2440/4000: train_loss=0.0213  test_loss=3.9499  λ_max=80.9995\n",
      "[SGD | lr=0.05] Epoch 2441/4000: train_loss=0.0213  test_loss=3.9502  λ_max=81.7222\n",
      "[SGD | lr=0.05] Epoch 2442/4000: train_loss=0.0213  test_loss=3.9506  λ_max=79.7529\n",
      "[SGD | lr=0.05] Epoch 2443/4000: train_loss=0.0212  test_loss=3.9511  λ_max=82.5452\n",
      "[SGD | lr=0.05] Iter 39100: loss=0.0208\n",
      "[SGD | lr=0.05] Epoch 2444/4000: train_loss=0.0212  test_loss=3.9514  λ_max=80.2030\n",
      "[SGD | lr=0.05] Epoch 2445/4000: train_loss=0.0212  test_loss=3.9520  λ_max=80.0127\n",
      "[SGD | lr=0.05] Epoch 2446/4000: train_loss=0.0212  test_loss=3.9524  λ_max=82.4993\n",
      "[SGD | lr=0.05] Epoch 2447/4000: train_loss=0.0212  test_loss=3.9525  λ_max=81.5487\n",
      "[SGD | lr=0.05] Epoch 2448/4000: train_loss=0.0212  test_loss=3.9526  λ_max=80.2703\n",
      "[SGD | lr=0.05] Epoch 2449/4000: train_loss=0.0212  test_loss=3.9531  λ_max=83.3713\n",
      "[SGD | lr=0.05] Iter 39200: loss=0.0213\n",
      "[SGD | lr=0.05] Epoch 2450/4000: train_loss=0.0212  test_loss=3.9537  λ_max=83.2382\n",
      "[SGD | lr=0.05] Epoch 2451/4000: train_loss=0.0212  test_loss=3.9541  λ_max=82.1351\n",
      "[SGD | lr=0.05] Epoch 2452/4000: train_loss=0.0211  test_loss=3.9542  λ_max=83.3523\n",
      "[SGD | lr=0.05] Epoch 2453/4000: train_loss=0.0211  test_loss=3.9546  λ_max=84.2121\n",
      "[SGD | lr=0.05] Epoch 2454/4000: train_loss=0.0211  test_loss=3.9552  λ_max=81.9829\n",
      "[SGD | lr=0.05] Epoch 2455/4000: train_loss=0.0211  test_loss=3.9555  λ_max=80.9769\n",
      "[SGD | lr=0.05] Epoch 2456/4000: train_loss=0.0211  test_loss=3.9560  λ_max=82.5443\n",
      "[SGD | lr=0.05] Iter 39300: loss=0.0211\n",
      "[SGD | lr=0.05] Epoch 2457/4000: train_loss=0.0211  test_loss=3.9563  λ_max=83.0183\n",
      "[SGD | lr=0.05] Epoch 2458/4000: train_loss=0.0211  test_loss=3.9564  λ_max=82.2710\n",
      "[SGD | lr=0.05] Epoch 2459/4000: train_loss=0.0210  test_loss=3.9567  λ_max=81.5873\n",
      "[SGD | lr=0.05] Epoch 2460/4000: train_loss=0.0210  test_loss=3.9573  λ_max=82.3465\n",
      "[SGD | lr=0.05] Epoch 2461/4000: train_loss=0.0210  test_loss=3.9576  λ_max=82.3317\n",
      "[SGD | lr=0.05] Epoch 2462/4000: train_loss=0.0210  test_loss=3.9580  λ_max=81.4297\n",
      "[SGD | lr=0.05] Iter 39400: loss=0.0208\n",
      "[SGD | lr=0.05] Epoch 2463/4000: train_loss=0.0210  test_loss=3.9582  λ_max=83.1479\n",
      "[SGD | lr=0.05] Epoch 2464/4000: train_loss=0.0210  test_loss=3.9587  λ_max=80.9186\n",
      "[SGD | lr=0.05] Epoch 2465/4000: train_loss=0.0210  test_loss=3.9591  λ_max=81.7033\n",
      "[SGD | lr=0.05] Epoch 2466/4000: train_loss=0.0210  test_loss=3.9595  λ_max=81.5127\n",
      "[SGD | lr=0.05] Epoch 2467/4000: train_loss=0.0209  test_loss=3.9599  λ_max=80.0395\n",
      "[SGD | lr=0.05] Epoch 2468/4000: train_loss=0.0209  test_loss=3.9603  λ_max=80.6254\n",
      "[SGD | lr=0.05] Iter 39500: loss=0.0209\n",
      "[SGD | lr=0.05] Epoch 2469/4000: train_loss=0.0209  test_loss=3.9607  λ_max=80.8710\n",
      "[SGD | lr=0.05] Epoch 2470/4000: train_loss=0.0209  test_loss=3.9609  λ_max=82.2274\n",
      "[SGD | lr=0.05] Epoch 2471/4000: train_loss=0.0209  test_loss=3.9611  λ_max=83.7887\n",
      "[SGD | lr=0.05] Epoch 2472/4000: train_loss=0.0209  test_loss=3.9617  λ_max=81.7437\n",
      "[SGD | lr=0.05] Epoch 2473/4000: train_loss=0.0209  test_loss=3.9618  λ_max=82.6877\n",
      "[SGD | lr=0.05] Epoch 2474/4000: train_loss=0.0209  test_loss=3.9622  λ_max=81.2486\n",
      "[SGD | lr=0.05] Iter 39600: loss=0.0211\n",
      "[SGD | lr=0.05] Epoch 2475/4000: train_loss=0.0208  test_loss=3.9627  λ_max=82.2325\n",
      "[SGD | lr=0.05] Epoch 2476/4000: train_loss=0.0208  test_loss=3.9631  λ_max=81.8112\n",
      "[SGD | lr=0.05] Epoch 2477/4000: train_loss=0.0208  test_loss=3.9635  λ_max=82.5586\n",
      "[SGD | lr=0.05] Epoch 2478/4000: train_loss=0.0208  test_loss=3.9637  λ_max=82.0865\n",
      "[SGD | lr=0.05] Epoch 2479/4000: train_loss=0.0208  test_loss=3.9642  λ_max=82.8443\n",
      "[SGD | lr=0.05] Epoch 2480/4000: train_loss=0.0208  test_loss=3.9642  λ_max=80.0054\n",
      "[SGD | lr=0.05] Epoch 2481/4000: train_loss=0.0208  test_loss=3.9650  λ_max=81.2120\n",
      "[SGD | lr=0.05] Iter 39700: loss=0.0209\n",
      "[SGD | lr=0.05] Epoch 2482/4000: train_loss=0.0207  test_loss=3.9654  λ_max=80.9370\n",
      "[SGD | lr=0.05] Epoch 2483/4000: train_loss=0.0207  test_loss=3.9655  λ_max=83.7970\n",
      "[SGD | lr=0.05] Epoch 2484/4000: train_loss=0.0207  test_loss=3.9660  λ_max=80.9258\n",
      "[SGD | lr=0.05] Epoch 2485/4000: train_loss=0.0207  test_loss=3.9663  λ_max=82.4630\n",
      "[SGD | lr=0.05] Epoch 2486/4000: train_loss=0.0207  test_loss=3.9663  λ_max=83.2751\n",
      "[SGD | lr=0.05] Epoch 2487/4000: train_loss=0.0207  test_loss=3.9668  λ_max=83.2194\n",
      "[SGD | lr=0.05] Iter 39800: loss=0.0205\n",
      "[SGD | lr=0.05] Epoch 2488/4000: train_loss=0.0207  test_loss=3.9674  λ_max=80.9595\n",
      "[SGD | lr=0.05] Epoch 2489/4000: train_loss=0.0207  test_loss=3.9675  λ_max=80.9168\n",
      "[SGD | lr=0.05] Epoch 2490/4000: train_loss=0.0206  test_loss=3.9680  λ_max=80.4003\n",
      "[SGD | lr=0.05] Epoch 2491/4000: train_loss=0.0206  test_loss=3.9685  λ_max=81.6138\n",
      "[SGD | lr=0.05] Epoch 2492/4000: train_loss=0.0206  test_loss=3.9688  λ_max=80.9801\n",
      "[SGD | lr=0.05] Epoch 2493/4000: train_loss=0.0206  test_loss=3.9692  λ_max=83.2066\n",
      "[SGD | lr=0.05] Iter 39900: loss=0.0205\n",
      "[SGD | lr=0.05] Epoch 2494/4000: train_loss=0.0206  test_loss=3.9695  λ_max=81.8371\n",
      "[SGD | lr=0.05] Epoch 2495/4000: train_loss=0.0206  test_loss=3.9697  λ_max=80.9786\n",
      "[SGD | lr=0.05] Epoch 2496/4000: train_loss=0.0206  test_loss=3.9702  λ_max=81.4328\n",
      "[SGD | lr=0.05] Epoch 2497/4000: train_loss=0.0205  test_loss=3.9704  λ_max=81.0553\n",
      "[SGD | lr=0.05] Epoch 2498/4000: train_loss=0.0205  test_loss=3.9712  λ_max=80.6525\n",
      "[SGD | lr=0.05] Epoch 2499/4000: train_loss=0.0205  test_loss=3.9713  λ_max=81.7469\n",
      "[SGD | lr=0.05] Iter 40000: loss=0.0202\n",
      "[SGD | lr=0.05] Epoch 2500/4000: train_loss=0.0205  test_loss=3.9717  λ_max=82.6214\n",
      "[SGD | lr=0.05] Epoch 2501/4000: train_loss=0.0205  test_loss=3.9718  λ_max=82.2733\n",
      "[SGD | lr=0.05] Epoch 2502/4000: train_loss=0.0205  test_loss=3.9724  λ_max=82.4106\n",
      "[SGD | lr=0.05] Epoch 2503/4000: train_loss=0.0205  test_loss=3.9727  λ_max=83.7226\n",
      "[SGD | lr=0.05] Epoch 2504/4000: train_loss=0.0205  test_loss=3.9730  λ_max=80.8292\n",
      "[SGD | lr=0.05] Epoch 2505/4000: train_loss=0.0205  test_loss=3.9734  λ_max=81.6458\n",
      "[SGD | lr=0.05] Epoch 2506/4000: train_loss=0.0204  test_loss=3.9738  λ_max=81.1553\n",
      "[SGD | lr=0.05] Iter 40100: loss=0.0203\n",
      "[SGD | lr=0.05] Epoch 2507/4000: train_loss=0.0204  test_loss=3.9742  λ_max=78.9612\n",
      "[SGD | lr=0.05] Epoch 2508/4000: train_loss=0.0204  test_loss=3.9745  λ_max=82.9347\n",
      "[SGD | lr=0.05] Epoch 2509/4000: train_loss=0.0204  test_loss=3.9748  λ_max=84.1750\n",
      "[SGD | lr=0.05] Epoch 2510/4000: train_loss=0.0204  test_loss=3.9751  λ_max=82.4778\n",
      "[SGD | lr=0.05] Epoch 2511/4000: train_loss=0.0204  test_loss=3.9755  λ_max=83.2310\n",
      "[SGD | lr=0.05] Epoch 2512/4000: train_loss=0.0204  test_loss=3.9762  λ_max=82.0104\n",
      "[SGD | lr=0.05] Iter 40200: loss=0.0207\n",
      "[SGD | lr=0.05] Epoch 2513/4000: train_loss=0.0203  test_loss=3.9762  λ_max=84.9945\n",
      "[SGD | lr=0.05] Epoch 2514/4000: train_loss=0.0203  test_loss=3.9764  λ_max=82.3429\n",
      "[SGD | lr=0.05] Epoch 2515/4000: train_loss=0.0203  test_loss=3.9771  λ_max=83.1564\n",
      "[SGD | lr=0.05] Epoch 2516/4000: train_loss=0.0203  test_loss=3.9773  λ_max=82.3226\n",
      "[SGD | lr=0.05] Epoch 2517/4000: train_loss=0.0203  test_loss=3.9778  λ_max=83.6077\n",
      "[SGD | lr=0.05] Epoch 2518/4000: train_loss=0.0203  test_loss=3.9781  λ_max=84.0418\n",
      "[SGD | lr=0.05] Iter 40300: loss=0.0204\n",
      "[SGD | lr=0.05] Epoch 2519/4000: train_loss=0.0203  test_loss=3.9783  λ_max=82.3909\n",
      "[SGD | lr=0.05] Epoch 2520/4000: train_loss=0.0203  test_loss=3.9785  λ_max=81.9880\n",
      "[SGD | lr=0.05] Epoch 2521/4000: train_loss=0.0203  test_loss=3.9789  λ_max=80.9315\n",
      "[SGD | lr=0.05] Epoch 2522/4000: train_loss=0.0202  test_loss=3.9795  λ_max=82.1952\n",
      "[SGD | lr=0.05] Epoch 2523/4000: train_loss=0.0202  test_loss=3.9798  λ_max=82.4127\n",
      "[SGD | lr=0.05] Epoch 2524/4000: train_loss=0.0202  test_loss=3.9803  λ_max=82.5879\n",
      "[SGD | lr=0.05] Iter 40400: loss=0.0201\n",
      "[SGD | lr=0.05] Epoch 2525/4000: train_loss=0.0202  test_loss=3.9801  λ_max=79.3270\n",
      "[SGD | lr=0.05] Epoch 2526/4000: train_loss=0.0202  test_loss=3.9806  λ_max=83.0478\n",
      "[SGD | lr=0.05] Epoch 2527/4000: train_loss=0.0202  test_loss=3.9811  λ_max=83.9332\n",
      "[SGD | lr=0.05] Epoch 2528/4000: train_loss=0.0202  test_loss=3.9813  λ_max=78.4591\n",
      "[SGD | lr=0.05] Epoch 2529/4000: train_loss=0.0202  test_loss=3.9816  λ_max=82.7958\n",
      "[SGD | lr=0.05] Epoch 2530/4000: train_loss=0.0201  test_loss=3.9820  λ_max=81.1945\n",
      "[SGD | lr=0.05] Epoch 2531/4000: train_loss=0.0201  test_loss=3.9828  λ_max=82.9061\n",
      "[SGD | lr=0.05] Iter 40500: loss=0.0199\n",
      "[SGD | lr=0.05] Epoch 2532/4000: train_loss=0.0201  test_loss=3.9826  λ_max=83.1374\n",
      "[SGD | lr=0.05] Epoch 2533/4000: train_loss=0.0201  test_loss=3.9831  λ_max=81.9519\n",
      "[SGD | lr=0.05] Epoch 2534/4000: train_loss=0.0201  test_loss=3.9834  λ_max=83.2825\n",
      "[SGD | lr=0.05] Epoch 2535/4000: train_loss=0.0201  test_loss=3.9840  λ_max=82.9351\n",
      "[SGD | lr=0.05] Epoch 2536/4000: train_loss=0.0201  test_loss=3.9843  λ_max=82.1693\n",
      "[SGD | lr=0.05] Epoch 2537/4000: train_loss=0.0201  test_loss=3.9848  λ_max=83.9939\n",
      "[SGD | lr=0.05] Iter 40600: loss=0.0200\n",
      "[SGD | lr=0.05] Epoch 2538/4000: train_loss=0.0201  test_loss=3.9848  λ_max=82.3881\n",
      "[SGD | lr=0.05] Epoch 2539/4000: train_loss=0.0200  test_loss=3.9851  λ_max=82.2532\n",
      "[SGD | lr=0.05] Epoch 2540/4000: train_loss=0.0200  test_loss=3.9856  λ_max=83.8949\n",
      "[SGD | lr=0.05] Epoch 2541/4000: train_loss=0.0200  test_loss=3.9858  λ_max=80.6272\n",
      "[SGD | lr=0.05] Epoch 2542/4000: train_loss=0.0200  test_loss=3.9862  λ_max=83.4933\n",
      "[SGD | lr=0.05] Epoch 2543/4000: train_loss=0.0200  test_loss=3.9870  λ_max=83.2377\n",
      "[SGD | lr=0.05] Iter 40700: loss=0.0201\n",
      "[SGD | lr=0.05] Epoch 2544/4000: train_loss=0.0200  test_loss=3.9871  λ_max=83.3397\n",
      "[SGD | lr=0.05] Epoch 2545/4000: train_loss=0.0200  test_loss=3.9875  λ_max=82.0202\n",
      "[SGD | lr=0.05] Epoch 2546/4000: train_loss=0.0200  test_loss=3.9876  λ_max=82.7179\n",
      "[SGD | lr=0.05] Epoch 2547/4000: train_loss=0.0199  test_loss=3.9881  λ_max=83.1521\n",
      "[SGD | lr=0.05] Epoch 2548/4000: train_loss=0.0199  test_loss=3.9885  λ_max=82.0911\n",
      "[SGD | lr=0.05] Epoch 2549/4000: train_loss=0.0199  test_loss=3.9887  λ_max=82.6675\n",
      "[SGD | lr=0.05] Iter 40800: loss=0.0194\n",
      "[SGD | lr=0.05] Epoch 2550/4000: train_loss=0.0199  test_loss=3.9889  λ_max=83.1983\n",
      "[SGD | lr=0.05] Epoch 2551/4000: train_loss=0.0199  test_loss=3.9892  λ_max=82.3643\n",
      "[SGD | lr=0.05] Epoch 2552/4000: train_loss=0.0199  test_loss=3.9895  λ_max=83.1752\n",
      "[SGD | lr=0.05] Epoch 2553/4000: train_loss=0.0199  test_loss=3.9902  λ_max=82.7475\n",
      "[SGD | lr=0.05] Epoch 2554/4000: train_loss=0.0198  test_loss=3.9903  λ_max=82.2586\n",
      "[SGD | lr=0.05] Epoch 2555/4000: train_loss=0.0198  test_loss=3.9907  λ_max=84.1212\n",
      "[SGD | lr=0.05] Epoch 2556/4000: train_loss=0.0198  test_loss=3.9911  λ_max=83.1583\n",
      "[SGD | lr=0.05] Iter 40900: loss=0.0201\n",
      "[SGD | lr=0.05] Epoch 2557/4000: train_loss=0.0198  test_loss=3.9915  λ_max=83.7294\n",
      "[SGD | lr=0.05] Epoch 2558/4000: train_loss=0.0198  test_loss=3.9918  λ_max=80.7893\n",
      "[SGD | lr=0.05] Epoch 2559/4000: train_loss=0.0198  test_loss=3.9919  λ_max=77.5282\n",
      "[SGD | lr=0.05] Epoch 2560/4000: train_loss=0.0198  test_loss=3.9925  λ_max=82.3778\n",
      "[SGD | lr=0.05] Epoch 2561/4000: train_loss=0.0198  test_loss=3.9929  λ_max=82.3986\n",
      "[SGD | lr=0.05] Epoch 2562/4000: train_loss=0.0198  test_loss=3.9932  λ_max=82.7900\n",
      "[SGD | lr=0.05] Iter 41000: loss=0.0198\n",
      "[SGD | lr=0.05] Epoch 2563/4000: train_loss=0.0197  test_loss=3.9935  λ_max=82.6997\n",
      "[SGD | lr=0.05] Epoch 2564/4000: train_loss=0.0197  test_loss=3.9939  λ_max=84.1104\n",
      "[SGD | lr=0.05] Epoch 2565/4000: train_loss=0.0197  test_loss=3.9942  λ_max=83.0924\n",
      "[SGD | lr=0.05] Epoch 2566/4000: train_loss=0.0197  test_loss=3.9946  λ_max=80.4568\n",
      "[SGD | lr=0.05] Epoch 2567/4000: train_loss=0.0197  test_loss=3.9949  λ_max=84.5951\n",
      "[SGD | lr=0.05] Epoch 2568/4000: train_loss=0.0197  test_loss=3.9953  λ_max=81.6718\n",
      "[SGD | lr=0.05] Iter 41100: loss=0.0198\n",
      "[SGD | lr=0.05] Epoch 2569/4000: train_loss=0.0197  test_loss=3.9954  λ_max=83.2214\n",
      "[SGD | lr=0.05] Epoch 2570/4000: train_loss=0.0197  test_loss=3.9959  λ_max=85.5929\n",
      "[SGD | lr=0.05] Epoch 2571/4000: train_loss=0.0197  test_loss=3.9964  λ_max=82.3068\n",
      "[SGD | lr=0.05] Epoch 2572/4000: train_loss=0.0196  test_loss=3.9964  λ_max=83.1920\n",
      "[SGD | lr=0.05] Epoch 2573/4000: train_loss=0.0196  test_loss=3.9970  λ_max=84.8878\n",
      "[SGD | lr=0.05] Epoch 2574/4000: train_loss=0.0196  test_loss=3.9972  λ_max=83.1143\n",
      "[SGD | lr=0.05] Iter 41200: loss=0.0194\n",
      "[SGD | lr=0.05] Epoch 2575/4000: train_loss=0.0196  test_loss=3.9975  λ_max=83.5036\n",
      "[SGD | lr=0.05] Epoch 2576/4000: train_loss=0.0196  test_loss=3.9981  λ_max=81.8953\n",
      "[SGD | lr=0.05] Epoch 2577/4000: train_loss=0.0196  test_loss=3.9982  λ_max=83.7910\n",
      "[SGD | lr=0.05] Epoch 2578/4000: train_loss=0.0196  test_loss=3.9987  λ_max=83.8773\n",
      "[SGD | lr=0.05] Epoch 2579/4000: train_loss=0.0196  test_loss=3.9991  λ_max=81.2107\n",
      "[SGD | lr=0.05] Epoch 2580/4000: train_loss=0.0195  test_loss=3.9990  λ_max=83.8893\n",
      "[SGD | lr=0.05] Epoch 2581/4000: train_loss=0.0195  test_loss=3.9997  λ_max=83.0123\n",
      "[SGD | lr=0.05] Iter 41300: loss=0.0199\n",
      "[SGD | lr=0.05] Epoch 2582/4000: train_loss=0.0195  test_loss=4.0002  λ_max=84.4699\n",
      "[SGD | lr=0.05] Epoch 2583/4000: train_loss=0.0195  test_loss=4.0004  λ_max=82.2392\n",
      "[SGD | lr=0.05] Epoch 2584/4000: train_loss=0.0195  test_loss=4.0007  λ_max=82.9103\n",
      "[SGD | lr=0.05] Epoch 2585/4000: train_loss=0.0195  test_loss=4.0013  λ_max=81.3445\n",
      "[SGD | lr=0.05] Epoch 2586/4000: train_loss=0.0195  test_loss=4.0013  λ_max=85.2616\n",
      "[SGD | lr=0.05] Epoch 2587/4000: train_loss=0.0195  test_loss=4.0018  λ_max=82.2956\n",
      "[SGD | lr=0.05] Iter 41400: loss=0.0193\n",
      "[SGD | lr=0.05] Epoch 2588/4000: train_loss=0.0195  test_loss=4.0019  λ_max=83.9307\n",
      "[SGD | lr=0.05] Epoch 2589/4000: train_loss=0.0195  test_loss=4.0023  λ_max=82.7018\n",
      "[SGD | lr=0.05] Epoch 2590/4000: train_loss=0.0194  test_loss=4.0025  λ_max=82.3682\n",
      "[SGD | lr=0.05] Epoch 2591/4000: train_loss=0.0194  test_loss=4.0031  λ_max=83.1143\n",
      "[SGD | lr=0.05] Epoch 2592/4000: train_loss=0.0194  test_loss=4.0034  λ_max=80.2144\n",
      "[SGD | lr=0.05] Epoch 2593/4000: train_loss=0.0194  test_loss=4.0037  λ_max=82.2007\n",
      "[SGD | lr=0.05] Iter 41500: loss=0.0190\n",
      "[SGD | lr=0.05] Epoch 2594/4000: train_loss=0.0194  test_loss=4.0040  λ_max=82.7838\n",
      "[SGD | lr=0.05] Epoch 2595/4000: train_loss=0.0194  test_loss=4.0041  λ_max=82.5863\n",
      "[SGD | lr=0.05] Epoch 2596/4000: train_loss=0.0194  test_loss=4.0048  λ_max=83.5179\n",
      "[SGD | lr=0.05] Epoch 2597/4000: train_loss=0.0194  test_loss=4.0051  λ_max=84.5959\n",
      "[SGD | lr=0.05] Epoch 2598/4000: train_loss=0.0193  test_loss=4.0055  λ_max=83.2636\n",
      "[SGD | lr=0.05] Epoch 2599/4000: train_loss=0.0193  test_loss=4.0056  λ_max=84.2585\n",
      "[SGD | lr=0.05] Iter 41600: loss=0.0195\n",
      "[SGD | lr=0.05] Epoch 2600/4000: train_loss=0.0193  test_loss=4.0059  λ_max=82.0602\n",
      "[SGD | lr=0.05] Epoch 2601/4000: train_loss=0.0193  test_loss=4.0064  λ_max=81.6195\n",
      "[SGD | lr=0.05] Epoch 2602/4000: train_loss=0.0193  test_loss=4.0067  λ_max=83.2421\n",
      "[SGD | lr=0.05] Epoch 2603/4000: train_loss=0.0193  test_loss=4.0069  λ_max=81.0680\n",
      "[SGD | lr=0.05] Epoch 2604/4000: train_loss=0.0193  test_loss=4.0075  λ_max=83.2753\n",
      "[SGD | lr=0.05] Epoch 2605/4000: train_loss=0.0193  test_loss=4.0076  λ_max=82.2393\n",
      "[SGD | lr=0.05] Epoch 2606/4000: train_loss=0.0193  test_loss=4.0079  λ_max=84.4766\n",
      "[SGD | lr=0.05] Iter 41700: loss=0.0189\n",
      "[SGD | lr=0.05] Epoch 2607/4000: train_loss=0.0192  test_loss=4.0084  λ_max=84.8924\n",
      "[SGD | lr=0.05] Epoch 2608/4000: train_loss=0.0192  test_loss=4.0087  λ_max=83.6660\n",
      "[SGD | lr=0.05] Epoch 2609/4000: train_loss=0.0192  test_loss=4.0093  λ_max=82.0499\n",
      "[SGD | lr=0.05] Epoch 2610/4000: train_loss=0.0192  test_loss=4.0096  λ_max=84.1787\n",
      "[SGD | lr=0.05] Epoch 2611/4000: train_loss=0.0192  test_loss=4.0096  λ_max=83.8713\n",
      "[SGD | lr=0.05] Epoch 2612/4000: train_loss=0.0192  test_loss=4.0100  λ_max=84.2522\n",
      "[SGD | lr=0.05] Iter 41800: loss=0.0193\n",
      "[SGD | lr=0.05] Epoch 2613/4000: train_loss=0.0192  test_loss=4.0103  λ_max=85.2569\n",
      "[SGD | lr=0.05] Epoch 2614/4000: train_loss=0.0192  test_loss=4.0109  λ_max=83.5776\n",
      "[SGD | lr=0.05] Epoch 2615/4000: train_loss=0.0192  test_loss=4.0111  λ_max=84.9175\n",
      "[SGD | lr=0.05] Epoch 2616/4000: train_loss=0.0191  test_loss=4.0114  λ_max=84.6552\n",
      "[SGD | lr=0.05] Epoch 2617/4000: train_loss=0.0191  test_loss=4.0118  λ_max=82.3882\n",
      "[SGD | lr=0.05] Epoch 2618/4000: train_loss=0.0191  test_loss=4.0121  λ_max=84.3532\n",
      "[SGD | lr=0.05] Iter 41900: loss=0.0192\n",
      "[SGD | lr=0.05] Epoch 2619/4000: train_loss=0.0191  test_loss=4.0124  λ_max=84.5830\n",
      "[SGD | lr=0.05] Epoch 2620/4000: train_loss=0.0191  test_loss=4.0127  λ_max=84.1898\n",
      "[SGD | lr=0.05] Epoch 2621/4000: train_loss=0.0191  test_loss=4.0129  λ_max=84.4357\n",
      "[SGD | lr=0.05] Epoch 2622/4000: train_loss=0.0191  test_loss=4.0135  λ_max=84.6554\n",
      "[SGD | lr=0.05] Epoch 2623/4000: train_loss=0.0191  test_loss=4.0137  λ_max=82.9635\n",
      "[SGD | lr=0.05] Epoch 2624/4000: train_loss=0.0190  test_loss=4.0141  λ_max=82.3255\n",
      "[SGD | lr=0.05] Iter 42000: loss=0.0189\n",
      "[SGD | lr=0.05] Epoch 2625/4000: train_loss=0.0190  test_loss=4.0141  λ_max=83.1618\n",
      "[SGD | lr=0.05] Epoch 2626/4000: train_loss=0.0190  test_loss=4.0149  λ_max=84.2350\n",
      "[SGD | lr=0.05] Epoch 2627/4000: train_loss=0.0190  test_loss=4.0151  λ_max=80.1663\n",
      "[SGD | lr=0.05] Epoch 2628/4000: train_loss=0.0190  test_loss=4.0155  λ_max=84.5054\n",
      "[SGD | lr=0.05] Epoch 2629/4000: train_loss=0.0190  test_loss=4.0154  λ_max=83.7178\n",
      "[SGD | lr=0.05] Epoch 2630/4000: train_loss=0.0190  test_loss=4.0162  λ_max=84.6054\n",
      "[SGD | lr=0.05] Epoch 2631/4000: train_loss=0.0190  test_loss=4.0162  λ_max=82.2707\n",
      "[SGD | lr=0.05] Iter 42100: loss=0.0192\n",
      "[SGD | lr=0.05] Epoch 2632/4000: train_loss=0.0190  test_loss=4.0165  λ_max=84.1713\n",
      "[SGD | lr=0.05] Epoch 2633/4000: train_loss=0.0190  test_loss=4.0170  λ_max=80.0116\n",
      "[SGD | lr=0.05] Epoch 2634/4000: train_loss=0.0189  test_loss=4.0175  λ_max=83.3451\n",
      "[SGD | lr=0.05] Epoch 2635/4000: train_loss=0.0189  test_loss=4.0176  λ_max=84.4948\n",
      "[SGD | lr=0.05] Epoch 2636/4000: train_loss=0.0189  test_loss=4.0180  λ_max=83.3407\n",
      "[SGD | lr=0.05] Epoch 2637/4000: train_loss=0.0189  test_loss=4.0183  λ_max=82.5536\n",
      "[SGD | lr=0.05] Iter 42200: loss=0.0189\n",
      "[SGD | lr=0.05] Epoch 2638/4000: train_loss=0.0189  test_loss=4.0188  λ_max=84.2644\n",
      "[SGD | lr=0.05] Epoch 2639/4000: train_loss=0.0189  test_loss=4.0190  λ_max=84.2071\n",
      "[SGD | lr=0.05] Epoch 2640/4000: train_loss=0.0189  test_loss=4.0192  λ_max=82.2448\n",
      "[SGD | lr=0.05] Epoch 2641/4000: train_loss=0.0189  test_loss=4.0196  λ_max=83.5929\n",
      "[SGD | lr=0.05] Epoch 2642/4000: train_loss=0.0189  test_loss=4.0202  λ_max=85.2081\n",
      "[SGD | lr=0.05] Epoch 2643/4000: train_loss=0.0189  test_loss=4.0202  λ_max=82.8395\n",
      "[SGD | lr=0.05] Iter 42300: loss=0.0192\n",
      "[SGD | lr=0.05] Epoch 2644/4000: train_loss=0.0188  test_loss=4.0206  λ_max=84.7464\n",
      "[SGD | lr=0.05] Epoch 2645/4000: train_loss=0.0188  test_loss=4.0210  λ_max=83.9802\n",
      "[SGD | lr=0.05] Epoch 2646/4000: train_loss=0.0188  test_loss=4.0213  λ_max=82.8984\n",
      "[SGD | lr=0.05] Epoch 2647/4000: train_loss=0.0188  test_loss=4.0217  λ_max=85.3297\n",
      "[SGD | lr=0.05] Epoch 2648/4000: train_loss=0.0188  test_loss=4.0221  λ_max=84.6411\n",
      "[SGD | lr=0.05] Epoch 2649/4000: train_loss=0.0188  test_loss=4.0223  λ_max=82.7993\n",
      "[SGD | lr=0.05] Iter 42400: loss=0.0187\n",
      "[SGD | lr=0.05] Epoch 2650/4000: train_loss=0.0188  test_loss=4.0225  λ_max=84.0597\n",
      "[SGD | lr=0.05] Epoch 2651/4000: train_loss=0.0188  test_loss=4.0231  λ_max=82.6504\n",
      "[SGD | lr=0.05] Epoch 2652/4000: train_loss=0.0188  test_loss=4.0234  λ_max=82.1874\n",
      "[SGD | lr=0.05] Epoch 2653/4000: train_loss=0.0187  test_loss=4.0235  λ_max=84.0729\n",
      "[SGD | lr=0.05] Epoch 2654/4000: train_loss=0.0187  test_loss=4.0238  λ_max=80.7781\n",
      "[SGD | lr=0.05] Epoch 2655/4000: train_loss=0.0187  test_loss=4.0244  λ_max=85.2963\n",
      "[SGD | lr=0.05] Epoch 2656/4000: train_loss=0.0187  test_loss=4.0247  λ_max=81.1466\n",
      "[SGD | lr=0.05] Iter 42500: loss=0.0183\n",
      "[SGD | lr=0.05] Epoch 2657/4000: train_loss=0.0187  test_loss=4.0250  λ_max=82.8613\n",
      "[SGD | lr=0.05] Epoch 2658/4000: train_loss=0.0187  test_loss=4.0252  λ_max=85.2181\n",
      "[SGD | lr=0.05] Epoch 2659/4000: train_loss=0.0187  test_loss=4.0256  λ_max=84.7329\n",
      "[SGD | lr=0.05] Epoch 2660/4000: train_loss=0.0187  test_loss=4.0260  λ_max=82.7490\n",
      "[SGD | lr=0.05] Epoch 2661/4000: train_loss=0.0187  test_loss=4.0263  λ_max=83.9502\n",
      "[SGD | lr=0.05] Epoch 2662/4000: train_loss=0.0187  test_loss=4.0267  λ_max=84.9511\n",
      "[SGD | lr=0.05] Iter 42600: loss=0.0184\n",
      "[SGD | lr=0.05] Epoch 2663/4000: train_loss=0.0186  test_loss=4.0270  λ_max=83.6668\n",
      "[SGD | lr=0.05] Epoch 2664/4000: train_loss=0.0186  test_loss=4.0273  λ_max=85.2746\n",
      "[SGD | lr=0.05] Epoch 2665/4000: train_loss=0.0186  test_loss=4.0276  λ_max=84.9942\n",
      "[SGD | lr=0.05] Epoch 2666/4000: train_loss=0.0186  test_loss=4.0278  λ_max=83.1711\n",
      "[SGD | lr=0.05] Epoch 2667/4000: train_loss=0.0186  test_loss=4.0282  λ_max=83.9795\n",
      "[SGD | lr=0.05] Epoch 2668/4000: train_loss=0.0186  test_loss=4.0286  λ_max=84.9212\n",
      "[SGD | lr=0.05] Iter 42700: loss=0.0189\n",
      "[SGD | lr=0.05] Epoch 2669/4000: train_loss=0.0186  test_loss=4.0290  λ_max=80.7663\n",
      "[SGD | lr=0.05] Epoch 2670/4000: train_loss=0.0186  test_loss=4.0292  λ_max=83.9747\n",
      "[SGD | lr=0.05] Epoch 2671/4000: train_loss=0.0186  test_loss=4.0295  λ_max=83.9035\n",
      "[SGD | lr=0.05] Epoch 2672/4000: train_loss=0.0185  test_loss=4.0297  λ_max=84.3253\n",
      "[SGD | lr=0.05] Epoch 2673/4000: train_loss=0.0185  test_loss=4.0302  λ_max=84.1878\n",
      "[SGD | lr=0.05] Epoch 2674/4000: train_loss=0.0185  test_loss=4.0306  λ_max=84.2547\n",
      "[SGD | lr=0.05] Iter 42800: loss=0.0180\n",
      "[SGD | lr=0.05] Epoch 2675/4000: train_loss=0.0185  test_loss=4.0308  λ_max=83.3018\n",
      "[SGD | lr=0.05] Epoch 2676/4000: train_loss=0.0185  test_loss=4.0310  λ_max=84.7856\n",
      "[SGD | lr=0.05] Epoch 2677/4000: train_loss=0.0185  test_loss=4.0316  λ_max=83.1534\n",
      "[SGD | lr=0.05] Epoch 2678/4000: train_loss=0.0185  test_loss=4.0318  λ_max=84.8053\n",
      "[SGD | lr=0.05] Epoch 2679/4000: train_loss=0.0185  test_loss=4.0322  λ_max=84.1278\n",
      "[SGD | lr=0.05] Epoch 2680/4000: train_loss=0.0185  test_loss=4.0326  λ_max=83.2348\n",
      "[SGD | lr=0.05] Epoch 2681/4000: train_loss=0.0184  test_loss=4.0328  λ_max=85.3820\n",
      "[SGD | lr=0.05] Iter 42900: loss=0.0185\n",
      "[SGD | lr=0.05] Epoch 2682/4000: train_loss=0.0184  test_loss=4.0333  λ_max=83.3670\n",
      "[SGD | lr=0.05] Epoch 2683/4000: train_loss=0.0184  test_loss=4.0334  λ_max=84.5615\n",
      "[SGD | lr=0.05] Epoch 2684/4000: train_loss=0.0184  test_loss=4.0336  λ_max=85.9863\n",
      "[SGD | lr=0.05] Epoch 2685/4000: train_loss=0.0184  test_loss=4.0342  λ_max=86.1554\n",
      "[SGD | lr=0.05] Epoch 2686/4000: train_loss=0.0184  test_loss=4.0343  λ_max=83.7422\n",
      "[SGD | lr=0.05] Epoch 2687/4000: train_loss=0.0184  test_loss=4.0348  λ_max=85.9494\n",
      "[SGD | lr=0.05] Iter 43000: loss=0.0187\n",
      "[SGD | lr=0.05] Epoch 2688/4000: train_loss=0.0184  test_loss=4.0351  λ_max=82.9285\n",
      "[SGD | lr=0.05] Epoch 2689/4000: train_loss=0.0184  test_loss=4.0354  λ_max=84.1279\n",
      "[SGD | lr=0.05] Epoch 2690/4000: train_loss=0.0184  test_loss=4.0359  λ_max=85.0599\n",
      "[SGD | lr=0.05] Epoch 2691/4000: train_loss=0.0184  test_loss=4.0360  λ_max=85.1284\n",
      "[SGD | lr=0.05] Epoch 2692/4000: train_loss=0.0183  test_loss=4.0366  λ_max=83.5090\n",
      "[SGD | lr=0.05] Epoch 2693/4000: train_loss=0.0183  test_loss=4.0369  λ_max=85.0792\n",
      "[SGD | lr=0.05] Iter 43100: loss=0.0182\n",
      "[SGD | lr=0.05] Epoch 2694/4000: train_loss=0.0183  test_loss=4.0371  λ_max=85.8604\n",
      "[SGD | lr=0.05] Epoch 2695/4000: train_loss=0.0183  test_loss=4.0373  λ_max=82.5584\n",
      "[SGD | lr=0.05] Epoch 2696/4000: train_loss=0.0183  test_loss=4.0376  λ_max=82.6088\n",
      "[SGD | lr=0.05] Epoch 2697/4000: train_loss=0.0183  test_loss=4.0380  λ_max=83.0591\n",
      "[SGD | lr=0.05] Epoch 2698/4000: train_loss=0.0183  test_loss=4.0385  λ_max=82.8346\n",
      "[SGD | lr=0.05] Epoch 2699/4000: train_loss=0.0183  test_loss=4.0385  λ_max=84.7515\n",
      "[SGD | lr=0.05] Iter 43200: loss=0.0180\n",
      "[SGD | lr=0.05] Epoch 2700/4000: train_loss=0.0183  test_loss=4.0389  λ_max=81.7127\n",
      "[SGD | lr=0.05] Epoch 2701/4000: train_loss=0.0182  test_loss=4.0390  λ_max=81.1755\n",
      "[SGD | lr=0.05] Epoch 2702/4000: train_loss=0.0182  test_loss=4.0399  λ_max=84.8667\n",
      "[SGD | lr=0.05] Epoch 2703/4000: train_loss=0.0182  test_loss=4.0400  λ_max=85.4204\n",
      "[SGD | lr=0.05] Epoch 2704/4000: train_loss=0.0182  test_loss=4.0403  λ_max=84.2213\n",
      "[SGD | lr=0.05] Epoch 2705/4000: train_loss=0.0182  test_loss=4.0404  λ_max=85.2019\n",
      "[SGD | lr=0.05] Epoch 2706/4000: train_loss=0.0182  test_loss=4.0410  λ_max=84.2333\n",
      "[SGD | lr=0.05] Iter 43300: loss=0.0180\n",
      "[SGD | lr=0.05] Epoch 2707/4000: train_loss=0.0182  test_loss=4.0414  λ_max=86.2044\n",
      "[SGD | lr=0.05] Epoch 2708/4000: train_loss=0.0182  test_loss=4.0416  λ_max=85.0657\n",
      "[SGD | lr=0.05] Epoch 2709/4000: train_loss=0.0182  test_loss=4.0418  λ_max=84.7438\n",
      "[SGD | lr=0.05] Epoch 2710/4000: train_loss=0.0182  test_loss=4.0422  λ_max=83.8976\n",
      "[SGD | lr=0.05] Epoch 2711/4000: train_loss=0.0182  test_loss=4.0422  λ_max=83.1569\n",
      "[SGD | lr=0.05] Epoch 2712/4000: train_loss=0.0181  test_loss=4.0429  λ_max=82.9225\n",
      "[SGD | lr=0.05] Iter 43400: loss=0.0180\n",
      "[SGD | lr=0.05] Epoch 2713/4000: train_loss=0.0181  test_loss=4.0432  λ_max=84.7261\n",
      "[SGD | lr=0.05] Epoch 2714/4000: train_loss=0.0181  test_loss=4.0434  λ_max=83.8124\n",
      "[SGD | lr=0.05] Epoch 2715/4000: train_loss=0.0181  test_loss=4.0436  λ_max=85.5699\n",
      "[SGD | lr=0.05] Epoch 2716/4000: train_loss=0.0181  test_loss=4.0441  λ_max=83.3787\n",
      "[SGD | lr=0.05] Epoch 2717/4000: train_loss=0.0181  test_loss=4.0445  λ_max=84.9039\n",
      "[SGD | lr=0.05] Epoch 2718/4000: train_loss=0.0181  test_loss=4.0448  λ_max=84.6249\n",
      "[SGD | lr=0.05] Iter 43500: loss=0.0184\n",
      "[SGD | lr=0.05] Epoch 2719/4000: train_loss=0.0181  test_loss=4.0447  λ_max=84.3929\n",
      "[SGD | lr=0.05] Epoch 2720/4000: train_loss=0.0181  test_loss=4.0454  λ_max=82.8004\n",
      "[SGD | lr=0.05] Epoch 2721/4000: train_loss=0.0180  test_loss=4.0457  λ_max=86.2309\n",
      "[SGD | lr=0.05] Epoch 2722/4000: train_loss=0.0180  test_loss=4.0457  λ_max=84.9779\n",
      "[SGD | lr=0.05] Epoch 2723/4000: train_loss=0.0180  test_loss=4.0463  λ_max=84.8458\n",
      "[SGD | lr=0.05] Epoch 2724/4000: train_loss=0.0180  test_loss=4.0465  λ_max=82.2045\n",
      "[SGD | lr=0.05] Iter 43600: loss=0.0178\n",
      "[SGD | lr=0.05] Epoch 2725/4000: train_loss=0.0180  test_loss=4.0469  λ_max=82.0721\n",
      "[SGD | lr=0.05] Epoch 2726/4000: train_loss=0.0180  test_loss=4.0471  λ_max=84.8268\n",
      "[SGD | lr=0.05] Epoch 2727/4000: train_loss=0.0180  test_loss=4.0474  λ_max=86.5713\n",
      "[SGD | lr=0.05] Epoch 2728/4000: train_loss=0.0180  test_loss=4.0479  λ_max=84.4011\n",
      "[SGD | lr=0.05] Epoch 2729/4000: train_loss=0.0180  test_loss=4.0481  λ_max=85.5281\n",
      "[SGD | lr=0.05] Epoch 2730/4000: train_loss=0.0180  test_loss=4.0487  λ_max=86.4850\n",
      "[SGD | lr=0.05] Epoch 2731/4000: train_loss=0.0180  test_loss=4.0488  λ_max=84.0327\n",
      "[SGD | lr=0.05] Iter 43700: loss=0.0176\n",
      "[SGD | lr=0.05] Epoch 2732/4000: train_loss=0.0179  test_loss=4.0493  λ_max=86.5750\n",
      "[SGD | lr=0.05] Epoch 2733/4000: train_loss=0.0179  test_loss=4.0493  λ_max=84.6474\n",
      "[SGD | lr=0.05] Epoch 2734/4000: train_loss=0.0179  test_loss=4.0499  λ_max=86.0992\n",
      "[SGD | lr=0.05] Epoch 2735/4000: train_loss=0.0179  test_loss=4.0502  λ_max=85.1559\n",
      "[SGD | lr=0.05] Epoch 2736/4000: train_loss=0.0179  test_loss=4.0505  λ_max=84.3827\n",
      "[SGD | lr=0.05] Epoch 2737/4000: train_loss=0.0179  test_loss=4.0505  λ_max=83.6827\n",
      "[SGD | lr=0.05] Iter 43800: loss=0.0180\n",
      "[SGD | lr=0.05] Epoch 2738/4000: train_loss=0.0179  test_loss=4.0510  λ_max=86.2831\n",
      "[SGD | lr=0.05] Epoch 2739/4000: train_loss=0.0179  test_loss=4.0513  λ_max=84.5876\n",
      "[SGD | lr=0.05] Epoch 2740/4000: train_loss=0.0179  test_loss=4.0515  λ_max=84.5468\n",
      "[SGD | lr=0.05] Epoch 2741/4000: train_loss=0.0179  test_loss=4.0519  λ_max=85.4949\n",
      "[SGD | lr=0.05] Epoch 2742/4000: train_loss=0.0178  test_loss=4.0522  λ_max=85.8863\n",
      "[SGD | lr=0.05] Epoch 2743/4000: train_loss=0.0178  test_loss=4.0530  λ_max=84.1379\n",
      "[SGD | lr=0.05] Iter 43900: loss=0.0177\n",
      "[SGD | lr=0.05] Epoch 2744/4000: train_loss=0.0178  test_loss=4.0530  λ_max=85.5115\n",
      "[SGD | lr=0.05] Epoch 2745/4000: train_loss=0.0178  test_loss=4.0533  λ_max=84.7744\n",
      "[SGD | lr=0.05] Epoch 2746/4000: train_loss=0.0178  test_loss=4.0536  λ_max=84.2113\n",
      "[SGD | lr=0.05] Epoch 2747/4000: train_loss=0.0178  test_loss=4.0540  λ_max=85.4716\n",
      "[SGD | lr=0.05] Epoch 2748/4000: train_loss=0.0178  test_loss=4.0542  λ_max=85.0639\n",
      "[SGD | lr=0.05] Epoch 2749/4000: train_loss=0.0178  test_loss=4.0548  λ_max=82.7396\n",
      "[SGD | lr=0.05] Iter 44000: loss=0.0180\n",
      "[SGD | lr=0.05] Epoch 2750/4000: train_loss=0.0178  test_loss=4.0548  λ_max=84.9593\n",
      "[SGD | lr=0.05] Epoch 2751/4000: train_loss=0.0178  test_loss=4.0553  λ_max=87.1606\n",
      "[SGD | lr=0.05] Epoch 2752/4000: train_loss=0.0178  test_loss=4.0556  λ_max=83.5249\n",
      "[SGD | lr=0.05] Epoch 2753/4000: train_loss=0.0177  test_loss=4.0558  λ_max=85.0421\n",
      "[SGD | lr=0.05] Epoch 2754/4000: train_loss=0.0177  test_loss=4.0561  λ_max=87.3587\n",
      "[SGD | lr=0.05] Epoch 2755/4000: train_loss=0.0177  test_loss=4.0565  λ_max=85.4595\n",
      "[SGD | lr=0.05] Epoch 2756/4000: train_loss=0.0177  test_loss=4.0567  λ_max=86.5576\n",
      "[SGD | lr=0.05] Iter 44100: loss=0.0179\n",
      "[SGD | lr=0.05] Epoch 2757/4000: train_loss=0.0177  test_loss=4.0572  λ_max=81.6189\n",
      "[SGD | lr=0.05] Epoch 2758/4000: train_loss=0.0177  test_loss=4.0572  λ_max=84.2445\n",
      "[SGD | lr=0.05] Epoch 2759/4000: train_loss=0.0177  test_loss=4.0577  λ_max=84.9744\n",
      "[SGD | lr=0.05] Epoch 2760/4000: train_loss=0.0177  test_loss=4.0581  λ_max=83.4003\n",
      "[SGD | lr=0.05] Epoch 2761/4000: train_loss=0.0177  test_loss=4.0582  λ_max=86.0755\n",
      "[SGD | lr=0.05] Epoch 2762/4000: train_loss=0.0177  test_loss=4.0586  λ_max=84.6341\n",
      "[SGD | lr=0.05] Iter 44200: loss=0.0184\n",
      "[SGD | lr=0.05] Epoch 2763/4000: train_loss=0.0176  test_loss=4.0591  λ_max=86.1271\n",
      "[SGD | lr=0.05] Epoch 2764/4000: train_loss=0.0176  test_loss=4.0593  λ_max=84.4327\n",
      "[SGD | lr=0.05] Epoch 2765/4000: train_loss=0.0176  test_loss=4.0594  λ_max=83.1473\n",
      "[SGD | lr=0.05] Epoch 2766/4000: train_loss=0.0176  test_loss=4.0598  λ_max=82.9998\n",
      "[SGD | lr=0.05] Epoch 2767/4000: train_loss=0.0176  test_loss=4.0602  λ_max=84.1407\n",
      "[SGD | lr=0.05] Epoch 2768/4000: train_loss=0.0176  test_loss=4.0606  λ_max=85.1765\n",
      "[SGD | lr=0.05] Iter 44300: loss=0.0174\n",
      "[SGD | lr=0.05] Epoch 2769/4000: train_loss=0.0176  test_loss=4.0609  λ_max=86.9170\n",
      "[SGD | lr=0.05] Epoch 2770/4000: train_loss=0.0176  test_loss=4.0611  λ_max=84.0161\n",
      "[SGD | lr=0.05] Epoch 2771/4000: train_loss=0.0176  test_loss=4.0615  λ_max=87.1726\n",
      "[SGD | lr=0.05] Epoch 2772/4000: train_loss=0.0176  test_loss=4.0616  λ_max=85.6410\n",
      "[SGD | lr=0.05] Epoch 2773/4000: train_loss=0.0175  test_loss=4.0622  λ_max=85.3195\n",
      "[SGD | lr=0.05] Epoch 2774/4000: train_loss=0.0175  test_loss=4.0625  λ_max=86.7276\n",
      "[SGD | lr=0.05] Iter 44400: loss=0.0175\n",
      "[SGD | lr=0.05] Epoch 2775/4000: train_loss=0.0175  test_loss=4.0628  λ_max=83.8167\n",
      "[SGD | lr=0.05] Epoch 2776/4000: train_loss=0.0175  test_loss=4.0628  λ_max=83.7101\n",
      "[SGD | lr=0.05] Epoch 2777/4000: train_loss=0.0175  test_loss=4.0634  λ_max=85.7897\n",
      "[SGD | lr=0.05] Epoch 2778/4000: train_loss=0.0175  test_loss=4.0635  λ_max=85.8945\n",
      "[SGD | lr=0.05] Epoch 2779/4000: train_loss=0.0175  test_loss=4.0637  λ_max=83.7372\n",
      "[SGD | lr=0.05] Epoch 2780/4000: train_loss=0.0175  test_loss=4.0642  λ_max=85.3123\n",
      "[SGD | lr=0.05] Epoch 2781/4000: train_loss=0.0175  test_loss=4.0648  λ_max=85.9318\n",
      "[SGD | lr=0.05] Iter 44500: loss=0.0175\n",
      "[SGD | lr=0.05] Epoch 2782/4000: train_loss=0.0174  test_loss=4.0647  λ_max=86.2151\n",
      "[SGD | lr=0.05] Epoch 2783/4000: train_loss=0.0175  test_loss=4.0650  λ_max=83.9945\n",
      "[SGD | lr=0.05] Epoch 2784/4000: train_loss=0.0174  test_loss=4.0653  λ_max=85.4382\n",
      "[SGD | lr=0.05] Epoch 2785/4000: train_loss=0.0174  test_loss=4.0659  λ_max=84.6344\n",
      "[SGD | lr=0.05] Epoch 2786/4000: train_loss=0.0174  test_loss=4.0660  λ_max=85.8118\n",
      "[SGD | lr=0.05] Epoch 2787/4000: train_loss=0.0174  test_loss=4.0666  λ_max=83.0111\n",
      "[SGD | lr=0.05] Iter 44600: loss=0.0177\n",
      "[SGD | lr=0.05] Epoch 2788/4000: train_loss=0.0174  test_loss=4.0667  λ_max=84.2136\n",
      "[SGD | lr=0.05] Epoch 2789/4000: train_loss=0.0174  test_loss=4.0670  λ_max=85.0999\n",
      "[SGD | lr=0.05] Epoch 2790/4000: train_loss=0.0174  test_loss=4.0673  λ_max=85.3795\n",
      "[SGD | lr=0.05] Epoch 2791/4000: train_loss=0.0174  test_loss=4.0676  λ_max=85.9802\n",
      "[SGD | lr=0.05] Epoch 2792/4000: train_loss=0.0174  test_loss=4.0679  λ_max=84.0971\n",
      "[SGD | lr=0.05] Epoch 2793/4000: train_loss=0.0174  test_loss=4.0682  λ_max=84.5052\n",
      "[SGD | lr=0.05] Iter 44700: loss=0.0172\n",
      "[SGD | lr=0.05] Epoch 2794/4000: train_loss=0.0174  test_loss=4.0684  λ_max=83.1992\n",
      "[SGD | lr=0.05] Epoch 2795/4000: train_loss=0.0173  test_loss=4.0690  λ_max=83.5876\n",
      "[SGD | lr=0.05] Epoch 2796/4000: train_loss=0.0173  test_loss=4.0692  λ_max=87.9944\n",
      "[SGD | lr=0.05] Epoch 2797/4000: train_loss=0.0173  test_loss=4.0695  λ_max=87.1874\n",
      "[SGD | lr=0.05] Epoch 2798/4000: train_loss=0.0173  test_loss=4.0698  λ_max=85.6303\n",
      "[SGD | lr=0.05] Epoch 2799/4000: train_loss=0.0173  test_loss=4.0701  λ_max=82.1225\n",
      "[SGD | lr=0.05] Iter 44800: loss=0.0172\n",
      "[SGD | lr=0.05] Epoch 2800/4000: train_loss=0.0173  test_loss=4.0702  λ_max=86.0530\n",
      "[SGD | lr=0.05] Epoch 2801/4000: train_loss=0.0173  test_loss=4.0707  λ_max=83.0859\n",
      "[SGD | lr=0.05] Epoch 2802/4000: train_loss=0.0173  test_loss=4.0709  λ_max=88.0599\n",
      "[SGD | lr=0.05] Epoch 2803/4000: train_loss=0.0173  test_loss=4.0714  λ_max=83.0986\n",
      "[SGD | lr=0.05] Epoch 2804/4000: train_loss=0.0173  test_loss=4.0716  λ_max=83.8518\n",
      "[SGD | lr=0.05] Epoch 2805/4000: train_loss=0.0172  test_loss=4.0718  λ_max=87.9741\n",
      "[SGD | lr=0.05] Epoch 2806/4000: train_loss=0.0172  test_loss=4.0721  λ_max=86.2265\n",
      "[SGD | lr=0.05] Iter 44900: loss=0.0172\n",
      "[SGD | lr=0.05] Epoch 2807/4000: train_loss=0.0172  test_loss=4.0726  λ_max=85.4034\n",
      "[SGD | lr=0.05] Epoch 2808/4000: train_loss=0.0172  test_loss=4.0731  λ_max=84.5767\n",
      "[SGD | lr=0.05] Epoch 2809/4000: train_loss=0.0172  test_loss=4.0733  λ_max=86.8617\n",
      "[SGD | lr=0.05] Epoch 2810/4000: train_loss=0.0172  test_loss=4.0733  λ_max=85.6262\n",
      "[SGD | lr=0.05] Epoch 2811/4000: train_loss=0.0172  test_loss=4.0739  λ_max=84.9365\n",
      "[SGD | lr=0.05] Epoch 2812/4000: train_loss=0.0172  test_loss=4.0742  λ_max=82.8284\n",
      "[SGD | lr=0.05] Iter 45000: loss=0.0176\n",
      "[SGD | lr=0.05] Epoch 2813/4000: train_loss=0.0172  test_loss=4.0742  λ_max=84.7180\n",
      "[SGD | lr=0.05] Epoch 2814/4000: train_loss=0.0172  test_loss=4.0745  λ_max=85.6449\n",
      "[SGD | lr=0.05] Epoch 2815/4000: train_loss=0.0172  test_loss=4.0750  λ_max=86.3373\n",
      "[SGD | lr=0.05] Epoch 2816/4000: train_loss=0.0171  test_loss=4.0753  λ_max=86.5849\n",
      "[SGD | lr=0.05] Epoch 2817/4000: train_loss=0.0171  test_loss=4.0755  λ_max=84.3858\n",
      "[SGD | lr=0.05] Epoch 2818/4000: train_loss=0.0171  test_loss=4.0758  λ_max=84.6227\n",
      "[SGD | lr=0.05] Iter 45100: loss=0.0176\n",
      "[SGD | lr=0.05] Epoch 2819/4000: train_loss=0.0171  test_loss=4.0764  λ_max=86.7982\n",
      "[SGD | lr=0.05] Epoch 2820/4000: train_loss=0.0171  test_loss=4.0764  λ_max=87.2848\n",
      "[SGD | lr=0.05] Epoch 2821/4000: train_loss=0.0171  test_loss=4.0768  λ_max=83.0462\n",
      "[SGD | lr=0.05] Epoch 2822/4000: train_loss=0.0171  test_loss=4.0775  λ_max=88.1054\n",
      "[SGD | lr=0.05] Epoch 2823/4000: train_loss=0.0171  test_loss=4.0775  λ_max=87.0807\n",
      "[SGD | lr=0.05] Epoch 2824/4000: train_loss=0.0171  test_loss=4.0778  λ_max=85.6840\n",
      "[SGD | lr=0.05] Iter 45200: loss=0.0169\n",
      "[SGD | lr=0.05] Epoch 2825/4000: train_loss=0.0171  test_loss=4.0782  λ_max=83.3569\n",
      "[SGD | lr=0.05] Epoch 2826/4000: train_loss=0.0171  test_loss=4.0782  λ_max=85.6062\n",
      "[SGD | lr=0.05] Epoch 2827/4000: train_loss=0.0170  test_loss=4.0787  λ_max=85.7703\n",
      "[SGD | lr=0.05] Epoch 2828/4000: train_loss=0.0171  test_loss=4.0790  λ_max=86.5179\n",
      "[SGD | lr=0.05] Epoch 2829/4000: train_loss=0.0170  test_loss=4.0793  λ_max=87.5436\n",
      "[SGD | lr=0.05] Epoch 2830/4000: train_loss=0.0170  test_loss=4.0796  λ_max=87.2376\n",
      "[SGD | lr=0.05] Epoch 2831/4000: train_loss=0.0170  test_loss=4.0798  λ_max=85.0548\n",
      "[SGD | lr=0.05] Iter 45300: loss=0.0173\n",
      "[SGD | lr=0.05] Epoch 2832/4000: train_loss=0.0170  test_loss=4.0803  λ_max=83.9537\n",
      "[SGD | lr=0.05] Epoch 2833/4000: train_loss=0.0170  test_loss=4.0805  λ_max=86.4039\n",
      "[SGD | lr=0.05] Epoch 2834/4000: train_loss=0.0170  test_loss=4.0811  λ_max=87.3500\n",
      "[SGD | lr=0.05] Epoch 2835/4000: train_loss=0.0170  test_loss=4.0813  λ_max=86.5909\n",
      "[SGD | lr=0.05] Epoch 2836/4000: train_loss=0.0170  test_loss=4.0813  λ_max=87.3950\n",
      "[SGD | lr=0.05] Epoch 2837/4000: train_loss=0.0170  test_loss=4.0815  λ_max=86.1620\n",
      "[SGD | lr=0.05] Iter 45400: loss=0.0170\n",
      "[SGD | lr=0.05] Epoch 2838/4000: train_loss=0.0170  test_loss=4.0820  λ_max=84.7944\n",
      "[SGD | lr=0.05] Epoch 2839/4000: train_loss=0.0169  test_loss=4.0823  λ_max=85.4875\n",
      "[SGD | lr=0.05] Epoch 2840/4000: train_loss=0.0169  test_loss=4.0826  λ_max=85.8118\n",
      "[SGD | lr=0.05] Epoch 2841/4000: train_loss=0.0169  test_loss=4.0830  λ_max=87.3278\n",
      "[SGD | lr=0.05] Epoch 2842/4000: train_loss=0.0169  test_loss=4.0832  λ_max=86.8264\n",
      "[SGD | lr=0.05] Epoch 2843/4000: train_loss=0.0169  test_loss=4.0836  λ_max=87.1742\n",
      "[SGD | lr=0.05] Iter 45500: loss=0.0169\n",
      "[SGD | lr=0.05] Epoch 2844/4000: train_loss=0.0169  test_loss=4.0839  λ_max=85.3283\n",
      "[SGD | lr=0.05] Epoch 2845/4000: train_loss=0.0169  test_loss=4.0842  λ_max=85.9593\n",
      "[SGD | lr=0.05] Epoch 2846/4000: train_loss=0.0169  test_loss=4.0846  λ_max=85.6337\n",
      "[SGD | lr=0.05] Epoch 2847/4000: train_loss=0.0169  test_loss=4.0847  λ_max=81.4002\n",
      "[SGD | lr=0.05] Epoch 2848/4000: train_loss=0.0169  test_loss=4.0851  λ_max=84.8138\n",
      "[SGD | lr=0.05] Epoch 2849/4000: train_loss=0.0169  test_loss=4.0853  λ_max=87.8199\n",
      "[SGD | lr=0.05] Iter 45600: loss=0.0169\n",
      "[SGD | lr=0.05] Epoch 2850/4000: train_loss=0.0168  test_loss=4.0857  λ_max=86.6037\n",
      "[SGD | lr=0.05] Epoch 2851/4000: train_loss=0.0168  test_loss=4.0859  λ_max=84.2242\n",
      "[SGD | lr=0.05] Epoch 2852/4000: train_loss=0.0168  test_loss=4.0862  λ_max=85.5003\n",
      "[SGD | lr=0.05] Epoch 2853/4000: train_loss=0.0168  test_loss=4.0865  λ_max=86.7679\n",
      "[SGD | lr=0.05] Epoch 2854/4000: train_loss=0.0168  test_loss=4.0868  λ_max=88.6740\n",
      "[SGD | lr=0.05] Epoch 2855/4000: train_loss=0.0168  test_loss=4.0871  λ_max=86.9950\n",
      "[SGD | lr=0.05] Epoch 2856/4000: train_loss=0.0168  test_loss=4.0875  λ_max=86.6147\n",
      "[SGD | lr=0.05] Iter 45700: loss=0.0166\n",
      "[SGD | lr=0.05] Epoch 2857/4000: train_loss=0.0168  test_loss=4.0879  λ_max=84.5795\n",
      "[SGD | lr=0.05] Epoch 2858/4000: train_loss=0.0168  test_loss=4.0882  λ_max=86.1614\n",
      "[SGD | lr=0.05] Epoch 2859/4000: train_loss=0.0168  test_loss=4.0881  λ_max=86.5373\n",
      "[SGD | lr=0.05] Epoch 2860/4000: train_loss=0.0168  test_loss=4.0890  λ_max=88.5008\n",
      "[SGD | lr=0.05] Epoch 2861/4000: train_loss=0.0167  test_loss=4.0890  λ_max=85.3871\n",
      "[SGD | lr=0.05] Epoch 2862/4000: train_loss=0.0167  test_loss=4.0892  λ_max=85.9920\n",
      "[SGD | lr=0.05] Iter 45800: loss=0.0168\n",
      "[SGD | lr=0.05] Epoch 2863/4000: train_loss=0.0167  test_loss=4.0897  λ_max=85.3035\n",
      "[SGD | lr=0.05] Epoch 2864/4000: train_loss=0.0167  test_loss=4.0899  λ_max=85.3307\n",
      "[SGD | lr=0.05] Epoch 2865/4000: train_loss=0.0167  test_loss=4.0904  λ_max=86.9888\n",
      "[SGD | lr=0.05] Epoch 2866/4000: train_loss=0.0167  test_loss=4.0904  λ_max=87.4718\n",
      "[SGD | lr=0.05] Epoch 2867/4000: train_loss=0.0167  test_loss=4.0906  λ_max=86.8383\n",
      "[SGD | lr=0.05] Epoch 2868/4000: train_loss=0.0167  test_loss=4.0911  λ_max=84.0057\n",
      "[SGD | lr=0.05] Iter 45900: loss=0.0164\n",
      "[SGD | lr=0.05] Epoch 2869/4000: train_loss=0.0167  test_loss=4.0914  λ_max=84.5154\n",
      "[SGD | lr=0.05] Epoch 2870/4000: train_loss=0.0167  test_loss=4.0913  λ_max=84.7707\n",
      "[SGD | lr=0.05] Epoch 2871/4000: train_loss=0.0167  test_loss=4.0921  λ_max=83.7130\n",
      "[SGD | lr=0.05] Epoch 2872/4000: train_loss=0.0167  test_loss=4.0922  λ_max=85.6355\n",
      "[SGD | lr=0.05] Epoch 2873/4000: train_loss=0.0166  test_loss=4.0925  λ_max=82.7775\n",
      "[SGD | lr=0.05] Epoch 2874/4000: train_loss=0.0166  test_loss=4.0928  λ_max=85.2747\n",
      "[SGD | lr=0.05] Iter 46000: loss=0.0167\n",
      "[SGD | lr=0.05] Epoch 2875/4000: train_loss=0.0166  test_loss=4.0931  λ_max=86.4962\n",
      "[SGD | lr=0.05] Epoch 2876/4000: train_loss=0.0166  test_loss=4.0935  λ_max=86.4948\n",
      "[SGD | lr=0.05] Epoch 2877/4000: train_loss=0.0166  test_loss=4.0936  λ_max=85.4369\n",
      "[SGD | lr=0.05] Epoch 2878/4000: train_loss=0.0166  test_loss=4.0940  λ_max=85.8905\n",
      "[SGD | lr=0.05] Epoch 2879/4000: train_loss=0.0166  test_loss=4.0945  λ_max=84.7358\n",
      "[SGD | lr=0.05] Epoch 2880/4000: train_loss=0.0166  test_loss=4.0946  λ_max=85.9121\n",
      "[SGD | lr=0.05] Epoch 2881/4000: train_loss=0.0166  test_loss=4.0949  λ_max=84.7546\n",
      "[SGD | lr=0.05] Iter 46100: loss=0.0165\n",
      "[SGD | lr=0.05] Epoch 2882/4000: train_loss=0.0166  test_loss=4.0953  λ_max=87.1825\n",
      "[SGD | lr=0.05] Epoch 2883/4000: train_loss=0.0166  test_loss=4.0956  λ_max=85.8994\n",
      "[SGD | lr=0.05] Epoch 2884/4000: train_loss=0.0166  test_loss=4.0958  λ_max=85.2853\n",
      "[SGD | lr=0.05] Epoch 2885/4000: train_loss=0.0165  test_loss=4.0960  λ_max=85.9999\n",
      "[SGD | lr=0.05] Epoch 2886/4000: train_loss=0.0165  test_loss=4.0962  λ_max=85.4364\n",
      "[SGD | lr=0.05] Epoch 2887/4000: train_loss=0.0165  test_loss=4.0967  λ_max=85.7251\n",
      "[SGD | lr=0.05] Iter 46200: loss=0.0164\n",
      "[SGD | lr=0.05] Epoch 2888/4000: train_loss=0.0165  test_loss=4.0971  λ_max=87.3261\n",
      "[SGD | lr=0.05] Epoch 2889/4000: train_loss=0.0165  test_loss=4.0972  λ_max=86.0242\n",
      "[SGD | lr=0.05] Epoch 2890/4000: train_loss=0.0165  test_loss=4.0976  λ_max=83.8748\n",
      "[SGD | lr=0.05] Epoch 2891/4000: train_loss=0.0165  test_loss=4.0981  λ_max=85.5946\n",
      "[SGD | lr=0.05] Epoch 2892/4000: train_loss=0.0165  test_loss=4.0983  λ_max=86.0327\n",
      "[SGD | lr=0.05] Epoch 2893/4000: train_loss=0.0165  test_loss=4.0984  λ_max=86.8559\n",
      "[SGD | lr=0.05] Iter 46300: loss=0.0164\n",
      "[SGD | lr=0.05] Epoch 2894/4000: train_loss=0.0165  test_loss=4.0989  λ_max=86.6414\n",
      "[SGD | lr=0.05] Epoch 2895/4000: train_loss=0.0165  test_loss=4.0994  λ_max=85.5900\n",
      "[SGD | lr=0.05] Epoch 2896/4000: train_loss=0.0164  test_loss=4.0996  λ_max=87.4305\n",
      "[SGD | lr=0.05] Epoch 2897/4000: train_loss=0.0164  test_loss=4.1000  λ_max=85.4500\n",
      "[SGD | lr=0.05] Epoch 2898/4000: train_loss=0.0164  test_loss=4.1000  λ_max=86.5221\n",
      "[SGD | lr=0.05] Epoch 2899/4000: train_loss=0.0164  test_loss=4.1001  λ_max=85.9990\n",
      "[SGD | lr=0.05] Iter 46400: loss=0.0164\n",
      "[SGD | lr=0.05] Epoch 2900/4000: train_loss=0.0164  test_loss=4.1008  λ_max=83.7273\n",
      "[SGD | lr=0.05] Epoch 2901/4000: train_loss=0.0164  test_loss=4.1009  λ_max=88.2422\n",
      "[SGD | lr=0.05] Epoch 2902/4000: train_loss=0.0164  test_loss=4.1012  λ_max=86.9869\n",
      "[SGD | lr=0.05] Epoch 2903/4000: train_loss=0.0164  test_loss=4.1016  λ_max=84.0831\n",
      "[SGD | lr=0.05] Epoch 2904/4000: train_loss=0.0164  test_loss=4.1018  λ_max=86.0005\n",
      "[SGD | lr=0.05] Epoch 2905/4000: train_loss=0.0164  test_loss=4.1022  λ_max=86.1778\n",
      "[SGD | lr=0.05] Epoch 2906/4000: train_loss=0.0164  test_loss=4.1022  λ_max=85.8245\n",
      "[SGD | lr=0.05] Iter 46500: loss=0.0163\n",
      "[SGD | lr=0.05] Epoch 2907/4000: train_loss=0.0164  test_loss=4.1028  λ_max=88.1409\n",
      "[SGD | lr=0.05] Epoch 2908/4000: train_loss=0.0163  test_loss=4.1030  λ_max=85.8874\n",
      "[SGD | lr=0.05] Epoch 2909/4000: train_loss=0.0163  test_loss=4.1034  λ_max=88.1365\n",
      "[SGD | lr=0.05] Epoch 2910/4000: train_loss=0.0163  test_loss=4.1036  λ_max=89.1175\n",
      "[SGD | lr=0.05] Epoch 2911/4000: train_loss=0.0163  test_loss=4.1038  λ_max=86.2940\n",
      "[SGD | lr=0.05] Epoch 2912/4000: train_loss=0.0163  test_loss=4.1040  λ_max=86.9469\n",
      "[SGD | lr=0.05] Iter 46600: loss=0.0165\n",
      "[SGD | lr=0.05] Epoch 2913/4000: train_loss=0.0163  test_loss=4.1044  λ_max=86.5712\n",
      "[SGD | lr=0.05] Epoch 2914/4000: train_loss=0.0163  test_loss=4.1047  λ_max=87.9696\n",
      "[SGD | lr=0.05] Epoch 2915/4000: train_loss=0.0163  test_loss=4.1050  λ_max=83.1580\n",
      "[SGD | lr=0.05] Epoch 2916/4000: train_loss=0.0163  test_loss=4.1055  λ_max=86.2035\n",
      "[SGD | lr=0.05] Epoch 2917/4000: train_loss=0.0163  test_loss=4.1057  λ_max=86.9537\n",
      "[SGD | lr=0.05] Epoch 2918/4000: train_loss=0.0163  test_loss=4.1061  λ_max=87.1356\n",
      "[SGD | lr=0.05] Iter 46700: loss=0.0162\n",
      "[SGD | lr=0.05] Epoch 2919/4000: train_loss=0.0163  test_loss=4.1062  λ_max=86.9579\n",
      "[SGD | lr=0.05] Epoch 2920/4000: train_loss=0.0162  test_loss=4.1067  λ_max=87.0936\n",
      "[SGD | lr=0.05] Epoch 2921/4000: train_loss=0.0162  test_loss=4.1069  λ_max=87.2598\n",
      "[SGD | lr=0.05] Epoch 2922/4000: train_loss=0.0162  test_loss=4.1072  λ_max=85.0927\n",
      "[SGD | lr=0.05] Epoch 2923/4000: train_loss=0.0162  test_loss=4.1075  λ_max=85.5756\n",
      "[SGD | lr=0.05] Epoch 2924/4000: train_loss=0.0162  test_loss=4.1077  λ_max=86.6634\n",
      "[SGD | lr=0.05] Iter 46800: loss=0.0160\n",
      "[SGD | lr=0.05] Epoch 2925/4000: train_loss=0.0162  test_loss=4.1078  λ_max=87.5011\n",
      "[SGD | lr=0.05] Epoch 2926/4000: train_loss=0.0162  test_loss=4.1084  λ_max=85.6178\n",
      "[SGD | lr=0.05] Epoch 2927/4000: train_loss=0.0162  test_loss=4.1087  λ_max=87.2366\n",
      "[SGD | lr=0.05] Epoch 2928/4000: train_loss=0.0162  test_loss=4.1088  λ_max=87.6763\n",
      "[SGD | lr=0.05] Epoch 2929/4000: train_loss=0.0162  test_loss=4.1093  λ_max=84.5890\n",
      "[SGD | lr=0.05] Epoch 2930/4000: train_loss=0.0162  test_loss=4.1094  λ_max=86.2980\n",
      "[SGD | lr=0.05] Epoch 2931/4000: train_loss=0.0162  test_loss=4.1099  λ_max=87.4856\n",
      "[SGD | lr=0.05] Iter 46900: loss=0.0159\n",
      "[SGD | lr=0.05] Epoch 2932/4000: train_loss=0.0161  test_loss=4.1100  λ_max=88.3161\n",
      "[SGD | lr=0.05] Epoch 2933/4000: train_loss=0.0161  test_loss=4.1103  λ_max=86.8053\n",
      "[SGD | lr=0.05] Epoch 2934/4000: train_loss=0.0161  test_loss=4.1105  λ_max=86.3532\n",
      "[SGD | lr=0.05] Epoch 2935/4000: train_loss=0.0161  test_loss=4.1109  λ_max=86.9164\n",
      "[SGD | lr=0.05] Epoch 2936/4000: train_loss=0.0161  test_loss=4.1112  λ_max=87.8213\n",
      "[SGD | lr=0.05] Epoch 2937/4000: train_loss=0.0161  test_loss=4.1115  λ_max=86.4800\n",
      "[SGD | lr=0.05] Iter 47000: loss=0.0160\n",
      "[SGD | lr=0.05] Epoch 2938/4000: train_loss=0.0161  test_loss=4.1117  λ_max=85.7133\n",
      "[SGD | lr=0.05] Epoch 2939/4000: train_loss=0.0161  test_loss=4.1121  λ_max=86.3009\n",
      "[SGD | lr=0.05] Epoch 2940/4000: train_loss=0.0161  test_loss=4.1123  λ_max=87.4406\n",
      "[SGD | lr=0.05] Epoch 2941/4000: train_loss=0.0161  test_loss=4.1127  λ_max=86.3906\n",
      "[SGD | lr=0.05] Epoch 2942/4000: train_loss=0.0161  test_loss=4.1130  λ_max=86.2043\n",
      "[SGD | lr=0.05] Epoch 2943/4000: train_loss=0.0161  test_loss=4.1133  λ_max=86.8580\n",
      "[SGD | lr=0.05] Iter 47100: loss=0.0162\n",
      "[SGD | lr=0.05] Epoch 2944/4000: train_loss=0.0161  test_loss=4.1134  λ_max=88.4361\n",
      "[SGD | lr=0.05] Epoch 2945/4000: train_loss=0.0160  test_loss=4.1138  λ_max=87.4320\n",
      "[SGD | lr=0.05] Epoch 2946/4000: train_loss=0.0160  test_loss=4.1141  λ_max=86.2388\n",
      "[SGD | lr=0.05] Epoch 2947/4000: train_loss=0.0160  test_loss=4.1144  λ_max=87.4175\n",
      "[SGD | lr=0.05] Epoch 2948/4000: train_loss=0.0160  test_loss=4.1147  λ_max=88.3244\n",
      "[SGD | lr=0.05] Epoch 2949/4000: train_loss=0.0160  test_loss=4.1148  λ_max=87.1026\n",
      "[SGD | lr=0.05] Iter 47200: loss=0.0160\n",
      "[SGD | lr=0.05] Epoch 2950/4000: train_loss=0.0160  test_loss=4.1152  λ_max=87.6591\n",
      "[SGD | lr=0.05] Epoch 2951/4000: train_loss=0.0160  test_loss=4.1156  λ_max=86.3150\n",
      "[SGD | lr=0.05] Epoch 2952/4000: train_loss=0.0160  test_loss=4.1158  λ_max=88.7006\n",
      "[SGD | lr=0.05] Epoch 2953/4000: train_loss=0.0160  test_loss=4.1162  λ_max=87.8446\n",
      "[SGD | lr=0.05] Epoch 2954/4000: train_loss=0.0160  test_loss=4.1164  λ_max=87.7644\n",
      "[SGD | lr=0.05] Epoch 2955/4000: train_loss=0.0160  test_loss=4.1168  λ_max=87.2252\n",
      "[SGD | lr=0.05] Epoch 2956/4000: train_loss=0.0160  test_loss=4.1169  λ_max=88.6443\n",
      "[SGD | lr=0.05] Iter 47300: loss=0.0155\n",
      "[SGD | lr=0.05] Epoch 2957/4000: train_loss=0.0160  test_loss=4.1175  λ_max=88.2275\n",
      "[SGD | lr=0.05] Epoch 2958/4000: train_loss=0.0159  test_loss=4.1176  λ_max=86.1680\n",
      "[SGD | lr=0.05] Epoch 2959/4000: train_loss=0.0159  test_loss=4.1179  λ_max=88.3056\n",
      "[SGD | lr=0.05] Epoch 2960/4000: train_loss=0.0159  test_loss=4.1182  λ_max=88.9162\n",
      "[SGD | lr=0.05] Epoch 2961/4000: train_loss=0.0159  test_loss=4.1187  λ_max=87.7464\n",
      "[SGD | lr=0.05] Epoch 2962/4000: train_loss=0.0159  test_loss=4.1187  λ_max=86.6332\n",
      "[SGD | lr=0.05] Iter 47400: loss=0.0161\n",
      "[SGD | lr=0.05] Epoch 2963/4000: train_loss=0.0159  test_loss=4.1191  λ_max=86.3577\n",
      "[SGD | lr=0.05] Epoch 2964/4000: train_loss=0.0159  test_loss=4.1194  λ_max=88.2917\n",
      "[SGD | lr=0.05] Epoch 2965/4000: train_loss=0.0159  test_loss=4.1197  λ_max=85.6953\n",
      "[SGD | lr=0.05] Epoch 2966/4000: train_loss=0.0159  test_loss=4.1199  λ_max=86.6777\n",
      "[SGD | lr=0.05] Epoch 2967/4000: train_loss=0.0159  test_loss=4.1202  λ_max=85.7550\n",
      "[SGD | lr=0.05] Epoch 2968/4000: train_loss=0.0159  test_loss=4.1206  λ_max=87.1343\n",
      "[SGD | lr=0.05] Iter 47500: loss=0.0158\n",
      "[SGD | lr=0.05] Epoch 2969/4000: train_loss=0.0159  test_loss=4.1207  λ_max=88.0257\n",
      "[SGD | lr=0.05] Epoch 2970/4000: train_loss=0.0159  test_loss=4.1210  λ_max=88.6666\n",
      "[SGD | lr=0.05] Epoch 2971/4000: train_loss=0.0158  test_loss=4.1211  λ_max=87.1078\n",
      "[SGD | lr=0.05] Epoch 2972/4000: train_loss=0.0158  test_loss=4.1217  λ_max=86.9479\n",
      "[SGD | lr=0.05] Epoch 2973/4000: train_loss=0.0158  test_loss=4.1219  λ_max=88.3167\n",
      "[SGD | lr=0.05] Epoch 2974/4000: train_loss=0.0158  test_loss=4.1222  λ_max=86.8981\n",
      "[SGD | lr=0.05] Iter 47600: loss=0.0162\n",
      "[SGD | lr=0.05] Epoch 2975/4000: train_loss=0.0158  test_loss=4.1224  λ_max=87.5389\n",
      "[SGD | lr=0.05] Epoch 2976/4000: train_loss=0.0158  test_loss=4.1229  λ_max=84.4373\n",
      "[SGD | lr=0.05] Epoch 2977/4000: train_loss=0.0158  test_loss=4.1231  λ_max=86.7153\n",
      "[SGD | lr=0.05] Epoch 2978/4000: train_loss=0.0158  test_loss=4.1232  λ_max=90.4486\n",
      "[SGD | lr=0.05] Epoch 2979/4000: train_loss=0.0158  test_loss=4.1235  λ_max=84.9952\n",
      "[SGD | lr=0.05] Epoch 2980/4000: train_loss=0.0158  test_loss=4.1240  λ_max=88.7914\n",
      "[SGD | lr=0.05] Epoch 2981/4000: train_loss=0.0158  test_loss=4.1241  λ_max=87.1254\n",
      "[SGD | lr=0.05] Iter 47700: loss=0.0157\n",
      "[SGD | lr=0.05] Epoch 2982/4000: train_loss=0.0158  test_loss=4.1247  λ_max=86.6916\n",
      "[SGD | lr=0.05] Epoch 2983/4000: train_loss=0.0157  test_loss=4.1247  λ_max=85.3757\n",
      "[SGD | lr=0.05] Epoch 2984/4000: train_loss=0.0157  test_loss=4.1250  λ_max=85.0126\n",
      "[SGD | lr=0.05] Epoch 2985/4000: train_loss=0.0157  test_loss=4.1255  λ_max=89.1154\n",
      "[SGD | lr=0.05] Epoch 2986/4000: train_loss=0.0157  test_loss=4.1255  λ_max=87.1891\n",
      "[SGD | lr=0.05] Epoch 2987/4000: train_loss=0.0157  test_loss=4.1259  λ_max=86.6292\n",
      "[SGD | lr=0.05] Iter 47800: loss=0.0155\n",
      "[SGD | lr=0.05] Epoch 2988/4000: train_loss=0.0157  test_loss=4.1262  λ_max=84.1070\n",
      "[SGD | lr=0.05] Epoch 2989/4000: train_loss=0.0157  test_loss=4.1265  λ_max=86.2270\n",
      "[SGD | lr=0.05] Epoch 2990/4000: train_loss=0.0157  test_loss=4.1271  λ_max=85.2451\n",
      "[SGD | lr=0.05] Epoch 2991/4000: train_loss=0.0157  test_loss=4.1271  λ_max=88.5637\n",
      "[SGD | lr=0.05] Epoch 2992/4000: train_loss=0.0157  test_loss=4.1275  λ_max=88.0585\n",
      "[SGD | lr=0.05] Epoch 2993/4000: train_loss=0.0157  test_loss=4.1276  λ_max=87.9464\n",
      "[SGD | lr=0.05] Iter 47900: loss=0.0160\n",
      "[SGD | lr=0.05] Epoch 2994/4000: train_loss=0.0157  test_loss=4.1280  λ_max=86.3847\n",
      "[SGD | lr=0.05] Epoch 2995/4000: train_loss=0.0157  test_loss=4.1282  λ_max=85.4005\n",
      "[SGD | lr=0.05] Epoch 2996/4000: train_loss=0.0156  test_loss=4.1287  λ_max=86.8728\n",
      "[SGD | lr=0.05] Epoch 2997/4000: train_loss=0.0156  test_loss=4.1288  λ_max=87.7440\n",
      "[SGD | lr=0.05] Epoch 2998/4000: train_loss=0.0156  test_loss=4.1289  λ_max=87.9977\n",
      "[SGD | lr=0.05] Epoch 2999/4000: train_loss=0.0156  test_loss=4.1296  λ_max=84.4945\n",
      "[SGD | lr=0.05] Iter 48000: loss=0.0162\n",
      "[SGD | lr=0.05] Epoch 3000/4000: train_loss=0.0156  test_loss=4.1296  λ_max=87.1428\n",
      "[SGD | lr=0.05] Epoch 3001/4000: train_loss=0.0156  test_loss=4.1299  λ_max=88.5777\n",
      "[SGD | lr=0.05] Epoch 3002/4000: train_loss=0.0156  test_loss=4.1299  λ_max=86.3996\n",
      "[SGD | lr=0.05] Epoch 3003/4000: train_loss=0.0156  test_loss=4.1304  λ_max=89.1986\n",
      "[SGD | lr=0.05] Epoch 3004/4000: train_loss=0.0156  test_loss=4.1310  λ_max=86.4536\n",
      "[SGD | lr=0.05] Epoch 3005/4000: train_loss=0.0156  test_loss=4.1312  λ_max=86.9730\n",
      "[SGD | lr=0.05] Epoch 3006/4000: train_loss=0.0156  test_loss=4.1313  λ_max=86.6971\n",
      "[SGD | lr=0.05] Iter 48100: loss=0.0156\n",
      "[SGD | lr=0.05] Epoch 3007/4000: train_loss=0.0156  test_loss=4.1317  λ_max=88.2161\n",
      "[SGD | lr=0.05] Epoch 3008/4000: train_loss=0.0156  test_loss=4.1319  λ_max=87.5194\n",
      "[SGD | lr=0.05] Epoch 3009/4000: train_loss=0.0155  test_loss=4.1321  λ_max=87.8997\n",
      "[SGD | lr=0.05] Epoch 3010/4000: train_loss=0.0156  test_loss=4.1325  λ_max=85.8760\n",
      "[SGD | lr=0.05] Epoch 3011/4000: train_loss=0.0155  test_loss=4.1329  λ_max=87.5041\n",
      "[SGD | lr=0.05] Epoch 3012/4000: train_loss=0.0155  test_loss=4.1330  λ_max=89.5980\n",
      "[SGD | lr=0.05] Iter 48200: loss=0.0156\n",
      "[SGD | lr=0.05] Epoch 3013/4000: train_loss=0.0155  test_loss=4.1332  λ_max=87.4280\n",
      "[SGD | lr=0.05] Epoch 3014/4000: train_loss=0.0155  test_loss=4.1338  λ_max=90.8330\n",
      "[SGD | lr=0.05] Epoch 3015/4000: train_loss=0.0155  test_loss=4.1339  λ_max=88.5140\n",
      "[SGD | lr=0.05] Epoch 3016/4000: train_loss=0.0155  test_loss=4.1342  λ_max=86.6607\n",
      "[SGD | lr=0.05] Epoch 3017/4000: train_loss=0.0155  test_loss=4.1344  λ_max=88.4710\n",
      "[SGD | lr=0.05] Epoch 3018/4000: train_loss=0.0155  test_loss=4.1349  λ_max=89.1240\n",
      "[SGD | lr=0.05] Iter 48300: loss=0.0154\n",
      "[SGD | lr=0.05] Epoch 3019/4000: train_loss=0.0155  test_loss=4.1349  λ_max=90.6026\n",
      "[SGD | lr=0.05] Epoch 3020/4000: train_loss=0.0155  test_loss=4.1352  λ_max=85.9501\n",
      "[SGD | lr=0.05] Epoch 3021/4000: train_loss=0.0155  test_loss=4.1357  λ_max=88.9608\n",
      "[SGD | lr=0.05] Epoch 3022/4000: train_loss=0.0154  test_loss=4.1357  λ_max=88.1727\n",
      "[SGD | lr=0.05] Epoch 3023/4000: train_loss=0.0155  test_loss=4.1362  λ_max=88.3630\n",
      "[SGD | lr=0.05] Epoch 3024/4000: train_loss=0.0154  test_loss=4.1366  λ_max=88.4176\n",
      "[SGD | lr=0.05] Iter 48400: loss=0.0154\n",
      "[SGD | lr=0.05] Epoch 3025/4000: train_loss=0.0154  test_loss=4.1369  λ_max=87.4389\n",
      "[SGD | lr=0.05] Epoch 3026/4000: train_loss=0.0154  test_loss=4.1369  λ_max=87.2315\n",
      "[SGD | lr=0.05] Epoch 3027/4000: train_loss=0.0154  test_loss=4.1375  λ_max=87.1980\n",
      "[SGD | lr=0.05] Epoch 3028/4000: train_loss=0.0154  test_loss=4.1374  λ_max=89.4134\n",
      "[SGD | lr=0.05] Epoch 3029/4000: train_loss=0.0154  test_loss=4.1379  λ_max=85.2257\n",
      "[SGD | lr=0.05] Epoch 3030/4000: train_loss=0.0154  test_loss=4.1384  λ_max=87.8681\n",
      "[SGD | lr=0.05] Epoch 3031/4000: train_loss=0.0154  test_loss=4.1386  λ_max=89.1082\n",
      "[SGD | lr=0.05] Iter 48500: loss=0.0156\n",
      "[SGD | lr=0.05] Epoch 3032/4000: train_loss=0.0154  test_loss=4.1389  λ_max=87.3128\n",
      "[SGD | lr=0.05] Epoch 3033/4000: train_loss=0.0154  test_loss=4.1389  λ_max=86.2787\n",
      "[SGD | lr=0.05] Epoch 3034/4000: train_loss=0.0154  test_loss=4.1393  λ_max=87.1348\n",
      "[SGD | lr=0.05] Epoch 3035/4000: train_loss=0.0154  test_loss=4.1396  λ_max=87.0052\n",
      "[SGD | lr=0.05] Epoch 3036/4000: train_loss=0.0153  test_loss=4.1399  λ_max=87.8816\n",
      "[SGD | lr=0.05] Epoch 3037/4000: train_loss=0.0154  test_loss=4.1401  λ_max=86.5134\n",
      "[SGD | lr=0.05] Iter 48600: loss=0.0153\n",
      "[SGD | lr=0.05] Epoch 3038/4000: train_loss=0.0153  test_loss=4.1402  λ_max=87.7611\n",
      "[SGD | lr=0.05] Epoch 3039/4000: train_loss=0.0153  test_loss=4.1407  λ_max=87.4536\n",
      "[SGD | lr=0.05] Epoch 3040/4000: train_loss=0.0153  test_loss=4.1412  λ_max=88.6881\n",
      "[SGD | lr=0.05] Epoch 3041/4000: train_loss=0.0153  test_loss=4.1410  λ_max=89.8030\n",
      "[SGD | lr=0.05] Epoch 3042/4000: train_loss=0.0153  test_loss=4.1416  λ_max=88.8720\n",
      "[SGD | lr=0.05] Epoch 3043/4000: train_loss=0.0153  test_loss=4.1417  λ_max=86.5089\n",
      "[SGD | lr=0.05] Iter 48700: loss=0.0154\n",
      "[SGD | lr=0.05] Epoch 3044/4000: train_loss=0.0153  test_loss=4.1421  λ_max=89.9390\n",
      "[SGD | lr=0.05] Epoch 3045/4000: train_loss=0.0153  test_loss=4.1423  λ_max=84.6312\n",
      "[SGD | lr=0.05] Epoch 3046/4000: train_loss=0.0153  test_loss=4.1428  λ_max=87.6583\n",
      "[SGD | lr=0.05] Epoch 3047/4000: train_loss=0.0153  test_loss=4.1429  λ_max=88.8351\n",
      "[SGD | lr=0.05] Epoch 3048/4000: train_loss=0.0153  test_loss=4.1432  λ_max=86.4149\n",
      "[SGD | lr=0.05] Epoch 3049/4000: train_loss=0.0153  test_loss=4.1433  λ_max=85.6304\n",
      "[SGD | lr=0.05] Iter 48800: loss=0.0152\n",
      "[SGD | lr=0.05] Epoch 3050/4000: train_loss=0.0152  test_loss=4.1436  λ_max=85.1265\n",
      "[SGD | lr=0.05] Epoch 3051/4000: train_loss=0.0152  test_loss=4.1441  λ_max=85.1423\n",
      "[SGD | lr=0.05] Epoch 3052/4000: train_loss=0.0152  test_loss=4.1443  λ_max=86.7396\n",
      "[SGD | lr=0.05] Epoch 3053/4000: train_loss=0.0152  test_loss=4.1444  λ_max=86.3830\n",
      "[SGD | lr=0.05] Epoch 3054/4000: train_loss=0.0152  test_loss=4.1449  λ_max=87.2948\n",
      "[SGD | lr=0.05] Epoch 3055/4000: train_loss=0.0152  test_loss=4.1450  λ_max=90.6900\n",
      "[SGD | lr=0.05] Epoch 3056/4000: train_loss=0.0152  test_loss=4.1455  λ_max=88.3322\n",
      "[SGD | lr=0.05] Iter 48900: loss=0.0151\n",
      "[SGD | lr=0.05] Epoch 3057/4000: train_loss=0.0152  test_loss=4.1456  λ_max=88.0544\n",
      "[SGD | lr=0.05] Epoch 3058/4000: train_loss=0.0152  test_loss=4.1459  λ_max=88.8510\n",
      "[SGD | lr=0.05] Epoch 3059/4000: train_loss=0.0152  test_loss=4.1461  λ_max=88.2881\n",
      "[SGD | lr=0.05] Epoch 3060/4000: train_loss=0.0152  test_loss=4.1466  λ_max=90.4250\n",
      "[SGD | lr=0.05] Epoch 3061/4000: train_loss=0.0152  test_loss=4.1467  λ_max=89.4062\n",
      "[SGD | lr=0.05] Epoch 3062/4000: train_loss=0.0151  test_loss=4.1472  λ_max=88.7820\n",
      "[SGD | lr=0.05] Iter 49000: loss=0.0149\n",
      "[SGD | lr=0.05] Epoch 3063/4000: train_loss=0.0152  test_loss=4.1474  λ_max=88.4840\n",
      "[SGD | lr=0.05] Epoch 3064/4000: train_loss=0.0151  test_loss=4.1476  λ_max=87.5855\n",
      "[SGD | lr=0.05] Epoch 3065/4000: train_loss=0.0151  test_loss=4.1480  λ_max=88.6254\n",
      "[SGD | lr=0.05] Epoch 3066/4000: train_loss=0.0151  test_loss=4.1484  λ_max=85.6761\n",
      "[SGD | lr=0.05] Epoch 3067/4000: train_loss=0.0151  test_loss=4.1484  λ_max=88.3589\n",
      "[SGD | lr=0.05] Epoch 3068/4000: train_loss=0.0151  test_loss=4.1489  λ_max=85.3789\n",
      "[SGD | lr=0.05] Iter 49100: loss=0.0147\n",
      "[SGD | lr=0.05] Epoch 3069/4000: train_loss=0.0151  test_loss=4.1492  λ_max=87.9954\n",
      "[SGD | lr=0.05] Epoch 3070/4000: train_loss=0.0151  test_loss=4.1494  λ_max=88.7972\n",
      "[SGD | lr=0.05] Epoch 3071/4000: train_loss=0.0151  test_loss=4.1495  λ_max=90.9326\n",
      "[SGD | lr=0.05] Epoch 3072/4000: train_loss=0.0151  test_loss=4.1500  λ_max=87.9415\n",
      "[SGD | lr=0.05] Epoch 3073/4000: train_loss=0.0151  test_loss=4.1501  λ_max=88.5593\n",
      "[SGD | lr=0.05] Epoch 3074/4000: train_loss=0.0151  test_loss=4.1504  λ_max=89.8209\n",
      "[SGD | lr=0.05] Iter 49200: loss=0.0152\n",
      "[SGD | lr=0.05] Epoch 3075/4000: train_loss=0.0151  test_loss=4.1507  λ_max=87.9531\n",
      "[SGD | lr=0.05] Epoch 3076/4000: train_loss=0.0151  test_loss=4.1510  λ_max=88.2296\n",
      "[SGD | lr=0.05] Epoch 3077/4000: train_loss=0.0151  test_loss=4.1514  λ_max=89.8976\n",
      "[SGD | lr=0.05] Epoch 3078/4000: train_loss=0.0150  test_loss=4.1514  λ_max=90.8745\n",
      "[SGD | lr=0.05] Epoch 3079/4000: train_loss=0.0150  test_loss=4.1517  λ_max=91.5546\n",
      "[SGD | lr=0.05] Epoch 3080/4000: train_loss=0.0150  test_loss=4.1521  λ_max=88.0497\n",
      "[SGD | lr=0.05] Epoch 3081/4000: train_loss=0.0150  test_loss=4.1524  λ_max=89.3207\n",
      "[SGD | lr=0.05] Iter 49300: loss=0.0149\n",
      "[SGD | lr=0.05] Epoch 3082/4000: train_loss=0.0150  test_loss=4.1526  λ_max=86.5025\n",
      "[SGD | lr=0.05] Epoch 3083/4000: train_loss=0.0150  test_loss=4.1529  λ_max=88.8027\n",
      "[SGD | lr=0.05] Epoch 3084/4000: train_loss=0.0150  test_loss=4.1532  λ_max=90.1301\n",
      "[SGD | lr=0.05] Epoch 3085/4000: train_loss=0.0150  test_loss=4.1535  λ_max=84.6502\n",
      "[SGD | lr=0.05] Epoch 3086/4000: train_loss=0.0150  test_loss=4.1538  λ_max=87.7029\n",
      "[SGD | lr=0.05] Epoch 3087/4000: train_loss=0.0150  test_loss=4.1539  λ_max=90.0688\n",
      "[SGD | lr=0.05] Iter 49400: loss=0.0151\n",
      "[SGD | lr=0.05] Epoch 3088/4000: train_loss=0.0150  test_loss=4.1545  λ_max=90.1421\n",
      "[SGD | lr=0.05] Epoch 3089/4000: train_loss=0.0150  test_loss=4.1543  λ_max=88.1206\n",
      "[SGD | lr=0.05] Epoch 3090/4000: train_loss=0.0150  test_loss=4.1547  λ_max=87.0445\n",
      "[SGD | lr=0.05] Epoch 3091/4000: train_loss=0.0149  test_loss=4.1550  λ_max=88.5708\n",
      "[SGD | lr=0.05] Epoch 3092/4000: train_loss=0.0149  test_loss=4.1554  λ_max=88.2527\n",
      "[SGD | lr=0.05] Epoch 3093/4000: train_loss=0.0149  test_loss=4.1556  λ_max=89.4281\n",
      "[SGD | lr=0.05] Iter 49500: loss=0.0150\n",
      "[SGD | lr=0.05] Epoch 3094/4000: train_loss=0.0149  test_loss=4.1559  λ_max=87.9096\n",
      "[SGD | lr=0.05] Epoch 3095/4000: train_loss=0.0149  test_loss=4.1562  λ_max=90.0434\n",
      "[SGD | lr=0.05] Epoch 3096/4000: train_loss=0.0149  test_loss=4.1562  λ_max=85.9837\n",
      "[SGD | lr=0.05] Epoch 3097/4000: train_loss=0.0149  test_loss=4.1564  λ_max=86.8053\n",
      "[SGD | lr=0.05] Epoch 3098/4000: train_loss=0.0149  test_loss=4.1570  λ_max=89.0725\n",
      "[SGD | lr=0.05] Epoch 3099/4000: train_loss=0.0149  test_loss=4.1572  λ_max=86.2932\n",
      "[SGD | lr=0.05] Iter 49600: loss=0.0154\n",
      "[SGD | lr=0.05] Epoch 3100/4000: train_loss=0.0149  test_loss=4.1575  λ_max=87.6261\n",
      "[SGD | lr=0.05] Epoch 3101/4000: train_loss=0.0149  test_loss=4.1578  λ_max=88.8877\n",
      "[SGD | lr=0.05] Epoch 3102/4000: train_loss=0.0149  test_loss=4.1583  λ_max=85.4181\n",
      "[SGD | lr=0.05] Epoch 3103/4000: train_loss=0.0149  test_loss=4.1584  λ_max=88.9753\n",
      "[SGD | lr=0.05] Epoch 3104/4000: train_loss=0.0149  test_loss=4.1587  λ_max=90.1462\n",
      "[SGD | lr=0.05] Epoch 3105/4000: train_loss=0.0149  test_loss=4.1589  λ_max=87.0718\n",
      "[SGD | lr=0.05] Epoch 3106/4000: train_loss=0.0148  test_loss=4.1593  λ_max=86.7998\n",
      "[SGD | lr=0.05] Iter 49700: loss=0.0147\n",
      "[SGD | lr=0.05] Epoch 3107/4000: train_loss=0.0148  test_loss=4.1594  λ_max=90.8102\n",
      "[SGD | lr=0.05] Epoch 3108/4000: train_loss=0.0148  test_loss=4.1599  λ_max=85.9789\n",
      "[SGD | lr=0.05] Epoch 3109/4000: train_loss=0.0148  test_loss=4.1601  λ_max=90.5963\n",
      "[SGD | lr=0.05] Epoch 3110/4000: train_loss=0.0148  test_loss=4.1605  λ_max=88.3142\n",
      "[SGD | lr=0.05] Epoch 3111/4000: train_loss=0.0148  test_loss=4.1605  λ_max=90.5520\n",
      "[SGD | lr=0.05] Epoch 3112/4000: train_loss=0.0148  test_loss=4.1610  λ_max=89.6456\n",
      "[SGD | lr=0.05] Iter 49800: loss=0.0148\n",
      "[SGD | lr=0.05] Epoch 3113/4000: train_loss=0.0148  test_loss=4.1610  λ_max=87.2211\n",
      "[SGD | lr=0.05] Epoch 3114/4000: train_loss=0.0148  test_loss=4.1614  λ_max=86.8635\n",
      "[SGD | lr=0.05] Epoch 3115/4000: train_loss=0.0148  test_loss=4.1616  λ_max=88.7844\n",
      "[SGD | lr=0.05] Epoch 3116/4000: train_loss=0.0148  test_loss=4.1620  λ_max=87.0139\n",
      "[SGD | lr=0.05] Epoch 3117/4000: train_loss=0.0148  test_loss=4.1623  λ_max=88.0644\n",
      "[SGD | lr=0.05] Epoch 3118/4000: train_loss=0.0148  test_loss=4.1625  λ_max=89.0283\n",
      "[SGD | lr=0.05] Iter 49900: loss=0.0148\n",
      "[SGD | lr=0.05] Epoch 3119/4000: train_loss=0.0148  test_loss=4.1629  λ_max=90.2449\n",
      "[SGD | lr=0.05] Epoch 3120/4000: train_loss=0.0147  test_loss=4.1632  λ_max=86.2407\n",
      "[SGD | lr=0.05] Epoch 3121/4000: train_loss=0.0147  test_loss=4.1634  λ_max=87.7615\n",
      "[SGD | lr=0.05] Epoch 3122/4000: train_loss=0.0147  test_loss=4.1636  λ_max=86.9553\n",
      "[SGD | lr=0.05] Epoch 3123/4000: train_loss=0.0147  test_loss=4.1640  λ_max=88.8094\n",
      "[SGD | lr=0.05] Epoch 3124/4000: train_loss=0.0147  test_loss=4.1641  λ_max=90.9006\n",
      "[SGD | lr=0.05] Iter 50000: loss=0.0143\n",
      "[SGD | lr=0.05] Epoch 3125/4000: train_loss=0.0147  test_loss=4.1645  λ_max=88.0042\n",
      "[SGD | lr=0.05] Epoch 3126/4000: train_loss=0.0147  test_loss=4.1647  λ_max=90.9875\n",
      "[SGD | lr=0.05] Epoch 3127/4000: train_loss=0.0147  test_loss=4.1648  λ_max=90.1397\n",
      "[SGD | lr=0.05] Epoch 3128/4000: train_loss=0.0147  test_loss=4.1652  λ_max=90.1147\n",
      "[SGD | lr=0.05] Epoch 3129/4000: train_loss=0.0147  test_loss=4.1655  λ_max=89.7669\n",
      "[SGD | lr=0.05] Epoch 3130/4000: train_loss=0.0147  test_loss=4.1657  λ_max=89.4148\n",
      "[SGD | lr=0.05] Epoch 3131/4000: train_loss=0.0147  test_loss=4.1661  λ_max=89.3314\n",
      "[SGD | lr=0.05] Iter 50100: loss=0.0147\n",
      "[SGD | lr=0.05] Epoch 3132/4000: train_loss=0.0147  test_loss=4.1663  λ_max=88.4937\n",
      "[SGD | lr=0.05] Epoch 3133/4000: train_loss=0.0147  test_loss=4.1666  λ_max=89.6124\n",
      "[SGD | lr=0.05] Epoch 3134/4000: train_loss=0.0146  test_loss=4.1668  λ_max=87.6674\n",
      "[SGD | lr=0.05] Epoch 3135/4000: train_loss=0.0146  test_loss=4.1672  λ_max=89.2360\n",
      "[SGD | lr=0.05] Epoch 3136/4000: train_loss=0.0146  test_loss=4.1675  λ_max=89.5854\n",
      "[SGD | lr=0.05] Epoch 3137/4000: train_loss=0.0146  test_loss=4.1677  λ_max=86.6675\n",
      "[SGD | lr=0.05] Iter 50200: loss=0.0148\n",
      "[SGD | lr=0.05] Epoch 3138/4000: train_loss=0.0146  test_loss=4.1678  λ_max=85.6041\n",
      "[SGD | lr=0.05] Epoch 3139/4000: train_loss=0.0146  test_loss=4.1683  λ_max=87.9323\n",
      "[SGD | lr=0.05] Epoch 3140/4000: train_loss=0.0146  test_loss=4.1684  λ_max=88.6658\n",
      "[SGD | lr=0.05] Epoch 3141/4000: train_loss=0.0146  test_loss=4.1687  λ_max=89.2844\n",
      "[SGD | lr=0.05] Epoch 3142/4000: train_loss=0.0146  test_loss=4.1690  λ_max=91.6586\n",
      "[SGD | lr=0.05] Epoch 3143/4000: train_loss=0.0146  test_loss=4.1693  λ_max=88.7359\n",
      "[SGD | lr=0.05] Iter 50300: loss=0.0145\n",
      "[SGD | lr=0.05] Epoch 3144/4000: train_loss=0.0146  test_loss=4.1695  λ_max=91.7322\n",
      "[SGD | lr=0.05] Epoch 3145/4000: train_loss=0.0146  test_loss=4.1697  λ_max=89.5203\n",
      "[SGD | lr=0.05] Epoch 3146/4000: train_loss=0.0146  test_loss=4.1701  λ_max=90.0107\n",
      "[SGD | lr=0.05] Epoch 3147/4000: train_loss=0.0146  test_loss=4.1703  λ_max=90.8293\n",
      "[SGD | lr=0.05] Epoch 3148/4000: train_loss=0.0145  test_loss=4.1706  λ_max=88.3250\n",
      "[SGD | lr=0.05] Epoch 3149/4000: train_loss=0.0145  test_loss=4.1710  λ_max=89.9197\n",
      "[SGD | lr=0.05] Iter 50400: loss=0.0149\n",
      "[SGD | lr=0.05] Epoch 3150/4000: train_loss=0.0145  test_loss=4.1712  λ_max=85.9004\n",
      "[SGD | lr=0.05] Epoch 3151/4000: train_loss=0.0145  test_loss=4.1715  λ_max=91.6063\n",
      "[SGD | lr=0.05] Epoch 3152/4000: train_loss=0.0145  test_loss=4.1717  λ_max=91.6698\n",
      "[SGD | lr=0.05] Epoch 3153/4000: train_loss=0.0145  test_loss=4.1721  λ_max=88.2883\n",
      "[SGD | lr=0.05] Epoch 3154/4000: train_loss=0.0145  test_loss=4.1724  λ_max=90.1655\n",
      "[SGD | lr=0.05] Epoch 3155/4000: train_loss=0.0145  test_loss=4.1723  λ_max=90.4722\n",
      "[SGD | lr=0.05] Epoch 3156/4000: train_loss=0.0145  test_loss=4.1728  λ_max=86.0061\n",
      "[SGD | lr=0.05] Iter 50500: loss=0.0147\n",
      "[SGD | lr=0.05] Epoch 3157/4000: train_loss=0.0145  test_loss=4.1730  λ_max=88.7293\n",
      "[SGD | lr=0.05] Epoch 3158/4000: train_loss=0.0145  test_loss=4.1732  λ_max=89.3623\n",
      "[SGD | lr=0.05] Epoch 3159/4000: train_loss=0.0145  test_loss=4.1735  λ_max=89.4282\n",
      "[SGD | lr=0.05] Epoch 3160/4000: train_loss=0.0145  test_loss=4.1739  λ_max=86.5306\n",
      "[SGD | lr=0.05] Epoch 3161/4000: train_loss=0.0145  test_loss=4.1740  λ_max=90.1937\n",
      "[SGD | lr=0.05] Epoch 3162/4000: train_loss=0.0145  test_loss=4.1743  λ_max=86.9511\n",
      "[SGD | lr=0.05] Iter 50600: loss=0.0146\n",
      "[SGD | lr=0.05] Epoch 3163/4000: train_loss=0.0145  test_loss=4.1746  λ_max=89.9952\n",
      "[SGD | lr=0.05] Epoch 3164/4000: train_loss=0.0144  test_loss=4.1748  λ_max=91.6972\n",
      "[SGD | lr=0.05] Epoch 3165/4000: train_loss=0.0144  test_loss=4.1753  λ_max=89.7744\n",
      "[SGD | lr=0.05] Epoch 3166/4000: train_loss=0.0144  test_loss=4.1754  λ_max=89.5827\n",
      "[SGD | lr=0.05] Epoch 3167/4000: train_loss=0.0144  test_loss=4.1756  λ_max=88.8865\n",
      "[SGD | lr=0.05] Epoch 3168/4000: train_loss=0.0144  test_loss=4.1760  λ_max=88.2711\n",
      "[SGD | lr=0.05] Iter 50700: loss=0.0145\n",
      "[SGD | lr=0.05] Epoch 3169/4000: train_loss=0.0144  test_loss=4.1762  λ_max=87.9306\n",
      "[SGD | lr=0.05] Epoch 3170/4000: train_loss=0.0144  test_loss=4.1765  λ_max=90.9916\n",
      "[SGD | lr=0.05] Epoch 3171/4000: train_loss=0.0144  test_loss=4.1768  λ_max=88.7261\n",
      "[SGD | lr=0.05] Epoch 3172/4000: train_loss=0.0144  test_loss=4.1770  λ_max=88.3266\n",
      "[SGD | lr=0.05] Epoch 3173/4000: train_loss=0.0144  test_loss=4.1774  λ_max=88.5550\n",
      "[SGD | lr=0.05] Epoch 3174/4000: train_loss=0.0144  test_loss=4.1774  λ_max=89.1336\n",
      "[SGD | lr=0.05] Iter 50800: loss=0.0141\n",
      "[SGD | lr=0.05] Epoch 3175/4000: train_loss=0.0144  test_loss=4.1777  λ_max=86.3375\n",
      "[SGD | lr=0.05] Epoch 3176/4000: train_loss=0.0144  test_loss=4.1779  λ_max=89.6341\n",
      "[SGD | lr=0.05] Epoch 3177/4000: train_loss=0.0144  test_loss=4.1784  λ_max=90.0246\n",
      "[SGD | lr=0.05] Epoch 3178/4000: train_loss=0.0144  test_loss=4.1787  λ_max=87.8575\n",
      "[SGD | lr=0.05] Epoch 3179/4000: train_loss=0.0143  test_loss=4.1789  λ_max=91.0141\n",
      "[SGD | lr=0.05] Epoch 3180/4000: train_loss=0.0143  test_loss=4.1793  λ_max=90.5058\n",
      "[SGD | lr=0.05] Epoch 3181/4000: train_loss=0.0143  test_loss=4.1795  λ_max=89.3171\n",
      "[SGD | lr=0.05] Iter 50900: loss=0.0144\n",
      "[SGD | lr=0.05] Epoch 3182/4000: train_loss=0.0143  test_loss=4.1796  λ_max=88.9722\n",
      "[SGD | lr=0.05] Epoch 3183/4000: train_loss=0.0143  test_loss=4.1800  λ_max=86.9398\n",
      "[SGD | lr=0.05] Epoch 3184/4000: train_loss=0.0143  test_loss=4.1804  λ_max=88.9367\n",
      "[SGD | lr=0.05] Epoch 3185/4000: train_loss=0.0143  test_loss=4.1805  λ_max=90.3463\n",
      "[SGD | lr=0.05] Epoch 3186/4000: train_loss=0.0143  test_loss=4.1807  λ_max=90.2262\n",
      "[SGD | lr=0.05] Epoch 3187/4000: train_loss=0.0143  test_loss=4.1809  λ_max=86.4011\n",
      "[SGD | lr=0.05] Iter 51000: loss=0.0144\n",
      "[SGD | lr=0.05] Epoch 3188/4000: train_loss=0.0143  test_loss=4.1814  λ_max=90.3362\n",
      "[SGD | lr=0.05] Epoch 3189/4000: train_loss=0.0143  test_loss=4.1817  λ_max=90.4297\n",
      "[SGD | lr=0.05] Epoch 3190/4000: train_loss=0.0143  test_loss=4.1818  λ_max=88.4205\n",
      "[SGD | lr=0.05] Epoch 3191/4000: train_loss=0.0143  test_loss=4.1822  λ_max=89.1413\n",
      "[SGD | lr=0.05] Epoch 3192/4000: train_loss=0.0143  test_loss=4.1823  λ_max=90.7344\n",
      "[SGD | lr=0.05] Epoch 3193/4000: train_loss=0.0143  test_loss=4.1826  λ_max=90.0185\n",
      "[SGD | lr=0.05] Iter 51100: loss=0.0141\n",
      "[SGD | lr=0.05] Epoch 3194/4000: train_loss=0.0142  test_loss=4.1828  λ_max=89.4623\n",
      "[SGD | lr=0.05] Epoch 3195/4000: train_loss=0.0142  test_loss=4.1832  λ_max=88.0230\n",
      "[SGD | lr=0.05] Epoch 3196/4000: train_loss=0.0142  test_loss=4.1834  λ_max=89.8605\n",
      "[SGD | lr=0.05] Epoch 3197/4000: train_loss=0.0142  test_loss=4.1837  λ_max=91.4840\n",
      "[SGD | lr=0.05] Epoch 3198/4000: train_loss=0.0142  test_loss=4.1842  λ_max=86.5383\n",
      "[SGD | lr=0.05] Epoch 3199/4000: train_loss=0.0142  test_loss=4.1840  λ_max=90.9733\n",
      "[SGD | lr=0.05] Iter 51200: loss=0.0143\n",
      "[SGD | lr=0.05] Epoch 3200/4000: train_loss=0.0142  test_loss=4.1842  λ_max=88.8615\n",
      "[SGD | lr=0.05] Epoch 3201/4000: train_loss=0.0142  test_loss=4.1845  λ_max=90.3966\n",
      "[SGD | lr=0.05] Epoch 3202/4000: train_loss=0.0142  test_loss=4.1850  λ_max=91.2547\n",
      "[SGD | lr=0.05] Epoch 3203/4000: train_loss=0.0142  test_loss=4.1854  λ_max=89.4022\n",
      "[SGD | lr=0.05] Epoch 3204/4000: train_loss=0.0142  test_loss=4.1856  λ_max=86.3849\n",
      "[SGD | lr=0.05] Epoch 3205/4000: train_loss=0.0142  test_loss=4.1860  λ_max=90.7999\n",
      "[SGD | lr=0.05] Epoch 3206/4000: train_loss=0.0142  test_loss=4.1860  λ_max=86.1858\n",
      "[SGD | lr=0.05] Iter 51300: loss=0.0140\n",
      "[SGD | lr=0.05] Epoch 3207/4000: train_loss=0.0142  test_loss=4.1863  λ_max=88.5244\n",
      "[SGD | lr=0.05] Epoch 3208/4000: train_loss=0.0142  test_loss=4.1867  λ_max=89.9675\n",
      "[SGD | lr=0.05] Epoch 3209/4000: train_loss=0.0142  test_loss=4.1867  λ_max=90.7166\n",
      "[SGD | lr=0.05] Epoch 3210/4000: train_loss=0.0141  test_loss=4.1871  λ_max=88.9541\n",
      "[SGD | lr=0.05] Epoch 3211/4000: train_loss=0.0141  test_loss=4.1873  λ_max=85.2083\n",
      "[SGD | lr=0.05] Epoch 3212/4000: train_loss=0.0141  test_loss=4.1877  λ_max=91.5263\n",
      "[SGD | lr=0.05] Iter 51400: loss=0.0143\n",
      "[SGD | lr=0.05] Epoch 3213/4000: train_loss=0.0141  test_loss=4.1878  λ_max=91.1987\n",
      "[SGD | lr=0.05] Epoch 3214/4000: train_loss=0.0141  test_loss=4.1882  λ_max=89.3469\n",
      "[SGD | lr=0.05] Epoch 3215/4000: train_loss=0.0141  test_loss=4.1885  λ_max=90.4890\n",
      "[SGD | lr=0.05] Epoch 3216/4000: train_loss=0.0141  test_loss=4.1888  λ_max=90.3831\n",
      "[SGD | lr=0.05] Epoch 3217/4000: train_loss=0.0141  test_loss=4.1889  λ_max=87.3954\n",
      "[SGD | lr=0.05] Epoch 3218/4000: train_loss=0.0141  test_loss=4.1890  λ_max=90.1457\n",
      "[SGD | lr=0.05] Iter 51500: loss=0.0142\n",
      "[SGD | lr=0.05] Epoch 3219/4000: train_loss=0.0141  test_loss=4.1895  λ_max=89.9823\n",
      "[SGD | lr=0.05] Epoch 3220/4000: train_loss=0.0141  test_loss=4.1898  λ_max=88.4644\n",
      "[SGD | lr=0.05] Epoch 3221/4000: train_loss=0.0141  test_loss=4.1900  λ_max=91.7326\n",
      "[SGD | lr=0.05] Epoch 3222/4000: train_loss=0.0141  test_loss=4.1903  λ_max=89.6817\n",
      "[SGD | lr=0.05] Epoch 3223/4000: train_loss=0.0141  test_loss=4.1905  λ_max=88.3954\n",
      "[SGD | lr=0.05] Epoch 3224/4000: train_loss=0.0141  test_loss=4.1908  λ_max=89.5803\n",
      "[SGD | lr=0.05] Iter 51600: loss=0.0141\n",
      "[SGD | lr=0.05] Epoch 3225/4000: train_loss=0.0141  test_loss=4.1910  λ_max=88.7397\n",
      "[SGD | lr=0.05] Epoch 3226/4000: train_loss=0.0141  test_loss=4.1914  λ_max=89.6589\n",
      "[SGD | lr=0.05] Epoch 3227/4000: train_loss=0.0140  test_loss=4.1916  λ_max=88.8037\n",
      "[SGD | lr=0.05] Epoch 3228/4000: train_loss=0.0140  test_loss=4.1917  λ_max=92.7146\n",
      "[SGD | lr=0.05] Epoch 3229/4000: train_loss=0.0140  test_loss=4.1922  λ_max=90.7121\n",
      "[SGD | lr=0.05] Epoch 3230/4000: train_loss=0.0140  test_loss=4.1923  λ_max=89.9435\n",
      "[SGD | lr=0.05] Epoch 3231/4000: train_loss=0.0140  test_loss=4.1927  λ_max=90.6878\n",
      "[SGD | lr=0.05] Iter 51700: loss=0.0140\n",
      "[SGD | lr=0.05] Epoch 3232/4000: train_loss=0.0140  test_loss=4.1928  λ_max=91.1291\n",
      "[SGD | lr=0.05] Epoch 3233/4000: train_loss=0.0140  test_loss=4.1930  λ_max=89.3008\n",
      "[SGD | lr=0.05] Epoch 3234/4000: train_loss=0.0140  test_loss=4.1935  λ_max=89.5932\n",
      "[SGD | lr=0.05] Epoch 3235/4000: train_loss=0.0140  test_loss=4.1936  λ_max=89.2032\n",
      "[SGD | lr=0.05] Epoch 3236/4000: train_loss=0.0140  test_loss=4.1941  λ_max=87.3298\n",
      "[SGD | lr=0.05] Epoch 3237/4000: train_loss=0.0140  test_loss=4.1941  λ_max=91.6804\n",
      "[SGD | lr=0.05] Iter 51800: loss=0.0136\n",
      "[SGD | lr=0.05] Epoch 3238/4000: train_loss=0.0140  test_loss=4.1942  λ_max=88.1851\n",
      "[SGD | lr=0.05] Epoch 3239/4000: train_loss=0.0140  test_loss=4.1947  λ_max=90.2869\n",
      "[SGD | lr=0.05] Epoch 3240/4000: train_loss=0.0140  test_loss=4.1950  λ_max=91.9206\n",
      "[SGD | lr=0.05] Epoch 3241/4000: train_loss=0.0140  test_loss=4.1953  λ_max=89.1469\n",
      "[SGD | lr=0.05] Epoch 3242/4000: train_loss=0.0139  test_loss=4.1954  λ_max=90.5626\n",
      "[SGD | lr=0.05] Epoch 3243/4000: train_loss=0.0139  test_loss=4.1958  λ_max=87.8300\n",
      "[SGD | lr=0.05] Iter 51900: loss=0.0141\n",
      "[SGD | lr=0.05] Epoch 3244/4000: train_loss=0.0139  test_loss=4.1962  λ_max=91.3870\n",
      "[SGD | lr=0.05] Epoch 3245/4000: train_loss=0.0139  test_loss=4.1963  λ_max=89.8032\n",
      "[SGD | lr=0.05] Epoch 3246/4000: train_loss=0.0139  test_loss=4.1966  λ_max=91.0570\n",
      "[SGD | lr=0.05] Epoch 3247/4000: train_loss=0.0139  test_loss=4.1967  λ_max=90.3173\n",
      "[SGD | lr=0.05] Epoch 3248/4000: train_loss=0.0139  test_loss=4.1971  λ_max=89.6715\n",
      "[SGD | lr=0.05] Epoch 3249/4000: train_loss=0.0139  test_loss=4.1973  λ_max=92.5534\n",
      "[SGD | lr=0.05] Iter 52000: loss=0.0140\n",
      "[SGD | lr=0.05] Epoch 3250/4000: train_loss=0.0139  test_loss=4.1975  λ_max=89.3935\n",
      "[SGD | lr=0.05] Epoch 3251/4000: train_loss=0.0139  test_loss=4.1978  λ_max=88.8093\n",
      "[SGD | lr=0.05] Epoch 3252/4000: train_loss=0.0139  test_loss=4.1980  λ_max=86.7559\n",
      "[SGD | lr=0.05] Epoch 3253/4000: train_loss=0.0139  test_loss=4.1983  λ_max=88.8526\n",
      "[SGD | lr=0.05] Epoch 3254/4000: train_loss=0.0139  test_loss=4.1986  λ_max=91.5330\n",
      "[SGD | lr=0.05] Epoch 3255/4000: train_loss=0.0139  test_loss=4.1988  λ_max=91.6457\n",
      "[SGD | lr=0.05] Epoch 3256/4000: train_loss=0.0139  test_loss=4.1990  λ_max=88.3163\n",
      "[SGD | lr=0.05] Iter 52100: loss=0.0137\n",
      "[SGD | lr=0.05] Epoch 3257/4000: train_loss=0.0138  test_loss=4.1994  λ_max=90.1337\n",
      "[SGD | lr=0.05] Epoch 3258/4000: train_loss=0.0139  test_loss=4.1997  λ_max=85.2579\n",
      "[SGD | lr=0.05] Epoch 3259/4000: train_loss=0.0138  test_loss=4.2000  λ_max=89.4945\n",
      "[SGD | lr=0.05] Epoch 3260/4000: train_loss=0.0138  test_loss=4.2002  λ_max=91.5245\n",
      "[SGD | lr=0.05] Epoch 3261/4000: train_loss=0.0138  test_loss=4.2005  λ_max=89.3717\n",
      "[SGD | lr=0.05] Epoch 3262/4000: train_loss=0.0138  test_loss=4.2007  λ_max=90.1999\n",
      "[SGD | lr=0.05] Iter 52200: loss=0.0138\n",
      "[SGD | lr=0.05] Epoch 3263/4000: train_loss=0.0138  test_loss=4.2010  λ_max=90.3275\n",
      "[SGD | lr=0.05] Epoch 3264/4000: train_loss=0.0138  test_loss=4.2012  λ_max=90.2773\n",
      "[SGD | lr=0.05] Epoch 3265/4000: train_loss=0.0138  test_loss=4.2014  λ_max=90.0012\n",
      "[SGD | lr=0.05] Epoch 3266/4000: train_loss=0.0138  test_loss=4.2015  λ_max=91.9555\n",
      "[SGD | lr=0.05] Epoch 3267/4000: train_loss=0.0138  test_loss=4.2019  λ_max=90.8897\n",
      "[SGD | lr=0.05] Epoch 3268/4000: train_loss=0.0138  test_loss=4.2022  λ_max=90.1707\n",
      "[SGD | lr=0.05] Iter 52300: loss=0.0140\n",
      "[SGD | lr=0.05] Epoch 3269/4000: train_loss=0.0138  test_loss=4.2024  λ_max=89.6509\n",
      "[SGD | lr=0.05] Epoch 3270/4000: train_loss=0.0138  test_loss=4.2029  λ_max=92.1240\n",
      "[SGD | lr=0.05] Epoch 3271/4000: train_loss=0.0138  test_loss=4.2028  λ_max=90.2739\n",
      "[SGD | lr=0.05] Epoch 3272/4000: train_loss=0.0138  test_loss=4.2032  λ_max=88.4730\n",
      "[SGD | lr=0.05] Epoch 3273/4000: train_loss=0.0138  test_loss=4.2035  λ_max=87.6136\n",
      "[SGD | lr=0.05] Epoch 3274/4000: train_loss=0.0137  test_loss=4.2039  λ_max=88.7378\n",
      "[SGD | lr=0.05] Iter 52400: loss=0.0136\n",
      "[SGD | lr=0.05] Epoch 3275/4000: train_loss=0.0137  test_loss=4.2040  λ_max=88.1030\n",
      "[SGD | lr=0.05] Epoch 3276/4000: train_loss=0.0137  test_loss=4.2042  λ_max=89.0456\n",
      "[SGD | lr=0.05] Epoch 3277/4000: train_loss=0.0137  test_loss=4.2045  λ_max=90.0847\n",
      "[SGD | lr=0.05] Epoch 3278/4000: train_loss=0.0137  test_loss=4.2048  λ_max=90.3770\n",
      "[SGD | lr=0.05] Epoch 3279/4000: train_loss=0.0137  test_loss=4.2051  λ_max=89.6545\n",
      "[SGD | lr=0.05] Epoch 3280/4000: train_loss=0.0137  test_loss=4.2054  λ_max=91.4386\n",
      "[SGD | lr=0.05] Epoch 3281/4000: train_loss=0.0137  test_loss=4.2057  λ_max=91.1035\n",
      "[SGD | lr=0.05] Iter 52500: loss=0.0139\n",
      "[SGD | lr=0.05] Epoch 3282/4000: train_loss=0.0137  test_loss=4.2060  λ_max=91.7151\n",
      "[SGD | lr=0.05] Epoch 3283/4000: train_loss=0.0137  test_loss=4.2062  λ_max=89.4504\n",
      "[SGD | lr=0.05] Epoch 3284/4000: train_loss=0.0137  test_loss=4.2063  λ_max=90.0786\n",
      "[SGD | lr=0.05] Epoch 3285/4000: train_loss=0.0137  test_loss=4.2067  λ_max=89.4309\n",
      "[SGD | lr=0.05] Epoch 3286/4000: train_loss=0.0137  test_loss=4.2069  λ_max=89.7768\n",
      "[SGD | lr=0.05] Epoch 3287/4000: train_loss=0.0137  test_loss=4.2072  λ_max=91.0390\n",
      "[SGD | lr=0.05] Iter 52600: loss=0.0136\n",
      "[SGD | lr=0.05] Epoch 3288/4000: train_loss=0.0137  test_loss=4.2074  λ_max=88.2221\n",
      "[SGD | lr=0.05] Epoch 3289/4000: train_loss=0.0137  test_loss=4.2078  λ_max=92.7357\n",
      "[SGD | lr=0.05] Epoch 3290/4000: train_loss=0.0136  test_loss=4.2079  λ_max=89.5147\n",
      "[SGD | lr=0.05] Epoch 3291/4000: train_loss=0.0136  test_loss=4.2081  λ_max=89.7274\n",
      "[SGD | lr=0.05] Epoch 3292/4000: train_loss=0.0136  test_loss=4.2085  λ_max=91.0062\n",
      "[SGD | lr=0.05] Epoch 3293/4000: train_loss=0.0136  test_loss=4.2088  λ_max=89.6370\n",
      "[SGD | lr=0.05] Iter 52700: loss=0.0133\n",
      "[SGD | lr=0.05] Epoch 3294/4000: train_loss=0.0136  test_loss=4.2089  λ_max=88.3514\n",
      "[SGD | lr=0.05] Epoch 3295/4000: train_loss=0.0136  test_loss=4.2093  λ_max=92.7075\n",
      "[SGD | lr=0.05] Epoch 3296/4000: train_loss=0.0136  test_loss=4.2095  λ_max=90.0961\n",
      "[SGD | lr=0.05] Epoch 3297/4000: train_loss=0.0136  test_loss=4.2096  λ_max=91.4524\n",
      "[SGD | lr=0.05] Epoch 3298/4000: train_loss=0.0136  test_loss=4.2101  λ_max=92.0258\n",
      "[SGD | lr=0.05] Epoch 3299/4000: train_loss=0.0136  test_loss=4.2103  λ_max=89.5653\n",
      "[SGD | lr=0.05] Iter 52800: loss=0.0130\n",
      "[SGD | lr=0.05] Epoch 3300/4000: train_loss=0.0136  test_loss=4.2104  λ_max=90.1387\n",
      "[SGD | lr=0.05] Epoch 3301/4000: train_loss=0.0136  test_loss=4.2108  λ_max=89.1279\n",
      "[SGD | lr=0.05] Epoch 3302/4000: train_loss=0.0136  test_loss=4.2106  λ_max=92.4638\n",
      "[SGD | lr=0.05] Epoch 3303/4000: train_loss=0.0136  test_loss=4.2111  λ_max=90.5226\n",
      "[SGD | lr=0.05] Epoch 3304/4000: train_loss=0.0136  test_loss=4.2115  λ_max=88.1814\n",
      "[SGD | lr=0.05] Epoch 3305/4000: train_loss=0.0136  test_loss=4.2118  λ_max=88.5724\n",
      "[SGD | lr=0.05] Epoch 3306/4000: train_loss=0.0136  test_loss=4.2120  λ_max=88.0355\n",
      "[SGD | lr=0.05] Iter 52900: loss=0.0134\n",
      "[SGD | lr=0.05] Epoch 3307/4000: train_loss=0.0136  test_loss=4.2120  λ_max=89.0731\n",
      "[SGD | lr=0.05] Epoch 3308/4000: train_loss=0.0135  test_loss=4.2124  λ_max=93.0548\n",
      "[SGD | lr=0.05] Epoch 3309/4000: train_loss=0.0135  test_loss=4.2126  λ_max=90.4055\n",
      "[SGD | lr=0.05] Epoch 3310/4000: train_loss=0.0135  test_loss=4.2131  λ_max=91.2283\n",
      "[SGD | lr=0.05] Epoch 3311/4000: train_loss=0.0135  test_loss=4.2134  λ_max=91.1656\n",
      "[SGD | lr=0.05] Epoch 3312/4000: train_loss=0.0135  test_loss=4.2136  λ_max=91.3380\n",
      "[SGD | lr=0.05] Iter 53000: loss=0.0137\n",
      "[SGD | lr=0.05] Epoch 3313/4000: train_loss=0.0135  test_loss=4.2138  λ_max=91.9835\n",
      "[SGD | lr=0.05] Epoch 3314/4000: train_loss=0.0135  test_loss=4.2141  λ_max=90.9760\n",
      "[SGD | lr=0.05] Epoch 3315/4000: train_loss=0.0135  test_loss=4.2142  λ_max=90.4892\n",
      "[SGD | lr=0.05] Epoch 3316/4000: train_loss=0.0135  test_loss=4.2144  λ_max=87.8861\n",
      "[SGD | lr=0.05] Epoch 3317/4000: train_loss=0.0135  test_loss=4.2147  λ_max=90.4716\n",
      "[SGD | lr=0.05] Epoch 3318/4000: train_loss=0.0135  test_loss=4.2150  λ_max=92.8530\n",
      "[SGD | lr=0.05] Iter 53100: loss=0.0136\n",
      "[SGD | lr=0.05] Epoch 3319/4000: train_loss=0.0135  test_loss=4.2152  λ_max=89.8902\n",
      "[SGD | lr=0.05] Epoch 3320/4000: train_loss=0.0135  test_loss=4.2156  λ_max=88.1564\n",
      "[SGD | lr=0.05] Epoch 3321/4000: train_loss=0.0135  test_loss=4.2158  λ_max=92.0908\n",
      "[SGD | lr=0.05] Epoch 3322/4000: train_loss=0.0135  test_loss=4.2160  λ_max=90.8318\n",
      "[SGD | lr=0.05] Epoch 3323/4000: train_loss=0.0135  test_loss=4.2164  λ_max=86.7207\n",
      "[SGD | lr=0.05] Epoch 3324/4000: train_loss=0.0134  test_loss=4.2165  λ_max=91.8294\n",
      "[SGD | lr=0.05] Iter 53200: loss=0.0137\n",
      "[SGD | lr=0.05] Epoch 3325/4000: train_loss=0.0135  test_loss=4.2167  λ_max=89.6487\n",
      "[SGD | lr=0.05] Epoch 3326/4000: train_loss=0.0134  test_loss=4.2170  λ_max=90.2106\n",
      "[SGD | lr=0.05] Epoch 3327/4000: train_loss=0.0134  test_loss=4.2175  λ_max=87.2302\n",
      "[SGD | lr=0.05] Epoch 3328/4000: train_loss=0.0134  test_loss=4.2177  λ_max=90.1265\n",
      "[SGD | lr=0.05] Epoch 3329/4000: train_loss=0.0134  test_loss=4.2178  λ_max=89.6423\n",
      "[SGD | lr=0.05] Epoch 3330/4000: train_loss=0.0134  test_loss=4.2182  λ_max=88.8742\n",
      "[SGD | lr=0.05] Epoch 3331/4000: train_loss=0.0134  test_loss=4.2183  λ_max=89.6620\n",
      "[SGD | lr=0.05] Iter 53300: loss=0.0135\n",
      "[SGD | lr=0.05] Epoch 3332/4000: train_loss=0.0134  test_loss=4.2186  λ_max=88.8200\n",
      "[SGD | lr=0.05] Epoch 3333/4000: train_loss=0.0134  test_loss=4.2189  λ_max=90.4825\n",
      "[SGD | lr=0.05] Epoch 3334/4000: train_loss=0.0134  test_loss=4.2190  λ_max=90.6753\n",
      "[SGD | lr=0.05] Epoch 3335/4000: train_loss=0.0134  test_loss=4.2192  λ_max=89.2414\n",
      "[SGD | lr=0.05] Epoch 3336/4000: train_loss=0.0134  test_loss=4.2195  λ_max=89.9560\n",
      "[SGD | lr=0.05] Epoch 3337/4000: train_loss=0.0134  test_loss=4.2199  λ_max=91.3007\n",
      "[SGD | lr=0.05] Iter 53400: loss=0.0133\n",
      "[SGD | lr=0.05] Epoch 3338/4000: train_loss=0.0134  test_loss=4.2200  λ_max=89.9064\n",
      "[SGD | lr=0.05] Epoch 3339/4000: train_loss=0.0134  test_loss=4.2204  λ_max=93.2020\n",
      "[SGD | lr=0.05] Epoch 3340/4000: train_loss=0.0134  test_loss=4.2207  λ_max=93.0068\n",
      "[SGD | lr=0.05] Epoch 3341/4000: train_loss=0.0134  test_loss=4.2208  λ_max=90.6970\n",
      "[SGD | lr=0.05] Epoch 3342/4000: train_loss=0.0133  test_loss=4.2211  λ_max=90.3128\n",
      "[SGD | lr=0.05] Epoch 3343/4000: train_loss=0.0133  test_loss=4.2213  λ_max=89.6076\n",
      "[SGD | lr=0.05] Iter 53500: loss=0.0133\n",
      "[SGD | lr=0.05] Epoch 3344/4000: train_loss=0.0133  test_loss=4.2218  λ_max=92.1675\n",
      "[SGD | lr=0.05] Epoch 3345/4000: train_loss=0.0133  test_loss=4.2218  λ_max=90.9914\n",
      "[SGD | lr=0.05] Epoch 3346/4000: train_loss=0.0133  test_loss=4.2222  λ_max=91.0231\n",
      "[SGD | lr=0.05] Epoch 3347/4000: train_loss=0.0133  test_loss=4.2225  λ_max=91.2531\n",
      "[SGD | lr=0.05] Epoch 3348/4000: train_loss=0.0133  test_loss=4.2227  λ_max=88.9565\n",
      "[SGD | lr=0.05] Epoch 3349/4000: train_loss=0.0133  test_loss=4.2228  λ_max=92.5972\n",
      "[SGD | lr=0.05] Iter 53600: loss=0.0134\n",
      "[SGD | lr=0.05] Epoch 3350/4000: train_loss=0.0133  test_loss=4.2231  λ_max=89.1127\n",
      "[SGD | lr=0.05] Epoch 3351/4000: train_loss=0.0133  test_loss=4.2234  λ_max=91.1603\n",
      "[SGD | lr=0.05] Epoch 3352/4000: train_loss=0.0133  test_loss=4.2236  λ_max=89.2882\n",
      "[SGD | lr=0.05] Epoch 3353/4000: train_loss=0.0133  test_loss=4.2241  λ_max=87.5724\n",
      "[SGD | lr=0.05] Epoch 3354/4000: train_loss=0.0133  test_loss=4.2241  λ_max=90.2252\n",
      "[SGD | lr=0.05] Epoch 3355/4000: train_loss=0.0133  test_loss=4.2245  λ_max=89.3274\n",
      "[SGD | lr=0.05] Epoch 3356/4000: train_loss=0.0133  test_loss=4.2247  λ_max=90.7444\n",
      "[SGD | lr=0.05] Iter 53700: loss=0.0132\n",
      "[SGD | lr=0.05] Epoch 3357/4000: train_loss=0.0133  test_loss=4.2250  λ_max=91.4463\n",
      "[SGD | lr=0.05] Epoch 3358/4000: train_loss=0.0133  test_loss=4.2249  λ_max=89.7819\n",
      "[SGD | lr=0.05] Epoch 3359/4000: train_loss=0.0133  test_loss=4.2253  λ_max=90.6977\n",
      "[SGD | lr=0.05] Epoch 3360/4000: train_loss=0.0132  test_loss=4.2256  λ_max=92.8389\n",
      "[SGD | lr=0.05] Epoch 3361/4000: train_loss=0.0132  test_loss=4.2259  λ_max=90.9603\n",
      "[SGD | lr=0.05] Epoch 3362/4000: train_loss=0.0132  test_loss=4.2261  λ_max=89.3243\n",
      "[SGD | lr=0.05] Iter 53800: loss=0.0133\n",
      "[SGD | lr=0.05] Epoch 3363/4000: train_loss=0.0132  test_loss=4.2265  λ_max=93.0144\n",
      "[SGD | lr=0.05] Epoch 3364/4000: train_loss=0.0132  test_loss=4.2268  λ_max=88.9653\n",
      "[SGD | lr=0.05] Epoch 3365/4000: train_loss=0.0132  test_loss=4.2270  λ_max=88.7687\n",
      "[SGD | lr=0.05] Epoch 3366/4000: train_loss=0.0132  test_loss=4.2271  λ_max=89.7369\n",
      "[SGD | lr=0.05] Epoch 3367/4000: train_loss=0.0132  test_loss=4.2272  λ_max=92.2181\n",
      "[SGD | lr=0.05] Epoch 3368/4000: train_loss=0.0132  test_loss=4.2278  λ_max=92.6489\n",
      "[SGD | lr=0.05] Iter 53900: loss=0.0135\n",
      "[SGD | lr=0.05] Epoch 3369/4000: train_loss=0.0132  test_loss=4.2278  λ_max=90.1204\n",
      "[SGD | lr=0.05] Epoch 3370/4000: train_loss=0.0132  test_loss=4.2282  λ_max=89.5583\n",
      "[SGD | lr=0.05] Epoch 3371/4000: train_loss=0.0132  test_loss=4.2282  λ_max=90.8920\n",
      "[SGD | lr=0.05] Epoch 3372/4000: train_loss=0.0132  test_loss=4.2286  λ_max=89.3901\n",
      "[SGD | lr=0.05] Epoch 3373/4000: train_loss=0.0132  test_loss=4.2288  λ_max=87.7795\n",
      "[SGD | lr=0.05] Epoch 3374/4000: train_loss=0.0132  test_loss=4.2292  λ_max=89.1813\n",
      "[SGD | lr=0.05] Iter 54000: loss=0.0131\n",
      "[SGD | lr=0.05] Epoch 3375/4000: train_loss=0.0132  test_loss=4.2294  λ_max=91.1374\n",
      "[SGD | lr=0.05] Epoch 3376/4000: train_loss=0.0131  test_loss=4.2296  λ_max=90.4932\n",
      "[SGD | lr=0.05] Epoch 3377/4000: train_loss=0.0131  test_loss=4.2298  λ_max=90.4242\n",
      "[SGD | lr=0.05] Epoch 3378/4000: train_loss=0.0132  test_loss=4.2300  λ_max=92.2221\n",
      "[SGD | lr=0.05] Epoch 3379/4000: train_loss=0.0131  test_loss=4.2304  λ_max=89.0377\n",
      "[SGD | lr=0.05] Epoch 3380/4000: train_loss=0.0131  test_loss=4.2306  λ_max=90.3665\n",
      "[SGD | lr=0.05] Epoch 3381/4000: train_loss=0.0131  test_loss=4.2309  λ_max=92.4443\n",
      "[SGD | lr=0.05] Iter 54100: loss=0.0130\n",
      "[SGD | lr=0.05] Epoch 3382/4000: train_loss=0.0131  test_loss=4.2312  λ_max=87.6415\n",
      "[SGD | lr=0.05] Epoch 3383/4000: train_loss=0.0131  test_loss=4.2315  λ_max=91.9496\n",
      "[SGD | lr=0.05] Epoch 3384/4000: train_loss=0.0131  test_loss=4.2318  λ_max=93.1500\n",
      "[SGD | lr=0.05] Epoch 3385/4000: train_loss=0.0131  test_loss=4.2319  λ_max=90.6004\n",
      "[SGD | lr=0.05] Epoch 3386/4000: train_loss=0.0131  test_loss=4.2322  λ_max=91.1832\n",
      "[SGD | lr=0.05] Epoch 3387/4000: train_loss=0.0131  test_loss=4.2323  λ_max=90.3219\n",
      "[SGD | lr=0.05] Iter 54200: loss=0.0132\n",
      "[SGD | lr=0.05] Epoch 3388/4000: train_loss=0.0131  test_loss=4.2327  λ_max=91.0501\n",
      "[SGD | lr=0.05] Epoch 3389/4000: train_loss=0.0131  test_loss=4.2329  λ_max=93.0640\n",
      "[SGD | lr=0.05] Epoch 3390/4000: train_loss=0.0131  test_loss=4.2330  λ_max=90.2199\n",
      "[SGD | lr=0.05] Epoch 3391/4000: train_loss=0.0131  test_loss=4.2335  λ_max=91.3090\n",
      "[SGD | lr=0.05] Epoch 3392/4000: train_loss=0.0131  test_loss=4.2336  λ_max=90.1408\n",
      "[SGD | lr=0.05] Epoch 3393/4000: train_loss=0.0131  test_loss=4.2339  λ_max=91.3672\n",
      "[SGD | lr=0.05] Iter 54300: loss=0.0133\n",
      "[SGD | lr=0.05] Epoch 3394/4000: train_loss=0.0130  test_loss=4.2340  λ_max=88.0687\n",
      "[SGD | lr=0.05] Epoch 3395/4000: train_loss=0.0130  test_loss=4.2341  λ_max=89.1424\n",
      "[SGD | lr=0.05] Epoch 3396/4000: train_loss=0.0130  test_loss=4.2346  λ_max=91.5862\n",
      "[SGD | lr=0.05] Epoch 3397/4000: train_loss=0.0130  test_loss=4.2346  λ_max=87.7840\n",
      "[SGD | lr=0.05] Epoch 3398/4000: train_loss=0.0130  test_loss=4.2351  λ_max=92.2037\n",
      "[SGD | lr=0.05] Epoch 3399/4000: train_loss=0.0130  test_loss=4.2352  λ_max=92.2155\n",
      "[SGD | lr=0.05] Iter 54400: loss=0.0126\n",
      "[SGD | lr=0.05] Epoch 3400/4000: train_loss=0.0130  test_loss=4.2355  λ_max=91.0236\n",
      "[SGD | lr=0.05] Epoch 3401/4000: train_loss=0.0130  test_loss=4.2357  λ_max=90.8255\n",
      "[SGD | lr=0.05] Epoch 3402/4000: train_loss=0.0130  test_loss=4.2360  λ_max=90.8673\n",
      "[SGD | lr=0.05] Epoch 3403/4000: train_loss=0.0130  test_loss=4.2363  λ_max=91.5112\n",
      "[SGD | lr=0.05] Epoch 3404/4000: train_loss=0.0130  test_loss=4.2365  λ_max=92.6767\n",
      "[SGD | lr=0.05] Epoch 3405/4000: train_loss=0.0130  test_loss=4.2367  λ_max=93.8965\n",
      "[SGD | lr=0.05] Epoch 3406/4000: train_loss=0.0130  test_loss=4.2370  λ_max=89.7544\n",
      "[SGD | lr=0.05] Iter 54500: loss=0.0128\n",
      "[SGD | lr=0.05] Epoch 3407/4000: train_loss=0.0130  test_loss=4.2373  λ_max=89.9160\n",
      "[SGD | lr=0.05] Epoch 3408/4000: train_loss=0.0130  test_loss=4.2375  λ_max=92.1298\n",
      "[SGD | lr=0.05] Epoch 3409/4000: train_loss=0.0130  test_loss=4.2378  λ_max=92.2049\n",
      "[SGD | lr=0.05] Epoch 3410/4000: train_loss=0.0130  test_loss=4.2381  λ_max=92.6267\n",
      "[SGD | lr=0.05] Epoch 3411/4000: train_loss=0.0130  test_loss=4.2383  λ_max=90.5636\n",
      "[SGD | lr=0.05] Epoch 3412/4000: train_loss=0.0129  test_loss=4.2386  λ_max=91.2444\n",
      "[SGD | lr=0.05] Iter 54600: loss=0.0129\n",
      "[SGD | lr=0.05] Epoch 3413/4000: train_loss=0.0130  test_loss=4.2385  λ_max=93.2241\n",
      "[SGD | lr=0.05] Epoch 3414/4000: train_loss=0.0129  test_loss=4.2390  λ_max=89.9677\n",
      "[SGD | lr=0.05] Epoch 3415/4000: train_loss=0.0129  test_loss=4.2393  λ_max=91.2769\n",
      "[SGD | lr=0.05] Epoch 3416/4000: train_loss=0.0129  test_loss=4.2393  λ_max=93.1103\n",
      "[SGD | lr=0.05] Epoch 3417/4000: train_loss=0.0129  test_loss=4.2398  λ_max=88.1186\n",
      "[SGD | lr=0.05] Epoch 3418/4000: train_loss=0.0129  test_loss=4.2400  λ_max=89.8234\n",
      "[SGD | lr=0.05] Iter 54700: loss=0.0132\n",
      "[SGD | lr=0.05] Epoch 3419/4000: train_loss=0.0129  test_loss=4.2403  λ_max=91.7952\n",
      "[SGD | lr=0.05] Epoch 3420/4000: train_loss=0.0129  test_loss=4.2406  λ_max=90.3942\n",
      "[SGD | lr=0.05] Epoch 3421/4000: train_loss=0.0129  test_loss=4.2408  λ_max=91.8815\n",
      "[SGD | lr=0.05] Epoch 3422/4000: train_loss=0.0129  test_loss=4.2410  λ_max=91.2807\n",
      "[SGD | lr=0.05] Epoch 3423/4000: train_loss=0.0129  test_loss=4.2412  λ_max=90.6345\n",
      "[SGD | lr=0.05] Epoch 3424/4000: train_loss=0.0129  test_loss=4.2412  λ_max=92.3494\n",
      "[SGD | lr=0.05] Iter 54800: loss=0.0128\n",
      "[SGD | lr=0.05] Epoch 3425/4000: train_loss=0.0129  test_loss=4.2415  λ_max=88.1430\n",
      "[SGD | lr=0.05] Epoch 3426/4000: train_loss=0.0129  test_loss=4.2421  λ_max=91.7106\n",
      "[SGD | lr=0.05] Epoch 3427/4000: train_loss=0.0129  test_loss=4.2421  λ_max=93.8327\n",
      "[SGD | lr=0.05] Epoch 3428/4000: train_loss=0.0129  test_loss=4.2424  λ_max=92.5010\n",
      "[SGD | lr=0.05] Epoch 3429/4000: train_loss=0.0129  test_loss=4.2426  λ_max=91.7163\n",
      "[SGD | lr=0.05] Epoch 3430/4000: train_loss=0.0129  test_loss=4.2428  λ_max=94.0417\n",
      "[SGD | lr=0.05] Epoch 3431/4000: train_loss=0.0129  test_loss=4.2432  λ_max=91.2402\n",
      "[SGD | lr=0.05] Iter 54900: loss=0.0128\n",
      "[SGD | lr=0.05] Epoch 3432/4000: train_loss=0.0129  test_loss=4.2433  λ_max=90.7060\n",
      "[SGD | lr=0.05] Epoch 3433/4000: train_loss=0.0128  test_loss=4.2437  λ_max=89.6868\n",
      "[SGD | lr=0.05] Epoch 3434/4000: train_loss=0.0128  test_loss=4.2438  λ_max=91.4572\n",
      "[SGD | lr=0.05] Epoch 3435/4000: train_loss=0.0128  test_loss=4.2441  λ_max=90.4323\n",
      "[SGD | lr=0.05] Epoch 3436/4000: train_loss=0.0128  test_loss=4.2443  λ_max=94.0644\n",
      "[SGD | lr=0.05] Epoch 3437/4000: train_loss=0.0128  test_loss=4.2446  λ_max=93.0216\n",
      "[SGD | lr=0.05] Iter 55000: loss=0.0129\n",
      "[SGD | lr=0.05] Epoch 3438/4000: train_loss=0.0128  test_loss=4.2449  λ_max=90.7117\n",
      "[SGD | lr=0.05] Epoch 3439/4000: train_loss=0.0128  test_loss=4.2451  λ_max=94.0354\n",
      "[SGD | lr=0.05] Epoch 3440/4000: train_loss=0.0128  test_loss=4.2452  λ_max=89.6018\n",
      "[SGD | lr=0.05] Epoch 3441/4000: train_loss=0.0128  test_loss=4.2456  λ_max=91.5743\n",
      "[SGD | lr=0.05] Epoch 3442/4000: train_loss=0.0128  test_loss=4.2458  λ_max=90.4804\n",
      "[SGD | lr=0.05] Epoch 3443/4000: train_loss=0.0128  test_loss=4.2462  λ_max=91.4962\n",
      "[SGD | lr=0.05] Iter 55100: loss=0.0130\n",
      "[SGD | lr=0.05] Epoch 3444/4000: train_loss=0.0128  test_loss=4.2463  λ_max=90.7192\n",
      "[SGD | lr=0.05] Epoch 3445/4000: train_loss=0.0128  test_loss=4.2465  λ_max=88.7253\n",
      "[SGD | lr=0.05] Epoch 3446/4000: train_loss=0.0128  test_loss=4.2465  λ_max=93.5492\n",
      "[SGD | lr=0.05] Epoch 3447/4000: train_loss=0.0128  test_loss=4.2469  λ_max=93.0498\n",
      "[SGD | lr=0.05] Epoch 3448/4000: train_loss=0.0128  test_loss=4.2474  λ_max=88.7124\n",
      "[SGD | lr=0.05] Epoch 3449/4000: train_loss=0.0128  test_loss=4.2476  λ_max=88.7555\n",
      "[SGD | lr=0.05] Iter 55200: loss=0.0127\n",
      "[SGD | lr=0.05] Epoch 3450/4000: train_loss=0.0128  test_loss=4.2476  λ_max=90.9190\n",
      "[SGD | lr=0.05] Epoch 3451/4000: train_loss=0.0127  test_loss=4.2480  λ_max=92.1383\n",
      "[SGD | lr=0.05] Epoch 3452/4000: train_loss=0.0127  test_loss=4.2481  λ_max=89.9703\n",
      "[SGD | lr=0.05] Epoch 3453/4000: train_loss=0.0127  test_loss=4.2485  λ_max=90.0924\n",
      "[SGD | lr=0.05] Epoch 3454/4000: train_loss=0.0127  test_loss=4.2488  λ_max=92.5316\n",
      "[SGD | lr=0.05] Epoch 3455/4000: train_loss=0.0127  test_loss=4.2490  λ_max=91.2787\n",
      "[SGD | lr=0.05] Epoch 3456/4000: train_loss=0.0127  test_loss=4.2491  λ_max=89.3021\n",
      "[SGD | lr=0.05] Iter 55300: loss=0.0125\n",
      "[SGD | lr=0.05] Epoch 3457/4000: train_loss=0.0127  test_loss=4.2493  λ_max=91.9584\n",
      "[SGD | lr=0.05] Epoch 3458/4000: train_loss=0.0127  test_loss=4.2496  λ_max=92.4042\n",
      "[SGD | lr=0.05] Epoch 3459/4000: train_loss=0.0127  test_loss=4.2499  λ_max=90.6481\n",
      "[SGD | lr=0.05] Epoch 3460/4000: train_loss=0.0127  test_loss=4.2499  λ_max=89.6689\n",
      "[SGD | lr=0.05] Epoch 3461/4000: train_loss=0.0127  test_loss=4.2505  λ_max=91.5014\n",
      "[SGD | lr=0.05] Epoch 3462/4000: train_loss=0.0127  test_loss=4.2507  λ_max=89.1050\n",
      "[SGD | lr=0.05] Iter 55400: loss=0.0129\n",
      "[SGD | lr=0.05] Epoch 3463/4000: train_loss=0.0127  test_loss=4.2508  λ_max=92.3017\n",
      "[SGD | lr=0.05] Epoch 3464/4000: train_loss=0.0127  test_loss=4.2511  λ_max=90.0098\n",
      "[SGD | lr=0.05] Epoch 3465/4000: train_loss=0.0127  test_loss=4.2513  λ_max=94.1242\n",
      "[SGD | lr=0.05] Epoch 3466/4000: train_loss=0.0127  test_loss=4.2516  λ_max=88.2522\n",
      "[SGD | lr=0.05] Epoch 3467/4000: train_loss=0.0127  test_loss=4.2518  λ_max=91.5539\n",
      "[SGD | lr=0.05] Epoch 3468/4000: train_loss=0.0127  test_loss=4.2520  λ_max=86.6285\n",
      "[SGD | lr=0.05] Iter 55500: loss=0.0126\n",
      "[SGD | lr=0.05] Epoch 3469/4000: train_loss=0.0126  test_loss=4.2523  λ_max=93.6733\n",
      "[SGD | lr=0.05] Epoch 3470/4000: train_loss=0.0126  test_loss=4.2527  λ_max=92.4442\n",
      "[SGD | lr=0.05] Epoch 3471/4000: train_loss=0.0126  test_loss=4.2528  λ_max=94.2193\n",
      "[SGD | lr=0.05] Epoch 3472/4000: train_loss=0.0126  test_loss=4.2531  λ_max=94.0432\n",
      "[SGD | lr=0.05] Epoch 3473/4000: train_loss=0.0126  test_loss=4.2533  λ_max=90.6479\n",
      "[SGD | lr=0.05] Epoch 3474/4000: train_loss=0.0126  test_loss=4.2536  λ_max=89.6739\n",
      "[SGD | lr=0.05] Iter 55600: loss=0.0125\n",
      "[SGD | lr=0.05] Epoch 3475/4000: train_loss=0.0126  test_loss=4.2539  λ_max=92.0461\n",
      "[SGD | lr=0.05] Epoch 3476/4000: train_loss=0.0126  test_loss=4.2541  λ_max=89.9958\n",
      "[SGD | lr=0.05] Epoch 3477/4000: train_loss=0.0126  test_loss=4.2543  λ_max=91.9986\n",
      "[SGD | lr=0.05] Epoch 3478/4000: train_loss=0.0126  test_loss=4.2547  λ_max=92.6731\n",
      "[SGD | lr=0.05] Epoch 3479/4000: train_loss=0.0126  test_loss=4.2548  λ_max=92.1408\n",
      "[SGD | lr=0.05] Epoch 3480/4000: train_loss=0.0126  test_loss=4.2550  λ_max=92.1557\n",
      "[SGD | lr=0.05] Epoch 3481/4000: train_loss=0.0126  test_loss=4.2552  λ_max=87.1872\n",
      "[SGD | lr=0.05] Iter 55700: loss=0.0126\n",
      "[SGD | lr=0.05] Epoch 3482/4000: train_loss=0.0126  test_loss=4.2553  λ_max=93.7238\n",
      "[SGD | lr=0.05] Epoch 3483/4000: train_loss=0.0126  test_loss=4.2558  λ_max=94.0126\n",
      "[SGD | lr=0.05] Epoch 3484/4000: train_loss=0.0126  test_loss=4.2560  λ_max=92.0631\n",
      "[SGD | lr=0.05] Epoch 3485/4000: train_loss=0.0126  test_loss=4.2562  λ_max=90.6585\n",
      "[SGD | lr=0.05] Epoch 3486/4000: train_loss=0.0126  test_loss=4.2564  λ_max=91.1121\n",
      "[SGD | lr=0.05] Epoch 3487/4000: train_loss=0.0126  test_loss=4.2566  λ_max=91.8057\n",
      "[SGD | lr=0.05] Iter 55800: loss=0.0126\n",
      "[SGD | lr=0.05] Epoch 3488/4000: train_loss=0.0126  test_loss=4.2568  λ_max=93.0130\n",
      "[SGD | lr=0.05] Epoch 3489/4000: train_loss=0.0125  test_loss=4.2571  λ_max=93.3170\n",
      "[SGD | lr=0.05] Epoch 3490/4000: train_loss=0.0125  test_loss=4.2574  λ_max=90.9171\n",
      "[SGD | lr=0.05] Epoch 3491/4000: train_loss=0.0125  test_loss=4.2577  λ_max=90.5784\n",
      "[SGD | lr=0.05] Epoch 3492/4000: train_loss=0.0125  test_loss=4.2579  λ_max=94.6265\n",
      "[SGD | lr=0.05] Epoch 3493/4000: train_loss=0.0125  test_loss=4.2582  λ_max=89.8693\n",
      "[SGD | lr=0.05] Iter 55900: loss=0.0128\n",
      "[SGD | lr=0.05] Epoch 3494/4000: train_loss=0.0125  test_loss=4.2585  λ_max=89.6580\n",
      "[SGD | lr=0.05] Epoch 3495/4000: train_loss=0.0125  test_loss=4.2585  λ_max=92.6429\n",
      "[SGD | lr=0.05] Epoch 3496/4000: train_loss=0.0125  test_loss=4.2588  λ_max=93.9380\n",
      "[SGD | lr=0.05] Epoch 3497/4000: train_loss=0.0125  test_loss=4.2589  λ_max=90.5583\n",
      "[SGD | lr=0.05] Epoch 3498/4000: train_loss=0.0125  test_loss=4.2593  λ_max=92.0937\n",
      "[SGD | lr=0.05] Epoch 3499/4000: train_loss=0.0125  test_loss=4.2595  λ_max=94.8196\n",
      "[SGD | lr=0.05] Iter 56000: loss=0.0127\n",
      "[SGD | lr=0.05] Epoch 3500/4000: train_loss=0.0125  test_loss=4.2598  λ_max=90.9312\n",
      "[SGD | lr=0.05] Epoch 3501/4000: train_loss=0.0125  test_loss=4.2599  λ_max=93.3008\n",
      "[SGD | lr=0.05] Epoch 3502/4000: train_loss=0.0125  test_loss=4.2603  λ_max=93.0190\n",
      "[SGD | lr=0.05] Epoch 3503/4000: train_loss=0.0125  test_loss=4.2606  λ_max=91.7900\n",
      "[SGD | lr=0.05] Epoch 3504/4000: train_loss=0.0125  test_loss=4.2607  λ_max=93.1399\n",
      "[SGD | lr=0.05] Epoch 3505/4000: train_loss=0.0125  test_loss=4.2610  λ_max=93.4763\n",
      "[SGD | lr=0.05] Epoch 3506/4000: train_loss=0.0125  test_loss=4.2612  λ_max=91.4918\n",
      "[SGD | lr=0.05] Iter 56100: loss=0.0129\n",
      "[SGD | lr=0.05] Epoch 3507/4000: train_loss=0.0125  test_loss=4.2615  λ_max=92.7125\n",
      "[SGD | lr=0.05] Epoch 3508/4000: train_loss=0.0125  test_loss=4.2617  λ_max=92.1851\n",
      "[SGD | lr=0.05] Epoch 3509/4000: train_loss=0.0124  test_loss=4.2620  λ_max=91.9995\n",
      "[SGD | lr=0.05] Epoch 3510/4000: train_loss=0.0124  test_loss=4.2622  λ_max=92.8978\n",
      "[SGD | lr=0.05] Epoch 3511/4000: train_loss=0.0124  test_loss=4.2623  λ_max=92.5426\n",
      "[SGD | lr=0.05] Epoch 3512/4000: train_loss=0.0124  test_loss=4.2628  λ_max=90.8959\n",
      "[SGD | lr=0.05] Iter 56200: loss=0.0123\n",
      "[SGD | lr=0.05] Epoch 3513/4000: train_loss=0.0124  test_loss=4.2629  λ_max=92.7732\n",
      "[SGD | lr=0.05] Epoch 3514/4000: train_loss=0.0124  test_loss=4.2632  λ_max=93.2753\n",
      "[SGD | lr=0.05] Epoch 3515/4000: train_loss=0.0124  test_loss=4.2632  λ_max=91.3203\n",
      "[SGD | lr=0.05] Epoch 3516/4000: train_loss=0.0124  test_loss=4.2637  λ_max=91.4087\n",
      "[SGD | lr=0.05] Epoch 3517/4000: train_loss=0.0124  test_loss=4.2639  λ_max=92.7221\n",
      "[SGD | lr=0.05] Epoch 3518/4000: train_loss=0.0124  test_loss=4.2640  λ_max=92.7695\n",
      "[SGD | lr=0.05] Iter 56300: loss=0.0124\n",
      "[SGD | lr=0.05] Epoch 3519/4000: train_loss=0.0124  test_loss=4.2643  λ_max=91.0742\n",
      "[SGD | lr=0.05] Epoch 3520/4000: train_loss=0.0124  test_loss=4.2645  λ_max=94.0825\n",
      "[SGD | lr=0.05] Epoch 3521/4000: train_loss=0.0124  test_loss=4.2648  λ_max=91.3850\n",
      "[SGD | lr=0.05] Epoch 3522/4000: train_loss=0.0124  test_loss=4.2652  λ_max=88.9975\n",
      "[SGD | lr=0.05] Epoch 3523/4000: train_loss=0.0124  test_loss=4.2652  λ_max=93.9734\n",
      "[SGD | lr=0.05] Epoch 3524/4000: train_loss=0.0124  test_loss=4.2654  λ_max=92.9991\n",
      "[SGD | lr=0.05] Iter 56400: loss=0.0121\n",
      "[SGD | lr=0.05] Epoch 3525/4000: train_loss=0.0124  test_loss=4.2657  λ_max=92.3453\n",
      "[SGD | lr=0.05] Epoch 3526/4000: train_loss=0.0124  test_loss=4.2660  λ_max=90.7320\n",
      "[SGD | lr=0.05] Epoch 3527/4000: train_loss=0.0124  test_loss=4.2662  λ_max=92.3565\n",
      "[SGD | lr=0.05] Epoch 3528/4000: train_loss=0.0123  test_loss=4.2665  λ_max=94.4421\n",
      "[SGD | lr=0.05] Epoch 3529/4000: train_loss=0.0123  test_loss=4.2666  λ_max=89.7098\n",
      "[SGD | lr=0.05] Epoch 3530/4000: train_loss=0.0123  test_loss=4.2668  λ_max=92.2469\n",
      "[SGD | lr=0.05] Epoch 3531/4000: train_loss=0.0123  test_loss=4.2672  λ_max=91.3127\n",
      "[SGD | lr=0.05] Iter 56500: loss=0.0124\n",
      "[SGD | lr=0.05] Epoch 3532/4000: train_loss=0.0123  test_loss=4.2674  λ_max=92.9059\n",
      "[SGD | lr=0.05] Epoch 3533/4000: train_loss=0.0123  test_loss=4.2677  λ_max=92.1636\n",
      "[SGD | lr=0.05] Epoch 3534/4000: train_loss=0.0123  test_loss=4.2679  λ_max=90.0663\n",
      "[SGD | lr=0.05] Epoch 3535/4000: train_loss=0.0123  test_loss=4.2680  λ_max=86.3493\n",
      "[SGD | lr=0.05] Epoch 3536/4000: train_loss=0.0123  test_loss=4.2683  λ_max=92.4613\n",
      "[SGD | lr=0.05] Epoch 3537/4000: train_loss=0.0123  test_loss=4.2684  λ_max=92.8410\n",
      "[SGD | lr=0.05] Iter 56600: loss=0.0120\n",
      "[SGD | lr=0.05] Epoch 3538/4000: train_loss=0.0123  test_loss=4.2687  λ_max=93.0098\n",
      "[SGD | lr=0.05] Epoch 3539/4000: train_loss=0.0123  test_loss=4.2690  λ_max=94.5154\n",
      "[SGD | lr=0.05] Epoch 3540/4000: train_loss=0.0123  test_loss=4.2694  λ_max=88.8959\n",
      "[SGD | lr=0.05] Epoch 3541/4000: train_loss=0.0123  test_loss=4.2696  λ_max=93.2381\n",
      "[SGD | lr=0.05] Epoch 3542/4000: train_loss=0.0123  test_loss=4.2699  λ_max=91.5478\n",
      "[SGD | lr=0.05] Epoch 3543/4000: train_loss=0.0123  test_loss=4.2700  λ_max=94.6258\n",
      "[SGD | lr=0.05] Iter 56700: loss=0.0124\n",
      "[SGD | lr=0.05] Epoch 3544/4000: train_loss=0.0123  test_loss=4.2701  λ_max=92.2762\n",
      "[SGD | lr=0.05] Epoch 3545/4000: train_loss=0.0123  test_loss=4.2705  λ_max=90.8120\n",
      "[SGD | lr=0.05] Epoch 3546/4000: train_loss=0.0123  test_loss=4.2706  λ_max=93.4352\n",
      "[SGD | lr=0.05] Epoch 3547/4000: train_loss=0.0123  test_loss=4.2709  λ_max=92.0946\n",
      "[SGD | lr=0.05] Epoch 3548/4000: train_loss=0.0122  test_loss=4.2712  λ_max=89.6113\n",
      "[SGD | lr=0.05] Epoch 3549/4000: train_loss=0.0122  test_loss=4.2714  λ_max=91.3632\n",
      "[SGD | lr=0.05] Iter 56800: loss=0.0122\n",
      "[SGD | lr=0.05] Epoch 3550/4000: train_loss=0.0122  test_loss=4.2714  λ_max=91.9897\n",
      "[SGD | lr=0.05] Epoch 3551/4000: train_loss=0.0122  test_loss=4.2720  λ_max=93.8294\n",
      "[SGD | lr=0.05] Epoch 3552/4000: train_loss=0.0122  test_loss=4.2722  λ_max=92.8015\n",
      "[SGD | lr=0.05] Epoch 3553/4000: train_loss=0.0122  test_loss=4.2724  λ_max=95.1292\n",
      "[SGD | lr=0.05] Epoch 3554/4000: train_loss=0.0122  test_loss=4.2725  λ_max=91.0822\n",
      "[SGD | lr=0.05] Epoch 3555/4000: train_loss=0.0122  test_loss=4.2727  λ_max=92.2350\n",
      "[SGD | lr=0.05] Epoch 3556/4000: train_loss=0.0122  test_loss=4.2730  λ_max=92.2658\n",
      "[SGD | lr=0.05] Iter 56900: loss=0.0123\n",
      "[SGD | lr=0.05] Epoch 3557/4000: train_loss=0.0122  test_loss=4.2735  λ_max=93.8437\n",
      "[SGD | lr=0.05] Epoch 3558/4000: train_loss=0.0122  test_loss=4.2735  λ_max=93.4666\n",
      "[SGD | lr=0.05] Epoch 3559/4000: train_loss=0.0122  test_loss=4.2736  λ_max=91.6598\n",
      "[SGD | lr=0.05] Epoch 3560/4000: train_loss=0.0122  test_loss=4.2739  λ_max=93.2171\n",
      "[SGD | lr=0.05] Epoch 3561/4000: train_loss=0.0122  test_loss=4.2744  λ_max=92.4295\n",
      "[SGD | lr=0.05] Epoch 3562/4000: train_loss=0.0122  test_loss=4.2745  λ_max=91.8458\n",
      "[SGD | lr=0.05] Iter 57000: loss=0.0124\n",
      "[SGD | lr=0.05] Epoch 3563/4000: train_loss=0.0122  test_loss=4.2747  λ_max=91.7598\n",
      "[SGD | lr=0.05] Epoch 3564/4000: train_loss=0.0122  test_loss=4.2749  λ_max=94.4685\n",
      "[SGD | lr=0.05] Epoch 3565/4000: train_loss=0.0122  test_loss=4.2751  λ_max=91.0441\n",
      "[SGD | lr=0.05] Epoch 3566/4000: train_loss=0.0122  test_loss=4.2753  λ_max=93.0303\n",
      "[SGD | lr=0.05] Epoch 3567/4000: train_loss=0.0122  test_loss=4.2757  λ_max=94.4699\n",
      "[SGD | lr=0.05] Epoch 3568/4000: train_loss=0.0122  test_loss=4.2758  λ_max=95.2583\n",
      "[SGD | lr=0.05] Iter 57100: loss=0.0122\n",
      "[SGD | lr=0.05] Epoch 3569/4000: train_loss=0.0121  test_loss=4.2761  λ_max=94.4856\n",
      "[SGD | lr=0.05] Epoch 3570/4000: train_loss=0.0121  test_loss=4.2762  λ_max=91.9555\n",
      "[SGD | lr=0.05] Epoch 3571/4000: train_loss=0.0121  test_loss=4.2766  λ_max=94.8872\n",
      "[SGD | lr=0.05] Epoch 3572/4000: train_loss=0.0121  test_loss=4.2768  λ_max=94.6665\n",
      "[SGD | lr=0.05] Epoch 3573/4000: train_loss=0.0121  test_loss=4.2770  λ_max=95.5749\n",
      "[SGD | lr=0.05] Epoch 3574/4000: train_loss=0.0121  test_loss=4.2773  λ_max=92.1081\n",
      "[SGD | lr=0.05] Iter 57200: loss=0.0122\n",
      "[SGD | lr=0.05] Epoch 3575/4000: train_loss=0.0121  test_loss=4.2775  λ_max=92.3464\n",
      "[SGD | lr=0.05] Epoch 3576/4000: train_loss=0.0121  test_loss=4.2776  λ_max=92.2570\n",
      "[SGD | lr=0.05] Epoch 3577/4000: train_loss=0.0121  test_loss=4.2779  λ_max=91.2121\n",
      "[SGD | lr=0.05] Epoch 3578/4000: train_loss=0.0121  test_loss=4.2784  λ_max=94.5335\n",
      "[SGD | lr=0.05] Epoch 3579/4000: train_loss=0.0121  test_loss=4.2785  λ_max=92.0881\n",
      "[SGD | lr=0.05] Epoch 3580/4000: train_loss=0.0121  test_loss=4.2788  λ_max=94.9562\n",
      "[SGD | lr=0.05] Epoch 3581/4000: train_loss=0.0121  test_loss=4.2789  λ_max=93.4917\n",
      "[SGD | lr=0.05] Iter 57300: loss=0.0122\n",
      "[SGD | lr=0.05] Epoch 3582/4000: train_loss=0.0121  test_loss=4.2790  λ_max=91.9855\n",
      "[SGD | lr=0.05] Epoch 3583/4000: train_loss=0.0121  test_loss=4.2793  λ_max=91.2030\n",
      "[SGD | lr=0.05] Epoch 3584/4000: train_loss=0.0121  test_loss=4.2795  λ_max=92.6428\n",
      "[SGD | lr=0.05] Epoch 3585/4000: train_loss=0.0121  test_loss=4.2797  λ_max=93.7898\n",
      "[SGD | lr=0.05] Epoch 3586/4000: train_loss=0.0121  test_loss=4.2799  λ_max=91.0522\n",
      "[SGD | lr=0.05] Epoch 3587/4000: train_loss=0.0121  test_loss=4.2805  λ_max=95.4373\n",
      "[SGD | lr=0.05] Iter 57400: loss=0.0121\n",
      "[SGD | lr=0.05] Epoch 3588/4000: train_loss=0.0121  test_loss=4.2804  λ_max=93.0707\n",
      "[SGD | lr=0.05] Epoch 3589/4000: train_loss=0.0121  test_loss=4.2810  λ_max=90.7443\n",
      "[SGD | lr=0.05] Epoch 3590/4000: train_loss=0.0120  test_loss=4.2810  λ_max=95.0041\n",
      "[SGD | lr=0.05] Epoch 3591/4000: train_loss=0.0120  test_loss=4.2812  λ_max=93.5340\n",
      "[SGD | lr=0.05] Epoch 3592/4000: train_loss=0.0120  test_loss=4.2815  λ_max=93.8651\n",
      "[SGD | lr=0.05] Epoch 3593/4000: train_loss=0.0120  test_loss=4.2817  λ_max=93.2222\n",
      "[SGD | lr=0.05] Iter 57500: loss=0.0120\n",
      "[SGD | lr=0.05] Epoch 3594/4000: train_loss=0.0120  test_loss=4.2820  λ_max=93.3821\n",
      "[SGD | lr=0.05] Epoch 3595/4000: train_loss=0.0120  test_loss=4.2821  λ_max=92.0601\n",
      "[SGD | lr=0.05] Epoch 3596/4000: train_loss=0.0120  test_loss=4.2824  λ_max=89.8800\n",
      "[SGD | lr=0.05] Epoch 3597/4000: train_loss=0.0120  test_loss=4.2826  λ_max=91.3232\n",
      "[SGD | lr=0.05] Epoch 3598/4000: train_loss=0.0120  test_loss=4.2827  λ_max=95.8404\n",
      "[SGD | lr=0.05] Epoch 3599/4000: train_loss=0.0120  test_loss=4.2831  λ_max=92.2218\n",
      "[SGD | lr=0.05] Iter 57600: loss=0.0123\n",
      "[SGD | lr=0.05] Epoch 3600/4000: train_loss=0.0120  test_loss=4.2834  λ_max=95.3805\n",
      "[SGD | lr=0.05] Epoch 3601/4000: train_loss=0.0120  test_loss=4.2833  λ_max=96.7892\n",
      "[SGD | lr=0.05] Epoch 3602/4000: train_loss=0.0120  test_loss=4.2837  λ_max=92.6284\n",
      "[SGD | lr=0.05] Epoch 3603/4000: train_loss=0.0120  test_loss=4.2840  λ_max=94.9562\n",
      "[SGD | lr=0.05] Epoch 3604/4000: train_loss=0.0120  test_loss=4.2841  λ_max=95.6774\n",
      "[SGD | lr=0.05] Epoch 3605/4000: train_loss=0.0120  test_loss=4.2846  λ_max=93.6786\n",
      "[SGD | lr=0.05] Epoch 3606/4000: train_loss=0.0120  test_loss=4.2846  λ_max=93.7286\n",
      "[SGD | lr=0.05] Iter 57700: loss=0.0119\n",
      "[SGD | lr=0.05] Epoch 3607/4000: train_loss=0.0120  test_loss=4.2849  λ_max=92.1223\n",
      "[SGD | lr=0.05] Epoch 3608/4000: train_loss=0.0120  test_loss=4.2852  λ_max=93.8869\n",
      "[SGD | lr=0.05] Epoch 3609/4000: train_loss=0.0120  test_loss=4.2855  λ_max=93.1750\n",
      "[SGD | lr=0.05] Epoch 3610/4000: train_loss=0.0120  test_loss=4.2857  λ_max=94.0082\n",
      "[SGD | lr=0.05] Epoch 3611/4000: train_loss=0.0119  test_loss=4.2858  λ_max=93.2792\n",
      "[SGD | lr=0.05] Epoch 3612/4000: train_loss=0.0119  test_loss=4.2861  λ_max=94.7093\n",
      "[SGD | lr=0.05] Iter 57800: loss=0.0119\n",
      "[SGD | lr=0.05] Epoch 3613/4000: train_loss=0.0119  test_loss=4.2862  λ_max=94.5410\n",
      "[SGD | lr=0.05] Epoch 3614/4000: train_loss=0.0119  test_loss=4.2865  λ_max=93.4756\n",
      "[SGD | lr=0.05] Epoch 3615/4000: train_loss=0.0119  test_loss=4.2868  λ_max=93.5689\n",
      "[SGD | lr=0.05] Epoch 3616/4000: train_loss=0.0119  test_loss=4.2867  λ_max=91.1418\n",
      "[SGD | lr=0.05] Epoch 3617/4000: train_loss=0.0119  test_loss=4.2872  λ_max=90.9474\n",
      "[SGD | lr=0.05] Epoch 3618/4000: train_loss=0.0119  test_loss=4.2875  λ_max=96.0371\n",
      "[SGD | lr=0.05] Iter 57900: loss=0.0121\n",
      "[SGD | lr=0.05] Epoch 3619/4000: train_loss=0.0119  test_loss=4.2877  λ_max=95.1501\n",
      "[SGD | lr=0.05] Epoch 3620/4000: train_loss=0.0119  test_loss=4.2878  λ_max=93.5282\n",
      "[SGD | lr=0.05] Epoch 3621/4000: train_loss=0.0119  test_loss=4.2882  λ_max=94.1946\n",
      "[SGD | lr=0.05] Epoch 3622/4000: train_loss=0.0119  test_loss=4.2884  λ_max=90.7195\n",
      "[SGD | lr=0.05] Epoch 3623/4000: train_loss=0.0119  test_loss=4.2887  λ_max=94.9403\n",
      "[SGD | lr=0.05] Epoch 3624/4000: train_loss=0.0119  test_loss=4.2888  λ_max=93.3254\n",
      "[SGD | lr=0.05] Iter 58000: loss=0.0117\n",
      "[SGD | lr=0.05] Epoch 3625/4000: train_loss=0.0119  test_loss=4.2891  λ_max=93.7200\n",
      "[SGD | lr=0.05] Epoch 3626/4000: train_loss=0.0119  test_loss=4.2893  λ_max=91.1956\n",
      "[SGD | lr=0.05] Epoch 3627/4000: train_loss=0.0119  test_loss=4.2895  λ_max=94.2639\n",
      "[SGD | lr=0.05] Epoch 3628/4000: train_loss=0.0119  test_loss=4.2898  λ_max=96.2280\n",
      "[SGD | lr=0.05] Epoch 3629/4000: train_loss=0.0119  test_loss=4.2900  λ_max=93.7710\n",
      "[SGD | lr=0.05] Epoch 3630/4000: train_loss=0.0119  test_loss=4.2903  λ_max=94.8232\n",
      "[SGD | lr=0.05] Epoch 3631/4000: train_loss=0.0119  test_loss=4.2906  λ_max=94.3778\n",
      "[SGD | lr=0.05] Iter 58100: loss=0.0119\n",
      "[SGD | lr=0.05] Epoch 3632/4000: train_loss=0.0118  test_loss=4.2907  λ_max=92.2518\n",
      "[SGD | lr=0.05] Epoch 3633/4000: train_loss=0.0118  test_loss=4.2909  λ_max=92.8937\n",
      "[SGD | lr=0.05] Epoch 3634/4000: train_loss=0.0118  test_loss=4.2910  λ_max=93.4904\n",
      "[SGD | lr=0.05] Epoch 3635/4000: train_loss=0.0118  test_loss=4.2913  λ_max=95.0390\n",
      "[SGD | lr=0.05] Epoch 3636/4000: train_loss=0.0118  test_loss=4.2917  λ_max=92.9727\n",
      "[SGD | lr=0.05] Epoch 3637/4000: train_loss=0.0118  test_loss=4.2918  λ_max=93.9678\n",
      "[SGD | lr=0.05] Iter 58200: loss=0.0117\n",
      "[SGD | lr=0.05] Epoch 3638/4000: train_loss=0.0118  test_loss=4.2920  λ_max=94.8478\n",
      "[SGD | lr=0.05] Epoch 3639/4000: train_loss=0.0118  test_loss=4.2923  λ_max=94.9618\n",
      "[SGD | lr=0.05] Epoch 3640/4000: train_loss=0.0118  test_loss=4.2924  λ_max=93.9370\n",
      "[SGD | lr=0.05] Epoch 3641/4000: train_loss=0.0118  test_loss=4.2927  λ_max=91.9113\n",
      "[SGD | lr=0.05] Epoch 3642/4000: train_loss=0.0118  test_loss=4.2930  λ_max=91.7420\n",
      "[SGD | lr=0.05] Epoch 3643/4000: train_loss=0.0118  test_loss=4.2931  λ_max=94.1339\n",
      "[SGD | lr=0.05] Iter 58300: loss=0.0118\n",
      "[SGD | lr=0.05] Epoch 3644/4000: train_loss=0.0118  test_loss=4.2935  λ_max=93.0011\n",
      "[SGD | lr=0.05] Epoch 3645/4000: train_loss=0.0118  test_loss=4.2936  λ_max=91.3862\n",
      "[SGD | lr=0.05] Epoch 3646/4000: train_loss=0.0118  test_loss=4.2939  λ_max=94.0575\n",
      "[SGD | lr=0.05] Epoch 3647/4000: train_loss=0.0118  test_loss=4.2942  λ_max=93.7205\n",
      "[SGD | lr=0.05] Epoch 3648/4000: train_loss=0.0118  test_loss=4.2943  λ_max=93.7026\n",
      "[SGD | lr=0.05] Epoch 3649/4000: train_loss=0.0118  test_loss=4.2946  λ_max=93.1368\n",
      "[SGD | lr=0.05] Iter 58400: loss=0.0119\n",
      "[SGD | lr=0.05] Epoch 3650/4000: train_loss=0.0118  test_loss=4.2949  λ_max=94.8907\n",
      "[SGD | lr=0.05] Epoch 3651/4000: train_loss=0.0118  test_loss=4.2950  λ_max=94.6721\n",
      "[SGD | lr=0.05] Epoch 3652/4000: train_loss=0.0118  test_loss=4.2952  λ_max=92.5554\n",
      "[SGD | lr=0.05] Epoch 3653/4000: train_loss=0.0118  test_loss=4.2955  λ_max=95.6855\n",
      "[SGD | lr=0.05] Epoch 3654/4000: train_loss=0.0117  test_loss=4.2957  λ_max=93.8507\n",
      "[SGD | lr=0.05] Epoch 3655/4000: train_loss=0.0117  test_loss=4.2958  λ_max=94.3590\n",
      "[SGD | lr=0.05] Epoch 3656/4000: train_loss=0.0117  test_loss=4.2962  λ_max=93.2838\n",
      "[SGD | lr=0.05] Iter 58500: loss=0.0119\n",
      "[SGD | lr=0.05] Epoch 3657/4000: train_loss=0.0117  test_loss=4.2964  λ_max=92.8299\n",
      "[SGD | lr=0.05] Epoch 3658/4000: train_loss=0.0117  test_loss=4.2966  λ_max=93.9360\n",
      "[SGD | lr=0.05] Epoch 3659/4000: train_loss=0.0117  test_loss=4.2968  λ_max=94.6489\n",
      "[SGD | lr=0.05] Epoch 3660/4000: train_loss=0.0117  test_loss=4.2969  λ_max=96.0768\n",
      "[SGD | lr=0.05] Epoch 3661/4000: train_loss=0.0117  test_loss=4.2973  λ_max=93.9938\n",
      "[SGD | lr=0.05] Epoch 3662/4000: train_loss=0.0117  test_loss=4.2973  λ_max=96.5180\n",
      "[SGD | lr=0.05] Iter 58600: loss=0.0118\n",
      "[SGD | lr=0.05] Epoch 3663/4000: train_loss=0.0117  test_loss=4.2978  λ_max=91.9795\n",
      "[SGD | lr=0.05] Epoch 3664/4000: train_loss=0.0117  test_loss=4.2981  λ_max=90.2851\n",
      "[SGD | lr=0.05] Epoch 3665/4000: train_loss=0.0117  test_loss=4.2981  λ_max=92.5487\n",
      "[SGD | lr=0.05] Epoch 3666/4000: train_loss=0.0117  test_loss=4.2982  λ_max=93.0501\n",
      "[SGD | lr=0.05] Epoch 3667/4000: train_loss=0.0117  test_loss=4.2988  λ_max=94.6179\n",
      "[SGD | lr=0.05] Epoch 3668/4000: train_loss=0.0117  test_loss=4.2989  λ_max=91.2499\n",
      "[SGD | lr=0.05] Iter 58700: loss=0.0118\n",
      "[SGD | lr=0.05] Epoch 3669/4000: train_loss=0.0117  test_loss=4.2989  λ_max=93.1878\n",
      "[SGD | lr=0.05] Epoch 3670/4000: train_loss=0.0117  test_loss=4.2993  λ_max=96.0159\n",
      "[SGD | lr=0.05] Epoch 3671/4000: train_loss=0.0117  test_loss=4.2995  λ_max=94.1981\n",
      "[SGD | lr=0.05] Epoch 3672/4000: train_loss=0.0117  test_loss=4.2997  λ_max=92.8784\n",
      "[SGD | lr=0.05] Epoch 3673/4000: train_loss=0.0117  test_loss=4.3001  λ_max=91.4617\n",
      "[SGD | lr=0.05] Epoch 3674/4000: train_loss=0.0117  test_loss=4.3001  λ_max=94.5185\n",
      "[SGD | lr=0.05] Iter 58800: loss=0.0119\n",
      "[SGD | lr=0.05] Epoch 3675/4000: train_loss=0.0117  test_loss=4.3004  λ_max=92.3233\n",
      "[SGD | lr=0.05] Epoch 3676/4000: train_loss=0.0117  test_loss=4.3008  λ_max=96.2692\n",
      "[SGD | lr=0.05] Epoch 3677/4000: train_loss=0.0116  test_loss=4.3010  λ_max=94.7986\n",
      "[SGD | lr=0.05] Epoch 3678/4000: train_loss=0.0116  test_loss=4.3011  λ_max=96.4251\n",
      "[SGD | lr=0.05] Epoch 3679/4000: train_loss=0.0116  test_loss=4.3014  λ_max=90.2263\n",
      "[SGD | lr=0.05] Epoch 3680/4000: train_loss=0.0116  test_loss=4.3015  λ_max=94.1780\n",
      "[SGD | lr=0.05] Epoch 3681/4000: train_loss=0.0116  test_loss=4.3018  λ_max=96.2978\n",
      "[SGD | lr=0.05] Iter 58900: loss=0.0117\n",
      "[SGD | lr=0.05] Epoch 3682/4000: train_loss=0.0116  test_loss=4.3020  λ_max=91.3794\n",
      "[SGD | lr=0.05] Epoch 3683/4000: train_loss=0.0116  test_loss=4.3024  λ_max=93.6331\n",
      "[SGD | lr=0.05] Epoch 3684/4000: train_loss=0.0116  test_loss=4.3023  λ_max=96.4432\n",
      "[SGD | lr=0.05] Epoch 3685/4000: train_loss=0.0116  test_loss=4.3027  λ_max=93.8754\n",
      "[SGD | lr=0.05] Epoch 3686/4000: train_loss=0.0116  test_loss=4.3030  λ_max=91.2182\n",
      "[SGD | lr=0.05] Epoch 3687/4000: train_loss=0.0116  test_loss=4.3031  λ_max=95.5844\n",
      "[SGD | lr=0.05] Iter 59000: loss=0.0119\n",
      "[SGD | lr=0.05] Epoch 3688/4000: train_loss=0.0116  test_loss=4.3032  λ_max=96.4890\n",
      "[SGD | lr=0.05] Epoch 3689/4000: train_loss=0.0116  test_loss=4.3036  λ_max=95.3278\n",
      "[SGD | lr=0.05] Epoch 3690/4000: train_loss=0.0116  test_loss=4.3038  λ_max=94.3333\n",
      "[SGD | lr=0.05] Epoch 3691/4000: train_loss=0.0116  test_loss=4.3040  λ_max=94.6092\n",
      "[SGD | lr=0.05] Epoch 3692/4000: train_loss=0.0116  test_loss=4.3042  λ_max=93.6829\n",
      "[SGD | lr=0.05] Epoch 3693/4000: train_loss=0.0116  test_loss=4.3045  λ_max=93.9204\n",
      "[SGD | lr=0.05] Iter 59100: loss=0.0117\n",
      "[SGD | lr=0.05] Epoch 3694/4000: train_loss=0.0116  test_loss=4.3047  λ_max=92.4217\n",
      "[SGD | lr=0.05] Epoch 3695/4000: train_loss=0.0116  test_loss=4.3050  λ_max=92.6760\n",
      "[SGD | lr=0.05] Epoch 3696/4000: train_loss=0.0116  test_loss=4.3051  λ_max=93.1172\n",
      "[SGD | lr=0.05] Epoch 3697/4000: train_loss=0.0116  test_loss=4.3053  λ_max=95.4171\n",
      "[SGD | lr=0.05] Epoch 3698/4000: train_loss=0.0115  test_loss=4.3057  λ_max=92.5992\n",
      "[SGD | lr=0.05] Epoch 3699/4000: train_loss=0.0115  test_loss=4.3057  λ_max=94.7173\n",
      "[SGD | lr=0.05] Iter 59200: loss=0.0116\n",
      "[SGD | lr=0.05] Epoch 3700/4000: train_loss=0.0115  test_loss=4.3061  λ_max=93.6965\n",
      "[SGD | lr=0.05] Epoch 3701/4000: train_loss=0.0115  test_loss=4.3064  λ_max=91.7135\n",
      "[SGD | lr=0.05] Epoch 3702/4000: train_loss=0.0115  test_loss=4.3065  λ_max=95.3298\n",
      "[SGD | lr=0.05] Epoch 3703/4000: train_loss=0.0115  test_loss=4.3068  λ_max=95.3056\n",
      "[SGD | lr=0.05] Epoch 3704/4000: train_loss=0.0115  test_loss=4.3069  λ_max=94.6415\n",
      "[SGD | lr=0.05] Epoch 3705/4000: train_loss=0.0115  test_loss=4.3073  λ_max=97.4884\n",
      "[SGD | lr=0.05] Epoch 3706/4000: train_loss=0.0115  test_loss=4.3076  λ_max=92.8057\n",
      "[SGD | lr=0.05] Iter 59300: loss=0.0114\n",
      "[SGD | lr=0.05] Epoch 3707/4000: train_loss=0.0115  test_loss=4.3077  λ_max=95.8377\n",
      "[SGD | lr=0.05] Epoch 3708/4000: train_loss=0.0115  test_loss=4.3078  λ_max=93.4958\n",
      "[SGD | lr=0.05] Epoch 3709/4000: train_loss=0.0115  test_loss=4.3080  λ_max=90.1625\n",
      "[SGD | lr=0.05] Epoch 3710/4000: train_loss=0.0115  test_loss=4.3083  λ_max=96.5628\n",
      "[SGD | lr=0.05] Epoch 3711/4000: train_loss=0.0115  test_loss=4.3085  λ_max=95.1314\n",
      "[SGD | lr=0.05] Epoch 3712/4000: train_loss=0.0115  test_loss=4.3087  λ_max=93.6208\n",
      "[SGD | lr=0.05] Iter 59400: loss=0.0113\n",
      "[SGD | lr=0.05] Epoch 3713/4000: train_loss=0.0115  test_loss=4.3091  λ_max=96.1103\n",
      "[SGD | lr=0.05] Epoch 3714/4000: train_loss=0.0115  test_loss=4.3093  λ_max=94.5378\n",
      "[SGD | lr=0.05] Epoch 3715/4000: train_loss=0.0115  test_loss=4.3094  λ_max=96.1513\n",
      "[SGD | lr=0.05] Epoch 3716/4000: train_loss=0.0115  test_loss=4.3098  λ_max=92.7905\n",
      "[SGD | lr=0.05] Epoch 3717/4000: train_loss=0.0115  test_loss=4.3100  λ_max=97.1776\n",
      "[SGD | lr=0.05] Epoch 3718/4000: train_loss=0.0115  test_loss=4.3102  λ_max=95.0518\n",
      "[SGD | lr=0.05] Iter 59500: loss=0.0114\n",
      "[SGD | lr=0.05] Epoch 3719/4000: train_loss=0.0115  test_loss=4.3101  λ_max=94.8806\n",
      "[SGD | lr=0.05] Epoch 3720/4000: train_loss=0.0115  test_loss=4.3105  λ_max=95.5976\n",
      "[SGD | lr=0.05] Epoch 3721/4000: train_loss=0.0115  test_loss=4.3110  λ_max=92.6710\n",
      "[SGD | lr=0.05] Epoch 3722/4000: train_loss=0.0114  test_loss=4.3109  λ_max=93.1799\n",
      "[SGD | lr=0.05] Epoch 3723/4000: train_loss=0.0114  test_loss=4.3113  λ_max=91.9627\n",
      "[SGD | lr=0.05] Epoch 3724/4000: train_loss=0.0114  test_loss=4.3114  λ_max=95.8321\n",
      "[SGD | lr=0.05] Iter 59600: loss=0.0114\n",
      "[SGD | lr=0.05] Epoch 3725/4000: train_loss=0.0114  test_loss=4.3117  λ_max=96.3613\n",
      "[SGD | lr=0.05] Epoch 3726/4000: train_loss=0.0114  test_loss=4.3120  λ_max=94.1095\n",
      "[SGD | lr=0.05] Epoch 3727/4000: train_loss=0.0114  test_loss=4.3122  λ_max=95.7415\n",
      "[SGD | lr=0.05] Epoch 3728/4000: train_loss=0.0114  test_loss=4.3124  λ_max=92.5282\n",
      "[SGD | lr=0.05] Epoch 3729/4000: train_loss=0.0114  test_loss=4.3125  λ_max=94.7963\n",
      "[SGD | lr=0.05] Epoch 3730/4000: train_loss=0.0114  test_loss=4.3127  λ_max=93.3450\n",
      "[SGD | lr=0.05] Epoch 3731/4000: train_loss=0.0114  test_loss=4.3131  λ_max=93.1639\n",
      "[SGD | lr=0.05] Iter 59700: loss=0.0113\n",
      "[SGD | lr=0.05] Epoch 3732/4000: train_loss=0.0114  test_loss=4.3133  λ_max=91.6338\n",
      "[SGD | lr=0.05] Epoch 3733/4000: train_loss=0.0114  test_loss=4.3135  λ_max=96.8072\n",
      "[SGD | lr=0.05] Epoch 3734/4000: train_loss=0.0114  test_loss=4.3136  λ_max=92.8488\n",
      "[SGD | lr=0.05] Epoch 3735/4000: train_loss=0.0114  test_loss=4.3138  λ_max=96.1361\n",
      "[SGD | lr=0.05] Epoch 3736/4000: train_loss=0.0114  test_loss=4.3141  λ_max=96.3401\n",
      "[SGD | lr=0.05] Epoch 3737/4000: train_loss=0.0114  test_loss=4.3144  λ_max=92.5218\n",
      "[SGD | lr=0.05] Iter 59800: loss=0.0113\n",
      "[SGD | lr=0.05] Epoch 3738/4000: train_loss=0.0114  test_loss=4.3145  λ_max=94.9711\n",
      "[SGD | lr=0.05] Epoch 3739/4000: train_loss=0.0114  test_loss=4.3148  λ_max=95.5474\n",
      "[SGD | lr=0.05] Epoch 3740/4000: train_loss=0.0114  test_loss=4.3150  λ_max=92.1763\n",
      "[SGD | lr=0.05] Epoch 3741/4000: train_loss=0.0114  test_loss=4.3152  λ_max=92.3980\n",
      "[SGD | lr=0.05] Epoch 3742/4000: train_loss=0.0114  test_loss=4.3155  λ_max=91.7161\n",
      "[SGD | lr=0.05] Epoch 3743/4000: train_loss=0.0114  test_loss=4.3156  λ_max=91.8798\n",
      "[SGD | lr=0.05] Iter 59900: loss=0.0114\n",
      "[SGD | lr=0.05] Epoch 3744/4000: train_loss=0.0114  test_loss=4.3159  λ_max=93.0878\n",
      "[SGD | lr=0.05] Epoch 3745/4000: train_loss=0.0114  test_loss=4.3163  λ_max=93.1138\n",
      "[SGD | lr=0.05] Epoch 3746/4000: train_loss=0.0113  test_loss=4.3164  λ_max=94.0140\n",
      "[SGD | lr=0.05] Epoch 3747/4000: train_loss=0.0113  test_loss=4.3166  λ_max=94.6737\n",
      "[SGD | lr=0.05] Epoch 3748/4000: train_loss=0.0113  test_loss=4.3167  λ_max=94.9434\n",
      "[SGD | lr=0.05] Epoch 3749/4000: train_loss=0.0113  test_loss=4.3169  λ_max=90.6436\n",
      "[SGD | lr=0.05] Iter 60000: loss=0.0113\n",
      "[SGD | lr=0.05] Epoch 3750/4000: train_loss=0.0113  test_loss=4.3173  λ_max=94.0719\n",
      "[SGD | lr=0.05] Epoch 3751/4000: train_loss=0.0113  test_loss=4.3175  λ_max=91.8984\n",
      "[SGD | lr=0.05] Epoch 3752/4000: train_loss=0.0113  test_loss=4.3176  λ_max=92.4154\n",
      "[SGD | lr=0.05] Epoch 3753/4000: train_loss=0.0113  test_loss=4.3179  λ_max=93.3004\n",
      "[SGD | lr=0.05] Epoch 3754/4000: train_loss=0.0113  test_loss=4.3180  λ_max=93.0174\n",
      "[SGD | lr=0.05] Epoch 3755/4000: train_loss=0.0113  test_loss=4.3182  λ_max=93.1995\n",
      "[SGD | lr=0.05] Epoch 3756/4000: train_loss=0.0113  test_loss=4.3186  λ_max=94.7808\n",
      "[SGD | lr=0.05] Iter 60100: loss=0.0111\n",
      "[SGD | lr=0.05] Epoch 3757/4000: train_loss=0.0113  test_loss=4.3187  λ_max=95.3477\n",
      "[SGD | lr=0.05] Epoch 3758/4000: train_loss=0.0113  test_loss=4.3190  λ_max=97.0330\n",
      "[SGD | lr=0.05] Epoch 3759/4000: train_loss=0.0113  test_loss=4.3193  λ_max=96.4870\n",
      "[SGD | lr=0.05] Epoch 3760/4000: train_loss=0.0113  test_loss=4.3194  λ_max=94.9728\n",
      "[SGD | lr=0.05] Epoch 3761/4000: train_loss=0.0113  test_loss=4.3196  λ_max=94.4246\n",
      "[SGD | lr=0.05] Epoch 3762/4000: train_loss=0.0113  test_loss=4.3198  λ_max=94.1811\n",
      "[SGD | lr=0.05] Iter 60200: loss=0.0112\n",
      "[SGD | lr=0.05] Epoch 3763/4000: train_loss=0.0113  test_loss=4.3200  λ_max=96.8117\n",
      "[SGD | lr=0.05] Epoch 3764/4000: train_loss=0.0113  test_loss=4.3204  λ_max=93.5945\n",
      "[SGD | lr=0.05] Epoch 3765/4000: train_loss=0.0113  test_loss=4.3205  λ_max=96.7479\n",
      "[SGD | lr=0.05] Epoch 3766/4000: train_loss=0.0113  test_loss=4.3205  λ_max=95.2835\n",
      "[SGD | lr=0.05] Epoch 3767/4000: train_loss=0.0113  test_loss=4.3209  λ_max=94.6099\n",
      "[SGD | lr=0.05] Epoch 3768/4000: train_loss=0.0112  test_loss=4.3213  λ_max=93.0194\n",
      "[SGD | lr=0.05] Iter 60300: loss=0.0111\n",
      "[SGD | lr=0.05] Epoch 3769/4000: train_loss=0.0113  test_loss=4.3214  λ_max=94.9487\n",
      "[SGD | lr=0.05] Epoch 3770/4000: train_loss=0.0112  test_loss=4.3216  λ_max=97.7841\n",
      "[SGD | lr=0.05] Epoch 3771/4000: train_loss=0.0112  test_loss=4.3219  λ_max=93.3455\n",
      "[SGD | lr=0.05] Epoch 3772/4000: train_loss=0.0112  test_loss=4.3219  λ_max=92.2184\n",
      "[SGD | lr=0.05] Epoch 3773/4000: train_loss=0.0112  test_loss=4.3223  λ_max=93.4182\n",
      "[SGD | lr=0.05] Epoch 3774/4000: train_loss=0.0112  test_loss=4.3223  λ_max=97.8433\n",
      "[SGD | lr=0.05] Iter 60400: loss=0.0110\n",
      "[SGD | lr=0.05] Epoch 3775/4000: train_loss=0.0112  test_loss=4.3227  λ_max=94.0504\n",
      "[SGD | lr=0.05] Epoch 3776/4000: train_loss=0.0112  test_loss=4.3231  λ_max=93.1524\n",
      "[SGD | lr=0.05] Epoch 3777/4000: train_loss=0.0112  test_loss=4.3232  λ_max=92.7935\n",
      "[SGD | lr=0.05] Epoch 3778/4000: train_loss=0.0112  test_loss=4.3234  λ_max=92.2159\n",
      "[SGD | lr=0.05] Epoch 3779/4000: train_loss=0.0112  test_loss=4.3236  λ_max=95.2998\n",
      "[SGD | lr=0.05] Epoch 3780/4000: train_loss=0.0112  test_loss=4.3238  λ_max=98.4436\n",
      "[SGD | lr=0.05] Epoch 3781/4000: train_loss=0.0112  test_loss=4.3240  λ_max=93.3874\n",
      "[SGD | lr=0.05] Iter 60500: loss=0.0114\n",
      "[SGD | lr=0.05] Epoch 3782/4000: train_loss=0.0112  test_loss=4.3244  λ_max=93.9672\n",
      "[SGD | lr=0.05] Epoch 3783/4000: train_loss=0.0112  test_loss=4.3245  λ_max=92.7479\n",
      "[SGD | lr=0.05] Epoch 3784/4000: train_loss=0.0112  test_loss=4.3246  λ_max=92.8723\n",
      "[SGD | lr=0.05] Epoch 3785/4000: train_loss=0.0112  test_loss=4.3250  λ_max=93.4623\n",
      "[SGD | lr=0.05] Epoch 3786/4000: train_loss=0.0112  test_loss=4.3250  λ_max=94.6437\n",
      "[SGD | lr=0.05] Epoch 3787/4000: train_loss=0.0112  test_loss=4.3252  λ_max=91.9662\n",
      "[SGD | lr=0.05] Iter 60600: loss=0.0110\n",
      "[SGD | lr=0.05] Epoch 3788/4000: train_loss=0.0112  test_loss=4.3255  λ_max=90.8834\n",
      "[SGD | lr=0.05] Epoch 3789/4000: train_loss=0.0112  test_loss=4.3258  λ_max=95.9581\n",
      "[SGD | lr=0.05] Epoch 3790/4000: train_loss=0.0112  test_loss=4.3259  λ_max=95.0811\n",
      "[SGD | lr=0.05] Epoch 3791/4000: train_loss=0.0112  test_loss=4.3262  λ_max=95.5475\n",
      "[SGD | lr=0.05] Epoch 3792/4000: train_loss=0.0112  test_loss=4.3264  λ_max=95.2165\n",
      "[SGD | lr=0.05] Epoch 3793/4000: train_loss=0.0111  test_loss=4.3265  λ_max=92.2138\n",
      "[SGD | lr=0.05] Iter 60700: loss=0.0113\n",
      "[SGD | lr=0.05] Epoch 3794/4000: train_loss=0.0111  test_loss=4.3271  λ_max=96.2120\n",
      "[SGD | lr=0.05] Epoch 3795/4000: train_loss=0.0111  test_loss=4.3271  λ_max=95.7916\n",
      "[SGD | lr=0.05] Epoch 3796/4000: train_loss=0.0111  test_loss=4.3274  λ_max=93.8438\n",
      "[SGD | lr=0.05] Epoch 3797/4000: train_loss=0.0111  test_loss=4.3275  λ_max=93.8688\n",
      "[SGD | lr=0.05] Epoch 3798/4000: train_loss=0.0111  test_loss=4.3277  λ_max=93.4936\n",
      "[SGD | lr=0.05] Epoch 3799/4000: train_loss=0.0111  test_loss=4.3279  λ_max=97.6831\n",
      "[SGD | lr=0.05] Iter 60800: loss=0.0113\n",
      "[SGD | lr=0.05] Epoch 3800/4000: train_loss=0.0111  test_loss=4.3281  λ_max=96.0695\n",
      "[SGD | lr=0.05] Epoch 3801/4000: train_loss=0.0111  test_loss=4.3284  λ_max=95.3745\n",
      "[SGD | lr=0.05] Epoch 3802/4000: train_loss=0.0111  test_loss=4.3285  λ_max=94.6969\n",
      "[SGD | lr=0.05] Epoch 3803/4000: train_loss=0.0111  test_loss=4.3289  λ_max=94.3459\n",
      "[SGD | lr=0.05] Epoch 3804/4000: train_loss=0.0111  test_loss=4.3289  λ_max=96.1875\n",
      "[SGD | lr=0.05] Epoch 3805/4000: train_loss=0.0111  test_loss=4.3292  λ_max=94.4659\n",
      "[SGD | lr=0.05] Epoch 3806/4000: train_loss=0.0111  test_loss=4.3294  λ_max=98.2850\n",
      "[SGD | lr=0.05] Iter 60900: loss=0.0112\n",
      "[SGD | lr=0.05] Epoch 3807/4000: train_loss=0.0111  test_loss=4.3297  λ_max=94.6985\n",
      "[SGD | lr=0.05] Epoch 3808/4000: train_loss=0.0111  test_loss=4.3300  λ_max=95.1394\n",
      "[SGD | lr=0.05] Epoch 3809/4000: train_loss=0.0111  test_loss=4.3301  λ_max=94.2836\n",
      "[SGD | lr=0.05] Epoch 3810/4000: train_loss=0.0111  test_loss=4.3303  λ_max=94.2143\n",
      "[SGD | lr=0.05] Epoch 3811/4000: train_loss=0.0111  test_loss=4.3304  λ_max=96.3026\n",
      "[SGD | lr=0.05] Epoch 3812/4000: train_loss=0.0111  test_loss=4.3309  λ_max=97.6231\n",
      "[SGD | lr=0.05] Iter 61000: loss=0.0108\n",
      "[SGD | lr=0.05] Epoch 3813/4000: train_loss=0.0111  test_loss=4.3310  λ_max=96.7363\n",
      "[SGD | lr=0.05] Epoch 3814/4000: train_loss=0.0111  test_loss=4.3313  λ_max=94.0741\n",
      "[SGD | lr=0.05] Epoch 3815/4000: train_loss=0.0111  test_loss=4.3314  λ_max=91.5700\n",
      "[SGD | lr=0.05] Epoch 3816/4000: train_loss=0.0110  test_loss=4.3317  λ_max=96.7269\n",
      "[SGD | lr=0.05] Epoch 3817/4000: train_loss=0.0111  test_loss=4.3320  λ_max=94.1092\n",
      "[SGD | lr=0.05] Epoch 3818/4000: train_loss=0.0110  test_loss=4.3321  λ_max=93.2258\n",
      "[SGD | lr=0.05] Iter 61100: loss=0.0110\n",
      "[SGD | lr=0.05] Epoch 3819/4000: train_loss=0.0110  test_loss=4.3326  λ_max=96.5136\n",
      "[SGD | lr=0.05] Epoch 3820/4000: train_loss=0.0110  test_loss=4.3327  λ_max=93.9500\n",
      "[SGD | lr=0.05] Epoch 3821/4000: train_loss=0.0110  test_loss=4.3327  λ_max=94.0295\n",
      "[SGD | lr=0.05] Epoch 3822/4000: train_loss=0.0110  test_loss=4.3330  λ_max=98.0226\n",
      "[SGD | lr=0.05] Epoch 3823/4000: train_loss=0.0110  test_loss=4.3330  λ_max=93.6582\n",
      "[SGD | lr=0.05] Epoch 3824/4000: train_loss=0.0110  test_loss=4.3335  λ_max=94.5290\n",
      "[SGD | lr=0.05] Iter 61200: loss=0.0108\n",
      "[SGD | lr=0.05] Epoch 3825/4000: train_loss=0.0110  test_loss=4.3335  λ_max=96.2599\n",
      "[SGD | lr=0.05] Epoch 3826/4000: train_loss=0.0110  test_loss=4.3338  λ_max=93.6709\n",
      "[SGD | lr=0.05] Epoch 3827/4000: train_loss=0.0110  test_loss=4.3339  λ_max=95.1442\n",
      "[SGD | lr=0.05] Epoch 3828/4000: train_loss=0.0110  test_loss=4.3342  λ_max=95.5804\n",
      "[SGD | lr=0.05] Epoch 3829/4000: train_loss=0.0110  test_loss=4.3345  λ_max=96.9562\n",
      "[SGD | lr=0.05] Epoch 3830/4000: train_loss=0.0110  test_loss=4.3348  λ_max=91.8928\n",
      "[SGD | lr=0.05] Epoch 3831/4000: train_loss=0.0110  test_loss=4.3349  λ_max=94.5785\n",
      "[SGD | lr=0.05] Iter 61300: loss=0.0109\n",
      "[SGD | lr=0.05] Epoch 3832/4000: train_loss=0.0110  test_loss=4.3352  λ_max=96.6429\n",
      "[SGD | lr=0.05] Epoch 3833/4000: train_loss=0.0110  test_loss=4.3354  λ_max=94.5969\n",
      "[SGD | lr=0.05] Epoch 3834/4000: train_loss=0.0110  test_loss=4.3355  λ_max=96.0884\n",
      "[SGD | lr=0.05] Epoch 3835/4000: train_loss=0.0110  test_loss=4.3358  λ_max=94.0291\n",
      "[SGD | lr=0.05] Epoch 3836/4000: train_loss=0.0110  test_loss=4.3361  λ_max=94.8908\n",
      "[SGD | lr=0.05] Epoch 3837/4000: train_loss=0.0110  test_loss=4.3361  λ_max=97.1991\n",
      "[SGD | lr=0.05] Iter 61400: loss=0.0108\n",
      "[SGD | lr=0.05] Epoch 3838/4000: train_loss=0.0110  test_loss=4.3363  λ_max=96.5419\n",
      "[SGD | lr=0.05] Epoch 3839/4000: train_loss=0.0110  test_loss=4.3367  λ_max=94.9985\n",
      "[SGD | lr=0.05] Epoch 3840/4000: train_loss=0.0110  test_loss=4.3368  λ_max=95.9326\n",
      "[SGD | lr=0.05] Epoch 3841/4000: train_loss=0.0110  test_loss=4.3371  λ_max=93.5494\n",
      "[SGD | lr=0.05] Epoch 3842/4000: train_loss=0.0109  test_loss=4.3372  λ_max=97.7867\n",
      "[SGD | lr=0.05] Epoch 3843/4000: train_loss=0.0109  test_loss=4.3375  λ_max=97.0870\n",
      "[SGD | lr=0.05] Iter 61500: loss=0.0110\n",
      "[SGD | lr=0.05] Epoch 3844/4000: train_loss=0.0109  test_loss=4.3376  λ_max=96.5784\n",
      "[SGD | lr=0.05] Epoch 3845/4000: train_loss=0.0109  test_loss=4.3379  λ_max=94.4503\n",
      "[SGD | lr=0.05] Epoch 3846/4000: train_loss=0.0109  test_loss=4.3381  λ_max=92.4069\n",
      "[SGD | lr=0.05] Epoch 3847/4000: train_loss=0.0109  test_loss=4.3384  λ_max=98.4288\n",
      "[SGD | lr=0.05] Epoch 3848/4000: train_loss=0.0109  test_loss=4.3385  λ_max=96.9688\n",
      "[SGD | lr=0.05] Epoch 3849/4000: train_loss=0.0109  test_loss=4.3386  λ_max=95.0523\n",
      "[SGD | lr=0.05] Iter 61600: loss=0.0108\n",
      "[SGD | lr=0.05] Epoch 3850/4000: train_loss=0.0109  test_loss=4.3389  λ_max=94.6383\n",
      "[SGD | lr=0.05] Epoch 3851/4000: train_loss=0.0109  test_loss=4.3392  λ_max=95.0361\n",
      "[SGD | lr=0.05] Epoch 3852/4000: train_loss=0.0109  test_loss=4.3395  λ_max=96.3239\n",
      "[SGD | lr=0.05] Epoch 3853/4000: train_loss=0.0109  test_loss=4.3396  λ_max=93.9431\n",
      "[SGD | lr=0.05] Epoch 3854/4000: train_loss=0.0109  test_loss=4.3397  λ_max=98.3396\n",
      "[SGD | lr=0.05] Epoch 3855/4000: train_loss=0.0109  test_loss=4.3401  λ_max=96.3807\n",
      "[SGD | lr=0.05] Epoch 3856/4000: train_loss=0.0109  test_loss=4.3402  λ_max=95.9352\n",
      "[SGD | lr=0.05] Iter 61700: loss=0.0108\n",
      "[SGD | lr=0.05] Epoch 3857/4000: train_loss=0.0109  test_loss=4.3404  λ_max=95.6116\n",
      "[SGD | lr=0.05] Epoch 3858/4000: train_loss=0.0109  test_loss=4.3407  λ_max=94.4565\n",
      "[SGD | lr=0.05] Epoch 3859/4000: train_loss=0.0109  test_loss=4.3409  λ_max=91.6013\n",
      "[SGD | lr=0.05] Epoch 3860/4000: train_loss=0.0109  test_loss=4.3411  λ_max=97.6947\n",
      "[SGD | lr=0.05] Epoch 3861/4000: train_loss=0.0109  test_loss=4.3413  λ_max=92.1928\n",
      "[SGD | lr=0.05] Epoch 3862/4000: train_loss=0.0109  test_loss=4.3416  λ_max=91.9375\n",
      "[SGD | lr=0.05] Iter 61800: loss=0.0110\n",
      "[SGD | lr=0.05] Epoch 3863/4000: train_loss=0.0109  test_loss=4.3416  λ_max=93.0218\n",
      "[SGD | lr=0.05] Epoch 3864/4000: train_loss=0.0109  test_loss=4.3419  λ_max=93.1814\n",
      "[SGD | lr=0.05] Epoch 3865/4000: train_loss=0.0109  test_loss=4.3423  λ_max=95.3755\n",
      "[SGD | lr=0.05] Epoch 3866/4000: train_loss=0.0109  test_loss=4.3424  λ_max=94.2542\n",
      "[SGD | lr=0.05] Epoch 3867/4000: train_loss=0.0108  test_loss=4.3428  λ_max=98.2962\n",
      "[SGD | lr=0.05] Epoch 3868/4000: train_loss=0.0108  test_loss=4.3429  λ_max=91.1201\n",
      "[SGD | lr=0.05] Iter 61900: loss=0.0109\n",
      "[SGD | lr=0.05] Epoch 3869/4000: train_loss=0.0108  test_loss=4.3431  λ_max=95.8093\n",
      "[SGD | lr=0.05] Epoch 3870/4000: train_loss=0.0108  test_loss=4.3432  λ_max=96.0105\n",
      "[SGD | lr=0.05] Epoch 3871/4000: train_loss=0.0108  test_loss=4.3435  λ_max=94.3816\n",
      "[SGD | lr=0.05] Epoch 3872/4000: train_loss=0.0108  test_loss=4.3437  λ_max=94.6746\n",
      "[SGD | lr=0.05] Epoch 3873/4000: train_loss=0.0108  test_loss=4.3440  λ_max=95.0340\n",
      "[SGD | lr=0.05] Epoch 3874/4000: train_loss=0.0108  test_loss=4.3441  λ_max=96.3986\n",
      "[SGD | lr=0.05] Iter 62000: loss=0.0112\n",
      "[SGD | lr=0.05] Epoch 3875/4000: train_loss=0.0108  test_loss=4.3442  λ_max=96.5249\n",
      "[SGD | lr=0.05] Epoch 3876/4000: train_loss=0.0108  test_loss=4.3445  λ_max=95.2340\n",
      "[SGD | lr=0.05] Epoch 3877/4000: train_loss=0.0108  test_loss=4.3447  λ_max=94.9215\n",
      "[SGD | lr=0.05] Epoch 3878/4000: train_loss=0.0108  test_loss=4.3450  λ_max=97.6286\n",
      "[SGD | lr=0.05] Epoch 3879/4000: train_loss=0.0108  test_loss=4.3451  λ_max=97.7838\n",
      "[SGD | lr=0.05] Epoch 3880/4000: train_loss=0.0108  test_loss=4.3454  λ_max=94.1508\n",
      "[SGD | lr=0.05] Epoch 3881/4000: train_loss=0.0108  test_loss=4.3455  λ_max=96.8522\n",
      "[SGD | lr=0.05] Iter 62100: loss=0.0107\n",
      "[SGD | lr=0.05] Epoch 3882/4000: train_loss=0.0108  test_loss=4.3458  λ_max=98.5124\n",
      "[SGD | lr=0.05] Epoch 3883/4000: train_loss=0.0108  test_loss=4.3461  λ_max=92.9188\n",
      "[SGD | lr=0.05] Epoch 3884/4000: train_loss=0.0108  test_loss=4.3463  λ_max=94.4959\n",
      "[SGD | lr=0.05] Epoch 3885/4000: train_loss=0.0108  test_loss=4.3465  λ_max=95.3226\n",
      "[SGD | lr=0.05] Epoch 3886/4000: train_loss=0.0108  test_loss=4.3468  λ_max=94.9333\n",
      "[SGD | lr=0.05] Epoch 3887/4000: train_loss=0.0108  test_loss=4.3467  λ_max=96.1294\n",
      "[SGD | lr=0.05] Iter 62200: loss=0.0108\n",
      "[SGD | lr=0.05] Epoch 3888/4000: train_loss=0.0108  test_loss=4.3469  λ_max=92.3023\n",
      "[SGD | lr=0.05] Epoch 3889/4000: train_loss=0.0108  test_loss=4.3471  λ_max=94.6262\n",
      "[SGD | lr=0.05] Epoch 3890/4000: train_loss=0.0108  test_loss=4.3477  λ_max=91.5333\n",
      "[SGD | lr=0.05] Epoch 3891/4000: train_loss=0.0108  test_loss=4.3478  λ_max=93.6209\n",
      "[SGD | lr=0.05] Epoch 3892/4000: train_loss=0.0108  test_loss=4.3481  λ_max=95.1580\n",
      "[SGD | lr=0.05] Epoch 3893/4000: train_loss=0.0107  test_loss=4.3483  λ_max=96.2497\n",
      "[SGD | lr=0.05] Iter 62300: loss=0.0107\n",
      "[SGD | lr=0.05] Epoch 3894/4000: train_loss=0.0107  test_loss=4.3484  λ_max=98.4214\n",
      "[SGD | lr=0.05] Epoch 3895/4000: train_loss=0.0107  test_loss=4.3486  λ_max=97.1806\n",
      "[SGD | lr=0.05] Epoch 3896/4000: train_loss=0.0107  test_loss=4.3487  λ_max=94.6909\n",
      "[SGD | lr=0.05] Epoch 3897/4000: train_loss=0.0107  test_loss=4.3489  λ_max=96.3015\n",
      "[SGD | lr=0.05] Epoch 3898/4000: train_loss=0.0107  test_loss=4.3495  λ_max=94.0571\n",
      "[SGD | lr=0.05] Epoch 3899/4000: train_loss=0.0107  test_loss=4.3495  λ_max=95.6501\n",
      "[SGD | lr=0.05] Iter 62400: loss=0.0107\n",
      "[SGD | lr=0.05] Epoch 3900/4000: train_loss=0.0107  test_loss=4.3497  λ_max=95.9580\n",
      "[SGD | lr=0.05] Epoch 3901/4000: train_loss=0.0107  test_loss=4.3499  λ_max=94.7591\n",
      "[SGD | lr=0.05] Epoch 3902/4000: train_loss=0.0107  test_loss=4.3501  λ_max=95.3509\n",
      "[SGD | lr=0.05] Epoch 3903/4000: train_loss=0.0107  test_loss=4.3503  λ_max=96.6820\n",
      "[SGD | lr=0.05] Epoch 3904/4000: train_loss=0.0107  test_loss=4.3506  λ_max=92.8185\n",
      "[SGD | lr=0.05] Epoch 3905/4000: train_loss=0.0107  test_loss=4.3507  λ_max=95.0709\n",
      "[SGD | lr=0.05] Epoch 3906/4000: train_loss=0.0107  test_loss=4.3509  λ_max=95.8424\n",
      "[SGD | lr=0.05] Iter 62500: loss=0.0108\n",
      "[SGD | lr=0.05] Epoch 3907/4000: train_loss=0.0107  test_loss=4.3511  λ_max=95.4393\n",
      "[SGD | lr=0.05] Epoch 3908/4000: train_loss=0.0107  test_loss=4.3514  λ_max=92.5117\n",
      "[SGD | lr=0.05] Epoch 3909/4000: train_loss=0.0107  test_loss=4.3516  λ_max=94.7218\n",
      "[SGD | lr=0.05] Epoch 3910/4000: train_loss=0.0107  test_loss=4.3517  λ_max=98.2613\n",
      "[SGD | lr=0.05] Epoch 3911/4000: train_loss=0.0107  test_loss=4.3520  λ_max=96.7888\n",
      "[SGD | lr=0.05] Epoch 3912/4000: train_loss=0.0107  test_loss=4.3522  λ_max=95.6480\n",
      "[SGD | lr=0.05] Iter 62600: loss=0.0106\n",
      "[SGD | lr=0.05] Epoch 3913/4000: train_loss=0.0107  test_loss=4.3524  λ_max=95.7812\n",
      "[SGD | lr=0.05] Epoch 3914/4000: train_loss=0.0107  test_loss=4.3525  λ_max=92.7285\n",
      "[SGD | lr=0.05] Epoch 3915/4000: train_loss=0.0107  test_loss=4.3529  λ_max=98.0568\n",
      "[SGD | lr=0.05] Epoch 3916/4000: train_loss=0.0107  test_loss=4.3530  λ_max=95.7309\n",
      "[SGD | lr=0.05] Epoch 3917/4000: train_loss=0.0107  test_loss=4.3533  λ_max=98.2111\n",
      "[SGD | lr=0.05] Epoch 3918/4000: train_loss=0.0107  test_loss=4.3535  λ_max=96.6592\n",
      "[SGD | lr=0.05] Iter 62700: loss=0.0107\n",
      "[SGD | lr=0.05] Epoch 3919/4000: train_loss=0.0106  test_loss=4.3535  λ_max=98.8465\n",
      "[SGD | lr=0.05] Epoch 3920/4000: train_loss=0.0106  test_loss=4.3538  λ_max=94.6024\n",
      "[SGD | lr=0.05] Epoch 3921/4000: train_loss=0.0106  test_loss=4.3540  λ_max=98.8263\n",
      "[SGD | lr=0.05] Epoch 3922/4000: train_loss=0.0106  test_loss=4.3542  λ_max=95.0392\n",
      "[SGD | lr=0.05] Epoch 3923/4000: train_loss=0.0106  test_loss=4.3546  λ_max=96.3426\n",
      "[SGD | lr=0.05] Epoch 3924/4000: train_loss=0.0106  test_loss=4.3546  λ_max=96.6857\n",
      "[SGD | lr=0.05] Iter 62800: loss=0.0107\n",
      "[SGD | lr=0.05] Epoch 3925/4000: train_loss=0.0106  test_loss=4.3548  λ_max=95.5768\n",
      "[SGD | lr=0.05] Epoch 3926/4000: train_loss=0.0106  test_loss=4.3550  λ_max=96.7989\n",
      "[SGD | lr=0.05] Epoch 3927/4000: train_loss=0.0106  test_loss=4.3553  λ_max=99.2294\n",
      "[SGD | lr=0.05] Epoch 3928/4000: train_loss=0.0106  test_loss=4.3555  λ_max=95.2462\n",
      "[SGD | lr=0.05] Epoch 3929/4000: train_loss=0.0106  test_loss=4.3557  λ_max=96.9647\n",
      "[SGD | lr=0.05] Epoch 3930/4000: train_loss=0.0106  test_loss=4.3558  λ_max=99.5977\n",
      "[SGD | lr=0.05] Epoch 3931/4000: train_loss=0.0106  test_loss=4.3561  λ_max=92.0621\n",
      "[SGD | lr=0.05] Iter 62900: loss=0.0106\n",
      "[SGD | lr=0.05] Epoch 3932/4000: train_loss=0.0106  test_loss=4.3563  λ_max=97.3468\n",
      "[SGD | lr=0.05] Epoch 3933/4000: train_loss=0.0106  test_loss=4.3565  λ_max=97.6165\n",
      "[SGD | lr=0.05] Epoch 3934/4000: train_loss=0.0106  test_loss=4.3567  λ_max=95.4242\n",
      "[SGD | lr=0.05] Epoch 3935/4000: train_loss=0.0106  test_loss=4.3569  λ_max=95.2613\n",
      "[SGD | lr=0.05] Epoch 3936/4000: train_loss=0.0106  test_loss=4.3571  λ_max=94.2860\n",
      "[SGD | lr=0.05] Epoch 3937/4000: train_loss=0.0106  test_loss=4.3574  λ_max=94.5922\n",
      "[SGD | lr=0.05] Iter 63000: loss=0.0105\n",
      "[SGD | lr=0.05] Epoch 3938/4000: train_loss=0.0106  test_loss=4.3576  λ_max=96.6080\n",
      "[SGD | lr=0.05] Epoch 3939/4000: train_loss=0.0106  test_loss=4.3578  λ_max=94.2841\n",
      "[SGD | lr=0.05] Epoch 3940/4000: train_loss=0.0106  test_loss=4.3579  λ_max=93.9986\n",
      "[SGD | lr=0.05] Epoch 3941/4000: train_loss=0.0106  test_loss=4.3584  λ_max=96.5126\n",
      "[SGD | lr=0.05] Epoch 3942/4000: train_loss=0.0106  test_loss=4.3584  λ_max=95.7088\n",
      "[SGD | lr=0.05] Epoch 3943/4000: train_loss=0.0106  test_loss=4.3587  λ_max=97.1407\n",
      "[SGD | lr=0.05] Iter 63100: loss=0.0105\n",
      "[SGD | lr=0.05] Epoch 3944/4000: train_loss=0.0106  test_loss=4.3587  λ_max=94.6009\n",
      "[SGD | lr=0.05] Epoch 3945/4000: train_loss=0.0105  test_loss=4.3592  λ_max=94.7190\n",
      "[SGD | lr=0.05] Epoch 3946/4000: train_loss=0.0105  test_loss=4.3594  λ_max=95.0032\n",
      "[SGD | lr=0.05] Epoch 3947/4000: train_loss=0.0105  test_loss=4.3595  λ_max=98.2833\n",
      "[SGD | lr=0.05] Epoch 3948/4000: train_loss=0.0105  test_loss=4.3596  λ_max=98.6384\n",
      "[SGD | lr=0.05] Epoch 3949/4000: train_loss=0.0105  test_loss=4.3600  λ_max=98.3754\n",
      "[SGD | lr=0.05] Iter 63200: loss=0.0107\n",
      "[SGD | lr=0.05] Epoch 3950/4000: train_loss=0.0105  test_loss=4.3603  λ_max=95.1271\n",
      "[SGD | lr=0.05] Epoch 3951/4000: train_loss=0.0105  test_loss=4.3604  λ_max=99.0041\n",
      "[SGD | lr=0.05] Epoch 3952/4000: train_loss=0.0105  test_loss=4.3605  λ_max=97.4436\n",
      "[SGD | lr=0.05] Epoch 3953/4000: train_loss=0.0105  test_loss=4.3607  λ_max=97.4182\n",
      "[SGD | lr=0.05] Epoch 3954/4000: train_loss=0.0105  test_loss=4.3609  λ_max=97.1696\n",
      "[SGD | lr=0.05] Epoch 3955/4000: train_loss=0.0105  test_loss=4.3612  λ_max=96.0658\n",
      "[SGD | lr=0.05] Epoch 3956/4000: train_loss=0.0105  test_loss=4.3613  λ_max=95.4706\n",
      "[SGD | lr=0.05] Iter 63300: loss=0.0105\n",
      "[SGD | lr=0.05] Epoch 3957/4000: train_loss=0.0105  test_loss=4.3616  λ_max=96.3307\n",
      "[SGD | lr=0.05] Epoch 3958/4000: train_loss=0.0105  test_loss=4.3618  λ_max=95.5620\n",
      "[SGD | lr=0.05] Epoch 3959/4000: train_loss=0.0105  test_loss=4.3620  λ_max=95.6776\n",
      "[SGD | lr=0.05] Epoch 3960/4000: train_loss=0.0105  test_loss=4.3623  λ_max=96.0190\n",
      "[SGD | lr=0.05] Epoch 3961/4000: train_loss=0.0105  test_loss=4.3625  λ_max=98.0659\n",
      "[SGD | lr=0.05] Epoch 3962/4000: train_loss=0.0105  test_loss=4.3625  λ_max=95.3026\n",
      "[SGD | lr=0.05] Iter 63400: loss=0.0105\n",
      "[SGD | lr=0.05] Epoch 3963/4000: train_loss=0.0105  test_loss=4.3626  λ_max=95.4615\n",
      "[SGD | lr=0.05] Epoch 3964/4000: train_loss=0.0105  test_loss=4.3631  λ_max=97.9579\n",
      "[SGD | lr=0.05] Epoch 3965/4000: train_loss=0.0105  test_loss=4.3632  λ_max=94.4931\n",
      "[SGD | lr=0.05] Epoch 3966/4000: train_loss=0.0105  test_loss=4.3635  λ_max=98.9945\n",
      "[SGD | lr=0.05] Epoch 3967/4000: train_loss=0.0105  test_loss=4.3636  λ_max=96.0560\n",
      "[SGD | lr=0.05] Epoch 3968/4000: train_loss=0.0105  test_loss=4.3639  λ_max=98.9428\n",
      "[SGD | lr=0.05] Iter 63500: loss=0.0104\n",
      "[SGD | lr=0.05] Epoch 3969/4000: train_loss=0.0105  test_loss=4.3641  λ_max=92.2089\n",
      "[SGD | lr=0.05] Epoch 3970/4000: train_loss=0.0105  test_loss=4.3643  λ_max=97.5149\n",
      "[SGD | lr=0.05] Epoch 3971/4000: train_loss=0.0105  test_loss=4.3644  λ_max=97.2277\n",
      "[SGD | lr=0.05] Epoch 3972/4000: train_loss=0.0105  test_loss=4.3646  λ_max=97.4316\n",
      "[SGD | lr=0.05] Epoch 3973/4000: train_loss=0.0104  test_loss=4.3650  λ_max=97.3875\n",
      "[SGD | lr=0.05] Epoch 3974/4000: train_loss=0.0104  test_loss=4.3652  λ_max=97.3025\n",
      "[SGD | lr=0.05] Iter 63600: loss=0.0104\n",
      "[SGD | lr=0.05] Epoch 3975/4000: train_loss=0.0104  test_loss=4.3654  λ_max=98.4533\n",
      "[SGD | lr=0.05] Epoch 3976/4000: train_loss=0.0104  test_loss=4.3654  λ_max=96.5143\n",
      "[SGD | lr=0.05] Epoch 3977/4000: train_loss=0.0104  test_loss=4.3658  λ_max=98.6927\n",
      "[SGD | lr=0.05] Epoch 3978/4000: train_loss=0.0104  test_loss=4.3659  λ_max=96.2548\n",
      "[SGD | lr=0.05] Epoch 3979/4000: train_loss=0.0104  test_loss=4.3662  λ_max=99.1207\n",
      "[SGD | lr=0.05] Epoch 3980/4000: train_loss=0.0104  test_loss=4.3663  λ_max=96.5221\n",
      "[SGD | lr=0.05] Epoch 3981/4000: train_loss=0.0104  test_loss=4.3666  λ_max=100.3876\n",
      "[SGD | lr=0.05] Iter 63700: loss=0.0105\n",
      "[SGD | lr=0.05] Epoch 3982/4000: train_loss=0.0104  test_loss=4.3669  λ_max=96.6825\n",
      "[SGD | lr=0.05] Epoch 3983/4000: train_loss=0.0104  test_loss=4.3670  λ_max=93.3138\n",
      "[SGD | lr=0.05] Epoch 3984/4000: train_loss=0.0104  test_loss=4.3671  λ_max=96.3501\n",
      "[SGD | lr=0.05] Epoch 3985/4000: train_loss=0.0104  test_loss=4.3674  λ_max=98.4023\n",
      "[SGD | lr=0.05] Epoch 3986/4000: train_loss=0.0104  test_loss=4.3675  λ_max=95.0948\n",
      "[SGD | lr=0.05] Epoch 3987/4000: train_loss=0.0104  test_loss=4.3678  λ_max=97.0879\n",
      "[SGD | lr=0.05] Iter 63800: loss=0.0102\n",
      "[SGD | lr=0.05] Epoch 3988/4000: train_loss=0.0104  test_loss=4.3679  λ_max=94.5355\n",
      "[SGD | lr=0.05] Epoch 3989/4000: train_loss=0.0104  test_loss=4.3683  λ_max=96.6513\n",
      "[SGD | lr=0.05] Epoch 3990/4000: train_loss=0.0104  test_loss=4.3685  λ_max=95.7220\n",
      "[SGD | lr=0.05] Epoch 3991/4000: train_loss=0.0104  test_loss=4.3687  λ_max=96.2080\n",
      "[SGD | lr=0.05] Epoch 3992/4000: train_loss=0.0104  test_loss=4.3689  λ_max=95.0997\n",
      "[SGD | lr=0.05] Epoch 3993/4000: train_loss=0.0104  test_loss=4.3690  λ_max=97.5969\n",
      "[SGD | lr=0.05] Iter 63900: loss=0.0104\n",
      "[SGD | lr=0.05] Epoch 3994/4000: train_loss=0.0104  test_loss=4.3692  λ_max=98.7352\n",
      "[SGD | lr=0.05] Epoch 3995/4000: train_loss=0.0104  test_loss=4.3695  λ_max=95.0709\n",
      "[SGD | lr=0.05] Epoch 3996/4000: train_loss=0.0104  test_loss=4.3696  λ_max=93.8386\n",
      "[SGD | lr=0.05] Epoch 3997/4000: train_loss=0.0104  test_loss=4.3699  λ_max=93.9594\n",
      "[SGD | lr=0.05] Epoch 3998/4000: train_loss=0.0104  test_loss=4.3702  λ_max=96.3485\n",
      "[SGD | lr=0.05] Epoch 3999/4000: train_loss=0.0104  test_loss=4.3703  λ_max=95.1211\n",
      "[SGD | lr=0.05] Iter 64000: loss=0.0106\n",
      "[SGD | lr=0.05] Epoch 4000/4000: train_loss=0.0104  test_loss=4.3704  λ_max=95.2832\n",
      "Saved data → results/SGD_lr0.05.npz\n",
      "Saved plot → results/SGD_lr0.05_sharpness.png\n",
      "\n",
      "### Running SGD with lr=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (/home/aradilla/.cache/huggingface/datasets/sapientinc___csv/sapientinc--sudoku-extreme-798989c95bd556dd/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n",
      "Found cached dataset csv (/home/aradilla/.cache/huggingface/datasets/sapientinc___csv/sapientinc--sudoku-extreme-798989c95bd556dd/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SGD | lr=0.01] Epoch 1/4000: train_loss=2.3298  test_loss=2.3227  λ_max=5.1155\n",
      "[SGD | lr=0.01] Epoch 2/4000: train_loss=2.3144  test_loss=2.3099  λ_max=5.2819\n",
      "[SGD | lr=0.01] Epoch 3/4000: train_loss=2.3000  test_loss=2.2980  λ_max=5.1123\n",
      "[SGD | lr=0.01] Epoch 4/4000: train_loss=2.2869  test_loss=2.2867  λ_max=5.1473\n",
      "[SGD | lr=0.01] Epoch 5/4000: train_loss=2.2751  test_loss=2.2763  λ_max=4.7128\n",
      "[SGD | lr=0.01] Epoch 6/4000: train_loss=2.2642  test_loss=2.2670  λ_max=4.4646\n",
      "[SGD | lr=0.01] Iter 100: loss=2.2523\n",
      "[SGD | lr=0.01] Epoch 7/4000: train_loss=2.2547  test_loss=2.2590  λ_max=4.4677\n",
      "[SGD | lr=0.01] Epoch 8/4000: train_loss=2.2470  test_loss=2.2519  λ_max=4.5463\n",
      "[SGD | lr=0.01] Epoch 9/4000: train_loss=2.2398  test_loss=2.2459  λ_max=4.3779\n",
      "[SGD | lr=0.01] Epoch 10/4000: train_loss=2.2338  test_loss=2.2406  λ_max=4.2055\n",
      "[SGD | lr=0.01] Epoch 11/4000: train_loss=2.2287  test_loss=2.2361  λ_max=4.0055\n",
      "[SGD | lr=0.01] Epoch 12/4000: train_loss=2.2242  test_loss=2.2321  λ_max=3.8738\n",
      "[SGD | lr=0.01] Iter 200: loss=2.2204\n",
      "[SGD | lr=0.01] Epoch 13/4000: train_loss=2.2202  test_loss=2.2288  λ_max=3.6618\n",
      "[SGD | lr=0.01] Epoch 14/4000: train_loss=2.2168  test_loss=2.2259  λ_max=3.8561\n",
      "[SGD | lr=0.01] Epoch 15/4000: train_loss=2.2139  test_loss=2.2234  λ_max=3.6469\n",
      "[SGD | lr=0.01] Epoch 16/4000: train_loss=2.2112  test_loss=2.2212  λ_max=3.5208\n",
      "[SGD | lr=0.01] Epoch 17/4000: train_loss=2.2092  test_loss=2.2193  λ_max=3.5509\n",
      "[SGD | lr=0.01] Epoch 18/4000: train_loss=2.2073  test_loss=2.2176  λ_max=3.6264\n",
      "[SGD | lr=0.01] Iter 300: loss=2.2019\n",
      "[SGD | lr=0.01] Epoch 19/4000: train_loss=2.2055  test_loss=2.2162  λ_max=3.4096\n",
      "[SGD | lr=0.01] Epoch 20/4000: train_loss=2.2039  test_loss=2.2150  λ_max=3.3848\n",
      "[SGD | lr=0.01] Epoch 21/4000: train_loss=2.2027  test_loss=2.2139  λ_max=3.3563\n",
      "[SGD | lr=0.01] Epoch 22/4000: train_loss=2.2016  test_loss=2.2129  λ_max=3.1678\n",
      "[SGD | lr=0.01] Epoch 23/4000: train_loss=2.2004  test_loss=2.2120  λ_max=3.2849\n",
      "[SGD | lr=0.01] Epoch 24/4000: train_loss=2.1995  test_loss=2.2114  λ_max=3.2330\n",
      "[SGD | lr=0.01] Iter 400: loss=2.1940\n",
      "[SGD | lr=0.01] Epoch 25/4000: train_loss=2.1985  test_loss=2.2108  λ_max=3.0846\n",
      "[SGD | lr=0.01] Epoch 26/4000: train_loss=2.1979  test_loss=2.2102  λ_max=3.1208\n",
      "[SGD | lr=0.01] Epoch 27/4000: train_loss=2.1972  test_loss=2.2097  λ_max=3.0955\n",
      "[SGD | lr=0.01] Epoch 28/4000: train_loss=2.1965  test_loss=2.2092  λ_max=3.0811\n",
      "[SGD | lr=0.01] Epoch 29/4000: train_loss=2.1958  test_loss=2.2088  λ_max=3.0941\n",
      "[SGD | lr=0.01] Epoch 30/4000: train_loss=2.1953  test_loss=2.2084  λ_max=3.0878\n",
      "[SGD | lr=0.01] Epoch 31/4000: train_loss=2.1946  test_loss=2.2081  λ_max=2.9542\n",
      "[SGD | lr=0.01] Iter 500: loss=2.1955\n",
      "[SGD | lr=0.01] Epoch 32/4000: train_loss=2.1942  test_loss=2.2078  λ_max=2.9515\n",
      "[SGD | lr=0.01] Epoch 33/4000: train_loss=2.1936  test_loss=2.2075  λ_max=2.9345\n",
      "[SGD | lr=0.01] Epoch 34/4000: train_loss=2.1934  test_loss=2.2072  λ_max=2.9180\n",
      "[SGD | lr=0.01] Epoch 35/4000: train_loss=2.1929  test_loss=2.2070  λ_max=2.9430\n",
      "[SGD | lr=0.01] Epoch 36/4000: train_loss=2.1925  test_loss=2.2067  λ_max=2.8288\n",
      "[SGD | lr=0.01] Epoch 37/4000: train_loss=2.1920  test_loss=2.2065  λ_max=2.8879\n",
      "[SGD | lr=0.01] Iter 600: loss=2.1898\n",
      "[SGD | lr=0.01] Epoch 38/4000: train_loss=2.1918  test_loss=2.2063  λ_max=2.8149\n",
      "[SGD | lr=0.01] Epoch 39/4000: train_loss=2.1914  test_loss=2.2061  λ_max=2.9189\n",
      "[SGD | lr=0.01] Epoch 40/4000: train_loss=2.1911  test_loss=2.2059  λ_max=2.7160\n",
      "[SGD | lr=0.01] Epoch 41/4000: train_loss=2.1907  test_loss=2.2057  λ_max=2.8018\n",
      "[SGD | lr=0.01] Epoch 42/4000: train_loss=2.1904  test_loss=2.2055  λ_max=2.8147\n",
      "[SGD | lr=0.01] Epoch 43/4000: train_loss=2.1901  test_loss=2.2053  λ_max=2.8142\n",
      "[SGD | lr=0.01] Iter 700: loss=2.1908\n",
      "[SGD | lr=0.01] Epoch 44/4000: train_loss=2.1898  test_loss=2.2052  λ_max=2.8391\n",
      "[SGD | lr=0.01] Epoch 45/4000: train_loss=2.1896  test_loss=2.2051  λ_max=2.8046\n",
      "[SGD | lr=0.01] Epoch 46/4000: train_loss=2.1892  test_loss=2.2049  λ_max=2.8147\n",
      "[SGD | lr=0.01] Epoch 47/4000: train_loss=2.1889  test_loss=2.2048  λ_max=2.8188\n",
      "[SGD | lr=0.01] Epoch 48/4000: train_loss=2.1886  test_loss=2.2047  λ_max=2.8069\n",
      "[SGD | lr=0.01] Epoch 49/4000: train_loss=2.1884  test_loss=2.2045  λ_max=2.7869\n",
      "[SGD | lr=0.01] Iter 800: loss=2.1893\n",
      "[SGD | lr=0.01] Epoch 50/4000: train_loss=2.1882  test_loss=2.2044  λ_max=2.7815\n",
      "[SGD | lr=0.01] Epoch 51/4000: train_loss=2.1879  test_loss=2.2043  λ_max=2.7973\n",
      "[SGD | lr=0.01] Epoch 52/4000: train_loss=2.1877  test_loss=2.2042  λ_max=2.6694\n",
      "[SGD | lr=0.01] Epoch 53/4000: train_loss=2.1873  test_loss=2.2041  λ_max=2.7124\n",
      "[SGD | lr=0.01] Epoch 54/4000: train_loss=2.1871  test_loss=2.2040  λ_max=2.7420\n",
      "[SGD | lr=0.01] Epoch 55/4000: train_loss=2.1870  test_loss=2.2039  λ_max=2.7565\n",
      "[SGD | lr=0.01] Epoch 56/4000: train_loss=2.1866  test_loss=2.2038  λ_max=2.7541\n",
      "[SGD | lr=0.01] Iter 900: loss=2.1859\n",
      "[SGD | lr=0.01] Epoch 57/4000: train_loss=2.1864  test_loss=2.2037  λ_max=2.6887\n",
      "[SGD | lr=0.01] Epoch 58/4000: train_loss=2.1861  test_loss=2.2037  λ_max=2.8193\n",
      "[SGD | lr=0.01] Epoch 59/4000: train_loss=2.1859  test_loss=2.2036  λ_max=2.7642\n",
      "[SGD | lr=0.01] Epoch 60/4000: train_loss=2.1856  test_loss=2.2035  λ_max=2.7071\n",
      "[SGD | lr=0.01] Epoch 61/4000: train_loss=2.1854  test_loss=2.2035  λ_max=2.8098\n",
      "[SGD | lr=0.01] Epoch 62/4000: train_loss=2.1852  test_loss=2.2034  λ_max=2.7682\n",
      "[SGD | lr=0.01] Iter 1000: loss=2.1852\n",
      "[SGD | lr=0.01] Epoch 63/4000: train_loss=2.1850  test_loss=2.2033  λ_max=2.7559\n",
      "[SGD | lr=0.01] Epoch 64/4000: train_loss=2.1847  test_loss=2.2033  λ_max=2.6977\n",
      "[SGD | lr=0.01] Epoch 65/4000: train_loss=2.1845  test_loss=2.2032  λ_max=2.7840\n",
      "[SGD | lr=0.01] Epoch 66/4000: train_loss=2.1843  test_loss=2.2032  λ_max=2.7467\n",
      "[SGD | lr=0.01] Epoch 67/4000: train_loss=2.1839  test_loss=2.2031  λ_max=2.7402\n",
      "[SGD | lr=0.01] Epoch 68/4000: train_loss=2.1838  test_loss=2.2031  λ_max=2.6881\n",
      "[SGD | lr=0.01] Iter 1100: loss=2.1844\n",
      "[SGD | lr=0.01] Epoch 69/4000: train_loss=2.1835  test_loss=2.2030  λ_max=2.7187\n",
      "[SGD | lr=0.01] Epoch 70/4000: train_loss=2.1832  test_loss=2.2030  λ_max=2.7714\n",
      "[SGD | lr=0.01] Epoch 71/4000: train_loss=2.1830  test_loss=2.2029  λ_max=2.8083\n",
      "[SGD | lr=0.01] Epoch 72/4000: train_loss=2.1827  test_loss=2.2029  λ_max=2.7649\n",
      "[SGD | lr=0.01] Epoch 73/4000: train_loss=2.1825  test_loss=2.2028  λ_max=2.8221\n",
      "[SGD | lr=0.01] Epoch 74/4000: train_loss=2.1822  test_loss=2.2028  λ_max=2.8117\n",
      "[SGD | lr=0.01] Iter 1200: loss=2.1826\n",
      "[SGD | lr=0.01] Epoch 75/4000: train_loss=2.1820  test_loss=2.2028  λ_max=2.8434\n",
      "[SGD | lr=0.01] Epoch 76/4000: train_loss=2.1818  test_loss=2.2027  λ_max=2.8455\n",
      "[SGD | lr=0.01] Epoch 77/4000: train_loss=2.1815  test_loss=2.2027  λ_max=2.8740\n",
      "[SGD | lr=0.01] Epoch 78/4000: train_loss=2.1812  test_loss=2.2027  λ_max=2.8215\n",
      "[SGD | lr=0.01] Epoch 79/4000: train_loss=2.1810  test_loss=2.2027  λ_max=2.8468\n",
      "[SGD | lr=0.01] Epoch 80/4000: train_loss=2.1807  test_loss=2.2026  λ_max=2.7817\n",
      "[SGD | lr=0.01] Epoch 81/4000: train_loss=2.1805  test_loss=2.2026  λ_max=2.8203\n",
      "[SGD | lr=0.01] Iter 1300: loss=2.1818\n",
      "[SGD | lr=0.01] Epoch 82/4000: train_loss=2.1802  test_loss=2.2025  λ_max=2.7787\n",
      "[SGD | lr=0.01] Epoch 83/4000: train_loss=2.1800  test_loss=2.2025  λ_max=2.8735\n",
      "[SGD | lr=0.01] Epoch 84/4000: train_loss=2.1797  test_loss=2.2025  λ_max=2.8441\n",
      "[SGD | lr=0.01] Epoch 85/4000: train_loss=2.1795  test_loss=2.2024  λ_max=2.9534\n",
      "[SGD | lr=0.01] Epoch 86/4000: train_loss=2.1793  test_loss=2.2025  λ_max=2.9035\n",
      "[SGD | lr=0.01] Epoch 87/4000: train_loss=2.1789  test_loss=2.2024  λ_max=2.8388\n",
      "[SGD | lr=0.01] Iter 1400: loss=2.1786\n",
      "[SGD | lr=0.01] Epoch 88/4000: train_loss=2.1786  test_loss=2.2024  λ_max=2.7909\n",
      "[SGD | lr=0.01] Epoch 89/4000: train_loss=2.1783  test_loss=2.2024  λ_max=2.9406\n",
      "[SGD | lr=0.01] Epoch 90/4000: train_loss=2.1781  test_loss=2.2024  λ_max=2.8773\n",
      "[SGD | lr=0.01] Epoch 91/4000: train_loss=2.1777  test_loss=2.2024  λ_max=2.9277\n",
      "[SGD | lr=0.01] Epoch 92/4000: train_loss=2.1775  test_loss=2.2024  λ_max=2.9434\n",
      "[SGD | lr=0.01] Epoch 93/4000: train_loss=2.1772  test_loss=2.2024  λ_max=2.9664\n",
      "[SGD | lr=0.01] Iter 1500: loss=2.1795\n",
      "[SGD | lr=0.01] Epoch 94/4000: train_loss=2.1770  test_loss=2.2023  λ_max=2.8468\n",
      "[SGD | lr=0.01] Epoch 95/4000: train_loss=2.1767  test_loss=2.2023  λ_max=2.9737\n",
      "[SGD | lr=0.01] Epoch 96/4000: train_loss=2.1763  test_loss=2.2024  λ_max=2.8739\n",
      "[SGD | lr=0.01] Epoch 97/4000: train_loss=2.1761  test_loss=2.2023  λ_max=3.0708\n",
      "[SGD | lr=0.01] Epoch 98/4000: train_loss=2.1757  test_loss=2.2023  λ_max=2.9176\n",
      "[SGD | lr=0.01] Epoch 99/4000: train_loss=2.1754  test_loss=2.2023  λ_max=3.0585\n",
      "[SGD | lr=0.01] Iter 1600: loss=2.1738\n",
      "[SGD | lr=0.01] Epoch 100/4000: train_loss=2.1751  test_loss=2.2023  λ_max=3.0352\n",
      "[SGD | lr=0.01] Epoch 101/4000: train_loss=2.1749  test_loss=2.2023  λ_max=3.1090\n",
      "[SGD | lr=0.01] Epoch 102/4000: train_loss=2.1745  test_loss=2.2023  λ_max=2.9861\n",
      "[SGD | lr=0.01] Epoch 103/4000: train_loss=2.1742  test_loss=2.2023  λ_max=3.1351\n",
      "[SGD | lr=0.01] Epoch 104/4000: train_loss=2.1738  test_loss=2.2023  λ_max=3.1324\n",
      "[SGD | lr=0.01] Epoch 105/4000: train_loss=2.1735  test_loss=2.2023  λ_max=3.1763\n",
      "[SGD | lr=0.01] Epoch 106/4000: train_loss=2.1733  test_loss=2.2023  λ_max=3.1652\n",
      "[SGD | lr=0.01] Iter 1700: loss=2.1706\n",
      "[SGD | lr=0.01] Epoch 107/4000: train_loss=2.1728  test_loss=2.2024  λ_max=3.1361\n",
      "[SGD | lr=0.01] Epoch 108/4000: train_loss=2.1725  test_loss=2.2024  λ_max=3.1057\n",
      "[SGD | lr=0.01] Epoch 109/4000: train_loss=2.1722  test_loss=2.2024  λ_max=3.1430\n",
      "[SGD | lr=0.01] Epoch 110/4000: train_loss=2.1717  test_loss=2.2025  λ_max=3.2328\n",
      "[SGD | lr=0.01] Epoch 111/4000: train_loss=2.1714  test_loss=2.2025  λ_max=3.2387\n",
      "[SGD | lr=0.01] Epoch 112/4000: train_loss=2.1710  test_loss=2.2025  λ_max=3.2503\n",
      "[SGD | lr=0.01] Iter 1800: loss=2.1708\n",
      "[SGD | lr=0.01] Epoch 113/4000: train_loss=2.1706  test_loss=2.2025  λ_max=3.3632\n",
      "[SGD | lr=0.01] Epoch 114/4000: train_loss=2.1704  test_loss=2.2025  λ_max=3.2357\n",
      "[SGD | lr=0.01] Epoch 115/4000: train_loss=2.1699  test_loss=2.2026  λ_max=3.3680\n",
      "[SGD | lr=0.01] Epoch 116/4000: train_loss=2.1695  test_loss=2.2026  λ_max=3.2943\n",
      "[SGD | lr=0.01] Epoch 117/4000: train_loss=2.1693  test_loss=2.2027  λ_max=3.3442\n",
      "[SGD | lr=0.01] Epoch 118/4000: train_loss=2.1687  test_loss=2.2027  λ_max=3.3704\n",
      "[SGD | lr=0.01] Iter 1900: loss=2.1686\n",
      "[SGD | lr=0.01] Epoch 119/4000: train_loss=2.1683  test_loss=2.2027  λ_max=3.4217\n",
      "[SGD | lr=0.01] Epoch 120/4000: train_loss=2.1679  test_loss=2.2028  λ_max=3.4036\n",
      "[SGD | lr=0.01] Epoch 121/4000: train_loss=2.1675  test_loss=2.2029  λ_max=3.5008\n",
      "[SGD | lr=0.01] Epoch 122/4000: train_loss=2.1671  test_loss=2.2030  λ_max=3.5208\n",
      "[SGD | lr=0.01] Epoch 123/4000: train_loss=2.1666  test_loss=2.2030  λ_max=3.6508\n",
      "[SGD | lr=0.01] Epoch 124/4000: train_loss=2.1662  test_loss=2.2031  λ_max=3.6782\n",
      "[SGD | lr=0.01] Iter 2000: loss=2.1675\n",
      "[SGD | lr=0.01] Epoch 125/4000: train_loss=2.1658  test_loss=2.2031  λ_max=3.6403\n",
      "[SGD | lr=0.01] Epoch 126/4000: train_loss=2.1653  test_loss=2.2031  λ_max=3.6959\n",
      "[SGD | lr=0.01] Epoch 127/4000: train_loss=2.1648  test_loss=2.2033  λ_max=3.6195\n",
      "[SGD | lr=0.01] Epoch 128/4000: train_loss=2.1644  test_loss=2.2033  λ_max=3.5945\n",
      "[SGD | lr=0.01] Epoch 129/4000: train_loss=2.1640  test_loss=2.2034  λ_max=3.6203\n",
      "[SGD | lr=0.01] Epoch 130/4000: train_loss=2.1634  test_loss=2.2035  λ_max=3.6291\n",
      "[SGD | lr=0.01] Epoch 131/4000: train_loss=2.1630  test_loss=2.2036  λ_max=3.9185\n",
      "[SGD | lr=0.01] Iter 2100: loss=2.1628\n",
      "[SGD | lr=0.01] Epoch 132/4000: train_loss=2.1623  test_loss=2.2037  λ_max=3.9543\n",
      "[SGD | lr=0.01] Epoch 133/4000: train_loss=2.1619  test_loss=2.2038  λ_max=3.8636\n",
      "[SGD | lr=0.01] Epoch 134/4000: train_loss=2.1614  test_loss=2.2039  λ_max=3.9982\n",
      "[SGD | lr=0.01] Epoch 135/4000: train_loss=2.1609  test_loss=2.2040  λ_max=3.8711\n",
      "[SGD | lr=0.01] Epoch 136/4000: train_loss=2.1604  test_loss=2.2041  λ_max=3.9110\n",
      "[SGD | lr=0.01] Epoch 137/4000: train_loss=2.1598  test_loss=2.2042  λ_max=4.0723\n",
      "[SGD | lr=0.01] Iter 2200: loss=2.1606\n",
      "[SGD | lr=0.01] Epoch 138/4000: train_loss=2.1594  test_loss=2.2043  λ_max=4.0066\n",
      "[SGD | lr=0.01] Epoch 139/4000: train_loss=2.1587  test_loss=2.2044  λ_max=4.1198\n",
      "[SGD | lr=0.01] Epoch 140/4000: train_loss=2.1583  test_loss=2.2045  λ_max=4.2544\n",
      "[SGD | lr=0.01] Epoch 141/4000: train_loss=2.1577  test_loss=2.2046  λ_max=4.1005\n",
      "[SGD | lr=0.01] Epoch 142/4000: train_loss=2.1570  test_loss=2.2047  λ_max=4.2132\n",
      "[SGD | lr=0.01] Epoch 143/4000: train_loss=2.1564  test_loss=2.2048  λ_max=4.3628\n",
      "[SGD | lr=0.01] Iter 2300: loss=2.1536\n",
      "[SGD | lr=0.01] Epoch 144/4000: train_loss=2.1558  test_loss=2.2049  λ_max=4.2753\n",
      "[SGD | lr=0.01] Epoch 145/4000: train_loss=2.1553  test_loss=2.2051  λ_max=4.2660\n",
      "[SGD | lr=0.01] Epoch 146/4000: train_loss=2.1547  test_loss=2.2053  λ_max=4.4433\n",
      "[SGD | lr=0.01] Epoch 147/4000: train_loss=2.1540  test_loss=2.2054  λ_max=4.3195\n",
      "[SGD | lr=0.01] Epoch 148/4000: train_loss=2.1534  test_loss=2.2055  λ_max=4.3989\n",
      "[SGD | lr=0.01] Epoch 149/4000: train_loss=2.1526  test_loss=2.2057  λ_max=4.5889\n",
      "[SGD | lr=0.01] Iter 2400: loss=2.1525\n",
      "[SGD | lr=0.01] Epoch 150/4000: train_loss=2.1520  test_loss=2.2059  λ_max=4.6222\n",
      "[SGD | lr=0.01] Epoch 151/4000: train_loss=2.1514  test_loss=2.2060  λ_max=4.6044\n",
      "[SGD | lr=0.01] Epoch 152/4000: train_loss=2.1507  test_loss=2.2061  λ_max=4.8060\n",
      "[SGD | lr=0.01] Epoch 153/4000: train_loss=2.1499  test_loss=2.2063  λ_max=4.7967\n",
      "[SGD | lr=0.01] Epoch 154/4000: train_loss=2.1494  test_loss=2.2065  λ_max=4.8855\n",
      "[SGD | lr=0.01] Epoch 155/4000: train_loss=2.1486  test_loss=2.2067  λ_max=4.6538\n",
      "[SGD | lr=0.01] Epoch 156/4000: train_loss=2.1478  test_loss=2.2067  λ_max=5.0404\n",
      "[SGD | lr=0.01] Iter 2500: loss=2.1488\n",
      "[SGD | lr=0.01] Epoch 157/4000: train_loss=2.1470  test_loss=2.2069  λ_max=5.1491\n",
      "[SGD | lr=0.01] Epoch 158/4000: train_loss=2.1465  test_loss=2.2072  λ_max=5.0969\n",
      "[SGD | lr=0.01] Epoch 159/4000: train_loss=2.1457  test_loss=2.2073  λ_max=5.1651\n",
      "[SGD | lr=0.01] Epoch 160/4000: train_loss=2.1447  test_loss=2.2075  λ_max=5.2964\n",
      "[SGD | lr=0.01] Epoch 161/4000: train_loss=2.1441  test_loss=2.2077  λ_max=5.0554\n",
      "[SGD | lr=0.01] Epoch 162/4000: train_loss=2.1434  test_loss=2.2077  λ_max=4.9883\n",
      "[SGD | lr=0.01] Iter 2600: loss=2.1435\n",
      "[SGD | lr=0.01] Epoch 163/4000: train_loss=2.1427  test_loss=2.2079  λ_max=5.3737\n",
      "[SGD | lr=0.01] Epoch 164/4000: train_loss=2.1416  test_loss=2.2081  λ_max=5.2202\n",
      "[SGD | lr=0.01] Epoch 165/4000: train_loss=2.1408  test_loss=2.2084  λ_max=5.4821\n",
      "[SGD | lr=0.01] Epoch 166/4000: train_loss=2.1401  test_loss=2.2084  λ_max=5.4898\n",
      "[SGD | lr=0.01] Epoch 167/4000: train_loss=2.1392  test_loss=2.2086  λ_max=5.3462\n",
      "[SGD | lr=0.01] Epoch 168/4000: train_loss=2.1383  test_loss=2.2088  λ_max=5.6556\n",
      "[SGD | lr=0.01] Iter 2700: loss=2.1386\n",
      "[SGD | lr=0.01] Epoch 169/4000: train_loss=2.1375  test_loss=2.2090  λ_max=5.8975\n",
      "[SGD | lr=0.01] Epoch 170/4000: train_loss=2.1368  test_loss=2.2091  λ_max=5.6541\n",
      "[SGD | lr=0.01] Epoch 171/4000: train_loss=2.1357  test_loss=2.2095  λ_max=5.6174\n",
      "[SGD | lr=0.01] Epoch 172/4000: train_loss=2.1348  test_loss=2.2095  λ_max=5.7586\n",
      "[SGD | lr=0.01] Epoch 173/4000: train_loss=2.1339  test_loss=2.2098  λ_max=5.8228\n",
      "[SGD | lr=0.01] Epoch 174/4000: train_loss=2.1329  test_loss=2.2100  λ_max=5.8361\n",
      "[SGD | lr=0.01] Iter 2800: loss=2.1320\n",
      "[SGD | lr=0.01] Epoch 175/4000: train_loss=2.1321  test_loss=2.2101  λ_max=6.0330\n",
      "[SGD | lr=0.01] Epoch 176/4000: train_loss=2.1311  test_loss=2.2103  λ_max=5.7035\n",
      "[SGD | lr=0.01] Epoch 177/4000: train_loss=2.1302  test_loss=2.2105  λ_max=6.2228\n",
      "[SGD | lr=0.01] Epoch 178/4000: train_loss=2.1292  test_loss=2.2107  λ_max=5.9508\n",
      "[SGD | lr=0.01] Epoch 179/4000: train_loss=2.1282  test_loss=2.2109  λ_max=6.2074\n",
      "[SGD | lr=0.01] Epoch 180/4000: train_loss=2.1274  test_loss=2.2110  λ_max=6.3347\n",
      "[SGD | lr=0.01] Epoch 181/4000: train_loss=2.1263  test_loss=2.2111  λ_max=6.2513\n",
      "[SGD | lr=0.01] Iter 2900: loss=2.1300\n",
      "[SGD | lr=0.01] Epoch 182/4000: train_loss=2.1253  test_loss=2.2113  λ_max=6.6430\n",
      "[SGD | lr=0.01] Epoch 183/4000: train_loss=2.1241  test_loss=2.2114  λ_max=6.4597\n",
      "[SGD | lr=0.01] Epoch 184/4000: train_loss=2.1233  test_loss=2.2116  λ_max=6.5026\n",
      "[SGD | lr=0.01] Epoch 185/4000: train_loss=2.1220  test_loss=2.2117  λ_max=6.5863\n",
      "[SGD | lr=0.01] Epoch 186/4000: train_loss=2.1211  test_loss=2.2120  λ_max=6.6642\n",
      "[SGD | lr=0.01] Epoch 187/4000: train_loss=2.1200  test_loss=2.2121  λ_max=6.8375\n",
      "[SGD | lr=0.01] Iter 3000: loss=2.1161\n",
      "[SGD | lr=0.01] Epoch 188/4000: train_loss=2.1190  test_loss=2.2123  λ_max=6.3830\n",
      "[SGD | lr=0.01] Epoch 189/4000: train_loss=2.1179  test_loss=2.2125  λ_max=6.5831\n",
      "[SGD | lr=0.01] Epoch 190/4000: train_loss=2.1167  test_loss=2.2127  λ_max=6.6393\n",
      "[SGD | lr=0.01] Epoch 191/4000: train_loss=2.1155  test_loss=2.2128  λ_max=7.0879\n",
      "[SGD | lr=0.01] Epoch 192/4000: train_loss=2.1147  test_loss=2.2130  λ_max=7.1942\n",
      "[SGD | lr=0.01] Epoch 193/4000: train_loss=2.1134  test_loss=2.2131  λ_max=7.0613\n",
      "[SGD | lr=0.01] Iter 3100: loss=2.1125\n",
      "[SGD | lr=0.01] Epoch 194/4000: train_loss=2.1124  test_loss=2.2132  λ_max=7.1896\n",
      "[SGD | lr=0.01] Epoch 195/4000: train_loss=2.1112  test_loss=2.2133  λ_max=7.1773\n",
      "[SGD | lr=0.01] Epoch 196/4000: train_loss=2.1100  test_loss=2.2136  λ_max=7.4307\n",
      "[SGD | lr=0.01] Epoch 197/4000: train_loss=2.1089  test_loss=2.2137  λ_max=7.4647\n",
      "[SGD | lr=0.01] Epoch 198/4000: train_loss=2.1077  test_loss=2.2138  λ_max=7.6243\n",
      "[SGD | lr=0.01] Epoch 199/4000: train_loss=2.1067  test_loss=2.2139  λ_max=7.1802\n",
      "[SGD | lr=0.01] Iter 3200: loss=2.1076\n",
      "[SGD | lr=0.01] Epoch 200/4000: train_loss=2.1053  test_loss=2.2140  λ_max=7.7894\n",
      "[SGD | lr=0.01] Epoch 201/4000: train_loss=2.1039  test_loss=2.2141  λ_max=7.0953\n",
      "[SGD | lr=0.01] Epoch 202/4000: train_loss=2.1028  test_loss=2.2142  λ_max=7.5489\n",
      "[SGD | lr=0.01] Epoch 203/4000: train_loss=2.1016  test_loss=2.2144  λ_max=7.7015\n",
      "[SGD | lr=0.01] Epoch 204/4000: train_loss=2.1004  test_loss=2.2145  λ_max=7.7132\n",
      "[SGD | lr=0.01] Epoch 205/4000: train_loss=2.0991  test_loss=2.2146  λ_max=7.8093\n",
      "[SGD | lr=0.01] Epoch 206/4000: train_loss=2.0979  test_loss=2.2148  λ_max=7.9406\n",
      "[SGD | lr=0.01] Iter 3300: loss=2.0951\n",
      "[SGD | lr=0.01] Epoch 207/4000: train_loss=2.0965  test_loss=2.2148  λ_max=8.2072\n",
      "[SGD | lr=0.01] Epoch 208/4000: train_loss=2.0953  test_loss=2.2149  λ_max=8.1196\n",
      "[SGD | lr=0.01] Epoch 209/4000: train_loss=2.0940  test_loss=2.2151  λ_max=8.2952\n",
      "[SGD | lr=0.01] Epoch 210/4000: train_loss=2.0927  test_loss=2.2152  λ_max=8.2095\n",
      "[SGD | lr=0.01] Epoch 211/4000: train_loss=2.0913  test_loss=2.2153  λ_max=8.2349\n",
      "[SGD | lr=0.01] Epoch 212/4000: train_loss=2.0901  test_loss=2.2153  λ_max=8.1951\n",
      "[SGD | lr=0.01] Iter 3400: loss=2.0804\n",
      "[SGD | lr=0.01] Epoch 213/4000: train_loss=2.0886  test_loss=2.2154  λ_max=8.3175\n",
      "[SGD | lr=0.01] Epoch 214/4000: train_loss=2.0875  test_loss=2.2153  λ_max=8.2427\n",
      "[SGD | lr=0.01] Epoch 215/4000: train_loss=2.0860  test_loss=2.2154  λ_max=8.4256\n",
      "[SGD | lr=0.01] Epoch 216/4000: train_loss=2.0847  test_loss=2.2155  λ_max=7.9842\n",
      "[SGD | lr=0.01] Epoch 217/4000: train_loss=2.0832  test_loss=2.2155  λ_max=8.6937\n",
      "[SGD | lr=0.01] Epoch 218/4000: train_loss=2.0821  test_loss=2.2155  λ_max=8.6655\n",
      "[SGD | lr=0.01] Iter 3500: loss=2.0883\n",
      "[SGD | lr=0.01] Epoch 219/4000: train_loss=2.0806  test_loss=2.2156  λ_max=8.6803\n",
      "[SGD | lr=0.01] Epoch 220/4000: train_loss=2.0793  test_loss=2.2155  λ_max=8.5463\n",
      "[SGD | lr=0.01] Epoch 221/4000: train_loss=2.0779  test_loss=2.2155  λ_max=8.6986\n",
      "[SGD | lr=0.01] Epoch 222/4000: train_loss=2.0766  test_loss=2.2157  λ_max=8.4366\n",
      "[SGD | lr=0.01] Epoch 223/4000: train_loss=2.0752  test_loss=2.2157  λ_max=9.0807\n",
      "[SGD | lr=0.01] Epoch 224/4000: train_loss=2.0738  test_loss=2.2156  λ_max=8.6153\n",
      "[SGD | lr=0.01] Iter 3600: loss=2.0673\n",
      "[SGD | lr=0.01] Epoch 225/4000: train_loss=2.0722  test_loss=2.2157  λ_max=8.1748\n",
      "[SGD | lr=0.01] Epoch 226/4000: train_loss=2.0710  test_loss=2.2155  λ_max=9.0772\n",
      "[SGD | lr=0.01] Epoch 227/4000: train_loss=2.0695  test_loss=2.2154  λ_max=9.0082\n",
      "[SGD | lr=0.01] Epoch 228/4000: train_loss=2.0681  test_loss=2.2154  λ_max=8.9777\n",
      "[SGD | lr=0.01] Epoch 229/4000: train_loss=2.0667  test_loss=2.2154  λ_max=9.2622\n",
      "[SGD | lr=0.01] Epoch 230/4000: train_loss=2.0652  test_loss=2.2153  λ_max=9.2638\n",
      "[SGD | lr=0.01] Epoch 231/4000: train_loss=2.0637  test_loss=2.2154  λ_max=9.3861\n",
      "[SGD | lr=0.01] Iter 3700: loss=2.0677\n",
      "[SGD | lr=0.01] Epoch 232/4000: train_loss=2.0621  test_loss=2.2153  λ_max=9.1765\n",
      "[SGD | lr=0.01] Epoch 233/4000: train_loss=2.0608  test_loss=2.2153  λ_max=9.1301\n",
      "[SGD | lr=0.01] Epoch 234/4000: train_loss=2.0595  test_loss=2.2152  λ_max=9.2875\n",
      "[SGD | lr=0.01] Epoch 235/4000: train_loss=2.0578  test_loss=2.2151  λ_max=9.6292\n",
      "[SGD | lr=0.01] Epoch 236/4000: train_loss=2.0564  test_loss=2.2149  λ_max=9.3375\n",
      "[SGD | lr=0.01] Epoch 237/4000: train_loss=2.0550  test_loss=2.2149  λ_max=9.1217\n",
      "[SGD | lr=0.01] Iter 3800: loss=2.0557\n",
      "[SGD | lr=0.01] Epoch 238/4000: train_loss=2.0533  test_loss=2.2147  λ_max=8.8785\n",
      "[SGD | lr=0.01] Epoch 239/4000: train_loss=2.0520  test_loss=2.2145  λ_max=9.2778\n",
      "[SGD | lr=0.01] Epoch 240/4000: train_loss=2.0508  test_loss=2.2145  λ_max=9.9692\n",
      "[SGD | lr=0.01] Epoch 241/4000: train_loss=2.0494  test_loss=2.2144  λ_max=9.8234\n",
      "[SGD | lr=0.01] Epoch 242/4000: train_loss=2.0479  test_loss=2.2143  λ_max=9.7297\n",
      "[SGD | lr=0.01] Epoch 243/4000: train_loss=2.0460  test_loss=2.2142  λ_max=9.9485\n",
      "[SGD | lr=0.01] Iter 3900: loss=2.0451\n",
      "[SGD | lr=0.01] Epoch 244/4000: train_loss=2.0449  test_loss=2.2140  λ_max=10.2306\n",
      "[SGD | lr=0.01] Epoch 245/4000: train_loss=2.0431  test_loss=2.2137  λ_max=10.2160\n",
      "[SGD | lr=0.01] Epoch 246/4000: train_loss=2.0419  test_loss=2.2136  λ_max=10.1609\n",
      "[SGD | lr=0.01] Epoch 247/4000: train_loss=2.0405  test_loss=2.2135  λ_max=10.0106\n",
      "[SGD | lr=0.01] Epoch 248/4000: train_loss=2.0388  test_loss=2.2134  λ_max=10.0160\n",
      "[SGD | lr=0.01] Epoch 249/4000: train_loss=2.0374  test_loss=2.2133  λ_max=10.4100\n",
      "[SGD | lr=0.01] Iter 4000: loss=2.0382\n",
      "[SGD | lr=0.01] Epoch 250/4000: train_loss=2.0359  test_loss=2.2130  λ_max=10.2169\n",
      "[SGD | lr=0.01] Epoch 251/4000: train_loss=2.0344  test_loss=2.2130  λ_max=9.9906\n",
      "[SGD | lr=0.01] Epoch 252/4000: train_loss=2.0328  test_loss=2.2126  λ_max=10.1934\n",
      "[SGD | lr=0.01] Epoch 253/4000: train_loss=2.0314  test_loss=2.2124  λ_max=10.1575\n",
      "[SGD | lr=0.01] Epoch 254/4000: train_loss=2.0298  test_loss=2.2123  λ_max=10.1029\n",
      "[SGD | lr=0.01] Epoch 255/4000: train_loss=2.0282  test_loss=2.2122  λ_max=10.0432\n",
      "[SGD | lr=0.01] Epoch 256/4000: train_loss=2.0268  test_loss=2.2119  λ_max=10.5183\n",
      "[SGD | lr=0.01] Iter 4100: loss=2.0311\n",
      "[SGD | lr=0.01] Epoch 257/4000: train_loss=2.0252  test_loss=2.2117  λ_max=10.3112\n",
      "[SGD | lr=0.01] Epoch 258/4000: train_loss=2.0239  test_loss=2.2115  λ_max=10.0101\n",
      "[SGD | lr=0.01] Epoch 259/4000: train_loss=2.0223  test_loss=2.2113  λ_max=10.5927\n",
      "[SGD | lr=0.01] Epoch 260/4000: train_loss=2.0207  test_loss=2.2112  λ_max=10.6403\n",
      "[SGD | lr=0.01] Epoch 261/4000: train_loss=2.0193  test_loss=2.2108  λ_max=10.0233\n",
      "[SGD | lr=0.01] Epoch 262/4000: train_loss=2.0179  test_loss=2.2108  λ_max=11.0949\n",
      "[SGD | lr=0.01] Iter 4200: loss=2.0208\n",
      "[SGD | lr=0.01] Epoch 263/4000: train_loss=2.0165  test_loss=2.2106  λ_max=10.8173\n",
      "[SGD | lr=0.01] Epoch 264/4000: train_loss=2.0148  test_loss=2.2103  λ_max=10.8791\n",
      "[SGD | lr=0.01] Epoch 265/4000: train_loss=2.0134  test_loss=2.2102  λ_max=10.5401\n",
      "[SGD | lr=0.01] Epoch 266/4000: train_loss=2.0118  test_loss=2.2098  λ_max=10.6795\n",
      "[SGD | lr=0.01] Epoch 267/4000: train_loss=2.0105  test_loss=2.2096  λ_max=10.9680\n",
      "[SGD | lr=0.01] Epoch 268/4000: train_loss=2.0090  test_loss=2.2094  λ_max=10.6069\n",
      "[SGD | lr=0.01] Iter 4300: loss=2.0092\n",
      "[SGD | lr=0.01] Epoch 269/4000: train_loss=2.0073  test_loss=2.2090  λ_max=11.1726\n",
      "[SGD | lr=0.01] Epoch 270/4000: train_loss=2.0057  test_loss=2.2089  λ_max=11.3076\n",
      "[SGD | lr=0.01] Epoch 271/4000: train_loss=2.0044  test_loss=2.2087  λ_max=10.5675\n",
      "[SGD | lr=0.01] Epoch 272/4000: train_loss=2.0030  test_loss=2.2084  λ_max=11.4925\n",
      "[SGD | lr=0.01] Epoch 273/4000: train_loss=2.0016  test_loss=2.2083  λ_max=10.7260\n",
      "[SGD | lr=0.01] Epoch 274/4000: train_loss=1.9998  test_loss=2.2080  λ_max=11.4369\n",
      "[SGD | lr=0.01] Iter 4400: loss=1.9959\n",
      "[SGD | lr=0.01] Epoch 275/4000: train_loss=1.9983  test_loss=2.2076  λ_max=11.4907\n",
      "[SGD | lr=0.01] Epoch 276/4000: train_loss=1.9970  test_loss=2.2075  λ_max=10.9684\n",
      "[SGD | lr=0.01] Epoch 277/4000: train_loss=1.9953  test_loss=2.2075  λ_max=11.3139\n",
      "[SGD | lr=0.01] Epoch 278/4000: train_loss=1.9938  test_loss=2.2069  λ_max=11.1104\n",
      "[SGD | lr=0.01] Epoch 279/4000: train_loss=1.9924  test_loss=2.2068  λ_max=11.7717\n",
      "[SGD | lr=0.01] Epoch 280/4000: train_loss=1.9911  test_loss=2.2065  λ_max=11.4321\n",
      "[SGD | lr=0.01] Epoch 281/4000: train_loss=1.9894  test_loss=2.2063  λ_max=11.0205\n",
      "[SGD | lr=0.01] Iter 4500: loss=1.9962\n",
      "[SGD | lr=0.01] Epoch 282/4000: train_loss=1.9877  test_loss=2.2058  λ_max=11.4014\n",
      "[SGD | lr=0.01] Epoch 283/4000: train_loss=1.9866  test_loss=2.2057  λ_max=11.6815\n",
      "[SGD | lr=0.01] Epoch 284/4000: train_loss=1.9853  test_loss=2.2052  λ_max=12.0925\n",
      "[SGD | lr=0.01] Epoch 285/4000: train_loss=1.9834  test_loss=2.2053  λ_max=11.6545\n",
      "[SGD | lr=0.01] Epoch 286/4000: train_loss=1.9819  test_loss=2.2049  λ_max=11.3630\n",
      "[SGD | lr=0.01] Epoch 287/4000: train_loss=1.9804  test_loss=2.2044  λ_max=12.3123\n",
      "[SGD | lr=0.01] Iter 4600: loss=1.9787\n",
      "[SGD | lr=0.01] Epoch 288/4000: train_loss=1.9789  test_loss=2.2042  λ_max=12.0842\n",
      "[SGD | lr=0.01] Epoch 289/4000: train_loss=1.9777  test_loss=2.2039  λ_max=11.7206\n",
      "[SGD | lr=0.01] Epoch 290/4000: train_loss=1.9760  test_loss=2.2035  λ_max=11.7972\n",
      "[SGD | lr=0.01] Epoch 291/4000: train_loss=1.9746  test_loss=2.2034  λ_max=11.9707\n",
      "[SGD | lr=0.01] Epoch 292/4000: train_loss=1.9730  test_loss=2.2031  λ_max=11.4763\n",
      "[SGD | lr=0.01] Epoch 293/4000: train_loss=1.9717  test_loss=2.2027  λ_max=12.3503\n",
      "[SGD | lr=0.01] Iter 4700: loss=1.9712\n",
      "[SGD | lr=0.01] Epoch 294/4000: train_loss=1.9704  test_loss=2.2024  λ_max=12.3684\n",
      "[SGD | lr=0.01] Epoch 295/4000: train_loss=1.9686  test_loss=2.2020  λ_max=11.6144\n",
      "[SGD | lr=0.01] Epoch 296/4000: train_loss=1.9672  test_loss=2.2017  λ_max=11.7609\n",
      "[SGD | lr=0.01] Epoch 297/4000: train_loss=1.9659  test_loss=2.2018  λ_max=11.8379\n",
      "[SGD | lr=0.01] Epoch 298/4000: train_loss=1.9643  test_loss=2.2012  λ_max=11.9836\n",
      "[SGD | lr=0.01] Epoch 299/4000: train_loss=1.9629  test_loss=2.2012  λ_max=12.0380\n",
      "[SGD | lr=0.01] Iter 4800: loss=1.9629\n",
      "[SGD | lr=0.01] Epoch 300/4000: train_loss=1.9615  test_loss=2.2008  λ_max=11.9725\n",
      "[SGD | lr=0.01] Epoch 301/4000: train_loss=1.9602  test_loss=2.2005  λ_max=12.2655\n",
      "[SGD | lr=0.01] Epoch 302/4000: train_loss=1.9584  test_loss=2.2002  λ_max=12.7888\n",
      "[SGD | lr=0.01] Epoch 303/4000: train_loss=1.9571  test_loss=2.2002  λ_max=12.8647\n",
      "[SGD | lr=0.01] Epoch 304/4000: train_loss=1.9557  test_loss=2.1998  λ_max=12.7047\n",
      "[SGD | lr=0.01] Epoch 305/4000: train_loss=1.9543  test_loss=2.1994  λ_max=11.9313\n",
      "[SGD | lr=0.01] Epoch 306/4000: train_loss=1.9529  test_loss=2.1990  λ_max=12.4729\n",
      "[SGD | lr=0.01] Iter 4900: loss=1.9442\n",
      "[SGD | lr=0.01] Epoch 307/4000: train_loss=1.9513  test_loss=2.1988  λ_max=12.8199\n",
      "[SGD | lr=0.01] Epoch 308/4000: train_loss=1.9498  test_loss=2.1985  λ_max=12.4489\n",
      "[SGD | lr=0.01] Epoch 309/4000: train_loss=1.9483  test_loss=2.1982  λ_max=12.9554\n",
      "[SGD | lr=0.01] Epoch 310/4000: train_loss=1.9467  test_loss=2.1979  λ_max=13.1980\n",
      "[SGD | lr=0.01] Epoch 311/4000: train_loss=1.9455  test_loss=2.1975  λ_max=13.0370\n",
      "[SGD | lr=0.01] Epoch 312/4000: train_loss=1.9441  test_loss=2.1972  λ_max=12.4879\n",
      "[SGD | lr=0.01] Iter 5000: loss=1.9532\n",
      "[SGD | lr=0.01] Epoch 313/4000: train_loss=1.9427  test_loss=2.1971  λ_max=13.3894\n",
      "[SGD | lr=0.01] Epoch 314/4000: train_loss=1.9412  test_loss=2.1967  λ_max=12.7417\n",
      "[SGD | lr=0.01] Epoch 315/4000: train_loss=1.9394  test_loss=2.1966  λ_max=12.9225\n",
      "[SGD | lr=0.01] Epoch 316/4000: train_loss=1.9385  test_loss=2.1963  λ_max=12.0182\n",
      "[SGD | lr=0.01] Epoch 317/4000: train_loss=1.9369  test_loss=2.1959  λ_max=12.8534\n",
      "[SGD | lr=0.01] Epoch 318/4000: train_loss=1.9353  test_loss=2.1958  λ_max=13.5261\n",
      "[SGD | lr=0.01] Iter 5100: loss=1.9271\n",
      "[SGD | lr=0.01] Epoch 319/4000: train_loss=1.9340  test_loss=2.1953  λ_max=13.1789\n",
      "[SGD | lr=0.01] Epoch 320/4000: train_loss=1.9325  test_loss=2.1952  λ_max=13.1766\n",
      "[SGD | lr=0.01] Epoch 321/4000: train_loss=1.9312  test_loss=2.1951  λ_max=12.9970\n",
      "[SGD | lr=0.01] Epoch 322/4000: train_loss=1.9300  test_loss=2.1947  λ_max=12.0891\n",
      "[SGD | lr=0.01] Epoch 323/4000: train_loss=1.9282  test_loss=2.1943  λ_max=13.3834\n",
      "[SGD | lr=0.01] Epoch 324/4000: train_loss=1.9270  test_loss=2.1940  λ_max=12.4384\n",
      "[SGD | lr=0.01] Iter 5200: loss=1.9191\n",
      "[SGD | lr=0.01] Epoch 325/4000: train_loss=1.9254  test_loss=2.1937  λ_max=13.7278\n",
      "[SGD | lr=0.01] Epoch 326/4000: train_loss=1.9239  test_loss=2.1934  λ_max=13.3141\n",
      "[SGD | lr=0.01] Epoch 327/4000: train_loss=1.9227  test_loss=2.1932  λ_max=12.9500\n",
      "[SGD | lr=0.01] Epoch 328/4000: train_loss=1.9214  test_loss=2.1929  λ_max=12.9955\n",
      "[SGD | lr=0.01] Epoch 329/4000: train_loss=1.9198  test_loss=2.1926  λ_max=12.9823\n",
      "[SGD | lr=0.01] Epoch 330/4000: train_loss=1.9183  test_loss=2.1924  λ_max=13.3852\n",
      "[SGD | lr=0.01] Epoch 331/4000: train_loss=1.9170  test_loss=2.1923  λ_max=13.6989\n",
      "[SGD | lr=0.01] Iter 5300: loss=1.9197\n",
      "[SGD | lr=0.01] Epoch 332/4000: train_loss=1.9157  test_loss=2.1918  λ_max=13.5983\n",
      "[SGD | lr=0.01] Epoch 333/4000: train_loss=1.9144  test_loss=2.1916  λ_max=13.5104\n",
      "[SGD | lr=0.01] Epoch 334/4000: train_loss=1.9129  test_loss=2.1912  λ_max=13.8136\n",
      "[SGD | lr=0.01] Epoch 335/4000: train_loss=1.9117  test_loss=2.1912  λ_max=13.9075\n",
      "[SGD | lr=0.01] Epoch 336/4000: train_loss=1.9101  test_loss=2.1908  λ_max=13.5053\n",
      "[SGD | lr=0.01] Epoch 337/4000: train_loss=1.9087  test_loss=2.1905  λ_max=14.0296\n",
      "[SGD | lr=0.01] Iter 5400: loss=1.9108\n",
      "[SGD | lr=0.01] Epoch 338/4000: train_loss=1.9074  test_loss=2.1906  λ_max=13.7334\n",
      "[SGD | lr=0.01] Epoch 339/4000: train_loss=1.9058  test_loss=2.1902  λ_max=13.6293\n",
      "[SGD | lr=0.01] Epoch 340/4000: train_loss=1.9044  test_loss=2.1897  λ_max=13.3060\n",
      "[SGD | lr=0.01] Epoch 341/4000: train_loss=1.9034  test_loss=2.1896  λ_max=13.8293\n",
      "[SGD | lr=0.01] Epoch 342/4000: train_loss=1.9018  test_loss=2.1893  λ_max=14.1662\n",
      "[SGD | lr=0.01] Epoch 343/4000: train_loss=1.9005  test_loss=2.1889  λ_max=14.3165\n",
      "[SGD | lr=0.01] Iter 5500: loss=1.9010\n",
      "[SGD | lr=0.01] Epoch 344/4000: train_loss=1.8991  test_loss=2.1888  λ_max=13.6220\n",
      "[SGD | lr=0.01] Epoch 345/4000: train_loss=1.8977  test_loss=2.1886  λ_max=14.3376\n",
      "[SGD | lr=0.01] Epoch 346/4000: train_loss=1.8962  test_loss=2.1885  λ_max=14.4941\n",
      "[SGD | lr=0.01] Epoch 347/4000: train_loss=1.8950  test_loss=2.1879  λ_max=14.2054\n",
      "[SGD | lr=0.01] Epoch 348/4000: train_loss=1.8937  test_loss=2.1877  λ_max=14.3700\n",
      "[SGD | lr=0.01] Epoch 349/4000: train_loss=1.8924  test_loss=2.1873  λ_max=14.6223\n",
      "[SGD | lr=0.01] Iter 5600: loss=1.8872\n",
      "[SGD | lr=0.01] Epoch 350/4000: train_loss=1.8908  test_loss=2.1873  λ_max=13.9288\n",
      "[SGD | lr=0.01] Epoch 351/4000: train_loss=1.8897  test_loss=2.1870  λ_max=14.2963\n",
      "[SGD | lr=0.01] Epoch 352/4000: train_loss=1.8881  test_loss=2.1867  λ_max=14.3368\n",
      "[SGD | lr=0.01] Epoch 353/4000: train_loss=1.8869  test_loss=2.1864  λ_max=14.2280\n",
      "[SGD | lr=0.01] Epoch 354/4000: train_loss=1.8855  test_loss=2.1863  λ_max=13.7543\n",
      "[SGD | lr=0.01] Epoch 355/4000: train_loss=1.8837  test_loss=2.1860  λ_max=14.9608\n",
      "[SGD | lr=0.01] Epoch 356/4000: train_loss=1.8828  test_loss=2.1858  λ_max=14.1714\n",
      "[SGD | lr=0.01] Iter 5700: loss=1.8859\n",
      "[SGD | lr=0.01] Epoch 357/4000: train_loss=1.8816  test_loss=2.1855  λ_max=14.5822\n",
      "[SGD | lr=0.01] Epoch 358/4000: train_loss=1.8802  test_loss=2.1851  λ_max=14.0867\n",
      "[SGD | lr=0.01] Epoch 359/4000: train_loss=1.8786  test_loss=2.1852  λ_max=14.0910\n",
      "[SGD | lr=0.01] Epoch 360/4000: train_loss=1.8774  test_loss=2.1848  λ_max=14.8427\n",
      "[SGD | lr=0.01] Epoch 361/4000: train_loss=1.8758  test_loss=2.1847  λ_max=15.0363\n",
      "[SGD | lr=0.01] Epoch 362/4000: train_loss=1.8749  test_loss=2.1842  λ_max=14.7852\n",
      "[SGD | lr=0.01] Iter 5800: loss=1.8716\n",
      "[SGD | lr=0.01] Epoch 363/4000: train_loss=1.8732  test_loss=2.1841  λ_max=14.6717\n",
      "[SGD | lr=0.01] Epoch 364/4000: train_loss=1.8720  test_loss=2.1838  λ_max=14.4676\n",
      "[SGD | lr=0.01] Epoch 365/4000: train_loss=1.8709  test_loss=2.1838  λ_max=15.5187\n",
      "[SGD | lr=0.01] Epoch 366/4000: train_loss=1.8693  test_loss=2.1834  λ_max=14.6599\n",
      "[SGD | lr=0.01] Epoch 367/4000: train_loss=1.8683  test_loss=2.1832  λ_max=14.9347\n",
      "[SGD | lr=0.01] Epoch 368/4000: train_loss=1.8669  test_loss=2.1830  λ_max=14.8071\n",
      "[SGD | lr=0.01] Iter 5900: loss=1.8673\n",
      "[SGD | lr=0.01] Epoch 369/4000: train_loss=1.8653  test_loss=2.1825  λ_max=15.3615\n",
      "[SGD | lr=0.01] Epoch 370/4000: train_loss=1.8640  test_loss=2.1825  λ_max=15.2928\n",
      "[SGD | lr=0.01] Epoch 371/4000: train_loss=1.8626  test_loss=2.1820  λ_max=15.3448\n",
      "[SGD | lr=0.01] Epoch 372/4000: train_loss=1.8615  test_loss=2.1819  λ_max=14.4739\n",
      "[SGD | lr=0.01] Epoch 373/4000: train_loss=1.8603  test_loss=2.1817  λ_max=14.9521\n",
      "[SGD | lr=0.01] Epoch 374/4000: train_loss=1.8590  test_loss=2.1815  λ_max=15.5360\n",
      "[SGD | lr=0.01] Iter 6000: loss=1.8590\n",
      "[SGD | lr=0.01] Epoch 375/4000: train_loss=1.8576  test_loss=2.1811  λ_max=13.9178\n",
      "[SGD | lr=0.01] Epoch 376/4000: train_loss=1.8565  test_loss=2.1812  λ_max=14.3402\n",
      "[SGD | lr=0.01] Epoch 377/4000: train_loss=1.8550  test_loss=2.1807  λ_max=15.2280\n",
      "[SGD | lr=0.01] Epoch 378/4000: train_loss=1.8537  test_loss=2.1806  λ_max=14.7427\n",
      "[SGD | lr=0.01] Epoch 379/4000: train_loss=1.8522  test_loss=2.1801  λ_max=15.0259\n",
      "[SGD | lr=0.01] Epoch 380/4000: train_loss=1.8510  test_loss=2.1802  λ_max=14.5066\n",
      "[SGD | lr=0.01] Epoch 381/4000: train_loss=1.8496  test_loss=2.1800  λ_max=15.9506\n",
      "[SGD | lr=0.01] Iter 6100: loss=1.8428\n",
      "[SGD | lr=0.01] Epoch 382/4000: train_loss=1.8484  test_loss=2.1798  λ_max=15.5520\n",
      "[SGD | lr=0.01] Epoch 383/4000: train_loss=1.8471  test_loss=2.1795  λ_max=15.8864\n",
      "[SGD | lr=0.01] Epoch 384/4000: train_loss=1.8460  test_loss=2.1793  λ_max=15.3350\n",
      "[SGD | lr=0.01] Epoch 385/4000: train_loss=1.8446  test_loss=2.1790  λ_max=16.2508\n",
      "[SGD | lr=0.01] Epoch 386/4000: train_loss=1.8436  test_loss=2.1789  λ_max=14.9939\n",
      "[SGD | lr=0.01] Epoch 387/4000: train_loss=1.8419  test_loss=2.1785  λ_max=14.9546\n",
      "[SGD | lr=0.01] Iter 6200: loss=1.8411\n",
      "[SGD | lr=0.01] Epoch 388/4000: train_loss=1.8407  test_loss=2.1782  λ_max=15.6628\n",
      "[SGD | lr=0.01] Epoch 389/4000: train_loss=1.8396  test_loss=2.1778  λ_max=16.3023\n",
      "[SGD | lr=0.01] Epoch 390/4000: train_loss=1.8383  test_loss=2.1777  λ_max=15.8575\n",
      "[SGD | lr=0.01] Epoch 391/4000: train_loss=1.8368  test_loss=2.1775  λ_max=16.1379\n",
      "[SGD | lr=0.01] Epoch 392/4000: train_loss=1.8355  test_loss=2.1773  λ_max=15.4013\n",
      "[SGD | lr=0.01] Epoch 393/4000: train_loss=1.8342  test_loss=2.1773  λ_max=15.7134\n",
      "[SGD | lr=0.01] Iter 6300: loss=1.8325\n",
      "[SGD | lr=0.01] Epoch 394/4000: train_loss=1.8332  test_loss=2.1769  λ_max=16.2624\n",
      "[SGD | lr=0.01] Epoch 395/4000: train_loss=1.8317  test_loss=2.1765  λ_max=16.0649\n",
      "[SGD | lr=0.01] Epoch 396/4000: train_loss=1.8303  test_loss=2.1766  λ_max=16.4358\n",
      "[SGD | lr=0.01] Epoch 397/4000: train_loss=1.8292  test_loss=2.1764  λ_max=16.7292\n",
      "[SGD | lr=0.01] Epoch 398/4000: train_loss=1.8277  test_loss=2.1759  λ_max=16.4578\n",
      "[SGD | lr=0.01] Epoch 399/4000: train_loss=1.8264  test_loss=2.1757  λ_max=16.6561\n",
      "[SGD | lr=0.01] Iter 6400: loss=1.8153\n",
      "[SGD | lr=0.01] Epoch 400/4000: train_loss=1.8252  test_loss=2.1756  λ_max=16.3721\n",
      "[SGD | lr=0.01] Epoch 401/4000: train_loss=1.8243  test_loss=2.1752  λ_max=16.4153\n",
      "[SGD | lr=0.01] Epoch 402/4000: train_loss=1.8229  test_loss=2.1750  λ_max=15.3025\n",
      "[SGD | lr=0.01] Epoch 403/4000: train_loss=1.8217  test_loss=2.1747  λ_max=15.6067\n",
      "[SGD | lr=0.01] Epoch 404/4000: train_loss=1.8203  test_loss=2.1748  λ_max=16.1265\n",
      "[SGD | lr=0.01] Epoch 405/4000: train_loss=1.8192  test_loss=2.1743  λ_max=16.5759\n",
      "[SGD | lr=0.01] Epoch 406/4000: train_loss=1.8180  test_loss=2.1741  λ_max=16.1655\n",
      "[SGD | lr=0.01] Iter 6500: loss=1.8159\n",
      "[SGD | lr=0.01] Epoch 407/4000: train_loss=1.8166  test_loss=2.1740  λ_max=16.2963\n",
      "[SGD | lr=0.01] Epoch 408/4000: train_loss=1.8155  test_loss=2.1739  λ_max=16.7390\n",
      "[SGD | lr=0.01] Epoch 409/4000: train_loss=1.8141  test_loss=2.1739  λ_max=16.6889\n",
      "[SGD | lr=0.01] Epoch 410/4000: train_loss=1.8130  test_loss=2.1733  λ_max=16.0928\n",
      "[SGD | lr=0.01] Epoch 411/4000: train_loss=1.8117  test_loss=2.1733  λ_max=16.8126\n",
      "[SGD | lr=0.01] Epoch 412/4000: train_loss=1.8103  test_loss=2.1730  λ_max=16.5126\n",
      "[SGD | lr=0.01] Iter 6600: loss=1.8069\n",
      "[SGD | lr=0.01] Epoch 413/4000: train_loss=1.8091  test_loss=2.1729  λ_max=15.7337\n",
      "[SGD | lr=0.01] Epoch 414/4000: train_loss=1.8077  test_loss=2.1724  λ_max=17.2374\n",
      "[SGD | lr=0.01] Epoch 415/4000: train_loss=1.8066  test_loss=2.1723  λ_max=16.2897\n",
      "[SGD | lr=0.01] Epoch 416/4000: train_loss=1.8055  test_loss=2.1723  λ_max=16.7339\n",
      "[SGD | lr=0.01] Epoch 417/4000: train_loss=1.8045  test_loss=2.1719  λ_max=17.0405\n",
      "[SGD | lr=0.01] Epoch 418/4000: train_loss=1.8027  test_loss=2.1717  λ_max=16.7338\n",
      "[SGD | lr=0.01] Iter 6700: loss=1.8035\n",
      "[SGD | lr=0.01] Epoch 419/4000: train_loss=1.8019  test_loss=2.1715  λ_max=17.4386\n",
      "[SGD | lr=0.01] Epoch 420/4000: train_loss=1.8005  test_loss=2.1714  λ_max=16.7861\n",
      "[SGD | lr=0.01] Epoch 421/4000: train_loss=1.7992  test_loss=2.1709  λ_max=16.4278\n",
      "[SGD | lr=0.01] Epoch 422/4000: train_loss=1.7983  test_loss=2.1707  λ_max=16.9099\n",
      "[SGD | lr=0.01] Epoch 423/4000: train_loss=1.7968  test_loss=2.1706  λ_max=16.5699\n",
      "[SGD | lr=0.01] Epoch 424/4000: train_loss=1.7957  test_loss=2.1701  λ_max=17.6492\n",
      "[SGD | lr=0.01] Iter 6800: loss=1.7844\n",
      "[SGD | lr=0.01] Epoch 425/4000: train_loss=1.7942  test_loss=2.1703  λ_max=17.8760\n",
      "[SGD | lr=0.01] Epoch 426/4000: train_loss=1.7934  test_loss=2.1698  λ_max=17.3549\n",
      "[SGD | lr=0.01] Epoch 427/4000: train_loss=1.7920  test_loss=2.1697  λ_max=17.9647\n",
      "[SGD | lr=0.01] Epoch 428/4000: train_loss=1.7909  test_loss=2.1695  λ_max=17.1351\n",
      "[SGD | lr=0.01] Epoch 429/4000: train_loss=1.7895  test_loss=2.1693  λ_max=16.2843\n",
      "[SGD | lr=0.01] Epoch 430/4000: train_loss=1.7885  test_loss=2.1692  λ_max=17.6693\n",
      "[SGD | lr=0.01] Epoch 431/4000: train_loss=1.7872  test_loss=2.1691  λ_max=17.8408\n",
      "[SGD | lr=0.01] Iter 6900: loss=1.7892\n",
      "[SGD | lr=0.01] Epoch 432/4000: train_loss=1.7858  test_loss=2.1689  λ_max=17.5430\n",
      "[SGD | lr=0.01] Epoch 433/4000: train_loss=1.7851  test_loss=2.1687  λ_max=18.0391\n",
      "[SGD | lr=0.01] Epoch 434/4000: train_loss=1.7834  test_loss=2.1684  λ_max=17.4016\n",
      "[SGD | lr=0.01] Epoch 435/4000: train_loss=1.7822  test_loss=2.1683  λ_max=16.7253\n",
      "[SGD | lr=0.01] Epoch 436/4000: train_loss=1.7810  test_loss=2.1682  λ_max=18.0400\n",
      "[SGD | lr=0.01] Epoch 437/4000: train_loss=1.7799  test_loss=2.1680  λ_max=17.2321\n",
      "[SGD | lr=0.01] Iter 7000: loss=1.7851\n",
      "[SGD | lr=0.01] Epoch 438/4000: train_loss=1.7787  test_loss=2.1675  λ_max=18.3246\n",
      "[SGD | lr=0.01] Epoch 439/4000: train_loss=1.7774  test_loss=2.1674  λ_max=18.0895\n",
      "[SGD | lr=0.01] Epoch 440/4000: train_loss=1.7761  test_loss=2.1673  λ_max=17.7321\n",
      "[SGD | lr=0.01] Epoch 441/4000: train_loss=1.7751  test_loss=2.1674  λ_max=16.7217\n",
      "[SGD | lr=0.01] Epoch 442/4000: train_loss=1.7740  test_loss=2.1673  λ_max=17.5483\n",
      "[SGD | lr=0.01] Epoch 443/4000: train_loss=1.7726  test_loss=2.1667  λ_max=18.6363\n",
      "[SGD | lr=0.01] Iter 7100: loss=1.7661\n",
      "[SGD | lr=0.01] Epoch 444/4000: train_loss=1.7717  test_loss=2.1665  λ_max=17.9289\n",
      "[SGD | lr=0.01] Epoch 445/4000: train_loss=1.7704  test_loss=2.1664  λ_max=18.6267\n",
      "[SGD | lr=0.01] Epoch 446/4000: train_loss=1.7688  test_loss=2.1658  λ_max=18.5262\n",
      "[SGD | lr=0.01] Epoch 447/4000: train_loss=1.7677  test_loss=2.1660  λ_max=18.2265\n",
      "[SGD | lr=0.01] Epoch 448/4000: train_loss=1.7668  test_loss=2.1657  λ_max=18.9454\n",
      "[SGD | lr=0.01] Epoch 449/4000: train_loss=1.7654  test_loss=2.1657  λ_max=17.8338\n",
      "[SGD | lr=0.01] Iter 7200: loss=1.7587\n",
      "[SGD | lr=0.01] Epoch 450/4000: train_loss=1.7642  test_loss=2.1655  λ_max=17.9658\n",
      "[SGD | lr=0.01] Epoch 451/4000: train_loss=1.7632  test_loss=2.1654  λ_max=17.3587\n",
      "[SGD | lr=0.01] Epoch 452/4000: train_loss=1.7620  test_loss=2.1652  λ_max=18.9169\n",
      "[SGD | lr=0.01] Epoch 453/4000: train_loss=1.7605  test_loss=2.1651  λ_max=18.6549\n",
      "[SGD | lr=0.01] Epoch 454/4000: train_loss=1.7596  test_loss=2.1647  λ_max=18.3832\n",
      "[SGD | lr=0.01] Epoch 455/4000: train_loss=1.7585  test_loss=2.1647  λ_max=17.8650\n",
      "[SGD | lr=0.01] Epoch 456/4000: train_loss=1.7571  test_loss=2.1644  λ_max=18.4177\n",
      "[SGD | lr=0.01] Iter 7300: loss=1.7495\n",
      "[SGD | lr=0.01] Epoch 457/4000: train_loss=1.7561  test_loss=2.1644  λ_max=19.0310\n",
      "[SGD | lr=0.01] Epoch 458/4000: train_loss=1.7548  test_loss=2.1639  λ_max=18.0844\n",
      "[SGD | lr=0.01] Epoch 459/4000: train_loss=1.7538  test_loss=2.1639  λ_max=18.8884\n",
      "[SGD | lr=0.01] Epoch 460/4000: train_loss=1.7525  test_loss=2.1638  λ_max=19.5299\n",
      "[SGD | lr=0.01] Epoch 461/4000: train_loss=1.7513  test_loss=2.1636  λ_max=19.1446\n",
      "[SGD | lr=0.01] Epoch 462/4000: train_loss=1.7501  test_loss=2.1633  λ_max=18.3617\n",
      "[SGD | lr=0.01] Iter 7400: loss=1.7453\n",
      "[SGD | lr=0.01] Epoch 463/4000: train_loss=1.7490  test_loss=2.1632  λ_max=19.4757\n",
      "[SGD | lr=0.01] Epoch 464/4000: train_loss=1.7477  test_loss=2.1632  λ_max=19.2606\n",
      "[SGD | lr=0.01] Epoch 465/4000: train_loss=1.7466  test_loss=2.1630  λ_max=19.3414\n",
      "[SGD | lr=0.01] Epoch 466/4000: train_loss=1.7456  test_loss=2.1629  λ_max=18.5202\n",
      "[SGD | lr=0.01] Epoch 467/4000: train_loss=1.7443  test_loss=2.1626  λ_max=19.6857\n",
      "[SGD | lr=0.01] Epoch 468/4000: train_loss=1.7432  test_loss=2.1623  λ_max=18.8966\n",
      "[SGD | lr=0.01] Iter 7500: loss=1.7434\n",
      "[SGD | lr=0.01] Epoch 469/4000: train_loss=1.7422  test_loss=2.1622  λ_max=18.3496\n",
      "[SGD | lr=0.01] Epoch 470/4000: train_loss=1.7409  test_loss=2.1622  λ_max=20.0763\n",
      "[SGD | lr=0.01] Epoch 471/4000: train_loss=1.7396  test_loss=2.1621  λ_max=19.8880\n",
      "[SGD | lr=0.01] Epoch 472/4000: train_loss=1.7384  test_loss=2.1619  λ_max=18.6707\n",
      "[SGD | lr=0.01] Epoch 473/4000: train_loss=1.7375  test_loss=2.1617  λ_max=19.4277\n",
      "[SGD | lr=0.01] Epoch 474/4000: train_loss=1.7363  test_loss=2.1613  λ_max=19.4268\n",
      "[SGD | lr=0.01] Iter 7600: loss=1.7280\n",
      "[SGD | lr=0.01] Epoch 475/4000: train_loss=1.7349  test_loss=2.1616  λ_max=19.0483\n",
      "[SGD | lr=0.01] Epoch 476/4000: train_loss=1.7339  test_loss=2.1613  λ_max=18.5620\n",
      "[SGD | lr=0.01] Epoch 477/4000: train_loss=1.7330  test_loss=2.1612  λ_max=19.6969\n",
      "[SGD | lr=0.01] Epoch 478/4000: train_loss=1.7318  test_loss=2.1612  λ_max=19.5137\n",
      "[SGD | lr=0.01] Epoch 479/4000: train_loss=1.7303  test_loss=2.1606  λ_max=18.9331\n",
      "[SGD | lr=0.01] Epoch 480/4000: train_loss=1.7292  test_loss=2.1609  λ_max=18.6583\n",
      "[SGD | lr=0.01] Epoch 481/4000: train_loss=1.7283  test_loss=2.1603  λ_max=19.7160\n",
      "[SGD | lr=0.01] Iter 7700: loss=1.7271\n",
      "[SGD | lr=0.01] Epoch 482/4000: train_loss=1.7271  test_loss=2.1603  λ_max=18.2931\n",
      "[SGD | lr=0.01] Epoch 483/4000: train_loss=1.7257  test_loss=2.1602  λ_max=19.8187\n",
      "[SGD | lr=0.01] Epoch 484/4000: train_loss=1.7246  test_loss=2.1598  λ_max=19.9799\n",
      "[SGD | lr=0.01] Epoch 485/4000: train_loss=1.7236  test_loss=2.1599  λ_max=20.0491\n",
      "[SGD | lr=0.01] Epoch 486/4000: train_loss=1.7226  test_loss=2.1599  λ_max=19.2036\n",
      "[SGD | lr=0.01] Epoch 487/4000: train_loss=1.7212  test_loss=2.1596  λ_max=20.2705\n",
      "[SGD | lr=0.01] Iter 7800: loss=1.7218\n",
      "[SGD | lr=0.01] Epoch 488/4000: train_loss=1.7203  test_loss=2.1595  λ_max=20.1041\n",
      "[SGD | lr=0.01] Epoch 489/4000: train_loss=1.7191  test_loss=2.1594  λ_max=20.1743\n",
      "[SGD | lr=0.01] Epoch 490/4000: train_loss=1.7179  test_loss=2.1591  λ_max=20.3820\n",
      "[SGD | lr=0.01] Epoch 491/4000: train_loss=1.7168  test_loss=2.1590  λ_max=19.8824\n",
      "[SGD | lr=0.01] Epoch 492/4000: train_loss=1.7158  test_loss=2.1592  λ_max=20.6390\n",
      "[SGD | lr=0.01] Epoch 493/4000: train_loss=1.7146  test_loss=2.1589  λ_max=20.5754\n",
      "[SGD | lr=0.01] Iter 7900: loss=1.7104\n",
      "[SGD | lr=0.01] Epoch 494/4000: train_loss=1.7135  test_loss=2.1585  λ_max=20.3794\n",
      "[SGD | lr=0.01] Epoch 495/4000: train_loss=1.7122  test_loss=2.1587  λ_max=20.4125\n",
      "[SGD | lr=0.01] Epoch 496/4000: train_loss=1.7111  test_loss=2.1584  λ_max=19.1624\n",
      "[SGD | lr=0.01] Epoch 497/4000: train_loss=1.7102  test_loss=2.1581  λ_max=20.2231\n",
      "[SGD | lr=0.01] Epoch 498/4000: train_loss=1.7091  test_loss=2.1580  λ_max=20.5008\n",
      "[SGD | lr=0.01] Epoch 499/4000: train_loss=1.7078  test_loss=2.1580  λ_max=20.7625\n",
      "[SGD | lr=0.01] Iter 8000: loss=1.7086\n",
      "[SGD | lr=0.01] Epoch 500/4000: train_loss=1.7067  test_loss=2.1578  λ_max=19.2257\n",
      "[SGD | lr=0.01] Epoch 501/4000: train_loss=1.7056  test_loss=2.1577  λ_max=20.4529\n",
      "[SGD | lr=0.01] Epoch 502/4000: train_loss=1.7044  test_loss=2.1575  λ_max=21.1410\n",
      "[SGD | lr=0.01] Epoch 503/4000: train_loss=1.7033  test_loss=2.1576  λ_max=20.3946\n",
      "[SGD | lr=0.01] Epoch 504/4000: train_loss=1.7019  test_loss=2.1574  λ_max=20.8729\n",
      "[SGD | lr=0.01] Epoch 505/4000: train_loss=1.7011  test_loss=2.1571  λ_max=20.4456\n",
      "[SGD | lr=0.01] Epoch 506/4000: train_loss=1.7001  test_loss=2.1573  λ_max=21.1289\n",
      "[SGD | lr=0.01] Iter 8100: loss=1.7045\n",
      "[SGD | lr=0.01] Epoch 507/4000: train_loss=1.6990  test_loss=2.1570  λ_max=21.3668\n",
      "[SGD | lr=0.01] Epoch 508/4000: train_loss=1.6977  test_loss=2.1565  λ_max=20.7094\n",
      "[SGD | lr=0.01] Epoch 509/4000: train_loss=1.6964  test_loss=2.1566  λ_max=20.7338\n",
      "[SGD | lr=0.01] Epoch 510/4000: train_loss=1.6956  test_loss=2.1563  λ_max=20.4546\n",
      "[SGD | lr=0.01] Epoch 511/4000: train_loss=1.6944  test_loss=2.1564  λ_max=20.6034\n",
      "[SGD | lr=0.01] Epoch 512/4000: train_loss=1.6934  test_loss=2.1564  λ_max=20.9458\n",
      "[SGD | lr=0.01] Iter 8200: loss=1.6904\n",
      "[SGD | lr=0.01] Epoch 513/4000: train_loss=1.6918  test_loss=2.1562  λ_max=21.4936\n",
      "[SGD | lr=0.01] Epoch 514/4000: train_loss=1.6908  test_loss=2.1558  λ_max=21.2726\n",
      "[SGD | lr=0.01] Epoch 515/4000: train_loss=1.6897  test_loss=2.1556  λ_max=20.6473\n",
      "[SGD | lr=0.01] Epoch 516/4000: train_loss=1.6885  test_loss=2.1559  λ_max=20.1982\n",
      "[SGD | lr=0.01] Epoch 517/4000: train_loss=1.6878  test_loss=2.1557  λ_max=20.5131\n",
      "[SGD | lr=0.01] Epoch 518/4000: train_loss=1.6866  test_loss=2.1556  λ_max=20.1462\n",
      "[SGD | lr=0.01] Iter 8300: loss=1.6886\n",
      "[SGD | lr=0.01] Epoch 519/4000: train_loss=1.6855  test_loss=2.1554  λ_max=20.2809\n",
      "[SGD | lr=0.01] Epoch 520/4000: train_loss=1.6842  test_loss=2.1552  λ_max=21.9738\n",
      "[SGD | lr=0.01] Epoch 521/4000: train_loss=1.6832  test_loss=2.1550  λ_max=21.5391\n",
      "[SGD | lr=0.01] Epoch 522/4000: train_loss=1.6821  test_loss=2.1549  λ_max=20.2424\n",
      "[SGD | lr=0.01] Epoch 523/4000: train_loss=1.6810  test_loss=2.1547  λ_max=20.7091\n",
      "[SGD | lr=0.01] Epoch 524/4000: train_loss=1.6800  test_loss=2.1545  λ_max=22.0256\n",
      "[SGD | lr=0.01] Iter 8400: loss=1.6712\n",
      "[SGD | lr=0.01] Epoch 525/4000: train_loss=1.6786  test_loss=2.1547  λ_max=22.2566\n",
      "[SGD | lr=0.01] Epoch 526/4000: train_loss=1.6776  test_loss=2.1545  λ_max=21.4683\n",
      "[SGD | lr=0.01] Epoch 527/4000: train_loss=1.6765  test_loss=2.1543  λ_max=20.5079\n",
      "[SGD | lr=0.01] Epoch 528/4000: train_loss=1.6753  test_loss=2.1542  λ_max=21.8545\n",
      "[SGD | lr=0.01] Epoch 529/4000: train_loss=1.6745  test_loss=2.1542  λ_max=21.7523\n",
      "[SGD | lr=0.01] Epoch 530/4000: train_loss=1.6734  test_loss=2.1540  λ_max=21.4111\n",
      "[SGD | lr=0.01] Epoch 531/4000: train_loss=1.6723  test_loss=2.1539  λ_max=21.4024\n",
      "[SGD | lr=0.01] Iter 8500: loss=1.6727\n",
      "[SGD | lr=0.01] Epoch 532/4000: train_loss=1.6711  test_loss=2.1537  λ_max=21.2948\n",
      "[SGD | lr=0.01] Epoch 533/4000: train_loss=1.6700  test_loss=2.1538  λ_max=20.4879\n",
      "[SGD | lr=0.01] Epoch 534/4000: train_loss=1.6689  test_loss=2.1534  λ_max=22.0813\n",
      "[SGD | lr=0.01] Epoch 535/4000: train_loss=1.6682  test_loss=2.1538  λ_max=21.9526\n",
      "[SGD | lr=0.01] Epoch 536/4000: train_loss=1.6668  test_loss=2.1535  λ_max=20.6636\n",
      "[SGD | lr=0.01] Epoch 537/4000: train_loss=1.6656  test_loss=2.1531  λ_max=22.2108\n",
      "[SGD | lr=0.01] Iter 8600: loss=1.6649\n",
      "[SGD | lr=0.01] Epoch 538/4000: train_loss=1.6646  test_loss=2.1529  λ_max=22.1868\n",
      "[SGD | lr=0.01] Epoch 539/4000: train_loss=1.6637  test_loss=2.1533  λ_max=21.3006\n",
      "[SGD | lr=0.01] Epoch 540/4000: train_loss=1.6625  test_loss=2.1528  λ_max=21.7651\n",
      "[SGD | lr=0.01] Epoch 541/4000: train_loss=1.6614  test_loss=2.1526  λ_max=21.7355\n",
      "[SGD | lr=0.01] Epoch 542/4000: train_loss=1.6602  test_loss=2.1530  λ_max=22.6006\n",
      "[SGD | lr=0.01] Epoch 543/4000: train_loss=1.6591  test_loss=2.1526  λ_max=22.8763\n",
      "[SGD | lr=0.01] Iter 8700: loss=1.6702\n",
      "[SGD | lr=0.01] Epoch 544/4000: train_loss=1.6579  test_loss=2.1523  λ_max=22.7865\n",
      "[SGD | lr=0.01] Epoch 545/4000: train_loss=1.6568  test_loss=2.1524  λ_max=22.6510\n",
      "[SGD | lr=0.01] Epoch 546/4000: train_loss=1.6559  test_loss=2.1524  λ_max=21.7403\n",
      "[SGD | lr=0.01] Epoch 547/4000: train_loss=1.6547  test_loss=2.1521  λ_max=22.6486\n",
      "[SGD | lr=0.01] Epoch 548/4000: train_loss=1.6540  test_loss=2.1519  λ_max=21.7631\n",
      "[SGD | lr=0.01] Epoch 549/4000: train_loss=1.6527  test_loss=2.1520  λ_max=22.0612\n",
      "[SGD | lr=0.01] Iter 8800: loss=1.6527\n",
      "[SGD | lr=0.01] Epoch 550/4000: train_loss=1.6517  test_loss=2.1522  λ_max=22.1730\n",
      "[SGD | lr=0.01] Epoch 551/4000: train_loss=1.6506  test_loss=2.1515  λ_max=23.3496\n",
      "[SGD | lr=0.01] Epoch 552/4000: train_loss=1.6496  test_loss=2.1516  λ_max=22.9243\n",
      "[SGD | lr=0.01] Epoch 553/4000: train_loss=1.6485  test_loss=2.1516  λ_max=21.6496\n",
      "[SGD | lr=0.01] Epoch 554/4000: train_loss=1.6476  test_loss=2.1516  λ_max=22.1047\n",
      "[SGD | lr=0.01] Epoch 555/4000: train_loss=1.6461  test_loss=2.1514  λ_max=23.0628\n",
      "[SGD | lr=0.01] Epoch 556/4000: train_loss=1.6453  test_loss=2.1513  λ_max=22.8023\n",
      "[SGD | lr=0.01] Iter 8900: loss=1.6423\n",
      "[SGD | lr=0.01] Epoch 557/4000: train_loss=1.6442  test_loss=2.1511  λ_max=22.7061\n",
      "[SGD | lr=0.01] Epoch 558/4000: train_loss=1.6432  test_loss=2.1511  λ_max=23.4316\n",
      "[SGD | lr=0.01] Epoch 559/4000: train_loss=1.6420  test_loss=2.1509  λ_max=22.3128\n",
      "[SGD | lr=0.01] Epoch 560/4000: train_loss=1.6409  test_loss=2.1509  λ_max=23.0658\n",
      "[SGD | lr=0.01] Epoch 561/4000: train_loss=1.6402  test_loss=2.1508  λ_max=23.2318\n",
      "[SGD | lr=0.01] Epoch 562/4000: train_loss=1.6387  test_loss=2.1508  λ_max=23.3246\n",
      "[SGD | lr=0.01] Iter 9000: loss=1.6390\n",
      "[SGD | lr=0.01] Epoch 563/4000: train_loss=1.6378  test_loss=2.1508  λ_max=22.6166\n",
      "[SGD | lr=0.01] Epoch 564/4000: train_loss=1.6368  test_loss=2.1505  λ_max=23.3394\n",
      "[SGD | lr=0.01] Epoch 565/4000: train_loss=1.6357  test_loss=2.1506  λ_max=23.0239\n",
      "[SGD | lr=0.01] Epoch 566/4000: train_loss=1.6346  test_loss=2.1499  λ_max=23.3761\n",
      "[SGD | lr=0.01] Epoch 567/4000: train_loss=1.6337  test_loss=2.1500  λ_max=22.7072\n",
      "[SGD | lr=0.01] Epoch 568/4000: train_loss=1.6324  test_loss=2.1502  λ_max=23.4778\n",
      "[SGD | lr=0.01] Iter 9100: loss=1.6340\n",
      "[SGD | lr=0.01] Epoch 569/4000: train_loss=1.6313  test_loss=2.1499  λ_max=23.5013\n",
      "[SGD | lr=0.01] Epoch 570/4000: train_loss=1.6305  test_loss=2.1496  λ_max=23.5332\n",
      "[SGD | lr=0.01] Epoch 571/4000: train_loss=1.6296  test_loss=2.1501  λ_max=23.2780\n",
      "[SGD | lr=0.01] Epoch 572/4000: train_loss=1.6282  test_loss=2.1501  λ_max=23.4732\n",
      "[SGD | lr=0.01] Epoch 573/4000: train_loss=1.6272  test_loss=2.1499  λ_max=24.4445\n",
      "[SGD | lr=0.01] Epoch 574/4000: train_loss=1.6260  test_loss=2.1498  λ_max=23.2918\n",
      "[SGD | lr=0.01] Iter 9200: loss=1.6174\n",
      "[SGD | lr=0.01] Epoch 575/4000: train_loss=1.6249  test_loss=2.1498  λ_max=22.2634\n",
      "[SGD | lr=0.01] Epoch 576/4000: train_loss=1.6238  test_loss=2.1494  λ_max=23.9340\n",
      "[SGD | lr=0.01] Epoch 577/4000: train_loss=1.6228  test_loss=2.1493  λ_max=23.1577\n",
      "[SGD | lr=0.01] Epoch 578/4000: train_loss=1.6219  test_loss=2.1493  λ_max=23.9434\n",
      "[SGD | lr=0.01] Epoch 579/4000: train_loss=1.6207  test_loss=2.1491  λ_max=23.2816\n",
      "[SGD | lr=0.01] Epoch 580/4000: train_loss=1.6197  test_loss=2.1491  λ_max=23.9664\n",
      "[SGD | lr=0.01] Epoch 581/4000: train_loss=1.6188  test_loss=2.1490  λ_max=23.4225\n",
      "[SGD | lr=0.01] Iter 9300: loss=1.6188\n",
      "[SGD | lr=0.01] Epoch 582/4000: train_loss=1.6176  test_loss=2.1489  λ_max=24.4758\n",
      "[SGD | lr=0.01] Epoch 583/4000: train_loss=1.6167  test_loss=2.1489  λ_max=24.1944\n",
      "[SGD | lr=0.01] Epoch 584/4000: train_loss=1.6156  test_loss=2.1487  λ_max=24.0940\n",
      "[SGD | lr=0.01] Epoch 585/4000: train_loss=1.6145  test_loss=2.1487  λ_max=24.4595\n",
      "[SGD | lr=0.01] Epoch 586/4000: train_loss=1.6137  test_loss=2.1486  λ_max=24.9867\n",
      "[SGD | lr=0.01] Epoch 587/4000: train_loss=1.6126  test_loss=2.1484  λ_max=25.0143\n",
      "[SGD | lr=0.01] Iter 9400: loss=1.6079\n",
      "[SGD | lr=0.01] Epoch 588/4000: train_loss=1.6112  test_loss=2.1482  λ_max=23.8790\n",
      "[SGD | lr=0.01] Epoch 589/4000: train_loss=1.6104  test_loss=2.1486  λ_max=24.8884\n",
      "[SGD | lr=0.01] Epoch 590/4000: train_loss=1.6095  test_loss=2.1483  λ_max=24.0227\n",
      "[SGD | lr=0.01] Epoch 591/4000: train_loss=1.6082  test_loss=2.1482  λ_max=24.2581\n",
      "[SGD | lr=0.01] Epoch 592/4000: train_loss=1.6074  test_loss=2.1483  λ_max=24.4153\n",
      "[SGD | lr=0.01] Epoch 593/4000: train_loss=1.6063  test_loss=2.1479  λ_max=23.6395\n",
      "[SGD | lr=0.01] Iter 9500: loss=1.6106\n",
      "[SGD | lr=0.01] Epoch 594/4000: train_loss=1.6052  test_loss=2.1479  λ_max=23.1742\n",
      "[SGD | lr=0.01] Epoch 595/4000: train_loss=1.6040  test_loss=2.1480  λ_max=25.2825\n",
      "[SGD | lr=0.01] Epoch 596/4000: train_loss=1.6029  test_loss=2.1476  λ_max=23.5604\n",
      "[SGD | lr=0.01] Epoch 597/4000: train_loss=1.6022  test_loss=2.1477  λ_max=24.6349\n",
      "[SGD | lr=0.01] Epoch 598/4000: train_loss=1.6009  test_loss=2.1475  λ_max=24.9135\n",
      "[SGD | lr=0.01] Epoch 599/4000: train_loss=1.5998  test_loss=2.1474  λ_max=24.0803\n",
      "[SGD | lr=0.01] Iter 9600: loss=1.6094\n",
      "[SGD | lr=0.01] Epoch 600/4000: train_loss=1.5992  test_loss=2.1474  λ_max=24.5440\n",
      "[SGD | lr=0.01] Epoch 601/4000: train_loss=1.5979  test_loss=2.1475  λ_max=25.3214\n",
      "[SGD | lr=0.01] Epoch 602/4000: train_loss=1.5969  test_loss=2.1478  λ_max=24.7098\n",
      "[SGD | lr=0.01] Epoch 603/4000: train_loss=1.5958  test_loss=2.1475  λ_max=24.4453\n",
      "[SGD | lr=0.01] Epoch 604/4000: train_loss=1.5949  test_loss=2.1471  λ_max=24.4135\n",
      "[SGD | lr=0.01] Epoch 605/4000: train_loss=1.5939  test_loss=2.1476  λ_max=25.0674\n",
      "[SGD | lr=0.01] Epoch 606/4000: train_loss=1.5926  test_loss=2.1474  λ_max=25.3031\n",
      "[SGD | lr=0.01] Iter 9700: loss=1.5902\n",
      "[SGD | lr=0.01] Epoch 607/4000: train_loss=1.5917  test_loss=2.1469  λ_max=25.4910\n",
      "[SGD | lr=0.01] Epoch 608/4000: train_loss=1.5908  test_loss=2.1468  λ_max=24.9368\n",
      "[SGD | lr=0.01] Epoch 609/4000: train_loss=1.5895  test_loss=2.1471  λ_max=24.7969\n",
      "[SGD | lr=0.01] Epoch 610/4000: train_loss=1.5885  test_loss=2.1466  λ_max=25.2655\n",
      "[SGD | lr=0.01] Epoch 611/4000: train_loss=1.5876  test_loss=2.1470  λ_max=23.8402\n",
      "[SGD | lr=0.01] Epoch 612/4000: train_loss=1.5867  test_loss=2.1471  λ_max=25.3009\n",
      "[SGD | lr=0.01] Iter 9800: loss=1.5818\n",
      "[SGD | lr=0.01] Epoch 613/4000: train_loss=1.5854  test_loss=2.1468  λ_max=25.9456\n",
      "[SGD | lr=0.01] Epoch 614/4000: train_loss=1.5844  test_loss=2.1465  λ_max=24.2833\n",
      "[SGD | lr=0.01] Epoch 615/4000: train_loss=1.5836  test_loss=2.1468  λ_max=24.4465\n",
      "[SGD | lr=0.01] Epoch 616/4000: train_loss=1.5825  test_loss=2.1464  λ_max=22.9215\n",
      "[SGD | lr=0.01] Epoch 617/4000: train_loss=1.5816  test_loss=2.1464  λ_max=25.8726\n",
      "[SGD | lr=0.01] Epoch 618/4000: train_loss=1.5803  test_loss=2.1465  λ_max=25.9057\n",
      "[SGD | lr=0.01] Iter 9900: loss=1.5781\n",
      "[SGD | lr=0.01] Epoch 619/4000: train_loss=1.5792  test_loss=2.1463  λ_max=24.9597\n",
      "[SGD | lr=0.01] Epoch 620/4000: train_loss=1.5785  test_loss=2.1462  λ_max=25.4665\n",
      "[SGD | lr=0.01] Epoch 621/4000: train_loss=1.5774  test_loss=2.1463  λ_max=24.9342\n",
      "[SGD | lr=0.01] Epoch 622/4000: train_loss=1.5764  test_loss=2.1460  λ_max=26.0694\n",
      "[SGD | lr=0.01] Epoch 623/4000: train_loss=1.5756  test_loss=2.1461  λ_max=24.4776\n",
      "[SGD | lr=0.01] Epoch 624/4000: train_loss=1.5744  test_loss=2.1460  λ_max=25.1924\n",
      "[SGD | lr=0.01] Iter 10000: loss=1.5700\n",
      "[SGD | lr=0.01] Epoch 625/4000: train_loss=1.5732  test_loss=2.1460  λ_max=24.8488\n",
      "[SGD | lr=0.01] Epoch 626/4000: train_loss=1.5723  test_loss=2.1462  λ_max=24.1763\n",
      "[SGD | lr=0.01] Epoch 627/4000: train_loss=1.5710  test_loss=2.1455  λ_max=25.8636\n",
      "[SGD | lr=0.01] Epoch 628/4000: train_loss=1.5702  test_loss=2.1456  λ_max=26.1462\n",
      "[SGD | lr=0.01] Epoch 629/4000: train_loss=1.5691  test_loss=2.1458  λ_max=26.4963\n",
      "[SGD | lr=0.01] Epoch 630/4000: train_loss=1.5682  test_loss=2.1457  λ_max=26.9495\n",
      "[SGD | lr=0.01] Epoch 631/4000: train_loss=1.5672  test_loss=2.1455  λ_max=26.5246\n",
      "[SGD | lr=0.01] Iter 10100: loss=1.5704\n",
      "[SGD | lr=0.01] Epoch 632/4000: train_loss=1.5660  test_loss=2.1456  λ_max=26.9650\n",
      "[SGD | lr=0.01] Epoch 633/4000: train_loss=1.5653  test_loss=2.1452  λ_max=26.4549\n",
      "[SGD | lr=0.01] Epoch 634/4000: train_loss=1.5643  test_loss=2.1456  λ_max=26.6254\n",
      "[SGD | lr=0.01] Epoch 635/4000: train_loss=1.5632  test_loss=2.1457  λ_max=25.9031\n",
      "[SGD | lr=0.01] Epoch 636/4000: train_loss=1.5618  test_loss=2.1452  λ_max=25.3282\n",
      "[SGD | lr=0.01] Epoch 637/4000: train_loss=1.5610  test_loss=2.1454  λ_max=26.8967\n",
      "[SGD | lr=0.01] Iter 10200: loss=1.5611\n",
      "[SGD | lr=0.01] Epoch 638/4000: train_loss=1.5601  test_loss=2.1455  λ_max=26.0016\n",
      "[SGD | lr=0.01] Epoch 639/4000: train_loss=1.5589  test_loss=2.1449  λ_max=25.0326\n",
      "[SGD | lr=0.01] Epoch 640/4000: train_loss=1.5583  test_loss=2.1452  λ_max=25.6711\n",
      "[SGD | lr=0.01] Epoch 641/4000: train_loss=1.5570  test_loss=2.1452  λ_max=24.6658\n",
      "[SGD | lr=0.01] Epoch 642/4000: train_loss=1.5559  test_loss=2.1454  λ_max=25.7120\n",
      "[SGD | lr=0.01] Epoch 643/4000: train_loss=1.5548  test_loss=2.1452  λ_max=26.4700\n",
      "[SGD | lr=0.01] Iter 10300: loss=1.5581\n",
      "[SGD | lr=0.01] Epoch 644/4000: train_loss=1.5539  test_loss=2.1450  λ_max=26.4207\n",
      "[SGD | lr=0.01] Epoch 645/4000: train_loss=1.5530  test_loss=2.1448  λ_max=26.5959\n",
      "[SGD | lr=0.01] Epoch 646/4000: train_loss=1.5522  test_loss=2.1452  λ_max=24.9085\n",
      "[SGD | lr=0.01] Epoch 647/4000: train_loss=1.5510  test_loss=2.1451  λ_max=26.4017\n",
      "[SGD | lr=0.01] Epoch 648/4000: train_loss=1.5500  test_loss=2.1449  λ_max=27.0111\n",
      "[SGD | lr=0.01] Epoch 649/4000: train_loss=1.5491  test_loss=2.1447  λ_max=25.6108\n",
      "[SGD | lr=0.01] Iter 10400: loss=1.5420\n",
      "[SGD | lr=0.01] Epoch 650/4000: train_loss=1.5479  test_loss=2.1448  λ_max=26.9071\n",
      "[SGD | lr=0.01] Epoch 651/4000: train_loss=1.5468  test_loss=2.1448  λ_max=27.3554\n",
      "[SGD | lr=0.01] Epoch 652/4000: train_loss=1.5460  test_loss=2.1446  λ_max=26.6914\n",
      "[SGD | lr=0.01] Epoch 653/4000: train_loss=1.5449  test_loss=2.1448  λ_max=28.0171\n",
      "[SGD | lr=0.01] Epoch 654/4000: train_loss=1.5438  test_loss=2.1446  λ_max=27.8375\n",
      "[SGD | lr=0.01] Epoch 655/4000: train_loss=1.5431  test_loss=2.1446  λ_max=28.0404\n",
      "[SGD | lr=0.01] Epoch 656/4000: train_loss=1.5420  test_loss=2.1448  λ_max=27.4756\n",
      "[SGD | lr=0.01] Iter 10500: loss=1.5414\n",
      "[SGD | lr=0.01] Epoch 657/4000: train_loss=1.5410  test_loss=2.1443  λ_max=27.5203\n",
      "[SGD | lr=0.01] Epoch 658/4000: train_loss=1.5398  test_loss=2.1450  λ_max=27.0379\n",
      "[SGD | lr=0.01] Epoch 659/4000: train_loss=1.5392  test_loss=2.1443  λ_max=27.7336\n",
      "[SGD | lr=0.01] Epoch 660/4000: train_loss=1.5383  test_loss=2.1445  λ_max=27.0328\n",
      "[SGD | lr=0.01] Epoch 661/4000: train_loss=1.5369  test_loss=2.1441  λ_max=25.8747\n",
      "[SGD | lr=0.01] Epoch 662/4000: train_loss=1.5362  test_loss=2.1442  λ_max=28.2219\n",
      "[SGD | lr=0.01] Iter 10600: loss=1.5396\n",
      "[SGD | lr=0.01] Epoch 663/4000: train_loss=1.5351  test_loss=2.1443  λ_max=27.5013\n",
      "[SGD | lr=0.01] Epoch 664/4000: train_loss=1.5345  test_loss=2.1442  λ_max=28.6057\n",
      "[SGD | lr=0.01] Epoch 665/4000: train_loss=1.5328  test_loss=2.1441  λ_max=28.0467\n",
      "[SGD | lr=0.01] Epoch 666/4000: train_loss=1.5321  test_loss=2.1442  λ_max=28.3127\n",
      "[SGD | lr=0.01] Epoch 667/4000: train_loss=1.5313  test_loss=2.1440  λ_max=28.2742\n",
      "[SGD | lr=0.01] Epoch 668/4000: train_loss=1.5301  test_loss=2.1443  λ_max=27.9117\n",
      "[SGD | lr=0.01] Iter 10700: loss=1.5280\n",
      "[SGD | lr=0.01] Epoch 669/4000: train_loss=1.5291  test_loss=2.1443  λ_max=28.0310\n",
      "[SGD | lr=0.01] Epoch 670/4000: train_loss=1.5282  test_loss=2.1442  λ_max=27.7110\n",
      "[SGD | lr=0.01] Epoch 671/4000: train_loss=1.5270  test_loss=2.1438  λ_max=27.8928\n",
      "[SGD | lr=0.01] Epoch 672/4000: train_loss=1.5261  test_loss=2.1440  λ_max=28.4921\n",
      "[SGD | lr=0.01] Epoch 673/4000: train_loss=1.5251  test_loss=2.1440  λ_max=27.7847\n",
      "[SGD | lr=0.01] Epoch 674/4000: train_loss=1.5242  test_loss=2.1441  λ_max=28.9675\n",
      "[SGD | lr=0.01] Iter 10800: loss=1.5195\n",
      "[SGD | lr=0.01] Epoch 675/4000: train_loss=1.5231  test_loss=2.1439  λ_max=28.8280\n",
      "[SGD | lr=0.01] Epoch 676/4000: train_loss=1.5220  test_loss=2.1440  λ_max=27.9094\n",
      "[SGD | lr=0.01] Epoch 677/4000: train_loss=1.5211  test_loss=2.1440  λ_max=26.0563\n",
      "[SGD | lr=0.01] Epoch 678/4000: train_loss=1.5201  test_loss=2.1438  λ_max=28.9113\n",
      "[SGD | lr=0.01] Epoch 679/4000: train_loss=1.5196  test_loss=2.1438  λ_max=28.7722\n",
      "[SGD | lr=0.01] Epoch 680/4000: train_loss=1.5179  test_loss=2.1436  λ_max=28.5147\n",
      "[SGD | lr=0.01] Epoch 681/4000: train_loss=1.5171  test_loss=2.1436  λ_max=28.6184\n",
      "[SGD | lr=0.01] Iter 10900: loss=1.5099\n",
      "[SGD | lr=0.01] Epoch 682/4000: train_loss=1.5163  test_loss=2.1440  λ_max=28.7399\n",
      "[SGD | lr=0.01] Epoch 683/4000: train_loss=1.5153  test_loss=2.1436  λ_max=29.1848\n",
      "[SGD | lr=0.01] Epoch 684/4000: train_loss=1.5142  test_loss=2.1439  λ_max=28.9084\n",
      "[SGD | lr=0.01] Epoch 685/4000: train_loss=1.5135  test_loss=2.1434  λ_max=27.9138\n",
      "[SGD | lr=0.01] Epoch 686/4000: train_loss=1.5122  test_loss=2.1437  λ_max=29.0361\n",
      "[SGD | lr=0.01] Epoch 687/4000: train_loss=1.5112  test_loss=2.1435  λ_max=27.6172\n",
      "[SGD | lr=0.01] Iter 11000: loss=1.5113\n",
      "[SGD | lr=0.01] Epoch 688/4000: train_loss=1.5102  test_loss=2.1436  λ_max=29.2013\n",
      "[SGD | lr=0.01] Epoch 689/4000: train_loss=1.5096  test_loss=2.1434  λ_max=27.8533\n",
      "[SGD | lr=0.01] Epoch 690/4000: train_loss=1.5083  test_loss=2.1434  λ_max=28.6888\n",
      "[SGD | lr=0.01] Epoch 691/4000: train_loss=1.5074  test_loss=2.1435  λ_max=29.5931\n",
      "[SGD | lr=0.01] Epoch 692/4000: train_loss=1.5065  test_loss=2.1438  λ_max=27.6786\n",
      "[SGD | lr=0.01] Epoch 693/4000: train_loss=1.5054  test_loss=2.1435  λ_max=29.6973\n",
      "[SGD | lr=0.01] Iter 11100: loss=1.5031\n",
      "[SGD | lr=0.01] Epoch 694/4000: train_loss=1.5043  test_loss=2.1434  λ_max=29.8673\n",
      "[SGD | lr=0.01] Epoch 695/4000: train_loss=1.5036  test_loss=2.1437  λ_max=28.9895\n",
      "[SGD | lr=0.01] Epoch 696/4000: train_loss=1.5025  test_loss=2.1435  λ_max=28.6167\n",
      "[SGD | lr=0.01] Epoch 697/4000: train_loss=1.5016  test_loss=2.1432  λ_max=29.9735\n",
      "[SGD | lr=0.01] Epoch 698/4000: train_loss=1.5006  test_loss=2.1433  λ_max=28.9823\n",
      "[SGD | lr=0.01] Epoch 699/4000: train_loss=1.4999  test_loss=2.1433  λ_max=26.4996\n",
      "[SGD | lr=0.01] Iter 11200: loss=1.5015\n",
      "[SGD | lr=0.01] Epoch 700/4000: train_loss=1.4987  test_loss=2.1433  λ_max=27.0678\n",
      "[SGD | lr=0.01] Epoch 701/4000: train_loss=1.4978  test_loss=2.1437  λ_max=28.4845\n",
      "[SGD | lr=0.01] Epoch 702/4000: train_loss=1.4965  test_loss=2.1435  λ_max=28.8080\n",
      "[SGD | lr=0.01] Epoch 703/4000: train_loss=1.4956  test_loss=2.1432  λ_max=29.8140\n",
      "[SGD | lr=0.01] Epoch 704/4000: train_loss=1.4948  test_loss=2.1432  λ_max=29.3385\n",
      "[SGD | lr=0.01] Epoch 705/4000: train_loss=1.4940  test_loss=2.1434  λ_max=28.9158\n",
      "[SGD | lr=0.01] Epoch 706/4000: train_loss=1.4925  test_loss=2.1435  λ_max=30.1836\n",
      "[SGD | lr=0.01] Iter 11300: loss=1.5016\n",
      "[SGD | lr=0.01] Epoch 707/4000: train_loss=1.4917  test_loss=2.1430  λ_max=28.5704\n",
      "[SGD | lr=0.01] Epoch 708/4000: train_loss=1.4907  test_loss=2.1430  λ_max=29.9909\n",
      "[SGD | lr=0.01] Epoch 709/4000: train_loss=1.4898  test_loss=2.1436  λ_max=30.3357\n",
      "[SGD | lr=0.01] Epoch 710/4000: train_loss=1.4888  test_loss=2.1432  λ_max=29.9731\n",
      "[SGD | lr=0.01] Epoch 711/4000: train_loss=1.4877  test_loss=2.1436  λ_max=29.1706\n",
      "[SGD | lr=0.01] Epoch 712/4000: train_loss=1.4870  test_loss=2.1432  λ_max=30.0600\n",
      "[SGD | lr=0.01] Iter 11400: loss=1.4884\n",
      "[SGD | lr=0.01] Epoch 713/4000: train_loss=1.4860  test_loss=2.1433  λ_max=28.2328\n",
      "[SGD | lr=0.01] Epoch 714/4000: train_loss=1.4850  test_loss=2.1433  λ_max=30.2673\n",
      "[SGD | lr=0.01] Epoch 715/4000: train_loss=1.4839  test_loss=2.1434  λ_max=30.0480\n",
      "[SGD | lr=0.01] Epoch 716/4000: train_loss=1.4827  test_loss=2.1434  λ_max=30.1166\n",
      "[SGD | lr=0.01] Epoch 717/4000: train_loss=1.4819  test_loss=2.1433  λ_max=29.0076\n",
      "[SGD | lr=0.01] Epoch 718/4000: train_loss=1.4811  test_loss=2.1432  λ_max=29.5415\n",
      "[SGD | lr=0.01] Iter 11500: loss=1.4790\n",
      "[SGD | lr=0.01] Epoch 719/4000: train_loss=1.4803  test_loss=2.1435  λ_max=30.6325\n",
      "[SGD | lr=0.01] Epoch 720/4000: train_loss=1.4789  test_loss=2.1433  λ_max=30.2065\n",
      "[SGD | lr=0.01] Epoch 721/4000: train_loss=1.4783  test_loss=2.1433  λ_max=30.6501\n",
      "[SGD | lr=0.01] Epoch 722/4000: train_loss=1.4772  test_loss=2.1431  λ_max=30.8475\n",
      "[SGD | lr=0.01] Epoch 723/4000: train_loss=1.4764  test_loss=2.1429  λ_max=27.9649\n",
      "[SGD | lr=0.01] Epoch 724/4000: train_loss=1.4755  test_loss=2.1429  λ_max=30.4282\n",
      "[SGD | lr=0.01] Iter 11600: loss=1.4788\n",
      "[SGD | lr=0.01] Epoch 725/4000: train_loss=1.4745  test_loss=2.1432  λ_max=30.9134\n",
      "[SGD | lr=0.01] Epoch 726/4000: train_loss=1.4735  test_loss=2.1432  λ_max=29.0079\n",
      "[SGD | lr=0.01] Epoch 727/4000: train_loss=1.4728  test_loss=2.1431  λ_max=31.0493\n",
      "[SGD | lr=0.01] Epoch 728/4000: train_loss=1.4713  test_loss=2.1428  λ_max=30.6446\n",
      "[SGD | lr=0.01] Epoch 729/4000: train_loss=1.4704  test_loss=2.1437  λ_max=30.4110\n",
      "[SGD | lr=0.01] Epoch 730/4000: train_loss=1.4695  test_loss=2.1434  λ_max=29.4198\n",
      "[SGD | lr=0.01] Epoch 731/4000: train_loss=1.4685  test_loss=2.1432  λ_max=30.3610\n",
      "[SGD | lr=0.01] Iter 11700: loss=1.4663\n",
      "[SGD | lr=0.01] Epoch 732/4000: train_loss=1.4677  test_loss=2.1432  λ_max=30.2371\n",
      "[SGD | lr=0.01] Epoch 733/4000: train_loss=1.4665  test_loss=2.1431  λ_max=30.6041\n",
      "[SGD | lr=0.01] Epoch 734/4000: train_loss=1.4655  test_loss=2.1434  λ_max=31.5314\n",
      "[SGD | lr=0.01] Epoch 735/4000: train_loss=1.4648  test_loss=2.1429  λ_max=31.1005\n",
      "[SGD | lr=0.01] Epoch 736/4000: train_loss=1.4638  test_loss=2.1430  λ_max=32.0976\n",
      "[SGD | lr=0.01] Epoch 737/4000: train_loss=1.4629  test_loss=2.1431  λ_max=31.2388\n",
      "[SGD | lr=0.01] Iter 11800: loss=1.4611\n",
      "[SGD | lr=0.01] Epoch 738/4000: train_loss=1.4618  test_loss=2.1429  λ_max=31.5548\n",
      "[SGD | lr=0.01] Epoch 739/4000: train_loss=1.4610  test_loss=2.1428  λ_max=31.9500\n",
      "[SGD | lr=0.01] Epoch 740/4000: train_loss=1.4601  test_loss=2.1430  λ_max=31.9040\n",
      "[SGD | lr=0.01] Epoch 741/4000: train_loss=1.4590  test_loss=2.1428  λ_max=30.9695\n",
      "[SGD | lr=0.01] Epoch 742/4000: train_loss=1.4578  test_loss=2.1434  λ_max=31.8256\n",
      "[SGD | lr=0.01] Epoch 743/4000: train_loss=1.4572  test_loss=2.1433  λ_max=31.7415\n",
      "[SGD | lr=0.01] Iter 11900: loss=1.4599\n",
      "[SGD | lr=0.01] Epoch 744/4000: train_loss=1.4562  test_loss=2.1428  λ_max=30.9691\n",
      "[SGD | lr=0.01] Epoch 745/4000: train_loss=1.4551  test_loss=2.1432  λ_max=31.9019\n",
      "[SGD | lr=0.01] Epoch 746/4000: train_loss=1.4542  test_loss=2.1429  λ_max=31.8267\n",
      "[SGD | lr=0.01] Epoch 747/4000: train_loss=1.4533  test_loss=2.1434  λ_max=31.0511\n",
      "[SGD | lr=0.01] Epoch 748/4000: train_loss=1.4522  test_loss=2.1436  λ_max=31.1045\n",
      "[SGD | lr=0.01] Epoch 749/4000: train_loss=1.4515  test_loss=2.1428  λ_max=30.9367\n",
      "[SGD | lr=0.01] Iter 12000: loss=1.4655\n",
      "[SGD | lr=0.01] Epoch 750/4000: train_loss=1.4508  test_loss=2.1431  λ_max=32.3235\n",
      "[SGD | lr=0.01] Epoch 751/4000: train_loss=1.4495  test_loss=2.1429  λ_max=32.5166\n",
      "[SGD | lr=0.01] Epoch 752/4000: train_loss=1.4485  test_loss=2.1430  λ_max=32.2234\n",
      "[SGD | lr=0.01] Epoch 753/4000: train_loss=1.4475  test_loss=2.1431  λ_max=32.8966\n",
      "[SGD | lr=0.01] Epoch 754/4000: train_loss=1.4465  test_loss=2.1431  λ_max=32.7898\n",
      "[SGD | lr=0.01] Epoch 755/4000: train_loss=1.4455  test_loss=2.1434  λ_max=32.4202\n",
      "[SGD | lr=0.01] Epoch 756/4000: train_loss=1.4448  test_loss=2.1429  λ_max=31.7307\n",
      "[SGD | lr=0.01] Iter 12100: loss=1.4436\n",
      "[SGD | lr=0.01] Epoch 757/4000: train_loss=1.4439  test_loss=2.1429  λ_max=30.1100\n",
      "[SGD | lr=0.01] Epoch 758/4000: train_loss=1.4426  test_loss=2.1435  λ_max=32.6813\n",
      "[SGD | lr=0.01] Epoch 759/4000: train_loss=1.4419  test_loss=2.1432  λ_max=32.2415\n",
      "[SGD | lr=0.01] Epoch 760/4000: train_loss=1.4410  test_loss=2.1433  λ_max=32.5327\n",
      "[SGD | lr=0.01] Epoch 761/4000: train_loss=1.4402  test_loss=2.1433  λ_max=32.7138\n",
      "[SGD | lr=0.01] Epoch 762/4000: train_loss=1.4392  test_loss=2.1432  λ_max=32.6637\n",
      "[SGD | lr=0.01] Iter 12200: loss=1.4436\n",
      "[SGD | lr=0.01] Epoch 763/4000: train_loss=1.4383  test_loss=2.1435  λ_max=33.2584\n",
      "[SGD | lr=0.01] Epoch 764/4000: train_loss=1.4373  test_loss=2.1432  λ_max=32.9502\n",
      "[SGD | lr=0.01] Epoch 765/4000: train_loss=1.4364  test_loss=2.1431  λ_max=32.5249\n",
      "[SGD | lr=0.01] Epoch 766/4000: train_loss=1.4352  test_loss=2.1431  λ_max=32.8092\n",
      "[SGD | lr=0.01] Epoch 767/4000: train_loss=1.4344  test_loss=2.1433  λ_max=33.4482\n",
      "[SGD | lr=0.01] Epoch 768/4000: train_loss=1.4331  test_loss=2.1436  λ_max=32.5295\n",
      "[SGD | lr=0.01] Iter 12300: loss=1.4312\n",
      "[SGD | lr=0.01] Epoch 769/4000: train_loss=1.4325  test_loss=2.1439  λ_max=32.5995\n",
      "[SGD | lr=0.01] Epoch 770/4000: train_loss=1.4315  test_loss=2.1435  λ_max=33.3009\n",
      "[SGD | lr=0.01] Epoch 771/4000: train_loss=1.4308  test_loss=2.1433  λ_max=33.6279\n",
      "[SGD | lr=0.01] Epoch 772/4000: train_loss=1.4297  test_loss=2.1433  λ_max=33.5048\n",
      "[SGD | lr=0.01] Epoch 773/4000: train_loss=1.4286  test_loss=2.1430  λ_max=31.7344\n",
      "[SGD | lr=0.01] Epoch 774/4000: train_loss=1.4275  test_loss=2.1430  λ_max=33.6082\n",
      "[SGD | lr=0.01] Iter 12400: loss=1.4311\n",
      "[SGD | lr=0.01] Epoch 775/4000: train_loss=1.4269  test_loss=2.1436  λ_max=31.5552\n",
      "[SGD | lr=0.01] Epoch 776/4000: train_loss=1.4262  test_loss=2.1434  λ_max=32.6411\n",
      "[SGD | lr=0.01] Epoch 777/4000: train_loss=1.4251  test_loss=2.1434  λ_max=33.8017\n",
      "[SGD | lr=0.01] Epoch 778/4000: train_loss=1.4241  test_loss=2.1429  λ_max=32.4370\n",
      "[SGD | lr=0.01] Epoch 779/4000: train_loss=1.4229  test_loss=2.1437  λ_max=32.5186\n",
      "[SGD | lr=0.01] Epoch 780/4000: train_loss=1.4221  test_loss=2.1437  λ_max=32.5685\n",
      "[SGD | lr=0.01] Epoch 781/4000: train_loss=1.4214  test_loss=2.1435  λ_max=33.9834\n",
      "[SGD | lr=0.01] Iter 12500: loss=1.4303\n",
      "[SGD | lr=0.01] Epoch 782/4000: train_loss=1.4201  test_loss=2.1433  λ_max=34.2267\n",
      "[SGD | lr=0.01] Epoch 783/4000: train_loss=1.4193  test_loss=2.1436  λ_max=33.7083\n",
      "[SGD | lr=0.01] Epoch 784/4000: train_loss=1.4185  test_loss=2.1435  λ_max=34.0928\n",
      "[SGD | lr=0.01] Epoch 785/4000: train_loss=1.4174  test_loss=2.1434  λ_max=32.4789\n",
      "[SGD | lr=0.01] Epoch 786/4000: train_loss=1.4164  test_loss=2.1436  λ_max=32.7797\n",
      "[SGD | lr=0.01] Epoch 787/4000: train_loss=1.4156  test_loss=2.1434  λ_max=33.5492\n",
      "[SGD | lr=0.01] Iter 12600: loss=1.4214\n",
      "[SGD | lr=0.01] Epoch 788/4000: train_loss=1.4146  test_loss=2.1434  λ_max=33.9961\n",
      "[SGD | lr=0.01] Epoch 789/4000: train_loss=1.4137  test_loss=2.1435  λ_max=31.7313\n",
      "[SGD | lr=0.01] Epoch 790/4000: train_loss=1.4128  test_loss=2.1438  λ_max=34.1590\n",
      "[SGD | lr=0.01] Epoch 791/4000: train_loss=1.4120  test_loss=2.1437  λ_max=32.2385\n",
      "[SGD | lr=0.01] Epoch 792/4000: train_loss=1.4109  test_loss=2.1436  λ_max=33.6429\n",
      "[SGD | lr=0.01] Epoch 793/4000: train_loss=1.4102  test_loss=2.1441  λ_max=33.4051\n",
      "[SGD | lr=0.01] Iter 12700: loss=1.4018\n",
      "[SGD | lr=0.01] Epoch 794/4000: train_loss=1.4089  test_loss=2.1437  λ_max=33.9483\n",
      "[SGD | lr=0.01] Epoch 795/4000: train_loss=1.4079  test_loss=2.1436  λ_max=33.9941\n",
      "[SGD | lr=0.01] Epoch 796/4000: train_loss=1.4071  test_loss=2.1441  λ_max=34.2578\n",
      "[SGD | lr=0.01] Epoch 797/4000: train_loss=1.4062  test_loss=2.1441  λ_max=34.8331\n",
      "[SGD | lr=0.01] Epoch 798/4000: train_loss=1.4053  test_loss=2.1439  λ_max=35.0842\n",
      "[SGD | lr=0.01] Epoch 799/4000: train_loss=1.4043  test_loss=2.1438  λ_max=33.9744\n",
      "[SGD | lr=0.01] Iter 12800: loss=1.4128\n",
      "[SGD | lr=0.01] Epoch 800/4000: train_loss=1.4037  test_loss=2.1440  λ_max=34.6726\n",
      "[SGD | lr=0.01] Epoch 801/4000: train_loss=1.4027  test_loss=2.1438  λ_max=34.6090\n",
      "[SGD | lr=0.01] Epoch 802/4000: train_loss=1.4016  test_loss=2.1439  λ_max=33.7754\n",
      "[SGD | lr=0.01] Epoch 803/4000: train_loss=1.4007  test_loss=2.1440  λ_max=34.2816\n",
      "[SGD | lr=0.01] Epoch 804/4000: train_loss=1.3996  test_loss=2.1437  λ_max=34.2539\n",
      "[SGD | lr=0.01] Epoch 805/4000: train_loss=1.3988  test_loss=2.1439  λ_max=35.3027\n",
      "[SGD | lr=0.01] Epoch 806/4000: train_loss=1.3978  test_loss=2.1440  λ_max=32.9116\n",
      "[SGD | lr=0.01] Iter 12900: loss=1.3979\n",
      "[SGD | lr=0.01] Epoch 807/4000: train_loss=1.3969  test_loss=2.1440  λ_max=35.5088\n",
      "[SGD | lr=0.01] Epoch 808/4000: train_loss=1.3959  test_loss=2.1438  λ_max=31.7600\n",
      "[SGD | lr=0.01] Epoch 809/4000: train_loss=1.3949  test_loss=2.1441  λ_max=35.6050\n",
      "[SGD | lr=0.01] Epoch 810/4000: train_loss=1.3944  test_loss=2.1439  λ_max=33.3620\n",
      "[SGD | lr=0.01] Epoch 811/4000: train_loss=1.3931  test_loss=2.1439  λ_max=35.1815\n",
      "[SGD | lr=0.01] Epoch 812/4000: train_loss=1.3924  test_loss=2.1442  λ_max=33.5319\n",
      "[SGD | lr=0.01] Iter 13000: loss=1.3817\n",
      "[SGD | lr=0.01] Epoch 813/4000: train_loss=1.3917  test_loss=2.1444  λ_max=33.6007\n",
      "[SGD | lr=0.01] Epoch 814/4000: train_loss=1.3903  test_loss=2.1442  λ_max=34.1008\n",
      "[SGD | lr=0.01] Epoch 815/4000: train_loss=1.3899  test_loss=2.1444  λ_max=35.2386\n",
      "[SGD | lr=0.01] Epoch 816/4000: train_loss=1.3885  test_loss=2.1443  λ_max=35.0553\n",
      "[SGD | lr=0.01] Epoch 817/4000: train_loss=1.3878  test_loss=2.1442  λ_max=33.9340\n",
      "[SGD | lr=0.01] Epoch 818/4000: train_loss=1.3866  test_loss=2.1444  λ_max=35.7340\n",
      "[SGD | lr=0.01] Iter 13100: loss=1.3842\n",
      "[SGD | lr=0.01] Epoch 819/4000: train_loss=1.3858  test_loss=2.1445  λ_max=35.2901\n",
      "[SGD | lr=0.01] Epoch 820/4000: train_loss=1.3849  test_loss=2.1442  λ_max=35.4136\n",
      "[SGD | lr=0.01] Epoch 821/4000: train_loss=1.3840  test_loss=2.1445  λ_max=33.5741\n",
      "[SGD | lr=0.01] Epoch 822/4000: train_loss=1.3830  test_loss=2.1449  λ_max=33.4631\n",
      "[SGD | lr=0.01] Epoch 823/4000: train_loss=1.3822  test_loss=2.1449  λ_max=35.0297\n",
      "[SGD | lr=0.01] Epoch 824/4000: train_loss=1.3811  test_loss=2.1447  λ_max=33.3953\n",
      "[SGD | lr=0.01] Iter 13200: loss=1.3974\n",
      "[SGD | lr=0.01] Epoch 825/4000: train_loss=1.3808  test_loss=2.1446  λ_max=36.2785\n",
      "[SGD | lr=0.01] Epoch 826/4000: train_loss=1.3794  test_loss=2.1447  λ_max=35.9282\n",
      "[SGD | lr=0.01] Epoch 827/4000: train_loss=1.3785  test_loss=2.1447  λ_max=36.3093\n",
      "[SGD | lr=0.01] Epoch 828/4000: train_loss=1.3777  test_loss=2.1449  λ_max=35.7316\n",
      "[SGD | lr=0.01] Epoch 829/4000: train_loss=1.3770  test_loss=2.1450  λ_max=35.4946\n",
      "[SGD | lr=0.01] Epoch 830/4000: train_loss=1.3758  test_loss=2.1448  λ_max=35.7290\n",
      "[SGD | lr=0.01] Epoch 831/4000: train_loss=1.3751  test_loss=2.1449  λ_max=33.9535\n",
      "[SGD | lr=0.01] Iter 13300: loss=1.3763\n",
      "[SGD | lr=0.01] Epoch 832/4000: train_loss=1.3740  test_loss=2.1451  λ_max=36.0013\n",
      "[SGD | lr=0.01] Epoch 833/4000: train_loss=1.3732  test_loss=2.1454  λ_max=36.2260\n",
      "[SGD | lr=0.01] Epoch 834/4000: train_loss=1.3724  test_loss=2.1452  λ_max=36.4611\n",
      "[SGD | lr=0.01] Epoch 835/4000: train_loss=1.3712  test_loss=2.1450  λ_max=36.6313\n",
      "[SGD | lr=0.01] Epoch 836/4000: train_loss=1.3703  test_loss=2.1451  λ_max=36.6622\n",
      "[SGD | lr=0.01] Epoch 837/4000: train_loss=1.3695  test_loss=2.1457  λ_max=35.0850\n",
      "[SGD | lr=0.01] Iter 13400: loss=1.3647\n",
      "[SGD | lr=0.01] Epoch 838/4000: train_loss=1.3689  test_loss=2.1450  λ_max=36.5680\n",
      "[SGD | lr=0.01] Epoch 839/4000: train_loss=1.3678  test_loss=2.1456  λ_max=33.7956\n",
      "[SGD | lr=0.01] Epoch 840/4000: train_loss=1.3669  test_loss=2.1454  λ_max=35.5846\n",
      "[SGD | lr=0.01] Epoch 841/4000: train_loss=1.3657  test_loss=2.1454  λ_max=34.8648\n",
      "[SGD | lr=0.01] Epoch 842/4000: train_loss=1.3648  test_loss=2.1457  λ_max=36.5258\n",
      "[SGD | lr=0.01] Epoch 843/4000: train_loss=1.3637  test_loss=2.1458  λ_max=35.5360\n",
      "[SGD | lr=0.01] Iter 13500: loss=1.3688\n",
      "[SGD | lr=0.01] Epoch 844/4000: train_loss=1.3629  test_loss=2.1459  λ_max=36.3660\n",
      "[SGD | lr=0.01] Epoch 845/4000: train_loss=1.3620  test_loss=2.1458  λ_max=36.9867\n",
      "[SGD | lr=0.01] Epoch 846/4000: train_loss=1.3613  test_loss=2.1454  λ_max=36.7954\n",
      "[SGD | lr=0.01] Epoch 847/4000: train_loss=1.3602  test_loss=2.1460  λ_max=37.1080\n",
      "[SGD | lr=0.01] Epoch 848/4000: train_loss=1.3595  test_loss=2.1460  λ_max=36.3486\n",
      "[SGD | lr=0.01] Epoch 849/4000: train_loss=1.3587  test_loss=2.1460  λ_max=34.9739\n",
      "[SGD | lr=0.01] Iter 13600: loss=1.3630\n",
      "[SGD | lr=0.01] Epoch 850/4000: train_loss=1.3577  test_loss=2.1461  λ_max=37.3650\n",
      "[SGD | lr=0.01] Epoch 851/4000: train_loss=1.3567  test_loss=2.1459  λ_max=37.8362\n",
      "[SGD | lr=0.01] Epoch 852/4000: train_loss=1.3559  test_loss=2.1463  λ_max=36.7485\n",
      "[SGD | lr=0.01] Epoch 853/4000: train_loss=1.3552  test_loss=2.1466  λ_max=37.5333\n",
      "[SGD | lr=0.01] Epoch 854/4000: train_loss=1.3537  test_loss=2.1468  λ_max=37.4449\n",
      "[SGD | lr=0.01] Epoch 855/4000: train_loss=1.3531  test_loss=2.1465  λ_max=35.9569\n",
      "[SGD | lr=0.01] Epoch 856/4000: train_loss=1.3521  test_loss=2.1464  λ_max=37.7021\n",
      "[SGD | lr=0.01] Iter 13700: loss=1.3474\n",
      "[SGD | lr=0.01] Epoch 857/4000: train_loss=1.3511  test_loss=2.1466  λ_max=37.2643\n",
      "[SGD | lr=0.01] Epoch 858/4000: train_loss=1.3501  test_loss=2.1466  λ_max=37.1148\n",
      "[SGD | lr=0.01] Epoch 859/4000: train_loss=1.3496  test_loss=2.1463  λ_max=37.1298\n",
      "[SGD | lr=0.01] Epoch 860/4000: train_loss=1.3485  test_loss=2.1464  λ_max=38.2680\n",
      "[SGD | lr=0.01] Epoch 861/4000: train_loss=1.3479  test_loss=2.1469  λ_max=37.6653\n",
      "[SGD | lr=0.01] Epoch 862/4000: train_loss=1.3468  test_loss=2.1469  λ_max=37.0736\n",
      "[SGD | lr=0.01] Iter 13800: loss=1.3445\n",
      "[SGD | lr=0.01] Epoch 863/4000: train_loss=1.3461  test_loss=2.1469  λ_max=37.7634\n",
      "[SGD | lr=0.01] Epoch 864/4000: train_loss=1.3451  test_loss=2.1468  λ_max=37.3949\n",
      "[SGD | lr=0.01] Epoch 865/4000: train_loss=1.3440  test_loss=2.1476  λ_max=36.4708\n",
      "[SGD | lr=0.01] Epoch 866/4000: train_loss=1.3433  test_loss=2.1470  λ_max=37.4092\n",
      "[SGD | lr=0.01] Epoch 867/4000: train_loss=1.3423  test_loss=2.1471  λ_max=37.7609\n",
      "[SGD | lr=0.01] Epoch 868/4000: train_loss=1.3411  test_loss=2.1473  λ_max=36.5937\n",
      "[SGD | lr=0.01] Iter 13900: loss=1.3443\n",
      "[SGD | lr=0.01] Epoch 869/4000: train_loss=1.3401  test_loss=2.1475  λ_max=36.5187\n",
      "[SGD | lr=0.01] Epoch 870/4000: train_loss=1.3395  test_loss=2.1475  λ_max=36.4115\n",
      "[SGD | lr=0.01] Epoch 871/4000: train_loss=1.3384  test_loss=2.1476  λ_max=38.7366\n",
      "[SGD | lr=0.01] Epoch 872/4000: train_loss=1.3377  test_loss=2.1476  λ_max=37.3312\n",
      "[SGD | lr=0.01] Epoch 873/4000: train_loss=1.3368  test_loss=2.1474  λ_max=37.8590\n",
      "[SGD | lr=0.01] Epoch 874/4000: train_loss=1.3358  test_loss=2.1475  λ_max=37.6440\n",
      "[SGD | lr=0.01] Iter 14000: loss=1.3343\n",
      "[SGD | lr=0.01] Epoch 875/4000: train_loss=1.3350  test_loss=2.1478  λ_max=38.7583\n",
      "[SGD | lr=0.01] Epoch 876/4000: train_loss=1.3342  test_loss=2.1482  λ_max=36.2431\n",
      "[SGD | lr=0.01] Epoch 877/4000: train_loss=1.3334  test_loss=2.1478  λ_max=39.0630\n",
      "[SGD | lr=0.01] Epoch 878/4000: train_loss=1.3324  test_loss=2.1478  λ_max=38.8767\n",
      "[SGD | lr=0.01] Epoch 879/4000: train_loss=1.3315  test_loss=2.1483  λ_max=37.8551\n",
      "[SGD | lr=0.01] Epoch 880/4000: train_loss=1.3302  test_loss=2.1482  λ_max=38.0299\n",
      "[SGD | lr=0.01] Epoch 881/4000: train_loss=1.3299  test_loss=2.1484  λ_max=38.1678\n",
      "[SGD | lr=0.01] Iter 14100: loss=1.3218\n",
      "[SGD | lr=0.01] Epoch 882/4000: train_loss=1.3290  test_loss=2.1489  λ_max=38.3756\n",
      "[SGD | lr=0.01] Epoch 883/4000: train_loss=1.3278  test_loss=2.1481  λ_max=38.6717\n",
      "[SGD | lr=0.01] Epoch 884/4000: train_loss=1.3275  test_loss=2.1486  λ_max=38.9586\n",
      "[SGD | lr=0.01] Epoch 885/4000: train_loss=1.3259  test_loss=2.1490  λ_max=37.2610\n",
      "[SGD | lr=0.01] Epoch 886/4000: train_loss=1.3250  test_loss=2.1488  λ_max=36.3101\n",
      "[SGD | lr=0.01] Epoch 887/4000: train_loss=1.3242  test_loss=2.1487  λ_max=39.4810\n",
      "[SGD | lr=0.01] Iter 14200: loss=1.3226\n",
      "[SGD | lr=0.01] Epoch 888/4000: train_loss=1.3232  test_loss=2.1489  λ_max=39.3998\n",
      "[SGD | lr=0.01] Epoch 889/4000: train_loss=1.3227  test_loss=2.1490  λ_max=38.1991\n",
      "[SGD | lr=0.01] Epoch 890/4000: train_loss=1.3213  test_loss=2.1491  λ_max=39.7058\n",
      "[SGD | lr=0.01] Epoch 891/4000: train_loss=1.3209  test_loss=2.1489  λ_max=38.9217\n",
      "[SGD | lr=0.01] Epoch 892/4000: train_loss=1.3198  test_loss=2.1493  λ_max=38.8152\n",
      "[SGD | lr=0.01] Epoch 893/4000: train_loss=1.3187  test_loss=2.1494  λ_max=37.4666\n",
      "[SGD | lr=0.01] Iter 14300: loss=1.3167\n",
      "[SGD | lr=0.01] Epoch 894/4000: train_loss=1.3176  test_loss=2.1495  λ_max=39.3622\n",
      "[SGD | lr=0.01] Epoch 895/4000: train_loss=1.3169  test_loss=2.1494  λ_max=38.3932\n",
      "[SGD | lr=0.01] Epoch 896/4000: train_loss=1.3162  test_loss=2.1493  λ_max=39.2006\n",
      "[SGD | lr=0.01] Epoch 897/4000: train_loss=1.3154  test_loss=2.1496  λ_max=39.7116\n",
      "[SGD | lr=0.01] Epoch 898/4000: train_loss=1.3144  test_loss=2.1496  λ_max=37.7394\n",
      "[SGD | lr=0.01] Epoch 899/4000: train_loss=1.3135  test_loss=2.1495  λ_max=38.9714\n",
      "[SGD | lr=0.01] Iter 14400: loss=1.3141\n",
      "[SGD | lr=0.01] Epoch 900/4000: train_loss=1.3127  test_loss=2.1500  λ_max=39.0861\n",
      "[SGD | lr=0.01] Epoch 901/4000: train_loss=1.3120  test_loss=2.1495  λ_max=36.4481\n",
      "[SGD | lr=0.01] Epoch 902/4000: train_loss=1.3108  test_loss=2.1499  λ_max=39.8588\n",
      "[SGD | lr=0.01] Epoch 903/4000: train_loss=1.3100  test_loss=2.1503  λ_max=38.7379\n",
      "[SGD | lr=0.01] Epoch 904/4000: train_loss=1.3090  test_loss=2.1501  λ_max=39.2907\n",
      "[SGD | lr=0.01] Epoch 905/4000: train_loss=1.3084  test_loss=2.1499  λ_max=39.2349\n",
      "[SGD | lr=0.01] Epoch 906/4000: train_loss=1.3072  test_loss=2.1506  λ_max=40.3767\n",
      "[SGD | lr=0.01] Iter 14500: loss=1.2956\n",
      "[SGD | lr=0.01] Epoch 907/4000: train_loss=1.3067  test_loss=2.1505  λ_max=40.3958\n",
      "[SGD | lr=0.01] Epoch 908/4000: train_loss=1.3055  test_loss=2.1505  λ_max=40.1625\n",
      "[SGD | lr=0.01] Epoch 909/4000: train_loss=1.3048  test_loss=2.1507  λ_max=40.2088\n",
      "[SGD | lr=0.01] Epoch 910/4000: train_loss=1.3039  test_loss=2.1504  λ_max=39.9410\n",
      "[SGD | lr=0.01] Epoch 911/4000: train_loss=1.3031  test_loss=2.1503  λ_max=38.2432\n",
      "[SGD | lr=0.01] Epoch 912/4000: train_loss=1.3021  test_loss=2.1508  λ_max=40.1173\n",
      "[SGD | lr=0.01] Iter 14600: loss=1.2990\n",
      "[SGD | lr=0.01] Epoch 913/4000: train_loss=1.3013  test_loss=2.1511  λ_max=40.2038\n",
      "[SGD | lr=0.01] Epoch 914/4000: train_loss=1.3003  test_loss=2.1509  λ_max=40.5235\n",
      "[SGD | lr=0.01] Epoch 915/4000: train_loss=1.2995  test_loss=2.1514  λ_max=39.8105\n",
      "[SGD | lr=0.01] Epoch 916/4000: train_loss=1.2983  test_loss=2.1515  λ_max=40.7194\n",
      "[SGD | lr=0.01] Epoch 917/4000: train_loss=1.2977  test_loss=2.1514  λ_max=39.7351\n",
      "[SGD | lr=0.01] Epoch 918/4000: train_loss=1.2968  test_loss=2.1517  λ_max=40.6907\n",
      "[SGD | lr=0.01] Iter 14700: loss=1.2928\n",
      "[SGD | lr=0.01] Epoch 919/4000: train_loss=1.2960  test_loss=2.1514  λ_max=40.8796\n",
      "[SGD | lr=0.01] Epoch 920/4000: train_loss=1.2953  test_loss=2.1514  λ_max=40.3077\n",
      "[SGD | lr=0.01] Epoch 921/4000: train_loss=1.2940  test_loss=2.1520  λ_max=40.9018\n",
      "[SGD | lr=0.01] Epoch 922/4000: train_loss=1.2935  test_loss=2.1513  λ_max=40.3358\n",
      "[SGD | lr=0.01] Epoch 923/4000: train_loss=1.2923  test_loss=2.1522  λ_max=40.8416\n",
      "[SGD | lr=0.01] Epoch 924/4000: train_loss=1.2917  test_loss=2.1522  λ_max=40.8129\n",
      "[SGD | lr=0.01] Iter 14800: loss=1.2944\n",
      "[SGD | lr=0.01] Epoch 925/4000: train_loss=1.2907  test_loss=2.1520  λ_max=40.6870\n",
      "[SGD | lr=0.01] Epoch 926/4000: train_loss=1.2898  test_loss=2.1522  λ_max=40.7089\n",
      "[SGD | lr=0.01] Epoch 927/4000: train_loss=1.2892  test_loss=2.1524  λ_max=40.1079\n",
      "[SGD | lr=0.01] Epoch 928/4000: train_loss=1.2884  test_loss=2.1523  λ_max=40.4612\n",
      "[SGD | lr=0.01] Epoch 929/4000: train_loss=1.2872  test_loss=2.1527  λ_max=41.9748\n",
      "[SGD | lr=0.01] Epoch 930/4000: train_loss=1.2862  test_loss=2.1524  λ_max=40.1291\n",
      "[SGD | lr=0.01] Epoch 931/4000: train_loss=1.2856  test_loss=2.1528  λ_max=41.7833\n",
      "[SGD | lr=0.01] Iter 14900: loss=1.2776\n",
      "[SGD | lr=0.01] Epoch 932/4000: train_loss=1.2845  test_loss=2.1526  λ_max=40.6346\n",
      "[SGD | lr=0.01] Epoch 933/4000: train_loss=1.2837  test_loss=2.1531  λ_max=42.1349\n",
      "[SGD | lr=0.01] Epoch 934/4000: train_loss=1.2829  test_loss=2.1531  λ_max=41.6877\n",
      "[SGD | lr=0.01] Epoch 935/4000: train_loss=1.2821  test_loss=2.1529  λ_max=41.2112\n",
      "[SGD | lr=0.01] Epoch 936/4000: train_loss=1.2811  test_loss=2.1533  λ_max=41.8253\n",
      "[SGD | lr=0.01] Epoch 937/4000: train_loss=1.2803  test_loss=2.1530  λ_max=41.9425\n",
      "[SGD | lr=0.01] Iter 15000: loss=1.2795\n",
      "[SGD | lr=0.01] Epoch 938/4000: train_loss=1.2794  test_loss=2.1535  λ_max=41.9745\n",
      "[SGD | lr=0.01] Epoch 939/4000: train_loss=1.2786  test_loss=2.1530  λ_max=41.9375\n",
      "[SGD | lr=0.01] Epoch 940/4000: train_loss=1.2776  test_loss=2.1537  λ_max=37.5991\n",
      "[SGD | lr=0.01] Epoch 941/4000: train_loss=1.2768  test_loss=2.1536  λ_max=41.8747\n",
      "[SGD | lr=0.01] Epoch 942/4000: train_loss=1.2760  test_loss=2.1545  λ_max=40.1490\n",
      "[SGD | lr=0.01] Epoch 943/4000: train_loss=1.2750  test_loss=2.1539  λ_max=40.3567\n",
      "[SGD | lr=0.01] Iter 15100: loss=1.2790\n",
      "[SGD | lr=0.01] Epoch 944/4000: train_loss=1.2741  test_loss=2.1541  λ_max=41.3152\n",
      "[SGD | lr=0.01] Epoch 945/4000: train_loss=1.2732  test_loss=2.1544  λ_max=40.0729\n",
      "[SGD | lr=0.01] Epoch 946/4000: train_loss=1.2722  test_loss=2.1543  λ_max=38.0984\n",
      "[SGD | lr=0.01] Epoch 947/4000: train_loss=1.2713  test_loss=2.1547  λ_max=41.5384\n",
      "[SGD | lr=0.01] Epoch 948/4000: train_loss=1.2702  test_loss=2.1547  λ_max=42.1917\n",
      "[SGD | lr=0.01] Epoch 949/4000: train_loss=1.2695  test_loss=2.1544  λ_max=42.7920\n",
      "[SGD | lr=0.01] Iter 15200: loss=1.2570\n",
      "[SGD | lr=0.01] Epoch 950/4000: train_loss=1.2686  test_loss=2.1550  λ_max=43.4040\n",
      "[SGD | lr=0.01] Epoch 951/4000: train_loss=1.2679  test_loss=2.1550  λ_max=41.9868\n",
      "[SGD | lr=0.01] Epoch 952/4000: train_loss=1.2672  test_loss=2.1548  λ_max=41.8776\n",
      "[SGD | lr=0.01] Epoch 953/4000: train_loss=1.2664  test_loss=2.1552  λ_max=42.3908\n",
      "[SGD | lr=0.01] Epoch 954/4000: train_loss=1.2657  test_loss=2.1554  λ_max=42.4220\n",
      "[SGD | lr=0.01] Epoch 955/4000: train_loss=1.2643  test_loss=2.1549  λ_max=41.3899\n",
      "[SGD | lr=0.01] Epoch 956/4000: train_loss=1.2636  test_loss=2.1552  λ_max=43.3924\n",
      "[SGD | lr=0.01] Iter 15300: loss=1.2651\n",
      "[SGD | lr=0.01] Epoch 957/4000: train_loss=1.2631  test_loss=2.1554  λ_max=42.1285\n",
      "[SGD | lr=0.01] Epoch 958/4000: train_loss=1.2621  test_loss=2.1555  λ_max=40.7187\n",
      "[SGD | lr=0.01] Epoch 959/4000: train_loss=1.2609  test_loss=2.1557  λ_max=42.6442\n",
      "[SGD | lr=0.01] Epoch 960/4000: train_loss=1.2603  test_loss=2.1553  λ_max=40.6688\n",
      "[SGD | lr=0.01] Epoch 961/4000: train_loss=1.2594  test_loss=2.1562  λ_max=41.2725\n",
      "[SGD | lr=0.01] Epoch 962/4000: train_loss=1.2587  test_loss=2.1564  λ_max=40.2246\n",
      "[SGD | lr=0.01] Iter 15400: loss=1.2583\n",
      "[SGD | lr=0.01] Epoch 963/4000: train_loss=1.2573  test_loss=2.1564  λ_max=41.2916\n",
      "[SGD | lr=0.01] Epoch 964/4000: train_loss=1.2568  test_loss=2.1568  λ_max=42.6835\n",
      "[SGD | lr=0.01] Epoch 965/4000: train_loss=1.2560  test_loss=2.1564  λ_max=41.7101\n",
      "[SGD | lr=0.01] Epoch 966/4000: train_loss=1.2550  test_loss=2.1566  λ_max=43.2967\n",
      "[SGD | lr=0.01] Epoch 967/4000: train_loss=1.2543  test_loss=2.1567  λ_max=39.5784\n",
      "[SGD | lr=0.01] Epoch 968/4000: train_loss=1.2536  test_loss=2.1571  λ_max=43.7913\n",
      "[SGD | lr=0.01] Iter 15500: loss=1.2553\n",
      "[SGD | lr=0.01] Epoch 969/4000: train_loss=1.2525  test_loss=2.1570  λ_max=42.9358\n",
      "[SGD | lr=0.01] Epoch 970/4000: train_loss=1.2515  test_loss=2.1570  λ_max=41.7151\n",
      "[SGD | lr=0.01] Epoch 971/4000: train_loss=1.2508  test_loss=2.1573  λ_max=41.7582\n",
      "[SGD | lr=0.01] Epoch 972/4000: train_loss=1.2498  test_loss=2.1580  λ_max=44.3417\n",
      "[SGD | lr=0.01] Epoch 973/4000: train_loss=1.2488  test_loss=2.1578  λ_max=43.3637\n",
      "[SGD | lr=0.01] Epoch 974/4000: train_loss=1.2482  test_loss=2.1577  λ_max=42.5774\n",
      "[SGD | lr=0.01] Iter 15600: loss=1.2422\n",
      "[SGD | lr=0.01] Epoch 975/4000: train_loss=1.2472  test_loss=2.1579  λ_max=39.1123\n",
      "[SGD | lr=0.01] Epoch 976/4000: train_loss=1.2465  test_loss=2.1579  λ_max=43.0026\n",
      "[SGD | lr=0.01] Epoch 977/4000: train_loss=1.2456  test_loss=2.1578  λ_max=43.0547\n",
      "[SGD | lr=0.01] Epoch 978/4000: train_loss=1.2449  test_loss=2.1579  λ_max=43.8023\n",
      "[SGD | lr=0.01] Epoch 979/4000: train_loss=1.2439  test_loss=2.1581  λ_max=41.9481\n",
      "[SGD | lr=0.01] Epoch 980/4000: train_loss=1.2432  test_loss=2.1584  λ_max=42.7775\n",
      "[SGD | lr=0.01] Epoch 981/4000: train_loss=1.2422  test_loss=2.1586  λ_max=42.9543\n",
      "[SGD | lr=0.01] Iter 15700: loss=1.2298\n",
      "[SGD | lr=0.01] Epoch 982/4000: train_loss=1.2415  test_loss=2.1585  λ_max=44.3119\n",
      "[SGD | lr=0.01] Epoch 983/4000: train_loss=1.2405  test_loss=2.1587  λ_max=44.5218\n",
      "[SGD | lr=0.01] Epoch 984/4000: train_loss=1.2396  test_loss=2.1591  λ_max=44.2872\n",
      "[SGD | lr=0.01] Epoch 985/4000: train_loss=1.2387  test_loss=2.1591  λ_max=41.3663\n",
      "[SGD | lr=0.01] Epoch 986/4000: train_loss=1.2379  test_loss=2.1591  λ_max=43.1371\n",
      "[SGD | lr=0.01] Epoch 987/4000: train_loss=1.2369  test_loss=2.1589  λ_max=43.2819\n",
      "[SGD | lr=0.01] Iter 15800: loss=1.2384\n",
      "[SGD | lr=0.01] Epoch 988/4000: train_loss=1.2364  test_loss=2.1590  λ_max=43.0042\n",
      "[SGD | lr=0.01] Epoch 989/4000: train_loss=1.2353  test_loss=2.1595  λ_max=42.3873\n",
      "[SGD | lr=0.01] Epoch 990/4000: train_loss=1.2344  test_loss=2.1599  λ_max=44.7263\n",
      "[SGD | lr=0.01] Epoch 991/4000: train_loss=1.2337  test_loss=2.1599  λ_max=44.9174\n",
      "[SGD | lr=0.01] Epoch 992/4000: train_loss=1.2327  test_loss=2.1601  λ_max=44.5612\n",
      "[SGD | lr=0.01] Epoch 993/4000: train_loss=1.2323  test_loss=2.1602  λ_max=44.4089\n",
      "[SGD | lr=0.01] Iter 15900: loss=1.2350\n",
      "[SGD | lr=0.01] Epoch 994/4000: train_loss=1.2313  test_loss=2.1603  λ_max=42.5434\n",
      "[SGD | lr=0.01] Epoch 995/4000: train_loss=1.2302  test_loss=2.1601  λ_max=45.0682\n",
      "[SGD | lr=0.01] Epoch 996/4000: train_loss=1.2292  test_loss=2.1604  λ_max=43.4401\n",
      "[SGD | lr=0.01] Epoch 997/4000: train_loss=1.2286  test_loss=2.1606  λ_max=44.9787\n",
      "[SGD | lr=0.01] Epoch 998/4000: train_loss=1.2277  test_loss=2.1610  λ_max=45.4170\n",
      "[SGD | lr=0.01] Epoch 999/4000: train_loss=1.2270  test_loss=2.1609  λ_max=40.8296\n",
      "[SGD | lr=0.01] Iter 16000: loss=1.2157\n",
      "[SGD | lr=0.01] Epoch 1000/4000: train_loss=1.2258  test_loss=2.1611  λ_max=42.4876\n",
      "[SGD | lr=0.01] Epoch 1001/4000: train_loss=1.2254  test_loss=2.1609  λ_max=44.0484\n",
      "[SGD | lr=0.01] Epoch 1002/4000: train_loss=1.2242  test_loss=2.1618  λ_max=45.8034\n",
      "[SGD | lr=0.01] Epoch 1003/4000: train_loss=1.2234  test_loss=2.1616  λ_max=45.3599\n",
      "[SGD | lr=0.01] Epoch 1004/4000: train_loss=1.2227  test_loss=2.1614  λ_max=45.6185\n",
      "[SGD | lr=0.01] Epoch 1005/4000: train_loss=1.2217  test_loss=2.1619  λ_max=45.2213\n",
      "[SGD | lr=0.01] Epoch 1006/4000: train_loss=1.2210  test_loss=2.1624  λ_max=46.0580\n",
      "[SGD | lr=0.01] Iter 16100: loss=1.2165\n",
      "[SGD | lr=0.01] Epoch 1007/4000: train_loss=1.2199  test_loss=2.1618  λ_max=45.8067\n",
      "[SGD | lr=0.01] Epoch 1008/4000: train_loss=1.2193  test_loss=2.1625  λ_max=45.6499\n",
      "[SGD | lr=0.01] Epoch 1009/4000: train_loss=1.2185  test_loss=2.1622  λ_max=42.9759\n",
      "[SGD | lr=0.01] Epoch 1010/4000: train_loss=1.2175  test_loss=2.1624  λ_max=42.6902\n",
      "[SGD | lr=0.01] Epoch 1011/4000: train_loss=1.2169  test_loss=2.1627  λ_max=46.2005\n",
      "[SGD | lr=0.01] Epoch 1012/4000: train_loss=1.2161  test_loss=2.1627  λ_max=45.3629\n",
      "[SGD | lr=0.01] Iter 16200: loss=1.2116\n",
      "[SGD | lr=0.01] Epoch 1013/4000: train_loss=1.2150  test_loss=2.1625  λ_max=45.5638\n",
      "[SGD | lr=0.01] Epoch 1014/4000: train_loss=1.2145  test_loss=2.1631  λ_max=46.5999\n",
      "[SGD | lr=0.01] Epoch 1015/4000: train_loss=1.2133  test_loss=2.1631  λ_max=45.9161\n",
      "[SGD | lr=0.01] Epoch 1016/4000: train_loss=1.2125  test_loss=2.1631  λ_max=45.7455\n",
      "[SGD | lr=0.01] Epoch 1017/4000: train_loss=1.2117  test_loss=2.1630  λ_max=45.1060\n",
      "[SGD | lr=0.01] Epoch 1018/4000: train_loss=1.2110  test_loss=2.1637  λ_max=44.3480\n",
      "[SGD | lr=0.01] Iter 16300: loss=1.2050\n",
      "[SGD | lr=0.01] Epoch 1019/4000: train_loss=1.2100  test_loss=2.1641  λ_max=46.8556\n",
      "[SGD | lr=0.01] Epoch 1020/4000: train_loss=1.2095  test_loss=2.1643  λ_max=43.7038\n",
      "[SGD | lr=0.01] Epoch 1021/4000: train_loss=1.2086  test_loss=2.1642  λ_max=46.5311\n",
      "[SGD | lr=0.01] Epoch 1022/4000: train_loss=1.2077  test_loss=2.1642  λ_max=45.8224\n",
      "[SGD | lr=0.01] Epoch 1023/4000: train_loss=1.2069  test_loss=2.1639  λ_max=46.6092\n",
      "[SGD | lr=0.01] Epoch 1024/4000: train_loss=1.2060  test_loss=2.1642  λ_max=44.5341\n",
      "[SGD | lr=0.01] Iter 16400: loss=1.2079\n",
      "[SGD | lr=0.01] Epoch 1025/4000: train_loss=1.2050  test_loss=2.1648  λ_max=46.7502\n",
      "[SGD | lr=0.01] Epoch 1026/4000: train_loss=1.2045  test_loss=2.1653  λ_max=45.1517\n",
      "[SGD | lr=0.01] Epoch 1027/4000: train_loss=1.2033  test_loss=2.1649  λ_max=46.7026\n",
      "[SGD | lr=0.01] Epoch 1028/4000: train_loss=1.2025  test_loss=2.1651  λ_max=45.9543\n",
      "[SGD | lr=0.01] Epoch 1029/4000: train_loss=1.2016  test_loss=2.1650  λ_max=47.3830\n",
      "[SGD | lr=0.01] Epoch 1030/4000: train_loss=1.2007  test_loss=2.1655  λ_max=45.0505\n",
      "[SGD | lr=0.01] Epoch 1031/4000: train_loss=1.2002  test_loss=2.1654  λ_max=45.3715\n",
      "[SGD | lr=0.01] Iter 16500: loss=1.2064\n",
      "[SGD | lr=0.01] Epoch 1032/4000: train_loss=1.1993  test_loss=2.1659  λ_max=46.6419\n",
      "[SGD | lr=0.01] Epoch 1033/4000: train_loss=1.1981  test_loss=2.1664  λ_max=45.3966\n",
      "[SGD | lr=0.01] Epoch 1034/4000: train_loss=1.1975  test_loss=2.1661  λ_max=48.0806\n",
      "[SGD | lr=0.01] Epoch 1035/4000: train_loss=1.1966  test_loss=2.1665  λ_max=45.7582\n",
      "[SGD | lr=0.01] Epoch 1036/4000: train_loss=1.1959  test_loss=2.1664  λ_max=44.0964\n",
      "[SGD | lr=0.01] Epoch 1037/4000: train_loss=1.1951  test_loss=2.1666  λ_max=47.3667\n",
      "[SGD | lr=0.01] Iter 16600: loss=1.1938\n",
      "[SGD | lr=0.01] Epoch 1038/4000: train_loss=1.1945  test_loss=2.1664  λ_max=46.9759\n",
      "[SGD | lr=0.01] Epoch 1039/4000: train_loss=1.1936  test_loss=2.1674  λ_max=47.8739\n",
      "[SGD | lr=0.01] Epoch 1040/4000: train_loss=1.1924  test_loss=2.1670  λ_max=46.0278\n",
      "[SGD | lr=0.01] Epoch 1041/4000: train_loss=1.1918  test_loss=2.1671  λ_max=47.8919\n",
      "[SGD | lr=0.01] Epoch 1042/4000: train_loss=1.1909  test_loss=2.1669  λ_max=47.4234\n",
      "[SGD | lr=0.01] Epoch 1043/4000: train_loss=1.1900  test_loss=2.1672  λ_max=46.8283\n",
      "[SGD | lr=0.01] Iter 16700: loss=1.1856\n",
      "[SGD | lr=0.01] Epoch 1044/4000: train_loss=1.1891  test_loss=2.1678  λ_max=48.3807\n",
      "[SGD | lr=0.01] Epoch 1045/4000: train_loss=1.1889  test_loss=2.1677  λ_max=46.2737\n",
      "[SGD | lr=0.01] Epoch 1046/4000: train_loss=1.1877  test_loss=2.1680  λ_max=45.4677\n",
      "[SGD | lr=0.01] Epoch 1047/4000: train_loss=1.1869  test_loss=2.1680  λ_max=47.6114\n",
      "[SGD | lr=0.01] Epoch 1048/4000: train_loss=1.1860  test_loss=2.1682  λ_max=47.7410\n",
      "[SGD | lr=0.01] Epoch 1049/4000: train_loss=1.1851  test_loss=2.1684  λ_max=47.3207\n",
      "[SGD | lr=0.01] Iter 16800: loss=1.1887\n",
      "[SGD | lr=0.01] Epoch 1050/4000: train_loss=1.1845  test_loss=2.1687  λ_max=48.0443\n",
      "[SGD | lr=0.01] Epoch 1051/4000: train_loss=1.1835  test_loss=2.1691  λ_max=47.5426\n",
      "[SGD | lr=0.01] Epoch 1052/4000: train_loss=1.1825  test_loss=2.1687  λ_max=42.5283\n",
      "[SGD | lr=0.01] Epoch 1053/4000: train_loss=1.1820  test_loss=2.1686  λ_max=44.8250\n",
      "[SGD | lr=0.01] Epoch 1054/4000: train_loss=1.1810  test_loss=2.1689  λ_max=47.7382\n",
      "[SGD | lr=0.01] Epoch 1055/4000: train_loss=1.1802  test_loss=2.1691  λ_max=49.2179\n",
      "[SGD | lr=0.01] Epoch 1056/4000: train_loss=1.1794  test_loss=2.1696  λ_max=47.1873\n",
      "[SGD | lr=0.01] Iter 16900: loss=1.1874\n",
      "[SGD | lr=0.01] Epoch 1057/4000: train_loss=1.1785  test_loss=2.1694  λ_max=48.1439\n",
      "[SGD | lr=0.01] Epoch 1058/4000: train_loss=1.1779  test_loss=2.1697  λ_max=48.6620\n",
      "[SGD | lr=0.01] Epoch 1059/4000: train_loss=1.1767  test_loss=2.1701  λ_max=48.4203\n",
      "[SGD | lr=0.01] Epoch 1060/4000: train_loss=1.1761  test_loss=2.1706  λ_max=47.2524\n",
      "[SGD | lr=0.01] Epoch 1061/4000: train_loss=1.1754  test_loss=2.1704  λ_max=47.8238\n",
      "[SGD | lr=0.01] Epoch 1062/4000: train_loss=1.1744  test_loss=2.1704  λ_max=46.6703\n",
      "[SGD | lr=0.01] Iter 17000: loss=1.1865\n",
      "[SGD | lr=0.01] Epoch 1063/4000: train_loss=1.1738  test_loss=2.1705  λ_max=47.9955\n",
      "[SGD | lr=0.01] Epoch 1064/4000: train_loss=1.1730  test_loss=2.1708  λ_max=47.3434\n",
      "[SGD | lr=0.01] Epoch 1065/4000: train_loss=1.1719  test_loss=2.1715  λ_max=46.2127\n",
      "[SGD | lr=0.01] Epoch 1066/4000: train_loss=1.1715  test_loss=2.1710  λ_max=49.8961\n",
      "[SGD | lr=0.01] Epoch 1067/4000: train_loss=1.1703  test_loss=2.1713  λ_max=49.2434\n",
      "[SGD | lr=0.01] Epoch 1068/4000: train_loss=1.1693  test_loss=2.1714  λ_max=46.1521\n",
      "[SGD | lr=0.01] Iter 17100: loss=1.1611\n",
      "[SGD | lr=0.01] Epoch 1069/4000: train_loss=1.1686  test_loss=2.1720  λ_max=49.0320\n",
      "[SGD | lr=0.01] Epoch 1070/4000: train_loss=1.1678  test_loss=2.1714  λ_max=49.2026\n",
      "[SGD | lr=0.01] Epoch 1071/4000: train_loss=1.1672  test_loss=2.1720  λ_max=47.5849\n",
      "[SGD | lr=0.01] Epoch 1072/4000: train_loss=1.1666  test_loss=2.1720  λ_max=48.8601\n",
      "[SGD | lr=0.01] Epoch 1073/4000: train_loss=1.1657  test_loss=2.1728  λ_max=46.2547\n",
      "[SGD | lr=0.01] Epoch 1074/4000: train_loss=1.1644  test_loss=2.1724  λ_max=47.0912\n",
      "[SGD | lr=0.01] Iter 17200: loss=1.1729\n",
      "[SGD | lr=0.01] Epoch 1075/4000: train_loss=1.1640  test_loss=2.1729  λ_max=48.5254\n",
      "[SGD | lr=0.01] Epoch 1076/4000: train_loss=1.1632  test_loss=2.1724  λ_max=46.2274\n",
      "[SGD | lr=0.01] Epoch 1077/4000: train_loss=1.1622  test_loss=2.1733  λ_max=49.0750\n",
      "[SGD | lr=0.01] Epoch 1078/4000: train_loss=1.1613  test_loss=2.1733  λ_max=48.4043\n",
      "[SGD | lr=0.01] Epoch 1079/4000: train_loss=1.1604  test_loss=2.1732  λ_max=47.6284\n",
      "[SGD | lr=0.01] Epoch 1080/4000: train_loss=1.1599  test_loss=2.1730  λ_max=47.1243\n",
      "[SGD | lr=0.01] Epoch 1081/4000: train_loss=1.1590  test_loss=2.1740  λ_max=50.3884\n",
      "[SGD | lr=0.01] Iter 17300: loss=1.1550\n",
      "[SGD | lr=0.01] Epoch 1082/4000: train_loss=1.1583  test_loss=2.1740  λ_max=48.7996\n",
      "[SGD | lr=0.01] Epoch 1083/4000: train_loss=1.1572  test_loss=2.1741  λ_max=48.2158\n",
      "[SGD | lr=0.01] Epoch 1084/4000: train_loss=1.1564  test_loss=2.1742  λ_max=50.5759\n",
      "[SGD | lr=0.01] Epoch 1085/4000: train_loss=1.1556  test_loss=2.1744  λ_max=50.5932\n",
      "[SGD | lr=0.01] Epoch 1086/4000: train_loss=1.1551  test_loss=2.1741  λ_max=48.8914\n",
      "[SGD | lr=0.01] Epoch 1087/4000: train_loss=1.1540  test_loss=2.1749  λ_max=49.7906\n",
      "[SGD | lr=0.01] Iter 17400: loss=1.1524\n",
      "[SGD | lr=0.01] Epoch 1088/4000: train_loss=1.1528  test_loss=2.1749  λ_max=48.7783\n",
      "[SGD | lr=0.01] Epoch 1089/4000: train_loss=1.1524  test_loss=2.1756  λ_max=47.3965\n",
      "[SGD | lr=0.01] Epoch 1090/4000: train_loss=1.1518  test_loss=2.1759  λ_max=49.7077\n",
      "[SGD | lr=0.01] Epoch 1091/4000: train_loss=1.1507  test_loss=2.1755  λ_max=50.2649\n",
      "[SGD | lr=0.01] Epoch 1092/4000: train_loss=1.1501  test_loss=2.1753  λ_max=50.2378\n",
      "[SGD | lr=0.01] Epoch 1093/4000: train_loss=1.1493  test_loss=2.1760  λ_max=50.3021\n",
      "[SGD | lr=0.01] Iter 17500: loss=1.1504\n",
      "[SGD | lr=0.01] Epoch 1094/4000: train_loss=1.1487  test_loss=2.1762  λ_max=50.3776\n",
      "[SGD | lr=0.01] Epoch 1095/4000: train_loss=1.1478  test_loss=2.1764  λ_max=51.9377\n",
      "[SGD | lr=0.01] Epoch 1096/4000: train_loss=1.1468  test_loss=2.1763  λ_max=45.6192\n",
      "[SGD | lr=0.01] Epoch 1097/4000: train_loss=1.1457  test_loss=2.1761  λ_max=47.2857\n",
      "[SGD | lr=0.01] Epoch 1098/4000: train_loss=1.1457  test_loss=2.1762  λ_max=50.4898\n",
      "[SGD | lr=0.01] Epoch 1099/4000: train_loss=1.1448  test_loss=2.1766  λ_max=50.6119\n",
      "[SGD | lr=0.01] Iter 17600: loss=1.1447\n",
      "[SGD | lr=0.01] Epoch 1100/4000: train_loss=1.1436  test_loss=2.1770  λ_max=41.9955\n",
      "[SGD | lr=0.01] Epoch 1101/4000: train_loss=1.1431  test_loss=2.1773  λ_max=51.3366\n",
      "[SGD | lr=0.01] Epoch 1102/4000: train_loss=1.1423  test_loss=2.1779  λ_max=48.8771\n",
      "[SGD | lr=0.01] Epoch 1103/4000: train_loss=1.1414  test_loss=2.1781  λ_max=51.0103\n",
      "[SGD | lr=0.01] Epoch 1104/4000: train_loss=1.1407  test_loss=2.1778  λ_max=49.4182\n",
      "[SGD | lr=0.01] Epoch 1105/4000: train_loss=1.1394  test_loss=2.1779  λ_max=49.4494\n",
      "[SGD | lr=0.01] Epoch 1106/4000: train_loss=1.1388  test_loss=2.1788  λ_max=51.2320\n",
      "[SGD | lr=0.01] Iter 17700: loss=1.1343\n",
      "[SGD | lr=0.01] Epoch 1107/4000: train_loss=1.1383  test_loss=2.1784  λ_max=50.9921\n",
      "[SGD | lr=0.01] Epoch 1108/4000: train_loss=1.1373  test_loss=2.1788  λ_max=51.6437\n",
      "[SGD | lr=0.01] Epoch 1109/4000: train_loss=1.1363  test_loss=2.1790  λ_max=51.6188\n",
      "[SGD | lr=0.01] Epoch 1110/4000: train_loss=1.1356  test_loss=2.1789  λ_max=49.9436\n",
      "[SGD | lr=0.01] Epoch 1111/4000: train_loss=1.1348  test_loss=2.1790  λ_max=50.7519\n",
      "[SGD | lr=0.01] Epoch 1112/4000: train_loss=1.1343  test_loss=2.1793  λ_max=51.0223\n",
      "[SGD | lr=0.01] Iter 17800: loss=1.1298\n",
      "[SGD | lr=0.01] Epoch 1113/4000: train_loss=1.1335  test_loss=2.1802  λ_max=51.4847\n",
      "[SGD | lr=0.01] Epoch 1114/4000: train_loss=1.1328  test_loss=2.1801  λ_max=51.1216\n",
      "[SGD | lr=0.01] Epoch 1115/4000: train_loss=1.1322  test_loss=2.1802  λ_max=50.5940\n",
      "[SGD | lr=0.01] Epoch 1116/4000: train_loss=1.1309  test_loss=2.1805  λ_max=52.1578\n",
      "[SGD | lr=0.01] Epoch 1117/4000: train_loss=1.1300  test_loss=2.1801  λ_max=51.6818\n",
      "[SGD | lr=0.01] Epoch 1118/4000: train_loss=1.1293  test_loss=2.1803  λ_max=51.7348\n",
      "[SGD | lr=0.01] Iter 17900: loss=1.1248\n",
      "[SGD | lr=0.01] Epoch 1119/4000: train_loss=1.1286  test_loss=2.1809  λ_max=50.9352\n",
      "[SGD | lr=0.01] Epoch 1120/4000: train_loss=1.1273  test_loss=2.1805  λ_max=51.0152\n",
      "[SGD | lr=0.01] Epoch 1121/4000: train_loss=1.1266  test_loss=2.1814  λ_max=49.9547\n",
      "[SGD | lr=0.01] Epoch 1122/4000: train_loss=1.1263  test_loss=2.1805  λ_max=53.3588\n",
      "[SGD | lr=0.01] Epoch 1123/4000: train_loss=1.1250  test_loss=2.1815  λ_max=50.0689\n",
      "[SGD | lr=0.01] Epoch 1124/4000: train_loss=1.1248  test_loss=2.1812  λ_max=50.5929\n",
      "[SGD | lr=0.01] Iter 18000: loss=1.1096\n",
      "[SGD | lr=0.01] Epoch 1125/4000: train_loss=1.1233  test_loss=2.1816  λ_max=51.8794\n",
      "[SGD | lr=0.01] Epoch 1126/4000: train_loss=1.1230  test_loss=2.1824  λ_max=50.7664\n",
      "[SGD | lr=0.01] Epoch 1127/4000: train_loss=1.1223  test_loss=2.1824  λ_max=53.5677\n",
      "[SGD | lr=0.01] Epoch 1128/4000: train_loss=1.1216  test_loss=2.1818  λ_max=51.8470\n",
      "[SGD | lr=0.01] Epoch 1129/4000: train_loss=1.1208  test_loss=2.1823  λ_max=53.3273\n",
      "[SGD | lr=0.01] Epoch 1130/4000: train_loss=1.1202  test_loss=2.1825  λ_max=50.5267\n",
      "[SGD | lr=0.01] Epoch 1131/4000: train_loss=1.1193  test_loss=2.1827  λ_max=51.9556\n",
      "[SGD | lr=0.01] Iter 18100: loss=1.1118\n",
      "[SGD | lr=0.01] Epoch 1132/4000: train_loss=1.1181  test_loss=2.1832  λ_max=53.2788\n",
      "[SGD | lr=0.01] Epoch 1133/4000: train_loss=1.1174  test_loss=2.1833  λ_max=52.6231\n",
      "[SGD | lr=0.01] Epoch 1134/4000: train_loss=1.1163  test_loss=2.1835  λ_max=50.2751\n",
      "[SGD | lr=0.01] Epoch 1135/4000: train_loss=1.1156  test_loss=2.1839  λ_max=49.4610\n",
      "[SGD | lr=0.01] Epoch 1136/4000: train_loss=1.1150  test_loss=2.1839  λ_max=51.1095\n",
      "[SGD | lr=0.01] Epoch 1137/4000: train_loss=1.1140  test_loss=2.1834  λ_max=53.0417\n",
      "[SGD | lr=0.01] Iter 18200: loss=1.1071\n",
      "[SGD | lr=0.01] Epoch 1138/4000: train_loss=1.1136  test_loss=2.1849  λ_max=51.0328\n",
      "[SGD | lr=0.01] Epoch 1139/4000: train_loss=1.1124  test_loss=2.1842  λ_max=52.5165\n",
      "[SGD | lr=0.01] Epoch 1140/4000: train_loss=1.1123  test_loss=2.1843  λ_max=50.9268\n",
      "[SGD | lr=0.01] Epoch 1141/4000: train_loss=1.1112  test_loss=2.1844  λ_max=52.1736\n",
      "[SGD | lr=0.01] Epoch 1142/4000: train_loss=1.1105  test_loss=2.1848  λ_max=50.9139\n",
      "[SGD | lr=0.01] Epoch 1143/4000: train_loss=1.1094  test_loss=2.1853  λ_max=53.4071\n",
      "[SGD | lr=0.01] Iter 18300: loss=1.1143\n",
      "[SGD | lr=0.01] Epoch 1144/4000: train_loss=1.1084  test_loss=2.1862  λ_max=53.1692\n",
      "[SGD | lr=0.01] Epoch 1145/4000: train_loss=1.1082  test_loss=2.1861  λ_max=52.5087\n",
      "[SGD | lr=0.01] Epoch 1146/4000: train_loss=1.1073  test_loss=2.1864  λ_max=54.6330\n",
      "[SGD | lr=0.01] Epoch 1147/4000: train_loss=1.1066  test_loss=2.1857  λ_max=53.4758\n",
      "[SGD | lr=0.01] Epoch 1148/4000: train_loss=1.1057  test_loss=2.1863  λ_max=51.7170\n",
      "[SGD | lr=0.01] Epoch 1149/4000: train_loss=1.1047  test_loss=2.1857  λ_max=54.5416\n",
      "[SGD | lr=0.01] Iter 18400: loss=1.1045\n",
      "[SGD | lr=0.01] Epoch 1150/4000: train_loss=1.1043  test_loss=2.1870  λ_max=52.1952\n",
      "[SGD | lr=0.01] Epoch 1151/4000: train_loss=1.1036  test_loss=2.1869  λ_max=54.3488\n",
      "[SGD | lr=0.01] Epoch 1152/4000: train_loss=1.1028  test_loss=2.1878  λ_max=53.8235\n",
      "[SGD | lr=0.01] Epoch 1153/4000: train_loss=1.1016  test_loss=2.1874  λ_max=54.0329\n",
      "[SGD | lr=0.01] Epoch 1154/4000: train_loss=1.1016  test_loss=2.1873  λ_max=54.4517\n",
      "[SGD | lr=0.01] Epoch 1155/4000: train_loss=1.1003  test_loss=2.1876  λ_max=51.4206\n",
      "[SGD | lr=0.01] Epoch 1156/4000: train_loss=1.0993  test_loss=2.1873  λ_max=54.8029\n",
      "[SGD | lr=0.01] Iter 18500: loss=1.0975\n",
      "[SGD | lr=0.01] Epoch 1157/4000: train_loss=1.0990  test_loss=2.1872  λ_max=52.2600\n",
      "[SGD | lr=0.01] Epoch 1158/4000: train_loss=1.0986  test_loss=2.1884  λ_max=54.9497\n",
      "[SGD | lr=0.01] Epoch 1159/4000: train_loss=1.0977  test_loss=2.1881  λ_max=50.7597\n",
      "[SGD | lr=0.01] Epoch 1160/4000: train_loss=1.0967  test_loss=2.1885  λ_max=49.1079\n",
      "[SGD | lr=0.01] Epoch 1161/4000: train_loss=1.0955  test_loss=2.1895  λ_max=51.5415\n",
      "[SGD | lr=0.01] Epoch 1162/4000: train_loss=1.0945  test_loss=2.1891  λ_max=53.0307\n",
      "[SGD | lr=0.01] Iter 18600: loss=1.0924\n",
      "[SGD | lr=0.01] Epoch 1163/4000: train_loss=1.0941  test_loss=2.1894  λ_max=55.1460\n",
      "[SGD | lr=0.01] Epoch 1164/4000: train_loss=1.0931  test_loss=2.1900  λ_max=49.3346\n",
      "[SGD | lr=0.01] Epoch 1165/4000: train_loss=1.0925  test_loss=2.1898  λ_max=54.3792\n",
      "[SGD | lr=0.01] Epoch 1166/4000: train_loss=1.0915  test_loss=2.1900  λ_max=53.5070\n",
      "[SGD | lr=0.01] Epoch 1167/4000: train_loss=1.0911  test_loss=2.1905  λ_max=55.3395\n",
      "[SGD | lr=0.01] Epoch 1168/4000: train_loss=1.0897  test_loss=2.1906  λ_max=54.1012\n",
      "[SGD | lr=0.01] Iter 18700: loss=1.0956\n",
      "[SGD | lr=0.01] Epoch 1169/4000: train_loss=1.0894  test_loss=2.1913  λ_max=54.3946\n",
      "[SGD | lr=0.01] Epoch 1170/4000: train_loss=1.0888  test_loss=2.1906  λ_max=53.4664\n",
      "[SGD | lr=0.01] Epoch 1171/4000: train_loss=1.0876  test_loss=2.1917  λ_max=55.5356\n",
      "[SGD | lr=0.01] Epoch 1172/4000: train_loss=1.0867  test_loss=2.1914  λ_max=55.6213\n",
      "[SGD | lr=0.01] Epoch 1173/4000: train_loss=1.0866  test_loss=2.1922  λ_max=54.5118\n",
      "[SGD | lr=0.01] Epoch 1174/4000: train_loss=1.0858  test_loss=2.1919  λ_max=54.7672\n",
      "[SGD | lr=0.01] Iter 18800: loss=1.0863\n",
      "[SGD | lr=0.01] Epoch 1175/4000: train_loss=1.0850  test_loss=2.1920  λ_max=51.7661\n",
      "[SGD | lr=0.01] Epoch 1176/4000: train_loss=1.0838  test_loss=2.1925  λ_max=52.2047\n",
      "[SGD | lr=0.01] Epoch 1177/4000: train_loss=1.0836  test_loss=2.1930  λ_max=53.6209\n",
      "[SGD | lr=0.01] Epoch 1178/4000: train_loss=1.0827  test_loss=2.1927  λ_max=52.8633\n",
      "[SGD | lr=0.01] Epoch 1179/4000: train_loss=1.0814  test_loss=2.1922  λ_max=55.1110\n",
      "[SGD | lr=0.01] Epoch 1180/4000: train_loss=1.0813  test_loss=2.1928  λ_max=55.4449\n",
      "[SGD | lr=0.01] Epoch 1181/4000: train_loss=1.0803  test_loss=2.1926  λ_max=54.9157\n",
      "[SGD | lr=0.01] Iter 18900: loss=1.0718\n",
      "[SGD | lr=0.01] Epoch 1182/4000: train_loss=1.0798  test_loss=2.1934  λ_max=49.5575\n",
      "[SGD | lr=0.01] Epoch 1183/4000: train_loss=1.0786  test_loss=2.1928  λ_max=54.5539\n",
      "[SGD | lr=0.01] Epoch 1184/4000: train_loss=1.0784  test_loss=2.1943  λ_max=53.7547\n",
      "[SGD | lr=0.01] Epoch 1185/4000: train_loss=1.0769  test_loss=2.1945  λ_max=50.5649\n",
      "[SGD | lr=0.01] Epoch 1186/4000: train_loss=1.0759  test_loss=2.1946  λ_max=54.4476\n",
      "[SGD | lr=0.01] Epoch 1187/4000: train_loss=1.0758  test_loss=2.1941  λ_max=55.7451\n",
      "[SGD | lr=0.01] Iter 19000: loss=1.0803\n",
      "[SGD | lr=0.01] Epoch 1188/4000: train_loss=1.0747  test_loss=2.1946  λ_max=53.9618\n",
      "[SGD | lr=0.01] Epoch 1189/4000: train_loss=1.0738  test_loss=2.1956  λ_max=54.8636\n",
      "[SGD | lr=0.01] Epoch 1190/4000: train_loss=1.0739  test_loss=2.1960  λ_max=56.0321\n",
      "[SGD | lr=0.01] Epoch 1191/4000: train_loss=1.0733  test_loss=2.1958  λ_max=55.3652\n",
      "[SGD | lr=0.01] Epoch 1192/4000: train_loss=1.0717  test_loss=2.1962  λ_max=53.6865\n",
      "[SGD | lr=0.01] Epoch 1193/4000: train_loss=1.0713  test_loss=2.1965  λ_max=56.1635\n",
      "[SGD | lr=0.01] Iter 19100: loss=1.0704\n",
      "[SGD | lr=0.01] Epoch 1194/4000: train_loss=1.0698  test_loss=2.1957  λ_max=54.5170\n",
      "[SGD | lr=0.01] Epoch 1195/4000: train_loss=1.0694  test_loss=2.1961  λ_max=56.1465\n",
      "[SGD | lr=0.01] Epoch 1196/4000: train_loss=1.0685  test_loss=2.1963  λ_max=53.4978\n",
      "[SGD | lr=0.01] Epoch 1197/4000: train_loss=1.0685  test_loss=2.1965  λ_max=55.6330\n",
      "[SGD | lr=0.01] Epoch 1198/4000: train_loss=1.0678  test_loss=2.1970  λ_max=55.9618\n",
      "[SGD | lr=0.01] Epoch 1199/4000: train_loss=1.0663  test_loss=2.1965  λ_max=51.8616\n",
      "[SGD | lr=0.01] Iter 19200: loss=1.0610\n",
      "[SGD | lr=0.01] Epoch 1200/4000: train_loss=1.0652  test_loss=2.1969  λ_max=56.8387\n",
      "[SGD | lr=0.01] Epoch 1201/4000: train_loss=1.0646  test_loss=2.1970  λ_max=55.5634\n",
      "[SGD | lr=0.01] Epoch 1202/4000: train_loss=1.0646  test_loss=2.1981  λ_max=54.8176\n",
      "[SGD | lr=0.01] Epoch 1203/4000: train_loss=1.0639  test_loss=2.1981  λ_max=53.9036\n",
      "[SGD | lr=0.01] Epoch 1204/4000: train_loss=1.0629  test_loss=2.1977  λ_max=57.1305\n",
      "[SGD | lr=0.01] Epoch 1205/4000: train_loss=1.0622  test_loss=2.1982  λ_max=56.3535\n",
      "[SGD | lr=0.01] Epoch 1206/4000: train_loss=1.0613  test_loss=2.1983  λ_max=56.0218\n",
      "[SGD | lr=0.01] Iter 19300: loss=1.0625\n",
      "[SGD | lr=0.01] Epoch 1207/4000: train_loss=1.0607  test_loss=2.1988  λ_max=50.1385\n",
      "[SGD | lr=0.01] Epoch 1208/4000: train_loss=1.0606  test_loss=2.1999  λ_max=57.2788\n",
      "[SGD | lr=0.01] Epoch 1209/4000: train_loss=1.0591  test_loss=2.1990  λ_max=54.5001\n",
      "[SGD | lr=0.01] Epoch 1210/4000: train_loss=1.0592  test_loss=2.1997  λ_max=53.6426\n",
      "[SGD | lr=0.01] Epoch 1211/4000: train_loss=1.0571  test_loss=2.1997  λ_max=55.0015\n",
      "[SGD | lr=0.01] Epoch 1212/4000: train_loss=1.0565  test_loss=2.2003  λ_max=58.0178\n",
      "[SGD | lr=0.01] Iter 19400: loss=1.0575\n",
      "[SGD | lr=0.01] Epoch 1213/4000: train_loss=1.0562  test_loss=2.2011  λ_max=54.1222\n",
      "[SGD | lr=0.01] Epoch 1214/4000: train_loss=1.0565  test_loss=2.2008  λ_max=54.3379\n",
      "[SGD | lr=0.01] Epoch 1215/4000: train_loss=1.0551  test_loss=2.2010  λ_max=55.4320\n",
      "[SGD | lr=0.01] Epoch 1216/4000: train_loss=1.0534  test_loss=2.2003  λ_max=55.9977\n",
      "[SGD | lr=0.01] Epoch 1217/4000: train_loss=1.0527  test_loss=2.2011  λ_max=54.3540\n",
      "[SGD | lr=0.01] Epoch 1218/4000: train_loss=1.0516  test_loss=2.2015  λ_max=57.8230\n",
      "[SGD | lr=0.01] Iter 19500: loss=1.0472\n",
      "[SGD | lr=0.01] Epoch 1219/4000: train_loss=1.0512  test_loss=2.2022  λ_max=57.9409\n",
      "[SGD | lr=0.01] Epoch 1220/4000: train_loss=1.0507  test_loss=2.2027  λ_max=58.1164\n",
      "[SGD | lr=0.01] Epoch 1221/4000: train_loss=1.0511  test_loss=2.2031  λ_max=57.2663\n",
      "[SGD | lr=0.01] Epoch 1222/4000: train_loss=1.0493  test_loss=2.2027  λ_max=55.3196\n",
      "[SGD | lr=0.01] Epoch 1223/4000: train_loss=1.0480  test_loss=2.2032  λ_max=57.3432\n",
      "[SGD | lr=0.01] Epoch 1224/4000: train_loss=1.0480  test_loss=2.2037  λ_max=54.6041\n",
      "[SGD | lr=0.01] Iter 19600: loss=1.0492\n",
      "[SGD | lr=0.01] Epoch 1225/4000: train_loss=1.0473  test_loss=2.2031  λ_max=57.8110\n",
      "[SGD | lr=0.01] Epoch 1226/4000: train_loss=1.0456  test_loss=2.2033  λ_max=58.2860\n",
      "[SGD | lr=0.01] Epoch 1227/4000: train_loss=1.0448  test_loss=2.2035  λ_max=55.6246\n",
      "[SGD | lr=0.01] Epoch 1228/4000: train_loss=1.0448  test_loss=2.2044  λ_max=55.2984\n",
      "[SGD | lr=0.01] Epoch 1229/4000: train_loss=1.0439  test_loss=2.2038  λ_max=55.8965\n",
      "[SGD | lr=0.01] Epoch 1230/4000: train_loss=1.0433  test_loss=2.2042  λ_max=57.7019\n",
      "[SGD | lr=0.01] Epoch 1231/4000: train_loss=1.0431  test_loss=2.2046  λ_max=57.7531\n",
      "[SGD | lr=0.01] Iter 19700: loss=1.0464\n",
      "[SGD | lr=0.01] Epoch 1232/4000: train_loss=1.0425  test_loss=2.2052  λ_max=55.0664\n",
      "[SGD | lr=0.01] Epoch 1233/4000: train_loss=1.0412  test_loss=2.2058  λ_max=55.0441\n",
      "[SGD | lr=0.01] Epoch 1234/4000: train_loss=1.0414  test_loss=2.2070  λ_max=53.9885\n",
      "[SGD | lr=0.01] Epoch 1235/4000: train_loss=1.0404  test_loss=2.2057  λ_max=58.4632\n",
      "[SGD | lr=0.01] Epoch 1236/4000: train_loss=1.0388  test_loss=2.2060  λ_max=55.3669\n",
      "[SGD | lr=0.01] Epoch 1237/4000: train_loss=1.0382  test_loss=2.2065  λ_max=54.5676\n",
      "[SGD | lr=0.01] Iter 19800: loss=1.0387\n",
      "[SGD | lr=0.01] Epoch 1238/4000: train_loss=1.0380  test_loss=2.2078  λ_max=56.0285\n",
      "[SGD | lr=0.01] Epoch 1239/4000: train_loss=1.0373  test_loss=2.2072  λ_max=57.4968\n",
      "[SGD | lr=0.01] Epoch 1240/4000: train_loss=1.0361  test_loss=2.2074  λ_max=54.7264\n",
      "[SGD | lr=0.01] Epoch 1241/4000: train_loss=1.0352  test_loss=2.2074  λ_max=54.5982\n",
      "[SGD | lr=0.01] Epoch 1242/4000: train_loss=1.0341  test_loss=2.2071  λ_max=59.0758\n",
      "[SGD | lr=0.01] Epoch 1243/4000: train_loss=1.0340  test_loss=2.2079  λ_max=58.6709\n",
      "[SGD | lr=0.01] Iter 19900: loss=1.0330\n",
      "[SGD | lr=0.01] Epoch 1244/4000: train_loss=1.0324  test_loss=2.2081  λ_max=57.5340\n",
      "[SGD | lr=0.01] Epoch 1245/4000: train_loss=1.0321  test_loss=2.2086  λ_max=58.7535\n",
      "[SGD | lr=0.01] Epoch 1246/4000: train_loss=1.0325  test_loss=2.2092  λ_max=56.4036\n",
      "[SGD | lr=0.01] Epoch 1247/4000: train_loss=1.0315  test_loss=2.2089  λ_max=55.3182\n",
      "[SGD | lr=0.01] Epoch 1248/4000: train_loss=1.0303  test_loss=2.2087  λ_max=57.3186\n",
      "[SGD | lr=0.01] Epoch 1249/4000: train_loss=1.0290  test_loss=2.2092  λ_max=58.9989\n",
      "[SGD | lr=0.01] Iter 20000: loss=1.0245\n",
      "[SGD | lr=0.01] Epoch 1250/4000: train_loss=1.0283  test_loss=2.2099  λ_max=57.5112\n",
      "[SGD | lr=0.01] Epoch 1251/4000: train_loss=1.0275  test_loss=2.2102  λ_max=57.5949\n",
      "[SGD | lr=0.01] Epoch 1252/4000: train_loss=1.0270  test_loss=2.2095  λ_max=58.9158\n",
      "[SGD | lr=0.01] Epoch 1253/4000: train_loss=1.0256  test_loss=2.2102  λ_max=54.3367\n",
      "[SGD | lr=0.01] Epoch 1254/4000: train_loss=1.0250  test_loss=2.2105  λ_max=58.1412\n",
      "[SGD | lr=0.01] Epoch 1255/4000: train_loss=1.0244  test_loss=2.2107  λ_max=58.9041\n",
      "[SGD | lr=0.01] Epoch 1256/4000: train_loss=1.0238  test_loss=2.2107  λ_max=55.6702\n",
      "[SGD | lr=0.01] Iter 20100: loss=1.0306\n",
      "[SGD | lr=0.01] Epoch 1257/4000: train_loss=1.0227  test_loss=2.2107  λ_max=59.2781\n",
      "[SGD | lr=0.01] Epoch 1258/4000: train_loss=1.0220  test_loss=2.2117  λ_max=58.9268\n",
      "[SGD | lr=0.01] Epoch 1259/4000: train_loss=1.0226  test_loss=2.2117  λ_max=59.0348\n",
      "[SGD | lr=0.01] Epoch 1260/4000: train_loss=1.0223  test_loss=2.2133  λ_max=55.7731\n",
      "[SGD | lr=0.01] Epoch 1261/4000: train_loss=1.0223  test_loss=2.2130  λ_max=55.9162\n",
      "[SGD | lr=0.01] Epoch 1262/4000: train_loss=1.0206  test_loss=2.2133  λ_max=60.0788\n",
      "[SGD | lr=0.01] Iter 20200: loss=1.0239\n",
      "[SGD | lr=0.01] Epoch 1263/4000: train_loss=1.0191  test_loss=2.2131  λ_max=57.2106\n",
      "[SGD | lr=0.01] Epoch 1264/4000: train_loss=1.0182  test_loss=2.2129  λ_max=56.5091\n",
      "[SGD | lr=0.01] Epoch 1265/4000: train_loss=1.0177  test_loss=2.2136  λ_max=59.4831\n",
      "[SGD | lr=0.01] Epoch 1266/4000: train_loss=1.0177  test_loss=2.2148  λ_max=57.9459\n",
      "[SGD | lr=0.01] Epoch 1267/4000: train_loss=1.0170  test_loss=2.2140  λ_max=59.3877\n",
      "[SGD | lr=0.01] Epoch 1268/4000: train_loss=1.0152  test_loss=2.2141  λ_max=59.0422\n",
      "[SGD | lr=0.01] Iter 20300: loss=1.0071\n",
      "[SGD | lr=0.01] Epoch 1269/4000: train_loss=1.0139  test_loss=2.2137  λ_max=59.6973\n",
      "[SGD | lr=0.01] Epoch 1270/4000: train_loss=1.0145  test_loss=2.2148  λ_max=59.9183\n",
      "[SGD | lr=0.01] Epoch 1271/4000: train_loss=1.0131  test_loss=2.2149  λ_max=59.6489\n",
      "[SGD | lr=0.01] Epoch 1272/4000: train_loss=1.0120  test_loss=2.2151  λ_max=61.5024\n",
      "[SGD | lr=0.01] Epoch 1273/4000: train_loss=1.0109  test_loss=2.2152  λ_max=60.0991\n",
      "[SGD | lr=0.01] Epoch 1274/4000: train_loss=1.0111  test_loss=2.2150  λ_max=58.8537\n",
      "[SGD | lr=0.01] Iter 20400: loss=1.0092\n",
      "[SGD | lr=0.01] Epoch 1275/4000: train_loss=1.0117  test_loss=2.2159  λ_max=57.5238\n",
      "[SGD | lr=0.01] Epoch 1276/4000: train_loss=1.0100  test_loss=2.2158  λ_max=58.3485\n",
      "[SGD | lr=0.01] Epoch 1277/4000: train_loss=1.0091  test_loss=2.2161  λ_max=60.3960\n",
      "[SGD | lr=0.01] Epoch 1278/4000: train_loss=1.0103  test_loss=2.2166  λ_max=61.2790\n",
      "[SGD | lr=0.01] Epoch 1279/4000: train_loss=1.0081  test_loss=2.2165  λ_max=61.8035\n",
      "[SGD | lr=0.01] Epoch 1280/4000: train_loss=1.0065  test_loss=2.2159  λ_max=58.6635\n",
      "[SGD | lr=0.01] Epoch 1281/4000: train_loss=1.0060  test_loss=2.2167  λ_max=61.3218\n",
      "[SGD | lr=0.01] Iter 20500: loss=1.0011\n",
      "[SGD | lr=0.01] Epoch 1282/4000: train_loss=1.0055  test_loss=2.2171  λ_max=58.6377\n",
      "[SGD | lr=0.01] Epoch 1283/4000: train_loss=1.0048  test_loss=2.2175  λ_max=58.8830\n",
      "[SGD | lr=0.01] Epoch 1284/4000: train_loss=1.0045  test_loss=2.2179  λ_max=58.9033\n",
      "[SGD | lr=0.01] Epoch 1285/4000: train_loss=1.0046  test_loss=2.2185  λ_max=59.3810\n",
      "[SGD | lr=0.01] Epoch 1286/4000: train_loss=1.0034  test_loss=2.2192  λ_max=60.8312\n",
      "[SGD | lr=0.01] Epoch 1287/4000: train_loss=1.0020  test_loss=2.2182  λ_max=57.6428\n",
      "[SGD | lr=0.01] Iter 20600: loss=0.9997\n",
      "[SGD | lr=0.01] Epoch 1288/4000: train_loss=1.0012  test_loss=2.2194  λ_max=59.4587\n",
      "[SGD | lr=0.01] Epoch 1289/4000: train_loss=1.0009  test_loss=2.2192  λ_max=60.3355\n",
      "[SGD | lr=0.01] Epoch 1290/4000: train_loss=0.9997  test_loss=2.2199  λ_max=52.9113\n",
      "[SGD | lr=0.01] Epoch 1291/4000: train_loss=0.9996  test_loss=2.2208  λ_max=57.5927\n",
      "[SGD | lr=0.01] Epoch 1292/4000: train_loss=0.9980  test_loss=2.2192  λ_max=59.6488\n",
      "[SGD | lr=0.01] Epoch 1293/4000: train_loss=0.9983  test_loss=2.2211  λ_max=60.3898\n",
      "[SGD | lr=0.01] Iter 20700: loss=0.9964\n",
      "[SGD | lr=0.01] Epoch 1294/4000: train_loss=0.9970  test_loss=2.2203  λ_max=61.8189\n",
      "[SGD | lr=0.01] Epoch 1295/4000: train_loss=0.9958  test_loss=2.2213  λ_max=58.1750\n",
      "[SGD | lr=0.01] Epoch 1296/4000: train_loss=0.9954  test_loss=2.2219  λ_max=57.2928\n",
      "[SGD | lr=0.01] Epoch 1297/4000: train_loss=0.9957  test_loss=2.2220  λ_max=62.6105\n",
      "[SGD | lr=0.01] Epoch 1298/4000: train_loss=0.9938  test_loss=2.2209  λ_max=60.7522\n",
      "[SGD | lr=0.01] Epoch 1299/4000: train_loss=0.9925  test_loss=2.2220  λ_max=59.5368\n",
      "[SGD | lr=0.01] Iter 20800: loss=0.9937\n",
      "[SGD | lr=0.01] Epoch 1300/4000: train_loss=0.9928  test_loss=2.2221  λ_max=55.9908\n",
      "[SGD | lr=0.01] Epoch 1301/4000: train_loss=0.9921  test_loss=2.2225  λ_max=61.8804\n",
      "[SGD | lr=0.01] Epoch 1302/4000: train_loss=0.9909  test_loss=2.2231  λ_max=59.4652\n",
      "[SGD | lr=0.01] Epoch 1303/4000: train_loss=0.9910  test_loss=2.2231  λ_max=61.6739\n",
      "[SGD | lr=0.01] Epoch 1304/4000: train_loss=0.9903  test_loss=2.2243  λ_max=58.1504\n",
      "[SGD | lr=0.01] Epoch 1305/4000: train_loss=0.9886  test_loss=2.2237  λ_max=60.9079\n",
      "[SGD | lr=0.01] Epoch 1306/4000: train_loss=0.9887  test_loss=2.2241  λ_max=60.9684\n",
      "[SGD | lr=0.01] Iter 20900: loss=0.9988\n",
      "[SGD | lr=0.01] Epoch 1307/4000: train_loss=0.9882  test_loss=2.2251  λ_max=62.0758\n",
      "[SGD | lr=0.01] Epoch 1308/4000: train_loss=0.9874  test_loss=2.2243  λ_max=62.5554\n",
      "[SGD | lr=0.01] Epoch 1309/4000: train_loss=0.9869  test_loss=2.2251  λ_max=61.4124\n",
      "[SGD | lr=0.01] Epoch 1310/4000: train_loss=0.9862  test_loss=2.2254  λ_max=62.0423\n",
      "[SGD | lr=0.01] Epoch 1311/4000: train_loss=0.9850  test_loss=2.2254  λ_max=60.3135\n",
      "[SGD | lr=0.01] Epoch 1312/4000: train_loss=0.9840  test_loss=2.2254  λ_max=60.0208\n",
      "[SGD | lr=0.01] Iter 21000: loss=0.9913\n",
      "[SGD | lr=0.01] Epoch 1313/4000: train_loss=0.9839  test_loss=2.2253  λ_max=59.3393\n",
      "[SGD | lr=0.01] Epoch 1314/4000: train_loss=0.9824  test_loss=2.2259  λ_max=60.7322\n",
      "[SGD | lr=0.01] Epoch 1315/4000: train_loss=0.9816  test_loss=2.2260  λ_max=61.3346\n",
      "[SGD | lr=0.01] Epoch 1316/4000: train_loss=0.9823  test_loss=2.2264  λ_max=60.8509\n",
      "[SGD | lr=0.01] Epoch 1317/4000: train_loss=0.9803  test_loss=2.2265  λ_max=61.4738\n",
      "[SGD | lr=0.01] Epoch 1318/4000: train_loss=0.9801  test_loss=2.2267  λ_max=61.1278\n",
      "[SGD | lr=0.01] Iter 21100: loss=0.9773\n",
      "[SGD | lr=0.01] Epoch 1319/4000: train_loss=0.9796  test_loss=2.2272  λ_max=60.7164\n",
      "[SGD | lr=0.01] Epoch 1320/4000: train_loss=0.9779  test_loss=2.2269  λ_max=63.0643\n",
      "[SGD | lr=0.01] Epoch 1321/4000: train_loss=0.9772  test_loss=2.2266  λ_max=60.3362\n",
      "[SGD | lr=0.01] Epoch 1322/4000: train_loss=0.9770  test_loss=2.2276  λ_max=60.4756\n",
      "[SGD | lr=0.01] Epoch 1323/4000: train_loss=0.9762  test_loss=2.2280  λ_max=61.5458\n",
      "[SGD | lr=0.01] Epoch 1324/4000: train_loss=0.9760  test_loss=2.2284  λ_max=61.1443\n",
      "[SGD | lr=0.01] Iter 21200: loss=0.9673\n",
      "[SGD | lr=0.01] Epoch 1325/4000: train_loss=0.9753  test_loss=2.2288  λ_max=62.1520\n",
      "[SGD | lr=0.01] Epoch 1326/4000: train_loss=0.9743  test_loss=2.2289  λ_max=58.6528\n",
      "[SGD | lr=0.01] Epoch 1327/4000: train_loss=0.9735  test_loss=2.2295  λ_max=62.0998\n",
      "[SGD | lr=0.01] Epoch 1328/4000: train_loss=0.9725  test_loss=2.2288  λ_max=61.2837\n",
      "[SGD | lr=0.01] Epoch 1329/4000: train_loss=0.9725  test_loss=2.2296  λ_max=59.9293\n",
      "[SGD | lr=0.01] Epoch 1330/4000: train_loss=0.9711  test_loss=2.2298  λ_max=63.9437\n",
      "[SGD | lr=0.01] Epoch 1331/4000: train_loss=0.9700  test_loss=2.2299  λ_max=60.4120\n",
      "[SGD | lr=0.01] Iter 21300: loss=0.9773\n",
      "[SGD | lr=0.01] Epoch 1332/4000: train_loss=0.9699  test_loss=2.2306  λ_max=60.9578\n",
      "[SGD | lr=0.01] Epoch 1333/4000: train_loss=0.9689  test_loss=2.2298  λ_max=64.0720\n",
      "[SGD | lr=0.01] Epoch 1334/4000: train_loss=0.9681  test_loss=2.2314  λ_max=59.4133\n",
      "[SGD | lr=0.01] Epoch 1335/4000: train_loss=0.9689  test_loss=2.2320  λ_max=59.3432\n",
      "[SGD | lr=0.01] Epoch 1336/4000: train_loss=0.9678  test_loss=2.2316  λ_max=62.5956\n",
      "[SGD | lr=0.01] Epoch 1337/4000: train_loss=0.9662  test_loss=2.2323  λ_max=61.7960\n",
      "[SGD | lr=0.01] Iter 21400: loss=0.9685\n",
      "[SGD | lr=0.01] Epoch 1338/4000: train_loss=0.9673  test_loss=2.2336  λ_max=63.3031\n",
      "[SGD | lr=0.01] Epoch 1339/4000: train_loss=0.9674  test_loss=2.2329  λ_max=58.1286\n",
      "[SGD | lr=0.01] Epoch 1340/4000: train_loss=0.9648  test_loss=2.2332  λ_max=60.7463\n",
      "[SGD | lr=0.01] Epoch 1341/4000: train_loss=0.9630  test_loss=2.2326  λ_max=61.2022\n",
      "[SGD | lr=0.01] Epoch 1342/4000: train_loss=0.9636  test_loss=2.2333  λ_max=60.8932\n",
      "[SGD | lr=0.01] Epoch 1343/4000: train_loss=0.9617  test_loss=2.2338  λ_max=63.9884\n",
      "[SGD | lr=0.01] Iter 21500: loss=0.9716\n",
      "[SGD | lr=0.01] Epoch 1344/4000: train_loss=0.9608  test_loss=2.2338  λ_max=63.5761\n",
      "[SGD | lr=0.01] Epoch 1345/4000: train_loss=0.9615  test_loss=2.2344  λ_max=63.2163\n",
      "[SGD | lr=0.01] Epoch 1346/4000: train_loss=0.9621  test_loss=2.2349  λ_max=58.8980\n",
      "[SGD | lr=0.01] Epoch 1347/4000: train_loss=0.9594  test_loss=2.2342  λ_max=62.8773\n",
      "[SGD | lr=0.01] Epoch 1348/4000: train_loss=0.9587  test_loss=2.2347  λ_max=60.3753\n",
      "[SGD | lr=0.01] Epoch 1349/4000: train_loss=0.9587  test_loss=2.2366  λ_max=61.0508\n",
      "[SGD | lr=0.01] Iter 21600: loss=0.9682\n",
      "[SGD | lr=0.01] Epoch 1350/4000: train_loss=0.9602  test_loss=2.2362  λ_max=61.9616\n",
      "[SGD | lr=0.01] Epoch 1351/4000: train_loss=0.9570  test_loss=2.2367  λ_max=60.3652\n",
      "[SGD | lr=0.01] Epoch 1352/4000: train_loss=0.9580  test_loss=2.2377  λ_max=60.9839\n",
      "[SGD | lr=0.01] Epoch 1353/4000: train_loss=0.9574  test_loss=2.2373  λ_max=65.0137\n",
      "[SGD | lr=0.01] Epoch 1354/4000: train_loss=0.9549  test_loss=2.2374  λ_max=62.8350\n",
      "[SGD | lr=0.01] Epoch 1355/4000: train_loss=0.9538  test_loss=2.2365  λ_max=63.4981\n",
      "[SGD | lr=0.01] Epoch 1356/4000: train_loss=0.9532  test_loss=2.2369  λ_max=61.2525\n",
      "[SGD | lr=0.01] Iter 21700: loss=0.9554\n",
      "[SGD | lr=0.01] Epoch 1357/4000: train_loss=0.9527  test_loss=2.2384  λ_max=62.1732\n",
      "[SGD | lr=0.01] Epoch 1358/4000: train_loss=0.9531  test_loss=2.2385  λ_max=61.0989\n",
      "[SGD | lr=0.01] Epoch 1359/4000: train_loss=0.9527  test_loss=2.2376  λ_max=64.1555\n",
      "[SGD | lr=0.01] Epoch 1360/4000: train_loss=0.9508  test_loss=2.2385  λ_max=59.1433\n",
      "[SGD | lr=0.01] Epoch 1361/4000: train_loss=0.9523  test_loss=2.2392  λ_max=60.2118\n",
      "[SGD | lr=0.01] Epoch 1362/4000: train_loss=0.9491  test_loss=2.2384  λ_max=60.3422\n",
      "[SGD | lr=0.01] Iter 21800: loss=0.9506\n",
      "[SGD | lr=0.01] Epoch 1363/4000: train_loss=0.9474  test_loss=2.2397  λ_max=59.4063\n",
      "[SGD | lr=0.01] Epoch 1364/4000: train_loss=0.9479  test_loss=2.2401  λ_max=64.9899\n",
      "[SGD | lr=0.01] Epoch 1365/4000: train_loss=0.9468  test_loss=2.2408  λ_max=58.0091\n",
      "[SGD | lr=0.01] Epoch 1366/4000: train_loss=0.9478  test_loss=2.2415  λ_max=62.0162\n",
      "[SGD | lr=0.01] Epoch 1367/4000: train_loss=0.9459  test_loss=2.2408  λ_max=65.3032\n",
      "[SGD | lr=0.01] Epoch 1368/4000: train_loss=0.9456  test_loss=2.2413  λ_max=64.9185\n",
      "[SGD | lr=0.01] Iter 21900: loss=0.9512\n",
      "[SGD | lr=0.01] Epoch 1369/4000: train_loss=0.9454  test_loss=2.2409  λ_max=62.9935\n",
      "[SGD | lr=0.01] Epoch 1370/4000: train_loss=0.9447  test_loss=2.2420  λ_max=64.0638\n",
      "[SGD | lr=0.01] Epoch 1371/4000: train_loss=0.9448  test_loss=2.2413  λ_max=64.4405\n",
      "[SGD | lr=0.01] Epoch 1372/4000: train_loss=0.9432  test_loss=2.2421  λ_max=66.6697\n",
      "[SGD | lr=0.01] Epoch 1373/4000: train_loss=0.9426  test_loss=2.2429  λ_max=65.9485\n",
      "[SGD | lr=0.01] Epoch 1374/4000: train_loss=0.9430  test_loss=2.2432  λ_max=63.0884\n",
      "[SGD | lr=0.01] Iter 22000: loss=0.9433\n",
      "[SGD | lr=0.01] Epoch 1375/4000: train_loss=0.9405  test_loss=2.2430  λ_max=65.9818\n",
      "[SGD | lr=0.01] Epoch 1376/4000: train_loss=0.9401  test_loss=2.2426  λ_max=65.5969\n",
      "[SGD | lr=0.01] Epoch 1377/4000: train_loss=0.9405  test_loss=2.2434  λ_max=64.2539\n",
      "[SGD | lr=0.01] Epoch 1378/4000: train_loss=0.9393  test_loss=2.2443  λ_max=63.9682\n",
      "[SGD | lr=0.01] Epoch 1379/4000: train_loss=0.9382  test_loss=2.2441  λ_max=59.5734\n",
      "[SGD | lr=0.01] Epoch 1380/4000: train_loss=0.9379  test_loss=2.2456  λ_max=66.5873\n",
      "[SGD | lr=0.01] Epoch 1381/4000: train_loss=0.9363  test_loss=2.2444  λ_max=64.8680\n",
      "[SGD | lr=0.01] Iter 22100: loss=0.9350\n",
      "[SGD | lr=0.01] Epoch 1382/4000: train_loss=0.9360  test_loss=2.2447  λ_max=64.6250\n",
      "[SGD | lr=0.01] Epoch 1383/4000: train_loss=0.9345  test_loss=2.2442  λ_max=64.7490\n",
      "[SGD | lr=0.01] Epoch 1384/4000: train_loss=0.9363  test_loss=2.2453  λ_max=66.0821\n",
      "[SGD | lr=0.01] Epoch 1385/4000: train_loss=0.9367  test_loss=2.2456  λ_max=59.9407\n",
      "[SGD | lr=0.01] Epoch 1386/4000: train_loss=0.9337  test_loss=2.2455  λ_max=62.9084\n",
      "[SGD | lr=0.01] Epoch 1387/4000: train_loss=0.9329  test_loss=2.2465  λ_max=67.0216\n",
      "[SGD | lr=0.01] Iter 22200: loss=0.9370\n",
      "[SGD | lr=0.01] Epoch 1388/4000: train_loss=0.9325  test_loss=2.2463  λ_max=59.1739\n",
      "[SGD | lr=0.01] Epoch 1389/4000: train_loss=0.9307  test_loss=2.2460  λ_max=66.6763\n",
      "[SGD | lr=0.01] Epoch 1390/4000: train_loss=0.9313  test_loss=2.2467  λ_max=64.3259\n",
      "[SGD | lr=0.01] Epoch 1391/4000: train_loss=0.9314  test_loss=2.2472  λ_max=61.6689\n",
      "[SGD | lr=0.01] Epoch 1392/4000: train_loss=0.9301  test_loss=2.2472  λ_max=64.2231\n",
      "[SGD | lr=0.01] Epoch 1393/4000: train_loss=0.9292  test_loss=2.2476  λ_max=60.5745\n",
      "[SGD | lr=0.01] Iter 22300: loss=0.9320\n",
      "[SGD | lr=0.01] Epoch 1394/4000: train_loss=0.9272  test_loss=2.2478  λ_max=60.3561\n",
      "[SGD | lr=0.01] Epoch 1395/4000: train_loss=0.9283  test_loss=2.2489  λ_max=64.7513\n",
      "[SGD | lr=0.01] Epoch 1396/4000: train_loss=0.9281  test_loss=2.2499  λ_max=66.1447\n",
      "[SGD | lr=0.01] Epoch 1397/4000: train_loss=0.9269  test_loss=2.2488  λ_max=62.0998\n",
      "[SGD | lr=0.01] Epoch 1398/4000: train_loss=0.9254  test_loss=2.2498  λ_max=65.9709\n",
      "[SGD | lr=0.01] Epoch 1399/4000: train_loss=0.9254  test_loss=2.2503  λ_max=61.2384\n",
      "[SGD | lr=0.01] Iter 22400: loss=0.9393\n",
      "[SGD | lr=0.01] Epoch 1400/4000: train_loss=0.9253  test_loss=2.2498  λ_max=66.7557\n",
      "[SGD | lr=0.01] Epoch 1401/4000: train_loss=0.9234  test_loss=2.2499  λ_max=67.2923\n",
      "[SGD | lr=0.01] Epoch 1402/4000: train_loss=0.9224  test_loss=2.2505  λ_max=61.0040\n",
      "[SGD | lr=0.01] Epoch 1403/4000: train_loss=0.9227  test_loss=2.2512  λ_max=59.3010\n",
      "[SGD | lr=0.01] Epoch 1404/4000: train_loss=0.9214  test_loss=2.2508  λ_max=61.8353\n",
      "[SGD | lr=0.01] Epoch 1405/4000: train_loss=0.9220  test_loss=2.2508  λ_max=62.9723\n",
      "[SGD | lr=0.01] Epoch 1406/4000: train_loss=0.9204  test_loss=2.2512  λ_max=65.6942\n",
      "[SGD | lr=0.01] Iter 22500: loss=0.9181\n",
      "[SGD | lr=0.01] Epoch 1407/4000: train_loss=0.9188  test_loss=2.2505  λ_max=65.1244\n",
      "[SGD | lr=0.01] Epoch 1408/4000: train_loss=0.9189  test_loss=2.2516  λ_max=65.6749\n",
      "[SGD | lr=0.01] Epoch 1409/4000: train_loss=0.9171  test_loss=2.2518  λ_max=66.4018\n",
      "[SGD | lr=0.01] Epoch 1410/4000: train_loss=0.9186  test_loss=2.2519  λ_max=60.3509\n",
      "[SGD | lr=0.01] Epoch 1411/4000: train_loss=0.9164  test_loss=2.2527  λ_max=64.8963\n",
      "[SGD | lr=0.01] Epoch 1412/4000: train_loss=0.9174  test_loss=2.2535  λ_max=65.6013\n",
      "[SGD | lr=0.01] Iter 22600: loss=0.9179\n",
      "[SGD | lr=0.01] Epoch 1413/4000: train_loss=0.9189  test_loss=2.2538  λ_max=64.4931\n",
      "[SGD | lr=0.01] Epoch 1414/4000: train_loss=0.9173  test_loss=2.2540  λ_max=62.7546\n",
      "[SGD | lr=0.01] Epoch 1415/4000: train_loss=0.9156  test_loss=2.2537  λ_max=63.0614\n",
      "[SGD | lr=0.01] Epoch 1416/4000: train_loss=0.9152  test_loss=2.2543  λ_max=67.2749\n",
      "[SGD | lr=0.01] Epoch 1417/4000: train_loss=0.9137  test_loss=2.2561  λ_max=63.2599\n",
      "[SGD | lr=0.01] Epoch 1418/4000: train_loss=0.9157  test_loss=2.2562  λ_max=64.4710\n",
      "[SGD | lr=0.01] Iter 22700: loss=0.9062\n",
      "[SGD | lr=0.01] Epoch 1419/4000: train_loss=0.9128  test_loss=2.2561  λ_max=64.5824\n",
      "[SGD | lr=0.01] Epoch 1420/4000: train_loss=0.9116  test_loss=2.2554  λ_max=60.1403\n",
      "[SGD | lr=0.01] Epoch 1421/4000: train_loss=0.9096  test_loss=2.2557  λ_max=64.0799\n",
      "[SGD | lr=0.01] Epoch 1422/4000: train_loss=0.9103  test_loss=2.2564  λ_max=60.6142\n",
      "[SGD | lr=0.01] Epoch 1423/4000: train_loss=0.9103  test_loss=2.2578  λ_max=66.6089\n",
      "[SGD | lr=0.01] Epoch 1424/4000: train_loss=0.9081  test_loss=2.2561  λ_max=63.2812\n",
      "[SGD | lr=0.01] Iter 22800: loss=0.9104\n",
      "[SGD | lr=0.01] Epoch 1425/4000: train_loss=0.9062  test_loss=2.2560  λ_max=63.6334\n",
      "[SGD | lr=0.01] Epoch 1426/4000: train_loss=0.9077  test_loss=2.2576  λ_max=64.4236\n",
      "[SGD | lr=0.01] Epoch 1427/4000: train_loss=0.9083  test_loss=2.2586  λ_max=64.8140\n",
      "[SGD | lr=0.01] Epoch 1428/4000: train_loss=0.9065  test_loss=2.2585  λ_max=65.4615\n",
      "[SGD | lr=0.01] Epoch 1429/4000: train_loss=0.9065  test_loss=2.2588  λ_max=64.4372\n",
      "[SGD | lr=0.01] Epoch 1430/4000: train_loss=0.9064  test_loss=2.2595  λ_max=65.4213\n",
      "[SGD | lr=0.01] Epoch 1431/4000: train_loss=0.9048  test_loss=2.2593  λ_max=64.6912\n",
      "[SGD | lr=0.01] Iter 22900: loss=0.9061\n",
      "[SGD | lr=0.01] Epoch 1432/4000: train_loss=0.9023  test_loss=2.2591  λ_max=63.5572\n",
      "[SGD | lr=0.01] Epoch 1433/4000: train_loss=0.9028  test_loss=2.2595  λ_max=64.2335\n",
      "[SGD | lr=0.01] Epoch 1434/4000: train_loss=0.9025  test_loss=2.2605  λ_max=64.2056\n",
      "[SGD | lr=0.01] Epoch 1435/4000: train_loss=0.9024  test_loss=2.2601  λ_max=63.3631\n",
      "[SGD | lr=0.01] Epoch 1436/4000: train_loss=0.8996  test_loss=2.2597  λ_max=65.3772\n",
      "[SGD | lr=0.01] Epoch 1437/4000: train_loss=0.9001  test_loss=2.2604  λ_max=65.2684\n",
      "[SGD | lr=0.01] Iter 23000: loss=0.8968\n",
      "[SGD | lr=0.01] Epoch 1438/4000: train_loss=0.9008  test_loss=2.2611  λ_max=66.5009\n",
      "[SGD | lr=0.01] Epoch 1439/4000: train_loss=0.9009  test_loss=2.2619  λ_max=64.1220\n",
      "[SGD | lr=0.01] Epoch 1440/4000: train_loss=0.8996  test_loss=2.2617  λ_max=61.3293\n",
      "[SGD | lr=0.01] Epoch 1441/4000: train_loss=0.8973  test_loss=2.2623  λ_max=62.5824\n",
      "[SGD | lr=0.01] Epoch 1442/4000: train_loss=0.8993  test_loss=2.2626  λ_max=67.5989\n",
      "[SGD | lr=0.01] Epoch 1443/4000: train_loss=0.8953  test_loss=2.2624  λ_max=61.1204\n",
      "[SGD | lr=0.01] Iter 23100: loss=0.9024\n",
      "[SGD | lr=0.01] Epoch 1444/4000: train_loss=0.8951  test_loss=2.2621  λ_max=64.3901\n",
      "[SGD | lr=0.01] Epoch 1445/4000: train_loss=0.8943  test_loss=2.2622  λ_max=63.0874\n",
      "[SGD | lr=0.01] Epoch 1446/4000: train_loss=0.8945  test_loss=2.2622  λ_max=66.1061\n",
      "[SGD | lr=0.01] Epoch 1447/4000: train_loss=0.8961  test_loss=2.2625  λ_max=63.8492\n",
      "[SGD | lr=0.01] Epoch 1448/4000: train_loss=0.8962  test_loss=2.2630  λ_max=66.4081\n",
      "[SGD | lr=0.01] Epoch 1449/4000: train_loss=0.8930  test_loss=2.2637  λ_max=65.2524\n",
      "[SGD | lr=0.01] Iter 23200: loss=0.8947\n",
      "[SGD | lr=0.01] Epoch 1450/4000: train_loss=0.8935  test_loss=2.2648  λ_max=67.6288\n",
      "[SGD | lr=0.01] Epoch 1451/4000: train_loss=0.8934  test_loss=2.2645  λ_max=63.8066\n",
      "[SGD | lr=0.01] Epoch 1452/4000: train_loss=0.8917  test_loss=2.2646  λ_max=65.3543\n",
      "[SGD | lr=0.01] Epoch 1453/4000: train_loss=0.8901  test_loss=2.2655  λ_max=67.5857\n",
      "[SGD | lr=0.01] Epoch 1454/4000: train_loss=0.8897  test_loss=2.2652  λ_max=63.3098\n",
      "[SGD | lr=0.01] Epoch 1455/4000: train_loss=0.8863  test_loss=2.2653  λ_max=65.4236\n",
      "[SGD | lr=0.01] Epoch 1456/4000: train_loss=0.8866  test_loss=2.2661  λ_max=65.6007\n",
      "[SGD | lr=0.01] Iter 23300: loss=0.8911\n",
      "[SGD | lr=0.01] Epoch 1457/4000: train_loss=0.8884  test_loss=2.2669  λ_max=62.7445\n",
      "[SGD | lr=0.01] Epoch 1458/4000: train_loss=0.8876  test_loss=2.2670  λ_max=64.1073\n",
      "[SGD | lr=0.01] Epoch 1459/4000: train_loss=0.8878  test_loss=2.2675  λ_max=66.7533\n",
      "[SGD | lr=0.01] Epoch 1460/4000: train_loss=0.8841  test_loss=2.2670  λ_max=67.3231\n",
      "[SGD | lr=0.01] Epoch 1461/4000: train_loss=0.8857  test_loss=2.2684  λ_max=62.3715\n",
      "[SGD | lr=0.01] Epoch 1462/4000: train_loss=0.8847  test_loss=2.2678  λ_max=65.7687\n",
      "[SGD | lr=0.01] Iter 23400: loss=0.8761\n",
      "[SGD | lr=0.01] Epoch 1463/4000: train_loss=0.8846  test_loss=2.2681  λ_max=64.8002\n",
      "[SGD | lr=0.01] Epoch 1464/4000: train_loss=0.8838  test_loss=2.2687  λ_max=63.8906\n",
      "[SGD | lr=0.01] Epoch 1465/4000: train_loss=0.8823  test_loss=2.2683  λ_max=65.1269\n",
      "[SGD | lr=0.01] Epoch 1466/4000: train_loss=0.8824  test_loss=2.2693  λ_max=65.2870\n",
      "[SGD | lr=0.01] Epoch 1467/4000: train_loss=0.8813  test_loss=2.2696  λ_max=64.9709\n",
      "[SGD | lr=0.01] Epoch 1468/4000: train_loss=0.8815  test_loss=2.2703  λ_max=61.5588\n",
      "[SGD | lr=0.01] Iter 23500: loss=0.8821\n",
      "[SGD | lr=0.01] Epoch 1469/4000: train_loss=0.8822  test_loss=2.2723  λ_max=66.7935\n",
      "[SGD | lr=0.01] Epoch 1470/4000: train_loss=0.8813  test_loss=2.2703  λ_max=68.4524\n",
      "[SGD | lr=0.01] Epoch 1471/4000: train_loss=0.8774  test_loss=2.2713  λ_max=68.7816\n",
      "[SGD | lr=0.01] Epoch 1472/4000: train_loss=0.8785  test_loss=2.2706  λ_max=68.3873\n",
      "[SGD | lr=0.01] Epoch 1473/4000: train_loss=0.8793  test_loss=2.2707  λ_max=64.4731\n",
      "[SGD | lr=0.01] Epoch 1474/4000: train_loss=0.8762  test_loss=2.2714  λ_max=64.1414\n",
      "[SGD | lr=0.01] Iter 23600: loss=0.8880\n",
      "[SGD | lr=0.01] Epoch 1475/4000: train_loss=0.8788  test_loss=2.2720  λ_max=66.1871\n",
      "[SGD | lr=0.01] Epoch 1476/4000: train_loss=0.8793  test_loss=2.2721  λ_max=65.8249\n",
      "[SGD | lr=0.01] Epoch 1477/4000: train_loss=0.8748  test_loss=2.2719  λ_max=67.2679\n",
      "[SGD | lr=0.01] Epoch 1478/4000: train_loss=0.8745  test_loss=2.2731  λ_max=68.0288\n",
      "[SGD | lr=0.01] Epoch 1479/4000: train_loss=0.8729  test_loss=2.2745  λ_max=66.8079\n",
      "[SGD | lr=0.01] Epoch 1480/4000: train_loss=0.8743  test_loss=2.2746  λ_max=66.8429\n",
      "[SGD | lr=0.01] Epoch 1481/4000: train_loss=0.8748  test_loss=2.2738  λ_max=68.1532\n",
      "[SGD | lr=0.01] Iter 23700: loss=0.8698\n",
      "[SGD | lr=0.01] Epoch 1482/4000: train_loss=0.8717  test_loss=2.2736  λ_max=66.6934\n",
      "[SGD | lr=0.01] Epoch 1483/4000: train_loss=0.8702  test_loss=2.2747  λ_max=65.8696\n",
      "[SGD | lr=0.01] Epoch 1484/4000: train_loss=0.8709  test_loss=2.2759  λ_max=64.1951\n",
      "[SGD | lr=0.01] Epoch 1485/4000: train_loss=0.8699  test_loss=2.2759  λ_max=66.3789\n",
      "[SGD | lr=0.01] Epoch 1486/4000: train_loss=0.8694  test_loss=2.2757  λ_max=66.7370\n",
      "[SGD | lr=0.01] Epoch 1487/4000: train_loss=0.8688  test_loss=2.2759  λ_max=64.5641\n",
      "[SGD | lr=0.01] Iter 23800: loss=0.8711\n",
      "[SGD | lr=0.01] Epoch 1488/4000: train_loss=0.8681  test_loss=2.2766  λ_max=63.0127\n",
      "[SGD | lr=0.01] Epoch 1489/4000: train_loss=0.8704  test_loss=2.2763  λ_max=65.8706\n",
      "[SGD | lr=0.01] Epoch 1490/4000: train_loss=0.8670  test_loss=2.2763  λ_max=65.1799\n",
      "[SGD | lr=0.01] Epoch 1491/4000: train_loss=0.8679  test_loss=2.2772  λ_max=59.9957\n",
      "[SGD | lr=0.01] Epoch 1492/4000: train_loss=0.8694  test_loss=2.2780  λ_max=66.0478\n",
      "[SGD | lr=0.01] Epoch 1493/4000: train_loss=0.8633  test_loss=2.2773  λ_max=65.1032\n",
      "[SGD | lr=0.01] Iter 23900: loss=0.8596\n",
      "[SGD | lr=0.01] Epoch 1494/4000: train_loss=0.8637  test_loss=2.2780  λ_max=68.7817\n",
      "[SGD | lr=0.01] Epoch 1495/4000: train_loss=0.8635  test_loss=2.2778  λ_max=63.5326\n",
      "[SGD | lr=0.01] Epoch 1496/4000: train_loss=0.8627  test_loss=2.2784  λ_max=65.0555\n",
      "[SGD | lr=0.01] Epoch 1497/4000: train_loss=0.8613  test_loss=2.2783  λ_max=65.1158\n",
      "[SGD | lr=0.01] Epoch 1498/4000: train_loss=0.8644  test_loss=2.2796  λ_max=63.8913\n",
      "[SGD | lr=0.01] Epoch 1499/4000: train_loss=0.8617  test_loss=2.2789  λ_max=67.7234\n",
      "[SGD | lr=0.01] Iter 24000: loss=0.8484\n",
      "[SGD | lr=0.01] Epoch 1500/4000: train_loss=0.8587  test_loss=2.2798  λ_max=67.1232\n",
      "[SGD | lr=0.01] Epoch 1501/4000: train_loss=0.8604  test_loss=2.2808  λ_max=65.0365\n",
      "[SGD | lr=0.01] Epoch 1502/4000: train_loss=0.8625  test_loss=2.2808  λ_max=68.1305\n",
      "[SGD | lr=0.01] Epoch 1503/4000: train_loss=0.8628  test_loss=2.2816  λ_max=65.9953\n",
      "[SGD | lr=0.01] Epoch 1504/4000: train_loss=0.8580  test_loss=2.2796  λ_max=64.7548\n",
      "[SGD | lr=0.01] Epoch 1505/4000: train_loss=0.8545  test_loss=2.2817  λ_max=68.2675\n",
      "[SGD | lr=0.01] Epoch 1506/4000: train_loss=0.8574  test_loss=2.2834  λ_max=64.0438\n",
      "[SGD | lr=0.01] Iter 24100: loss=0.8611\n",
      "[SGD | lr=0.01] Epoch 1507/4000: train_loss=0.8578  test_loss=2.2827  λ_max=67.1573\n",
      "[SGD | lr=0.01] Epoch 1508/4000: train_loss=0.8575  test_loss=2.2816  λ_max=65.3171\n",
      "[SGD | lr=0.01] Epoch 1509/4000: train_loss=0.8573  test_loss=2.2824  λ_max=64.3513\n",
      "[SGD | lr=0.01] Epoch 1510/4000: train_loss=0.8572  test_loss=2.2833  λ_max=64.1740\n",
      "[SGD | lr=0.01] Epoch 1511/4000: train_loss=0.8557  test_loss=2.2835  λ_max=66.0895\n",
      "[SGD | lr=0.01] Epoch 1512/4000: train_loss=0.8544  test_loss=2.2853  λ_max=68.6664\n",
      "[SGD | lr=0.01] Iter 24200: loss=0.8522\n",
      "[SGD | lr=0.01] Epoch 1513/4000: train_loss=0.8538  test_loss=2.2857  λ_max=67.3072\n",
      "[SGD | lr=0.01] Epoch 1514/4000: train_loss=0.8547  test_loss=2.2858  λ_max=66.2508\n",
      "[SGD | lr=0.01] Epoch 1515/4000: train_loss=0.8548  test_loss=2.2855  λ_max=65.0288\n",
      "[SGD | lr=0.01] Epoch 1516/4000: train_loss=0.8519  test_loss=2.2856  λ_max=63.8813\n",
      "[SGD | lr=0.01] Epoch 1517/4000: train_loss=0.8494  test_loss=2.2862  λ_max=65.9375\n",
      "[SGD | lr=0.01] Epoch 1518/4000: train_loss=0.8515  test_loss=2.2873  λ_max=69.1937\n",
      "[SGD | lr=0.01] Iter 24300: loss=0.8552\n",
      "[SGD | lr=0.01] Epoch 1519/4000: train_loss=0.8506  test_loss=2.2877  λ_max=66.4698\n",
      "[SGD | lr=0.01] Epoch 1520/4000: train_loss=0.8511  test_loss=2.2872  λ_max=69.7112\n",
      "[SGD | lr=0.01] Epoch 1521/4000: train_loss=0.8476  test_loss=2.2871  λ_max=65.3412\n",
      "[SGD | lr=0.01] Epoch 1522/4000: train_loss=0.8494  test_loss=2.2862  λ_max=67.5578\n",
      "[SGD | lr=0.01] Epoch 1523/4000: train_loss=0.8479  test_loss=2.2870  λ_max=69.2635\n",
      "[SGD | lr=0.01] Epoch 1524/4000: train_loss=0.8458  test_loss=2.2869  λ_max=68.2778\n",
      "[SGD | lr=0.01] Iter 24400: loss=0.8391\n",
      "[SGD | lr=0.01] Epoch 1525/4000: train_loss=0.8465  test_loss=2.2878  λ_max=63.6661\n",
      "[SGD | lr=0.01] Epoch 1526/4000: train_loss=0.8446  test_loss=2.2900  λ_max=70.7088\n",
      "[SGD | lr=0.01] Epoch 1527/4000: train_loss=0.8466  test_loss=2.2899  λ_max=67.7517\n",
      "[SGD | lr=0.01] Epoch 1528/4000: train_loss=0.8436  test_loss=2.2901  λ_max=67.7759\n",
      "[SGD | lr=0.01] Epoch 1529/4000: train_loss=0.8472  test_loss=2.2893  λ_max=69.9029\n",
      "[SGD | lr=0.01] Epoch 1530/4000: train_loss=0.8393  test_loss=2.2884  λ_max=61.9363\n",
      "[SGD | lr=0.01] Epoch 1531/4000: train_loss=0.8394  test_loss=2.2888  λ_max=65.7870\n",
      "[SGD | lr=0.01] Iter 24500: loss=0.8419\n",
      "[SGD | lr=0.01] Epoch 1532/4000: train_loss=0.8428  test_loss=2.2891  λ_max=67.2791\n",
      "[SGD | lr=0.01] Epoch 1533/4000: train_loss=0.8396  test_loss=2.2901  λ_max=67.6070\n",
      "[SGD | lr=0.01] Epoch 1534/4000: train_loss=0.8409  test_loss=2.2912  λ_max=64.4713\n",
      "[SGD | lr=0.01] Epoch 1535/4000: train_loss=0.8407  test_loss=2.2913  λ_max=66.3995\n",
      "[SGD | lr=0.01] Epoch 1536/4000: train_loss=0.8398  test_loss=2.2917  λ_max=64.6175\n",
      "[SGD | lr=0.01] Epoch 1537/4000: train_loss=0.8397  test_loss=2.2928  λ_max=65.1274\n",
      "[SGD | lr=0.01] Iter 24600: loss=0.8420\n",
      "[SGD | lr=0.01] Epoch 1538/4000: train_loss=0.8407  test_loss=2.2928  λ_max=68.0398\n",
      "[SGD | lr=0.01] Epoch 1539/4000: train_loss=0.8371  test_loss=2.2923  λ_max=65.2634\n",
      "[SGD | lr=0.01] Epoch 1540/4000: train_loss=0.8364  test_loss=2.2932  λ_max=68.0765\n",
      "[SGD | lr=0.01] Epoch 1541/4000: train_loss=0.8361  test_loss=2.2935  λ_max=65.5194\n",
      "[SGD | lr=0.01] Epoch 1542/4000: train_loss=0.8376  test_loss=2.2936  λ_max=68.8452\n",
      "[SGD | lr=0.01] Epoch 1543/4000: train_loss=0.8343  test_loss=2.2955  λ_max=70.0560\n",
      "[SGD | lr=0.01] Iter 24700: loss=0.8331\n",
      "[SGD | lr=0.01] Epoch 1544/4000: train_loss=0.8349  test_loss=2.2943  λ_max=65.4412\n",
      "[SGD | lr=0.01] Epoch 1545/4000: train_loss=0.8347  test_loss=2.2933  λ_max=63.9527\n",
      "[SGD | lr=0.01] Epoch 1546/4000: train_loss=0.8351  test_loss=2.2940  λ_max=65.7281\n",
      "[SGD | lr=0.01] Epoch 1547/4000: train_loss=0.8326  test_loss=2.2958  λ_max=65.6339\n",
      "[SGD | lr=0.01] Epoch 1548/4000: train_loss=0.8322  test_loss=2.2973  λ_max=69.4839\n",
      "[SGD | lr=0.01] Epoch 1549/4000: train_loss=0.8303  test_loss=2.2961  λ_max=67.4363\n",
      "[SGD | lr=0.01] Iter 24800: loss=0.8398\n",
      "[SGD | lr=0.01] Epoch 1550/4000: train_loss=0.8307  test_loss=2.2975  λ_max=67.8391\n",
      "[SGD | lr=0.01] Epoch 1551/4000: train_loss=0.8289  test_loss=2.2962  λ_max=62.8376\n",
      "[SGD | lr=0.01] Epoch 1552/4000: train_loss=0.8268  test_loss=2.2957  λ_max=70.2097\n",
      "[SGD | lr=0.01] Epoch 1553/4000: train_loss=0.8257  test_loss=2.2958  λ_max=68.0027\n",
      "[SGD | lr=0.01] Epoch 1554/4000: train_loss=0.8299  test_loss=2.2974  λ_max=66.3907\n",
      "[SGD | lr=0.01] Epoch 1555/4000: train_loss=0.8327  test_loss=2.2991  λ_max=66.3189\n",
      "[SGD | lr=0.01] Epoch 1556/4000: train_loss=0.8285  test_loss=2.2980  λ_max=66.5842\n",
      "[SGD | lr=0.01] Iter 24900: loss=0.8227\n",
      "[SGD | lr=0.01] Epoch 1557/4000: train_loss=0.8279  test_loss=2.2987  λ_max=65.8183\n",
      "[SGD | lr=0.01] Epoch 1558/4000: train_loss=0.8301  test_loss=2.2985  λ_max=63.7170\n",
      "[SGD | lr=0.01] Epoch 1559/4000: train_loss=0.8258  test_loss=2.2980  λ_max=63.3281\n",
      "[SGD | lr=0.01] Epoch 1560/4000: train_loss=0.8232  test_loss=2.2981  λ_max=64.9954\n",
      "[SGD | lr=0.01] Epoch 1561/4000: train_loss=0.8232  test_loss=2.2991  λ_max=69.7079\n",
      "[SGD | lr=0.01] Epoch 1562/4000: train_loss=0.8236  test_loss=2.2998  λ_max=68.7245\n",
      "[SGD | lr=0.01] Iter 25000: loss=0.8251\n",
      "[SGD | lr=0.01] Epoch 1563/4000: train_loss=0.8232  test_loss=2.3002  λ_max=65.2016\n",
      "[SGD | lr=0.01] Epoch 1564/4000: train_loss=0.8250  test_loss=2.3004  λ_max=66.5048\n",
      "[SGD | lr=0.01] Epoch 1565/4000: train_loss=0.8212  test_loss=2.3004  λ_max=64.7391\n",
      "[SGD | lr=0.01] Epoch 1566/4000: train_loss=0.8233  test_loss=2.3009  λ_max=68.5002\n",
      "[SGD | lr=0.01] Epoch 1567/4000: train_loss=0.8214  test_loss=2.3019  λ_max=67.4428\n",
      "[SGD | lr=0.01] Epoch 1568/4000: train_loss=0.8195  test_loss=2.3015  λ_max=66.3130\n",
      "[SGD | lr=0.01] Iter 25100: loss=0.8131\n",
      "[SGD | lr=0.01] Epoch 1569/4000: train_loss=0.8180  test_loss=2.3031  λ_max=65.9127\n",
      "[SGD | lr=0.01] Epoch 1570/4000: train_loss=0.8210  test_loss=2.3045  λ_max=69.8545\n",
      "[SGD | lr=0.01] Epoch 1571/4000: train_loss=0.8214  test_loss=2.3053  λ_max=65.3962\n",
      "[SGD | lr=0.01] Epoch 1572/4000: train_loss=0.8231  test_loss=2.3043  λ_max=68.7265\n",
      "[SGD | lr=0.01] Epoch 1573/4000: train_loss=0.8179  test_loss=2.3040  λ_max=67.5980\n",
      "[SGD | lr=0.01] Epoch 1574/4000: train_loss=0.8147  test_loss=2.3035  λ_max=70.5568\n",
      "[SGD | lr=0.01] Iter 25200: loss=0.8185\n",
      "[SGD | lr=0.01] Epoch 1575/4000: train_loss=0.8158  test_loss=2.3050  λ_max=67.4168\n",
      "[SGD | lr=0.01] Epoch 1576/4000: train_loss=0.8181  test_loss=2.3047  λ_max=65.4605\n",
      "[SGD | lr=0.01] Epoch 1577/4000: train_loss=0.8131  test_loss=2.3062  λ_max=66.9122\n",
      "[SGD | lr=0.01] Epoch 1578/4000: train_loss=0.8149  test_loss=2.3063  λ_max=66.5033\n",
      "[SGD | lr=0.01] Epoch 1579/4000: train_loss=0.8143  test_loss=2.3062  λ_max=70.8042\n",
      "[SGD | lr=0.01] Epoch 1580/4000: train_loss=0.8139  test_loss=2.3075  λ_max=71.1185\n",
      "[SGD | lr=0.01] Epoch 1581/4000: train_loss=0.8154  test_loss=2.3085  λ_max=70.1730\n",
      "[SGD | lr=0.01] Iter 25300: loss=0.8046\n",
      "[SGD | lr=0.01] Epoch 1582/4000: train_loss=0.8113  test_loss=2.3094  λ_max=69.8418\n",
      "[SGD | lr=0.01] Epoch 1583/4000: train_loss=0.8157  test_loss=2.3099  λ_max=69.5355\n",
      "[SGD | lr=0.01] Epoch 1584/4000: train_loss=0.8149  test_loss=2.3108  λ_max=68.2847\n",
      "[SGD | lr=0.01] Epoch 1585/4000: train_loss=0.8144  test_loss=2.3070  λ_max=66.2524\n",
      "[SGD | lr=0.01] Epoch 1586/4000: train_loss=0.8090  test_loss=2.3068  λ_max=67.1502\n",
      "[SGD | lr=0.01] Epoch 1587/4000: train_loss=0.8095  test_loss=2.3069  λ_max=68.0041\n",
      "[SGD | lr=0.01] Iter 25400: loss=0.8175\n",
      "[SGD | lr=0.01] Epoch 1588/4000: train_loss=0.8125  test_loss=2.3074  λ_max=67.3845\n",
      "[SGD | lr=0.01] Epoch 1589/4000: train_loss=0.8075  test_loss=2.3089  λ_max=67.9321\n",
      "[SGD | lr=0.01] Epoch 1590/4000: train_loss=0.8097  test_loss=2.3094  λ_max=71.4810\n",
      "[SGD | lr=0.01] Epoch 1591/4000: train_loss=0.8066  test_loss=2.3097  λ_max=65.5159\n",
      "[SGD | lr=0.01] Epoch 1592/4000: train_loss=0.8028  test_loss=2.3102  λ_max=70.4335\n",
      "[SGD | lr=0.01] Epoch 1593/4000: train_loss=0.8033  test_loss=2.3115  λ_max=65.8430\n",
      "[SGD | lr=0.01] Iter 25500: loss=0.8046\n",
      "[SGD | lr=0.01] Epoch 1594/4000: train_loss=0.8041  test_loss=2.3121  λ_max=74.1045\n",
      "[SGD | lr=0.01] Epoch 1595/4000: train_loss=0.8064  test_loss=2.3115  λ_max=69.3477\n",
      "[SGD | lr=0.01] Epoch 1596/4000: train_loss=0.8026  test_loss=2.3106  λ_max=70.1232\n",
      "[SGD | lr=0.01] Epoch 1597/4000: train_loss=0.8046  test_loss=2.3122  λ_max=68.9463\n",
      "[SGD | lr=0.01] Epoch 1598/4000: train_loss=0.8040  test_loss=2.3121  λ_max=67.8563\n",
      "[SGD | lr=0.01] Epoch 1599/4000: train_loss=0.8028  test_loss=2.3133  λ_max=67.9111\n",
      "[SGD | lr=0.01] Iter 25600: loss=0.8025\n",
      "[SGD | lr=0.01] Epoch 1600/4000: train_loss=0.8013  test_loss=2.3126  λ_max=67.6091\n",
      "[SGD | lr=0.01] Epoch 1601/4000: train_loss=0.8009  test_loss=2.3122  λ_max=66.5629\n",
      "[SGD | lr=0.01] Epoch 1602/4000: train_loss=0.8010  test_loss=2.3127  λ_max=69.8875\n",
      "[SGD | lr=0.01] Epoch 1603/4000: train_loss=0.8006  test_loss=2.3138  λ_max=67.5585\n",
      "[SGD | lr=0.01] Epoch 1604/4000: train_loss=0.7993  test_loss=2.3145  λ_max=68.9865\n",
      "[SGD | lr=0.01] Epoch 1605/4000: train_loss=0.8027  test_loss=2.3163  λ_max=65.3057\n",
      "[SGD | lr=0.01] Epoch 1606/4000: train_loss=0.7997  test_loss=2.3155  λ_max=69.7236\n",
      "[SGD | lr=0.01] Iter 25700: loss=0.8071\n",
      "[SGD | lr=0.01] Epoch 1607/4000: train_loss=0.8003  test_loss=2.3169  λ_max=70.2153\n",
      "[SGD | lr=0.01] Epoch 1608/4000: train_loss=0.7961  test_loss=2.3149  λ_max=67.1879\n",
      "[SGD | lr=0.01] Epoch 1609/4000: train_loss=0.7979  test_loss=2.3159  λ_max=70.0209\n",
      "[SGD | lr=0.01] Epoch 1610/4000: train_loss=0.7983  test_loss=2.3148  λ_max=70.8378\n",
      "[SGD | lr=0.01] Epoch 1611/4000: train_loss=0.7922  test_loss=2.3152  λ_max=68.8903\n",
      "[SGD | lr=0.01] Epoch 1612/4000: train_loss=0.7930  test_loss=2.3166  λ_max=69.7557\n",
      "[SGD | lr=0.01] Iter 25800: loss=0.7916\n",
      "[SGD | lr=0.01] Epoch 1613/4000: train_loss=0.7940  test_loss=2.3172  λ_max=69.2174\n",
      "[SGD | lr=0.01] Epoch 1614/4000: train_loss=0.7958  test_loss=2.3212  λ_max=72.4230\n",
      "[SGD | lr=0.01] Epoch 1615/4000: train_loss=0.7972  test_loss=2.3201  λ_max=73.1865\n",
      "[SGD | lr=0.01] Epoch 1616/4000: train_loss=0.7915  test_loss=2.3190  λ_max=72.6253\n",
      "[SGD | lr=0.01] Epoch 1617/4000: train_loss=0.7917  test_loss=2.3193  λ_max=64.6976\n",
      "[SGD | lr=0.01] Epoch 1618/4000: train_loss=0.7904  test_loss=2.3183  λ_max=66.0997\n",
      "[SGD | lr=0.01] Iter 25900: loss=0.8011\n",
      "[SGD | lr=0.01] Epoch 1619/4000: train_loss=0.7914  test_loss=2.3184  λ_max=67.5152\n",
      "[SGD | lr=0.01] Epoch 1620/4000: train_loss=0.7919  test_loss=2.3186  λ_max=66.0424\n",
      "[SGD | lr=0.01] Epoch 1621/4000: train_loss=0.7874  test_loss=2.3205  λ_max=65.6707\n",
      "[SGD | lr=0.01] Epoch 1622/4000: train_loss=0.7933  test_loss=2.3203  λ_max=69.2260\n",
      "[SGD | lr=0.01] Epoch 1623/4000: train_loss=0.7883  test_loss=2.3209  λ_max=68.3169\n",
      "[SGD | lr=0.01] Epoch 1624/4000: train_loss=0.7904  test_loss=2.3208  λ_max=66.9431\n",
      "[SGD | lr=0.01] Iter 26000: loss=0.7848\n",
      "[SGD | lr=0.01] Epoch 1625/4000: train_loss=0.7884  test_loss=2.3207  λ_max=69.7395\n",
      "[SGD | lr=0.01] Epoch 1626/4000: train_loss=0.7900  test_loss=2.3212  λ_max=69.1495\n",
      "[SGD | lr=0.01] Epoch 1627/4000: train_loss=0.7883  test_loss=2.3217  λ_max=69.7076\n",
      "[SGD | lr=0.01] Epoch 1628/4000: train_loss=0.7860  test_loss=2.3212  λ_max=68.1448\n",
      "[SGD | lr=0.01] Epoch 1629/4000: train_loss=0.7854  test_loss=2.3223  λ_max=68.8164\n",
      "[SGD | lr=0.01] Epoch 1630/4000: train_loss=0.7855  test_loss=2.3228  λ_max=68.0886\n",
      "[SGD | lr=0.01] Epoch 1631/4000: train_loss=0.7847  test_loss=2.3237  λ_max=69.1128\n",
      "[SGD | lr=0.01] Iter 26100: loss=0.7836\n",
      "[SGD | lr=0.01] Epoch 1632/4000: train_loss=0.7831  test_loss=2.3227  λ_max=69.0159\n",
      "[SGD | lr=0.01] Epoch 1633/4000: train_loss=0.7820  test_loss=2.3237  λ_max=67.1640\n",
      "[SGD | lr=0.01] Epoch 1634/4000: train_loss=0.7828  test_loss=2.3237  λ_max=70.5794\n",
      "[SGD | lr=0.01] Epoch 1635/4000: train_loss=0.7824  test_loss=2.3228  λ_max=70.3468\n",
      "[SGD | lr=0.01] Epoch 1636/4000: train_loss=0.7849  test_loss=2.3246  λ_max=69.6740\n",
      "[SGD | lr=0.01] Epoch 1637/4000: train_loss=0.7855  test_loss=2.3267  λ_max=68.6367\n",
      "[SGD | lr=0.01] Iter 26200: loss=0.7735\n",
      "[SGD | lr=0.01] Epoch 1638/4000: train_loss=0.7801  test_loss=2.3245  λ_max=66.5416\n",
      "[SGD | lr=0.01] Epoch 1639/4000: train_loss=0.7780  test_loss=2.3247  λ_max=66.0684\n",
      "[SGD | lr=0.01] Epoch 1640/4000: train_loss=0.7783  test_loss=2.3251  λ_max=67.7204\n",
      "[SGD | lr=0.01] Epoch 1641/4000: train_loss=0.7767  test_loss=2.3266  λ_max=66.1241\n",
      "[SGD | lr=0.01] Epoch 1642/4000: train_loss=0.7785  test_loss=2.3271  λ_max=68.4473\n",
      "[SGD | lr=0.01] Epoch 1643/4000: train_loss=0.7789  test_loss=2.3288  λ_max=68.9046\n",
      "[SGD | lr=0.01] Iter 26300: loss=0.7831\n",
      "[SGD | lr=0.01] Epoch 1644/4000: train_loss=0.7776  test_loss=2.3272  λ_max=66.5182\n",
      "[SGD | lr=0.01] Epoch 1645/4000: train_loss=0.7760  test_loss=2.3286  λ_max=67.7393\n",
      "[SGD | lr=0.01] Epoch 1646/4000: train_loss=0.7797  test_loss=2.3279  λ_max=67.4466\n",
      "[SGD | lr=0.01] Epoch 1647/4000: train_loss=0.7749  test_loss=2.3279  λ_max=67.1886\n",
      "[SGD | lr=0.01] Epoch 1648/4000: train_loss=0.7757  test_loss=2.3287  λ_max=68.4796\n",
      "[SGD | lr=0.01] Epoch 1649/4000: train_loss=0.7770  test_loss=2.3286  λ_max=67.6694\n",
      "[SGD | lr=0.01] Iter 26400: loss=0.7669\n",
      "[SGD | lr=0.01] Epoch 1650/4000: train_loss=0.7709  test_loss=2.3279  λ_max=67.9356\n",
      "[SGD | lr=0.01] Epoch 1651/4000: train_loss=0.7733  test_loss=2.3299  λ_max=66.6173\n",
      "[SGD | lr=0.01] Epoch 1652/4000: train_loss=0.7740  test_loss=2.3301  λ_max=69.3882\n",
      "[SGD | lr=0.01] Epoch 1653/4000: train_loss=0.7714  test_loss=2.3303  λ_max=69.7510\n",
      "[SGD | lr=0.01] Epoch 1654/4000: train_loss=0.7696  test_loss=2.3307  λ_max=67.9529\n",
      "[SGD | lr=0.01] Epoch 1655/4000: train_loss=0.7718  test_loss=2.3319  λ_max=70.3875\n",
      "[SGD | lr=0.01] Epoch 1656/4000: train_loss=0.7740  test_loss=2.3321  λ_max=67.6870\n",
      "[SGD | lr=0.01] Iter 26500: loss=0.7802\n",
      "[SGD | lr=0.01] Epoch 1657/4000: train_loss=0.7735  test_loss=2.3326  λ_max=70.2309\n",
      "[SGD | lr=0.01] Epoch 1658/4000: train_loss=0.7722  test_loss=2.3314  λ_max=70.0813\n",
      "[SGD | lr=0.01] Epoch 1659/4000: train_loss=0.7671  test_loss=2.3305  λ_max=69.3279\n",
      "[SGD | lr=0.01] Epoch 1660/4000: train_loss=0.7680  test_loss=2.3314  λ_max=67.7316\n",
      "[SGD | lr=0.01] Epoch 1661/4000: train_loss=0.7691  test_loss=2.3342  λ_max=69.3762\n",
      "[SGD | lr=0.01] Epoch 1662/4000: train_loss=0.7655  test_loss=2.3341  λ_max=67.9081\n",
      "[SGD | lr=0.01] Iter 26600: loss=0.7715\n",
      "[SGD | lr=0.01] Epoch 1663/4000: train_loss=0.7657  test_loss=2.3340  λ_max=69.7773\n",
      "[SGD | lr=0.01] Epoch 1664/4000: train_loss=0.7674  test_loss=2.3361  λ_max=67.0031\n",
      "[SGD | lr=0.01] Epoch 1665/4000: train_loss=0.7645  test_loss=2.3372  λ_max=71.3212\n",
      "[SGD | lr=0.01] Epoch 1666/4000: train_loss=0.7666  test_loss=2.3392  λ_max=69.2397\n",
      "[SGD | lr=0.01] Epoch 1667/4000: train_loss=0.7683  test_loss=2.3393  λ_max=67.2467\n",
      "[SGD | lr=0.01] Epoch 1668/4000: train_loss=0.7638  test_loss=2.3380  λ_max=67.6415\n",
      "[SGD | lr=0.01] Iter 26700: loss=0.7510\n",
      "[SGD | lr=0.01] Epoch 1669/4000: train_loss=0.7636  test_loss=2.3381  λ_max=71.3465\n",
      "[SGD | lr=0.01] Epoch 1670/4000: train_loss=0.7633  test_loss=2.3398  λ_max=70.4374\n",
      "[SGD | lr=0.01] Epoch 1671/4000: train_loss=0.7658  test_loss=2.3381  λ_max=68.8083\n",
      "[SGD | lr=0.01] Epoch 1672/4000: train_loss=0.7588  test_loss=2.3393  λ_max=67.0993\n",
      "[SGD | lr=0.01] Epoch 1673/4000: train_loss=0.7631  test_loss=2.3419  λ_max=70.2429\n",
      "[SGD | lr=0.01] Epoch 1674/4000: train_loss=0.7632  test_loss=2.3393  λ_max=65.3545\n",
      "[SGD | lr=0.01] Iter 26800: loss=0.7599\n",
      "[SGD | lr=0.01] Epoch 1675/4000: train_loss=0.7591  test_loss=2.3383  λ_max=73.4489\n",
      "[SGD | lr=0.01] Epoch 1676/4000: train_loss=0.7638  test_loss=2.3385  λ_max=68.1707\n",
      "[SGD | lr=0.01] Epoch 1677/4000: train_loss=0.7588  test_loss=2.3387  λ_max=72.7664\n",
      "[SGD | lr=0.01] Epoch 1678/4000: train_loss=0.7591  test_loss=2.3393  λ_max=71.6432\n",
      "[SGD | lr=0.01] Epoch 1679/4000: train_loss=0.7591  test_loss=2.3397  λ_max=64.8605\n",
      "[SGD | lr=0.01] Epoch 1680/4000: train_loss=0.7569  test_loss=2.3396  λ_max=66.6951\n",
      "[SGD | lr=0.01] Epoch 1681/4000: train_loss=0.7548  test_loss=2.3407  λ_max=67.8608\n",
      "[SGD | lr=0.01] Iter 26900: loss=0.7694\n",
      "[SGD | lr=0.01] Epoch 1682/4000: train_loss=0.7566  test_loss=2.3398  λ_max=68.6402\n",
      "[SGD | lr=0.01] Epoch 1683/4000: train_loss=0.7537  test_loss=2.3393  λ_max=72.7904\n",
      "[SGD | lr=0.01] Epoch 1684/4000: train_loss=0.7532  test_loss=2.3394  λ_max=72.2852\n",
      "[SGD | lr=0.01] Epoch 1685/4000: train_loss=0.7523  test_loss=2.3413  λ_max=70.6840\n",
      "[SGD | lr=0.01] Epoch 1686/4000: train_loss=0.7549  test_loss=2.3416  λ_max=72.2008\n",
      "[SGD | lr=0.01] Epoch 1687/4000: train_loss=0.7539  test_loss=2.3430  λ_max=72.5754\n",
      "[SGD | lr=0.01] Iter 27000: loss=0.7587\n",
      "[SGD | lr=0.01] Epoch 1688/4000: train_loss=0.7524  test_loss=2.3424  λ_max=69.7740\n",
      "[SGD | lr=0.01] Epoch 1689/4000: train_loss=0.7529  test_loss=2.3428  λ_max=70.0110\n",
      "[SGD | lr=0.01] Epoch 1690/4000: train_loss=0.7542  test_loss=2.3442  λ_max=71.7320\n",
      "[SGD | lr=0.01] Epoch 1691/4000: train_loss=0.7554  test_loss=2.3456  λ_max=67.9766\n",
      "[SGD | lr=0.01] Epoch 1692/4000: train_loss=0.7536  test_loss=2.3451  λ_max=66.9132\n",
      "[SGD | lr=0.01] Epoch 1693/4000: train_loss=0.7544  test_loss=2.3454  λ_max=72.0462\n",
      "[SGD | lr=0.01] Iter 27100: loss=0.7573\n",
      "[SGD | lr=0.01] Epoch 1694/4000: train_loss=0.7480  test_loss=2.3436  λ_max=67.9406\n",
      "[SGD | lr=0.01] Epoch 1695/4000: train_loss=0.7493  test_loss=2.3428  λ_max=69.7379\n",
      "[SGD | lr=0.01] Epoch 1696/4000: train_loss=0.7492  test_loss=2.3434  λ_max=69.8724\n",
      "[SGD | lr=0.01] Epoch 1697/4000: train_loss=0.7488  test_loss=2.3442  λ_max=68.0067\n",
      "[SGD | lr=0.01] Epoch 1698/4000: train_loss=0.7485  test_loss=2.3465  λ_max=71.8876\n",
      "[SGD | lr=0.01] Epoch 1699/4000: train_loss=0.7510  test_loss=2.3461  λ_max=68.1665\n",
      "[SGD | lr=0.01] Iter 27200: loss=0.7468\n",
      "[SGD | lr=0.01] Epoch 1700/4000: train_loss=0.7467  test_loss=2.3469  λ_max=70.9581\n",
      "[SGD | lr=0.01] Epoch 1701/4000: train_loss=0.7486  test_loss=2.3459  λ_max=69.3938\n",
      "[SGD | lr=0.01] Epoch 1702/4000: train_loss=0.7458  test_loss=2.3465  λ_max=72.2368\n",
      "[SGD | lr=0.01] Epoch 1703/4000: train_loss=0.7455  test_loss=2.3457  λ_max=72.0193\n",
      "[SGD | lr=0.01] Epoch 1704/4000: train_loss=0.7401  test_loss=2.3458  λ_max=71.4335\n",
      "[SGD | lr=0.01] Epoch 1705/4000: train_loss=0.7412  test_loss=2.3478  λ_max=68.8024\n",
      "[SGD | lr=0.01] Epoch 1706/4000: train_loss=0.7478  test_loss=2.3498  λ_max=69.6127\n",
      "[SGD | lr=0.01] Iter 27300: loss=0.7387\n",
      "[SGD | lr=0.01] Epoch 1707/4000: train_loss=0.7423  test_loss=2.3493  λ_max=68.4374\n",
      "[SGD | lr=0.01] Epoch 1708/4000: train_loss=0.7417  test_loss=2.3512  λ_max=73.5373\n",
      "[SGD | lr=0.01] Epoch 1709/4000: train_loss=0.7454  test_loss=2.3508  λ_max=66.3936\n",
      "[SGD | lr=0.01] Epoch 1710/4000: train_loss=0.7431  test_loss=2.3505  λ_max=66.0737\n",
      "[SGD | lr=0.01] Epoch 1711/4000: train_loss=0.7390  test_loss=2.3503  λ_max=69.1091\n",
      "[SGD | lr=0.01] Epoch 1712/4000: train_loss=0.7414  test_loss=2.3522  λ_max=68.8625\n",
      "[SGD | lr=0.01] Iter 27400: loss=0.7498\n",
      "[SGD | lr=0.01] Epoch 1713/4000: train_loss=0.7449  test_loss=2.3524  λ_max=70.4840\n",
      "[SGD | lr=0.01] Epoch 1714/4000: train_loss=0.7414  test_loss=2.3518  λ_max=72.6594\n",
      "[SGD | lr=0.01] Epoch 1715/4000: train_loss=0.7394  test_loss=2.3512  λ_max=67.9882\n",
      "[SGD | lr=0.01] Epoch 1716/4000: train_loss=0.7364  test_loss=2.3502  λ_max=71.1205\n",
      "[SGD | lr=0.01] Epoch 1717/4000: train_loss=0.7366  test_loss=2.3512  λ_max=71.4710\n",
      "[SGD | lr=0.01] Epoch 1718/4000: train_loss=0.7361  test_loss=2.3526  λ_max=69.7468\n",
      "[SGD | lr=0.01] Iter 27500: loss=0.7375\n",
      "[SGD | lr=0.01] Epoch 1719/4000: train_loss=0.7379  test_loss=2.3554  λ_max=71.8458\n",
      "[SGD | lr=0.01] Epoch 1720/4000: train_loss=0.7369  test_loss=2.3528  λ_max=71.3364\n",
      "[SGD | lr=0.01] Epoch 1721/4000: train_loss=0.7345  test_loss=2.3537  λ_max=70.7794\n",
      "[SGD | lr=0.01] Epoch 1722/4000: train_loss=0.7350  test_loss=2.3550  λ_max=73.2215\n",
      "[SGD | lr=0.01] Epoch 1723/4000: train_loss=0.7363  test_loss=2.3550  λ_max=67.9937\n",
      "[SGD | lr=0.01] Epoch 1724/4000: train_loss=0.7303  test_loss=2.3552  λ_max=69.9870\n",
      "[SGD | lr=0.01] Iter 27600: loss=0.7308\n",
      "[SGD | lr=0.01] Epoch 1725/4000: train_loss=0.7337  test_loss=2.3560  λ_max=71.5696\n",
      "[SGD | lr=0.01] Epoch 1726/4000: train_loss=0.7345  test_loss=2.3579  λ_max=72.7983\n",
      "[SGD | lr=0.01] Epoch 1727/4000: train_loss=0.7347  test_loss=2.3569  λ_max=72.6700\n",
      "[SGD | lr=0.01] Epoch 1728/4000: train_loss=0.7325  test_loss=2.3564  λ_max=69.3535\n",
      "[SGD | lr=0.01] Epoch 1729/4000: train_loss=0.7327  test_loss=2.3579  λ_max=71.5877\n",
      "[SGD | lr=0.01] Epoch 1730/4000: train_loss=0.7367  test_loss=2.3601  λ_max=73.2223\n",
      "[SGD | lr=0.01] Epoch 1731/4000: train_loss=0.7300  test_loss=2.3578  λ_max=75.9568\n",
      "[SGD | lr=0.01] Iter 27700: loss=0.7349\n",
      "[SGD | lr=0.01] Epoch 1732/4000: train_loss=0.7306  test_loss=2.3593  λ_max=72.3605\n",
      "[SGD | lr=0.01] Epoch 1733/4000: train_loss=0.7283  test_loss=2.3580  λ_max=70.2266\n",
      "[SGD | lr=0.01] Epoch 1734/4000: train_loss=0.7262  test_loss=2.3586  λ_max=74.0985\n",
      "[SGD | lr=0.01] Epoch 1735/4000: train_loss=0.7321  test_loss=2.3588  λ_max=69.1845\n",
      "[SGD | lr=0.01] Epoch 1736/4000: train_loss=0.7292  test_loss=2.3586  λ_max=71.7523\n",
      "[SGD | lr=0.01] Epoch 1737/4000: train_loss=0.7238  test_loss=2.3572  λ_max=69.9461\n",
      "[SGD | lr=0.01] Iter 27800: loss=0.7240\n",
      "[SGD | lr=0.01] Epoch 1738/4000: train_loss=0.7225  test_loss=2.3586  λ_max=72.6086\n",
      "[SGD | lr=0.01] Epoch 1739/4000: train_loss=0.7263  test_loss=2.3578  λ_max=70.6558\n",
      "[SGD | lr=0.01] Epoch 1740/4000: train_loss=0.7275  test_loss=2.3581  λ_max=72.5599\n",
      "[SGD | lr=0.01] Epoch 1741/4000: train_loss=0.7240  test_loss=2.3592  λ_max=72.4688\n",
      "[SGD | lr=0.01] Epoch 1742/4000: train_loss=0.7269  test_loss=2.3596  λ_max=72.5247\n",
      "[SGD | lr=0.01] Epoch 1743/4000: train_loss=0.7222  test_loss=2.3596  λ_max=71.1065\n",
      "[SGD | lr=0.01] Iter 27900: loss=0.7160\n",
      "[SGD | lr=0.01] Epoch 1744/4000: train_loss=0.7234  test_loss=2.3611  λ_max=75.0766\n",
      "[SGD | lr=0.01] Epoch 1745/4000: train_loss=0.7248  test_loss=2.3613  λ_max=72.8025\n",
      "[SGD | lr=0.01] Epoch 1746/4000: train_loss=0.7249  test_loss=2.3609  λ_max=73.9371\n",
      "[SGD | lr=0.01] Epoch 1747/4000: train_loss=0.7252  test_loss=2.3617  λ_max=69.8173\n",
      "[SGD | lr=0.01] Epoch 1748/4000: train_loss=0.7193  test_loss=2.3636  λ_max=75.1905\n",
      "[SGD | lr=0.01] Epoch 1749/4000: train_loss=0.7177  test_loss=2.3637  λ_max=66.1383\n",
      "[SGD | lr=0.01] Iter 28000: loss=0.7154\n",
      "[SGD | lr=0.01] Epoch 1750/4000: train_loss=0.7187  test_loss=2.3651  λ_max=72.8055\n",
      "[SGD | lr=0.01] Epoch 1751/4000: train_loss=0.7209  test_loss=2.3675  λ_max=72.4372\n",
      "[SGD | lr=0.01] Epoch 1752/4000: train_loss=0.7235  test_loss=2.3669  λ_max=71.0346\n",
      "[SGD | lr=0.01] Epoch 1753/4000: train_loss=0.7237  test_loss=2.3668  λ_max=71.0758\n",
      "[SGD | lr=0.01] Epoch 1754/4000: train_loss=0.7195  test_loss=2.3664  λ_max=75.2242\n",
      "[SGD | lr=0.01] Epoch 1755/4000: train_loss=0.7160  test_loss=2.3677  λ_max=75.4986\n",
      "[SGD | lr=0.01] Epoch 1756/4000: train_loss=0.7194  test_loss=2.3673  λ_max=68.0538\n",
      "[SGD | lr=0.01] Iter 28100: loss=0.7256\n",
      "[SGD | lr=0.01] Epoch 1757/4000: train_loss=0.7164  test_loss=2.3671  λ_max=69.6989\n",
      "[SGD | lr=0.01] Epoch 1758/4000: train_loss=0.7179  test_loss=2.3668  λ_max=71.1537\n",
      "[SGD | lr=0.01] Epoch 1759/4000: train_loss=0.7175  test_loss=2.3675  λ_max=75.9825\n",
      "[SGD | lr=0.01] Epoch 1760/4000: train_loss=0.7172  test_loss=2.3690  λ_max=74.3460\n",
      "[SGD | lr=0.01] Epoch 1761/4000: train_loss=0.7130  test_loss=2.3679  λ_max=70.5271\n",
      "[SGD | lr=0.01] Epoch 1762/4000: train_loss=0.7129  test_loss=2.3684  λ_max=70.5674\n",
      "[SGD | lr=0.01] Iter 28200: loss=0.7095\n",
      "[SGD | lr=0.01] Epoch 1763/4000: train_loss=0.7128  test_loss=2.3697  λ_max=73.0487\n",
      "[SGD | lr=0.01] Epoch 1764/4000: train_loss=0.7133  test_loss=2.3693  λ_max=68.7219\n",
      "[SGD | lr=0.01] Epoch 1765/4000: train_loss=0.7127  test_loss=2.3691  λ_max=70.5298\n",
      "[SGD | lr=0.01] Epoch 1766/4000: train_loss=0.7119  test_loss=2.3689  λ_max=70.5134\n",
      "[SGD | lr=0.01] Epoch 1767/4000: train_loss=0.7159  test_loss=2.3707  λ_max=70.3039\n",
      "[SGD | lr=0.01] Epoch 1768/4000: train_loss=0.7113  test_loss=2.3708  λ_max=74.1378\n",
      "[SGD | lr=0.01] Iter 28300: loss=0.7044\n",
      "[SGD | lr=0.01] Epoch 1769/4000: train_loss=0.7094  test_loss=2.3700  λ_max=70.4936\n",
      "[SGD | lr=0.01] Epoch 1770/4000: train_loss=0.7126  test_loss=2.3733  λ_max=73.1094\n",
      "[SGD | lr=0.01] Epoch 1771/4000: train_loss=0.7156  test_loss=2.3730  λ_max=72.3487\n",
      "[SGD | lr=0.01] Epoch 1772/4000: train_loss=0.7150  test_loss=2.3725  λ_max=72.0708\n",
      "[SGD | lr=0.01] Epoch 1773/4000: train_loss=0.7060  test_loss=2.3708  λ_max=71.6958\n",
      "[SGD | lr=0.01] Epoch 1774/4000: train_loss=0.7053  test_loss=2.3727  λ_max=69.5736\n",
      "[SGD | lr=0.01] Iter 28400: loss=0.7006\n",
      "[SGD | lr=0.01] Epoch 1775/4000: train_loss=0.7103  test_loss=2.3743  λ_max=75.1186\n",
      "[SGD | lr=0.01] Epoch 1776/4000: train_loss=0.7071  test_loss=2.3735  λ_max=69.1046\n",
      "[SGD | lr=0.01] Epoch 1777/4000: train_loss=0.7058  test_loss=2.3740  λ_max=73.1290\n",
      "[SGD | lr=0.01] Epoch 1778/4000: train_loss=0.7043  test_loss=2.3729  λ_max=68.0113\n",
      "[SGD | lr=0.01] Epoch 1779/4000: train_loss=0.7040  test_loss=2.3722  λ_max=72.3148\n",
      "[SGD | lr=0.01] Epoch 1780/4000: train_loss=0.7052  test_loss=2.3737  λ_max=65.9966\n",
      "[SGD | lr=0.01] Epoch 1781/4000: train_loss=0.7046  test_loss=2.3732  λ_max=69.5812\n",
      "[SGD | lr=0.01] Iter 28500: loss=0.7011\n",
      "[SGD | lr=0.01] Epoch 1782/4000: train_loss=0.7030  test_loss=2.3751  λ_max=70.4744\n",
      "[SGD | lr=0.01] Epoch 1783/4000: train_loss=0.7045  test_loss=2.3749  λ_max=72.8956\n",
      "[SGD | lr=0.01] Epoch 1784/4000: train_loss=0.7034  test_loss=2.3755  λ_max=73.6647\n",
      "[SGD | lr=0.01] Epoch 1785/4000: train_loss=0.7050  test_loss=2.3743  λ_max=71.8524\n",
      "[SGD | lr=0.01] Epoch 1786/4000: train_loss=0.7072  test_loss=2.3753  λ_max=73.8796\n",
      "[SGD | lr=0.01] Epoch 1787/4000: train_loss=0.7030  test_loss=2.3766  λ_max=72.4315\n",
      "[SGD | lr=0.01] Iter 28600: loss=0.7038\n",
      "[SGD | lr=0.01] Epoch 1788/4000: train_loss=0.7005  test_loss=2.3757  λ_max=74.4765\n",
      "[SGD | lr=0.01] Epoch 1789/4000: train_loss=0.6972  test_loss=2.3770  λ_max=72.2059\n",
      "[SGD | lr=0.01] Epoch 1790/4000: train_loss=0.7029  test_loss=2.3779  λ_max=71.4653\n",
      "[SGD | lr=0.01] Epoch 1791/4000: train_loss=0.7008  test_loss=2.3775  λ_max=74.1809\n",
      "[SGD | lr=0.01] Epoch 1792/4000: train_loss=0.6972  test_loss=2.3778  λ_max=70.2379\n",
      "[SGD | lr=0.01] Epoch 1793/4000: train_loss=0.6951  test_loss=2.3798  λ_max=73.6640\n",
      "[SGD | lr=0.01] Iter 28700: loss=0.7015\n",
      "[SGD | lr=0.01] Epoch 1794/4000: train_loss=0.7027  test_loss=2.3811  λ_max=72.3235\n",
      "[SGD | lr=0.01] Epoch 1795/4000: train_loss=0.6995  test_loss=2.3809  λ_max=71.7722\n",
      "[SGD | lr=0.01] Epoch 1796/4000: train_loss=0.6996  test_loss=2.3807  λ_max=72.9908\n",
      "[SGD | lr=0.01] Epoch 1797/4000: train_loss=0.6982  test_loss=2.3825  λ_max=73.5390\n",
      "[SGD | lr=0.01] Epoch 1798/4000: train_loss=0.6978  test_loss=2.3795  λ_max=71.1513\n",
      "[SGD | lr=0.01] Epoch 1799/4000: train_loss=0.6923  test_loss=2.3791  λ_max=69.1712\n",
      "[SGD | lr=0.01] Iter 28800: loss=0.6901\n",
      "[SGD | lr=0.01] Epoch 1800/4000: train_loss=0.6965  test_loss=2.3793  λ_max=70.1537\n",
      "[SGD | lr=0.01] Epoch 1801/4000: train_loss=0.6920  test_loss=2.3803  λ_max=75.4699\n",
      "[SGD | lr=0.01] Epoch 1802/4000: train_loss=0.6930  test_loss=2.3825  λ_max=70.2207\n",
      "[SGD | lr=0.01] Epoch 1803/4000: train_loss=0.6966  test_loss=2.3834  λ_max=71.7758\n",
      "[SGD | lr=0.01] Epoch 1804/4000: train_loss=0.6945  test_loss=2.3820  λ_max=72.3841\n",
      "[SGD | lr=0.01] Epoch 1805/4000: train_loss=0.6917  test_loss=2.3829  λ_max=74.6493\n",
      "[SGD | lr=0.01] Epoch 1806/4000: train_loss=0.6928  test_loss=2.3842  λ_max=71.5810\n",
      "[SGD | lr=0.01] Iter 28900: loss=0.6897\n",
      "[SGD | lr=0.01] Epoch 1807/4000: train_loss=0.6931  test_loss=2.3837  λ_max=73.9081\n",
      "[SGD | lr=0.01] Epoch 1808/4000: train_loss=0.6897  test_loss=2.3839  λ_max=69.1572\n",
      "[SGD | lr=0.01] Epoch 1809/4000: train_loss=0.6895  test_loss=2.3854  λ_max=78.1511\n",
      "[SGD | lr=0.01] Epoch 1810/4000: train_loss=0.6939  test_loss=2.3831  λ_max=73.5504\n",
      "[SGD | lr=0.01] Epoch 1811/4000: train_loss=0.6900  test_loss=2.3841  λ_max=75.0882\n",
      "[SGD | lr=0.01] Epoch 1812/4000: train_loss=0.6929  test_loss=2.3848  λ_max=73.4441\n",
      "[SGD | lr=0.01] Iter 29000: loss=0.6942\n",
      "[SGD | lr=0.01] Epoch 1813/4000: train_loss=0.6934  test_loss=2.3833  λ_max=75.0310\n",
      "[SGD | lr=0.01] Epoch 1814/4000: train_loss=0.6880  test_loss=2.3851  λ_max=70.9413\n",
      "[SGD | lr=0.01] Epoch 1815/4000: train_loss=0.6859  test_loss=2.3863  λ_max=75.7730\n",
      "[SGD | lr=0.01] Epoch 1816/4000: train_loss=0.6909  test_loss=2.3878  λ_max=75.8152\n",
      "[SGD | lr=0.01] Epoch 1817/4000: train_loss=0.6859  test_loss=2.3876  λ_max=74.8795\n",
      "[SGD | lr=0.01] Epoch 1818/4000: train_loss=0.6868  test_loss=2.3874  λ_max=75.8365\n",
      "[SGD | lr=0.01] Iter 29100: loss=0.6997\n",
      "[SGD | lr=0.01] Epoch 1819/4000: train_loss=0.6848  test_loss=2.3862  λ_max=73.3402\n",
      "[SGD | lr=0.01] Epoch 1820/4000: train_loss=0.6868  test_loss=2.3874  λ_max=70.9829\n",
      "[SGD | lr=0.01] Epoch 1821/4000: train_loss=0.6808  test_loss=2.3890  λ_max=72.3157\n",
      "[SGD | lr=0.01] Epoch 1822/4000: train_loss=0.6875  test_loss=2.3900  λ_max=73.6630\n",
      "[SGD | lr=0.01] Epoch 1823/4000: train_loss=0.6867  test_loss=2.3885  λ_max=72.1105\n",
      "[SGD | lr=0.01] Epoch 1824/4000: train_loss=0.6793  test_loss=2.3873  λ_max=75.1396\n",
      "[SGD | lr=0.01] Iter 29200: loss=0.6877\n",
      "[SGD | lr=0.01] Epoch 1825/4000: train_loss=0.6802  test_loss=2.3872  λ_max=74.7695\n",
      "[SGD | lr=0.01] Epoch 1826/4000: train_loss=0.6852  test_loss=2.3903  λ_max=76.2689\n",
      "[SGD | lr=0.01] Epoch 1827/4000: train_loss=0.6832  test_loss=2.3931  λ_max=76.9065\n",
      "[SGD | lr=0.01] Epoch 1828/4000: train_loss=0.6838  test_loss=2.3938  λ_max=68.9460\n",
      "[SGD | lr=0.01] Epoch 1829/4000: train_loss=0.6804  test_loss=2.3933  λ_max=74.1867\n",
      "[SGD | lr=0.01] Epoch 1830/4000: train_loss=0.6834  test_loss=2.3931  λ_max=69.8431\n",
      "[SGD | lr=0.01] Epoch 1831/4000: train_loss=0.6796  test_loss=2.3904  λ_max=73.7371\n",
      "[SGD | lr=0.01] Iter 29300: loss=0.6755\n",
      "[SGD | lr=0.01] Epoch 1832/4000: train_loss=0.6770  test_loss=2.3908  λ_max=72.3408\n",
      "[SGD | lr=0.01] Epoch 1833/4000: train_loss=0.6802  test_loss=2.3940  λ_max=72.0469\n",
      "[SGD | lr=0.01] Epoch 1834/4000: train_loss=0.6816  test_loss=2.3963  λ_max=68.4710\n",
      "[SGD | lr=0.01] Epoch 1835/4000: train_loss=0.6806  test_loss=2.3944  λ_max=73.3120\n",
      "[SGD | lr=0.01] Epoch 1836/4000: train_loss=0.6721  test_loss=2.3932  λ_max=71.7324\n",
      "[SGD | lr=0.01] Epoch 1837/4000: train_loss=0.6697  test_loss=2.3929  λ_max=71.8470\n",
      "[SGD | lr=0.01] Iter 29400: loss=0.6691\n",
      "[SGD | lr=0.01] Epoch 1838/4000: train_loss=0.6708  test_loss=2.3952  λ_max=71.0980\n",
      "[SGD | lr=0.01] Epoch 1839/4000: train_loss=0.6767  test_loss=2.3997  λ_max=76.8316\n",
      "[SGD | lr=0.01] Epoch 1840/4000: train_loss=0.6805  test_loss=2.4004  λ_max=71.8501\n",
      "[SGD | lr=0.01] Epoch 1841/4000: train_loss=0.6796  test_loss=2.3970  λ_max=72.5897\n",
      "[SGD | lr=0.01] Epoch 1842/4000: train_loss=0.6710  test_loss=2.3943  λ_max=72.4357\n",
      "[SGD | lr=0.01] Epoch 1843/4000: train_loss=0.6743  test_loss=2.3940  λ_max=74.9403\n",
      "[SGD | lr=0.01] Iter 29500: loss=0.6736\n",
      "[SGD | lr=0.01] Epoch 1844/4000: train_loss=0.6728  test_loss=2.3949  λ_max=75.1481\n",
      "[SGD | lr=0.01] Epoch 1845/4000: train_loss=0.6698  test_loss=2.3971  λ_max=73.1287\n",
      "[SGD | lr=0.01] Epoch 1846/4000: train_loss=0.6756  test_loss=2.3976  λ_max=71.8164\n",
      "[SGD | lr=0.01] Epoch 1847/4000: train_loss=0.6779  test_loss=2.4003  λ_max=72.1760\n",
      "[SGD | lr=0.01] Epoch 1848/4000: train_loss=0.6772  test_loss=2.3995  λ_max=74.4864\n",
      "[SGD | lr=0.01] Epoch 1849/4000: train_loss=0.6667  test_loss=2.3991  λ_max=74.9577\n",
      "[SGD | lr=0.01] Iter 29600: loss=0.6616\n",
      "[SGD | lr=0.01] Epoch 1850/4000: train_loss=0.6695  test_loss=2.4002  λ_max=73.2936\n",
      "[SGD | lr=0.01] Epoch 1851/4000: train_loss=0.6720  test_loss=2.4006  λ_max=75.0011\n",
      "[SGD | lr=0.01] Epoch 1852/4000: train_loss=0.6700  test_loss=2.3993  λ_max=75.8907\n",
      "[SGD | lr=0.01] Epoch 1853/4000: train_loss=0.6646  test_loss=2.3980  λ_max=74.9357\n",
      "[SGD | lr=0.01] Epoch 1854/4000: train_loss=0.6694  test_loss=2.4008  λ_max=74.8768\n",
      "[SGD | lr=0.01] Epoch 1855/4000: train_loss=0.6669  test_loss=2.4015  λ_max=77.0403\n",
      "[SGD | lr=0.01] Epoch 1856/4000: train_loss=0.6690  test_loss=2.4016  λ_max=73.8018\n",
      "[SGD | lr=0.01] Iter 29700: loss=0.6653\n",
      "[SGD | lr=0.01] Epoch 1857/4000: train_loss=0.6694  test_loss=2.4008  λ_max=76.2236\n",
      "[SGD | lr=0.01] Epoch 1858/4000: train_loss=0.6653  test_loss=2.4020  λ_max=70.8518\n",
      "[SGD | lr=0.01] Epoch 1859/4000: train_loss=0.6661  test_loss=2.4037  λ_max=72.2833\n",
      "[SGD | lr=0.01] Epoch 1860/4000: train_loss=0.6690  test_loss=2.4036  λ_max=75.7492\n",
      "[SGD | lr=0.01] Epoch 1861/4000: train_loss=0.6698  test_loss=2.4019  λ_max=74.9606\n",
      "[SGD | lr=0.01] Epoch 1862/4000: train_loss=0.6639  test_loss=2.4027  λ_max=74.9024\n",
      "[SGD | lr=0.01] Iter 29800: loss=0.6602\n",
      "[SGD | lr=0.01] Epoch 1863/4000: train_loss=0.6663  test_loss=2.4038  λ_max=73.3419\n",
      "[SGD | lr=0.01] Epoch 1864/4000: train_loss=0.6693  test_loss=2.4050  λ_max=72.5179\n",
      "[SGD | lr=0.01] Epoch 1865/4000: train_loss=0.6660  test_loss=2.4044  λ_max=74.6284\n",
      "[SGD | lr=0.01] Epoch 1866/4000: train_loss=0.6627  test_loss=2.4068  λ_max=75.7463\n",
      "[SGD | lr=0.01] Epoch 1867/4000: train_loss=0.6654  test_loss=2.4069  λ_max=69.0449\n",
      "[SGD | lr=0.01] Epoch 1868/4000: train_loss=0.6578  test_loss=2.4065  λ_max=75.8825\n",
      "[SGD | lr=0.01] Iter 29900: loss=0.6613\n",
      "[SGD | lr=0.01] Epoch 1869/4000: train_loss=0.6590  test_loss=2.4099  λ_max=70.4791\n",
      "[SGD | lr=0.01] Epoch 1870/4000: train_loss=0.6669  test_loss=2.4097  λ_max=71.4762\n",
      "[SGD | lr=0.01] Epoch 1871/4000: train_loss=0.6631  test_loss=2.4061  λ_max=71.4510\n",
      "[SGD | lr=0.01] Epoch 1872/4000: train_loss=0.6659  test_loss=2.4082  λ_max=76.6361\n",
      "[SGD | lr=0.01] Epoch 1873/4000: train_loss=0.6678  test_loss=2.4096  λ_max=75.9833\n",
      "[SGD | lr=0.01] Epoch 1874/4000: train_loss=0.6649  test_loss=2.4095  λ_max=72.6030\n",
      "[SGD | lr=0.01] Iter 30000: loss=0.6511\n",
      "[SGD | lr=0.01] Epoch 1875/4000: train_loss=0.6610  test_loss=2.4091  λ_max=73.2709\n",
      "[SGD | lr=0.01] Epoch 1876/4000: train_loss=0.6522  test_loss=2.4085  λ_max=73.1273\n",
      "[SGD | lr=0.01] Epoch 1877/4000: train_loss=0.6513  test_loss=2.4085  λ_max=75.5863\n",
      "[SGD | lr=0.01] Epoch 1878/4000: train_loss=0.6563  test_loss=2.4091  λ_max=75.6719\n",
      "[SGD | lr=0.01] Epoch 1879/4000: train_loss=0.6582  test_loss=2.4094  λ_max=73.9114\n",
      "[SGD | lr=0.01] Epoch 1880/4000: train_loss=0.6608  test_loss=2.4090  λ_max=76.0582\n",
      "[SGD | lr=0.01] Epoch 1881/4000: train_loss=0.6571  test_loss=2.4088  λ_max=72.6081\n",
      "[SGD | lr=0.01] Iter 30100: loss=0.6500\n",
      "[SGD | lr=0.01] Epoch 1882/4000: train_loss=0.6566  test_loss=2.4115  λ_max=75.0464\n",
      "[SGD | lr=0.01] Epoch 1883/4000: train_loss=0.6558  test_loss=2.4121  λ_max=71.3706\n",
      "[SGD | lr=0.01] Epoch 1884/4000: train_loss=0.6550  test_loss=2.4143  λ_max=72.7843\n",
      "[SGD | lr=0.01] Epoch 1885/4000: train_loss=0.6547  test_loss=2.4137  λ_max=70.5171\n",
      "[SGD | lr=0.01] Epoch 1886/4000: train_loss=0.6529  test_loss=2.4129  λ_max=74.2296\n",
      "[SGD | lr=0.01] Epoch 1887/4000: train_loss=0.6525  test_loss=2.4129  λ_max=76.5501\n",
      "[SGD | lr=0.01] Iter 30200: loss=0.6566\n",
      "[SGD | lr=0.01] Epoch 1888/4000: train_loss=0.6526  test_loss=2.4124  λ_max=73.3973\n",
      "[SGD | lr=0.01] Epoch 1889/4000: train_loss=0.6483  test_loss=2.4122  λ_max=71.7604\n",
      "[SGD | lr=0.01] Epoch 1890/4000: train_loss=0.6521  test_loss=2.4155  λ_max=68.7075\n",
      "[SGD | lr=0.01] Epoch 1891/4000: train_loss=0.6542  test_loss=2.4145  λ_max=73.9177\n",
      "[SGD | lr=0.01] Epoch 1892/4000: train_loss=0.6495  test_loss=2.4153  λ_max=75.5361\n",
      "[SGD | lr=0.01] Epoch 1893/4000: train_loss=0.6481  test_loss=2.4159  λ_max=78.9811\n",
      "[SGD | lr=0.01] Iter 30300: loss=0.6522\n",
      "[SGD | lr=0.01] Epoch 1894/4000: train_loss=0.6522  test_loss=2.4168  λ_max=77.9003\n",
      "[SGD | lr=0.01] Epoch 1895/4000: train_loss=0.6497  test_loss=2.4155  λ_max=71.4473\n",
      "[SGD | lr=0.01] Epoch 1896/4000: train_loss=0.6458  test_loss=2.4161  λ_max=75.6457\n",
      "[SGD | lr=0.01] Epoch 1897/4000: train_loss=0.6520  test_loss=2.4188  λ_max=76.7975\n",
      "[SGD | lr=0.01] Epoch 1898/4000: train_loss=0.6524  test_loss=2.4205  λ_max=74.4608\n",
      "[SGD | lr=0.01] Epoch 1899/4000: train_loss=0.6518  test_loss=2.4179  λ_max=74.1503\n",
      "[SGD | lr=0.01] Iter 30400: loss=0.6348\n",
      "[SGD | lr=0.01] Epoch 1900/4000: train_loss=0.6456  test_loss=2.4166  λ_max=76.4672\n",
      "[SGD | lr=0.01] Epoch 1901/4000: train_loss=0.6464  test_loss=2.4181  λ_max=73.0436\n",
      "[SGD | lr=0.01] Epoch 1902/4000: train_loss=0.6475  test_loss=2.4179  λ_max=70.8036\n",
      "[SGD | lr=0.01] Epoch 1903/4000: train_loss=0.6445  test_loss=2.4183  λ_max=74.5638\n",
      "[SGD | lr=0.01] Epoch 1904/4000: train_loss=0.6481  test_loss=2.4197  λ_max=71.6040\n",
      "[SGD | lr=0.01] Epoch 1905/4000: train_loss=0.6486  test_loss=2.4184  λ_max=73.8095\n",
      "[SGD | lr=0.01] Epoch 1906/4000: train_loss=0.6421  test_loss=2.4193  λ_max=73.7807\n",
      "[SGD | lr=0.01] Iter 30500: loss=0.6452\n",
      "[SGD | lr=0.01] Epoch 1907/4000: train_loss=0.6406  test_loss=2.4200  λ_max=71.6973\n",
      "[SGD | lr=0.01] Epoch 1908/4000: train_loss=0.6427  test_loss=2.4245  λ_max=75.5030\n",
      "[SGD | lr=0.01] Epoch 1909/4000: train_loss=0.6508  test_loss=2.4279  λ_max=74.4721\n",
      "[SGD | lr=0.01] Epoch 1910/4000: train_loss=0.6486  test_loss=2.4255  λ_max=73.2380\n",
      "[SGD | lr=0.01] Epoch 1911/4000: train_loss=0.6460  test_loss=2.4237  λ_max=77.2639\n",
      "[SGD | lr=0.01] Epoch 1912/4000: train_loss=0.6435  test_loss=2.4230  λ_max=77.5328\n",
      "[SGD | lr=0.01] Iter 30600: loss=0.6340\n",
      "[SGD | lr=0.01] Epoch 1913/4000: train_loss=0.6403  test_loss=2.4212  λ_max=72.7592\n",
      "[SGD | lr=0.01] Epoch 1914/4000: train_loss=0.6413  test_loss=2.4245  λ_max=77.0136\n",
      "[SGD | lr=0.01] Epoch 1915/4000: train_loss=0.6412  test_loss=2.4257  λ_max=76.8174\n",
      "[SGD | lr=0.01] Epoch 1916/4000: train_loss=0.6404  test_loss=2.4237  λ_max=71.5009\n",
      "[SGD | lr=0.01] Epoch 1917/4000: train_loss=0.6334  test_loss=2.4214  λ_max=70.4740\n",
      "[SGD | lr=0.01] Epoch 1918/4000: train_loss=0.6345  test_loss=2.4236  λ_max=75.0629\n",
      "[SGD | lr=0.01] Iter 30700: loss=0.6386\n",
      "[SGD | lr=0.01] Epoch 1919/4000: train_loss=0.6372  test_loss=2.4241  λ_max=71.2188\n",
      "[SGD | lr=0.01] Epoch 1920/4000: train_loss=0.6388  test_loss=2.4244  λ_max=73.8193\n",
      "[SGD | lr=0.01] Epoch 1921/4000: train_loss=0.6379  test_loss=2.4235  λ_max=76.6427\n",
      "[SGD | lr=0.01] Epoch 1922/4000: train_loss=0.6365  test_loss=2.4252  λ_max=77.2882\n",
      "[SGD | lr=0.01] Epoch 1923/4000: train_loss=0.6458  test_loss=2.4255  λ_max=73.1541\n",
      "[SGD | lr=0.01] Epoch 1924/4000: train_loss=0.6382  test_loss=2.4259  λ_max=75.2163\n",
      "[SGD | lr=0.01] Iter 30800: loss=0.6404\n",
      "[SGD | lr=0.01] Epoch 1925/4000: train_loss=0.6354  test_loss=2.4247  λ_max=77.0789\n",
      "[SGD | lr=0.01] Epoch 1926/4000: train_loss=0.6407  test_loss=2.4266  λ_max=73.0717\n",
      "[SGD | lr=0.01] Epoch 1927/4000: train_loss=0.6398  test_loss=2.4272  λ_max=77.0060\n",
      "[SGD | lr=0.01] Epoch 1928/4000: train_loss=0.6366  test_loss=2.4289  λ_max=74.4016\n",
      "[SGD | lr=0.01] Epoch 1929/4000: train_loss=0.6322  test_loss=2.4289  λ_max=77.8426\n",
      "[SGD | lr=0.01] Epoch 1930/4000: train_loss=0.6315  test_loss=2.4279  λ_max=74.1830\n",
      "[SGD | lr=0.01] Epoch 1931/4000: train_loss=0.6329  test_loss=2.4304  λ_max=71.1762\n",
      "[SGD | lr=0.01] Iter 30900: loss=0.6324\n",
      "[SGD | lr=0.01] Epoch 1932/4000: train_loss=0.6308  test_loss=2.4304  λ_max=75.1901\n",
      "[SGD | lr=0.01] Epoch 1933/4000: train_loss=0.6336  test_loss=2.4334  λ_max=75.5803\n",
      "[SGD | lr=0.01] Epoch 1934/4000: train_loss=0.6307  test_loss=2.4304  λ_max=76.5490\n",
      "[SGD | lr=0.01] Epoch 1935/4000: train_loss=0.6332  test_loss=2.4298  λ_max=78.3144\n",
      "[SGD | lr=0.01] Epoch 1936/4000: train_loss=0.6344  test_loss=2.4306  λ_max=77.3771\n",
      "[SGD | lr=0.01] Epoch 1937/4000: train_loss=0.6325  test_loss=2.4304  λ_max=76.9489\n",
      "[SGD | lr=0.01] Iter 31000: loss=0.6286\n",
      "[SGD | lr=0.01] Epoch 1938/4000: train_loss=0.6294  test_loss=2.4303  λ_max=77.1623\n",
      "[SGD | lr=0.01] Epoch 1939/4000: train_loss=0.6335  test_loss=2.4325  λ_max=74.5262\n",
      "[SGD | lr=0.01] Epoch 1940/4000: train_loss=0.6283  test_loss=2.4337  λ_max=73.9751\n",
      "[SGD | lr=0.01] Epoch 1941/4000: train_loss=0.6316  test_loss=2.4319  λ_max=72.2069\n",
      "[SGD | lr=0.01] Epoch 1942/4000: train_loss=0.6240  test_loss=2.4334  λ_max=72.4184\n",
      "[SGD | lr=0.01] Epoch 1943/4000: train_loss=0.6237  test_loss=2.4328  λ_max=77.0452\n",
      "[SGD | lr=0.01] Iter 31100: loss=0.6250\n",
      "[SGD | lr=0.01] Epoch 1944/4000: train_loss=0.6275  test_loss=2.4334  λ_max=77.5117\n",
      "[SGD | lr=0.01] Epoch 1945/4000: train_loss=0.6303  test_loss=2.4339  λ_max=75.8557\n",
      "[SGD | lr=0.01] Epoch 1946/4000: train_loss=0.6286  test_loss=2.4348  λ_max=76.2430\n",
      "[SGD | lr=0.01] Epoch 1947/4000: train_loss=0.6278  test_loss=2.4363  λ_max=72.7419\n",
      "[SGD | lr=0.01] Epoch 1948/4000: train_loss=0.6250  test_loss=2.4367  λ_max=74.8397\n",
      "[SGD | lr=0.01] Epoch 1949/4000: train_loss=0.6289  test_loss=2.4354  λ_max=75.5272\n",
      "[SGD | lr=0.01] Iter 31200: loss=0.6230\n",
      "[SGD | lr=0.01] Epoch 1950/4000: train_loss=0.6271  test_loss=2.4353  λ_max=74.3293\n",
      "[SGD | lr=0.01] Epoch 1951/4000: train_loss=0.6257  test_loss=2.4346  λ_max=72.7076\n",
      "[SGD | lr=0.01] Epoch 1952/4000: train_loss=0.6239  test_loss=2.4354  λ_max=71.4900\n",
      "[SGD | lr=0.01] Epoch 1953/4000: train_loss=0.6252  test_loss=2.4361  λ_max=75.2855\n",
      "[SGD | lr=0.01] Epoch 1954/4000: train_loss=0.6303  test_loss=2.4370  λ_max=70.6240\n",
      "[SGD | lr=0.01] Epoch 1955/4000: train_loss=0.6208  test_loss=2.4357  λ_max=74.6945\n",
      "[SGD | lr=0.01] Epoch 1956/4000: train_loss=0.6155  test_loss=2.4366  λ_max=76.9264\n",
      "[SGD | lr=0.01] Iter 31300: loss=0.6168\n",
      "[SGD | lr=0.01] Epoch 1957/4000: train_loss=0.6186  test_loss=2.4380  λ_max=74.2642\n",
      "[SGD | lr=0.01] Epoch 1958/4000: train_loss=0.6221  test_loss=2.4397  λ_max=76.0694\n",
      "[SGD | lr=0.01] Epoch 1959/4000: train_loss=0.6230  test_loss=2.4391  λ_max=74.8571\n",
      "[SGD | lr=0.01] Epoch 1960/4000: train_loss=0.6204  test_loss=2.4388  λ_max=74.7884\n",
      "[SGD | lr=0.01] Epoch 1961/4000: train_loss=0.6153  test_loss=2.4381  λ_max=75.3832\n",
      "[SGD | lr=0.01] Epoch 1962/4000: train_loss=0.6131  test_loss=2.4382  λ_max=77.6654\n",
      "[SGD | lr=0.01] Iter 31400: loss=0.6232\n",
      "[SGD | lr=0.01] Epoch 1963/4000: train_loss=0.6157  test_loss=2.4391  λ_max=77.0214\n",
      "[SGD | lr=0.01] Epoch 1964/4000: train_loss=0.6197  test_loss=2.4413  λ_max=75.6717\n",
      "[SGD | lr=0.01] Epoch 1965/4000: train_loss=0.6206  test_loss=2.4419  λ_max=76.1328\n",
      "[SGD | lr=0.01] Epoch 1966/4000: train_loss=0.6205  test_loss=2.4435  λ_max=73.9410\n",
      "[SGD | lr=0.01] Epoch 1967/4000: train_loss=0.6174  test_loss=2.4460  λ_max=75.6506\n",
      "[SGD | lr=0.01] Epoch 1968/4000: train_loss=0.6153  test_loss=2.4449  λ_max=75.8770\n",
      "[SGD | lr=0.01] Iter 31500: loss=0.6200\n",
      "[SGD | lr=0.01] Epoch 1969/4000: train_loss=0.6155  test_loss=2.4460  λ_max=75.5875\n",
      "[SGD | lr=0.01] Epoch 1970/4000: train_loss=0.6177  test_loss=2.4458  λ_max=74.0849\n",
      "[SGD | lr=0.01] Epoch 1971/4000: train_loss=0.6176  test_loss=2.4414  λ_max=74.3488\n",
      "[SGD | lr=0.01] Epoch 1972/4000: train_loss=0.6209  test_loss=2.4417  λ_max=74.3882\n",
      "[SGD | lr=0.01] Epoch 1973/4000: train_loss=0.6145  test_loss=2.4409  λ_max=73.2905\n",
      "[SGD | lr=0.01] Epoch 1974/4000: train_loss=0.6168  test_loss=2.4422  λ_max=72.5187\n",
      "[SGD | lr=0.01] Iter 31600: loss=0.6137\n",
      "[SGD | lr=0.01] Epoch 1975/4000: train_loss=0.6163  test_loss=2.4428  λ_max=79.4232\n",
      "[SGD | lr=0.01] Epoch 1976/4000: train_loss=0.6159  test_loss=2.4442  λ_max=74.3317\n",
      "[SGD | lr=0.01] Epoch 1977/4000: train_loss=0.6100  test_loss=2.4442  λ_max=78.3645\n",
      "[SGD | lr=0.01] Epoch 1978/4000: train_loss=0.6104  test_loss=2.4465  λ_max=77.7098\n",
      "[SGD | lr=0.01] Epoch 1979/4000: train_loss=0.6174  test_loss=2.4479  λ_max=74.1307\n",
      "[SGD | lr=0.01] Epoch 1980/4000: train_loss=0.6169  test_loss=2.4476  λ_max=75.4367\n",
      "[SGD | lr=0.01] Epoch 1981/4000: train_loss=0.6064  test_loss=2.4464  λ_max=79.2856\n",
      "[SGD | lr=0.01] Iter 31700: loss=0.6156\n",
      "[SGD | lr=0.01] Epoch 1982/4000: train_loss=0.6038  test_loss=2.4465  λ_max=74.6888\n",
      "[SGD | lr=0.01] Epoch 1983/4000: train_loss=0.6020  test_loss=2.4475  λ_max=76.0130\n",
      "[SGD | lr=0.01] Epoch 1984/4000: train_loss=0.6061  test_loss=2.4513  λ_max=78.1886\n",
      "[SGD | lr=0.01] Epoch 1985/4000: train_loss=0.6146  test_loss=2.4539  λ_max=73.3987\n",
      "[SGD | lr=0.01] Epoch 1986/4000: train_loss=0.6194  test_loss=2.4519  λ_max=75.9334\n",
      "[SGD | lr=0.01] Epoch 1987/4000: train_loss=0.6086  test_loss=2.4504  λ_max=73.9457\n",
      "[SGD | lr=0.01] Iter 31800: loss=0.5984\n",
      "[SGD | lr=0.01] Epoch 1988/4000: train_loss=0.6077  test_loss=2.4493  λ_max=72.8459\n",
      "[SGD | lr=0.01] Epoch 1989/4000: train_loss=0.6060  test_loss=2.4485  λ_max=77.1969\n",
      "[SGD | lr=0.01] Epoch 1990/4000: train_loss=0.6100  test_loss=2.4498  λ_max=77.4008\n",
      "[SGD | lr=0.01] Epoch 1991/4000: train_loss=0.6087  test_loss=2.4521  λ_max=76.6380\n",
      "[SGD | lr=0.01] Epoch 1992/4000: train_loss=0.6105  test_loss=2.4523  λ_max=75.4051\n",
      "[SGD | lr=0.01] Epoch 1993/4000: train_loss=0.6098  test_loss=2.4542  λ_max=76.8614\n",
      "[SGD | lr=0.01] Iter 31900: loss=0.6049\n",
      "[SGD | lr=0.01] Epoch 1994/4000: train_loss=0.6091  test_loss=2.4528  λ_max=77.9542\n",
      "[SGD | lr=0.01] Epoch 1995/4000: train_loss=0.6043  test_loss=2.4528  λ_max=76.4333\n",
      "[SGD | lr=0.01] Epoch 1996/4000: train_loss=0.6041  test_loss=2.4522  λ_max=74.2795\n",
      "[SGD | lr=0.01] Epoch 1997/4000: train_loss=0.6054  test_loss=2.4520  λ_max=72.8061\n",
      "[SGD | lr=0.01] Epoch 1998/4000: train_loss=0.6030  test_loss=2.4510  λ_max=78.5715\n",
      "[SGD | lr=0.01] Epoch 1999/4000: train_loss=0.6026  test_loss=2.4504  λ_max=73.7483\n",
      "[SGD | lr=0.01] Iter 32000: loss=0.6129\n",
      "[SGD | lr=0.01] Epoch 2000/4000: train_loss=0.6026  test_loss=2.4512  λ_max=75.0939\n",
      "[SGD | lr=0.01] Epoch 2001/4000: train_loss=0.6008  test_loss=2.4524  λ_max=75.9765\n",
      "[SGD | lr=0.01] Epoch 2002/4000: train_loss=0.6038  test_loss=2.4516  λ_max=75.3691\n",
      "[SGD | lr=0.01] Epoch 2003/4000: train_loss=0.6048  test_loss=2.4521  λ_max=77.0229\n",
      "[SGD | lr=0.01] Epoch 2004/4000: train_loss=0.6056  test_loss=2.4558  λ_max=75.4583\n",
      "[SGD | lr=0.01] Epoch 2005/4000: train_loss=0.6012  test_loss=2.4561  λ_max=76.0925\n",
      "[SGD | lr=0.01] Epoch 2006/4000: train_loss=0.6003  test_loss=2.4577  λ_max=76.0192\n",
      "[SGD | lr=0.01] Iter 32100: loss=0.5957\n",
      "[SGD | lr=0.01] Epoch 2007/4000: train_loss=0.5993  test_loss=2.4616  λ_max=76.4882\n",
      "[SGD | lr=0.01] Epoch 2008/4000: train_loss=0.6050  test_loss=2.4577  λ_max=73.9962\n",
      "[SGD | lr=0.01] Epoch 2009/4000: train_loss=0.5991  test_loss=2.4573  λ_max=76.7777\n",
      "[SGD | lr=0.01] Epoch 2010/4000: train_loss=0.6027  test_loss=2.4585  λ_max=73.5570\n",
      "[SGD | lr=0.01] Epoch 2011/4000: train_loss=0.6028  test_loss=2.4600  λ_max=73.5881\n",
      "[SGD | lr=0.01] Epoch 2012/4000: train_loss=0.6012  test_loss=2.4590  λ_max=79.4358\n",
      "[SGD | lr=0.01] Iter 32200: loss=0.6005\n",
      "[SGD | lr=0.01] Epoch 2013/4000: train_loss=0.6003  test_loss=2.4595  λ_max=78.0611\n",
      "[SGD | lr=0.01] Epoch 2014/4000: train_loss=0.5936  test_loss=2.4586  λ_max=76.2262\n",
      "[SGD | lr=0.01] Epoch 2015/4000: train_loss=0.5919  test_loss=2.4574  λ_max=76.0713\n",
      "[SGD | lr=0.01] Epoch 2016/4000: train_loss=0.5915  test_loss=2.4591  λ_max=77.2049\n",
      "[SGD | lr=0.01] Epoch 2017/4000: train_loss=0.5968  test_loss=2.4615  λ_max=73.4476\n",
      "[SGD | lr=0.01] Epoch 2018/4000: train_loss=0.6018  test_loss=2.4611  λ_max=76.9769\n",
      "[SGD | lr=0.01] Iter 32300: loss=0.5868\n",
      "[SGD | lr=0.01] Epoch 2019/4000: train_loss=0.5936  test_loss=2.4601  λ_max=74.6795\n",
      "[SGD | lr=0.01] Epoch 2020/4000: train_loss=0.5952  test_loss=2.4608  λ_max=73.1593\n",
      "[SGD | lr=0.01] Epoch 2021/4000: train_loss=0.5932  test_loss=2.4619  λ_max=76.2027\n",
      "[SGD | lr=0.01] Epoch 2022/4000: train_loss=0.5981  test_loss=2.4637  λ_max=81.3275\n",
      "[SGD | lr=0.01] Epoch 2023/4000: train_loss=0.5991  test_loss=2.4637  λ_max=75.0266\n",
      "[SGD | lr=0.01] Epoch 2024/4000: train_loss=0.5894  test_loss=2.4620  λ_max=79.8258\n",
      "[SGD | lr=0.01] Iter 32400: loss=0.5901\n",
      "[SGD | lr=0.01] Epoch 2025/4000: train_loss=0.5874  test_loss=2.4633  λ_max=76.9378\n",
      "[SGD | lr=0.01] Epoch 2026/4000: train_loss=0.5889  test_loss=2.4658  λ_max=74.7778\n",
      "[SGD | lr=0.01] Epoch 2027/4000: train_loss=0.5924  test_loss=2.4679  λ_max=77.5540\n",
      "[SGD | lr=0.01] Epoch 2028/4000: train_loss=0.5914  test_loss=2.4654  λ_max=76.2145\n",
      "[SGD | lr=0.01] Epoch 2029/4000: train_loss=0.5945  test_loss=2.4664  λ_max=73.6946\n",
      "[SGD | lr=0.01] Epoch 2030/4000: train_loss=0.5947  test_loss=2.4673  λ_max=76.4846\n",
      "[SGD | lr=0.01] Epoch 2031/4000: train_loss=0.5947  test_loss=2.4667  λ_max=78.1738\n",
      "[SGD | lr=0.01] Iter 32500: loss=0.5936\n",
      "[SGD | lr=0.01] Epoch 2032/4000: train_loss=0.5920  test_loss=2.4660  λ_max=78.5586\n",
      "[SGD | lr=0.01] Epoch 2033/4000: train_loss=0.5930  test_loss=2.4647  λ_max=78.6274\n",
      "[SGD | lr=0.01] Epoch 2034/4000: train_loss=0.5927  test_loss=2.4640  λ_max=79.5102\n",
      "[SGD | lr=0.01] Epoch 2035/4000: train_loss=0.5881  test_loss=2.4654  λ_max=79.2003\n",
      "[SGD | lr=0.01] Epoch 2036/4000: train_loss=0.5902  test_loss=2.4676  λ_max=73.3367\n",
      "[SGD | lr=0.01] Epoch 2037/4000: train_loss=0.5872  test_loss=2.4702  λ_max=73.2818\n",
      "[SGD | lr=0.01] Iter 32600: loss=0.5834\n",
      "[SGD | lr=0.01] Epoch 2038/4000: train_loss=0.5861  test_loss=2.4702  λ_max=77.6989\n",
      "[SGD | lr=0.01] Epoch 2039/4000: train_loss=0.5877  test_loss=2.4695  λ_max=77.7147\n",
      "[SGD | lr=0.01] Epoch 2040/4000: train_loss=0.5897  test_loss=2.4686  λ_max=76.3749\n",
      "[SGD | lr=0.01] Epoch 2041/4000: train_loss=0.5905  test_loss=2.4703  λ_max=78.7050\n",
      "[SGD | lr=0.01] Epoch 2042/4000: train_loss=0.5824  test_loss=2.4708  λ_max=75.5853\n",
      "[SGD | lr=0.01] Epoch 2043/4000: train_loss=0.5784  test_loss=2.4684  λ_max=78.9303\n",
      "[SGD | lr=0.01] Iter 32700: loss=0.5756\n",
      "[SGD | lr=0.01] Epoch 2044/4000: train_loss=0.5765  test_loss=2.4685  λ_max=75.9402\n",
      "[SGD | lr=0.01] Epoch 2045/4000: train_loss=0.5799  test_loss=2.4721  λ_max=76.8977\n",
      "[SGD | lr=0.01] Epoch 2046/4000: train_loss=0.5849  test_loss=2.4720  λ_max=76.1478\n",
      "[SGD | lr=0.01] Epoch 2047/4000: train_loss=0.5843  test_loss=2.4720  λ_max=77.0832\n",
      "[SGD | lr=0.01] Epoch 2048/4000: train_loss=0.5855  test_loss=2.4690  λ_max=77.1328\n",
      "[SGD | lr=0.01] Epoch 2049/4000: train_loss=0.5793  test_loss=2.4695  λ_max=76.6667\n",
      "[SGD | lr=0.01] Iter 32800: loss=0.5767\n",
      "[SGD | lr=0.01] Epoch 2050/4000: train_loss=0.5808  test_loss=2.4678  λ_max=77.9796\n",
      "[SGD | lr=0.01] Epoch 2051/4000: train_loss=0.5841  test_loss=2.4695  λ_max=73.8178\n",
      "[SGD | lr=0.01] Epoch 2052/4000: train_loss=0.5830  test_loss=2.4722  λ_max=75.0311\n",
      "[SGD | lr=0.01] Epoch 2053/4000: train_loss=0.5820  test_loss=2.4759  λ_max=75.3357\n",
      "[SGD | lr=0.01] Epoch 2054/4000: train_loss=0.5848  test_loss=2.4787  λ_max=80.5097\n",
      "[SGD | lr=0.01] Epoch 2055/4000: train_loss=0.5807  test_loss=2.4767  λ_max=74.1054\n",
      "[SGD | lr=0.01] Epoch 2056/4000: train_loss=0.5818  test_loss=2.4743  λ_max=80.1016\n",
      "[SGD | lr=0.01] Iter 32900: loss=0.5738\n",
      "[SGD | lr=0.01] Epoch 2057/4000: train_loss=0.5772  test_loss=2.4738  λ_max=75.8455\n",
      "[SGD | lr=0.01] Epoch 2058/4000: train_loss=0.5800  test_loss=2.4757  λ_max=80.4881\n",
      "[SGD | lr=0.01] Epoch 2059/4000: train_loss=0.5730  test_loss=2.4769  λ_max=79.9463\n",
      "[SGD | lr=0.01] Epoch 2060/4000: train_loss=0.5742  test_loss=2.4779  λ_max=77.1480\n",
      "[SGD | lr=0.01] Epoch 2061/4000: train_loss=0.5754  test_loss=2.4759  λ_max=77.7469\n",
      "[SGD | lr=0.01] Epoch 2062/4000: train_loss=0.5751  test_loss=2.4761  λ_max=74.2630\n",
      "[SGD | lr=0.01] Iter 33000: loss=0.5730\n",
      "[SGD | lr=0.01] Epoch 2063/4000: train_loss=0.5767  test_loss=2.4762  λ_max=76.7557\n",
      "[SGD | lr=0.01] Epoch 2064/4000: train_loss=0.5738  test_loss=2.4761  λ_max=77.7093\n",
      "[SGD | lr=0.01] Epoch 2065/4000: train_loss=0.5746  test_loss=2.4800  λ_max=77.0359\n",
      "[SGD | lr=0.01] Epoch 2066/4000: train_loss=0.5852  test_loss=2.4803  λ_max=80.1383\n",
      "[SGD | lr=0.01] Epoch 2067/4000: train_loss=0.5787  test_loss=2.4794  λ_max=75.4877\n",
      "[SGD | lr=0.01] Epoch 2068/4000: train_loss=0.5726  test_loss=2.4795  λ_max=74.9499\n",
      "[SGD | lr=0.01] Iter 33100: loss=0.5614\n",
      "[SGD | lr=0.01] Epoch 2069/4000: train_loss=0.5723  test_loss=2.4812  λ_max=79.9283\n",
      "[SGD | lr=0.01] Epoch 2070/4000: train_loss=0.5754  test_loss=2.4822  λ_max=79.6399\n",
      "[SGD | lr=0.01] Epoch 2071/4000: train_loss=0.5690  test_loss=2.4808  λ_max=80.7847\n",
      "[SGD | lr=0.01] Epoch 2072/4000: train_loss=0.5719  test_loss=2.4809  λ_max=76.1118\n",
      "[SGD | lr=0.01] Epoch 2073/4000: train_loss=0.5754  test_loss=2.4818  λ_max=76.9110\n",
      "[SGD | lr=0.01] Epoch 2074/4000: train_loss=0.5749  test_loss=2.4811  λ_max=78.3007\n",
      "[SGD | lr=0.01] Iter 33200: loss=0.5678\n",
      "[SGD | lr=0.01] Epoch 2075/4000: train_loss=0.5719  test_loss=2.4817  λ_max=76.9333\n",
      "[SGD | lr=0.01] Epoch 2076/4000: train_loss=0.5773  test_loss=2.4823  λ_max=77.8712\n",
      "[SGD | lr=0.01] Epoch 2077/4000: train_loss=0.5721  test_loss=2.4822  λ_max=79.5146\n",
      "[SGD | lr=0.01] Epoch 2078/4000: train_loss=0.5665  test_loss=2.4815  λ_max=75.1307\n",
      "[SGD | lr=0.01] Epoch 2079/4000: train_loss=0.5705  test_loss=2.4819  λ_max=79.4975\n",
      "[SGD | lr=0.01] Epoch 2080/4000: train_loss=0.5721  test_loss=2.4838  λ_max=76.3737\n",
      "[SGD | lr=0.01] Epoch 2081/4000: train_loss=0.5740  test_loss=2.4850  λ_max=79.8738\n",
      "[SGD | lr=0.01] Iter 33300: loss=0.5749\n",
      "[SGD | lr=0.01] Epoch 2082/4000: train_loss=0.5739  test_loss=2.4876  λ_max=79.6692\n",
      "[SGD | lr=0.01] Epoch 2083/4000: train_loss=0.5727  test_loss=2.4845  λ_max=81.4997\n",
      "[SGD | lr=0.01] Epoch 2084/4000: train_loss=0.5667  test_loss=2.4855  λ_max=78.9419\n",
      "[SGD | lr=0.01] Epoch 2085/4000: train_loss=0.5705  test_loss=2.4865  λ_max=77.7185\n",
      "[SGD | lr=0.01] Epoch 2086/4000: train_loss=0.5729  test_loss=2.4869  λ_max=75.7459\n",
      "[SGD | lr=0.01] Epoch 2087/4000: train_loss=0.5648  test_loss=2.4850  λ_max=76.5413\n",
      "[SGD | lr=0.01] Iter 33400: loss=0.5780\n",
      "[SGD | lr=0.01] Epoch 2088/4000: train_loss=0.5669  test_loss=2.4881  λ_max=77.5736\n",
      "[SGD | lr=0.01] Epoch 2089/4000: train_loss=0.5699  test_loss=2.4906  λ_max=80.4627\n",
      "[SGD | lr=0.01] Epoch 2090/4000: train_loss=0.5675  test_loss=2.4882  λ_max=75.2910\n",
      "[SGD | lr=0.01] Epoch 2091/4000: train_loss=0.5645  test_loss=2.4886  λ_max=77.4788\n",
      "[SGD | lr=0.01] Epoch 2092/4000: train_loss=0.5682  test_loss=2.4907  λ_max=74.5110\n",
      "[SGD | lr=0.01] Epoch 2093/4000: train_loss=0.5666  test_loss=2.4920  λ_max=78.2700\n",
      "[SGD | lr=0.01] Iter 33500: loss=0.5679\n",
      "[SGD | lr=0.01] Epoch 2094/4000: train_loss=0.5753  test_loss=2.4895  λ_max=80.5340\n",
      "[SGD | lr=0.01] Epoch 2095/4000: train_loss=0.5628  test_loss=2.4912  λ_max=74.1982\n",
      "[SGD | lr=0.01] Epoch 2096/4000: train_loss=0.5640  test_loss=2.4927  λ_max=76.6527\n",
      "[SGD | lr=0.01] Epoch 2097/4000: train_loss=0.5619  test_loss=2.4925  λ_max=79.1246\n",
      "[SGD | lr=0.01] Epoch 2098/4000: train_loss=0.5584  test_loss=2.4913  λ_max=76.2715\n",
      "[SGD | lr=0.01] Epoch 2099/4000: train_loss=0.5576  test_loss=2.4918  λ_max=76.1381\n",
      "[SGD | lr=0.01] Iter 33600: loss=0.5656\n",
      "[SGD | lr=0.01] Epoch 2100/4000: train_loss=0.5610  test_loss=2.4910  λ_max=76.4015\n",
      "[SGD | lr=0.01] Epoch 2101/4000: train_loss=0.5617  test_loss=2.4902  λ_max=73.6696\n",
      "[SGD | lr=0.01] Epoch 2102/4000: train_loss=0.5628  test_loss=2.4891  λ_max=78.0847\n",
      "[SGD | lr=0.01] Epoch 2103/4000: train_loss=0.5556  test_loss=2.4890  λ_max=78.2370\n",
      "[SGD | lr=0.01] Epoch 2104/4000: train_loss=0.5605  test_loss=2.4904  λ_max=78.3319\n",
      "[SGD | lr=0.01] Epoch 2105/4000: train_loss=0.5710  test_loss=2.4924  λ_max=77.2155\n",
      "[SGD | lr=0.01] Epoch 2106/4000: train_loss=0.5604  test_loss=2.4911  λ_max=72.6152\n",
      "[SGD | lr=0.01] Iter 33700: loss=0.5666\n",
      "[SGD | lr=0.01] Epoch 2107/4000: train_loss=0.5585  test_loss=2.4917  λ_max=80.4878\n",
      "[SGD | lr=0.01] Epoch 2108/4000: train_loss=0.5598  test_loss=2.4922  λ_max=82.2974\n",
      "[SGD | lr=0.01] Epoch 2109/4000: train_loss=0.5614  test_loss=2.4922  λ_max=81.3882\n",
      "[SGD | lr=0.01] Epoch 2110/4000: train_loss=0.5628  test_loss=2.4944  λ_max=76.0374\n",
      "[SGD | lr=0.01] Epoch 2111/4000: train_loss=0.5574  test_loss=2.4972  λ_max=80.0573\n",
      "[SGD | lr=0.01] Epoch 2112/4000: train_loss=0.5592  test_loss=2.4970  λ_max=75.4995\n",
      "[SGD | lr=0.01] Iter 33800: loss=0.5495\n",
      "[SGD | lr=0.01] Epoch 2113/4000: train_loss=0.5513  test_loss=2.4939  λ_max=76.5320\n",
      "[SGD | lr=0.01] Epoch 2114/4000: train_loss=0.5513  test_loss=2.4946  λ_max=77.3299\n",
      "[SGD | lr=0.01] Epoch 2115/4000: train_loss=0.5591  test_loss=2.4954  λ_max=76.5529\n",
      "[SGD | lr=0.01] Epoch 2116/4000: train_loss=0.5563  test_loss=2.4952  λ_max=78.5103\n",
      "[SGD | lr=0.01] Epoch 2117/4000: train_loss=0.5571  test_loss=2.4946  λ_max=76.9441\n",
      "[SGD | lr=0.01] Epoch 2118/4000: train_loss=0.5555  test_loss=2.4944  λ_max=75.9553\n",
      "[SGD | lr=0.01] Iter 33900: loss=0.5522\n",
      "[SGD | lr=0.01] Epoch 2119/4000: train_loss=0.5516  test_loss=2.4957  λ_max=78.8578\n",
      "[SGD | lr=0.01] Epoch 2120/4000: train_loss=0.5528  test_loss=2.4961  λ_max=80.4011\n",
      "[SGD | lr=0.01] Epoch 2121/4000: train_loss=0.5530  test_loss=2.4977  λ_max=78.4147\n",
      "[SGD | lr=0.01] Epoch 2122/4000: train_loss=0.5585  test_loss=2.4997  λ_max=79.5469\n",
      "[SGD | lr=0.01] Epoch 2123/4000: train_loss=0.5542  test_loss=2.4991  λ_max=78.1072\n",
      "[SGD | lr=0.01] Epoch 2124/4000: train_loss=0.5497  test_loss=2.5033  λ_max=76.5571\n",
      "[SGD | lr=0.01] Iter 34000: loss=0.5484\n",
      "[SGD | lr=0.01] Epoch 2125/4000: train_loss=0.5561  test_loss=2.5017  λ_max=78.1837\n",
      "[SGD | lr=0.01] Epoch 2126/4000: train_loss=0.5501  test_loss=2.5008  λ_max=79.6513\n",
      "[SGD | lr=0.01] Epoch 2127/4000: train_loss=0.5549  test_loss=2.5006  λ_max=77.5826\n",
      "[SGD | lr=0.01] Epoch 2128/4000: train_loss=0.5536  test_loss=2.5003  λ_max=73.9874\n",
      "[SGD | lr=0.01] Epoch 2129/4000: train_loss=0.5468  test_loss=2.5009  λ_max=76.6429\n",
      "[SGD | lr=0.01] Epoch 2130/4000: train_loss=0.5460  test_loss=2.5011  λ_max=77.7243\n",
      "[SGD | lr=0.01] Epoch 2131/4000: train_loss=0.5456  test_loss=2.5003  λ_max=79.7754\n",
      "[SGD | lr=0.01] Iter 34100: loss=0.5492\n",
      "[SGD | lr=0.01] Epoch 2132/4000: train_loss=0.5476  test_loss=2.5016  λ_max=80.9365\n",
      "[SGD | lr=0.01] Epoch 2133/4000: train_loss=0.5474  test_loss=2.5035  λ_max=76.0607\n",
      "[SGD | lr=0.01] Epoch 2134/4000: train_loss=0.5493  test_loss=2.5023  λ_max=76.0188\n",
      "[SGD | lr=0.01] Epoch 2135/4000: train_loss=0.5491  test_loss=2.5027  λ_max=77.2331\n",
      "[SGD | lr=0.01] Epoch 2136/4000: train_loss=0.5602  test_loss=2.5026  λ_max=77.9863\n",
      "[SGD | lr=0.01] Epoch 2137/4000: train_loss=0.5501  test_loss=2.5015  λ_max=80.0244\n",
      "[SGD | lr=0.01] Iter 34200: loss=0.5473\n",
      "[SGD | lr=0.01] Epoch 2138/4000: train_loss=0.5493  test_loss=2.5033  λ_max=79.9794\n",
      "[SGD | lr=0.01] Epoch 2139/4000: train_loss=0.5531  test_loss=2.5055  λ_max=79.4573\n",
      "[SGD | lr=0.01] Epoch 2140/4000: train_loss=0.5459  test_loss=2.5052  λ_max=80.3582\n",
      "[SGD | lr=0.01] Epoch 2141/4000: train_loss=0.5455  test_loss=2.5044  λ_max=82.6693\n",
      "[SGD | lr=0.01] Epoch 2142/4000: train_loss=0.5494  test_loss=2.5061  λ_max=76.9483\n",
      "[SGD | lr=0.01] Epoch 2143/4000: train_loss=0.5469  test_loss=2.5052  λ_max=75.2434\n",
      "[SGD | lr=0.01] Iter 34300: loss=0.5357\n",
      "[SGD | lr=0.01] Epoch 2144/4000: train_loss=0.5413  test_loss=2.5053  λ_max=81.0960\n",
      "[SGD | lr=0.01] Epoch 2145/4000: train_loss=0.5414  test_loss=2.5059  λ_max=80.7366\n",
      "[SGD | lr=0.01] Epoch 2146/4000: train_loss=0.5465  test_loss=2.5083  λ_max=80.3952\n",
      "[SGD | lr=0.01] Epoch 2147/4000: train_loss=0.5477  test_loss=2.5105  λ_max=77.8229\n",
      "[SGD | lr=0.01] Epoch 2148/4000: train_loss=0.5457  test_loss=2.5117  λ_max=77.2187\n",
      "[SGD | lr=0.01] Epoch 2149/4000: train_loss=0.5446  test_loss=2.5117  λ_max=74.6094\n",
      "[SGD | lr=0.01] Iter 34400: loss=0.5495\n",
      "[SGD | lr=0.01] Epoch 2150/4000: train_loss=0.5451  test_loss=2.5102  λ_max=79.4470\n",
      "[SGD | lr=0.01] Epoch 2151/4000: train_loss=0.5406  test_loss=2.5113  λ_max=76.9005\n",
      "[SGD | lr=0.01] Epoch 2152/4000: train_loss=0.5356  test_loss=2.5099  λ_max=77.8649\n",
      "[SGD | lr=0.01] Epoch 2153/4000: train_loss=0.5325  test_loss=2.5086  λ_max=78.6527\n",
      "[SGD | lr=0.01] Epoch 2154/4000: train_loss=0.5316  test_loss=2.5097  λ_max=79.4436\n",
      "[SGD | lr=0.01] Epoch 2155/4000: train_loss=0.5342  test_loss=2.5112  λ_max=80.5730\n",
      "[SGD | lr=0.01] Epoch 2156/4000: train_loss=0.5443  test_loss=2.5107  λ_max=81.2594\n",
      "[SGD | lr=0.01] Iter 34500: loss=0.5460\n",
      "[SGD | lr=0.01] Epoch 2157/4000: train_loss=0.5466  test_loss=2.5120  λ_max=75.9196\n",
      "[SGD | lr=0.01] Epoch 2158/4000: train_loss=0.5455  test_loss=2.5141  λ_max=78.7429\n",
      "[SGD | lr=0.01] Epoch 2159/4000: train_loss=0.5418  test_loss=2.5147  λ_max=79.6552\n",
      "[SGD | lr=0.01] Epoch 2160/4000: train_loss=0.5351  test_loss=2.5150  λ_max=80.4344\n",
      "[SGD | lr=0.01] Epoch 2161/4000: train_loss=0.5356  test_loss=2.5166  λ_max=78.2441\n",
      "[SGD | lr=0.01] Epoch 2162/4000: train_loss=0.5344  test_loss=2.5163  λ_max=75.7579\n",
      "[SGD | lr=0.01] Iter 34600: loss=0.5486\n",
      "[SGD | lr=0.01] Epoch 2163/4000: train_loss=0.5451  test_loss=2.5172  λ_max=76.8138\n",
      "[SGD | lr=0.01] Epoch 2164/4000: train_loss=0.5428  test_loss=2.5148  λ_max=76.8275\n",
      "[SGD | lr=0.01] Epoch 2165/4000: train_loss=0.5411  test_loss=2.5140  λ_max=80.6035\n",
      "[SGD | lr=0.01] Epoch 2166/4000: train_loss=0.5349  test_loss=2.5164  λ_max=82.5302\n",
      "[SGD | lr=0.01] Epoch 2167/4000: train_loss=0.5337  test_loss=2.5182  λ_max=75.0092\n",
      "[SGD | lr=0.01] Epoch 2168/4000: train_loss=0.5385  test_loss=2.5194  λ_max=81.6403\n",
      "[SGD | lr=0.01] Iter 34700: loss=0.5481\n",
      "[SGD | lr=0.01] Epoch 2169/4000: train_loss=0.5421  test_loss=2.5183  λ_max=82.5049\n",
      "[SGD | lr=0.01] Epoch 2170/4000: train_loss=0.5393  test_loss=2.5180  λ_max=75.7985\n",
      "[SGD | lr=0.01] Epoch 2171/4000: train_loss=0.5391  test_loss=2.5190  λ_max=82.4394\n",
      "[SGD | lr=0.01] Epoch 2172/4000: train_loss=0.5320  test_loss=2.5194  λ_max=82.3904\n",
      "[SGD | lr=0.01] Epoch 2173/4000: train_loss=0.5368  test_loss=2.5202  λ_max=78.2782\n",
      "[SGD | lr=0.01] Epoch 2174/4000: train_loss=0.5366  test_loss=2.5185  λ_max=76.5668\n",
      "[SGD | lr=0.01] Iter 34800: loss=0.5398\n",
      "[SGD | lr=0.01] Epoch 2175/4000: train_loss=0.5356  test_loss=2.5182  λ_max=81.2823\n",
      "[SGD | lr=0.01] Epoch 2176/4000: train_loss=0.5311  test_loss=2.5184  λ_max=78.2078\n",
      "[SGD | lr=0.01] Epoch 2177/4000: train_loss=0.5291  test_loss=2.5190  λ_max=81.0140\n",
      "[SGD | lr=0.01] Epoch 2178/4000: train_loss=0.5309  test_loss=2.5197  λ_max=77.5486\n",
      "[SGD | lr=0.01] Epoch 2179/4000: train_loss=0.5327  test_loss=2.5217  λ_max=81.3652\n",
      "[SGD | lr=0.01] Epoch 2180/4000: train_loss=0.5338  test_loss=2.5219  λ_max=78.4396\n",
      "[SGD | lr=0.01] Epoch 2181/4000: train_loss=0.5294  test_loss=2.5217  λ_max=78.6066\n",
      "[SGD | lr=0.01] Iter 34900: loss=0.5272\n",
      "[SGD | lr=0.01] Epoch 2182/4000: train_loss=0.5242  test_loss=2.5225  λ_max=76.7921\n",
      "[SGD | lr=0.01] Epoch 2183/4000: train_loss=0.5277  test_loss=2.5263  λ_max=78.5584\n",
      "[SGD | lr=0.01] Epoch 2184/4000: train_loss=0.5353  test_loss=2.5284  λ_max=77.4668\n",
      "[SGD | lr=0.01] Epoch 2185/4000: train_loss=0.5367  test_loss=2.5257  λ_max=77.8772\n",
      "[SGD | lr=0.01] Epoch 2186/4000: train_loss=0.5334  test_loss=2.5230  λ_max=82.2622\n",
      "[SGD | lr=0.01] Epoch 2187/4000: train_loss=0.5274  test_loss=2.5212  λ_max=78.3008\n",
      "[SGD | lr=0.01] Iter 35000: loss=0.5287\n",
      "[SGD | lr=0.01] Epoch 2188/4000: train_loss=0.5292  test_loss=2.5211  λ_max=78.8748\n",
      "[SGD | lr=0.01] Epoch 2189/4000: train_loss=0.5294  test_loss=2.5219  λ_max=79.4431\n",
      "[SGD | lr=0.01] Epoch 2190/4000: train_loss=0.5325  test_loss=2.5227  λ_max=80.6191\n",
      "[SGD | lr=0.01] Epoch 2191/4000: train_loss=0.5240  test_loss=2.5227  λ_max=81.3000\n",
      "[SGD | lr=0.01] Epoch 2192/4000: train_loss=0.5215  test_loss=2.5252  λ_max=76.2955\n",
      "[SGD | lr=0.01] Epoch 2193/4000: train_loss=0.5256  test_loss=2.5263  λ_max=81.4852\n",
      "[SGD | lr=0.01] Iter 35100: loss=0.5285\n",
      "[SGD | lr=0.01] Epoch 2194/4000: train_loss=0.5279  test_loss=2.5270  λ_max=75.7487\n",
      "[SGD | lr=0.01] Epoch 2195/4000: train_loss=0.5251  test_loss=2.5259  λ_max=80.0544\n",
      "[SGD | lr=0.01] Epoch 2196/4000: train_loss=0.5263  test_loss=2.5266  λ_max=81.4164\n",
      "[SGD | lr=0.01] Epoch 2197/4000: train_loss=0.5236  test_loss=2.5269  λ_max=80.9662\n",
      "[SGD | lr=0.01] Epoch 2198/4000: train_loss=0.5350  test_loss=2.5252  λ_max=82.7198\n",
      "[SGD | lr=0.01] Epoch 2199/4000: train_loss=0.5259  test_loss=2.5261  λ_max=79.3118\n",
      "[SGD | lr=0.01] Iter 35200: loss=0.5274\n",
      "[SGD | lr=0.01] Epoch 2200/4000: train_loss=0.5226  test_loss=2.5263  λ_max=75.5663\n",
      "[SGD | lr=0.01] Epoch 2201/4000: train_loss=0.5233  test_loss=2.5278  λ_max=82.0815\n",
      "[SGD | lr=0.01] Epoch 2202/4000: train_loss=0.5236  test_loss=2.5285  λ_max=82.0502\n",
      "[SGD | lr=0.01] Epoch 2203/4000: train_loss=0.5217  test_loss=2.5296  λ_max=81.2191\n",
      "[SGD | lr=0.01] Epoch 2204/4000: train_loss=0.5243  test_loss=2.5320  λ_max=82.1396\n",
      "[SGD | lr=0.01] Epoch 2205/4000: train_loss=0.5271  test_loss=2.5314  λ_max=83.2068\n",
      "[SGD | lr=0.01] Epoch 2206/4000: train_loss=0.5208  test_loss=2.5311  λ_max=81.6262\n",
      "[SGD | lr=0.01] Iter 35300: loss=0.5165\n",
      "[SGD | lr=0.01] Epoch 2207/4000: train_loss=0.5194  test_loss=2.5327  λ_max=80.0257\n",
      "[SGD | lr=0.01] Epoch 2208/4000: train_loss=0.5195  test_loss=2.5334  λ_max=82.6915\n",
      "[SGD | lr=0.01] Epoch 2209/4000: train_loss=0.5202  test_loss=2.5358  λ_max=82.4295\n",
      "[SGD | lr=0.01] Epoch 2210/4000: train_loss=0.5205  test_loss=2.5350  λ_max=77.6571\n",
      "[SGD | lr=0.01] Epoch 2211/4000: train_loss=0.5209  test_loss=2.5335  λ_max=80.0676\n",
      "[SGD | lr=0.01] Epoch 2212/4000: train_loss=0.5183  test_loss=2.5325  λ_max=75.4287\n",
      "[SGD | lr=0.01] Iter 35400: loss=0.5058\n",
      "[SGD | lr=0.01] Epoch 2213/4000: train_loss=0.5117  test_loss=2.5311  λ_max=78.9876\n",
      "[SGD | lr=0.01] Epoch 2214/4000: train_loss=0.5111  test_loss=2.5331  λ_max=82.6700\n",
      "[SGD | lr=0.01] Epoch 2215/4000: train_loss=0.5117  test_loss=2.5320  λ_max=74.6893\n",
      "[SGD | lr=0.01] Epoch 2216/4000: train_loss=0.5181  test_loss=2.5332  λ_max=78.8929\n",
      "[SGD | lr=0.01] Epoch 2217/4000: train_loss=0.5281  test_loss=2.5318  λ_max=80.5873\n",
      "[SGD | lr=0.01] Epoch 2218/4000: train_loss=0.5205  test_loss=2.5339  λ_max=77.9537\n",
      "[SGD | lr=0.01] Iter 35500: loss=0.5182\n",
      "[SGD | lr=0.01] Epoch 2219/4000: train_loss=0.5166  test_loss=2.5359  λ_max=78.5833\n",
      "[SGD | lr=0.01] Epoch 2220/4000: train_loss=0.5160  test_loss=2.5377  λ_max=74.0793\n",
      "[SGD | lr=0.01] Epoch 2221/4000: train_loss=0.5217  test_loss=2.5406  λ_max=84.2062\n",
      "[SGD | lr=0.01] Epoch 2222/4000: train_loss=0.5147  test_loss=2.5380  λ_max=79.9970\n",
      "[SGD | lr=0.01] Epoch 2223/4000: train_loss=0.5106  test_loss=2.5359  λ_max=81.6910\n",
      "[SGD | lr=0.01] Epoch 2224/4000: train_loss=0.5115  test_loss=2.5362  λ_max=77.9811\n",
      "[SGD | lr=0.01] Iter 35600: loss=0.5122\n",
      "[SGD | lr=0.01] Epoch 2225/4000: train_loss=0.5144  test_loss=2.5386  λ_max=82.5385\n",
      "[SGD | lr=0.01] Epoch 2226/4000: train_loss=0.5149  test_loss=2.5415  λ_max=80.9201\n",
      "[SGD | lr=0.01] Epoch 2227/4000: train_loss=0.5155  test_loss=2.5409  λ_max=79.1842\n",
      "[SGD | lr=0.01] Epoch 2228/4000: train_loss=0.5174  test_loss=2.5434  λ_max=75.6804\n",
      "[SGD | lr=0.01] Epoch 2229/4000: train_loss=0.5206  test_loss=2.5415  λ_max=81.5267\n",
      "[SGD | lr=0.01] Epoch 2230/4000: train_loss=0.5198  test_loss=2.5407  λ_max=82.0526\n",
      "[SGD | lr=0.01] Epoch 2231/4000: train_loss=0.5151  test_loss=2.5412  λ_max=77.6107\n",
      "[SGD | lr=0.01] Iter 35700: loss=0.5107\n",
      "[SGD | lr=0.01] Epoch 2232/4000: train_loss=0.5114  test_loss=2.5413  λ_max=78.6189\n",
      "[SGD | lr=0.01] Epoch 2233/4000: train_loss=0.5072  test_loss=2.5407  λ_max=80.1526\n",
      "[SGD | lr=0.01] Epoch 2234/4000: train_loss=0.5054  test_loss=2.5409  λ_max=82.9091\n",
      "[SGD | lr=0.01] Epoch 2235/4000: train_loss=0.5096  test_loss=2.5419  λ_max=81.4482\n",
      "[SGD | lr=0.01] Epoch 2236/4000: train_loss=0.5116  test_loss=2.5454  λ_max=81.6287\n",
      "[SGD | lr=0.01] Epoch 2237/4000: train_loss=0.5145  test_loss=2.5437  λ_max=78.6561\n",
      "[SGD | lr=0.01] Iter 35800: loss=0.5073\n",
      "[SGD | lr=0.01] Epoch 2238/4000: train_loss=0.5084  test_loss=2.5445  λ_max=80.6304\n",
      "[SGD | lr=0.01] Epoch 2239/4000: train_loss=0.5149  test_loss=2.5464  λ_max=82.5611\n",
      "[SGD | lr=0.01] Epoch 2240/4000: train_loss=0.5151  test_loss=2.5427  λ_max=78.8244\n",
      "[SGD | lr=0.01] Epoch 2241/4000: train_loss=0.5027  test_loss=2.5408  λ_max=80.2356\n",
      "[SGD | lr=0.01] Epoch 2242/4000: train_loss=0.5028  test_loss=2.5418  λ_max=83.3774\n",
      "[SGD | lr=0.01] Epoch 2243/4000: train_loss=0.5063  test_loss=2.5421  λ_max=79.8141\n",
      "[SGD | lr=0.01] Iter 35900: loss=0.5329\n",
      "[SGD | lr=0.01] Epoch 2244/4000: train_loss=0.5196  test_loss=2.5438  λ_max=75.4519\n",
      "[SGD | lr=0.01] Epoch 2245/4000: train_loss=0.5113  test_loss=2.5447  λ_max=79.8206\n",
      "[SGD | lr=0.01] Epoch 2246/4000: train_loss=0.5026  test_loss=2.5450  λ_max=82.0189\n",
      "[SGD | lr=0.01] Epoch 2247/4000: train_loss=0.5015  test_loss=2.5469  λ_max=80.9192\n",
      "[SGD | lr=0.01] Epoch 2248/4000: train_loss=0.5044  test_loss=2.5473  λ_max=81.4091\n",
      "[SGD | lr=0.01] Epoch 2249/4000: train_loss=0.5084  test_loss=2.5476  λ_max=82.1877\n",
      "[SGD | lr=0.01] Iter 36000: loss=0.5086\n",
      "[SGD | lr=0.01] Epoch 2250/4000: train_loss=0.5019  test_loss=2.5454  λ_max=79.7581\n",
      "[SGD | lr=0.01] Epoch 2251/4000: train_loss=0.5007  test_loss=2.5452  λ_max=80.2249\n",
      "[SGD | lr=0.01] Epoch 2252/4000: train_loss=0.5040  test_loss=2.5468  λ_max=80.3100\n",
      "[SGD | lr=0.01] Epoch 2253/4000: train_loss=0.5087  test_loss=2.5479  λ_max=80.0699\n",
      "[SGD | lr=0.01] Epoch 2254/4000: train_loss=0.5028  test_loss=2.5512  λ_max=81.5943\n",
      "[SGD | lr=0.01] Epoch 2255/4000: train_loss=0.5116  test_loss=2.5551  λ_max=80.8643\n",
      "[SGD | lr=0.01] Epoch 2256/4000: train_loss=0.5088  test_loss=2.5544  λ_max=79.7337\n",
      "[SGD | lr=0.01] Iter 36100: loss=0.5048\n",
      "[SGD | lr=0.01] Epoch 2257/4000: train_loss=0.5070  test_loss=2.5553  λ_max=78.7811\n",
      "[SGD | lr=0.01] Epoch 2258/4000: train_loss=0.5054  test_loss=2.5510  λ_max=79.0647\n",
      "[SGD | lr=0.01] Epoch 2259/4000: train_loss=0.4981  test_loss=2.5510  λ_max=81.3509\n",
      "[SGD | lr=0.01] Epoch 2260/4000: train_loss=0.4978  test_loss=2.5515  λ_max=80.6654\n",
      "[SGD | lr=0.01] Epoch 2261/4000: train_loss=0.5018  test_loss=2.5517  λ_max=84.7641\n",
      "[SGD | lr=0.01] Epoch 2262/4000: train_loss=0.4996  test_loss=2.5502  λ_max=78.7878\n",
      "[SGD | lr=0.01] Iter 36200: loss=0.5028\n",
      "[SGD | lr=0.01] Epoch 2263/4000: train_loss=0.4981  test_loss=2.5516  λ_max=78.2293\n",
      "[SGD | lr=0.01] Epoch 2264/4000: train_loss=0.5014  test_loss=2.5535  λ_max=79.3968\n",
      "[SGD | lr=0.01] Epoch 2265/4000: train_loss=0.5058  test_loss=2.5545  λ_max=78.1800\n",
      "[SGD | lr=0.01] Epoch 2266/4000: train_loss=0.5051  test_loss=2.5550  λ_max=80.2777\n",
      "[SGD | lr=0.01] Epoch 2267/4000: train_loss=0.5045  test_loss=2.5544  λ_max=81.9286\n",
      "[SGD | lr=0.01] Epoch 2268/4000: train_loss=0.5051  test_loss=2.5578  λ_max=80.6157\n",
      "[SGD | lr=0.01] Iter 36300: loss=0.4987\n",
      "[SGD | lr=0.01] Epoch 2269/4000: train_loss=0.5016  test_loss=2.5548  λ_max=76.8277\n",
      "[SGD | lr=0.01] Epoch 2270/4000: train_loss=0.4988  test_loss=2.5563  λ_max=80.0027\n",
      "[SGD | lr=0.01] Epoch 2271/4000: train_loss=0.4964  test_loss=2.5554  λ_max=83.4931\n",
      "[SGD | lr=0.01] Epoch 2272/4000: train_loss=0.4941  test_loss=2.5559  λ_max=82.7738\n",
      "[SGD | lr=0.01] Epoch 2273/4000: train_loss=0.4952  test_loss=2.5563  λ_max=75.4183\n",
      "[SGD | lr=0.01] Epoch 2274/4000: train_loss=0.4998  test_loss=2.5566  λ_max=79.6477\n",
      "[SGD | lr=0.01] Iter 36400: loss=0.5060\n",
      "[SGD | lr=0.01] Epoch 2275/4000: train_loss=0.5051  test_loss=2.5578  λ_max=78.9447\n",
      "[SGD | lr=0.01] Epoch 2276/4000: train_loss=0.4988  test_loss=2.5560  λ_max=83.1164\n",
      "[SGD | lr=0.01] Epoch 2277/4000: train_loss=0.5009  test_loss=2.5577  λ_max=82.0472\n",
      "[SGD | lr=0.01] Epoch 2278/4000: train_loss=0.5009  test_loss=2.5615  λ_max=85.0197\n",
      "[SGD | lr=0.01] Epoch 2279/4000: train_loss=0.4996  test_loss=2.5595  λ_max=79.2674\n",
      "[SGD | lr=0.01] Epoch 2280/4000: train_loss=0.4954  test_loss=2.5618  λ_max=84.0637\n",
      "[SGD | lr=0.01] Epoch 2281/4000: train_loss=0.4993  test_loss=2.5577  λ_max=85.1900\n",
      "[SGD | lr=0.01] Iter 36500: loss=0.4921\n",
      "[SGD | lr=0.01] Epoch 2282/4000: train_loss=0.4928  test_loss=2.5574  λ_max=80.5800\n",
      "[SGD | lr=0.01] Epoch 2283/4000: train_loss=0.4922  test_loss=2.5558  λ_max=78.6901\n",
      "[SGD | lr=0.01] Epoch 2284/4000: train_loss=0.4921  test_loss=2.5564  λ_max=82.1376\n",
      "[SGD | lr=0.01] Epoch 2285/4000: train_loss=0.4898  test_loss=2.5577  λ_max=80.9167\n",
      "[SGD | lr=0.01] Epoch 2286/4000: train_loss=0.4915  test_loss=2.5603  λ_max=83.9754\n",
      "[SGD | lr=0.01] Epoch 2287/4000: train_loss=0.4971  test_loss=2.5611  λ_max=80.3317\n",
      "[SGD | lr=0.01] Iter 36600: loss=0.4798\n",
      "[SGD | lr=0.01] Epoch 2288/4000: train_loss=0.4865  test_loss=2.5594  λ_max=76.9709\n",
      "[SGD | lr=0.01] Epoch 2289/4000: train_loss=0.4851  test_loss=2.5596  λ_max=79.4063\n",
      "[SGD | lr=0.01] Epoch 2290/4000: train_loss=0.4884  test_loss=2.5612  λ_max=79.4907\n",
      "[SGD | lr=0.01] Epoch 2291/4000: train_loss=0.5008  test_loss=2.5603  λ_max=79.4199\n",
      "[SGD | lr=0.01] Epoch 2292/4000: train_loss=0.4948  test_loss=2.5609  λ_max=79.5514\n",
      "[SGD | lr=0.01] Epoch 2293/4000: train_loss=0.4929  test_loss=2.5620  λ_max=82.3909\n",
      "[SGD | lr=0.01] Iter 36700: loss=0.4854\n",
      "[SGD | lr=0.01] Epoch 2294/4000: train_loss=0.4854  test_loss=2.5615  λ_max=78.8589\n",
      "[SGD | lr=0.01] Epoch 2295/4000: train_loss=0.4822  test_loss=2.5627  λ_max=82.6223\n",
      "[SGD | lr=0.01] Epoch 2296/4000: train_loss=0.4808  test_loss=2.5641  λ_max=81.1396\n",
      "[SGD | lr=0.01] Epoch 2297/4000: train_loss=0.4801  test_loss=2.5638  λ_max=79.6527\n",
      "[SGD | lr=0.01] Epoch 2298/4000: train_loss=0.4801  test_loss=2.5644  λ_max=82.1429\n",
      "[SGD | lr=0.01] Epoch 2299/4000: train_loss=0.4810  test_loss=2.5647  λ_max=82.6092\n",
      "[SGD | lr=0.01] Iter 36800: loss=0.4898\n",
      "[SGD | lr=0.01] Epoch 2300/4000: train_loss=0.4835  test_loss=2.5675  λ_max=80.1365\n",
      "[SGD | lr=0.01] Epoch 2301/4000: train_loss=0.4981  test_loss=2.5683  λ_max=79.0998\n",
      "[SGD | lr=0.01] Epoch 2302/4000: train_loss=0.4928  test_loss=2.5680  λ_max=83.6116\n",
      "[SGD | lr=0.01] Epoch 2303/4000: train_loss=0.4957  test_loss=2.5696  λ_max=79.7069\n",
      "[SGD | lr=0.01] Epoch 2304/4000: train_loss=0.4927  test_loss=2.5685  λ_max=83.0124\n",
      "[SGD | lr=0.01] Epoch 2305/4000: train_loss=0.4912  test_loss=2.5687  λ_max=79.7786\n",
      "[SGD | lr=0.01] Epoch 2306/4000: train_loss=0.4931  test_loss=2.5688  λ_max=80.3765\n",
      "[SGD | lr=0.01] Iter 36900: loss=0.4945\n",
      "[SGD | lr=0.01] Epoch 2307/4000: train_loss=0.4928  test_loss=2.5692  λ_max=78.3432\n",
      "[SGD | lr=0.01] Epoch 2308/4000: train_loss=0.4930  test_loss=2.5680  λ_max=81.5361\n",
      "[SGD | lr=0.01] Epoch 2309/4000: train_loss=0.4874  test_loss=2.5682  λ_max=81.3846\n",
      "[SGD | lr=0.01] Epoch 2310/4000: train_loss=0.4921  test_loss=2.5684  λ_max=80.9655\n",
      "[SGD | lr=0.01] Epoch 2311/4000: train_loss=0.4887  test_loss=2.5689  λ_max=77.4263\n",
      "[SGD | lr=0.01] Epoch 2312/4000: train_loss=0.4819  test_loss=2.5687  λ_max=83.8815\n",
      "[SGD | lr=0.01] Iter 37000: loss=0.4920\n",
      "[SGD | lr=0.01] Epoch 2313/4000: train_loss=0.4858  test_loss=2.5712  λ_max=83.7759\n",
      "[SGD | lr=0.01] Epoch 2314/4000: train_loss=0.4865  test_loss=2.5726  λ_max=81.4435\n",
      "[SGD | lr=0.01] Epoch 2315/4000: train_loss=0.4860  test_loss=2.5721  λ_max=83.5474\n",
      "[SGD | lr=0.01] Epoch 2316/4000: train_loss=0.4823  test_loss=2.5719  λ_max=81.9606\n",
      "[SGD | lr=0.01] Epoch 2317/4000: train_loss=0.4800  test_loss=2.5728  λ_max=80.5141\n",
      "[SGD | lr=0.01] Epoch 2318/4000: train_loss=0.4767  test_loss=2.5734  λ_max=82.4234\n",
      "[SGD | lr=0.01] Iter 37100: loss=0.4728\n",
      "[SGD | lr=0.01] Epoch 2319/4000: train_loss=0.4746  test_loss=2.5730  λ_max=82.4309\n",
      "[SGD | lr=0.01] Epoch 2320/4000: train_loss=0.4730  test_loss=2.5724  λ_max=82.0241\n",
      "[SGD | lr=0.01] Epoch 2321/4000: train_loss=0.4726  test_loss=2.5716  λ_max=84.5066\n",
      "[SGD | lr=0.01] Epoch 2322/4000: train_loss=0.4726  test_loss=2.5736  λ_max=84.8150\n",
      "[SGD | lr=0.01] Epoch 2323/4000: train_loss=0.4741  test_loss=2.5744  λ_max=78.7885\n",
      "[SGD | lr=0.01] Epoch 2324/4000: train_loss=0.4813  test_loss=2.5783  λ_max=80.3220\n",
      "[SGD | lr=0.01] Iter 37200: loss=0.4784\n",
      "[SGD | lr=0.01] Epoch 2325/4000: train_loss=0.4905  test_loss=2.5815  λ_max=81.8905\n",
      "[SGD | lr=0.01] Epoch 2326/4000: train_loss=0.4849  test_loss=2.5813  λ_max=81.0855\n",
      "[SGD | lr=0.01] Epoch 2327/4000: train_loss=0.4852  test_loss=2.5807  λ_max=78.1444\n",
      "[SGD | lr=0.01] Epoch 2328/4000: train_loss=0.4820  test_loss=2.5803  λ_max=83.1200\n",
      "[SGD | lr=0.01] Epoch 2329/4000: train_loss=0.4883  test_loss=2.5795  λ_max=85.7530\n",
      "[SGD | lr=0.01] Epoch 2330/4000: train_loss=0.4804  test_loss=2.5780  λ_max=84.6287\n",
      "[SGD | lr=0.01] Epoch 2331/4000: train_loss=0.4767  test_loss=2.5781  λ_max=80.1731\n",
      "[SGD | lr=0.01] Iter 37300: loss=0.4770\n",
      "[SGD | lr=0.01] Epoch 2332/4000: train_loss=0.4737  test_loss=2.5790  λ_max=83.2154\n",
      "[SGD | lr=0.01] Epoch 2333/4000: train_loss=0.4743  test_loss=2.5811  λ_max=80.8924\n",
      "[SGD | lr=0.01] Epoch 2334/4000: train_loss=0.4792  test_loss=2.5830  λ_max=85.1670\n",
      "[SGD | lr=0.01] Epoch 2335/4000: train_loss=0.4859  test_loss=2.5843  λ_max=85.6086\n",
      "[SGD | lr=0.01] Epoch 2336/4000: train_loss=0.4869  test_loss=2.5864  λ_max=83.8586\n",
      "[SGD | lr=0.01] Epoch 2337/4000: train_loss=0.4817  test_loss=2.5858  λ_max=80.5279\n",
      "[SGD | lr=0.01] Iter 37400: loss=0.4654\n",
      "[SGD | lr=0.01] Epoch 2338/4000: train_loss=0.4728  test_loss=2.5827  λ_max=82.2311\n",
      "[SGD | lr=0.01] Epoch 2339/4000: train_loss=0.4712  test_loss=2.5821  λ_max=83.3725\n",
      "[SGD | lr=0.01] Epoch 2340/4000: train_loss=0.4718  test_loss=2.5830  λ_max=86.7119\n",
      "[SGD | lr=0.01] Epoch 2341/4000: train_loss=0.4724  test_loss=2.5829  λ_max=79.6989\n",
      "[SGD | lr=0.01] Epoch 2342/4000: train_loss=0.4741  test_loss=2.5855  λ_max=80.6404\n",
      "[SGD | lr=0.01] Epoch 2343/4000: train_loss=0.4799  test_loss=2.5840  λ_max=79.5055\n",
      "[SGD | lr=0.01] Iter 37500: loss=0.4772\n",
      "[SGD | lr=0.01] Epoch 2344/4000: train_loss=0.4721  test_loss=2.5833  λ_max=84.7824\n",
      "[SGD | lr=0.01] Epoch 2345/4000: train_loss=0.4751  test_loss=2.5836  λ_max=80.9927\n",
      "[SGD | lr=0.01] Epoch 2346/4000: train_loss=0.4850  test_loss=2.5828  λ_max=80.1388\n",
      "[SGD | lr=0.01] Epoch 2347/4000: train_loss=0.4706  test_loss=2.5846  λ_max=80.8645\n",
      "[SGD | lr=0.01] Epoch 2348/4000: train_loss=0.4661  test_loss=2.5834  λ_max=81.2481\n",
      "[SGD | lr=0.01] Epoch 2349/4000: train_loss=0.4672  test_loss=2.5861  λ_max=81.6705\n",
      "[SGD | lr=0.01] Iter 37600: loss=0.4635\n",
      "[SGD | lr=0.01] Epoch 2350/4000: train_loss=0.4691  test_loss=2.5876  λ_max=81.6212\n",
      "[SGD | lr=0.01] Epoch 2351/4000: train_loss=0.4700  test_loss=2.5898  λ_max=76.6649\n",
      "[SGD | lr=0.01] Epoch 2352/4000: train_loss=0.4817  test_loss=2.5897  λ_max=80.1527\n",
      "[SGD | lr=0.01] Epoch 2353/4000: train_loss=0.4768  test_loss=2.5869  λ_max=83.5359\n",
      "[SGD | lr=0.01] Epoch 2354/4000: train_loss=0.4710  test_loss=2.5854  λ_max=81.9127\n",
      "[SGD | lr=0.01] Epoch 2355/4000: train_loss=0.4693  test_loss=2.5861  λ_max=81.9071\n",
      "[SGD | lr=0.01] Epoch 2356/4000: train_loss=0.4827  test_loss=2.5865  λ_max=84.6476\n",
      "[SGD | lr=0.01] Iter 37700: loss=0.4638\n",
      "[SGD | lr=0.01] Epoch 2357/4000: train_loss=0.4692  test_loss=2.5855  λ_max=79.6392\n",
      "[SGD | lr=0.01] Epoch 2358/4000: train_loss=0.4691  test_loss=2.5874  λ_max=80.6794\n",
      "[SGD | lr=0.01] Epoch 2359/4000: train_loss=0.4701  test_loss=2.5870  λ_max=79.2309\n",
      "[SGD | lr=0.01] Epoch 2360/4000: train_loss=0.4660  test_loss=2.5877  λ_max=85.4651\n",
      "[SGD | lr=0.01] Epoch 2361/4000: train_loss=0.4643  test_loss=2.5890  λ_max=85.3010\n",
      "[SGD | lr=0.01] Epoch 2362/4000: train_loss=0.4616  test_loss=2.5880  λ_max=81.9495\n",
      "[SGD | lr=0.01] Iter 37800: loss=0.4646\n",
      "[SGD | lr=0.01] Epoch 2363/4000: train_loss=0.4653  test_loss=2.5908  λ_max=83.9036\n",
      "[SGD | lr=0.01] Epoch 2364/4000: train_loss=0.4697  test_loss=2.5923  λ_max=79.8326\n",
      "[SGD | lr=0.01] Epoch 2365/4000: train_loss=0.4736  test_loss=2.5928  λ_max=86.7679\n",
      "[SGD | lr=0.01] Epoch 2366/4000: train_loss=0.4724  test_loss=2.5914  λ_max=86.4585\n",
      "[SGD | lr=0.01] Epoch 2367/4000: train_loss=0.4658  test_loss=2.5919  λ_max=84.8186\n",
      "[SGD | lr=0.01] Epoch 2368/4000: train_loss=0.4699  test_loss=2.5944  λ_max=88.3604\n",
      "[SGD | lr=0.01] Iter 37900: loss=0.4766\n",
      "[SGD | lr=0.01] Epoch 2369/4000: train_loss=0.4756  test_loss=2.5922  λ_max=81.4982\n",
      "[SGD | lr=0.01] Epoch 2370/4000: train_loss=0.4628  test_loss=2.5915  λ_max=86.0052\n",
      "[SGD | lr=0.01] Epoch 2371/4000: train_loss=0.4658  test_loss=2.5924  λ_max=80.7869\n",
      "[SGD | lr=0.01] Epoch 2372/4000: train_loss=0.4634  test_loss=2.5934  λ_max=80.4439\n",
      "[SGD | lr=0.01] Epoch 2373/4000: train_loss=0.4655  test_loss=2.5966  λ_max=85.6994\n",
      "[SGD | lr=0.01] Epoch 2374/4000: train_loss=0.4714  test_loss=2.5969  λ_max=85.4496\n",
      "[SGD | lr=0.01] Iter 38000: loss=0.4626\n",
      "[SGD | lr=0.01] Epoch 2375/4000: train_loss=0.4640  test_loss=2.5956  λ_max=83.9960\n",
      "[SGD | lr=0.01] Epoch 2376/4000: train_loss=0.4616  test_loss=2.5946  λ_max=85.7242\n",
      "[SGD | lr=0.01] Epoch 2377/4000: train_loss=0.4627  test_loss=2.5933  λ_max=84.9816\n",
      "[SGD | lr=0.01] Epoch 2378/4000: train_loss=0.4561  test_loss=2.5932  λ_max=82.1073\n",
      "[SGD | lr=0.01] Epoch 2379/4000: train_loss=0.4539  test_loss=2.5950  λ_max=79.6555\n",
      "[SGD | lr=0.01] Epoch 2380/4000: train_loss=0.4535  test_loss=2.5953  λ_max=84.3043\n",
      "[SGD | lr=0.01] Epoch 2381/4000: train_loss=0.4529  test_loss=2.5959  λ_max=84.6088\n",
      "[SGD | lr=0.01] Iter 38100: loss=0.4434\n",
      "[SGD | lr=0.01] Epoch 2382/4000: train_loss=0.4525  test_loss=2.5963  λ_max=84.0127\n",
      "[SGD | lr=0.01] Epoch 2383/4000: train_loss=0.4521  test_loss=2.5961  λ_max=83.2259\n",
      "[SGD | lr=0.01] Epoch 2384/4000: train_loss=0.4516  test_loss=2.5964  λ_max=83.5211\n",
      "[SGD | lr=0.01] Epoch 2385/4000: train_loss=0.4574  test_loss=2.5989  λ_max=80.9086\n",
      "[SGD | lr=0.01] Epoch 2386/4000: train_loss=0.4765  test_loss=2.5988  λ_max=83.1903\n",
      "[SGD | lr=0.01] Epoch 2387/4000: train_loss=0.4640  test_loss=2.5996  λ_max=85.1088\n",
      "[SGD | lr=0.01] Iter 38200: loss=0.4673\n",
      "[SGD | lr=0.01] Epoch 2388/4000: train_loss=0.4636  test_loss=2.6020  λ_max=81.4011\n",
      "[SGD | lr=0.01] Epoch 2389/4000: train_loss=0.4634  test_loss=2.6042  λ_max=80.1453\n",
      "[SGD | lr=0.01] Epoch 2390/4000: train_loss=0.4697  test_loss=2.6056  λ_max=85.1428\n",
      "[SGD | lr=0.01] Epoch 2391/4000: train_loss=0.4646  test_loss=2.6035  λ_max=82.7546\n",
      "[SGD | lr=0.01] Epoch 2392/4000: train_loss=0.4604  test_loss=2.6041  λ_max=86.0079\n",
      "[SGD | lr=0.01] Epoch 2393/4000: train_loss=0.4561  test_loss=2.6030  λ_max=84.5630\n",
      "[SGD | lr=0.01] Iter 38300: loss=0.4675\n",
      "[SGD | lr=0.01] Epoch 2394/4000: train_loss=0.4585  test_loss=2.6033  λ_max=83.0809\n",
      "[SGD | lr=0.01] Epoch 2395/4000: train_loss=0.4595  test_loss=2.6032  λ_max=83.7196\n",
      "[SGD | lr=0.01] Epoch 2396/4000: train_loss=0.4614  test_loss=2.6025  λ_max=87.4174\n",
      "[SGD | lr=0.01] Epoch 2397/4000: train_loss=0.4575  test_loss=2.6018  λ_max=84.2932\n",
      "[SGD | lr=0.01] Epoch 2398/4000: train_loss=0.4593  test_loss=2.6017  λ_max=84.4592\n",
      "[SGD | lr=0.01] Epoch 2399/4000: train_loss=0.4614  test_loss=2.6040  λ_max=75.2146\n",
      "[SGD | lr=0.01] Iter 38400: loss=0.4524\n",
      "[SGD | lr=0.01] Epoch 2400/4000: train_loss=0.4563  test_loss=2.6034  λ_max=84.0393\n",
      "[SGD | lr=0.01] Epoch 2401/4000: train_loss=0.4526  test_loss=2.6041  λ_max=85.2922\n",
      "[SGD | lr=0.01] Epoch 2402/4000: train_loss=0.4507  test_loss=2.6044  λ_max=84.5304\n",
      "[SGD | lr=0.01] Epoch 2403/4000: train_loss=0.4488  test_loss=2.6036  λ_max=79.3202\n",
      "[SGD | lr=0.01] Epoch 2404/4000: train_loss=0.4508  test_loss=2.6061  λ_max=83.4163\n",
      "[SGD | lr=0.01] Epoch 2405/4000: train_loss=0.4598  test_loss=2.6099  λ_max=86.5716\n",
      "[SGD | lr=0.01] Epoch 2406/4000: train_loss=0.4614  test_loss=2.6086  λ_max=81.6222\n",
      "[SGD | lr=0.01] Iter 38500: loss=0.4511\n",
      "[SGD | lr=0.01] Epoch 2407/4000: train_loss=0.4541  test_loss=2.6052  λ_max=80.9956\n",
      "[SGD | lr=0.01] Epoch 2408/4000: train_loss=0.4510  test_loss=2.6055  λ_max=83.8118\n",
      "[SGD | lr=0.01] Epoch 2409/4000: train_loss=0.4465  test_loss=2.6069  λ_max=81.4167\n",
      "[SGD | lr=0.01] Epoch 2410/4000: train_loss=0.4441  test_loss=2.6067  λ_max=83.2996\n",
      "[SGD | lr=0.01] Epoch 2411/4000: train_loss=0.4448  test_loss=2.6076  λ_max=81.4355\n",
      "[SGD | lr=0.01] Epoch 2412/4000: train_loss=0.4466  test_loss=2.6089  λ_max=82.4810\n",
      "[SGD | lr=0.01] Iter 38600: loss=0.4541\n",
      "[SGD | lr=0.01] Epoch 2413/4000: train_loss=0.4543  test_loss=2.6129  λ_max=81.5888\n",
      "[SGD | lr=0.01] Epoch 2414/4000: train_loss=0.4614  test_loss=2.6122  λ_max=82.1862\n",
      "[SGD | lr=0.01] Epoch 2415/4000: train_loss=0.4513  test_loss=2.6119  λ_max=82.4982\n",
      "[SGD | lr=0.01] Epoch 2416/4000: train_loss=0.4570  test_loss=2.6119  λ_max=82.0004\n",
      "[SGD | lr=0.01] Epoch 2417/4000: train_loss=0.4520  test_loss=2.6110  λ_max=86.7428\n",
      "[SGD | lr=0.01] Epoch 2418/4000: train_loss=0.4521  test_loss=2.6114  λ_max=85.1147\n",
      "[SGD | lr=0.01] Iter 38700: loss=0.4583\n",
      "[SGD | lr=0.01] Epoch 2419/4000: train_loss=0.4524  test_loss=2.6118  λ_max=82.7248\n",
      "[SGD | lr=0.01] Epoch 2420/4000: train_loss=0.4530  test_loss=2.6130  λ_max=84.2772\n",
      "[SGD | lr=0.01] Epoch 2421/4000: train_loss=0.4568  test_loss=2.6122  λ_max=80.0139\n",
      "[SGD | lr=0.01] Epoch 2422/4000: train_loss=0.4584  test_loss=2.6106  λ_max=83.8969\n",
      "[SGD | lr=0.01] Epoch 2423/4000: train_loss=0.4479  test_loss=2.6108  λ_max=82.6327\n",
      "[SGD | lr=0.01] Epoch 2424/4000: train_loss=0.4421  test_loss=2.6116  λ_max=82.2549\n",
      "[SGD | lr=0.01] Iter 38800: loss=0.4364\n",
      "[SGD | lr=0.01] Epoch 2425/4000: train_loss=0.4394  test_loss=2.6119  λ_max=83.3455\n",
      "[SGD | lr=0.01] Epoch 2426/4000: train_loss=0.4382  test_loss=2.6120  λ_max=84.0156\n",
      "[SGD | lr=0.01] Epoch 2427/4000: train_loss=0.4383  test_loss=2.6125  λ_max=81.6526\n",
      "[SGD | lr=0.01] Epoch 2428/4000: train_loss=0.4381  test_loss=2.6124  λ_max=83.3501\n",
      "[SGD | lr=0.01] Epoch 2429/4000: train_loss=0.4382  test_loss=2.6136  λ_max=79.7344\n",
      "[SGD | lr=0.01] Epoch 2430/4000: train_loss=0.4395  test_loss=2.6145  λ_max=84.7317\n",
      "[SGD | lr=0.01] Epoch 2431/4000: train_loss=0.4446  test_loss=2.6186  λ_max=83.5159\n",
      "[SGD | lr=0.01] Iter 38900: loss=0.4545\n",
      "[SGD | lr=0.01] Epoch 2432/4000: train_loss=0.4595  test_loss=2.6212  λ_max=87.8351\n",
      "[SGD | lr=0.01] Epoch 2433/4000: train_loss=0.4572  test_loss=2.6218  λ_max=88.6927\n",
      "[SGD | lr=0.01] Epoch 2434/4000: train_loss=0.4478  test_loss=2.6244  λ_max=82.1716\n",
      "[SGD | lr=0.01] Epoch 2435/4000: train_loss=0.4516  test_loss=2.6238  λ_max=83.2650\n",
      "[SGD | lr=0.01] Epoch 2436/4000: train_loss=0.4485  test_loss=2.6230  λ_max=86.5350\n",
      "[SGD | lr=0.01] Epoch 2437/4000: train_loss=0.4559  test_loss=2.6183  λ_max=88.4579\n",
      "[SGD | lr=0.01] Iter 39000: loss=0.4590\n",
      "[SGD | lr=0.01] Epoch 2438/4000: train_loss=0.4546  test_loss=2.6173  λ_max=80.9692\n",
      "[SGD | lr=0.01] Epoch 2439/4000: train_loss=0.4395  test_loss=2.6177  λ_max=84.3989\n",
      "[SGD | lr=0.01] Epoch 2440/4000: train_loss=0.4375  test_loss=2.6190  λ_max=86.4529\n",
      "[SGD | lr=0.01] Epoch 2441/4000: train_loss=0.4360  test_loss=2.6193  λ_max=83.3520\n",
      "[SGD | lr=0.01] Epoch 2442/4000: train_loss=0.4346  test_loss=2.6203  λ_max=83.8440\n",
      "[SGD | lr=0.01] Epoch 2443/4000: train_loss=0.4367  test_loss=2.6217  λ_max=84.0669\n",
      "[SGD | lr=0.01] Iter 39100: loss=0.4430\n",
      "[SGD | lr=0.01] Epoch 2444/4000: train_loss=0.4389  test_loss=2.6244  λ_max=81.7522\n",
      "[SGD | lr=0.01] Epoch 2445/4000: train_loss=0.4515  test_loss=2.6253  λ_max=83.2328\n",
      "[SGD | lr=0.01] Epoch 2446/4000: train_loss=0.4481  test_loss=2.6218  λ_max=81.5893\n",
      "[SGD | lr=0.01] Epoch 2447/4000: train_loss=0.4407  test_loss=2.6220  λ_max=78.8686\n",
      "[SGD | lr=0.01] Epoch 2448/4000: train_loss=0.4471  test_loss=2.6242  λ_max=82.6525\n",
      "[SGD | lr=0.01] Epoch 2449/4000: train_loss=0.4426  test_loss=2.6243  λ_max=84.1452\n",
      "[SGD | lr=0.01] Iter 39200: loss=0.4433\n",
      "[SGD | lr=0.01] Epoch 2450/4000: train_loss=0.4384  test_loss=2.6239  λ_max=82.9764\n",
      "[SGD | lr=0.01] Epoch 2451/4000: train_loss=0.4416  test_loss=2.6221  λ_max=90.9948\n",
      "[SGD | lr=0.01] Epoch 2452/4000: train_loss=0.4440  test_loss=2.6227  λ_max=87.4915\n",
      "[SGD | lr=0.01] Epoch 2453/4000: train_loss=0.4438  test_loss=2.6256  λ_max=83.8515\n",
      "[SGD | lr=0.01] Epoch 2454/4000: train_loss=0.4464  test_loss=2.6258  λ_max=86.3057\n",
      "[SGD | lr=0.01] Epoch 2455/4000: train_loss=0.4393  test_loss=2.6256  λ_max=86.2390\n",
      "[SGD | lr=0.01] Epoch 2456/4000: train_loss=0.4462  test_loss=2.6252  λ_max=86.8370\n",
      "[SGD | lr=0.01] Iter 39300: loss=0.4406\n",
      "[SGD | lr=0.01] Epoch 2457/4000: train_loss=0.4414  test_loss=2.6247  λ_max=86.8919\n",
      "[SGD | lr=0.01] Epoch 2458/4000: train_loss=0.4411  test_loss=2.6223  λ_max=87.3476\n",
      "[SGD | lr=0.01] Epoch 2459/4000: train_loss=0.4478  test_loss=2.6238  λ_max=85.2921\n",
      "[SGD | lr=0.01] Epoch 2460/4000: train_loss=0.4447  test_loss=2.6253  λ_max=84.0429\n",
      "[SGD | lr=0.01] Epoch 2461/4000: train_loss=0.4340  test_loss=2.6264  λ_max=81.3350\n",
      "[SGD | lr=0.01] Epoch 2462/4000: train_loss=0.4296  test_loss=2.6253  λ_max=84.2158\n",
      "[SGD | lr=0.01] Iter 39400: loss=0.4266\n",
      "[SGD | lr=0.01] Epoch 2463/4000: train_loss=0.4278  test_loss=2.6267  λ_max=84.5663\n",
      "[SGD | lr=0.01] Epoch 2464/4000: train_loss=0.4269  test_loss=2.6270  λ_max=85.0592\n",
      "[SGD | lr=0.01] Epoch 2465/4000: train_loss=0.4270  test_loss=2.6286  λ_max=83.2588\n",
      "[SGD | lr=0.01] Epoch 2466/4000: train_loss=0.4268  test_loss=2.6288  λ_max=83.8208\n",
      "[SGD | lr=0.01] Epoch 2467/4000: train_loss=0.4272  test_loss=2.6302  λ_max=84.7317\n",
      "[SGD | lr=0.01] Epoch 2468/4000: train_loss=0.4293  test_loss=2.6319  λ_max=87.1599\n",
      "[SGD | lr=0.01] Iter 39500: loss=0.4377\n",
      "[SGD | lr=0.01] Epoch 2469/4000: train_loss=0.4444  test_loss=2.6361  λ_max=86.1828\n",
      "[SGD | lr=0.01] Epoch 2470/4000: train_loss=0.4511  test_loss=2.6370  λ_max=83.2327\n",
      "[SGD | lr=0.01] Epoch 2471/4000: train_loss=0.4446  test_loss=2.6371  λ_max=81.8931\n",
      "[SGD | lr=0.01] Epoch 2472/4000: train_loss=0.4452  test_loss=2.6355  λ_max=83.4190\n",
      "[SGD | lr=0.01] Epoch 2473/4000: train_loss=0.4376  test_loss=2.6324  λ_max=84.8682\n",
      "[SGD | lr=0.01] Epoch 2474/4000: train_loss=0.4418  test_loss=2.6316  λ_max=84.8019\n",
      "[SGD | lr=0.01] Iter 39600: loss=0.4330\n",
      "[SGD | lr=0.01] Epoch 2475/4000: train_loss=0.4371  test_loss=2.6306  λ_max=88.4246\n",
      "[SGD | lr=0.01] Epoch 2476/4000: train_loss=0.4360  test_loss=2.6322  λ_max=86.3024\n",
      "[SGD | lr=0.01] Epoch 2477/4000: train_loss=0.4359  test_loss=2.6341  λ_max=87.6430\n",
      "[SGD | lr=0.01] Epoch 2478/4000: train_loss=0.4333  test_loss=2.6335  λ_max=80.8802\n",
      "[SGD | lr=0.01] Epoch 2479/4000: train_loss=0.4371  test_loss=2.6347  λ_max=81.2124\n",
      "[SGD | lr=0.01] Epoch 2480/4000: train_loss=0.4367  test_loss=2.6356  λ_max=83.0266\n",
      "[SGD | lr=0.01] Epoch 2481/4000: train_loss=0.4294  test_loss=2.6352  λ_max=82.4539\n",
      "[SGD | lr=0.01] Iter 39700: loss=0.4305\n",
      "[SGD | lr=0.01] Epoch 2482/4000: train_loss=0.4253  test_loss=2.6353  λ_max=84.0179\n",
      "[SGD | lr=0.01] Epoch 2483/4000: train_loss=0.4228  test_loss=2.6347  λ_max=87.1742\n",
      "[SGD | lr=0.01] Epoch 2484/4000: train_loss=0.4213  test_loss=2.6346  λ_max=80.9945\n",
      "[SGD | lr=0.01] Epoch 2485/4000: train_loss=0.4210  test_loss=2.6355  λ_max=85.2063\n",
      "[SGD | lr=0.01] Epoch 2486/4000: train_loss=0.4208  test_loss=2.6359  λ_max=79.3346\n",
      "[SGD | lr=0.01] Epoch 2487/4000: train_loss=0.4211  test_loss=2.6357  λ_max=83.3223\n",
      "[SGD | lr=0.01] Iter 39800: loss=0.4168\n",
      "[SGD | lr=0.01] Epoch 2488/4000: train_loss=0.4203  test_loss=2.6361  λ_max=83.4947\n",
      "[SGD | lr=0.01] Epoch 2489/4000: train_loss=0.4206  test_loss=2.6383  λ_max=80.8866\n",
      "[SGD | lr=0.01] Epoch 2490/4000: train_loss=0.4228  test_loss=2.6406  λ_max=82.7590\n",
      "[SGD | lr=0.01] Epoch 2491/4000: train_loss=0.4338  test_loss=2.6454  λ_max=82.9909\n",
      "[SGD | lr=0.01] Epoch 2492/4000: train_loss=0.4404  test_loss=2.6422  λ_max=87.3347\n",
      "[SGD | lr=0.01] Epoch 2493/4000: train_loss=0.4405  test_loss=2.6444  λ_max=90.9646\n",
      "[SGD | lr=0.01] Iter 39900: loss=0.4311\n",
      "[SGD | lr=0.01] Epoch 2494/4000: train_loss=0.4374  test_loss=2.6451  λ_max=88.1671\n",
      "[SGD | lr=0.01] Epoch 2495/4000: train_loss=0.4313  test_loss=2.6473  λ_max=86.2657\n",
      "[SGD | lr=0.01] Epoch 2496/4000: train_loss=0.4361  test_loss=2.6467  λ_max=84.8915\n",
      "[SGD | lr=0.01] Epoch 2497/4000: train_loss=0.4365  test_loss=2.6426  λ_max=83.9079\n",
      "[SGD | lr=0.01] Epoch 2498/4000: train_loss=0.4282  test_loss=2.6403  λ_max=81.7923\n",
      "[SGD | lr=0.01] Epoch 2499/4000: train_loss=0.4240  test_loss=2.6404  λ_max=81.9335\n",
      "[SGD | lr=0.01] Iter 40000: loss=0.4396\n",
      "[SGD | lr=0.01] Epoch 2500/4000: train_loss=0.4241  test_loss=2.6413  λ_max=89.4015\n",
      "[SGD | lr=0.01] Epoch 2501/4000: train_loss=0.4264  test_loss=2.6416  λ_max=85.4703\n",
      "[SGD | lr=0.01] Epoch 2502/4000: train_loss=0.4248  test_loss=2.6442  λ_max=82.1102\n",
      "[SGD | lr=0.01] Epoch 2503/4000: train_loss=0.4249  test_loss=2.6453  λ_max=86.0458\n",
      "[SGD | lr=0.01] Epoch 2504/4000: train_loss=0.4232  test_loss=2.6471  λ_max=82.3508\n",
      "[SGD | lr=0.01] Epoch 2505/4000: train_loss=0.4254  test_loss=2.6486  λ_max=86.7126\n",
      "[SGD | lr=0.01] Epoch 2506/4000: train_loss=0.4212  test_loss=2.6460  λ_max=83.7162\n",
      "[SGD | lr=0.01] Iter 40100: loss=0.4144\n",
      "[SGD | lr=0.01] Epoch 2507/4000: train_loss=0.4212  test_loss=2.6469  λ_max=84.0347\n",
      "[SGD | lr=0.01] Epoch 2508/4000: train_loss=0.4217  test_loss=2.6439  λ_max=85.8706\n",
      "[SGD | lr=0.01] Epoch 2509/4000: train_loss=0.4198  test_loss=2.6432  λ_max=82.5405\n",
      "[SGD | lr=0.01] Epoch 2510/4000: train_loss=0.4189  test_loss=2.6444  λ_max=82.1267\n",
      "[SGD | lr=0.01] Epoch 2511/4000: train_loss=0.4186  test_loss=2.6444  λ_max=90.7236\n",
      "[SGD | lr=0.01] Epoch 2512/4000: train_loss=0.4186  test_loss=2.6477  λ_max=88.1100\n",
      "[SGD | lr=0.01] Iter 40200: loss=0.4414\n",
      "[SGD | lr=0.01] Epoch 2513/4000: train_loss=0.4337  test_loss=2.6506  λ_max=84.5410\n",
      "[SGD | lr=0.01] Epoch 2514/4000: train_loss=0.4350  test_loss=2.6495  λ_max=86.6602\n",
      "[SGD | lr=0.01] Epoch 2515/4000: train_loss=0.4246  test_loss=2.6487  λ_max=85.6482\n",
      "[SGD | lr=0.01] Epoch 2516/4000: train_loss=0.4242  test_loss=2.6468  λ_max=83.4569\n",
      "[SGD | lr=0.01] Epoch 2517/4000: train_loss=0.4192  test_loss=2.6455  λ_max=84.1432\n",
      "[SGD | lr=0.01] Epoch 2518/4000: train_loss=0.4158  test_loss=2.6473  λ_max=83.9121\n",
      "[SGD | lr=0.01] Iter 40300: loss=0.4078\n",
      "[SGD | lr=0.01] Epoch 2519/4000: train_loss=0.4144  test_loss=2.6491  λ_max=84.7651\n",
      "[SGD | lr=0.01] Epoch 2520/4000: train_loss=0.4142  test_loss=2.6493  λ_max=87.6221\n",
      "[SGD | lr=0.01] Epoch 2521/4000: train_loss=0.4158  test_loss=2.6498  λ_max=84.5024\n",
      "[SGD | lr=0.01] Epoch 2522/4000: train_loss=0.4259  test_loss=2.6521  λ_max=84.1765\n",
      "[SGD | lr=0.01] Epoch 2523/4000: train_loss=0.4255  test_loss=2.6514  λ_max=81.3341\n",
      "[SGD | lr=0.01] Epoch 2524/4000: train_loss=0.4211  test_loss=2.6555  λ_max=83.9752\n",
      "[SGD | lr=0.01] Iter 40400: loss=0.4216\n",
      "[SGD | lr=0.01] Epoch 2525/4000: train_loss=0.4206  test_loss=2.6567  λ_max=82.0682\n",
      "[SGD | lr=0.01] Epoch 2526/4000: train_loss=0.4179  test_loss=2.6561  λ_max=85.3477\n",
      "[SGD | lr=0.01] Epoch 2527/4000: train_loss=0.4166  test_loss=2.6567  λ_max=84.4747\n",
      "[SGD | lr=0.01] Epoch 2528/4000: train_loss=0.4214  test_loss=2.6553  λ_max=79.9321\n",
      "[SGD | lr=0.01] Epoch 2529/4000: train_loss=0.4191  test_loss=2.6536  λ_max=85.5670\n",
      "[SGD | lr=0.01] Epoch 2530/4000: train_loss=0.4147  test_loss=2.6535  λ_max=88.2589\n",
      "[SGD | lr=0.01] Epoch 2531/4000: train_loss=0.4134  test_loss=2.6546  λ_max=81.0994\n",
      "[SGD | lr=0.01] Iter 40500: loss=0.4054\n",
      "[SGD | lr=0.01] Epoch 2532/4000: train_loss=0.4116  test_loss=2.6529  λ_max=81.6085\n",
      "[SGD | lr=0.01] Epoch 2533/4000: train_loss=0.4109  test_loss=2.6548  λ_max=84.9536\n",
      "[SGD | lr=0.01] Epoch 2534/4000: train_loss=0.4122  test_loss=2.6554  λ_max=84.0000\n",
      "[SGD | lr=0.01] Epoch 2535/4000: train_loss=0.4161  test_loss=2.6578  λ_max=85.4187\n",
      "[SGD | lr=0.01] Epoch 2536/4000: train_loss=0.4197  test_loss=2.6575  λ_max=85.6514\n",
      "[SGD | lr=0.01] Epoch 2537/4000: train_loss=0.4149  test_loss=2.6577  λ_max=84.8518\n",
      "[SGD | lr=0.01] Iter 40600: loss=0.4133\n",
      "[SGD | lr=0.01] Epoch 2538/4000: train_loss=0.4199  test_loss=2.6591  λ_max=82.4988\n",
      "[SGD | lr=0.01] Epoch 2539/4000: train_loss=0.4199  test_loss=2.6577  λ_max=83.0891\n",
      "[SGD | lr=0.01] Epoch 2540/4000: train_loss=0.4134  test_loss=2.6612  λ_max=86.7008\n",
      "[SGD | lr=0.01] Epoch 2541/4000: train_loss=0.4199  test_loss=2.6634  λ_max=87.0206\n",
      "[SGD | lr=0.01] Epoch 2542/4000: train_loss=0.4184  test_loss=2.6604  λ_max=82.2932\n",
      "[SGD | lr=0.01] Epoch 2543/4000: train_loss=0.4082  test_loss=2.6585  λ_max=83.8398\n",
      "[SGD | lr=0.01] Iter 40700: loss=0.4019\n",
      "[SGD | lr=0.01] Epoch 2544/4000: train_loss=0.4059  test_loss=2.6587  λ_max=81.9592\n",
      "[SGD | lr=0.01] Epoch 2545/4000: train_loss=0.4052  test_loss=2.6583  λ_max=82.7751\n",
      "[SGD | lr=0.01] Epoch 2546/4000: train_loss=0.4043  test_loss=2.6605  λ_max=84.2646\n",
      "[SGD | lr=0.01] Epoch 2547/4000: train_loss=0.4055  test_loss=2.6617  λ_max=83.4535\n",
      "[SGD | lr=0.01] Epoch 2548/4000: train_loss=0.4081  test_loss=2.6632  λ_max=84.9254\n",
      "[SGD | lr=0.01] Epoch 2549/4000: train_loss=0.4226  test_loss=2.6627  λ_max=85.1146\n",
      "[SGD | lr=0.01] Iter 40800: loss=0.4141\n",
      "[SGD | lr=0.01] Epoch 2550/4000: train_loss=0.4235  test_loss=2.6610  λ_max=82.7293\n",
      "[SGD | lr=0.01] Epoch 2551/4000: train_loss=0.4218  test_loss=2.6621  λ_max=89.6352\n",
      "[SGD | lr=0.01] Epoch 2552/4000: train_loss=0.4125  test_loss=2.6637  λ_max=88.3737\n",
      "[SGD | lr=0.01] Epoch 2553/4000: train_loss=0.4095  test_loss=2.6635  λ_max=86.2520\n",
      "[SGD | lr=0.01] Epoch 2554/4000: train_loss=0.4052  test_loss=2.6619  λ_max=89.6564\n",
      "[SGD | lr=0.01] Epoch 2555/4000: train_loss=0.4026  test_loss=2.6623  λ_max=82.0410\n",
      "[SGD | lr=0.01] Epoch 2556/4000: train_loss=0.4018  test_loss=2.6629  λ_max=81.8467\n",
      "[SGD | lr=0.01] Iter 40900: loss=0.4074\n",
      "[SGD | lr=0.01] Epoch 2557/4000: train_loss=0.4007  test_loss=2.6634  λ_max=90.1732\n",
      "[SGD | lr=0.01] Epoch 2558/4000: train_loss=0.4006  test_loss=2.6638  λ_max=85.0214\n",
      "[SGD | lr=0.01] Epoch 2559/4000: train_loss=0.4007  test_loss=2.6642  λ_max=86.7621\n",
      "[SGD | lr=0.01] Epoch 2560/4000: train_loss=0.4030  test_loss=2.6646  λ_max=84.7012\n",
      "[SGD | lr=0.01] Epoch 2561/4000: train_loss=0.4121  test_loss=2.6690  λ_max=92.0419\n",
      "[SGD | lr=0.01] Epoch 2562/4000: train_loss=0.4277  test_loss=2.6722  λ_max=87.5960\n",
      "[SGD | lr=0.01] Iter 41000: loss=0.4140\n",
      "[SGD | lr=0.01] Epoch 2563/4000: train_loss=0.4157  test_loss=2.6733  λ_max=89.4515\n",
      "[SGD | lr=0.01] Epoch 2564/4000: train_loss=0.4202  test_loss=2.6704  λ_max=82.7880\n",
      "[SGD | lr=0.01] Epoch 2565/4000: train_loss=0.4195  test_loss=2.6709  λ_max=87.0930\n",
      "[SGD | lr=0.01] Epoch 2566/4000: train_loss=0.4167  test_loss=2.6671  λ_max=88.7847\n",
      "[SGD | lr=0.01] Epoch 2567/4000: train_loss=0.4148  test_loss=2.6660  λ_max=86.7019\n",
      "[SGD | lr=0.01] Epoch 2568/4000: train_loss=0.4085  test_loss=2.6672  λ_max=87.7295\n",
      "[SGD | lr=0.01] Iter 41100: loss=0.4050\n",
      "[SGD | lr=0.01] Epoch 2569/4000: train_loss=0.4014  test_loss=2.6688  λ_max=86.5511\n",
      "[SGD | lr=0.01] Epoch 2570/4000: train_loss=0.4007  test_loss=2.6705  λ_max=89.7903\n",
      "[SGD | lr=0.01] Epoch 2571/4000: train_loss=0.3990  test_loss=2.6704  λ_max=89.7244\n",
      "[SGD | lr=0.01] Epoch 2572/4000: train_loss=0.3996  test_loss=2.6725  λ_max=83.9397\n",
      "[SGD | lr=0.01] Epoch 2573/4000: train_loss=0.4049  test_loss=2.6746  λ_max=85.4874\n",
      "[SGD | lr=0.01] Epoch 2574/4000: train_loss=0.4153  test_loss=2.6760  λ_max=87.0563\n",
      "[SGD | lr=0.01] Iter 41200: loss=0.4083\n",
      "[SGD | lr=0.01] Epoch 2575/4000: train_loss=0.4045  test_loss=2.6730  λ_max=87.2947\n",
      "[SGD | lr=0.01] Epoch 2576/4000: train_loss=0.3995  test_loss=2.6733  λ_max=84.3974\n",
      "[SGD | lr=0.01] Epoch 2577/4000: train_loss=0.4010  test_loss=2.6746  λ_max=86.7699\n",
      "[SGD | lr=0.01] Epoch 2578/4000: train_loss=0.4052  test_loss=2.6757  λ_max=84.7785\n",
      "[SGD | lr=0.01] Epoch 2579/4000: train_loss=0.4139  test_loss=2.6758  λ_max=87.9356\n",
      "[SGD | lr=0.01] Epoch 2580/4000: train_loss=0.4113  test_loss=2.6735  λ_max=83.6952\n",
      "[SGD | lr=0.01] Epoch 2581/4000: train_loss=0.4080  test_loss=2.6729  λ_max=83.5817\n",
      "[SGD | lr=0.01] Iter 41300: loss=0.4049\n",
      "[SGD | lr=0.01] Epoch 2582/4000: train_loss=0.4036  test_loss=2.6731  λ_max=87.2258\n",
      "[SGD | lr=0.01] Epoch 2583/4000: train_loss=0.4016  test_loss=2.6753  λ_max=86.5034\n",
      "[SGD | lr=0.01] Epoch 2584/4000: train_loss=0.4062  test_loss=2.6758  λ_max=87.6721\n",
      "[SGD | lr=0.01] Epoch 2585/4000: train_loss=0.4037  test_loss=2.6742  λ_max=87.0945\n",
      "[SGD | lr=0.01] Epoch 2586/4000: train_loss=0.4011  test_loss=2.6754  λ_max=81.9743\n",
      "[SGD | lr=0.01] Epoch 2587/4000: train_loss=0.3969  test_loss=2.6756  λ_max=91.9840\n",
      "[SGD | lr=0.01] Iter 41400: loss=0.4012\n",
      "[SGD | lr=0.01] Epoch 2588/4000: train_loss=0.3955  test_loss=2.6766  λ_max=86.9656\n",
      "[SGD | lr=0.01] Epoch 2589/4000: train_loss=0.3954  test_loss=2.6774  λ_max=87.3715\n",
      "[SGD | lr=0.01] Epoch 2590/4000: train_loss=0.3965  test_loss=2.6784  λ_max=86.2993\n",
      "[SGD | lr=0.01] Epoch 2591/4000: train_loss=0.3988  test_loss=2.6819  λ_max=86.0081\n",
      "[SGD | lr=0.01] Epoch 2592/4000: train_loss=0.4083  test_loss=2.6804  λ_max=86.0514\n",
      "[SGD | lr=0.01] Epoch 2593/4000: train_loss=0.4050  test_loss=2.6784  λ_max=86.4921\n",
      "[SGD | lr=0.01] Iter 41500: loss=0.4026\n",
      "[SGD | lr=0.01] Epoch 2594/4000: train_loss=0.4067  test_loss=2.6796  λ_max=87.6786\n",
      "[SGD | lr=0.01] Epoch 2595/4000: train_loss=0.4073  test_loss=2.6778  λ_max=83.8432\n",
      "[SGD | lr=0.01] Epoch 2596/4000: train_loss=0.4040  test_loss=2.6784  λ_max=87.2706\n",
      "[SGD | lr=0.01] Epoch 2597/4000: train_loss=0.3986  test_loss=2.6791  λ_max=86.2024\n",
      "[SGD | lr=0.01] Epoch 2598/4000: train_loss=0.3918  test_loss=2.6790  λ_max=85.2033\n",
      "[SGD | lr=0.01] Epoch 2599/4000: train_loss=0.3900  test_loss=2.6791  λ_max=88.8436\n",
      "[SGD | lr=0.01] Iter 41600: loss=0.3919\n",
      "[SGD | lr=0.01] Epoch 2600/4000: train_loss=0.3897  test_loss=2.6797  λ_max=83.5317\n",
      "[SGD | lr=0.01] Epoch 2601/4000: train_loss=0.3894  test_loss=2.6802  λ_max=87.9569\n",
      "[SGD | lr=0.01] Epoch 2602/4000: train_loss=0.3886  test_loss=2.6804  λ_max=89.8376\n",
      "[SGD | lr=0.01] Epoch 2603/4000: train_loss=0.3883  test_loss=2.6800  λ_max=85.4971\n",
      "[SGD | lr=0.01] Epoch 2604/4000: train_loss=0.3890  test_loss=2.6810  λ_max=85.8129\n",
      "[SGD | lr=0.01] Epoch 2605/4000: train_loss=0.3917  test_loss=2.6823  λ_max=89.2508\n",
      "[SGD | lr=0.01] Epoch 2606/4000: train_loss=0.3975  test_loss=2.6849  λ_max=91.3786\n",
      "[SGD | lr=0.01] Iter 41700: loss=0.4093\n",
      "[SGD | lr=0.01] Epoch 2607/4000: train_loss=0.4062  test_loss=2.6856  λ_max=89.9616\n",
      "[SGD | lr=0.01] Epoch 2608/4000: train_loss=0.4028  test_loss=2.6880  λ_max=88.0219\n",
      "[SGD | lr=0.01] Epoch 2609/4000: train_loss=0.4008  test_loss=2.6877  λ_max=86.9224\n",
      "[SGD | lr=0.01] Epoch 2610/4000: train_loss=0.3963  test_loss=2.6885  λ_max=85.9186\n",
      "[SGD | lr=0.01] Epoch 2611/4000: train_loss=0.4069  test_loss=2.6888  λ_max=91.1742\n",
      "[SGD | lr=0.01] Epoch 2612/4000: train_loss=0.4050  test_loss=2.6881  λ_max=83.0823\n",
      "[SGD | lr=0.01] Iter 41800: loss=0.3906\n",
      "[SGD | lr=0.01] Epoch 2613/4000: train_loss=0.3928  test_loss=2.6862  λ_max=87.9244\n",
      "[SGD | lr=0.01] Epoch 2614/4000: train_loss=0.3946  test_loss=2.6868  λ_max=82.1065\n",
      "[SGD | lr=0.01] Epoch 2615/4000: train_loss=0.3956  test_loss=2.6876  λ_max=87.5390\n",
      "[SGD | lr=0.01] Epoch 2616/4000: train_loss=0.3914  test_loss=2.6864  λ_max=86.6091\n",
      "[SGD | lr=0.01] Epoch 2617/4000: train_loss=0.3928  test_loss=2.6892  λ_max=84.2474\n",
      "[SGD | lr=0.01] Epoch 2618/4000: train_loss=0.3965  test_loss=2.6887  λ_max=92.7617\n",
      "[SGD | lr=0.01] Iter 41900: loss=0.4011\n",
      "[SGD | lr=0.01] Epoch 2619/4000: train_loss=0.4004  test_loss=2.6873  λ_max=90.6816\n",
      "[SGD | lr=0.01] Epoch 2620/4000: train_loss=0.3938  test_loss=2.6879  λ_max=88.0439\n",
      "[SGD | lr=0.01] Epoch 2621/4000: train_loss=0.3961  test_loss=2.6885  λ_max=89.6741\n",
      "[SGD | lr=0.01] Epoch 2622/4000: train_loss=0.4029  test_loss=2.6870  λ_max=86.7750\n",
      "[SGD | lr=0.01] Epoch 2623/4000: train_loss=0.3900  test_loss=2.6868  λ_max=83.9253\n",
      "[SGD | lr=0.01] Epoch 2624/4000: train_loss=0.3897  test_loss=2.6889  λ_max=89.0853\n",
      "[SGD | lr=0.01] Iter 42000: loss=0.3963\n",
      "[SGD | lr=0.01] Epoch 2625/4000: train_loss=0.3950  test_loss=2.6880  λ_max=91.6701\n",
      "[SGD | lr=0.01] Epoch 2626/4000: train_loss=0.3897  test_loss=2.6890  λ_max=85.0798\n",
      "[SGD | lr=0.01] Epoch 2627/4000: train_loss=0.3841  test_loss=2.6897  λ_max=86.9637\n",
      "[SGD | lr=0.01] Epoch 2628/4000: train_loss=0.3824  test_loss=2.6902  λ_max=83.5050\n",
      "[SGD | lr=0.01] Epoch 2629/4000: train_loss=0.3819  test_loss=2.6907  λ_max=91.6542\n",
      "[SGD | lr=0.01] Epoch 2630/4000: train_loss=0.3815  test_loss=2.6917  λ_max=88.2315\n",
      "[SGD | lr=0.01] Epoch 2631/4000: train_loss=0.3811  test_loss=2.6920  λ_max=86.7472\n",
      "[SGD | lr=0.01] Iter 42100: loss=0.3865\n",
      "[SGD | lr=0.01] Epoch 2632/4000: train_loss=0.3810  test_loss=2.6925  λ_max=83.6353\n",
      "[SGD | lr=0.01] Epoch 2633/4000: train_loss=0.3810  test_loss=2.6934  λ_max=86.7989\n",
      "[SGD | lr=0.01] Epoch 2634/4000: train_loss=0.3830  test_loss=2.6953  λ_max=84.5015\n",
      "[SGD | lr=0.01] Epoch 2635/4000: train_loss=0.3941  test_loss=2.7013  λ_max=86.5814\n",
      "[SGD | lr=0.01] Epoch 2636/4000: train_loss=0.4050  test_loss=2.7015  λ_max=90.9384\n",
      "[SGD | lr=0.01] Epoch 2637/4000: train_loss=0.3981  test_loss=2.6941  λ_max=84.7425\n",
      "[SGD | lr=0.01] Iter 42200: loss=0.4009\n",
      "[SGD | lr=0.01] Epoch 2638/4000: train_loss=0.4008  test_loss=2.6985  λ_max=88.9391\n",
      "[SGD | lr=0.01] Epoch 2639/4000: train_loss=0.3990  test_loss=2.7019  λ_max=89.1348\n",
      "[SGD | lr=0.01] Epoch 2640/4000: train_loss=0.3969  test_loss=2.6986  λ_max=87.8247\n",
      "[SGD | lr=0.01] Epoch 2641/4000: train_loss=0.3909  test_loss=2.6957  λ_max=89.7976\n",
      "[SGD | lr=0.01] Epoch 2642/4000: train_loss=0.3870  test_loss=2.6959  λ_max=83.4476\n",
      "[SGD | lr=0.01] Epoch 2643/4000: train_loss=0.3858  test_loss=2.6977  λ_max=87.2437\n",
      "[SGD | lr=0.01] Iter 42300: loss=0.3897\n",
      "[SGD | lr=0.01] Epoch 2644/4000: train_loss=0.3835  test_loss=2.6984  λ_max=85.1624\n",
      "[SGD | lr=0.01] Epoch 2645/4000: train_loss=0.3827  test_loss=2.6978  λ_max=87.9631\n",
      "[SGD | lr=0.01] Epoch 2646/4000: train_loss=0.3832  test_loss=2.6988  λ_max=87.9059\n",
      "[SGD | lr=0.01] Epoch 2647/4000: train_loss=0.3820  test_loss=2.7002  λ_max=86.7902\n",
      "[SGD | lr=0.01] Epoch 2648/4000: train_loss=0.3831  test_loss=2.6988  λ_max=84.4363\n",
      "[SGD | lr=0.01] Epoch 2649/4000: train_loss=0.3800  test_loss=2.6975  λ_max=92.2733\n",
      "[SGD | lr=0.01] Iter 42400: loss=0.3714\n",
      "[SGD | lr=0.01] Epoch 2650/4000: train_loss=0.3778  test_loss=2.6982  λ_max=85.2445\n",
      "[SGD | lr=0.01] Epoch 2651/4000: train_loss=0.3777  test_loss=2.6996  λ_max=88.5074\n",
      "[SGD | lr=0.01] Epoch 2652/4000: train_loss=0.3791  test_loss=2.6996  λ_max=87.0206\n",
      "[SGD | lr=0.01] Epoch 2653/4000: train_loss=0.3788  test_loss=2.6998  λ_max=89.9652\n",
      "[SGD | lr=0.01] Epoch 2654/4000: train_loss=0.3837  test_loss=2.7002  λ_max=90.4458\n",
      "[SGD | lr=0.01] Epoch 2655/4000: train_loss=0.3906  test_loss=2.7013  λ_max=93.1090\n",
      "[SGD | lr=0.01] Epoch 2656/4000: train_loss=0.3844  test_loss=2.7041  λ_max=88.9764\n",
      "[SGD | lr=0.01] Iter 42500: loss=0.3749\n",
      "[SGD | lr=0.01] Epoch 2657/4000: train_loss=0.3842  test_loss=2.7060  λ_max=91.8334\n",
      "[SGD | lr=0.01] Epoch 2658/4000: train_loss=0.3883  test_loss=2.7071  λ_max=89.5507\n",
      "[SGD | lr=0.01] Epoch 2659/4000: train_loss=0.3951  test_loss=2.7093  λ_max=91.6765\n",
      "[SGD | lr=0.01] Epoch 2660/4000: train_loss=0.3977  test_loss=2.7056  λ_max=86.9876\n",
      "[SGD | lr=0.01] Epoch 2661/4000: train_loss=0.3884  test_loss=2.7031  λ_max=85.1969\n",
      "[SGD | lr=0.01] Epoch 2662/4000: train_loss=0.3826  test_loss=2.7044  λ_max=88.4138\n",
      "[SGD | lr=0.01] Iter 42600: loss=0.3842\n",
      "[SGD | lr=0.01] Epoch 2663/4000: train_loss=0.3847  test_loss=2.7045  λ_max=90.4053\n",
      "[SGD | lr=0.01] Epoch 2664/4000: train_loss=0.3767  test_loss=2.7046  λ_max=85.5557\n",
      "[SGD | lr=0.01] Epoch 2665/4000: train_loss=0.3731  test_loss=2.7049  λ_max=86.8543\n",
      "[SGD | lr=0.01] Epoch 2666/4000: train_loss=0.3725  test_loss=2.7053  λ_max=85.6358\n",
      "[SGD | lr=0.01] Epoch 2667/4000: train_loss=0.3724  test_loss=2.7062  λ_max=85.3455\n",
      "[SGD | lr=0.01] Epoch 2668/4000: train_loss=0.3716  test_loss=2.7064  λ_max=88.2158\n",
      "[SGD | lr=0.01] Iter 42700: loss=0.3750\n",
      "[SGD | lr=0.01] Epoch 2669/4000: train_loss=0.3718  test_loss=2.7072  λ_max=87.7771\n",
      "[SGD | lr=0.01] Epoch 2670/4000: train_loss=0.3722  test_loss=2.7067  λ_max=90.1823\n",
      "[SGD | lr=0.01] Epoch 2671/4000: train_loss=0.3739  test_loss=2.7073  λ_max=90.0367\n",
      "[SGD | lr=0.01] Epoch 2672/4000: train_loss=0.3759  test_loss=2.7126  λ_max=90.4776\n",
      "[SGD | lr=0.01] Epoch 2673/4000: train_loss=0.3955  test_loss=2.7183  λ_max=88.2239\n",
      "[SGD | lr=0.01] Epoch 2674/4000: train_loss=0.3951  test_loss=2.7180  λ_max=88.7037\n",
      "[SGD | lr=0.01] Iter 42800: loss=0.3859\n",
      "[SGD | lr=0.01] Epoch 2675/4000: train_loss=0.3873  test_loss=2.7157  λ_max=86.5732\n",
      "[SGD | lr=0.01] Epoch 2676/4000: train_loss=0.3880  test_loss=2.7134  λ_max=86.3626\n",
      "[SGD | lr=0.01] Epoch 2677/4000: train_loss=0.3778  test_loss=2.7113  λ_max=91.0605\n",
      "[SGD | lr=0.01] Epoch 2678/4000: train_loss=0.3748  test_loss=2.7112  λ_max=85.9100\n",
      "[SGD | lr=0.01] Epoch 2679/4000: train_loss=0.3788  test_loss=2.7123  λ_max=86.8362\n",
      "[SGD | lr=0.01] Epoch 2680/4000: train_loss=0.3759  test_loss=2.7130  λ_max=86.6620\n",
      "[SGD | lr=0.01] Epoch 2681/4000: train_loss=0.3743  test_loss=2.7133  λ_max=86.8678\n",
      "[SGD | lr=0.01] Iter 42900: loss=0.3727\n",
      "[SGD | lr=0.01] Epoch 2682/4000: train_loss=0.3723  test_loss=2.7127  λ_max=86.1507\n",
      "[SGD | lr=0.01] Epoch 2683/4000: train_loss=0.3732  test_loss=2.7138  λ_max=87.2868\n",
      "[SGD | lr=0.01] Epoch 2684/4000: train_loss=0.3735  test_loss=2.7142  λ_max=92.6027\n",
      "[SGD | lr=0.01] Epoch 2685/4000: train_loss=0.3817  test_loss=2.7186  λ_max=90.5725\n",
      "[SGD | lr=0.01] Epoch 2686/4000: train_loss=0.3886  test_loss=2.7150  λ_max=91.3041\n",
      "[SGD | lr=0.01] Epoch 2687/4000: train_loss=0.3823  test_loss=2.7182  λ_max=86.8244\n",
      "[SGD | lr=0.01] Iter 43000: loss=0.3749\n",
      "[SGD | lr=0.01] Epoch 2688/4000: train_loss=0.3731  test_loss=2.7173  λ_max=91.6959\n",
      "[SGD | lr=0.01] Epoch 2689/4000: train_loss=0.3692  test_loss=2.7159  λ_max=84.0593\n",
      "[SGD | lr=0.01] Epoch 2690/4000: train_loss=0.3677  test_loss=2.7151  λ_max=90.6666\n",
      "[SGD | lr=0.01] Epoch 2691/4000: train_loss=0.3663  test_loss=2.7151  λ_max=89.5657\n",
      "[SGD | lr=0.01] Epoch 2692/4000: train_loss=0.3661  test_loss=2.7155  λ_max=84.6498\n",
      "[SGD | lr=0.01] Epoch 2693/4000: train_loss=0.3660  test_loss=2.7163  λ_max=90.0846\n",
      "[SGD | lr=0.01] Iter 43100: loss=0.3723\n",
      "[SGD | lr=0.01] Epoch 2694/4000: train_loss=0.3664  test_loss=2.7178  λ_max=86.1580\n",
      "[SGD | lr=0.01] Epoch 2695/4000: train_loss=0.3667  test_loss=2.7186  λ_max=91.4101\n",
      "[SGD | lr=0.01] Epoch 2696/4000: train_loss=0.3669  test_loss=2.7191  λ_max=86.6316\n",
      "[SGD | lr=0.01] Epoch 2697/4000: train_loss=0.3752  test_loss=2.7274  λ_max=84.1485\n",
      "[SGD | lr=0.01] Epoch 2698/4000: train_loss=0.3872  test_loss=2.7308  λ_max=87.6731\n",
      "[SGD | lr=0.01] Epoch 2699/4000: train_loss=0.3841  test_loss=2.7255  λ_max=90.0032\n",
      "[SGD | lr=0.01] Iter 43200: loss=0.3791\n",
      "[SGD | lr=0.01] Epoch 2700/4000: train_loss=0.3815  test_loss=2.7233  λ_max=86.0378\n",
      "[SGD | lr=0.01] Epoch 2701/4000: train_loss=0.3784  test_loss=2.7185  λ_max=90.6156\n",
      "[SGD | lr=0.01] Epoch 2702/4000: train_loss=0.3763  test_loss=2.7210  λ_max=91.4325\n",
      "[SGD | lr=0.01] Epoch 2703/4000: train_loss=0.3819  test_loss=2.7227  λ_max=89.8524\n",
      "[SGD | lr=0.01] Epoch 2704/4000: train_loss=0.3788  test_loss=2.7214  λ_max=91.9971\n",
      "[SGD | lr=0.01] Epoch 2705/4000: train_loss=0.3802  test_loss=2.7227  λ_max=87.2201\n",
      "[SGD | lr=0.01] Epoch 2706/4000: train_loss=0.3760  test_loss=2.7258  λ_max=89.8010\n",
      "[SGD | lr=0.01] Iter 43300: loss=0.3766\n",
      "[SGD | lr=0.01] Epoch 2707/4000: train_loss=0.3718  test_loss=2.7247  λ_max=87.5160\n",
      "[SGD | lr=0.01] Epoch 2708/4000: train_loss=0.3679  test_loss=2.7222  λ_max=90.7719\n",
      "[SGD | lr=0.01] Epoch 2709/4000: train_loss=0.3650  test_loss=2.7219  λ_max=92.0643\n",
      "[SGD | lr=0.01] Epoch 2710/4000: train_loss=0.3627  test_loss=2.7222  λ_max=90.6576\n",
      "[SGD | lr=0.01] Epoch 2711/4000: train_loss=0.3619  test_loss=2.7229  λ_max=91.9963\n",
      "[SGD | lr=0.01] Epoch 2712/4000: train_loss=0.3613  test_loss=2.7235  λ_max=90.1441\n",
      "[SGD | lr=0.01] Iter 43400: loss=0.3638\n",
      "[SGD | lr=0.01] Epoch 2713/4000: train_loss=0.3609  test_loss=2.7234  λ_max=91.1607\n",
      "[SGD | lr=0.01] Epoch 2714/4000: train_loss=0.3611  test_loss=2.7235  λ_max=89.4614\n",
      "[SGD | lr=0.01] Epoch 2715/4000: train_loss=0.3608  test_loss=2.7240  λ_max=91.6333\n",
      "[SGD | lr=0.01] Epoch 2716/4000: train_loss=0.3608  test_loss=2.7251  λ_max=91.9296\n",
      "[SGD | lr=0.01] Epoch 2717/4000: train_loss=0.3612  test_loss=2.7261  λ_max=93.1075\n",
      "[SGD | lr=0.01] Epoch 2718/4000: train_loss=0.3628  test_loss=2.7278  λ_max=84.3282\n",
      "[SGD | lr=0.01] Iter 43500: loss=0.3654\n",
      "[SGD | lr=0.01] Epoch 2719/4000: train_loss=0.3691  test_loss=2.7342  λ_max=87.2296\n",
      "[SGD | lr=0.01] Epoch 2720/4000: train_loss=0.3811  test_loss=2.7352  λ_max=89.7735\n",
      "[SGD | lr=0.01] Epoch 2721/4000: train_loss=0.3820  test_loss=2.7333  λ_max=93.3681\n",
      "[SGD | lr=0.01] Epoch 2722/4000: train_loss=0.3785  test_loss=2.7298  λ_max=88.4787\n",
      "[SGD | lr=0.01] Epoch 2723/4000: train_loss=0.3714  test_loss=2.7299  λ_max=90.1587\n",
      "[SGD | lr=0.01] Epoch 2724/4000: train_loss=0.3743  test_loss=2.7309  λ_max=88.0827\n",
      "[SGD | lr=0.01] Iter 43600: loss=0.3565\n",
      "[SGD | lr=0.01] Epoch 2725/4000: train_loss=0.3715  test_loss=2.7295  λ_max=85.4515\n",
      "[SGD | lr=0.01] Epoch 2726/4000: train_loss=0.3741  test_loss=2.7279  λ_max=89.8754\n",
      "[SGD | lr=0.01] Epoch 2727/4000: train_loss=0.3672  test_loss=2.7276  λ_max=89.7898\n",
      "[SGD | lr=0.01] Epoch 2728/4000: train_loss=0.3599  test_loss=2.7293  λ_max=89.3728\n",
      "[SGD | lr=0.01] Epoch 2729/4000: train_loss=0.3583  test_loss=2.7299  λ_max=87.9311\n",
      "[SGD | lr=0.01] Epoch 2730/4000: train_loss=0.3571  test_loss=2.7303  λ_max=89.8414\n",
      "[SGD | lr=0.01] Epoch 2731/4000: train_loss=0.3570  test_loss=2.7301  λ_max=87.7279\n",
      "[SGD | lr=0.01] Iter 43700: loss=0.3540\n",
      "[SGD | lr=0.01] Epoch 2732/4000: train_loss=0.3574  test_loss=2.7310  λ_max=89.4055\n",
      "[SGD | lr=0.01] Epoch 2733/4000: train_loss=0.3575  test_loss=2.7299  λ_max=93.1514\n",
      "[SGD | lr=0.01] Epoch 2734/4000: train_loss=0.3585  test_loss=2.7308  λ_max=87.4888\n",
      "[SGD | lr=0.01] Epoch 2735/4000: train_loss=0.3656  test_loss=2.7319  λ_max=91.7946\n",
      "[SGD | lr=0.01] Epoch 2736/4000: train_loss=0.3841  test_loss=2.7322  λ_max=86.5754\n",
      "[SGD | lr=0.01] Epoch 2737/4000: train_loss=0.3716  test_loss=2.7346  λ_max=89.2849\n",
      "[SGD | lr=0.01] Iter 43800: loss=0.3683\n",
      "[SGD | lr=0.01] Epoch 2738/4000: train_loss=0.3697  test_loss=2.7367  λ_max=94.9294\n",
      "[SGD | lr=0.01] Epoch 2739/4000: train_loss=0.3683  test_loss=2.7354  λ_max=87.6249\n",
      "[SGD | lr=0.01] Epoch 2740/4000: train_loss=0.3652  test_loss=2.7348  λ_max=92.0782\n",
      "[SGD | lr=0.01] Epoch 2741/4000: train_loss=0.3746  test_loss=2.7343  λ_max=93.4249\n",
      "[SGD | lr=0.01] Epoch 2742/4000: train_loss=0.3685  test_loss=2.7334  λ_max=88.9984\n",
      "[SGD | lr=0.01] Epoch 2743/4000: train_loss=0.3621  test_loss=2.7365  λ_max=93.5783\n",
      "[SGD | lr=0.01] Iter 43900: loss=0.3556\n",
      "[SGD | lr=0.01] Epoch 2744/4000: train_loss=0.3623  test_loss=2.7373  λ_max=94.2515\n",
      "[SGD | lr=0.01] Epoch 2745/4000: train_loss=0.3619  test_loss=2.7380  λ_max=89.5391\n",
      "[SGD | lr=0.01] Epoch 2746/4000: train_loss=0.3566  test_loss=2.7363  λ_max=89.2073\n",
      "[SGD | lr=0.01] Epoch 2747/4000: train_loss=0.3539  test_loss=2.7367  λ_max=89.0293\n",
      "[SGD | lr=0.01] Epoch 2748/4000: train_loss=0.3532  test_loss=2.7378  λ_max=88.6874\n",
      "[SGD | lr=0.01] Epoch 2749/4000: train_loss=0.3528  test_loss=2.7376  λ_max=93.2295\n",
      "[SGD | lr=0.01] Iter 44000: loss=0.3643\n",
      "[SGD | lr=0.01] Epoch 2750/4000: train_loss=0.3527  test_loss=2.7373  λ_max=89.8654\n",
      "[SGD | lr=0.01] Epoch 2751/4000: train_loss=0.3519  test_loss=2.7381  λ_max=91.9406\n",
      "[SGD | lr=0.01] Epoch 2752/4000: train_loss=0.3519  test_loss=2.7383  λ_max=89.8857\n",
      "[SGD | lr=0.01] Epoch 2753/4000: train_loss=0.3518  test_loss=2.7389  λ_max=89.8744\n",
      "[SGD | lr=0.01] Epoch 2754/4000: train_loss=0.3518  test_loss=2.7408  λ_max=86.0365\n",
      "[SGD | lr=0.01] Epoch 2755/4000: train_loss=0.3542  test_loss=2.7413  λ_max=89.0685\n",
      "[SGD | lr=0.01] Epoch 2756/4000: train_loss=0.3684  test_loss=2.7476  λ_max=93.6388\n",
      "[SGD | lr=0.01] Iter 44100: loss=0.3683\n",
      "[SGD | lr=0.01] Epoch 2757/4000: train_loss=0.3711  test_loss=2.7501  λ_max=89.1822\n",
      "[SGD | lr=0.01] Epoch 2758/4000: train_loss=0.3740  test_loss=2.7471  λ_max=88.4819\n",
      "[SGD | lr=0.01] Epoch 2759/4000: train_loss=0.3720  test_loss=2.7463  λ_max=85.1175\n",
      "[SGD | lr=0.01] Epoch 2760/4000: train_loss=0.3602  test_loss=2.7449  λ_max=91.1462\n",
      "[SGD | lr=0.01] Epoch 2761/4000: train_loss=0.3616  test_loss=2.7461  λ_max=87.9736\n",
      "[SGD | lr=0.01] Epoch 2762/4000: train_loss=0.3544  test_loss=2.7444  λ_max=87.0145\n",
      "[SGD | lr=0.01] Iter 44200: loss=0.3546\n",
      "[SGD | lr=0.01] Epoch 2763/4000: train_loss=0.3513  test_loss=2.7430  λ_max=89.2820\n",
      "[SGD | lr=0.01] Epoch 2764/4000: train_loss=0.3504  test_loss=2.7430  λ_max=93.1323\n",
      "[SGD | lr=0.01] Epoch 2765/4000: train_loss=0.3509  test_loss=2.7435  λ_max=91.1483\n",
      "[SGD | lr=0.01] Epoch 2766/4000: train_loss=0.3508  test_loss=2.7425  λ_max=90.8905\n",
      "[SGD | lr=0.01] Epoch 2767/4000: train_loss=0.3515  test_loss=2.7447  λ_max=92.5534\n",
      "[SGD | lr=0.01] Epoch 2768/4000: train_loss=0.3568  test_loss=2.7475  λ_max=92.0371\n",
      "[SGD | lr=0.01] Iter 44300: loss=0.3678\n",
      "[SGD | lr=0.01] Epoch 2769/4000: train_loss=0.3680  test_loss=2.7535  λ_max=89.5772\n",
      "[SGD | lr=0.01] Epoch 2770/4000: train_loss=0.3724  test_loss=2.7506  λ_max=88.6827\n",
      "[SGD | lr=0.01] Epoch 2771/4000: train_loss=0.3630  test_loss=2.7528  λ_max=89.7528\n",
      "[SGD | lr=0.01] Epoch 2772/4000: train_loss=0.3582  test_loss=2.7510  λ_max=92.1436\n",
      "[SGD | lr=0.01] Epoch 2773/4000: train_loss=0.3562  test_loss=2.7507  λ_max=88.8938\n",
      "[SGD | lr=0.01] Epoch 2774/4000: train_loss=0.3583  test_loss=2.7503  λ_max=89.0449\n",
      "[SGD | lr=0.01] Iter 44400: loss=0.3575\n",
      "[SGD | lr=0.01] Epoch 2775/4000: train_loss=0.3582  test_loss=2.7511  λ_max=90.4606\n",
      "[SGD | lr=0.01] Epoch 2776/4000: train_loss=0.3585  test_loss=2.7501  λ_max=92.5899\n",
      "[SGD | lr=0.01] Epoch 2777/4000: train_loss=0.3538  test_loss=2.7499  λ_max=92.9664\n",
      "[SGD | lr=0.01] Epoch 2778/4000: train_loss=0.3489  test_loss=2.7488  λ_max=89.0260\n",
      "[SGD | lr=0.01] Epoch 2779/4000: train_loss=0.3462  test_loss=2.7493  λ_max=90.8261\n",
      "[SGD | lr=0.01] Epoch 2780/4000: train_loss=0.3456  test_loss=2.7498  λ_max=88.2390\n",
      "[SGD | lr=0.01] Epoch 2781/4000: train_loss=0.3455  test_loss=2.7502  λ_max=84.7720\n",
      "[SGD | lr=0.01] Iter 44500: loss=0.3475\n",
      "[SGD | lr=0.01] Epoch 2782/4000: train_loss=0.3452  test_loss=2.7515  λ_max=88.3863\n",
      "[SGD | lr=0.01] Epoch 2783/4000: train_loss=0.3452  test_loss=2.7508  λ_max=94.6552\n",
      "[SGD | lr=0.01] Epoch 2784/4000: train_loss=0.3453  test_loss=2.7515  λ_max=90.1762\n",
      "[SGD | lr=0.01] Epoch 2785/4000: train_loss=0.3473  test_loss=2.7529  λ_max=89.6495\n",
      "[SGD | lr=0.01] Epoch 2786/4000: train_loss=0.3539  test_loss=2.7535  λ_max=91.7473\n",
      "[SGD | lr=0.01] Epoch 2787/4000: train_loss=0.3627  test_loss=2.7556  λ_max=89.2280\n",
      "[SGD | lr=0.01] Iter 44600: loss=0.3583\n",
      "[SGD | lr=0.01] Epoch 2788/4000: train_loss=0.3579  test_loss=2.7537  λ_max=95.2029\n",
      "[SGD | lr=0.01] Epoch 2789/4000: train_loss=0.3515  test_loss=2.7533  λ_max=89.6758\n",
      "[SGD | lr=0.01] Epoch 2790/4000: train_loss=0.3586  test_loss=2.7538  λ_max=89.2761\n",
      "[SGD | lr=0.01] Epoch 2791/4000: train_loss=0.3620  test_loss=2.7594  λ_max=90.0057\n",
      "[SGD | lr=0.01] Epoch 2792/4000: train_loss=0.3695  test_loss=2.7598  λ_max=90.2034\n",
      "[SGD | lr=0.01] Epoch 2793/4000: train_loss=0.3600  test_loss=2.7583  λ_max=87.2516\n",
      "[SGD | lr=0.01] Iter 44700: loss=0.3484\n",
      "[SGD | lr=0.01] Epoch 2794/4000: train_loss=0.3495  test_loss=2.7578  λ_max=94.3092\n",
      "[SGD | lr=0.01] Epoch 2795/4000: train_loss=0.3468  test_loss=2.7564  λ_max=85.9379\n",
      "[SGD | lr=0.01] Epoch 2796/4000: train_loss=0.3447  test_loss=2.7570  λ_max=91.3671\n",
      "[SGD | lr=0.01] Epoch 2797/4000: train_loss=0.3431  test_loss=2.7577  λ_max=88.3484\n",
      "[SGD | lr=0.01] Epoch 2798/4000: train_loss=0.3422  test_loss=2.7573  λ_max=88.4893\n",
      "[SGD | lr=0.01] Epoch 2799/4000: train_loss=0.3418  test_loss=2.7574  λ_max=87.7120\n",
      "[SGD | lr=0.01] Iter 44800: loss=0.3399\n",
      "[SGD | lr=0.01] Epoch 2800/4000: train_loss=0.3413  test_loss=2.7575  λ_max=89.7606\n",
      "[SGD | lr=0.01] Epoch 2801/4000: train_loss=0.3411  test_loss=2.7584  λ_max=92.7211\n",
      "[SGD | lr=0.01] Epoch 2802/4000: train_loss=0.3409  test_loss=2.7592  λ_max=92.2440\n",
      "[SGD | lr=0.01] Epoch 2803/4000: train_loss=0.3409  test_loss=2.7588  λ_max=89.6860\n",
      "[SGD | lr=0.01] Epoch 2804/4000: train_loss=0.3410  test_loss=2.7619  λ_max=90.4051\n",
      "[SGD | lr=0.01] Epoch 2805/4000: train_loss=0.3443  test_loss=2.7646  λ_max=86.3084\n",
      "[SGD | lr=0.01] Epoch 2806/4000: train_loss=0.3546  test_loss=2.7695  λ_max=92.2631\n",
      "[SGD | lr=0.01] Iter 44900: loss=0.3572\n",
      "[SGD | lr=0.01] Epoch 2807/4000: train_loss=0.3582  test_loss=2.7646  λ_max=91.8449\n",
      "[SGD | lr=0.01] Epoch 2808/4000: train_loss=0.3585  test_loss=2.7599  λ_max=87.8316\n",
      "[SGD | lr=0.01] Epoch 2809/4000: train_loss=0.3537  test_loss=2.7594  λ_max=88.9409\n",
      "[SGD | lr=0.01] Epoch 2810/4000: train_loss=0.3550  test_loss=2.7589  λ_max=87.9196\n",
      "[SGD | lr=0.01] Epoch 2811/4000: train_loss=0.3520  test_loss=2.7625  λ_max=91.8615\n",
      "[SGD | lr=0.01] Epoch 2812/4000: train_loss=0.3483  test_loss=2.7634  λ_max=87.8435\n",
      "[SGD | lr=0.01] Iter 45000: loss=0.3425\n",
      "[SGD | lr=0.01] Epoch 2813/4000: train_loss=0.3408  test_loss=2.7634  λ_max=89.7747\n",
      "[SGD | lr=0.01] Epoch 2814/4000: train_loss=0.3388  test_loss=2.7625  λ_max=90.2147\n",
      "[SGD | lr=0.01] Epoch 2815/4000: train_loss=0.3377  test_loss=2.7637  λ_max=85.4774\n",
      "[SGD | lr=0.01] Epoch 2816/4000: train_loss=0.3375  test_loss=2.7639  λ_max=91.3505\n",
      "[SGD | lr=0.01] Epoch 2817/4000: train_loss=0.3373  test_loss=2.7646  λ_max=88.7086\n",
      "[SGD | lr=0.01] Epoch 2818/4000: train_loss=0.3376  test_loss=2.7651  λ_max=93.8749\n",
      "[SGD | lr=0.01] Iter 45100: loss=0.3365\n",
      "[SGD | lr=0.01] Epoch 2819/4000: train_loss=0.3372  test_loss=2.7642  λ_max=89.4083\n",
      "[SGD | lr=0.01] Epoch 2820/4000: train_loss=0.3380  test_loss=2.7640  λ_max=90.0519\n",
      "[SGD | lr=0.01] Epoch 2821/4000: train_loss=0.3452  test_loss=2.7670  λ_max=89.6932\n",
      "[SGD | lr=0.01] Epoch 2822/4000: train_loss=0.3600  test_loss=2.7684  λ_max=90.3162\n",
      "[SGD | lr=0.01] Epoch 2823/4000: train_loss=0.3642  test_loss=2.7665  λ_max=90.5166\n",
      "[SGD | lr=0.01] Epoch 2824/4000: train_loss=0.3480  test_loss=2.7671  λ_max=92.9133\n",
      "[SGD | lr=0.01] Iter 45200: loss=0.3425\n",
      "[SGD | lr=0.01] Epoch 2825/4000: train_loss=0.3509  test_loss=2.7666  λ_max=93.0982\n",
      "[SGD | lr=0.01] Epoch 2826/4000: train_loss=0.3490  test_loss=2.7678  λ_max=92.3915\n",
      "[SGD | lr=0.01] Epoch 2827/4000: train_loss=0.3429  test_loss=2.7695  λ_max=91.4473\n",
      "[SGD | lr=0.01] Epoch 2828/4000: train_loss=0.3385  test_loss=2.7688  λ_max=87.7110\n",
      "[SGD | lr=0.01] Epoch 2829/4000: train_loss=0.3358  test_loss=2.7686  λ_max=89.6711\n",
      "[SGD | lr=0.01] Epoch 2830/4000: train_loss=0.3345  test_loss=2.7688  λ_max=92.6775\n",
      "[SGD | lr=0.01] Epoch 2831/4000: train_loss=0.3343  test_loss=2.7701  λ_max=90.9794\n",
      "[SGD | lr=0.01] Iter 45300: loss=0.3336\n",
      "[SGD | lr=0.01] Epoch 2832/4000: train_loss=0.3339  test_loss=2.7708  λ_max=90.5720\n",
      "[SGD | lr=0.01] Epoch 2833/4000: train_loss=0.3340  test_loss=2.7708  λ_max=96.2673\n",
      "[SGD | lr=0.01] Epoch 2834/4000: train_loss=0.3336  test_loss=2.7712  λ_max=93.5396\n",
      "[SGD | lr=0.01] Epoch 2835/4000: train_loss=0.3346  test_loss=2.7710  λ_max=90.8054\n",
      "[SGD | lr=0.01] Epoch 2836/4000: train_loss=0.3398  test_loss=2.7726  λ_max=89.3923\n",
      "[SGD | lr=0.01] Epoch 2837/4000: train_loss=0.3531  test_loss=2.7755  λ_max=92.8804\n",
      "[SGD | lr=0.01] Iter 45400: loss=0.3520\n",
      "[SGD | lr=0.01] Epoch 2838/4000: train_loss=0.3562  test_loss=2.7762  λ_max=93.0471\n",
      "[SGD | lr=0.01] Epoch 2839/4000: train_loss=0.3478  test_loss=2.7771  λ_max=93.5139\n",
      "[SGD | lr=0.01] Epoch 2840/4000: train_loss=0.3476  test_loss=2.7757  λ_max=94.6839\n",
      "[SGD | lr=0.01] Epoch 2841/4000: train_loss=0.3478  test_loss=2.7750  λ_max=90.0639\n",
      "[SGD | lr=0.01] Epoch 2842/4000: train_loss=0.3490  test_loss=2.7759  λ_max=93.9421\n",
      "[SGD | lr=0.01] Epoch 2843/4000: train_loss=0.3458  test_loss=2.7774  λ_max=87.9138\n",
      "[SGD | lr=0.01] Iter 45500: loss=0.3332\n",
      "[SGD | lr=0.01] Epoch 2844/4000: train_loss=0.3368  test_loss=2.7771  λ_max=87.4727\n",
      "[SGD | lr=0.01] Epoch 2845/4000: train_loss=0.3332  test_loss=2.7752  λ_max=92.4698\n",
      "[SGD | lr=0.01] Epoch 2846/4000: train_loss=0.3311  test_loss=2.7749  λ_max=91.2622\n",
      "[SGD | lr=0.01] Epoch 2847/4000: train_loss=0.3308  test_loss=2.7760  λ_max=95.0230\n",
      "[SGD | lr=0.01] Epoch 2848/4000: train_loss=0.3305  test_loss=2.7765  λ_max=88.2132\n",
      "[SGD | lr=0.01] Epoch 2849/4000: train_loss=0.3305  test_loss=2.7765  λ_max=91.8703\n",
      "[SGD | lr=0.01] Iter 45600: loss=0.3344\n",
      "[SGD | lr=0.01] Epoch 2850/4000: train_loss=0.3303  test_loss=2.7783  λ_max=90.0910\n",
      "[SGD | lr=0.01] Epoch 2851/4000: train_loss=0.3303  test_loss=2.7778  λ_max=93.4449\n",
      "[SGD | lr=0.01] Epoch 2852/4000: train_loss=0.3308  test_loss=2.7796  λ_max=89.7802\n",
      "[SGD | lr=0.01] Epoch 2853/4000: train_loss=0.3312  test_loss=2.7810  λ_max=91.7596\n",
      "[SGD | lr=0.01] Epoch 2854/4000: train_loss=0.3382  test_loss=2.7833  λ_max=90.8806\n",
      "[SGD | lr=0.01] Epoch 2855/4000: train_loss=0.3530  test_loss=2.7856  λ_max=94.6635\n",
      "[SGD | lr=0.01] Epoch 2856/4000: train_loss=0.3485  test_loss=2.7864  λ_max=92.2192\n",
      "[SGD | lr=0.01] Iter 45700: loss=0.3445\n",
      "[SGD | lr=0.01] Epoch 2857/4000: train_loss=0.3475  test_loss=2.7855  λ_max=88.9744\n",
      "[SGD | lr=0.01] Epoch 2858/4000: train_loss=0.3486  test_loss=2.7843  λ_max=90.1994\n",
      "[SGD | lr=0.01] Epoch 2859/4000: train_loss=0.3414  test_loss=2.7830  λ_max=92.5942\n",
      "[SGD | lr=0.01] Epoch 2860/4000: train_loss=0.3405  test_loss=2.7835  λ_max=92.7719\n",
      "[SGD | lr=0.01] Epoch 2861/4000: train_loss=0.3372  test_loss=2.7829  λ_max=89.3988\n",
      "[SGD | lr=0.01] Epoch 2862/4000: train_loss=0.3339  test_loss=2.7839  λ_max=88.4530\n",
      "[SGD | lr=0.01] Iter 45800: loss=0.3330\n",
      "[SGD | lr=0.01] Epoch 2863/4000: train_loss=0.3290  test_loss=2.7824  λ_max=90.6784\n",
      "[SGD | lr=0.01] Epoch 2864/4000: train_loss=0.3277  test_loss=2.7824  λ_max=88.7038\n",
      "[SGD | lr=0.01] Epoch 2865/4000: train_loss=0.3270  test_loss=2.7828  λ_max=91.3691\n",
      "[SGD | lr=0.01] Epoch 2866/4000: train_loss=0.3269  test_loss=2.7824  λ_max=92.5537\n",
      "[SGD | lr=0.01] Epoch 2867/4000: train_loss=0.3265  test_loss=2.7829  λ_max=94.2290\n",
      "[SGD | lr=0.01] Epoch 2868/4000: train_loss=0.3267  test_loss=2.7836  λ_max=87.3600\n",
      "[SGD | lr=0.01] Iter 45900: loss=0.3255\n",
      "[SGD | lr=0.01] Epoch 2869/4000: train_loss=0.3266  test_loss=2.7845  λ_max=89.3079\n",
      "[SGD | lr=0.01] Epoch 2870/4000: train_loss=0.3275  test_loss=2.7848  λ_max=93.8730\n",
      "[SGD | lr=0.01] Epoch 2871/4000: train_loss=0.3301  test_loss=2.7876  λ_max=88.7060\n",
      "[SGD | lr=0.01] Epoch 2872/4000: train_loss=0.3388  test_loss=2.7907  λ_max=92.5313\n",
      "[SGD | lr=0.01] Epoch 2873/4000: train_loss=0.3414  test_loss=2.7912  λ_max=91.5389\n",
      "[SGD | lr=0.01] Epoch 2874/4000: train_loss=0.3438  test_loss=2.7909  λ_max=92.8485\n",
      "[SGD | lr=0.01] Iter 46000: loss=0.3457\n",
      "[SGD | lr=0.01] Epoch 2875/4000: train_loss=0.3516  test_loss=2.7881  λ_max=97.5201\n",
      "[SGD | lr=0.01] Epoch 2876/4000: train_loss=0.3315  test_loss=2.7875  λ_max=93.2400\n",
      "[SGD | lr=0.01] Epoch 2877/4000: train_loss=0.3265  test_loss=2.7877  λ_max=92.1820\n",
      "[SGD | lr=0.01] Epoch 2878/4000: train_loss=0.3255  test_loss=2.7881  λ_max=93.6198\n",
      "[SGD | lr=0.01] Epoch 2879/4000: train_loss=0.3257  test_loss=2.7887  λ_max=90.3011\n",
      "[SGD | lr=0.01] Epoch 2880/4000: train_loss=0.3267  test_loss=2.7887  λ_max=89.4136\n",
      "[SGD | lr=0.01] Epoch 2881/4000: train_loss=0.3284  test_loss=2.7902  λ_max=92.6542\n",
      "[SGD | lr=0.01] Iter 46100: loss=0.3288\n",
      "[SGD | lr=0.01] Epoch 2882/4000: train_loss=0.3317  test_loss=2.7930  λ_max=92.5140\n",
      "[SGD | lr=0.01] Epoch 2883/4000: train_loss=0.3409  test_loss=2.7952  λ_max=91.6400\n",
      "[SGD | lr=0.01] Epoch 2884/4000: train_loss=0.3463  test_loss=2.7944  λ_max=87.8649\n",
      "[SGD | lr=0.01] Epoch 2885/4000: train_loss=0.3373  test_loss=2.7919  λ_max=91.0174\n",
      "[SGD | lr=0.01] Epoch 2886/4000: train_loss=0.3339  test_loss=2.7914  λ_max=95.0465\n",
      "[SGD | lr=0.01] Epoch 2887/4000: train_loss=0.3349  test_loss=2.7903  λ_max=95.5707\n",
      "[SGD | lr=0.01] Iter 46200: loss=0.3378\n",
      "[SGD | lr=0.01] Epoch 2888/4000: train_loss=0.3369  test_loss=2.7939  λ_max=90.7234\n",
      "[SGD | lr=0.01] Epoch 2889/4000: train_loss=0.3273  test_loss=2.7930  λ_max=94.0974\n",
      "[SGD | lr=0.01] Epoch 2890/4000: train_loss=0.3229  test_loss=2.7925  λ_max=89.7568\n",
      "[SGD | lr=0.01] Epoch 2891/4000: train_loss=0.3216  test_loss=2.7931  λ_max=90.6861\n",
      "[SGD | lr=0.01] Epoch 2892/4000: train_loss=0.3216  test_loss=2.7926  λ_max=97.8645\n",
      "[SGD | lr=0.01] Epoch 2893/4000: train_loss=0.3214  test_loss=2.7932  λ_max=91.5332\n",
      "[SGD | lr=0.01] Iter 46300: loss=0.3226\n",
      "[SGD | lr=0.01] Epoch 2894/4000: train_loss=0.3215  test_loss=2.7939  λ_max=91.5393\n",
      "[SGD | lr=0.01] Epoch 2895/4000: train_loss=0.3210  test_loss=2.7946  λ_max=93.7887\n",
      "[SGD | lr=0.01] Epoch 2896/4000: train_loss=0.3205  test_loss=2.7942  λ_max=96.0815\n",
      "[SGD | lr=0.01] Epoch 2897/4000: train_loss=0.3205  test_loss=2.7944  λ_max=91.0307\n",
      "[SGD | lr=0.01] Epoch 2898/4000: train_loss=0.3202  test_loss=2.7944  λ_max=97.3268\n",
      "[SGD | lr=0.01] Epoch 2899/4000: train_loss=0.3201  test_loss=2.7946  λ_max=91.0918\n",
      "[SGD | lr=0.01] Iter 46400: loss=0.3282\n",
      "[SGD | lr=0.01] Epoch 2900/4000: train_loss=0.3231  test_loss=2.7957  λ_max=97.6804\n",
      "[SGD | lr=0.01] Epoch 2901/4000: train_loss=0.3375  test_loss=2.7964  λ_max=97.8653\n",
      "[SGD | lr=0.01] Epoch 2902/4000: train_loss=0.3522  test_loss=2.7997  λ_max=92.4000\n",
      "[SGD | lr=0.01] Epoch 2903/4000: train_loss=0.3391  test_loss=2.8063  λ_max=96.3615\n",
      "[SGD | lr=0.01] Epoch 2904/4000: train_loss=0.3472  test_loss=2.7986  λ_max=91.7198\n",
      "[SGD | lr=0.01] Epoch 2905/4000: train_loss=0.3380  test_loss=2.7986  λ_max=92.3418\n",
      "[SGD | lr=0.01] Epoch 2906/4000: train_loss=0.3253  test_loss=2.7991  λ_max=97.8449\n",
      "[SGD | lr=0.01] Iter 46500: loss=0.3204\n",
      "[SGD | lr=0.01] Epoch 2907/4000: train_loss=0.3211  test_loss=2.7984  λ_max=96.6291\n",
      "[SGD | lr=0.01] Epoch 2908/4000: train_loss=0.3187  test_loss=2.7982  λ_max=93.6767\n",
      "[SGD | lr=0.01] Epoch 2909/4000: train_loss=0.3180  test_loss=2.7989  λ_max=89.8986\n",
      "[SGD | lr=0.01] Epoch 2910/4000: train_loss=0.3178  test_loss=2.7986  λ_max=91.9866\n",
      "[SGD | lr=0.01] Epoch 2911/4000: train_loss=0.3176  test_loss=2.7992  λ_max=94.3834\n",
      "[SGD | lr=0.01] Epoch 2912/4000: train_loss=0.3174  test_loss=2.8000  λ_max=92.5144\n",
      "[SGD | lr=0.01] Iter 46600: loss=0.3161\n",
      "[SGD | lr=0.01] Epoch 2913/4000: train_loss=0.3173  test_loss=2.8013  λ_max=92.8006\n",
      "[SGD | lr=0.01] Epoch 2914/4000: train_loss=0.3172  test_loss=2.8015  λ_max=93.9959\n",
      "[SGD | lr=0.01] Epoch 2915/4000: train_loss=0.3184  test_loss=2.8020  λ_max=90.0084\n",
      "[SGD | lr=0.01] Epoch 2916/4000: train_loss=0.3198  test_loss=2.8033  λ_max=90.0288\n",
      "[SGD | lr=0.01] Epoch 2917/4000: train_loss=0.3280  test_loss=2.8107  λ_max=94.1036\n",
      "[SGD | lr=0.01] Epoch 2918/4000: train_loss=0.3417  test_loss=2.8099  λ_max=90.2026\n",
      "[SGD | lr=0.01] Iter 46700: loss=0.3349\n",
      "[SGD | lr=0.01] Epoch 2919/4000: train_loss=0.3389  test_loss=2.8039  λ_max=91.1133\n",
      "[SGD | lr=0.01] Epoch 2920/4000: train_loss=0.3352  test_loss=2.8037  λ_max=98.4426\n",
      "[SGD | lr=0.01] Epoch 2921/4000: train_loss=0.3299  test_loss=2.8063  λ_max=95.4915\n",
      "[SGD | lr=0.01] Epoch 2922/4000: train_loss=0.3210  test_loss=2.8056  λ_max=92.4748\n",
      "[SGD | lr=0.01] Epoch 2923/4000: train_loss=0.3176  test_loss=2.8052  λ_max=94.8005\n",
      "[SGD | lr=0.01] Epoch 2924/4000: train_loss=0.3157  test_loss=2.8058  λ_max=92.0575\n",
      "[SGD | lr=0.01] Iter 46800: loss=0.3227\n",
      "[SGD | lr=0.01] Epoch 2925/4000: train_loss=0.3153  test_loss=2.8058  λ_max=90.3724\n",
      "[SGD | lr=0.01] Epoch 2926/4000: train_loss=0.3149  test_loss=2.8071  λ_max=93.5900\n",
      "[SGD | lr=0.01] Epoch 2927/4000: train_loss=0.3158  test_loss=2.8072  λ_max=92.4761\n",
      "[SGD | lr=0.01] Epoch 2928/4000: train_loss=0.3151  test_loss=2.8080  λ_max=98.3131\n",
      "[SGD | lr=0.01] Epoch 2929/4000: train_loss=0.3158  test_loss=2.8090  λ_max=89.0010\n",
      "[SGD | lr=0.01] Epoch 2930/4000: train_loss=0.3198  test_loss=2.8125  λ_max=94.8998\n",
      "[SGD | lr=0.01] Epoch 2931/4000: train_loss=0.3304  test_loss=2.8203  λ_max=94.4931\n",
      "[SGD | lr=0.01] Iter 46900: loss=0.3347\n",
      "[SGD | lr=0.01] Epoch 2932/4000: train_loss=0.3346  test_loss=2.8165  λ_max=88.1473\n",
      "[SGD | lr=0.01] Epoch 2933/4000: train_loss=0.3283  test_loss=2.8165  λ_max=92.7691\n",
      "[SGD | lr=0.01] Epoch 2934/4000: train_loss=0.3267  test_loss=2.8144  λ_max=94.0081\n",
      "[SGD | lr=0.01] Epoch 2935/4000: train_loss=0.3202  test_loss=2.8123  λ_max=97.4908\n",
      "[SGD | lr=0.01] Epoch 2936/4000: train_loss=0.3180  test_loss=2.8128  λ_max=97.9655\n",
      "[SGD | lr=0.01] Epoch 2937/4000: train_loss=0.3194  test_loss=2.8116  λ_max=91.9127\n",
      "[SGD | lr=0.01] Iter 47000: loss=0.3195\n",
      "[SGD | lr=0.01] Epoch 2938/4000: train_loss=0.3179  test_loss=2.8124  λ_max=92.2640\n",
      "[SGD | lr=0.01] Epoch 2939/4000: train_loss=0.3145  test_loss=2.8111  λ_max=92.6155\n",
      "[SGD | lr=0.01] Epoch 2940/4000: train_loss=0.3127  test_loss=2.8118  λ_max=91.0993\n",
      "[SGD | lr=0.01] Epoch 2941/4000: train_loss=0.3116  test_loss=2.8112  λ_max=87.9308\n",
      "[SGD | lr=0.01] Epoch 2942/4000: train_loss=0.3111  test_loss=2.8119  λ_max=94.9617\n",
      "[SGD | lr=0.01] Epoch 2943/4000: train_loss=0.3109  test_loss=2.8130  λ_max=91.0911\n",
      "[SGD | lr=0.01] Iter 47100: loss=0.3080\n",
      "[SGD | lr=0.01] Epoch 2944/4000: train_loss=0.3110  test_loss=2.8137  λ_max=95.2492\n",
      "[SGD | lr=0.01] Epoch 2945/4000: train_loss=0.3111  test_loss=2.8139  λ_max=89.7170\n",
      "[SGD | lr=0.01] Epoch 2946/4000: train_loss=0.3114  test_loss=2.8152  λ_max=94.8161\n",
      "[SGD | lr=0.01] Epoch 2947/4000: train_loss=0.3131  test_loss=2.8156  λ_max=95.3378\n",
      "[SGD | lr=0.01] Epoch 2948/4000: train_loss=0.3250  test_loss=2.8195  λ_max=94.5170\n",
      "[SGD | lr=0.01] Epoch 2949/4000: train_loss=0.3374  test_loss=2.8249  λ_max=87.7102\n",
      "[SGD | lr=0.01] Iter 47200: loss=0.3287\n",
      "[SGD | lr=0.01] Epoch 2950/4000: train_loss=0.3292  test_loss=2.8208  λ_max=94.7190\n",
      "[SGD | lr=0.01] Epoch 2951/4000: train_loss=0.3287  test_loss=2.8213  λ_max=91.4688\n",
      "[SGD | lr=0.01] Epoch 2952/4000: train_loss=0.3263  test_loss=2.8188  λ_max=89.5629\n",
      "[SGD | lr=0.01] Epoch 2953/4000: train_loss=0.3232  test_loss=2.8177  λ_max=90.6408\n",
      "[SGD | lr=0.01] Epoch 2954/4000: train_loss=0.3202  test_loss=2.8176  λ_max=90.9937\n",
      "[SGD | lr=0.01] Epoch 2955/4000: train_loss=0.3119  test_loss=2.8177  λ_max=94.6074\n",
      "[SGD | lr=0.01] Epoch 2956/4000: train_loss=0.3093  test_loss=2.8192  λ_max=89.7959\n",
      "[SGD | lr=0.01] Iter 47300: loss=0.3052\n",
      "[SGD | lr=0.01] Epoch 2957/4000: train_loss=0.3085  test_loss=2.8187  λ_max=91.8066\n",
      "[SGD | lr=0.01] Epoch 2958/4000: train_loss=0.3084  test_loss=2.8182  λ_max=96.0235\n",
      "[SGD | lr=0.01] Epoch 2959/4000: train_loss=0.3079  test_loss=2.8182  λ_max=94.5577\n",
      "[SGD | lr=0.01] Epoch 2960/4000: train_loss=0.3079  test_loss=2.8194  λ_max=96.1124\n",
      "[SGD | lr=0.01] Epoch 2961/4000: train_loss=0.3080  test_loss=2.8187  λ_max=94.7165\n",
      "[SGD | lr=0.01] Epoch 2962/4000: train_loss=0.3076  test_loss=2.8191  λ_max=98.5799\n",
      "[SGD | lr=0.01] Iter 47400: loss=0.3057\n",
      "[SGD | lr=0.01] Epoch 2963/4000: train_loss=0.3079  test_loss=2.8205  λ_max=92.1503\n",
      "[SGD | lr=0.01] Epoch 2964/4000: train_loss=0.3105  test_loss=2.8230  λ_max=94.2187\n",
      "[SGD | lr=0.01] Epoch 2965/4000: train_loss=0.3178  test_loss=2.8247  λ_max=95.9394\n",
      "[SGD | lr=0.01] Epoch 2966/4000: train_loss=0.3340  test_loss=2.8250  λ_max=90.3491\n",
      "[SGD | lr=0.01] Epoch 2967/4000: train_loss=0.3196  test_loss=2.8241  λ_max=93.2794\n",
      "[SGD | lr=0.01] Epoch 2968/4000: train_loss=0.3181  test_loss=2.8260  λ_max=94.3066\n",
      "[SGD | lr=0.01] Iter 47500: loss=0.3175\n",
      "[SGD | lr=0.01] Epoch 2969/4000: train_loss=0.3176  test_loss=2.8242  λ_max=91.5236\n",
      "[SGD | lr=0.01] Epoch 2970/4000: train_loss=0.3141  test_loss=2.8237  λ_max=94.9253\n",
      "[SGD | lr=0.01] Epoch 2971/4000: train_loss=0.3154  test_loss=2.8244  λ_max=94.3763\n",
      "[SGD | lr=0.01] Epoch 2972/4000: train_loss=0.3137  test_loss=2.8239  λ_max=91.8420\n",
      "[SGD | lr=0.01] Epoch 2973/4000: train_loss=0.3067  test_loss=2.8246  λ_max=96.6204\n",
      "[SGD | lr=0.01] Epoch 2974/4000: train_loss=0.3053  test_loss=2.8251  λ_max=95.5228\n",
      "[SGD | lr=0.01] Iter 47600: loss=0.2994\n",
      "[SGD | lr=0.01] Epoch 2975/4000: train_loss=0.3047  test_loss=2.8245  λ_max=92.7039\n",
      "[SGD | lr=0.01] Epoch 2976/4000: train_loss=0.3049  test_loss=2.8252  λ_max=94.4900\n",
      "[SGD | lr=0.01] Epoch 2977/4000: train_loss=0.3045  test_loss=2.8260  λ_max=96.1084\n",
      "[SGD | lr=0.01] Epoch 2978/4000: train_loss=0.3044  test_loss=2.8270  λ_max=97.5378\n",
      "[SGD | lr=0.01] Epoch 2979/4000: train_loss=0.3041  test_loss=2.8269  λ_max=98.9512\n",
      "[SGD | lr=0.01] Epoch 2980/4000: train_loss=0.3042  test_loss=2.8276  λ_max=98.3404\n",
      "[SGD | lr=0.01] Epoch 2981/4000: train_loss=0.3040  test_loss=2.8284  λ_max=93.9873\n",
      "[SGD | lr=0.01] Iter 47700: loss=0.3039\n",
      "[SGD | lr=0.01] Epoch 2982/4000: train_loss=0.3042  test_loss=2.8295  λ_max=91.0735\n",
      "[SGD | lr=0.01] Epoch 2983/4000: train_loss=0.3062  test_loss=2.8312  λ_max=93.0694\n",
      "[SGD | lr=0.01] Epoch 2984/4000: train_loss=0.3141  test_loss=2.8334  λ_max=95.1849\n",
      "[SGD | lr=0.01] Epoch 2985/4000: train_loss=0.3249  test_loss=2.8383  λ_max=94.1962\n",
      "[SGD | lr=0.01] Epoch 2986/4000: train_loss=0.3253  test_loss=2.8369  λ_max=90.8111\n",
      "[SGD | lr=0.01] Epoch 2987/4000: train_loss=0.3164  test_loss=2.8313  λ_max=94.4471\n",
      "[SGD | lr=0.01] Iter 47800: loss=0.3105\n",
      "[SGD | lr=0.01] Epoch 2988/4000: train_loss=0.3114  test_loss=2.8292  λ_max=94.3934\n",
      "[SGD | lr=0.01] Epoch 2989/4000: train_loss=0.3114  test_loss=2.8291  λ_max=95.0252\n",
      "[SGD | lr=0.01] Epoch 2990/4000: train_loss=0.3135  test_loss=2.8294  λ_max=87.5860\n",
      "[SGD | lr=0.01] Epoch 2991/4000: train_loss=0.3102  test_loss=2.8313  λ_max=92.4720\n",
      "[SGD | lr=0.01] Epoch 2992/4000: train_loss=0.3061  test_loss=2.8313  λ_max=93.2292\n",
      "[SGD | lr=0.01] Epoch 2993/4000: train_loss=0.3030  test_loss=2.8319  λ_max=96.0715\n",
      "[SGD | lr=0.01] Iter 47900: loss=0.3027\n",
      "[SGD | lr=0.01] Epoch 2994/4000: train_loss=0.3024  test_loss=2.8327  λ_max=92.0623\n",
      "[SGD | lr=0.01] Epoch 2995/4000: train_loss=0.3010  test_loss=2.8322  λ_max=92.5947\n",
      "[SGD | lr=0.01] Epoch 2996/4000: train_loss=0.3008  test_loss=2.8323  λ_max=90.2732\n",
      "[SGD | lr=0.01] Epoch 2997/4000: train_loss=0.3005  test_loss=2.8322  λ_max=91.3126\n",
      "[SGD | lr=0.01] Epoch 2998/4000: train_loss=0.3004  test_loss=2.8340  λ_max=94.0252\n",
      "[SGD | lr=0.01] Epoch 2999/4000: train_loss=0.3004  test_loss=2.8341  λ_max=91.0249\n",
      "[SGD | lr=0.01] Iter 48000: loss=0.2992\n",
      "[SGD | lr=0.01] Epoch 3000/4000: train_loss=0.3003  test_loss=2.8347  λ_max=93.6520\n",
      "[SGD | lr=0.01] Epoch 3001/4000: train_loss=0.3003  test_loss=2.8367  λ_max=91.6343\n",
      "[SGD | lr=0.01] Epoch 3002/4000: train_loss=0.3003  test_loss=2.8374  λ_max=97.2712\n",
      "[SGD | lr=0.01] Epoch 3003/4000: train_loss=0.3024  test_loss=2.8392  λ_max=96.5060\n",
      "[SGD | lr=0.01] Epoch 3004/4000: train_loss=0.3087  test_loss=2.8465  λ_max=98.3445\n",
      "[SGD | lr=0.01] Epoch 3005/4000: train_loss=0.3291  test_loss=2.8471  λ_max=96.6213\n",
      "[SGD | lr=0.01] Epoch 3006/4000: train_loss=0.3130  test_loss=2.8445  λ_max=93.2629\n",
      "[SGD | lr=0.01] Iter 48100: loss=0.3196\n",
      "[SGD | lr=0.01] Epoch 3007/4000: train_loss=0.3224  test_loss=2.8474  λ_max=94.3720\n",
      "[SGD | lr=0.01] Epoch 3008/4000: train_loss=0.3222  test_loss=2.8468  λ_max=93.2148\n",
      "[SGD | lr=0.01] Epoch 3009/4000: train_loss=0.3130  test_loss=2.8447  λ_max=94.9867\n",
      "[SGD | lr=0.01] Epoch 3010/4000: train_loss=0.3117  test_loss=2.8443  λ_max=90.8805\n",
      "[SGD | lr=0.01] Epoch 3011/4000: train_loss=0.3077  test_loss=2.8404  λ_max=96.4011\n",
      "[SGD | lr=0.01] Epoch 3012/4000: train_loss=0.3012  test_loss=2.8386  λ_max=89.9334\n",
      "[SGD | lr=0.01] Iter 48200: loss=0.3001\n",
      "[SGD | lr=0.01] Epoch 3013/4000: train_loss=0.2985  test_loss=2.8392  λ_max=94.8437\n",
      "[SGD | lr=0.01] Epoch 3014/4000: train_loss=0.2977  test_loss=2.8405  λ_max=94.2134\n",
      "[SGD | lr=0.01] Epoch 3015/4000: train_loss=0.2972  test_loss=2.8397  λ_max=93.8271\n",
      "[SGD | lr=0.01] Epoch 3016/4000: train_loss=0.2969  test_loss=2.8402  λ_max=89.1803\n",
      "[SGD | lr=0.01] Epoch 3017/4000: train_loss=0.2971  test_loss=2.8410  λ_max=93.0948\n",
      "[SGD | lr=0.01] Epoch 3018/4000: train_loss=0.2967  test_loss=2.8417  λ_max=94.1887\n",
      "[SGD | lr=0.01] Iter 48300: loss=0.2968\n",
      "[SGD | lr=0.01] Epoch 3019/4000: train_loss=0.2970  test_loss=2.8433  λ_max=94.0240\n",
      "[SGD | lr=0.01] Epoch 3020/4000: train_loss=0.2973  test_loss=2.8443  λ_max=91.4291\n",
      "[SGD | lr=0.01] Epoch 3021/4000: train_loss=0.2995  test_loss=2.8446  λ_max=96.7226\n",
      "[SGD | lr=0.01] Epoch 3022/4000: train_loss=0.3019  test_loss=2.8468  λ_max=96.7839\n",
      "[SGD | lr=0.01] Epoch 3023/4000: train_loss=0.3114  test_loss=2.8538  λ_max=94.7003\n",
      "[SGD | lr=0.01] Epoch 3024/4000: train_loss=0.3220  test_loss=2.8485  λ_max=96.3312\n",
      "[SGD | lr=0.01] Iter 48400: loss=0.3190\n",
      "[SGD | lr=0.01] Epoch 3025/4000: train_loss=0.3225  test_loss=2.8430  λ_max=96.3599\n",
      "[SGD | lr=0.01] Epoch 3026/4000: train_loss=0.3073  test_loss=2.8440  λ_max=93.9924\n",
      "[SGD | lr=0.01] Epoch 3027/4000: train_loss=0.3025  test_loss=2.8466  λ_max=91.5193\n",
      "[SGD | lr=0.01] Epoch 3028/4000: train_loss=0.2992  test_loss=2.8480  λ_max=92.7388\n",
      "[SGD | lr=0.01] Epoch 3029/4000: train_loss=0.2995  test_loss=2.8477  λ_max=91.8448\n",
      "[SGD | lr=0.01] Epoch 3030/4000: train_loss=0.2959  test_loss=2.8469  λ_max=97.8003\n",
      "[SGD | lr=0.01] Epoch 3031/4000: train_loss=0.2948  test_loss=2.8468  λ_max=91.3198\n",
      "[SGD | lr=0.01] Iter 48500: loss=0.2922\n",
      "[SGD | lr=0.01] Epoch 3032/4000: train_loss=0.2944  test_loss=2.8476  λ_max=99.1976\n",
      "[SGD | lr=0.01] Epoch 3033/4000: train_loss=0.2940  test_loss=2.8471  λ_max=92.2389\n",
      "[SGD | lr=0.01] Epoch 3034/4000: train_loss=0.2939  test_loss=2.8471  λ_max=95.6192\n",
      "[SGD | lr=0.01] Epoch 3035/4000: train_loss=0.2940  test_loss=2.8477  λ_max=93.8918\n",
      "[SGD | lr=0.01] Epoch 3036/4000: train_loss=0.2942  test_loss=2.8486  λ_max=94.9239\n",
      "[SGD | lr=0.01] Epoch 3037/4000: train_loss=0.2940  test_loss=2.8499  λ_max=95.8745\n",
      "[SGD | lr=0.01] Iter 48600: loss=0.2946\n",
      "[SGD | lr=0.01] Epoch 3038/4000: train_loss=0.2951  test_loss=2.8506  λ_max=94.4551\n",
      "[SGD | lr=0.01] Epoch 3039/4000: train_loss=0.3030  test_loss=2.8513  λ_max=93.6166\n",
      "[SGD | lr=0.01] Epoch 3040/4000: train_loss=0.3131  test_loss=2.8506  λ_max=90.6798\n",
      "[SGD | lr=0.01] Epoch 3041/4000: train_loss=0.3116  test_loss=2.8560  λ_max=102.0461\n",
      "[SGD | lr=0.01] Epoch 3042/4000: train_loss=0.3176  test_loss=2.8567  λ_max=94.9798\n",
      "[SGD | lr=0.01] Epoch 3043/4000: train_loss=0.3081  test_loss=2.8551  λ_max=92.7072\n",
      "[SGD | lr=0.01] Iter 48700: loss=0.3042\n",
      "[SGD | lr=0.01] Epoch 3044/4000: train_loss=0.3101  test_loss=2.8563  λ_max=91.7693\n",
      "[SGD | lr=0.01] Epoch 3045/4000: train_loss=0.2992  test_loss=2.8519  λ_max=93.3331\n",
      "[SGD | lr=0.01] Epoch 3046/4000: train_loss=0.2963  test_loss=2.8528  λ_max=93.6632\n",
      "[SGD | lr=0.01] Epoch 3047/4000: train_loss=0.2923  test_loss=2.8520  λ_max=95.9857\n",
      "[SGD | lr=0.01] Epoch 3048/4000: train_loss=0.2915  test_loss=2.8518  λ_max=97.5113\n",
      "[SGD | lr=0.01] Epoch 3049/4000: train_loss=0.2912  test_loss=2.8528  λ_max=93.0031\n",
      "[SGD | lr=0.01] Iter 48800: loss=0.2877\n",
      "[SGD | lr=0.01] Epoch 3050/4000: train_loss=0.2908  test_loss=2.8527  λ_max=96.0229\n",
      "[SGD | lr=0.01] Epoch 3051/4000: train_loss=0.2905  test_loss=2.8536  λ_max=96.0578\n",
      "[SGD | lr=0.01] Epoch 3052/4000: train_loss=0.2909  test_loss=2.8538  λ_max=98.0112\n",
      "[SGD | lr=0.01] Epoch 3053/4000: train_loss=0.2909  test_loss=2.8541  λ_max=95.0430\n",
      "[SGD | lr=0.01] Epoch 3054/4000: train_loss=0.2906  test_loss=2.8542  λ_max=93.6230\n",
      "[SGD | lr=0.01] Epoch 3055/4000: train_loss=0.2908  test_loss=2.8548  λ_max=94.2142\n",
      "[SGD | lr=0.01] Epoch 3056/4000: train_loss=0.2905  test_loss=2.8560  λ_max=94.5281\n",
      "[SGD | lr=0.01] Iter 48900: loss=0.2877\n",
      "[SGD | lr=0.01] Epoch 3057/4000: train_loss=0.2927  test_loss=2.8566  λ_max=96.7094\n",
      "[SGD | lr=0.01] Epoch 3058/4000: train_loss=0.2975  test_loss=2.8560  λ_max=96.1314\n",
      "[SGD | lr=0.01] Epoch 3059/4000: train_loss=0.3063  test_loss=2.8600  λ_max=95.8328\n",
      "[SGD | lr=0.01] Epoch 3060/4000: train_loss=0.3170  test_loss=2.8590  λ_max=97.3813\n",
      "[SGD | lr=0.01] Epoch 3061/4000: train_loss=0.3107  test_loss=2.8623  λ_max=97.1640\n",
      "[SGD | lr=0.01] Epoch 3062/4000: train_loss=0.3013  test_loss=2.8623  λ_max=97.2838\n",
      "[SGD | lr=0.01] Iter 49000: loss=0.3030\n",
      "[SGD | lr=0.01] Epoch 3063/4000: train_loss=0.3013  test_loss=2.8630  λ_max=96.0855\n",
      "[SGD | lr=0.01] Epoch 3064/4000: train_loss=0.2984  test_loss=2.8594  λ_max=95.4776\n",
      "[SGD | lr=0.01] Epoch 3065/4000: train_loss=0.2898  test_loss=2.8589  λ_max=95.4334\n",
      "[SGD | lr=0.01] Epoch 3066/4000: train_loss=0.2882  test_loss=2.8589  λ_max=96.7665\n",
      "[SGD | lr=0.01] Epoch 3067/4000: train_loss=0.2880  test_loss=2.8603  λ_max=93.5232\n",
      "[SGD | lr=0.01] Epoch 3068/4000: train_loss=0.2879  test_loss=2.8607  λ_max=95.2868\n",
      "[SGD | lr=0.01] Iter 49100: loss=0.2861\n",
      "[SGD | lr=0.01] Epoch 3069/4000: train_loss=0.2876  test_loss=2.8614  λ_max=95.6237\n",
      "[SGD | lr=0.01] Epoch 3070/4000: train_loss=0.2872  test_loss=2.8618  λ_max=95.3235\n",
      "[SGD | lr=0.01] Epoch 3071/4000: train_loss=0.2875  test_loss=2.8621  λ_max=94.7758\n",
      "[SGD | lr=0.01] Epoch 3072/4000: train_loss=0.2875  test_loss=2.8629  λ_max=94.2924\n",
      "[SGD | lr=0.01] Epoch 3073/4000: train_loss=0.2869  test_loss=2.8629  λ_max=92.0070\n",
      "[SGD | lr=0.01] Epoch 3074/4000: train_loss=0.2867  test_loss=2.8629  λ_max=94.6132\n",
      "[SGD | lr=0.01] Iter 49200: loss=0.2843\n",
      "[SGD | lr=0.01] Epoch 3075/4000: train_loss=0.2876  test_loss=2.8638  λ_max=97.9584\n",
      "[SGD | lr=0.01] Epoch 3076/4000: train_loss=0.2916  test_loss=2.8665  λ_max=97.4141\n",
      "[SGD | lr=0.01] Epoch 3077/4000: train_loss=0.3045  test_loss=2.8730  λ_max=97.2810\n",
      "[SGD | lr=0.01] Epoch 3078/4000: train_loss=0.3110  test_loss=2.8757  λ_max=101.5598\n",
      "[SGD | lr=0.01] Epoch 3079/4000: train_loss=0.3047  test_loss=2.8687  λ_max=97.1327\n",
      "[SGD | lr=0.01] Epoch 3080/4000: train_loss=0.3019  test_loss=2.8646  λ_max=92.5269\n",
      "[SGD | lr=0.01] Epoch 3081/4000: train_loss=0.2944  test_loss=2.8653  λ_max=99.6033\n",
      "[SGD | lr=0.01] Iter 49300: loss=0.2937\n",
      "[SGD | lr=0.01] Epoch 3082/4000: train_loss=0.2896  test_loss=2.8670  λ_max=100.2184\n",
      "[SGD | lr=0.01] Epoch 3083/4000: train_loss=0.2868  test_loss=2.8669  λ_max=97.6412\n",
      "[SGD | lr=0.01] Epoch 3084/4000: train_loss=0.2860  test_loss=2.8675  λ_max=92.5807\n",
      "[SGD | lr=0.01] Epoch 3085/4000: train_loss=0.2849  test_loss=2.8670  λ_max=92.2665\n",
      "[SGD | lr=0.01] Epoch 3086/4000: train_loss=0.2848  test_loss=2.8681  λ_max=96.3905\n",
      "[SGD | lr=0.01] Epoch 3087/4000: train_loss=0.2843  test_loss=2.8681  λ_max=94.9509\n",
      "[SGD | lr=0.01] Iter 49400: loss=0.2859\n",
      "[SGD | lr=0.01] Epoch 3088/4000: train_loss=0.2844  test_loss=2.8691  λ_max=93.0926\n",
      "[SGD | lr=0.01] Epoch 3089/4000: train_loss=0.2839  test_loss=2.8683  λ_max=92.1422\n",
      "[SGD | lr=0.01] Epoch 3090/4000: train_loss=0.2842  test_loss=2.8688  λ_max=94.6209\n",
      "[SGD | lr=0.01] Epoch 3091/4000: train_loss=0.2844  test_loss=2.8698  λ_max=91.5530\n",
      "[SGD | lr=0.01] Epoch 3092/4000: train_loss=0.2854  test_loss=2.8692  λ_max=95.9265\n",
      "[SGD | lr=0.01] Epoch 3093/4000: train_loss=0.2906  test_loss=2.8700  λ_max=95.6141\n",
      "[SGD | lr=0.01] Iter 49500: loss=0.3113\n",
      "[SGD | lr=0.01] Epoch 3094/4000: train_loss=0.3041  test_loss=2.8713  λ_max=98.9921\n",
      "[SGD | lr=0.01] Epoch 3095/4000: train_loss=0.3097  test_loss=2.8718  λ_max=95.5449\n",
      "[SGD | lr=0.01] Epoch 3096/4000: train_loss=0.3071  test_loss=2.8789  λ_max=98.3218\n",
      "[SGD | lr=0.01] Epoch 3097/4000: train_loss=0.3071  test_loss=2.8801  λ_max=94.7280\n",
      "[SGD | lr=0.01] Epoch 3098/4000: train_loss=0.2962  test_loss=2.8753  λ_max=98.2727\n",
      "[SGD | lr=0.01] Epoch 3099/4000: train_loss=0.2872  test_loss=2.8735  λ_max=96.0554\n",
      "[SGD | lr=0.01] Iter 49600: loss=0.2828\n",
      "[SGD | lr=0.01] Epoch 3100/4000: train_loss=0.2835  test_loss=2.8734  λ_max=99.1752\n",
      "[SGD | lr=0.01] Epoch 3101/4000: train_loss=0.2824  test_loss=2.8725  λ_max=96.2230\n",
      "[SGD | lr=0.01] Epoch 3102/4000: train_loss=0.2821  test_loss=2.8732  λ_max=94.4219\n",
      "[SGD | lr=0.01] Epoch 3103/4000: train_loss=0.2816  test_loss=2.8743  λ_max=94.5965\n",
      "[SGD | lr=0.01] Epoch 3104/4000: train_loss=0.2814  test_loss=2.8744  λ_max=95.6673\n",
      "[SGD | lr=0.01] Epoch 3105/4000: train_loss=0.2813  test_loss=2.8744  λ_max=95.6649\n",
      "[SGD | lr=0.01] Epoch 3106/4000: train_loss=0.2812  test_loss=2.8755  λ_max=96.3086\n",
      "[SGD | lr=0.01] Iter 49700: loss=0.2816\n",
      "[SGD | lr=0.01] Epoch 3107/4000: train_loss=0.2810  test_loss=2.8760  λ_max=95.5234\n",
      "[SGD | lr=0.01] Epoch 3108/4000: train_loss=0.2810  test_loss=2.8764  λ_max=96.3302\n",
      "[SGD | lr=0.01] Epoch 3109/4000: train_loss=0.2809  test_loss=2.8768  λ_max=94.0266\n",
      "[SGD | lr=0.01] Epoch 3110/4000: train_loss=0.2817  test_loss=2.8779  λ_max=96.5209\n",
      "[SGD | lr=0.01] Epoch 3111/4000: train_loss=0.2843  test_loss=2.8801  λ_max=100.0979\n",
      "[SGD | lr=0.01] Epoch 3112/4000: train_loss=0.3041  test_loss=2.8842  λ_max=96.2217\n",
      "[SGD | lr=0.01] Iter 49800: loss=0.3099\n",
      "[SGD | lr=0.01] Epoch 3113/4000: train_loss=0.3077  test_loss=2.8821  λ_max=93.4232\n",
      "[SGD | lr=0.01] Epoch 3114/4000: train_loss=0.3078  test_loss=2.8802  λ_max=96.6508\n",
      "[SGD | lr=0.01] Epoch 3115/4000: train_loss=0.2876  test_loss=2.8802  λ_max=94.9786\n",
      "[SGD | lr=0.01] Epoch 3116/4000: train_loss=0.2843  test_loss=2.8834  λ_max=96.0247\n",
      "[SGD | lr=0.01] Epoch 3117/4000: train_loss=0.2851  test_loss=2.8825  λ_max=99.8381\n",
      "[SGD | lr=0.01] Epoch 3118/4000: train_loss=0.2823  test_loss=2.8816  λ_max=92.7072\n",
      "[SGD | lr=0.01] Iter 49900: loss=0.2763\n",
      "[SGD | lr=0.01] Epoch 3119/4000: train_loss=0.2794  test_loss=2.8793  λ_max=96.3784\n",
      "[SGD | lr=0.01] Epoch 3120/4000: train_loss=0.2789  test_loss=2.8799  λ_max=93.6056\n",
      "[SGD | lr=0.01] Epoch 3121/4000: train_loss=0.2785  test_loss=2.8802  λ_max=93.5348\n",
      "[SGD | lr=0.01] Epoch 3122/4000: train_loss=0.2785  test_loss=2.8814  λ_max=98.7911\n",
      "[SGD | lr=0.01] Epoch 3123/4000: train_loss=0.2781  test_loss=2.8816  λ_max=97.2242\n",
      "[SGD | lr=0.01] Epoch 3124/4000: train_loss=0.2779  test_loss=2.8823  λ_max=95.5737\n",
      "[SGD | lr=0.01] Iter 50000: loss=0.2738\n",
      "[SGD | lr=0.01] Epoch 3125/4000: train_loss=0.2778  test_loss=2.8825  λ_max=93.8675\n",
      "[SGD | lr=0.01] Epoch 3126/4000: train_loss=0.2781  test_loss=2.8834  λ_max=92.8482\n",
      "[SGD | lr=0.01] Epoch 3127/4000: train_loss=0.2787  test_loss=2.8834  λ_max=94.0721\n",
      "[SGD | lr=0.01] Epoch 3128/4000: train_loss=0.2791  test_loss=2.8842  λ_max=96.2570\n",
      "[SGD | lr=0.01] Epoch 3129/4000: train_loss=0.2807  test_loss=2.8852  λ_max=96.4718\n",
      "[SGD | lr=0.01] Epoch 3130/4000: train_loss=0.2949  test_loss=2.8900  λ_max=97.2818\n",
      "[SGD | lr=0.01] Epoch 3131/4000: train_loss=0.2958  test_loss=2.8897  λ_max=97.9005\n",
      "[SGD | lr=0.01] Iter 50100: loss=0.2982\n",
      "[SGD | lr=0.01] Epoch 3132/4000: train_loss=0.3000  test_loss=2.8882  λ_max=102.0820\n",
      "[SGD | lr=0.01] Epoch 3133/4000: train_loss=0.2914  test_loss=2.8932  λ_max=100.6380\n",
      "[SGD | lr=0.01] Epoch 3134/4000: train_loss=0.2964  test_loss=2.8909  λ_max=93.4748\n",
      "[SGD | lr=0.01] Epoch 3135/4000: train_loss=0.2950  test_loss=2.8901  λ_max=96.2843\n",
      "[SGD | lr=0.01] Epoch 3136/4000: train_loss=0.2870  test_loss=2.8899  λ_max=94.5763\n",
      "[SGD | lr=0.01] Epoch 3137/4000: train_loss=0.2787  test_loss=2.8883  λ_max=96.4457\n",
      "[SGD | lr=0.01] Iter 50200: loss=0.2730\n",
      "[SGD | lr=0.01] Epoch 3138/4000: train_loss=0.2760  test_loss=2.8875  λ_max=91.5590\n",
      "[SGD | lr=0.01] Epoch 3139/4000: train_loss=0.2755  test_loss=2.8877  λ_max=100.9815\n",
      "[SGD | lr=0.01] Epoch 3140/4000: train_loss=0.2755  test_loss=2.8878  λ_max=97.8807\n",
      "[SGD | lr=0.01] Epoch 3141/4000: train_loss=0.2754  test_loss=2.8883  λ_max=95.5944\n",
      "[SGD | lr=0.01] Epoch 3142/4000: train_loss=0.2750  test_loss=2.8890  λ_max=94.8192\n",
      "[SGD | lr=0.01] Epoch 3143/4000: train_loss=0.2750  test_loss=2.8897  λ_max=93.8177\n",
      "[SGD | lr=0.01] Iter 50300: loss=0.2722\n",
      "[SGD | lr=0.01] Epoch 3144/4000: train_loss=0.2745  test_loss=2.8890  λ_max=96.4440\n",
      "[SGD | lr=0.01] Epoch 3145/4000: train_loss=0.2743  test_loss=2.8887  λ_max=94.7252\n",
      "[SGD | lr=0.01] Epoch 3146/4000: train_loss=0.2741  test_loss=2.8897  λ_max=93.8265\n",
      "[SGD | lr=0.01] Epoch 3147/4000: train_loss=0.2741  test_loss=2.8901  λ_max=99.9497\n",
      "[SGD | lr=0.01] Epoch 3148/4000: train_loss=0.2741  test_loss=2.8913  λ_max=92.3035\n",
      "[SGD | lr=0.01] Epoch 3149/4000: train_loss=0.2752  test_loss=2.8926  λ_max=97.6967\n",
      "[SGD | lr=0.01] Iter 50400: loss=0.2817\n",
      "[SGD | lr=0.01] Epoch 3150/4000: train_loss=0.2777  test_loss=2.8962  λ_max=94.8410\n",
      "[SGD | lr=0.01] Epoch 3151/4000: train_loss=0.2896  test_loss=2.8961  λ_max=93.2756\n",
      "[SGD | lr=0.01] Epoch 3152/4000: train_loss=0.3049  test_loss=2.8946  λ_max=96.3162\n",
      "[SGD | lr=0.01] Epoch 3153/4000: train_loss=0.2919  test_loss=2.8978  λ_max=92.8511\n",
      "[SGD | lr=0.01] Epoch 3154/4000: train_loss=0.2850  test_loss=2.8986  λ_max=96.7072\n",
      "[SGD | lr=0.01] Epoch 3155/4000: train_loss=0.2814  test_loss=2.8979  λ_max=97.7253\n",
      "[SGD | lr=0.01] Epoch 3156/4000: train_loss=0.2805  test_loss=2.8976  λ_max=100.0219\n",
      "[SGD | lr=0.01] Iter 50500: loss=0.2833\n",
      "[SGD | lr=0.01] Epoch 3157/4000: train_loss=0.2766  test_loss=2.8962  λ_max=96.8669\n",
      "[SGD | lr=0.01] Epoch 3158/4000: train_loss=0.2736  test_loss=2.8952  λ_max=95.4941\n",
      "[SGD | lr=0.01] Epoch 3159/4000: train_loss=0.2725  test_loss=2.8956  λ_max=95.9164\n",
      "[SGD | lr=0.01] Epoch 3160/4000: train_loss=0.2721  test_loss=2.8949  λ_max=95.0354\n",
      "[SGD | lr=0.01] Epoch 3161/4000: train_loss=0.2719  test_loss=2.8957  λ_max=96.0952\n",
      "[SGD | lr=0.01] Epoch 3162/4000: train_loss=0.2718  test_loss=2.8968  λ_max=97.3993\n",
      "[SGD | lr=0.01] Iter 50600: loss=0.2715\n",
      "[SGD | lr=0.01] Epoch 3163/4000: train_loss=0.2714  test_loss=2.8965  λ_max=94.6357\n",
      "[SGD | lr=0.01] Epoch 3164/4000: train_loss=0.2713  test_loss=2.8979  λ_max=97.1108\n",
      "[SGD | lr=0.01] Epoch 3165/4000: train_loss=0.2714  test_loss=2.8982  λ_max=92.6453\n",
      "[SGD | lr=0.01] Epoch 3166/4000: train_loss=0.2714  test_loss=2.8982  λ_max=97.8257\n",
      "[SGD | lr=0.01] Epoch 3167/4000: train_loss=0.2718  test_loss=2.8986  λ_max=96.9648\n",
      "[SGD | lr=0.01] Epoch 3168/4000: train_loss=0.2726  test_loss=2.9008  λ_max=95.0317\n",
      "[SGD | lr=0.01] Iter 50700: loss=0.2698\n",
      "[SGD | lr=0.01] Epoch 3169/4000: train_loss=0.2762  test_loss=2.9009  λ_max=97.7035\n",
      "[SGD | lr=0.01] Epoch 3170/4000: train_loss=0.2872  test_loss=2.9010  λ_max=101.3360\n",
      "[SGD | lr=0.01] Epoch 3171/4000: train_loss=0.3000  test_loss=2.9041  λ_max=96.6718\n",
      "[SGD | lr=0.01] Epoch 3172/4000: train_loss=0.2953  test_loss=2.9047  λ_max=99.5738\n",
      "[SGD | lr=0.01] Epoch 3173/4000: train_loss=0.2800  test_loss=2.9017  λ_max=100.3893\n",
      "[SGD | lr=0.01] Epoch 3174/4000: train_loss=0.2722  test_loss=2.9002  λ_max=98.7869\n",
      "[SGD | lr=0.01] Iter 50800: loss=0.2674\n",
      "[SGD | lr=0.01] Epoch 3175/4000: train_loss=0.2700  test_loss=2.9006  λ_max=96.7071\n",
      "[SGD | lr=0.01] Epoch 3176/4000: train_loss=0.2697  test_loss=2.9015  λ_max=95.3305\n",
      "[SGD | lr=0.01] Epoch 3177/4000: train_loss=0.2694  test_loss=2.9018  λ_max=101.6027\n",
      "[SGD | lr=0.01] Epoch 3178/4000: train_loss=0.2693  test_loss=2.9024  λ_max=96.6375\n",
      "[SGD | lr=0.01] Epoch 3179/4000: train_loss=0.2690  test_loss=2.9038  λ_max=100.0182\n",
      "[SGD | lr=0.01] Epoch 3180/4000: train_loss=0.2688  test_loss=2.9036  λ_max=99.8315\n",
      "[SGD | lr=0.01] Epoch 3181/4000: train_loss=0.2686  test_loss=2.9041  λ_max=95.8732\n",
      "[SGD | lr=0.01] Iter 50900: loss=0.2669\n",
      "[SGD | lr=0.01] Epoch 3182/4000: train_loss=0.2686  test_loss=2.9040  λ_max=99.2146\n",
      "[SGD | lr=0.01] Epoch 3183/4000: train_loss=0.2685  test_loss=2.9048  λ_max=95.4280\n",
      "[SGD | lr=0.01] Epoch 3184/4000: train_loss=0.2679  test_loss=2.9048  λ_max=99.2444\n",
      "[SGD | lr=0.01] Epoch 3185/4000: train_loss=0.2680  test_loss=2.9049  λ_max=97.2421\n",
      "[SGD | lr=0.01] Epoch 3186/4000: train_loss=0.2684  test_loss=2.9066  λ_max=100.3187\n",
      "[SGD | lr=0.01] Epoch 3187/4000: train_loss=0.2700  test_loss=2.9087  λ_max=100.9251\n",
      "[SGD | lr=0.01] Iter 51000: loss=0.2794\n",
      "[SGD | lr=0.01] Epoch 3188/4000: train_loss=0.2798  test_loss=2.9118  λ_max=101.6330\n",
      "[SGD | lr=0.01] Epoch 3189/4000: train_loss=0.2950  test_loss=2.9130  λ_max=93.0274\n",
      "[SGD | lr=0.01] Epoch 3190/4000: train_loss=0.2946  test_loss=2.9151  λ_max=101.9305\n",
      "[SGD | lr=0.01] Epoch 3191/4000: train_loss=0.2803  test_loss=2.9126  λ_max=97.7629\n",
      "[SGD | lr=0.01] Epoch 3192/4000: train_loss=0.2789  test_loss=2.9123  λ_max=95.5009\n",
      "[SGD | lr=0.01] Epoch 3193/4000: train_loss=0.2793  test_loss=2.9074  λ_max=102.6743\n",
      "[SGD | lr=0.01] Iter 51100: loss=0.2698\n",
      "[SGD | lr=0.01] Epoch 3194/4000: train_loss=0.2748  test_loss=2.9072  λ_max=102.4551\n",
      "[SGD | lr=0.01] Epoch 3195/4000: train_loss=0.2729  test_loss=2.9072  λ_max=97.2898\n",
      "[SGD | lr=0.01] Epoch 3196/4000: train_loss=0.2687  test_loss=2.9088  λ_max=97.4543\n",
      "[SGD | lr=0.01] Epoch 3197/4000: train_loss=0.2663  test_loss=2.9092  λ_max=98.2340\n",
      "[SGD | lr=0.01] Epoch 3198/4000: train_loss=0.2659  test_loss=2.9104  λ_max=100.6936\n",
      "[SGD | lr=0.01] Epoch 3199/4000: train_loss=0.2657  test_loss=2.9108  λ_max=94.1747\n",
      "[SGD | lr=0.01] Iter 51200: loss=0.2659\n",
      "[SGD | lr=0.01] Epoch 3200/4000: train_loss=0.2655  test_loss=2.9103  λ_max=96.4498\n",
      "[SGD | lr=0.01] Epoch 3201/4000: train_loss=0.2653  test_loss=2.9107  λ_max=96.5607\n",
      "[SGD | lr=0.01] Epoch 3202/4000: train_loss=0.2653  test_loss=2.9118  λ_max=98.7636\n",
      "[SGD | lr=0.01] Epoch 3203/4000: train_loss=0.2651  test_loss=2.9131  λ_max=95.9367\n",
      "[SGD | lr=0.01] Epoch 3204/4000: train_loss=0.2650  test_loss=2.9132  λ_max=93.3340\n",
      "[SGD | lr=0.01] Epoch 3205/4000: train_loss=0.2651  test_loss=2.9139  λ_max=96.0697\n",
      "[SGD | lr=0.01] Epoch 3206/4000: train_loss=0.2651  test_loss=2.9148  λ_max=95.4840\n",
      "[SGD | lr=0.01] Iter 51300: loss=0.2605\n",
      "[SGD | lr=0.01] Epoch 3207/4000: train_loss=0.2661  test_loss=2.9165  λ_max=101.1706\n",
      "[SGD | lr=0.01] Epoch 3208/4000: train_loss=0.2689  test_loss=2.9198  λ_max=97.3935\n",
      "[SGD | lr=0.01] Epoch 3209/4000: train_loss=0.2772  test_loss=2.9193  λ_max=101.3553\n",
      "[SGD | lr=0.01] Epoch 3210/4000: train_loss=0.2886  test_loss=2.9162  λ_max=104.1620\n",
      "[SGD | lr=0.01] Epoch 3211/4000: train_loss=0.2843  test_loss=2.9127  λ_max=101.2536\n",
      "[SGD | lr=0.01] Epoch 3212/4000: train_loss=0.2793  test_loss=2.9152  λ_max=95.4078\n",
      "[SGD | lr=0.01] Iter 51400: loss=0.2732\n",
      "[SGD | lr=0.01] Epoch 3213/4000: train_loss=0.2717  test_loss=2.9162  λ_max=97.3290\n",
      "[SGD | lr=0.01] Epoch 3214/4000: train_loss=0.2663  test_loss=2.9176  λ_max=99.9901\n",
      "[SGD | lr=0.01] Epoch 3215/4000: train_loss=0.2642  test_loss=2.9167  λ_max=101.1484\n",
      "[SGD | lr=0.01] Epoch 3216/4000: train_loss=0.2633  test_loss=2.9162  λ_max=95.6548\n",
      "[SGD | lr=0.01] Epoch 3217/4000: train_loss=0.2629  test_loss=2.9166  λ_max=97.2905\n",
      "[SGD | lr=0.01] Epoch 3218/4000: train_loss=0.2627  test_loss=2.9174  λ_max=96.5524\n",
      "[SGD | lr=0.01] Iter 51500: loss=0.2634\n",
      "[SGD | lr=0.01] Epoch 3219/4000: train_loss=0.2624  test_loss=2.9180  λ_max=98.5328\n",
      "[SGD | lr=0.01] Epoch 3220/4000: train_loss=0.2623  test_loss=2.9183  λ_max=101.4898\n",
      "[SGD | lr=0.01] Epoch 3221/4000: train_loss=0.2621  test_loss=2.9184  λ_max=97.8819\n",
      "[SGD | lr=0.01] Epoch 3222/4000: train_loss=0.2620  test_loss=2.9193  λ_max=97.3894\n",
      "[SGD | lr=0.01] Epoch 3223/4000: train_loss=0.2621  test_loss=2.9205  λ_max=95.7125\n",
      "[SGD | lr=0.01] Epoch 3224/4000: train_loss=0.2624  test_loss=2.9199  λ_max=97.5986\n",
      "[SGD | lr=0.01] Iter 51600: loss=0.2670\n",
      "[SGD | lr=0.01] Epoch 3225/4000: train_loss=0.2631  test_loss=2.9205  λ_max=99.4871\n",
      "[SGD | lr=0.01] Epoch 3226/4000: train_loss=0.2679  test_loss=2.9215  λ_max=102.0257\n",
      "[SGD | lr=0.01] Epoch 3227/4000: train_loss=0.2789  test_loss=2.9226  λ_max=96.6944\n",
      "[SGD | lr=0.01] Epoch 3228/4000: train_loss=0.2847  test_loss=2.9243  λ_max=98.4385\n",
      "[SGD | lr=0.01] Epoch 3229/4000: train_loss=0.2830  test_loss=2.9263  λ_max=105.3969\n",
      "[SGD | lr=0.01] Epoch 3230/4000: train_loss=0.2805  test_loss=2.9279  λ_max=94.4238\n",
      "[SGD | lr=0.01] Epoch 3231/4000: train_loss=0.2688  test_loss=2.9270  λ_max=98.7057\n",
      "[SGD | lr=0.01] Iter 51700: loss=0.2644\n",
      "[SGD | lr=0.01] Epoch 3232/4000: train_loss=0.2631  test_loss=2.9249  λ_max=97.4518\n",
      "[SGD | lr=0.01] Epoch 3233/4000: train_loss=0.2610  test_loss=2.9233  λ_max=99.0220\n",
      "[SGD | lr=0.01] Epoch 3234/4000: train_loss=0.2603  test_loss=2.9236  λ_max=99.3805\n",
      "[SGD | lr=0.01] Epoch 3235/4000: train_loss=0.2602  test_loss=2.9243  λ_max=96.1861\n",
      "[SGD | lr=0.01] Epoch 3236/4000: train_loss=0.2599  test_loss=2.9245  λ_max=102.7211\n",
      "[SGD | lr=0.01] Epoch 3237/4000: train_loss=0.2600  test_loss=2.9250  λ_max=97.3367\n",
      "[SGD | lr=0.01] Iter 51800: loss=0.2551\n",
      "[SGD | lr=0.01] Epoch 3238/4000: train_loss=0.2597  test_loss=2.9267  λ_max=100.7483\n",
      "[SGD | lr=0.01] Epoch 3239/4000: train_loss=0.2598  test_loss=2.9270  λ_max=99.1636\n",
      "[SGD | lr=0.01] Epoch 3240/4000: train_loss=0.2598  test_loss=2.9278  λ_max=100.3275\n",
      "[SGD | lr=0.01] Epoch 3241/4000: train_loss=0.2596  test_loss=2.9279  λ_max=97.4092\n",
      "[SGD | lr=0.01] Epoch 3242/4000: train_loss=0.2592  test_loss=2.9277  λ_max=96.8713\n",
      "[SGD | lr=0.01] Epoch 3243/4000: train_loss=0.2590  test_loss=2.9277  λ_max=99.8622\n",
      "[SGD | lr=0.01] Iter 51900: loss=0.2628\n",
      "[SGD | lr=0.01] Epoch 3244/4000: train_loss=0.2589  test_loss=2.9276  λ_max=95.1078\n",
      "[SGD | lr=0.01] Epoch 3245/4000: train_loss=0.2592  test_loss=2.9276  λ_max=95.7789\n",
      "[SGD | lr=0.01] Epoch 3246/4000: train_loss=0.2609  test_loss=2.9287  λ_max=97.3597\n",
      "[SGD | lr=0.01] Epoch 3247/4000: train_loss=0.2669  test_loss=2.9308  λ_max=100.7936\n",
      "[SGD | lr=0.01] Epoch 3248/4000: train_loss=0.2796  test_loss=2.9349  λ_max=101.3748\n",
      "[SGD | lr=0.01] Epoch 3249/4000: train_loss=0.2820  test_loss=2.9378  λ_max=96.0898\n",
      "[SGD | lr=0.01] Iter 52000: loss=0.2734\n",
      "[SGD | lr=0.01] Epoch 3250/4000: train_loss=0.2787  test_loss=2.9395  λ_max=99.7838\n",
      "[SGD | lr=0.01] Epoch 3251/4000: train_loss=0.2799  test_loss=2.9343  λ_max=96.7599\n",
      "[SGD | lr=0.01] Epoch 3252/4000: train_loss=0.2770  test_loss=2.9343  λ_max=95.6660\n",
      "[SGD | lr=0.01] Epoch 3253/4000: train_loss=0.2689  test_loss=2.9314  λ_max=99.5427\n",
      "[SGD | lr=0.01] Epoch 3254/4000: train_loss=0.2591  test_loss=2.9308  λ_max=94.1461\n",
      "[SGD | lr=0.01] Epoch 3255/4000: train_loss=0.2575  test_loss=2.9314  λ_max=95.6052\n",
      "[SGD | lr=0.01] Epoch 3256/4000: train_loss=0.2571  test_loss=2.9317  λ_max=99.4994\n",
      "[SGD | lr=0.01] Iter 52100: loss=0.2570\n",
      "[SGD | lr=0.01] Epoch 3257/4000: train_loss=0.2568  test_loss=2.9312  λ_max=98.9720\n",
      "[SGD | lr=0.01] Epoch 3258/4000: train_loss=0.2567  test_loss=2.9326  λ_max=99.0853\n",
      "[SGD | lr=0.01] Epoch 3259/4000: train_loss=0.2563  test_loss=2.9339  λ_max=99.7821\n",
      "[SGD | lr=0.01] Epoch 3260/4000: train_loss=0.2562  test_loss=2.9340  λ_max=95.0972\n",
      "[SGD | lr=0.01] Epoch 3261/4000: train_loss=0.2561  test_loss=2.9337  λ_max=96.5292\n",
      "[SGD | lr=0.01] Epoch 3262/4000: train_loss=0.2560  test_loss=2.9356  λ_max=98.0867\n",
      "[SGD | lr=0.01] Iter 52200: loss=0.2571\n",
      "[SGD | lr=0.01] Epoch 3263/4000: train_loss=0.2561  test_loss=2.9346  λ_max=99.1926\n",
      "[SGD | lr=0.01] Epoch 3264/4000: train_loss=0.2558  test_loss=2.9354  λ_max=94.4864\n",
      "[SGD | lr=0.01] Epoch 3265/4000: train_loss=0.2562  test_loss=2.9362  λ_max=97.5967\n",
      "[SGD | lr=0.01] Epoch 3266/4000: train_loss=0.2576  test_loss=2.9362  λ_max=96.9143\n",
      "[SGD | lr=0.01] Epoch 3267/4000: train_loss=0.2637  test_loss=2.9393  λ_max=99.5954\n",
      "[SGD | lr=0.01] Epoch 3268/4000: train_loss=0.2766  test_loss=2.9414  λ_max=96.2103\n",
      "[SGD | lr=0.01] Iter 52300: loss=0.2877\n",
      "[SGD | lr=0.01] Epoch 3269/4000: train_loss=0.2823  test_loss=2.9455  λ_max=98.8368\n",
      "[SGD | lr=0.01] Epoch 3270/4000: train_loss=0.2801  test_loss=2.9417  λ_max=95.7311\n",
      "[SGD | lr=0.01] Epoch 3271/4000: train_loss=0.2648  test_loss=2.9380  λ_max=94.5827\n",
      "[SGD | lr=0.01] Epoch 3272/4000: train_loss=0.2576  test_loss=2.9362  λ_max=101.3500\n",
      "[SGD | lr=0.01] Epoch 3273/4000: train_loss=0.2553  test_loss=2.9369  λ_max=98.9871\n",
      "[SGD | lr=0.01] Epoch 3274/4000: train_loss=0.2545  test_loss=2.9380  λ_max=100.7162\n",
      "[SGD | lr=0.01] Iter 52400: loss=0.2514\n",
      "[SGD | lr=0.01] Epoch 3275/4000: train_loss=0.2541  test_loss=2.9386  λ_max=100.1653\n",
      "[SGD | lr=0.01] Epoch 3276/4000: train_loss=0.2540  test_loss=2.9385  λ_max=104.0662\n",
      "[SGD | lr=0.01] Epoch 3277/4000: train_loss=0.2537  test_loss=2.9396  λ_max=95.6209\n",
      "[SGD | lr=0.01] Epoch 3278/4000: train_loss=0.2536  test_loss=2.9398  λ_max=102.4661\n",
      "[SGD | lr=0.01] Epoch 3279/4000: train_loss=0.2534  test_loss=2.9406  λ_max=96.2642\n",
      "[SGD | lr=0.01] Epoch 3280/4000: train_loss=0.2534  test_loss=2.9409  λ_max=103.5735\n",
      "[SGD | lr=0.01] Epoch 3281/4000: train_loss=0.2532  test_loss=2.9413  λ_max=101.5799\n",
      "[SGD | lr=0.01] Iter 52500: loss=0.2566\n",
      "[SGD | lr=0.01] Epoch 3282/4000: train_loss=0.2532  test_loss=2.9415  λ_max=102.8130\n",
      "[SGD | lr=0.01] Epoch 3283/4000: train_loss=0.2531  test_loss=2.9422  λ_max=101.6617\n",
      "[SGD | lr=0.01] Epoch 3284/4000: train_loss=0.2531  test_loss=2.9426  λ_max=98.5598\n",
      "[SGD | lr=0.01] Epoch 3285/4000: train_loss=0.2527  test_loss=2.9436  λ_max=98.6389\n",
      "[SGD | lr=0.01] Epoch 3286/4000: train_loss=0.2529  test_loss=2.9435  λ_max=98.7961\n",
      "[SGD | lr=0.01] Epoch 3287/4000: train_loss=0.2539  test_loss=2.9438  λ_max=103.2723\n",
      "[SGD | lr=0.01] Iter 52600: loss=0.2528\n",
      "[SGD | lr=0.01] Epoch 3288/4000: train_loss=0.2557  test_loss=2.9461  λ_max=103.1975\n",
      "[SGD | lr=0.01] Epoch 3289/4000: train_loss=0.2634  test_loss=2.9520  λ_max=100.6827\n",
      "[SGD | lr=0.01] Epoch 3290/4000: train_loss=0.2797  test_loss=2.9490  λ_max=99.7863\n",
      "[SGD | lr=0.01] Epoch 3291/4000: train_loss=0.2791  test_loss=2.9465  λ_max=97.8814\n",
      "[SGD | lr=0.01] Epoch 3292/4000: train_loss=0.2621  test_loss=2.9513  λ_max=96.1057\n",
      "[SGD | lr=0.01] Epoch 3293/4000: train_loss=0.2596  test_loss=2.9495  λ_max=101.4633\n",
      "[SGD | lr=0.01] Iter 52700: loss=0.2512\n",
      "[SGD | lr=0.01] Epoch 3294/4000: train_loss=0.2548  test_loss=2.9480  λ_max=95.9930\n",
      "[SGD | lr=0.01] Epoch 3295/4000: train_loss=0.2526  test_loss=2.9468  λ_max=102.3061\n",
      "[SGD | lr=0.01] Epoch 3296/4000: train_loss=0.2512  test_loss=2.9469  λ_max=103.4646\n",
      "[SGD | lr=0.01] Epoch 3297/4000: train_loss=0.2508  test_loss=2.9471  λ_max=96.7822\n",
      "[SGD | lr=0.01] Epoch 3298/4000: train_loss=0.2505  test_loss=2.9479  λ_max=102.4050\n",
      "[SGD | lr=0.01] Epoch 3299/4000: train_loss=0.2505  test_loss=2.9482  λ_max=97.8293\n",
      "[SGD | lr=0.01] Iter 52800: loss=0.2494\n",
      "[SGD | lr=0.01] Epoch 3300/4000: train_loss=0.2503  test_loss=2.9481  λ_max=103.0941\n",
      "[SGD | lr=0.01] Epoch 3301/4000: train_loss=0.2501  test_loss=2.9488  λ_max=98.4986\n",
      "[SGD | lr=0.01] Epoch 3302/4000: train_loss=0.2502  test_loss=2.9489  λ_max=102.2065\n",
      "[SGD | lr=0.01] Epoch 3303/4000: train_loss=0.2506  test_loss=2.9495  λ_max=105.6942\n",
      "[SGD | lr=0.01] Epoch 3304/4000: train_loss=0.2508  test_loss=2.9499  λ_max=99.5407\n",
      "[SGD | lr=0.01] Epoch 3305/4000: train_loss=0.2519  test_loss=2.9506  λ_max=98.5390\n",
      "[SGD | lr=0.01] Epoch 3306/4000: train_loss=0.2553  test_loss=2.9521  λ_max=100.3652\n",
      "[SGD | lr=0.01] Iter 52900: loss=0.2647\n",
      "[SGD | lr=0.01] Epoch 3307/4000: train_loss=0.2667  test_loss=2.9546  λ_max=98.8442\n",
      "[SGD | lr=0.01] Epoch 3308/4000: train_loss=0.2647  test_loss=2.9520  λ_max=102.8932\n",
      "[SGD | lr=0.01] Epoch 3309/4000: train_loss=0.2601  test_loss=2.9552  λ_max=102.2498\n",
      "[SGD | lr=0.01] Epoch 3310/4000: train_loss=0.2613  test_loss=2.9534  λ_max=98.8845\n",
      "[SGD | lr=0.01] Epoch 3311/4000: train_loss=0.2549  test_loss=2.9531  λ_max=101.0217\n",
      "[SGD | lr=0.01] Epoch 3312/4000: train_loss=0.2506  test_loss=2.9534  λ_max=99.3539\n",
      "[SGD | lr=0.01] Iter 53000: loss=0.2465\n",
      "[SGD | lr=0.01] Epoch 3313/4000: train_loss=0.2490  test_loss=2.9542  λ_max=98.3162\n",
      "[SGD | lr=0.01] Epoch 3314/4000: train_loss=0.2484  test_loss=2.9544  λ_max=97.0202\n",
      "[SGD | lr=0.01] Epoch 3315/4000: train_loss=0.2480  test_loss=2.9543  λ_max=100.3704\n",
      "[SGD | lr=0.01] Epoch 3316/4000: train_loss=0.2480  test_loss=2.9542  λ_max=101.4624\n",
      "[SGD | lr=0.01] Epoch 3317/4000: train_loss=0.2478  test_loss=2.9543  λ_max=99.8967\n",
      "[SGD | lr=0.01] Epoch 3318/4000: train_loss=0.2477  test_loss=2.9545  λ_max=98.7243\n",
      "[SGD | lr=0.01] Iter 53100: loss=0.2477\n",
      "[SGD | lr=0.01] Epoch 3319/4000: train_loss=0.2475  test_loss=2.9555  λ_max=92.6966\n",
      "[SGD | lr=0.01] Epoch 3320/4000: train_loss=0.2474  test_loss=2.9557  λ_max=96.1636\n",
      "[SGD | lr=0.01] Epoch 3321/4000: train_loss=0.2474  test_loss=2.9553  λ_max=98.8036\n",
      "[SGD | lr=0.01] Epoch 3322/4000: train_loss=0.2476  test_loss=2.9563  λ_max=96.4045\n",
      "[SGD | lr=0.01] Epoch 3323/4000: train_loss=0.2486  test_loss=2.9574  λ_max=98.6119\n",
      "[SGD | lr=0.01] Epoch 3324/4000: train_loss=0.2520  test_loss=2.9572  λ_max=103.3013\n",
      "[SGD | lr=0.01] Iter 53200: loss=0.2669\n",
      "[SGD | lr=0.01] Epoch 3325/4000: train_loss=0.2676  test_loss=2.9574  λ_max=106.0886\n",
      "[SGD | lr=0.01] Epoch 3326/4000: train_loss=0.2666  test_loss=2.9582  λ_max=102.3369\n",
      "[SGD | lr=0.01] Epoch 3327/4000: train_loss=0.2706  test_loss=2.9596  λ_max=106.5014\n",
      "[SGD | lr=0.01] Epoch 3328/4000: train_loss=0.2616  test_loss=2.9613  λ_max=101.3885\n",
      "[SGD | lr=0.01] Epoch 3329/4000: train_loss=0.2539  test_loss=2.9625  λ_max=98.1224\n",
      "[SGD | lr=0.01] Epoch 3330/4000: train_loss=0.2488  test_loss=2.9609  λ_max=98.6340\n",
      "[SGD | lr=0.01] Epoch 3331/4000: train_loss=0.2472  test_loss=2.9601  λ_max=101.7666\n",
      "[SGD | lr=0.01] Iter 53300: loss=0.2458\n",
      "[SGD | lr=0.01] Epoch 3332/4000: train_loss=0.2459  test_loss=2.9608  λ_max=102.1963\n",
      "[SGD | lr=0.01] Epoch 3333/4000: train_loss=0.2455  test_loss=2.9611  λ_max=98.9319\n",
      "[SGD | lr=0.01] Epoch 3334/4000: train_loss=0.2455  test_loss=2.9614  λ_max=101.1324\n",
      "[SGD | lr=0.01] Epoch 3335/4000: train_loss=0.2452  test_loss=2.9620  λ_max=104.8098\n",
      "[SGD | lr=0.01] Epoch 3336/4000: train_loss=0.2451  test_loss=2.9617  λ_max=97.1613\n",
      "[SGD | lr=0.01] Epoch 3337/4000: train_loss=0.2451  test_loss=2.9614  λ_max=99.2447\n",
      "[SGD | lr=0.01] Iter 53400: loss=0.2443\n",
      "[SGD | lr=0.01] Epoch 3338/4000: train_loss=0.2451  test_loss=2.9626  λ_max=98.8288\n",
      "[SGD | lr=0.01] Epoch 3339/4000: train_loss=0.2447  test_loss=2.9627  λ_max=100.3294\n",
      "[SGD | lr=0.01] Epoch 3340/4000: train_loss=0.2451  test_loss=2.9631  λ_max=101.1667\n",
      "[SGD | lr=0.01] Epoch 3341/4000: train_loss=0.2457  test_loss=2.9636  λ_max=99.7352\n",
      "[SGD | lr=0.01] Epoch 3342/4000: train_loss=0.2486  test_loss=2.9644  λ_max=98.2280\n",
      "[SGD | lr=0.01] Epoch 3343/4000: train_loss=0.2583  test_loss=2.9661  λ_max=101.9266\n",
      "[SGD | lr=0.01] Iter 53500: loss=0.2821\n",
      "[SGD | lr=0.01] Epoch 3344/4000: train_loss=0.2814  test_loss=2.9632  λ_max=100.2878\n",
      "[SGD | lr=0.01] Epoch 3345/4000: train_loss=0.2672  test_loss=2.9698  λ_max=100.6277\n",
      "[SGD | lr=0.01] Epoch 3346/4000: train_loss=0.2540  test_loss=2.9700  λ_max=99.6979\n",
      "[SGD | lr=0.01] Epoch 3347/4000: train_loss=0.2460  test_loss=2.9674  λ_max=96.8322\n",
      "[SGD | lr=0.01] Epoch 3348/4000: train_loss=0.2437  test_loss=2.9677  λ_max=101.7018\n",
      "[SGD | lr=0.01] Epoch 3349/4000: train_loss=0.2435  test_loss=2.9671  λ_max=101.6430\n",
      "[SGD | lr=0.01] Iter 53600: loss=0.2441\n",
      "[SGD | lr=0.01] Epoch 3350/4000: train_loss=0.2433  test_loss=2.9667  λ_max=102.5553\n",
      "[SGD | lr=0.01] Epoch 3351/4000: train_loss=0.2429  test_loss=2.9675  λ_max=102.6220\n",
      "[SGD | lr=0.01] Epoch 3352/4000: train_loss=0.2428  test_loss=2.9678  λ_max=98.9613\n",
      "[SGD | lr=0.01] Epoch 3353/4000: train_loss=0.2426  test_loss=2.9681  λ_max=100.3524\n",
      "[SGD | lr=0.01] Epoch 3354/4000: train_loss=0.2426  test_loss=2.9683  λ_max=101.2889\n",
      "[SGD | lr=0.01] Epoch 3355/4000: train_loss=0.2424  test_loss=2.9683  λ_max=100.9473\n",
      "[SGD | lr=0.01] Epoch 3356/4000: train_loss=0.2423  test_loss=2.9697  λ_max=102.2192\n",
      "[SGD | lr=0.01] Iter 53700: loss=0.2456\n",
      "[SGD | lr=0.01] Epoch 3357/4000: train_loss=0.2424  test_loss=2.9688  λ_max=104.1200\n",
      "[SGD | lr=0.01] Epoch 3358/4000: train_loss=0.2435  test_loss=2.9688  λ_max=101.7522\n",
      "[SGD | lr=0.01] Epoch 3359/4000: train_loss=0.2459  test_loss=2.9698  λ_max=103.9599\n",
      "[SGD | lr=0.01] Epoch 3360/4000: train_loss=0.2530  test_loss=2.9715  λ_max=107.1400\n",
      "[SGD | lr=0.01] Epoch 3361/4000: train_loss=0.2621  test_loss=2.9690  λ_max=97.8472\n",
      "[SGD | lr=0.01] Epoch 3362/4000: train_loss=0.2580  test_loss=2.9690  λ_max=101.8327\n",
      "[SGD | lr=0.01] Iter 53800: loss=0.2470\n",
      "[SGD | lr=0.01] Epoch 3363/4000: train_loss=0.2459  test_loss=2.9709  λ_max=100.7641\n",
      "[SGD | lr=0.01] Epoch 3364/4000: train_loss=0.2432  test_loss=2.9714  λ_max=100.5384\n",
      "[SGD | lr=0.01] Epoch 3365/4000: train_loss=0.2413  test_loss=2.9729  λ_max=103.1510\n",
      "[SGD | lr=0.01] Epoch 3366/4000: train_loss=0.2410  test_loss=2.9727  λ_max=99.6967\n",
      "[SGD | lr=0.01] Epoch 3367/4000: train_loss=0.2408  test_loss=2.9731  λ_max=101.9218\n",
      "[SGD | lr=0.01] Epoch 3368/4000: train_loss=0.2408  test_loss=2.9740  λ_max=99.5457\n",
      "[SGD | lr=0.01] Iter 53900: loss=0.2380\n",
      "[SGD | lr=0.01] Epoch 3369/4000: train_loss=0.2406  test_loss=2.9745  λ_max=100.9495\n",
      "[SGD | lr=0.01] Epoch 3370/4000: train_loss=0.2403  test_loss=2.9739  λ_max=100.0500\n",
      "[SGD | lr=0.01] Epoch 3371/4000: train_loss=0.2405  test_loss=2.9748  λ_max=102.8038\n",
      "[SGD | lr=0.01] Epoch 3372/4000: train_loss=0.2403  test_loss=2.9751  λ_max=101.1841\n",
      "[SGD | lr=0.01] Epoch 3373/4000: train_loss=0.2400  test_loss=2.9756  λ_max=97.4603\n",
      "[SGD | lr=0.01] Epoch 3374/4000: train_loss=0.2401  test_loss=2.9752  λ_max=101.7177\n",
      "[SGD | lr=0.01] Iter 54000: loss=0.2383\n",
      "[SGD | lr=0.01] Epoch 3375/4000: train_loss=0.2405  test_loss=2.9759  λ_max=101.7341\n",
      "[SGD | lr=0.01] Epoch 3376/4000: train_loss=0.2419  test_loss=2.9782  λ_max=101.8338\n",
      "[SGD | lr=0.01] Epoch 3377/4000: train_loss=0.2491  test_loss=2.9804  λ_max=100.8592\n",
      "[SGD | lr=0.01] Epoch 3378/4000: train_loss=0.2659  test_loss=2.9803  λ_max=100.5598\n",
      "[SGD | lr=0.01] Epoch 3379/4000: train_loss=0.2533  test_loss=2.9794  λ_max=102.7302\n",
      "[SGD | lr=0.01] Epoch 3380/4000: train_loss=0.2458  test_loss=2.9804  λ_max=104.9178\n",
      "[SGD | lr=0.01] Epoch 3381/4000: train_loss=0.2455  test_loss=2.9800  λ_max=104.2470\n",
      "[SGD | lr=0.01] Iter 54100: loss=0.2428\n",
      "[SGD | lr=0.01] Epoch 3382/4000: train_loss=0.2413  test_loss=2.9797  λ_max=102.8976\n",
      "[SGD | lr=0.01] Epoch 3383/4000: train_loss=0.2390  test_loss=2.9796  λ_max=99.7035\n",
      "[SGD | lr=0.01] Epoch 3384/4000: train_loss=0.2387  test_loss=2.9798  λ_max=95.9357\n",
      "[SGD | lr=0.01] Epoch 3385/4000: train_loss=0.2384  test_loss=2.9797  λ_max=104.1939\n",
      "[SGD | lr=0.01] Epoch 3386/4000: train_loss=0.2383  test_loss=2.9804  λ_max=98.5487\n",
      "[SGD | lr=0.01] Epoch 3387/4000: train_loss=0.2380  test_loss=2.9804  λ_max=105.9231\n",
      "[SGD | lr=0.01] Iter 54200: loss=0.2404\n",
      "[SGD | lr=0.01] Epoch 3388/4000: train_loss=0.2378  test_loss=2.9812  λ_max=102.8335\n",
      "[SGD | lr=0.01] Epoch 3389/4000: train_loss=0.2377  test_loss=2.9816  λ_max=99.8154\n",
      "[SGD | lr=0.01] Epoch 3390/4000: train_loss=0.2377  test_loss=2.9817  λ_max=99.5078\n",
      "[SGD | lr=0.01] Epoch 3391/4000: train_loss=0.2380  test_loss=2.9823  λ_max=106.1464\n",
      "[SGD | lr=0.01] Epoch 3392/4000: train_loss=0.2377  test_loss=2.9829  λ_max=104.4213\n",
      "[SGD | lr=0.01] Epoch 3393/4000: train_loss=0.2381  test_loss=2.9838  λ_max=104.3451\n",
      "[SGD | lr=0.01] Iter 54300: loss=0.2413\n",
      "[SGD | lr=0.01] Epoch 3394/4000: train_loss=0.2388  test_loss=2.9849  λ_max=105.1937\n",
      "[SGD | lr=0.01] Epoch 3395/4000: train_loss=0.2405  test_loss=2.9847  λ_max=100.0217\n",
      "[SGD | lr=0.01] Epoch 3396/4000: train_loss=0.2426  test_loss=2.9852  λ_max=102.1493\n",
      "[SGD | lr=0.01] Epoch 3397/4000: train_loss=0.2593  test_loss=2.9912  λ_max=99.9094\n",
      "[SGD | lr=0.01] Epoch 3398/4000: train_loss=0.2595  test_loss=2.9881  λ_max=101.7128\n",
      "[SGD | lr=0.01] Epoch 3399/4000: train_loss=0.2525  test_loss=2.9881  λ_max=98.4290\n",
      "[SGD | lr=0.01] Iter 54400: loss=0.2464\n",
      "[SGD | lr=0.01] Epoch 3400/4000: train_loss=0.2463  test_loss=2.9895  λ_max=100.6349\n",
      "[SGD | lr=0.01] Epoch 3401/4000: train_loss=0.2430  test_loss=2.9883  λ_max=100.5923\n",
      "[SGD | lr=0.01] Epoch 3402/4000: train_loss=0.2386  test_loss=2.9877  λ_max=100.7424\n",
      "[SGD | lr=0.01] Epoch 3403/4000: train_loss=0.2364  test_loss=2.9865  λ_max=101.5540\n",
      "[SGD | lr=0.01] Epoch 3404/4000: train_loss=0.2357  test_loss=2.9864  λ_max=100.3111\n",
      "[SGD | lr=0.01] Epoch 3405/4000: train_loss=0.2356  test_loss=2.9870  λ_max=101.2307\n",
      "[SGD | lr=0.01] Epoch 3406/4000: train_loss=0.2356  test_loss=2.9874  λ_max=103.1228\n",
      "[SGD | lr=0.01] Iter 54500: loss=0.2347\n",
      "[SGD | lr=0.01] Epoch 3407/4000: train_loss=0.2355  test_loss=2.9874  λ_max=104.1469\n",
      "[SGD | lr=0.01] Epoch 3408/4000: train_loss=0.2352  test_loss=2.9883  λ_max=98.2620\n",
      "[SGD | lr=0.01] Epoch 3409/4000: train_loss=0.2351  test_loss=2.9885  λ_max=105.0385\n",
      "[SGD | lr=0.01] Epoch 3410/4000: train_loss=0.2349  test_loss=2.9890  λ_max=100.0037\n",
      "[SGD | lr=0.01] Epoch 3411/4000: train_loss=0.2348  test_loss=2.9891  λ_max=102.4383\n",
      "[SGD | lr=0.01] Epoch 3412/4000: train_loss=0.2347  test_loss=2.9889  λ_max=99.7559\n",
      "[SGD | lr=0.01] Iter 54600: loss=0.2370\n",
      "[SGD | lr=0.01] Epoch 3413/4000: train_loss=0.2349  test_loss=2.9897  λ_max=105.2066\n",
      "[SGD | lr=0.01] Epoch 3414/4000: train_loss=0.2345  test_loss=2.9904  λ_max=103.3000\n",
      "[SGD | lr=0.01] Epoch 3415/4000: train_loss=0.2348  test_loss=2.9904  λ_max=102.2938\n",
      "[SGD | lr=0.01] Epoch 3416/4000: train_loss=0.2354  test_loss=2.9918  λ_max=100.9109\n",
      "[SGD | lr=0.01] Epoch 3417/4000: train_loss=0.2373  test_loss=2.9907  λ_max=101.8454\n",
      "[SGD | lr=0.01] Epoch 3418/4000: train_loss=0.2428  test_loss=2.9918  λ_max=98.3874\n",
      "[SGD | lr=0.01] Iter 54700: loss=0.2627\n",
      "[SGD | lr=0.01] Epoch 3419/4000: train_loss=0.2615  test_loss=2.9953  λ_max=100.9138\n",
      "[SGD | lr=0.01] Epoch 3420/4000: train_loss=0.2491  test_loss=2.9908  λ_max=98.5325\n",
      "[SGD | lr=0.01] Epoch 3421/4000: train_loss=0.2428  test_loss=2.9933  λ_max=104.3608\n",
      "[SGD | lr=0.01] Epoch 3422/4000: train_loss=0.2405  test_loss=2.9937  λ_max=103.3894\n",
      "[SGD | lr=0.01] Epoch 3423/4000: train_loss=0.2376  test_loss=2.9945  λ_max=101.0409\n",
      "[SGD | lr=0.01] Epoch 3424/4000: train_loss=0.2347  test_loss=2.9936  λ_max=102.3335\n",
      "[SGD | lr=0.01] Iter 54800: loss=0.2366\n",
      "[SGD | lr=0.01] Epoch 3425/4000: train_loss=0.2333  test_loss=2.9939  λ_max=101.5539\n",
      "[SGD | lr=0.01] Epoch 3426/4000: train_loss=0.2330  test_loss=2.9949  λ_max=103.4061\n",
      "[SGD | lr=0.01] Epoch 3427/4000: train_loss=0.2328  test_loss=2.9941  λ_max=96.0105\n",
      "[SGD | lr=0.01] Epoch 3428/4000: train_loss=0.2323  test_loss=2.9954  λ_max=103.4739\n",
      "[SGD | lr=0.01] Epoch 3429/4000: train_loss=0.2323  test_loss=2.9954  λ_max=104.2346\n",
      "[SGD | lr=0.01] Epoch 3430/4000: train_loss=0.2321  test_loss=2.9957  λ_max=101.5338\n",
      "[SGD | lr=0.01] Epoch 3431/4000: train_loss=0.2321  test_loss=2.9964  λ_max=101.5166\n",
      "[SGD | lr=0.01] Iter 54900: loss=0.2277\n",
      "[SGD | lr=0.01] Epoch 3432/4000: train_loss=0.2319  test_loss=2.9975  λ_max=102.4608\n",
      "[SGD | lr=0.01] Epoch 3433/4000: train_loss=0.2318  test_loss=2.9983  λ_max=103.0940\n",
      "[SGD | lr=0.01] Epoch 3434/4000: train_loss=0.2320  test_loss=2.9986  λ_max=101.6113\n",
      "[SGD | lr=0.01] Epoch 3435/4000: train_loss=0.2324  test_loss=2.9993  λ_max=101.3610\n",
      "[SGD | lr=0.01] Epoch 3436/4000: train_loss=0.2328  test_loss=3.0009  λ_max=102.5090\n",
      "[SGD | lr=0.01] Epoch 3437/4000: train_loss=0.2335  test_loss=3.0006  λ_max=104.3117\n",
      "[SGD | lr=0.01] Iter 55000: loss=0.2343\n",
      "[SGD | lr=0.01] Epoch 3438/4000: train_loss=0.2357  test_loss=3.0025  λ_max=106.5716\n",
      "[SGD | lr=0.01] Epoch 3439/4000: train_loss=0.2470  test_loss=3.0058  λ_max=104.4735\n",
      "[SGD | lr=0.01] Epoch 3440/4000: train_loss=0.2603  test_loss=3.0028  λ_max=109.3664\n",
      "[SGD | lr=0.01] Epoch 3441/4000: train_loss=0.2542  test_loss=3.0017  λ_max=108.6833\n",
      "[SGD | lr=0.01] Epoch 3442/4000: train_loss=0.2423  test_loss=3.0015  λ_max=104.2128\n",
      "[SGD | lr=0.01] Epoch 3443/4000: train_loss=0.2345  test_loss=3.0018  λ_max=100.6517\n",
      "[SGD | lr=0.01] Iter 55100: loss=0.2350\n",
      "[SGD | lr=0.01] Epoch 3444/4000: train_loss=0.2312  test_loss=3.0009  λ_max=104.2866\n",
      "[SGD | lr=0.01] Epoch 3445/4000: train_loss=0.2306  test_loss=3.0015  λ_max=105.8636\n",
      "[SGD | lr=0.01] Epoch 3446/4000: train_loss=0.2302  test_loss=3.0013  λ_max=99.8442\n",
      "[SGD | lr=0.01] Epoch 3447/4000: train_loss=0.2304  test_loss=3.0016  λ_max=103.3438\n",
      "[SGD | lr=0.01] Epoch 3448/4000: train_loss=0.2299  test_loss=3.0023  λ_max=101.9303\n",
      "[SGD | lr=0.01] Epoch 3449/4000: train_loss=0.2296  test_loss=3.0020  λ_max=104.3832\n",
      "[SGD | lr=0.01] Iter 55200: loss=0.2291\n",
      "[SGD | lr=0.01] Epoch 3450/4000: train_loss=0.2297  test_loss=3.0030  λ_max=101.7540\n",
      "[SGD | lr=0.01] Epoch 3451/4000: train_loss=0.2297  test_loss=3.0031  λ_max=100.6694\n",
      "[SGD | lr=0.01] Epoch 3452/4000: train_loss=0.2297  test_loss=3.0039  λ_max=104.5691\n",
      "[SGD | lr=0.01] Epoch 3453/4000: train_loss=0.2295  test_loss=3.0047  λ_max=101.8220\n",
      "[SGD | lr=0.01] Epoch 3454/4000: train_loss=0.2292  test_loss=3.0054  λ_max=103.0183\n",
      "[SGD | lr=0.01] Epoch 3455/4000: train_loss=0.2291  test_loss=3.0061  λ_max=97.4982\n",
      "[SGD | lr=0.01] Epoch 3456/4000: train_loss=0.2290  test_loss=3.0053  λ_max=102.6779\n",
      "[SGD | lr=0.01] Iter 55300: loss=0.2297\n",
      "[SGD | lr=0.01] Epoch 3457/4000: train_loss=0.2290  test_loss=3.0063  λ_max=102.4162\n",
      "[SGD | lr=0.01] Epoch 3458/4000: train_loss=0.2288  test_loss=3.0060  λ_max=101.5339\n",
      "[SGD | lr=0.01] Epoch 3459/4000: train_loss=0.2292  test_loss=3.0064  λ_max=102.6562\n",
      "[SGD | lr=0.01] Epoch 3460/4000: train_loss=0.2314  test_loss=3.0064  λ_max=105.9946\n",
      "[SGD | lr=0.01] Epoch 3461/4000: train_loss=0.2399  test_loss=3.0130  λ_max=106.1830\n",
      "[SGD | lr=0.01] Epoch 3462/4000: train_loss=0.2538  test_loss=3.0148  λ_max=104.5360\n",
      "[SGD | lr=0.01] Iter 55400: loss=0.2622\n",
      "[SGD | lr=0.01] Epoch 3463/4000: train_loss=0.2639  test_loss=3.0139  λ_max=97.5247\n",
      "[SGD | lr=0.01] Epoch 3464/4000: train_loss=0.2421  test_loss=3.0136  λ_max=98.5023\n",
      "[SGD | lr=0.01] Epoch 3465/4000: train_loss=0.2347  test_loss=3.0099  λ_max=104.7267\n",
      "[SGD | lr=0.01] Epoch 3466/4000: train_loss=0.2316  test_loss=3.0093  λ_max=101.4912\n",
      "[SGD | lr=0.01] Epoch 3467/4000: train_loss=0.2290  test_loss=3.0097  λ_max=103.6681\n",
      "[SGD | lr=0.01] Epoch 3468/4000: train_loss=0.2279  test_loss=3.0095  λ_max=104.0957\n",
      "[SGD | lr=0.01] Iter 55500: loss=0.2231\n",
      "[SGD | lr=0.01] Epoch 3469/4000: train_loss=0.2274  test_loss=3.0103  λ_max=103.3393\n",
      "[SGD | lr=0.01] Epoch 3470/4000: train_loss=0.2272  test_loss=3.0106  λ_max=98.6108\n",
      "[SGD | lr=0.01] Epoch 3471/4000: train_loss=0.2270  test_loss=3.0110  λ_max=97.2290\n",
      "[SGD | lr=0.01] Epoch 3472/4000: train_loss=0.2270  test_loss=3.0119  λ_max=102.7707\n",
      "[SGD | lr=0.01] Epoch 3473/4000: train_loss=0.2268  test_loss=3.0118  λ_max=102.1232\n",
      "[SGD | lr=0.01] Epoch 3474/4000: train_loss=0.2266  test_loss=3.0120  λ_max=102.6518\n",
      "[SGD | lr=0.01] Iter 55600: loss=0.2296\n",
      "[SGD | lr=0.01] Epoch 3475/4000: train_loss=0.2266  test_loss=3.0124  λ_max=99.4729\n",
      "[SGD | lr=0.01] Epoch 3476/4000: train_loss=0.2264  test_loss=3.0134  λ_max=108.9365\n",
      "[SGD | lr=0.01] Epoch 3477/4000: train_loss=0.2262  test_loss=3.0135  λ_max=104.9012\n",
      "[SGD | lr=0.01] Epoch 3478/4000: train_loss=0.2264  test_loss=3.0136  λ_max=106.3721\n",
      "[SGD | lr=0.01] Epoch 3479/4000: train_loss=0.2263  test_loss=3.0141  λ_max=97.0950\n",
      "[SGD | lr=0.01] Epoch 3480/4000: train_loss=0.2265  test_loss=3.0150  λ_max=101.3963\n",
      "[SGD | lr=0.01] Epoch 3481/4000: train_loss=0.2265  test_loss=3.0149  λ_max=105.1572\n",
      "[SGD | lr=0.01] Iter 55700: loss=0.2257\n",
      "[SGD | lr=0.01] Epoch 3482/4000: train_loss=0.2269  test_loss=3.0155  λ_max=102.4532\n",
      "[SGD | lr=0.01] Epoch 3483/4000: train_loss=0.2284  test_loss=3.0149  λ_max=100.8298\n",
      "[SGD | lr=0.01] Epoch 3484/4000: train_loss=0.2350  test_loss=3.0174  λ_max=103.5392\n",
      "[SGD | lr=0.01] Epoch 3485/4000: train_loss=0.2479  test_loss=3.0179  λ_max=102.1145\n",
      "[SGD | lr=0.01] Epoch 3486/4000: train_loss=0.2396  test_loss=3.0208  λ_max=106.2390\n",
      "[SGD | lr=0.01] Epoch 3487/4000: train_loss=0.2388  test_loss=3.0237  λ_max=103.6807\n",
      "[SGD | lr=0.01] Iter 55800: loss=0.2324\n",
      "[SGD | lr=0.01] Epoch 3488/4000: train_loss=0.2300  test_loss=3.0204  λ_max=101.9194\n",
      "[SGD | lr=0.01] Epoch 3489/4000: train_loss=0.2262  test_loss=3.0193  λ_max=106.6196\n",
      "[SGD | lr=0.01] Epoch 3490/4000: train_loss=0.2250  test_loss=3.0179  λ_max=101.6983\n",
      "[SGD | lr=0.01] Epoch 3491/4000: train_loss=0.2244  test_loss=3.0179  λ_max=103.9045\n",
      "[SGD | lr=0.01] Epoch 3492/4000: train_loss=0.2243  test_loss=3.0186  λ_max=103.1882\n",
      "[SGD | lr=0.01] Epoch 3493/4000: train_loss=0.2240  test_loss=3.0187  λ_max=104.9141\n",
      "[SGD | lr=0.01] Iter 55900: loss=0.2226\n",
      "[SGD | lr=0.01] Epoch 3494/4000: train_loss=0.2240  test_loss=3.0188  λ_max=103.8520\n",
      "[SGD | lr=0.01] Epoch 3495/4000: train_loss=0.2239  test_loss=3.0196  λ_max=105.0245\n",
      "[SGD | lr=0.01] Epoch 3496/4000: train_loss=0.2238  test_loss=3.0197  λ_max=101.9434\n",
      "[SGD | lr=0.01] Epoch 3497/4000: train_loss=0.2237  test_loss=3.0202  λ_max=106.4161\n",
      "[SGD | lr=0.01] Epoch 3498/4000: train_loss=0.2237  test_loss=3.0200  λ_max=98.9381\n",
      "[SGD | lr=0.01] Epoch 3499/4000: train_loss=0.2237  test_loss=3.0199  λ_max=101.6477\n",
      "[SGD | lr=0.01] Iter 56000: loss=0.2226\n",
      "[SGD | lr=0.01] Epoch 3500/4000: train_loss=0.2239  test_loss=3.0199  λ_max=101.2029\n",
      "[SGD | lr=0.01] Epoch 3501/4000: train_loss=0.2242  test_loss=3.0198  λ_max=108.3517\n",
      "[SGD | lr=0.01] Epoch 3502/4000: train_loss=0.2251  test_loss=3.0195  λ_max=106.7749\n",
      "[SGD | lr=0.01] Epoch 3503/4000: train_loss=0.2275  test_loss=3.0208  λ_max=110.5574\n",
      "[SGD | lr=0.01] Epoch 3504/4000: train_loss=0.2352  test_loss=3.0239  λ_max=105.9791\n",
      "[SGD | lr=0.01] Epoch 3505/4000: train_loss=0.2353  test_loss=3.0272  λ_max=104.9851\n",
      "[SGD | lr=0.01] Epoch 3506/4000: train_loss=0.2407  test_loss=3.0269  λ_max=109.7983\n",
      "[SGD | lr=0.01] Iter 56100: loss=0.2384\n",
      "[SGD | lr=0.01] Epoch 3507/4000: train_loss=0.2312  test_loss=3.0291  λ_max=102.1093\n",
      "[SGD | lr=0.01] Epoch 3508/4000: train_loss=0.2307  test_loss=3.0326  λ_max=103.5667\n",
      "[SGD | lr=0.01] Epoch 3509/4000: train_loss=0.2296  test_loss=3.0325  λ_max=102.6310\n",
      "[SGD | lr=0.01] Epoch 3510/4000: train_loss=0.2256  test_loss=3.0304  λ_max=103.4612\n",
      "[SGD | lr=0.01] Epoch 3511/4000: train_loss=0.2232  test_loss=3.0276  λ_max=102.5398\n",
      "[SGD | lr=0.01] Epoch 3512/4000: train_loss=0.2219  test_loss=3.0260  λ_max=103.3215\n",
      "[SGD | lr=0.01] Iter 56200: loss=0.2200\n",
      "[SGD | lr=0.01] Epoch 3513/4000: train_loss=0.2217  test_loss=3.0267  λ_max=107.2591\n",
      "[SGD | lr=0.01] Epoch 3514/4000: train_loss=0.2215  test_loss=3.0270  λ_max=101.1773\n",
      "[SGD | lr=0.01] Epoch 3515/4000: train_loss=0.2216  test_loss=3.0274  λ_max=105.6652\n",
      "[SGD | lr=0.01] Epoch 3516/4000: train_loss=0.2216  test_loss=3.0281  λ_max=102.1241\n",
      "[SGD | lr=0.01] Epoch 3517/4000: train_loss=0.2213  test_loss=3.0281  λ_max=103.3195\n",
      "[SGD | lr=0.01] Epoch 3518/4000: train_loss=0.2210  test_loss=3.0281  λ_max=100.1182\n",
      "[SGD | lr=0.01] Iter 56300: loss=0.2241\n",
      "[SGD | lr=0.01] Epoch 3519/4000: train_loss=0.2209  test_loss=3.0286  λ_max=107.9036\n",
      "[SGD | lr=0.01] Epoch 3520/4000: train_loss=0.2208  test_loss=3.0295  λ_max=103.2042\n",
      "[SGD | lr=0.01] Epoch 3521/4000: train_loss=0.2208  test_loss=3.0296  λ_max=103.9246\n",
      "[SGD | lr=0.01] Epoch 3522/4000: train_loss=0.2208  test_loss=3.0305  λ_max=107.0371\n",
      "[SGD | lr=0.01] Epoch 3523/4000: train_loss=0.2208  test_loss=3.0300  λ_max=104.2210\n",
      "[SGD | lr=0.01] Epoch 3524/4000: train_loss=0.2209  test_loss=3.0301  λ_max=106.6409\n",
      "[SGD | lr=0.01] Iter 56400: loss=0.2267\n",
      "[SGD | lr=0.01] Epoch 3525/4000: train_loss=0.2218  test_loss=3.0303  λ_max=107.0613\n",
      "[SGD | lr=0.01] Epoch 3526/4000: train_loss=0.2235  test_loss=3.0303  λ_max=101.7760\n",
      "[SGD | lr=0.01] Epoch 3527/4000: train_loss=0.2295  test_loss=3.0326  λ_max=104.8430\n",
      "[SGD | lr=0.01] Epoch 3528/4000: train_loss=0.2552  test_loss=3.0375  λ_max=105.8729\n",
      "[SGD | lr=0.01] Epoch 3529/4000: train_loss=0.2443  test_loss=3.0331  λ_max=103.1915\n",
      "[SGD | lr=0.01] Epoch 3530/4000: train_loss=0.2307  test_loss=3.0307  λ_max=106.6938\n",
      "[SGD | lr=0.01] Epoch 3531/4000: train_loss=0.2228  test_loss=3.0321  λ_max=104.9934\n",
      "[SGD | lr=0.01] Iter 56500: loss=0.2202\n",
      "[SGD | lr=0.01] Epoch 3532/4000: train_loss=0.2199  test_loss=3.0331  λ_max=104.6908\n",
      "[SGD | lr=0.01] Epoch 3533/4000: train_loss=0.2194  test_loss=3.0331  λ_max=104.5055\n",
      "[SGD | lr=0.01] Epoch 3534/4000: train_loss=0.2194  test_loss=3.0335  λ_max=104.5847\n",
      "[SGD | lr=0.01] Epoch 3535/4000: train_loss=0.2191  test_loss=3.0334  λ_max=104.2793\n",
      "[SGD | lr=0.01] Epoch 3536/4000: train_loss=0.2190  test_loss=3.0344  λ_max=103.8626\n",
      "[SGD | lr=0.01] Epoch 3537/4000: train_loss=0.2186  test_loss=3.0346  λ_max=107.1138\n",
      "[SGD | lr=0.01] Iter 56600: loss=0.2197\n",
      "[SGD | lr=0.01] Epoch 3538/4000: train_loss=0.2187  test_loss=3.0352  λ_max=105.6515\n",
      "[SGD | lr=0.01] Epoch 3539/4000: train_loss=0.2186  test_loss=3.0355  λ_max=105.5959\n",
      "[SGD | lr=0.01] Epoch 3540/4000: train_loss=0.2185  test_loss=3.0358  λ_max=103.5058\n",
      "[SGD | lr=0.01] Epoch 3541/4000: train_loss=0.2183  test_loss=3.0359  λ_max=107.6159\n",
      "[SGD | lr=0.01] Epoch 3542/4000: train_loss=0.2185  test_loss=3.0363  λ_max=101.4053\n",
      "[SGD | lr=0.01] Epoch 3543/4000: train_loss=0.2183  test_loss=3.0368  λ_max=108.9412\n",
      "[SGD | lr=0.01] Iter 56700: loss=0.2154\n",
      "[SGD | lr=0.01] Epoch 3544/4000: train_loss=0.2181  test_loss=3.0371  λ_max=101.4470\n",
      "[SGD | lr=0.01] Epoch 3545/4000: train_loss=0.2179  test_loss=3.0382  λ_max=106.5256\n",
      "[SGD | lr=0.01] Epoch 3546/4000: train_loss=0.2178  test_loss=3.0393  λ_max=105.3988\n",
      "[SGD | lr=0.01] Epoch 3547/4000: train_loss=0.2180  test_loss=3.0398  λ_max=104.4220\n",
      "[SGD | lr=0.01] Epoch 3548/4000: train_loss=0.2182  test_loss=3.0398  λ_max=101.2840\n",
      "[SGD | lr=0.01] Epoch 3549/4000: train_loss=0.2192  test_loss=3.0403  λ_max=104.8212\n",
      "[SGD | lr=0.01] Iter 56800: loss=0.2180\n",
      "[SGD | lr=0.01] Epoch 3550/4000: train_loss=0.2221  test_loss=3.0431  λ_max=104.7861\n",
      "[SGD | lr=0.01] Epoch 3551/4000: train_loss=0.2273  test_loss=3.0426  λ_max=106.8496\n",
      "[SGD | lr=0.01] Epoch 3552/4000: train_loss=0.2347  test_loss=3.0435  λ_max=103.4735\n",
      "[SGD | lr=0.01] Epoch 3553/4000: train_loss=0.2416  test_loss=3.0430  λ_max=106.5279\n",
      "[SGD | lr=0.01] Epoch 3554/4000: train_loss=0.2540  test_loss=3.0411  λ_max=105.3865\n",
      "[SGD | lr=0.01] Epoch 3555/4000: train_loss=0.2289  test_loss=3.0437  λ_max=108.7384\n",
      "[SGD | lr=0.01] Epoch 3556/4000: train_loss=0.2209  test_loss=3.0427  λ_max=109.8908\n",
      "[SGD | lr=0.01] Iter 56900: loss=0.2161\n",
      "[SGD | lr=0.01] Epoch 3557/4000: train_loss=0.2174  test_loss=3.0423  λ_max=104.3250\n",
      "[SGD | lr=0.01] Epoch 3558/4000: train_loss=0.2164  test_loss=3.0427  λ_max=100.2927\n",
      "[SGD | lr=0.01] Epoch 3559/4000: train_loss=0.2166  test_loss=3.0429  λ_max=103.7960\n",
      "[SGD | lr=0.01] Epoch 3560/4000: train_loss=0.2161  test_loss=3.0430  λ_max=105.1837\n",
      "[SGD | lr=0.01] Epoch 3561/4000: train_loss=0.2160  test_loss=3.0431  λ_max=108.8332\n",
      "[SGD | lr=0.01] Epoch 3562/4000: train_loss=0.2159  test_loss=3.0438  λ_max=103.0951\n",
      "[SGD | lr=0.01] Iter 57000: loss=0.2121\n",
      "[SGD | lr=0.01] Epoch 3563/4000: train_loss=0.2156  test_loss=3.0440  λ_max=102.6382\n",
      "[SGD | lr=0.01] Epoch 3564/4000: train_loss=0.2156  test_loss=3.0437  λ_max=104.0773\n",
      "[SGD | lr=0.01] Epoch 3565/4000: train_loss=0.2154  test_loss=3.0439  λ_max=100.4064\n",
      "[SGD | lr=0.01] Epoch 3566/4000: train_loss=0.2153  test_loss=3.0458  λ_max=104.2297\n",
      "[SGD | lr=0.01] Epoch 3567/4000: train_loss=0.2151  test_loss=3.0462  λ_max=100.3655\n",
      "[SGD | lr=0.01] Epoch 3568/4000: train_loss=0.2153  test_loss=3.0462  λ_max=107.3881\n",
      "[SGD | lr=0.01] Iter 57100: loss=0.2116\n",
      "[SGD | lr=0.01] Epoch 3569/4000: train_loss=0.2150  test_loss=3.0471  λ_max=100.2093\n",
      "[SGD | lr=0.01] Epoch 3570/4000: train_loss=0.2150  test_loss=3.0469  λ_max=103.5731\n",
      "[SGD | lr=0.01] Epoch 3571/4000: train_loss=0.2155  test_loss=3.0480  λ_max=107.5296\n",
      "[SGD | lr=0.01] Epoch 3572/4000: train_loss=0.2159  test_loss=3.0479  λ_max=106.9610\n",
      "[SGD | lr=0.01] Epoch 3573/4000: train_loss=0.2164  test_loss=3.0494  λ_max=103.4748\n",
      "[SGD | lr=0.01] Epoch 3574/4000: train_loss=0.2156  test_loss=3.0497  λ_max=106.3261\n",
      "[SGD | lr=0.01] Iter 57200: loss=0.2108\n",
      "[SGD | lr=0.01] Epoch 3575/4000: train_loss=0.2159  test_loss=3.0486  λ_max=106.7106\n",
      "[SGD | lr=0.01] Epoch 3576/4000: train_loss=0.2153  test_loss=3.0492  λ_max=106.2190\n",
      "[SGD | lr=0.01] Epoch 3577/4000: train_loss=0.2151  test_loss=3.0496  λ_max=104.6271\n",
      "[SGD | lr=0.01] Epoch 3578/4000: train_loss=0.2146  test_loss=3.0504  λ_max=102.8157\n",
      "[SGD | lr=0.01] Epoch 3579/4000: train_loss=0.2146  test_loss=3.0513  λ_max=104.9812\n",
      "[SGD | lr=0.01] Epoch 3580/4000: train_loss=0.2143  test_loss=3.0516  λ_max=105.0791\n",
      "[SGD | lr=0.01] Epoch 3581/4000: train_loss=0.2138  test_loss=3.0511  λ_max=104.8895\n",
      "[SGD | lr=0.01] Iter 57300: loss=0.2085\n",
      "[SGD | lr=0.01] Epoch 3582/4000: train_loss=0.2135  test_loss=3.0511  λ_max=108.3552\n",
      "[SGD | lr=0.01] Epoch 3583/4000: train_loss=0.2134  test_loss=3.0519  λ_max=105.4122\n",
      "[SGD | lr=0.01] Epoch 3584/4000: train_loss=0.2132  test_loss=3.0518  λ_max=102.4399\n",
      "[SGD | lr=0.01] Epoch 3585/4000: train_loss=0.2129  test_loss=3.0522  λ_max=104.9751\n",
      "[SGD | lr=0.01] Epoch 3586/4000: train_loss=0.2130  test_loss=3.0526  λ_max=105.3881\n",
      "[SGD | lr=0.01] Epoch 3587/4000: train_loss=0.2131  test_loss=3.0536  λ_max=104.7663\n",
      "[SGD | lr=0.01] Iter 57400: loss=0.2168\n",
      "[SGD | lr=0.01] Epoch 3588/4000: train_loss=0.2131  test_loss=3.0534  λ_max=106.6758\n",
      "[SGD | lr=0.01] Epoch 3589/4000: train_loss=0.2134  test_loss=3.0541  λ_max=105.5087\n",
      "[SGD | lr=0.01] Epoch 3590/4000: train_loss=0.2134  test_loss=3.0546  λ_max=110.9819\n",
      "[SGD | lr=0.01] Epoch 3591/4000: train_loss=0.2147  test_loss=3.0564  λ_max=103.4395\n",
      "[SGD | lr=0.01] Epoch 3592/4000: train_loss=0.2226  test_loss=3.0615  λ_max=105.9758\n",
      "[SGD | lr=0.01] Epoch 3593/4000: train_loss=0.2193  test_loss=3.0609  λ_max=105.7313\n",
      "[SGD | lr=0.01] Iter 57500: loss=0.2267\n",
      "[SGD | lr=0.01] Epoch 3594/4000: train_loss=0.2285  test_loss=3.0671  λ_max=106.0456\n",
      "[SGD | lr=0.01] Epoch 3595/4000: train_loss=0.2333  test_loss=3.0688  λ_max=105.8056\n",
      "[SGD | lr=0.01] Epoch 3596/4000: train_loss=0.2277  test_loss=3.0600  λ_max=102.9570\n",
      "[SGD | lr=0.01] Epoch 3597/4000: train_loss=0.2192  test_loss=3.0558  λ_max=106.7336\n",
      "[SGD | lr=0.01] Epoch 3598/4000: train_loss=0.2147  test_loss=3.0556  λ_max=100.6226\n",
      "[SGD | lr=0.01] Epoch 3599/4000: train_loss=0.2125  test_loss=3.0567  λ_max=104.0574\n",
      "[SGD | lr=0.01] Iter 57600: loss=0.2114\n",
      "[SGD | lr=0.01] Epoch 3600/4000: train_loss=0.2116  test_loss=3.0577  λ_max=105.0677\n",
      "[SGD | lr=0.01] Epoch 3601/4000: train_loss=0.2114  test_loss=3.0577  λ_max=109.2039\n",
      "[SGD | lr=0.01] Epoch 3602/4000: train_loss=0.2112  test_loss=3.0582  λ_max=109.9123\n",
      "[SGD | lr=0.01] Epoch 3603/4000: train_loss=0.2110  test_loss=3.0583  λ_max=101.6709\n",
      "[SGD | lr=0.01] Epoch 3604/4000: train_loss=0.2109  test_loss=3.0589  λ_max=104.7709\n",
      "[SGD | lr=0.01] Epoch 3605/4000: train_loss=0.2108  test_loss=3.0598  λ_max=104.6261\n",
      "[SGD | lr=0.01] Epoch 3606/4000: train_loss=0.2107  test_loss=3.0599  λ_max=110.2380\n",
      "[SGD | lr=0.01] Iter 57700: loss=0.2114\n",
      "[SGD | lr=0.01] Epoch 3607/4000: train_loss=0.2107  test_loss=3.0603  λ_max=102.9768\n",
      "[SGD | lr=0.01] Epoch 3608/4000: train_loss=0.2108  test_loss=3.0614  λ_max=106.3670\n",
      "[SGD | lr=0.01] Epoch 3609/4000: train_loss=0.2105  test_loss=3.0614  λ_max=107.6853\n",
      "[SGD | lr=0.01] Epoch 3610/4000: train_loss=0.2103  test_loss=3.0618  λ_max=106.2345\n",
      "[SGD | lr=0.01] Epoch 3611/4000: train_loss=0.2101  test_loss=3.0614  λ_max=103.3677\n",
      "[SGD | lr=0.01] Epoch 3612/4000: train_loss=0.2101  test_loss=3.0616  λ_max=107.7657\n",
      "[SGD | lr=0.01] Iter 57800: loss=0.2088\n",
      "[SGD | lr=0.01] Epoch 3613/4000: train_loss=0.2099  test_loss=3.0619  λ_max=102.1078\n",
      "[SGD | lr=0.01] Epoch 3614/4000: train_loss=0.2098  test_loss=3.0629  λ_max=107.9808\n",
      "[SGD | lr=0.01] Epoch 3615/4000: train_loss=0.2102  test_loss=3.0635  λ_max=101.2393\n",
      "[SGD | lr=0.01] Epoch 3616/4000: train_loss=0.2110  test_loss=3.0657  λ_max=107.4123\n",
      "[SGD | lr=0.01] Epoch 3617/4000: train_loss=0.2187  test_loss=3.0674  λ_max=106.8509\n",
      "[SGD | lr=0.01] Epoch 3618/4000: train_loss=0.2353  test_loss=3.0673  λ_max=105.0877\n",
      "[SGD | lr=0.01] Iter 57900: loss=0.2539\n",
      "[SGD | lr=0.01] Epoch 3619/4000: train_loss=0.2444  test_loss=3.0677  λ_max=107.5875\n",
      "[SGD | lr=0.01] Epoch 3620/4000: train_loss=0.2262  test_loss=3.0701  λ_max=102.3515\n",
      "[SGD | lr=0.01] Epoch 3621/4000: train_loss=0.2173  test_loss=3.0707  λ_max=101.2498\n",
      "[SGD | lr=0.01] Epoch 3622/4000: train_loss=0.2113  test_loss=3.0673  λ_max=105.8832\n",
      "[SGD | lr=0.01] Epoch 3623/4000: train_loss=0.2093  test_loss=3.0654  λ_max=104.6803\n",
      "[SGD | lr=0.01] Epoch 3624/4000: train_loss=0.2087  test_loss=3.0662  λ_max=110.7473\n",
      "[SGD | lr=0.01] Iter 58000: loss=0.2051\n",
      "[SGD | lr=0.01] Epoch 3625/4000: train_loss=0.2086  test_loss=3.0661  λ_max=103.4369\n",
      "[SGD | lr=0.01] Epoch 3626/4000: train_loss=0.2085  test_loss=3.0665  λ_max=107.2061\n",
      "[SGD | lr=0.01] Epoch 3627/4000: train_loss=0.2084  test_loss=3.0672  λ_max=102.1318\n",
      "[SGD | lr=0.01] Epoch 3628/4000: train_loss=0.2084  test_loss=3.0674  λ_max=105.8539\n",
      "[SGD | lr=0.01] Epoch 3629/4000: train_loss=0.2081  test_loss=3.0675  λ_max=103.7030\n",
      "[SGD | lr=0.01] Epoch 3630/4000: train_loss=0.2079  test_loss=3.0675  λ_max=108.6906\n",
      "[SGD | lr=0.01] Epoch 3631/4000: train_loss=0.2079  test_loss=3.0690  λ_max=110.8468\n",
      "[SGD | lr=0.01] Iter 58100: loss=0.2076\n",
      "[SGD | lr=0.01] Epoch 3632/4000: train_loss=0.2078  test_loss=3.0680  λ_max=111.7811\n",
      "[SGD | lr=0.01] Epoch 3633/4000: train_loss=0.2077  test_loss=3.0690  λ_max=105.9069\n",
      "[SGD | lr=0.01] Epoch 3634/4000: train_loss=0.2077  test_loss=3.0695  λ_max=107.6931\n",
      "[SGD | lr=0.01] Epoch 3635/4000: train_loss=0.2075  test_loss=3.0693  λ_max=108.0769\n",
      "[SGD | lr=0.01] Epoch 3636/4000: train_loss=0.2076  test_loss=3.0699  λ_max=104.6749\n",
      "[SGD | lr=0.01] Epoch 3637/4000: train_loss=0.2074  test_loss=3.0702  λ_max=107.0363\n",
      "[SGD | lr=0.01] Iter 58200: loss=0.2101\n",
      "[SGD | lr=0.01] Epoch 3638/4000: train_loss=0.2073  test_loss=3.0714  λ_max=104.6418\n",
      "[SGD | lr=0.01] Epoch 3639/4000: train_loss=0.2075  test_loss=3.0721  λ_max=100.8893\n",
      "[SGD | lr=0.01] Epoch 3640/4000: train_loss=0.2075  test_loss=3.0726  λ_max=105.5360\n",
      "[SGD | lr=0.01] Epoch 3641/4000: train_loss=0.2074  test_loss=3.0726  λ_max=107.0194\n",
      "[SGD | lr=0.01] Epoch 3642/4000: train_loss=0.2083  test_loss=3.0726  λ_max=103.1029\n",
      "[SGD | lr=0.01] Epoch 3643/4000: train_loss=0.2083  test_loss=3.0738  λ_max=105.5252\n",
      "[SGD | lr=0.01] Iter 58300: loss=0.2159\n",
      "[SGD | lr=0.01] Epoch 3644/4000: train_loss=0.2161  test_loss=3.0756  λ_max=107.8556\n",
      "[SGD | lr=0.01] Epoch 3645/4000: train_loss=0.2370  test_loss=3.0783  λ_max=108.9289\n",
      "[SGD | lr=0.01] Epoch 3646/4000: train_loss=0.2241  test_loss=3.0788  λ_max=103.4675\n",
      "[SGD | lr=0.01] Epoch 3647/4000: train_loss=0.2115  test_loss=3.0756  λ_max=105.9610\n",
      "[SGD | lr=0.01] Epoch 3648/4000: train_loss=0.2069  test_loss=3.0750  λ_max=105.8331\n",
      "[SGD | lr=0.01] Epoch 3649/4000: train_loss=0.2061  test_loss=3.0746  λ_max=104.9323\n",
      "[SGD | lr=0.01] Iter 58400: loss=0.2056\n",
      "[SGD | lr=0.01] Epoch 3650/4000: train_loss=0.2059  test_loss=3.0753  λ_max=103.4426\n",
      "[SGD | lr=0.01] Epoch 3651/4000: train_loss=0.2057  test_loss=3.0753  λ_max=103.7760\n",
      "[SGD | lr=0.01] Epoch 3652/4000: train_loss=0.2056  test_loss=3.0765  λ_max=104.0431\n",
      "[SGD | lr=0.01] Epoch 3653/4000: train_loss=0.2054  test_loss=3.0768  λ_max=110.0668\n",
      "[SGD | lr=0.01] Epoch 3654/4000: train_loss=0.2054  test_loss=3.0764  λ_max=107.1029\n",
      "[SGD | lr=0.01] Epoch 3655/4000: train_loss=0.2053  test_loss=3.0770  λ_max=108.5237\n",
      "[SGD | lr=0.01] Epoch 3656/4000: train_loss=0.2053  test_loss=3.0772  λ_max=108.3998\n",
      "[SGD | lr=0.01] Iter 58500: loss=0.2042\n",
      "[SGD | lr=0.01] Epoch 3657/4000: train_loss=0.2053  test_loss=3.0782  λ_max=105.6161\n",
      "[SGD | lr=0.01] Epoch 3658/4000: train_loss=0.2050  test_loss=3.0772  λ_max=109.7295\n",
      "[SGD | lr=0.01] Epoch 3659/4000: train_loss=0.2054  test_loss=3.0774  λ_max=104.5904\n",
      "[SGD | lr=0.01] Epoch 3660/4000: train_loss=0.2052  test_loss=3.0788  λ_max=103.5239\n",
      "[SGD | lr=0.01] Epoch 3661/4000: train_loss=0.2049  test_loss=3.0793  λ_max=106.0591\n",
      "[SGD | lr=0.01] Epoch 3662/4000: train_loss=0.2047  test_loss=3.0800  λ_max=112.1877\n",
      "[SGD | lr=0.01] Iter 58600: loss=0.2044\n",
      "[SGD | lr=0.01] Epoch 3663/4000: train_loss=0.2046  test_loss=3.0807  λ_max=111.4497\n",
      "[SGD | lr=0.01] Epoch 3664/4000: train_loss=0.2045  test_loss=3.0809  λ_max=111.5545\n",
      "[SGD | lr=0.01] Epoch 3665/4000: train_loss=0.2046  test_loss=3.0811  λ_max=106.8556\n",
      "[SGD | lr=0.01] Epoch 3666/4000: train_loss=0.2041  test_loss=3.0805  λ_max=107.6325\n",
      "[SGD | lr=0.01] Epoch 3667/4000: train_loss=0.2040  test_loss=3.0824  λ_max=103.4565\n",
      "[SGD | lr=0.01] Epoch 3668/4000: train_loss=0.2050  test_loss=3.0822  λ_max=100.1686\n",
      "[SGD | lr=0.01] Iter 58700: loss=0.2118\n",
      "[SGD | lr=0.01] Epoch 3669/4000: train_loss=0.2094  test_loss=3.0828  λ_max=103.7535\n",
      "[SGD | lr=0.01] Epoch 3670/4000: train_loss=0.2121  test_loss=3.0825  λ_max=109.3113\n",
      "[SGD | lr=0.01] Epoch 3671/4000: train_loss=0.2234  test_loss=3.0819  λ_max=114.4097\n",
      "[SGD | lr=0.01] Epoch 3672/4000: train_loss=0.2324  test_loss=3.0858  λ_max=111.7385\n",
      "[SGD | lr=0.01] Epoch 3673/4000: train_loss=0.2142  test_loss=3.0881  λ_max=109.2066\n",
      "[SGD | lr=0.01] Epoch 3674/4000: train_loss=0.2089  test_loss=3.0869  λ_max=105.7677\n",
      "[SGD | lr=0.01] Iter 58800: loss=0.2070\n",
      "[SGD | lr=0.01] Epoch 3675/4000: train_loss=0.2065  test_loss=3.0850  λ_max=110.9566\n",
      "[SGD | lr=0.01] Epoch 3676/4000: train_loss=0.2041  test_loss=3.0845  λ_max=106.7742\n",
      "[SGD | lr=0.01] Epoch 3677/4000: train_loss=0.2030  test_loss=3.0847  λ_max=105.6493\n",
      "[SGD | lr=0.01] Epoch 3678/4000: train_loss=0.2028  test_loss=3.0845  λ_max=103.9423\n",
      "[SGD | lr=0.01] Epoch 3679/4000: train_loss=0.2028  test_loss=3.0853  λ_max=106.2937\n",
      "[SGD | lr=0.01] Epoch 3680/4000: train_loss=0.2025  test_loss=3.0857  λ_max=111.0256\n",
      "[SGD | lr=0.01] Epoch 3681/4000: train_loss=0.2024  test_loss=3.0858  λ_max=107.9099\n",
      "[SGD | lr=0.01] Iter 58900: loss=0.2020\n",
      "[SGD | lr=0.01] Epoch 3682/4000: train_loss=0.2024  test_loss=3.0865  λ_max=108.9589\n",
      "[SGD | lr=0.01] Epoch 3683/4000: train_loss=0.2022  test_loss=3.0864  λ_max=105.4562\n",
      "[SGD | lr=0.01] Epoch 3684/4000: train_loss=0.2021  test_loss=3.0864  λ_max=108.8390\n",
      "[SGD | lr=0.01] Epoch 3685/4000: train_loss=0.2018  test_loss=3.0866  λ_max=107.1521\n",
      "[SGD | lr=0.01] Epoch 3686/4000: train_loss=0.2017  test_loss=3.0871  λ_max=105.5840\n",
      "[SGD | lr=0.01] Epoch 3687/4000: train_loss=0.2018  test_loss=3.0886  λ_max=104.7360\n",
      "[SGD | lr=0.01] Iter 59000: loss=0.2007\n",
      "[SGD | lr=0.01] Epoch 3688/4000: train_loss=0.2018  test_loss=3.0888  λ_max=102.4212\n",
      "[SGD | lr=0.01] Epoch 3689/4000: train_loss=0.2015  test_loss=3.0889  λ_max=103.8615\n",
      "[SGD | lr=0.01] Epoch 3690/4000: train_loss=0.2017  test_loss=3.0891  λ_max=109.1052\n",
      "[SGD | lr=0.01] Epoch 3691/4000: train_loss=0.2015  test_loss=3.0889  λ_max=104.9668\n",
      "[SGD | lr=0.01] Epoch 3692/4000: train_loss=0.2015  test_loss=3.0893  λ_max=106.7237\n",
      "[SGD | lr=0.01] Epoch 3693/4000: train_loss=0.2015  test_loss=3.0902  λ_max=109.4534\n",
      "[SGD | lr=0.01] Iter 59100: loss=0.2019\n",
      "[SGD | lr=0.01] Epoch 3694/4000: train_loss=0.2015  test_loss=3.0918  λ_max=102.6814\n",
      "[SGD | lr=0.01] Epoch 3695/4000: train_loss=0.2017  test_loss=3.0928  λ_max=107.3835\n",
      "[SGD | lr=0.01] Epoch 3696/4000: train_loss=0.2023  test_loss=3.0939  λ_max=108.0312\n",
      "[SGD | lr=0.01] Epoch 3697/4000: train_loss=0.2038  test_loss=3.0955  λ_max=104.7373\n",
      "[SGD | lr=0.01] Epoch 3698/4000: train_loss=0.2090  test_loss=3.0986  λ_max=111.5839\n",
      "[SGD | lr=0.01] Epoch 3699/4000: train_loss=0.2354  test_loss=3.1040  λ_max=111.2847\n",
      "[SGD | lr=0.01] Iter 59200: loss=0.2214\n",
      "[SGD | lr=0.01] Epoch 3700/4000: train_loss=0.2366  test_loss=3.0955  λ_max=110.2887\n",
      "[SGD | lr=0.01] Epoch 3701/4000: train_loss=0.2164  test_loss=3.0931  λ_max=114.2880\n",
      "[SGD | lr=0.01] Epoch 3702/4000: train_loss=0.2158  test_loss=3.0947  λ_max=108.0621\n",
      "[SGD | lr=0.001] Epoch 207/4000: train_loss=2.2034  test_loss=2.2184  λ_max=3.2315\n",
      "[SGD | lr=0.001] Epoch 208/4000: train_loss=2.2033  test_loss=2.2183  λ_max=3.2917\n",
      "[SGD | lr=0.001] Epoch 209/4000: train_loss=2.2033  test_loss=2.2182  λ_max=3.2115\n",
      "[SGD | lr=0.001] Epoch 210/4000: train_loss=2.2031  test_loss=2.2181  λ_max=3.4638\n",
      "[SGD | lr=0.001] Epoch 211/4000: train_loss=2.2031  test_loss=2.2179  λ_max=3.3075\n",
      "[SGD | lr=0.001] Epoch 212/4000: train_loss=2.2029  test_loss=2.2178  λ_max=3.3490\n",
      "[SGD | lr=0.001] Iter 3400: loss=2.2037\n",
      "[SGD | lr=0.001] Epoch 213/4000: train_loss=2.2026  test_loss=2.2177  λ_max=3.4081\n",
      "[SGD | lr=0.001] Epoch 214/4000: train_loss=2.2026  test_loss=2.2176  λ_max=3.3514\n",
      "[SGD | lr=0.001] Epoch 215/4000: train_loss=2.2024  test_loss=2.2175  λ_max=3.1763\n",
      "[SGD | lr=0.001] Epoch 216/4000: train_loss=2.2023  test_loss=2.2174  λ_max=3.3790\n",
      "[SGD | lr=0.001] Epoch 217/4000: train_loss=2.2022  test_loss=2.2172  λ_max=3.2652\n",
      "[SGD | lr=0.001] Epoch 218/4000: train_loss=2.2022  test_loss=2.2171  λ_max=3.3938\n",
      "[SGD | lr=0.001] Iter 3500: loss=2.2017\n",
      "[SGD | lr=0.001] Epoch 219/4000: train_loss=2.2021  test_loss=2.2170  λ_max=3.2688\n",
      "[SGD | lr=0.001] Epoch 220/4000: train_loss=2.2018  test_loss=2.2169  λ_max=3.1601\n",
      "[SGD | lr=0.001] Epoch 221/4000: train_loss=2.2019  test_loss=2.2168  λ_max=3.2841\n",
      "[SGD | lr=0.001] Epoch 222/4000: train_loss=2.2016  test_loss=2.2167  λ_max=3.3659\n",
      "[SGD | lr=0.001] Epoch 223/4000: train_loss=2.2015  test_loss=2.2166  λ_max=3.3289\n",
      "[SGD | lr=0.001] Epoch 224/4000: train_loss=2.2015  test_loss=2.2165  λ_max=3.1709\n",
      "[SGD | lr=0.001] Iter 3600: loss=2.2021\n",
      "[SGD | lr=0.001] Epoch 225/4000: train_loss=2.2014  test_loss=2.2164  λ_max=3.1343\n",
      "[SGD | lr=0.001] Epoch 226/4000: train_loss=2.2013  test_loss=2.2163  λ_max=3.3220\n",
      "[SGD | lr=0.001] Epoch 227/4000: train_loss=2.2011  test_loss=2.2162  λ_max=3.1779\n",
      "[SGD | lr=0.001] Epoch 228/4000: train_loss=2.2012  test_loss=2.2161  λ_max=3.2484\n",
      "[SGD | lr=0.001] Epoch 229/4000: train_loss=2.2009  test_loss=2.2160  λ_max=3.2303\n",
      "[SGD | lr=0.001] Epoch 230/4000: train_loss=2.2008  test_loss=2.2159  λ_max=3.3147\n",
      "[SGD | lr=0.001] Epoch 231/4000: train_loss=2.2007  test_loss=2.2158  λ_max=3.2593\n",
      "[SGD | lr=0.001] Iter 3700: loss=2.1971\n",
      "[SGD | lr=0.001] Epoch 232/4000: train_loss=2.2007  test_loss=2.2157  λ_max=3.2561\n",
      "[SGD | lr=0.001] Epoch 233/4000: train_loss=2.2006  test_loss=2.2156  λ_max=3.2613\n",
      "[SGD | lr=0.001] Epoch 234/4000: train_loss=2.2004  test_loss=2.2155  λ_max=3.2985\n",
      "[SGD | lr=0.001] Epoch 235/4000: train_loss=2.2004  test_loss=2.2154  λ_max=3.1765\n",
      "[SGD | lr=0.001] Epoch 236/4000: train_loss=2.2002  test_loss=2.2153  λ_max=3.3112\n",
      "[SGD | lr=0.001] Epoch 237/4000: train_loss=2.2000  test_loss=2.2153  λ_max=3.2065\n",
      "[SGD | lr=0.001] Iter 3800: loss=2.1996\n",
      "[SGD | lr=0.001] Epoch 238/4000: train_loss=2.2001  test_loss=2.2152  λ_max=3.2581\n",
      "[SGD | lr=0.001] Epoch 239/4000: train_loss=2.1999  test_loss=2.2151  λ_max=3.2793\n",
      "[SGD | lr=0.001] Epoch 240/4000: train_loss=2.2000  test_loss=2.2150  λ_max=3.0597\n",
      "[SGD | lr=0.001] Epoch 241/4000: train_loss=2.1998  test_loss=2.2149  λ_max=3.2263\n",
      "[SGD | lr=0.001] Epoch 242/4000: train_loss=2.1997  test_loss=2.2148  λ_max=3.1123\n",
      "[SGD | lr=0.001] Epoch 243/4000: train_loss=2.1997  test_loss=2.2147  λ_max=3.1702\n",
      "[SGD | lr=0.001] Iter 3900: loss=2.2001\n",
      "[SGD | lr=0.001] Epoch 244/4000: train_loss=2.1996  test_loss=2.2147  λ_max=3.2189\n",
      "[SGD | lr=0.001] Epoch 245/4000: train_loss=2.1995  test_loss=2.2146  λ_max=3.1557\n",
      "[SGD | lr=0.001] Epoch 246/4000: train_loss=2.1995  test_loss=2.2145  λ_max=3.2652\n",
      "[SGD | lr=0.001] Epoch 247/4000: train_loss=2.1993  test_loss=2.2144  λ_max=3.2090\n",
      "[SGD | lr=0.001] Epoch 248/4000: train_loss=2.1993  test_loss=2.2143  λ_max=3.2511\n",
      "[SGD | lr=0.001] Epoch 249/4000: train_loss=2.1993  test_loss=2.2143  λ_max=3.2514\n",
      "[SGD | lr=0.001] Iter 4000: loss=2.1974\n",
      "[SGD | lr=0.001] Epoch 250/4000: train_loss=2.1990  test_loss=2.2142  λ_max=3.2694\n",
      "[SGD | lr=0.001] Epoch 251/4000: train_loss=2.1989  test_loss=2.2141  λ_max=3.2478\n",
      "[SGD | lr=0.001] Epoch 252/4000: train_loss=2.1989  test_loss=2.2140  λ_max=3.1702\n",
      "[SGD | lr=0.001] Epoch 253/4000: train_loss=2.1989  test_loss=2.2139  λ_max=3.2195\n",
      "[SGD | lr=0.001] Epoch 254/4000: train_loss=2.1988  test_loss=2.2139  λ_max=3.1716\n",
      "[SGD | lr=0.001] Epoch 255/4000: train_loss=2.1986  test_loss=2.2138  λ_max=3.1906\n",
      "[SGD | lr=0.001] Epoch 256/4000: train_loss=2.1987  test_loss=2.2137  λ_max=3.1002\n",
      "[SGD | lr=0.001] Iter 4100: loss=2.1987\n",
      "[SGD | lr=0.001] Epoch 257/4000: train_loss=2.1985  test_loss=2.2136  λ_max=3.2095\n",
      "[SGD | lr=0.001] Epoch 258/4000: train_loss=2.1985  test_loss=2.2136  λ_max=3.1296\n",
      "[SGD | lr=0.001] Epoch 259/4000: train_loss=2.1985  test_loss=2.2135  λ_max=3.2064\n",
      "[SGD | lr=0.001] Epoch 260/4000: train_loss=2.1983  test_loss=2.2134  λ_max=3.0733\n",
      "[SGD | lr=0.001] Epoch 261/4000: train_loss=2.1983  test_loss=2.2134  λ_max=3.2171\n",
      "[SGD | lr=0.001] Epoch 262/4000: train_loss=2.1982  test_loss=2.2133  λ_max=3.0512\n",
      "[SGD | lr=0.001] Iter 4200: loss=2.1972\n",
      "[SGD | lr=0.001] Epoch 263/4000: train_loss=2.1981  test_loss=2.2132  λ_max=3.0009\n",
      "[SGD | lr=0.001] Epoch 264/4000: train_loss=2.1979  test_loss=2.2132  λ_max=3.1270\n",
      "[SGD | lr=0.001] Epoch 265/4000: train_loss=2.1980  test_loss=2.2131  λ_max=2.9912\n",
      "[SGD | lr=0.001] Epoch 266/4000: train_loss=2.1978  test_loss=2.2130  λ_max=3.1566\n",
      "[SGD | lr=0.001] Epoch 267/4000: train_loss=2.1979  test_loss=2.2130  λ_max=3.1176\n",
      "[SGD | lr=0.001] Epoch 268/4000: train_loss=2.1978  test_loss=2.2129  λ_max=3.0770\n",
      "[SGD | lr=0.001] Iter 4300: loss=2.1986\n",
      "[SGD | lr=0.001] Epoch 269/4000: train_loss=2.1976  test_loss=2.2128  λ_max=3.1172\n",
      "[SGD | lr=0.001] Epoch 270/4000: train_loss=2.1977  test_loss=2.2128  λ_max=2.9550\n",
      "[SGD | lr=0.001] Epoch 271/4000: train_loss=2.1976  test_loss=2.2127  λ_max=3.2275\n",
      "[SGD | lr=0.001] Epoch 272/4000: train_loss=2.1975  test_loss=2.2126  λ_max=3.1709\n",
      "[SGD | lr=0.001] Epoch 273/4000: train_loss=2.1975  test_loss=2.2126  λ_max=3.0976\n",
      "[SGD | lr=0.001] Epoch 274/4000: train_loss=2.1972  test_loss=2.2125  λ_max=2.9477\n",
      "[SGD | lr=0.001] Iter 4400: loss=2.1977\n",
      "[SGD | lr=0.001] Epoch 275/4000: train_loss=2.1973  test_loss=2.2125  λ_max=3.0751\n",
      "[SGD | lr=0.001] Epoch 276/4000: train_loss=2.1971  test_loss=2.2124  λ_max=3.0044\n",
      "[SGD | lr=0.001] Epoch 277/4000: train_loss=2.1972  test_loss=2.2123  λ_max=3.0622\n",
      "[SGD | lr=0.001] Epoch 278/4000: train_loss=2.1971  test_loss=2.2123  λ_max=2.9870\n",
      "[SGD | lr=0.001] Epoch 279/4000: train_loss=2.1970  test_loss=2.2122  λ_max=3.2263\n",
      "[SGD | lr=0.001] Epoch 280/4000: train_loss=2.1969  test_loss=2.2122  λ_max=3.0200\n",
      "[SGD | lr=0.001] Epoch 281/4000: train_loss=2.1968  test_loss=2.2121  λ_max=3.1873\n",
      "[SGD | lr=0.001] Iter 4500: loss=2.1981\n",
      "[SGD | lr=0.001] Epoch 282/4000: train_loss=2.1968  test_loss=2.2120  λ_max=3.0205\n",
      "[SGD | lr=0.001] Epoch 283/4000: train_loss=2.1967  test_loss=2.2120  λ_max=3.1230\n",
      "[SGD | lr=0.001] Epoch 284/4000: train_loss=2.1968  test_loss=2.2119  λ_max=3.0531\n",
      "[SGD | lr=0.001] Epoch 285/4000: train_loss=2.1966  test_loss=2.2119  λ_max=3.0585\n",
      "[SGD | lr=0.001] Epoch 286/4000: train_loss=2.1966  test_loss=2.2118  λ_max=3.0689\n",
      "[SGD | lr=0.001] Epoch 287/4000: train_loss=2.1966  test_loss=2.2118  λ_max=2.9964\n",
      "[SGD | lr=0.001] Iter 4600: loss=2.1986\n",
      "[SGD | lr=0.001] Epoch 288/4000: train_loss=2.1965  test_loss=2.2117  λ_max=3.1529\n",
      "[SGD | lr=0.001] Epoch 289/4000: train_loss=2.1963  test_loss=2.2117  λ_max=2.9024\n",
      "[SGD | lr=0.001] Epoch 290/4000: train_loss=2.1963  test_loss=2.2116  λ_max=3.0204\n",
      "[SGD | lr=0.001] Epoch 291/4000: train_loss=2.1962  test_loss=2.2116  λ_max=3.0091\n",
      "[SGD | lr=0.001] Epoch 292/4000: train_loss=2.1961  test_loss=2.2115  λ_max=3.0512\n",
      "[SGD | lr=0.001] Epoch 293/4000: train_loss=2.1962  test_loss=2.2115  λ_max=3.1707\n",
      "[SGD | lr=0.001] Iter 4700: loss=2.1999\n",
      "[SGD | lr=0.001] Epoch 294/4000: train_loss=2.1961  test_loss=2.2114  λ_max=3.0949\n",
      "[SGD | lr=0.001] Epoch 295/4000: train_loss=2.1961  test_loss=2.2114  λ_max=2.9471\n",
      "[SGD | lr=0.001] Epoch 296/4000: train_loss=2.1960  test_loss=2.2113  λ_max=3.1036\n",
      "[SGD | lr=0.001] Epoch 297/4000: train_loss=2.1959  test_loss=2.2113  λ_max=3.0138\n",
      "[SGD | lr=0.001] Epoch 298/4000: train_loss=2.1958  test_loss=2.2112  λ_max=3.1120\n",
      "[SGD | lr=0.001] Epoch 299/4000: train_loss=2.1958  test_loss=2.2112  λ_max=2.9823\n",
      "[SGD | lr=0.001] Iter 4800: loss=2.1976\n",
      "[SGD | lr=0.001] Epoch 300/4000: train_loss=2.1958  test_loss=2.2111  λ_max=3.0407\n",
      "[SGD | lr=0.001] Epoch 301/4000: train_loss=2.1958  test_loss=2.2111  λ_max=3.0987\n",
      "[SGD | lr=0.001] Epoch 302/4000: train_loss=2.1956  test_loss=2.2110  λ_max=2.9729\n",
      "[SGD | lr=0.001] Epoch 303/4000: train_loss=2.1956  test_loss=2.2110  λ_max=3.0639\n",
      "[SGD | lr=0.001] Epoch 304/4000: train_loss=2.1955  test_loss=2.2109  λ_max=3.0788\n",
      "[SGD | lr=0.001] Epoch 305/4000: train_loss=2.1955  test_loss=2.2109  λ_max=3.0647\n",
      "[SGD | lr=0.001] Epoch 306/4000: train_loss=2.1954  test_loss=2.2108  λ_max=3.0377\n",
      "[SGD | lr=0.001] Iter 4900: loss=2.1947\n",
      "[SGD | lr=0.001] Epoch 307/4000: train_loss=2.1955  test_loss=2.2108  λ_max=3.0533\n",
      "[SGD | lr=0.001] Epoch 308/4000: train_loss=2.1952  test_loss=2.2107  λ_max=3.0024\n",
      "[SGD | lr=0.001] Epoch 309/4000: train_loss=2.1952  test_loss=2.2107  λ_max=2.8470\n",
      "[SGD | lr=0.001] Epoch 310/4000: train_loss=2.1953  test_loss=2.2107  λ_max=2.8911\n",
      "[SGD | lr=0.001] Epoch 311/4000: train_loss=2.1951  test_loss=2.2106  λ_max=2.9886\n",
      "[SGD | lr=0.001] Epoch 312/4000: train_loss=2.1951  test_loss=2.2106  λ_max=2.8843\n",
      "[SGD | lr=0.001] Iter 5000: loss=2.1959\n",
      "[SGD | lr=0.001] Epoch 313/4000: train_loss=2.1951  test_loss=2.2105  λ_max=3.0572\n",
      "[SGD | lr=0.001] Epoch 314/4000: train_loss=2.1951  test_loss=2.2105  λ_max=2.9206\n",
      "[SGD | lr=0.001] Epoch 315/4000: train_loss=2.1950  test_loss=2.2104  λ_max=2.8918\n",
      "[SGD | lr=0.001] Epoch 316/4000: train_loss=2.1949  test_loss=2.2104  λ_max=2.9832\n",
      "[SGD | lr=0.001] Epoch 317/4000: train_loss=2.1949  test_loss=2.2104  λ_max=2.9018\n",
      "[SGD | lr=0.001] Epoch 318/4000: train_loss=2.1949  test_loss=2.2103  λ_max=2.9873\n",
      "[SGD | lr=0.001] Iter 5100: loss=2.1944\n",
      "[SGD | lr=0.001] Epoch 319/4000: train_loss=2.1947  test_loss=2.2103  λ_max=2.8176\n",
      "[SGD | lr=0.001] Epoch 320/4000: train_loss=2.1948  test_loss=2.2102  λ_max=2.8982\n",
      "[SGD | lr=0.001] Epoch 321/4000: train_loss=2.1947  test_loss=2.2102  λ_max=2.9432\n",
      "[SGD | lr=0.001] Epoch 322/4000: train_loss=2.1947  test_loss=2.2102  λ_max=3.0120\n",
      "[SGD | lr=0.001] Epoch 323/4000: train_loss=2.1946  test_loss=2.2101  λ_max=2.8765\n",
      "[SGD | lr=0.001] Epoch 324/4000: train_loss=2.1946  test_loss=2.2101  λ_max=3.0452\n",
      "[SGD | lr=0.001] Iter 5200: loss=2.1983\n",
      "[SGD | lr=0.001] Epoch 325/4000: train_loss=2.1946  test_loss=2.2100  λ_max=3.0436\n",
      "[SGD | lr=0.001] Epoch 326/4000: train_loss=2.1944  test_loss=2.2100  λ_max=2.8960\n",
      "[SGD | lr=0.001] Epoch 327/4000: train_loss=2.1945  test_loss=2.2100  λ_max=2.9593\n",
      "[SGD | lr=0.001] Epoch 328/4000: train_loss=2.1943  test_loss=2.2099  λ_max=2.9178\n",
      "[SGD | lr=0.001] Epoch 329/4000: train_loss=2.1944  test_loss=2.2099  λ_max=3.0528\n",
      "[SGD | lr=0.001] Epoch 330/4000: train_loss=2.1944  test_loss=2.2099  λ_max=2.8795\n",
      "[SGD | lr=0.001] Epoch 331/4000: train_loss=2.1943  test_loss=2.2098  λ_max=3.0508\n",
      "[SGD | lr=0.001] Iter 5300: loss=2.1959\n",
      "[SGD | lr=0.001] Epoch 332/4000: train_loss=2.1942  test_loss=2.2098  λ_max=2.9733\n",
      "[SGD | lr=0.001] Epoch 333/4000: train_loss=2.1942  test_loss=2.2097  λ_max=3.0135\n",
      "[SGD | lr=0.001] Epoch 334/4000: train_loss=2.1942  test_loss=2.2097  λ_max=3.0065\n",
      "[SGD | lr=0.001] Epoch 335/4000: train_loss=2.1941  test_loss=2.2097  λ_max=2.7952\n",
      "[SGD | lr=0.001] Epoch 336/4000: train_loss=2.1940  test_loss=2.2096  λ_max=2.9363\n",
      "[SGD | lr=0.001] Epoch 337/4000: train_loss=2.1940  test_loss=2.2096  λ_max=2.8961\n",
      "[SGD | lr=0.001] Iter 5400: loss=2.1951\n",
      "[SGD | lr=0.001] Epoch 338/4000: train_loss=2.1939  test_loss=2.2096  λ_max=2.8808\n",
      "[SGD | lr=0.001] Epoch 339/4000: train_loss=2.1939  test_loss=2.2095  λ_max=2.7995\n",
      "[SGD | lr=0.001] Epoch 340/4000: train_loss=2.1939  test_loss=2.2095  λ_max=2.8852\n",
      "[SGD | lr=0.001] Epoch 341/4000: train_loss=2.1939  test_loss=2.2095  λ_max=2.8925\n",
      "[SGD | lr=0.001] Epoch 342/4000: train_loss=2.1938  test_loss=2.2094  λ_max=2.9265\n",
      "[SGD | lr=0.001] Epoch 343/4000: train_loss=2.1937  test_loss=2.2094  λ_max=2.9236\n",
      "[SGD | lr=0.001] Iter 5500: loss=2.1944\n",
      "[SGD | lr=0.001] Epoch 344/4000: train_loss=2.1936  test_loss=2.2094  λ_max=2.9834\n",
      "[SGD | lr=0.001] Epoch 345/4000: train_loss=2.1936  test_loss=2.2093  λ_max=2.8088\n",
      "[SGD | lr=0.001] Epoch 346/4000: train_loss=2.1936  test_loss=2.2093  λ_max=2.8719\n",
      "[SGD | lr=0.001] Epoch 347/4000: train_loss=2.1936  test_loss=2.2093  λ_max=2.8894\n",
      "[SGD | lr=0.001] Epoch 348/4000: train_loss=2.1934  test_loss=2.2092  λ_max=2.9580\n",
      "[SGD | lr=0.001] Epoch 349/4000: train_loss=2.1935  test_loss=2.2092  λ_max=2.8343\n",
      "[SGD | lr=0.001] Iter 5600: loss=2.1953\n",
      "[SGD | lr=0.001] Epoch 350/4000: train_loss=2.1935  test_loss=2.2092  λ_max=2.9732\n",
      "[SGD | lr=0.001] Epoch 351/4000: train_loss=2.1934  test_loss=2.2091  λ_max=2.9357\n",
      "[SGD | lr=0.001] Epoch 352/4000: train_loss=2.1934  test_loss=2.2091  λ_max=2.9473\n",
      "[SGD | lr=0.001] Epoch 353/4000: train_loss=2.1933  test_loss=2.2091  λ_max=2.9434\n",
      "[SGD | lr=0.001] Epoch 354/4000: train_loss=2.1933  test_loss=2.2090  λ_max=2.9383\n",
      "[SGD | lr=0.001] Epoch 355/4000: train_loss=2.1932  test_loss=2.2090  λ_max=2.8798\n",
      "[SGD | lr=0.001] Epoch 356/4000: train_loss=2.1932  test_loss=2.2090  λ_max=2.8634\n",
      "[SGD | lr=0.001] Iter 5700: loss=2.1930\n",
      "[SGD | lr=0.001] Epoch 357/4000: train_loss=2.1931  test_loss=2.2089  λ_max=2.8321\n",
      "[SGD | lr=0.001] Epoch 358/4000: train_loss=2.1931  test_loss=2.2089  λ_max=2.8510\n",
      "[SGD | lr=0.001] Epoch 359/4000: train_loss=2.1931  test_loss=2.2089  λ_max=2.9148\n",
      "[SGD | lr=0.001] Epoch 360/4000: train_loss=2.1931  test_loss=2.2088  λ_max=2.9857\n",
      "[SGD | lr=0.001] Epoch 361/4000: train_loss=2.1930  test_loss=2.2088  λ_max=2.9251\n",
      "[SGD | lr=0.001] Epoch 362/4000: train_loss=2.1930  test_loss=2.2088  λ_max=2.9533\n",
      "[SGD | lr=0.001] Iter 5800: loss=2.1941\n",
      "[SGD | lr=0.001] Epoch 363/4000: train_loss=2.1929  test_loss=2.2088  λ_max=2.8050\n",
      "[SGD | lr=0.001] Epoch 364/4000: train_loss=2.1929  test_loss=2.2087  λ_max=2.8725\n",
      "[SGD | lr=0.001] Epoch 365/4000: train_loss=2.1928  test_loss=2.2087  λ_max=2.9185\n",
      "[SGD | lr=0.001] Epoch 366/4000: train_loss=2.1929  test_loss=2.2087  λ_max=2.8797\n",
      "[SGD | lr=0.001] Epoch 367/4000: train_loss=2.1928  test_loss=2.2086  λ_max=2.9805\n",
      "[SGD | lr=0.001] Epoch 368/4000: train_loss=2.1927  test_loss=2.2086  λ_max=2.8954\n",
      "[SGD | lr=0.001] Iter 5900: loss=2.1925\n",
      "[SGD | lr=0.001] Epoch 369/4000: train_loss=2.1927  test_loss=2.2086  λ_max=2.9466\n",
      "[SGD | lr=0.001] Epoch 370/4000: train_loss=2.1926  test_loss=2.2086  λ_max=2.8550\n",
      "[SGD | lr=0.001] Epoch 371/4000: train_loss=2.1926  test_loss=2.2085  λ_max=2.8158\n",
      "[SGD | lr=0.001] Epoch 372/4000: train_loss=2.1926  test_loss=2.2085  λ_max=2.8106\n",
      "[SGD | lr=0.001] Epoch 373/4000: train_loss=2.1924  test_loss=2.2085  λ_max=2.9626\n",
      "[SGD | lr=0.001] Epoch 374/4000: train_loss=2.1925  test_loss=2.2084  λ_max=2.8557\n",
      "[SGD | lr=0.001] Iter 6000: loss=2.1916\n",
      "[SGD | lr=0.001] Epoch 375/4000: train_loss=2.1925  test_loss=2.2084  λ_max=2.7931\n",
      "[SGD | lr=0.001] Epoch 376/4000: train_loss=2.1924  test_loss=2.2084  λ_max=2.8739\n",
      "[SGD | lr=0.001] Epoch 377/4000: train_loss=2.1923  test_loss=2.2084  λ_max=2.8959\n",
      "[SGD | lr=0.001] Epoch 378/4000: train_loss=2.1923  test_loss=2.2083  λ_max=2.8148\n",
      "[SGD | lr=0.001] Epoch 379/4000: train_loss=2.1923  test_loss=2.2083  λ_max=2.8013\n",
      "[SGD | lr=0.001] Epoch 380/4000: train_loss=2.1923  test_loss=2.2083  λ_max=2.9534\n",
      "[SGD | lr=0.001] Epoch 381/4000: train_loss=2.1923  test_loss=2.2083  λ_max=2.7342\n",
      "[SGD | lr=0.001] Iter 6100: loss=2.1929\n",
      "[SGD | lr=0.001] Epoch 382/4000: train_loss=2.1922  test_loss=2.2082  λ_max=2.8519\n",
      "[SGD | lr=0.001] Epoch 383/4000: train_loss=2.1922  test_loss=2.2082  λ_max=2.9051\n",
      "[SGD | lr=0.001] Epoch 384/4000: train_loss=2.1921  test_loss=2.2082  λ_max=2.9656\n",
      "[SGD | lr=0.001] Epoch 385/4000: train_loss=2.1922  test_loss=2.2082  λ_max=2.8184\n",
      "[SGD | lr=0.001] Epoch 386/4000: train_loss=2.1920  test_loss=2.2081  λ_max=2.6656\n",
      "[SGD | lr=0.001] Epoch 387/4000: train_loss=2.1921  test_loss=2.2081  λ_max=2.8384\n",
      "[SGD | lr=0.001] Iter 6200: loss=2.1899\n",
      "[SGD | lr=0.001] Epoch 388/4000: train_loss=2.1920  test_loss=2.2081  λ_max=2.9287\n",
      "[SGD | lr=0.001] Epoch 389/4000: train_loss=2.1920  test_loss=2.2081  λ_max=2.9199\n",
      "[SGD | lr=0.001] Epoch 390/4000: train_loss=2.1919  test_loss=2.2081  λ_max=2.8286\n",
      "[SGD | lr=0.001] Epoch 391/4000: train_loss=2.1918  test_loss=2.2080  λ_max=2.7351\n",
      "[SGD | lr=0.001] Epoch 392/4000: train_loss=2.1918  test_loss=2.2080  λ_max=2.7477\n",
      "[SGD | lr=0.001] Epoch 393/4000: train_loss=2.1918  test_loss=2.2080  λ_max=2.9745\n",
      "[SGD | lr=0.001] Iter 6300: loss=2.1932\n",
      "[SGD | lr=0.001] Epoch 394/4000: train_loss=2.1918  test_loss=2.2079  λ_max=2.9448\n",
      "[SGD | lr=0.001] Epoch 395/4000: train_loss=2.1917  test_loss=2.2079  λ_max=2.9281\n",
      "[SGD | lr=0.001] Epoch 396/4000: train_loss=2.1918  test_loss=2.2079  λ_max=2.8493\n",
      "[SGD | lr=0.001] Epoch 397/4000: train_loss=2.1917  test_loss=2.2079  λ_max=2.7649\n",
      "[SGD | lr=0.001] Epoch 398/4000: train_loss=2.1917  test_loss=2.2079  λ_max=2.8814\n",
      "[SGD | lr=0.001] Epoch 399/4000: train_loss=2.1916  test_loss=2.2078  λ_max=2.9054\n",
      "[SGD | lr=0.001] Iter 6400: loss=2.1923\n",
      "[SGD | lr=0.001] Epoch 400/4000: train_loss=2.1916  test_loss=2.2078  λ_max=2.9127\n",
      "[SGD | lr=0.001] Epoch 401/4000: train_loss=2.1916  test_loss=2.2078  λ_max=2.7429\n",
      "[SGD | lr=0.001] Epoch 402/4000: train_loss=2.1915  test_loss=2.2078  λ_max=2.8984\n",
      "[SGD | lr=0.001] Epoch 403/4000: train_loss=2.1915  test_loss=2.2077  λ_max=2.8878\n",
      "[SGD | lr=0.001] Epoch 404/4000: train_loss=2.1915  test_loss=2.2077  λ_max=2.7740\n",
      "[SGD | lr=0.001] Epoch 405/4000: train_loss=2.1914  test_loss=2.2077  λ_max=2.8536\n",
      "[SGD | lr=0.001] Epoch 406/4000: train_loss=2.1913  test_loss=2.2077  λ_max=2.9008\n",
      "[SGD | lr=0.001] Iter 6500: loss=2.1915\n",
      "[SGD | lr=0.001] Epoch 407/4000: train_loss=2.1914  test_loss=2.2076  λ_max=2.8743\n",
      "[SGD | lr=0.001] Epoch 408/4000: train_loss=2.1914  test_loss=2.2076  λ_max=2.7431\n",
      "[SGD | lr=0.001] Epoch 409/4000: train_loss=2.1913  test_loss=2.2076  λ_max=2.7728\n",
      "[SGD | lr=0.001] Epoch 410/4000: train_loss=2.1912  test_loss=2.2076  λ_max=2.8669\n",
      "[SGD | lr=0.001] Epoch 411/4000: train_loss=2.1913  test_loss=2.2076  λ_max=2.7704\n",
      "[SGD | lr=0.001] Epoch 412/4000: train_loss=2.1912  test_loss=2.2075  λ_max=2.8775\n",
      "[SGD | lr=0.001] Iter 6600: loss=2.1917\n",
      "[SGD | lr=0.001] Epoch 413/4000: train_loss=2.1912  test_loss=2.2075  λ_max=2.7727\n",
      "[SGD | lr=0.001] Epoch 414/4000: train_loss=2.1912  test_loss=2.2075  λ_max=2.7663\n",
      "[SGD | lr=0.001] Epoch 415/4000: train_loss=2.1911  test_loss=2.2075  λ_max=2.7951\n",
      "[SGD | lr=0.001] Epoch 416/4000: train_loss=2.1910  test_loss=2.2075  λ_max=2.7692\n",
      "[SGD | lr=0.001] Epoch 417/4000: train_loss=2.1910  test_loss=2.2074  λ_max=2.8762\n",
      "[SGD | lr=0.001] Epoch 418/4000: train_loss=2.1910  test_loss=2.2074  λ_max=2.7778\n",
      "[SGD | lr=0.001] Iter 6700: loss=2.1916\n",
      "[SGD | lr=0.001] Epoch 419/4000: train_loss=2.1910  test_loss=2.2074  λ_max=2.8863\n",
      "[SGD | lr=0.001] Epoch 420/4000: train_loss=2.1909  test_loss=2.2074  λ_max=2.9234\n",
      "[SGD | lr=0.001] Epoch 421/4000: train_loss=2.1909  test_loss=2.2074  λ_max=2.8757\n",
      "[SGD | lr=0.001] Epoch 422/4000: train_loss=2.1909  test_loss=2.2073  λ_max=2.7825\n",
      "[SGD | lr=0.001] Epoch 423/4000: train_loss=2.1909  test_loss=2.2073  λ_max=2.7187\n",
      "[SGD | lr=0.001] Epoch 424/4000: train_loss=2.1908  test_loss=2.2073  λ_max=2.8518\n",
      "[SGD | lr=0.001] Iter 6800: loss=2.1915\n",
      "[SGD | lr=0.001] Epoch 425/4000: train_loss=2.1908  test_loss=2.2073  λ_max=2.7527\n",
      "[SGD | lr=0.001] Epoch 426/4000: train_loss=2.1908  test_loss=2.2073  λ_max=2.8345\n",
      "[SGD | lr=0.001] Epoch 427/4000: train_loss=2.1907  test_loss=2.2072  λ_max=2.8526\n",
      "[SGD | lr=0.001] Epoch 428/4000: train_loss=2.1908  test_loss=2.2072  λ_max=2.9258\n",
      "[SGD | lr=0.001] Epoch 429/4000: train_loss=2.1906  test_loss=2.2072  λ_max=2.7827\n",
      "[SGD | lr=0.001] Epoch 430/4000: train_loss=2.1907  test_loss=2.2072  λ_max=2.8828\n",
      "[SGD | lr=0.001] Epoch 431/4000: train_loss=2.1906  test_loss=2.2072  λ_max=2.6987\n",
      "[SGD | lr=0.001] Iter 6900: loss=2.1917\n",
      "[SGD | lr=0.001] Epoch 432/4000: train_loss=2.1905  test_loss=2.2071  λ_max=2.8195\n",
      "[SGD | lr=0.001] Epoch 433/4000: train_loss=2.1906  test_loss=2.2071  λ_max=2.7994\n",
      "[SGD | lr=0.001] Epoch 434/4000: train_loss=2.1905  test_loss=2.2071  λ_max=2.8759\n",
      "[SGD | lr=0.001] Epoch 435/4000: train_loss=2.1905  test_loss=2.2071  λ_max=2.6494\n",
      "[SGD | lr=0.001] Epoch 436/4000: train_loss=2.1903  test_loss=2.2071  λ_max=2.7221\n",
      "[SGD | lr=0.001] Epoch 437/4000: train_loss=2.1904  test_loss=2.2070  λ_max=2.6393\n",
      "[SGD | lr=0.001] Iter 7000: loss=2.1920\n",
      "[SGD | lr=0.001] Epoch 438/4000: train_loss=2.1903  test_loss=2.2070  λ_max=2.7499\n",
      "[SGD | lr=0.001] Epoch 439/4000: train_loss=2.1903  test_loss=2.2070  λ_max=2.7086\n",
      "[SGD | lr=0.001] Epoch 440/4000: train_loss=2.1904  test_loss=2.2070  λ_max=2.8139\n",
      "[SGD | lr=0.001] Epoch 441/4000: train_loss=2.1903  test_loss=2.2070  λ_max=2.8872\n",
      "[SGD | lr=0.001] Epoch 442/4000: train_loss=2.1903  test_loss=2.2070  λ_max=2.7717\n",
      "[SGD | lr=0.001] Epoch 443/4000: train_loss=2.1902  test_loss=2.2069  λ_max=2.7598\n",
      "[SGD | lr=0.001] Iter 7100: loss=2.1893\n",
      "[SGD | lr=0.001] Epoch 444/4000: train_loss=2.1903  test_loss=2.2069  λ_max=2.9009\n",
      "[SGD | lr=0.001] Epoch 445/4000: train_loss=2.1902  test_loss=2.2069  λ_max=2.7213\n",
      "[SGD | lr=0.001] Epoch 446/4000: train_loss=2.1902  test_loss=2.2069  λ_max=2.6575\n",
      "[SGD | lr=0.001] Epoch 447/4000: train_loss=2.1901  test_loss=2.2069  λ_max=2.7392\n",
      "[SGD | lr=0.001] Epoch 448/4000: train_loss=2.1902  test_loss=2.2068  λ_max=2.7360\n",
      "[SGD | lr=0.001] Epoch 449/4000: train_loss=2.1901  test_loss=2.2068  λ_max=2.8088\n",
      "[SGD | lr=0.001] Iter 7200: loss=2.1918\n",
      "[SGD | lr=0.001] Epoch 450/4000: train_loss=2.1901  test_loss=2.2068  λ_max=2.8984\n",
      "[SGD | lr=0.001] Epoch 451/4000: train_loss=2.1900  test_loss=2.2068  λ_max=2.8692\n",
      "[SGD | lr=0.001] Epoch 452/4000: train_loss=2.1900  test_loss=2.2068  λ_max=2.7734\n",
      "[SGD | lr=0.001] Epoch 453/4000: train_loss=2.1900  test_loss=2.2068  λ_max=2.7861\n",
      "[SGD | lr=0.001] Epoch 454/4000: train_loss=2.1899  test_loss=2.2067  λ_max=2.7613\n",
      "[SGD | lr=0.001] Epoch 455/4000: train_loss=2.1899  test_loss=2.2067  λ_max=2.8376\n",
      "[SGD | lr=0.001] Epoch 456/4000: train_loss=2.1899  test_loss=2.2067  λ_max=2.6562\n",
      "[SGD | lr=0.001] Iter 7300: loss=2.1888\n",
      "[SGD | lr=0.001] Epoch 457/4000: train_loss=2.1898  test_loss=2.2067  λ_max=2.8814\n",
      "[SGD | lr=0.001] Epoch 458/4000: train_loss=2.1898  test_loss=2.2067  λ_max=2.8410\n",
      "[SGD | lr=0.001] Epoch 459/4000: train_loss=2.1898  test_loss=2.2067  λ_max=2.7545\n",
      "[SGD | lr=0.001] Epoch 460/4000: train_loss=2.1898  test_loss=2.2066  λ_max=2.7078\n",
      "[SGD | lr=0.001] Epoch 461/4000: train_loss=2.1897  test_loss=2.2066  λ_max=2.8603\n",
      "[SGD | lr=0.001] Epoch 462/4000: train_loss=2.1897  test_loss=2.2066  λ_max=2.7561\n",
      "[SGD | lr=0.001] Iter 7400: loss=2.1894\n",
      "[SGD | lr=0.001] Epoch 463/4000: train_loss=2.1896  test_loss=2.2066  λ_max=2.7055\n",
      "[SGD | lr=0.001] Epoch 464/4000: train_loss=2.1898  test_loss=2.2066  λ_max=2.7956\n",
      "[SGD | lr=0.001] Epoch 465/4000: train_loss=2.1896  test_loss=2.2066  λ_max=2.7152\n",
      "[SGD | lr=0.001] Epoch 466/4000: train_loss=2.1896  test_loss=2.2065  λ_max=2.7762\n",
      "[SGD | lr=0.001] Epoch 467/4000: train_loss=2.1895  test_loss=2.2065  λ_max=2.6431\n",
      "[SGD | lr=0.001] Epoch 468/4000: train_loss=2.1895  test_loss=2.2065  λ_max=2.7729\n",
      "[SGD | lr=0.001] Iter 7500: loss=2.1902\n",
      "[SGD | lr=0.001] Epoch 469/4000: train_loss=2.1895  test_loss=2.2065  λ_max=2.8466\n",
      "[SGD | lr=0.001] Epoch 470/4000: train_loss=2.1895  test_loss=2.2065  λ_max=2.7329\n",
      "[SGD | lr=0.001] Epoch 471/4000: train_loss=2.1894  test_loss=2.2065  λ_max=2.7222\n",
      "[SGD | lr=0.001] Epoch 472/4000: train_loss=2.1895  test_loss=2.2064  λ_max=2.8667\n",
      "[SGD | lr=0.001] Epoch 473/4000: train_loss=2.1895  test_loss=2.2064  λ_max=2.8818\n",
      "[SGD | lr=0.001] Epoch 474/4000: train_loss=2.1894  test_loss=2.2064  λ_max=2.8458\n",
      "[SGD | lr=0.001] Iter 7600: loss=2.1902\n",
      "[SGD | lr=0.001] Epoch 475/4000: train_loss=2.1894  test_loss=2.2064  λ_max=2.8136\n",
      "[SGD | lr=0.001] Epoch 476/4000: train_loss=2.1893  test_loss=2.2064  λ_max=2.7058\n",
      "[SGD | lr=0.001] Epoch 477/4000: train_loss=2.1893  test_loss=2.2064  λ_max=2.6416\n",
      "[SGD | lr=0.001] Epoch 478/4000: train_loss=2.1892  test_loss=2.2064  λ_max=2.7647\n",
      "[SGD | lr=0.001] Epoch 479/4000: train_loss=2.1892  test_loss=2.2063  λ_max=2.6287\n",
      "[SGD | lr=0.001] Epoch 480/4000: train_loss=2.1892  test_loss=2.2063  λ_max=2.8002\n",
      "[SGD | lr=0.001] Epoch 481/4000: train_loss=2.1892  test_loss=2.2063  λ_max=2.7673\n",
      "[SGD | lr=0.001] Iter 7700: loss=2.1918\n",
      "[SGD | lr=0.001] Epoch 482/4000: train_loss=2.1891  test_loss=2.2063  λ_max=2.8967\n",
      "[SGD | lr=0.001] Epoch 483/4000: train_loss=2.1891  test_loss=2.2063  λ_max=2.7266\n",
      "[SGD | lr=0.001] Epoch 484/4000: train_loss=2.1890  test_loss=2.2063  λ_max=2.7133\n",
      "[SGD | lr=0.001] Epoch 485/4000: train_loss=2.1890  test_loss=2.2063  λ_max=2.8484\n",
      "[SGD | lr=0.001] Epoch 486/4000: train_loss=2.1891  test_loss=2.2062  λ_max=2.8143\n",
      "[SGD | lr=0.001] Epoch 487/4000: train_loss=2.1890  test_loss=2.2062  λ_max=2.6933\n",
      "[SGD | lr=0.001] Iter 7800: loss=2.1899\n",
      "[SGD | lr=0.001] Epoch 488/4000: train_loss=2.1889  test_loss=2.2062  λ_max=2.8422\n",
      "[SGD | lr=0.001] Epoch 489/4000: train_loss=2.1890  test_loss=2.2062  λ_max=2.8092\n",
      "[SGD | lr=0.001] Epoch 490/4000: train_loss=2.1890  test_loss=2.2062  λ_max=2.7095\n",
      "[SGD | lr=0.001] Epoch 491/4000: train_loss=2.1889  test_loss=2.2062  λ_max=2.7722\n",
      "[SGD | lr=0.001] Epoch 492/4000: train_loss=2.1889  test_loss=2.2062  λ_max=2.7968\n",
      "[SGD | lr=0.001] Epoch 493/4000: train_loss=2.1890  test_loss=2.2061  λ_max=2.6802\n",
      "[SGD | lr=0.001] Iter 7900: loss=2.1907\n",
      "[SGD | lr=0.001] Epoch 494/4000: train_loss=2.1888  test_loss=2.2061  λ_max=2.7666\n",
      "[SGD | lr=0.001] Epoch 495/4000: train_loss=2.1888  test_loss=2.2061  λ_max=2.7904\n",
      "[SGD | lr=0.001] Epoch 496/4000: train_loss=2.1888  test_loss=2.2061  λ_max=2.7449\n",
      "[SGD | lr=0.001] Epoch 497/4000: train_loss=2.1887  test_loss=2.2061  λ_max=2.6007\n",
      "[SGD | lr=0.001] Epoch 498/4000: train_loss=2.1888  test_loss=2.2061  λ_max=2.7302\n",
      "[SGD | lr=0.001] Epoch 499/4000: train_loss=2.1887  test_loss=2.2061  λ_max=2.7791\n",
      "[SGD | lr=0.001] Iter 8000: loss=2.1915\n",
      "[SGD | lr=0.001] Epoch 500/4000: train_loss=2.1887  test_loss=2.2060  λ_max=2.8457\n",
      "[SGD | lr=0.001] Epoch 501/4000: train_loss=2.1886  test_loss=2.2060  λ_max=2.7894\n",
      "[SGD | lr=0.001] Epoch 502/4000: train_loss=2.1885  test_loss=2.2060  λ_max=2.7534\n",
      "[SGD | lr=0.001] Epoch 503/4000: train_loss=2.1886  test_loss=2.2060  λ_max=2.8197\n",
      "[SGD | lr=0.001] Epoch 504/4000: train_loss=2.1885  test_loss=2.2060  λ_max=2.8520\n",
      "[SGD | lr=0.001] Epoch 505/4000: train_loss=2.1885  test_loss=2.2060  λ_max=2.7859\n",
      "[SGD | lr=0.001] Epoch 506/4000: train_loss=2.1885  test_loss=2.2060  λ_max=2.7251\n",
      "[SGD | lr=0.001] Iter 8100: loss=2.1864\n",
      "[SGD | lr=0.001] Epoch 507/4000: train_loss=2.1885  test_loss=2.2060  λ_max=2.7837\n",
      "[SGD | lr=0.001] Epoch 508/4000: train_loss=2.1884  test_loss=2.2059  λ_max=2.6472\n",
      "[SGD | lr=0.001] Epoch 509/4000: train_loss=2.1885  test_loss=2.2059  λ_max=2.8158\n",
      "[SGD | lr=0.001] Epoch 510/4000: train_loss=2.1883  test_loss=2.2059  λ_max=2.6870\n",
      "[SGD | lr=0.001] Epoch 511/4000: train_loss=2.1883  test_loss=2.2059  λ_max=2.7161\n",
      "[SGD | lr=0.001] Epoch 512/4000: train_loss=2.1884  test_loss=2.2059  λ_max=2.6758\n",
      "[SGD | lr=0.001] Iter 8200: loss=2.1882\n",
      "[SGD | lr=0.001] Epoch 513/4000: train_loss=2.1883  test_loss=2.2059  λ_max=2.6150\n",
      "[SGD | lr=0.001] Epoch 514/4000: train_loss=2.1883  test_loss=2.2059  λ_max=2.7692\n",
      "[SGD | lr=0.001] Epoch 515/4000: train_loss=2.1882  test_loss=2.2059  λ_max=2.7050\n",
      "[SGD | lr=0.001] Epoch 516/4000: train_loss=2.1883  test_loss=2.2058  λ_max=2.7678\n",
      "[SGD | lr=0.001] Epoch 517/4000: train_loss=2.1882  test_loss=2.2058  λ_max=2.7526\n",
      "[SGD | lr=0.001] Epoch 518/4000: train_loss=2.1882  test_loss=2.2058  λ_max=2.6147\n",
      "[SGD | lr=0.001] Iter 8300: loss=2.1870\n",
      "[SGD | lr=0.001] Epoch 519/4000: train_loss=2.1881  test_loss=2.2058  λ_max=2.7793\n",
      "[SGD | lr=0.001] Epoch 520/4000: train_loss=2.1881  test_loss=2.2058  λ_max=2.6907\n",
      "[SGD | lr=0.001] Epoch 521/4000: train_loss=2.1881  test_loss=2.2058  λ_max=2.7243\n",
      "[SGD | lr=0.001] Epoch 522/4000: train_loss=2.1880  test_loss=2.2058  λ_max=2.7991\n",
      "[SGD | lr=0.001] Epoch 523/4000: train_loss=2.1880  test_loss=2.2058  λ_max=2.5814\n",
      "[SGD | lr=0.001] Epoch 524/4000: train_loss=2.1880  test_loss=2.2057  λ_max=2.7524\n",
      "[SGD | lr=0.001] Iter 8400: loss=2.1870\n",
      "[SGD | lr=0.001] Epoch 525/4000: train_loss=2.1880  test_loss=2.2057  λ_max=2.7271\n",
      "[SGD | lr=0.001] Epoch 526/4000: train_loss=2.1879  test_loss=2.2057  λ_max=2.6736\n",
      "[SGD | lr=0.001] Epoch 527/4000: train_loss=2.1880  test_loss=2.2057  λ_max=2.5867\n",
      "[SGD | lr=0.001] Epoch 528/4000: train_loss=2.1880  test_loss=2.2057  λ_max=2.6671\n",
      "[SGD | lr=0.001] Epoch 529/4000: train_loss=2.1879  test_loss=2.2057  λ_max=2.6638\n",
      "[SGD | lr=0.001] Epoch 530/4000: train_loss=2.1878  test_loss=2.2057  λ_max=2.6303\n",
      "[SGD | lr=0.001] Epoch 531/4000: train_loss=2.1879  test_loss=2.2057  λ_max=2.6620\n",
      "[SGD | lr=0.001] Iter 8500: loss=2.1863\n",
      "[SGD | lr=0.001] Epoch 532/4000: train_loss=2.1878  test_loss=2.2057  λ_max=2.7813\n",
      "[SGD | lr=0.001] Epoch 533/4000: train_loss=2.1877  test_loss=2.2056  λ_max=2.6795\n",
      "[SGD | lr=0.001] Epoch 534/4000: train_loss=2.1877  test_loss=2.2056  λ_max=2.7242\n",
      "[SGD | lr=0.001] Epoch 535/4000: train_loss=2.1878  test_loss=2.2056  λ_max=2.8180\n",
      "[SGD | lr=0.001] Epoch 536/4000: train_loss=2.1877  test_loss=2.2056  λ_max=2.7401\n",
      "[SGD | lr=0.001] Epoch 537/4000: train_loss=2.1877  test_loss=2.2056  λ_max=2.7244\n",
      "[SGD | lr=0.001] Iter 8600: loss=2.1854\n",
      "[SGD | lr=0.001] Epoch 538/4000: train_loss=2.1876  test_loss=2.2056  λ_max=2.7523\n",
      "[SGD | lr=0.001] Epoch 539/4000: train_loss=2.1877  test_loss=2.2056  λ_max=2.6817\n",
      "[SGD | lr=0.001] Epoch 540/4000: train_loss=2.1876  test_loss=2.2056  λ_max=2.7660\n",
      "[SGD | lr=0.001] Epoch 541/4000: train_loss=2.1876  test_loss=2.2056  λ_max=2.7581\n",
      "[SGD | lr=0.001] Epoch 542/4000: train_loss=2.1876  test_loss=2.2055  λ_max=2.7548\n",
      "[SGD | lr=0.001] Epoch 543/4000: train_loss=2.1875  test_loss=2.2055  λ_max=2.7225\n",
      "[SGD | lr=0.001] Iter 8700: loss=2.1860\n",
      "[SGD | lr=0.001] Epoch 544/4000: train_loss=2.1875  test_loss=2.2055  λ_max=2.6841\n",
      "[SGD | lr=0.001] Epoch 545/4000: train_loss=2.1875  test_loss=2.2055  λ_max=2.7045\n",
      "[SGD | lr=0.001] Epoch 546/4000: train_loss=2.1874  test_loss=2.2055  λ_max=2.7101\n",
      "[SGD | lr=0.001] Epoch 547/4000: train_loss=2.1875  test_loss=2.2055  λ_max=2.7056\n",
      "[SGD | lr=0.001] Epoch 548/4000: train_loss=2.1874  test_loss=2.2055  λ_max=2.8008\n",
      "[SGD | lr=0.001] Epoch 549/4000: train_loss=2.1874  test_loss=2.2055  λ_max=2.6901\n",
      "[SGD | lr=0.001] Iter 8800: loss=2.1880\n",
      "[SGD | lr=0.001] Epoch 550/4000: train_loss=2.1874  test_loss=2.2055  λ_max=2.7406\n",
      "[SGD | lr=0.001] Epoch 551/4000: train_loss=2.1874  test_loss=2.2055  λ_max=2.8034\n",
      "[SGD | lr=0.001] Epoch 552/4000: train_loss=2.1873  test_loss=2.2054  λ_max=2.6752\n",
      "[SGD | lr=0.001] Epoch 553/4000: train_loss=2.1874  test_loss=2.2054  λ_max=2.7047\n",
      "[SGD | lr=0.001] Epoch 554/4000: train_loss=2.1873  test_loss=2.2054  λ_max=2.6942\n",
      "[SGD | lr=0.001] Epoch 555/4000: train_loss=2.1872  test_loss=2.2054  λ_max=2.6306\n",
      "[SGD | lr=0.001] Epoch 556/4000: train_loss=2.1871  test_loss=2.2054  λ_max=2.7413\n",
      "[SGD | lr=0.001] Iter 8900: loss=2.1860\n",
      "[SGD | lr=0.001] Epoch 557/4000: train_loss=2.1871  test_loss=2.2054  λ_max=2.7317\n",
      "[SGD | lr=0.001] Epoch 558/4000: train_loss=2.1871  test_loss=2.2054  λ_max=2.7897\n",
      "[SGD | lr=0.001] Epoch 559/4000: train_loss=2.1872  test_loss=2.2054  λ_max=2.6699\n",
      "[SGD | lr=0.001] Epoch 560/4000: train_loss=2.1871  test_loss=2.2054  λ_max=2.7073\n",
      "[SGD | lr=0.001] Epoch 561/4000: train_loss=2.1871  test_loss=2.2054  λ_max=2.7489\n",
      "[SGD | lr=0.001] Epoch 562/4000: train_loss=2.1871  test_loss=2.2053  λ_max=2.6418\n",
      "[SGD | lr=0.001] Iter 9000: loss=2.1861\n",
      "[SGD | lr=0.001] Epoch 563/4000: train_loss=2.1871  test_loss=2.2053  λ_max=2.8068\n",
      "[SGD | lr=0.001] Epoch 564/4000: train_loss=2.1870  test_loss=2.2053  λ_max=2.5918\n",
      "[SGD | lr=0.001] Epoch 565/4000: train_loss=2.1869  test_loss=2.2053  λ_max=2.7163\n",
      "[SGD | lr=0.001] Epoch 566/4000: train_loss=2.1869  test_loss=2.2053  λ_max=2.7447\n",
      "[SGD | lr=0.001] Epoch 567/4000: train_loss=2.1870  test_loss=2.2053  λ_max=2.7996\n",
      "[SGD | lr=0.001] Epoch 568/4000: train_loss=2.1869  test_loss=2.2053  λ_max=2.7313\n",
      "[SGD | lr=0.001] Iter 9100: loss=2.1882\n",
      "[SGD | lr=0.001] Epoch 569/4000: train_loss=2.1870  test_loss=2.2053  λ_max=2.7767\n",
      "[SGD | lr=0.001] Epoch 570/4000: train_loss=2.1869  test_loss=2.2053  λ_max=2.6696\n",
      "[SGD | lr=0.001] Epoch 571/4000: train_loss=2.1868  test_loss=2.2053  λ_max=2.7203\n",
      "[SGD | lr=0.001] Epoch 572/4000: train_loss=2.1868  test_loss=2.2053  λ_max=2.8184\n",
      "[SGD | lr=0.001] Epoch 573/4000: train_loss=2.1869  test_loss=2.2052  λ_max=2.7748\n",
      "[SGD | lr=0.001] Epoch 574/4000: train_loss=2.1868  test_loss=2.2052  λ_max=2.6855\n",
      "[SGD | lr=0.001] Iter 9200: loss=2.1859\n",
      "[SGD | lr=0.001] Epoch 575/4000: train_loss=2.1867  test_loss=2.2052  λ_max=2.7441\n",
      "[SGD | lr=0.001] Epoch 576/4000: train_loss=2.1867  test_loss=2.2052  λ_max=2.6570\n",
      "[SGD | lr=0.001] Epoch 577/4000: train_loss=2.1866  test_loss=2.2052  λ_max=2.7846\n",
      "[SGD | lr=0.001] Epoch 578/4000: train_loss=2.1867  test_loss=2.2052  λ_max=2.7153\n",
      "[SGD | lr=0.001] Epoch 579/4000: train_loss=2.1866  test_loss=2.2052  λ_max=2.7409\n",
      "[SGD | lr=0.001] Epoch 580/4000: train_loss=2.1866  test_loss=2.2052  λ_max=2.6520\n",
      "[SGD | lr=0.001] Epoch 581/4000: train_loss=2.1866  test_loss=2.2052  λ_max=2.5761\n",
      "[SGD | lr=0.001] Iter 9300: loss=2.1880\n",
      "[SGD | lr=0.001] Epoch 582/4000: train_loss=2.1866  test_loss=2.2052  λ_max=2.6369\n",
      "[SGD | lr=0.001] Epoch 583/4000: train_loss=2.1866  test_loss=2.2052  λ_max=2.6607\n",
      "[SGD | lr=0.001] Epoch 584/4000: train_loss=2.1865  test_loss=2.2051  λ_max=2.7222\n",
      "[SGD | lr=0.001] Epoch 585/4000: train_loss=2.1864  test_loss=2.2051  λ_max=2.6891\n",
      "[SGD | lr=0.001] Epoch 586/4000: train_loss=2.1865  test_loss=2.2051  λ_max=2.7297\n",
      "[SGD | lr=0.001] Epoch 587/4000: train_loss=2.1865  test_loss=2.2051  λ_max=2.7121\n",
      "[SGD | lr=0.001] Iter 9400: loss=2.1892\n",
      "[SGD | lr=0.001] Epoch 588/4000: train_loss=2.1865  test_loss=2.2051  λ_max=2.7086\n",
      "[SGD | lr=0.001] Epoch 589/4000: train_loss=2.1863  test_loss=2.2051  λ_max=2.7548\n",
      "[SGD | lr=0.001] Epoch 590/4000: train_loss=2.1863  test_loss=2.2051  λ_max=2.7490\n",
      "[SGD | lr=0.001] Epoch 591/4000: train_loss=2.1863  test_loss=2.2051  λ_max=2.6596\n",
      "[SGD | lr=0.001] Epoch 592/4000: train_loss=2.1863  test_loss=2.2051  λ_max=2.6650\n",
      "[SGD | lr=0.001] Epoch 593/4000: train_loss=2.1863  test_loss=2.2051  λ_max=2.7501\n",
      "[SGD | lr=0.001] Iter 9500: loss=2.1850\n",
      "[SGD | lr=0.001] Epoch 594/4000: train_loss=2.1862  test_loss=2.2051  λ_max=2.7661\n",
      "[SGD | lr=0.001] Epoch 595/4000: train_loss=2.1863  test_loss=2.2051  λ_max=2.6568\n",
      "[SGD | lr=0.001] Epoch 596/4000: train_loss=2.1862  test_loss=2.2050  λ_max=2.6274\n",
      "[SGD | lr=0.001] Epoch 597/4000: train_loss=2.1862  test_loss=2.2050  λ_max=2.8098\n",
      "[SGD | lr=0.001] Epoch 598/4000: train_loss=2.1862  test_loss=2.2050  λ_max=2.7421\n",
      "[SGD | lr=0.001] Epoch 599/4000: train_loss=2.1862  test_loss=2.2050  λ_max=2.6705\n",
      "[SGD | lr=0.001] Iter 9600: loss=2.1828\n",
      "[SGD | lr=0.001] Epoch 600/4000: train_loss=2.1861  test_loss=2.2050  λ_max=2.8136\n",
      "[SGD | lr=0.001] Epoch 601/4000: train_loss=2.1861  test_loss=2.2050  λ_max=2.7994\n",
      "[SGD | lr=0.001] Epoch 602/4000: train_loss=2.1861  test_loss=2.2050  λ_max=2.6453\n",
      "[SGD | lr=0.001] Epoch 603/4000: train_loss=2.1860  test_loss=2.2050  λ_max=2.7481\n",
      "[SGD | lr=0.001] Epoch 604/4000: train_loss=2.1861  test_loss=2.2050  λ_max=2.5788\n",
      "[SGD | lr=0.001] Epoch 605/4000: train_loss=2.1861  test_loss=2.2050  λ_max=2.8329\n",
      "[SGD | lr=0.001] Epoch 606/4000: train_loss=2.1860  test_loss=2.2050  λ_max=2.7192\n",
      "[SGD | lr=0.001] Iter 9700: loss=2.1873\n",
      "[SGD | lr=0.001] Epoch 607/4000: train_loss=2.1860  test_loss=2.2050  λ_max=2.7675\n",
      "[SGD | lr=0.001] Epoch 608/4000: train_loss=2.1860  test_loss=2.2050  λ_max=2.6681\n",
      "[SGD | lr=0.001] Epoch 609/4000: train_loss=2.1859  test_loss=2.2049  λ_max=2.6945\n",
      "[SGD | lr=0.001] Epoch 610/4000: train_loss=2.1858  test_loss=2.2049  λ_max=2.7381\n",
      "[SGD | lr=0.001] Epoch 611/4000: train_loss=2.1858  test_loss=2.2049  λ_max=2.6827\n",
      "[SGD | lr=0.001] Epoch 612/4000: train_loss=2.1858  test_loss=2.2049  λ_max=2.6905\n",
      "[SGD | lr=0.001] Iter 9800: loss=2.1844\n",
      "[SGD | lr=0.001] Epoch 613/4000: train_loss=2.1858  test_loss=2.2049  λ_max=2.8199\n",
      "[SGD | lr=0.001] Epoch 614/4000: train_loss=2.1857  test_loss=2.2049  λ_max=2.7460\n",
      "[SGD | lr=0.001] Epoch 615/4000: train_loss=2.1858  test_loss=2.2049  λ_max=2.6361\n",
      "[SGD | lr=0.001] Epoch 616/4000: train_loss=2.1857  test_loss=2.2049  λ_max=2.6904\n",
      "[SGD | lr=0.001] Epoch 617/4000: train_loss=2.1857  test_loss=2.2049  λ_max=2.7708\n",
      "[SGD | lr=0.001] Epoch 618/4000: train_loss=2.1858  test_loss=2.2049  λ_max=2.6102\n",
      "[SGD | lr=0.001] Iter 9900: loss=2.1842\n",
      "[SGD | lr=0.001] Epoch 619/4000: train_loss=2.1856  test_loss=2.2049  λ_max=2.7560\n",
      "[SGD | lr=0.001] Epoch 620/4000: train_loss=2.1856  test_loss=2.2049  λ_max=2.7241\n",
      "[SGD | lr=0.001] Epoch 621/4000: train_loss=2.1856  test_loss=2.2049  λ_max=2.7055\n",
      "[SGD | lr=0.001] Epoch 622/4000: train_loss=2.1856  test_loss=2.2049  λ_max=2.6409\n",
      "[SGD | lr=0.001] Epoch 623/4000: train_loss=2.1856  test_loss=2.2048  λ_max=2.7683\n",
      "[SGD | lr=0.001] Epoch 624/4000: train_loss=2.1856  test_loss=2.2048  λ_max=2.7657\n",
      "[SGD | lr=0.001] Iter 10000: loss=2.1851\n",
      "[SGD | lr=0.001] Epoch 625/4000: train_loss=2.1855  test_loss=2.2048  λ_max=2.7142\n",
      "[SGD | lr=0.001] Epoch 626/4000: train_loss=2.1855  test_loss=2.2048  λ_max=2.7121\n",
      "[SGD | lr=0.001] Epoch 627/4000: train_loss=2.1855  test_loss=2.2048  λ_max=2.7186\n",
      "[SGD | lr=0.001] Epoch 628/4000: train_loss=2.1854  test_loss=2.2048  λ_max=2.7296\n",
      "[SGD | lr=0.001] Epoch 629/4000: train_loss=2.1854  test_loss=2.2048  λ_max=2.8023\n",
      "[SGD | lr=0.001] Epoch 630/4000: train_loss=2.1854  test_loss=2.2048  λ_max=2.7027\n",
      "[SGD | lr=0.001] Epoch 631/4000: train_loss=2.1854  test_loss=2.2048  λ_max=2.7401\n",
      "[SGD | lr=0.001] Iter 10100: loss=2.1824\n",
      "[SGD | lr=0.001] Epoch 632/4000: train_loss=2.1854  test_loss=2.2048  λ_max=2.7364\n",
      "[SGD | lr=0.001] Epoch 633/4000: train_loss=2.1853  test_loss=2.2048  λ_max=2.6281\n",
      "[SGD | lr=0.001] Epoch 634/4000: train_loss=2.1853  test_loss=2.2048  λ_max=2.6657\n",
      "[SGD | lr=0.001] Epoch 635/4000: train_loss=2.1852  test_loss=2.2048  λ_max=2.7158\n",
      "[SGD | lr=0.001] Epoch 636/4000: train_loss=2.1853  test_loss=2.2048  λ_max=2.6071\n",
      "[SGD | lr=0.001] Epoch 637/4000: train_loss=2.1852  test_loss=2.2047  λ_max=2.7982\n",
      "[SGD | lr=0.001] Iter 10200: loss=2.1891\n",
      "[SGD | lr=0.001] Epoch 638/4000: train_loss=2.1852  test_loss=2.2047  λ_max=2.8065\n",
      "[SGD | lr=0.001] Epoch 639/4000: train_loss=2.1852  test_loss=2.2047  λ_max=2.7470\n",
      "[SGD | lr=0.001] Epoch 640/4000: train_loss=2.1851  test_loss=2.2047  λ_max=2.6982\n",
      "[SGD | lr=0.001] Epoch 641/4000: train_loss=2.1851  test_loss=2.2047  λ_max=2.5306\n",
      "[SGD | lr=0.001] Epoch 642/4000: train_loss=2.1852  test_loss=2.2047  λ_max=2.6095\n",
      "[SGD | lr=0.001] Epoch 643/4000: train_loss=2.1852  test_loss=2.2047  λ_max=2.7601\n",
      "[SGD | lr=0.001] Iter 10300: loss=2.1863\n",
      "[SGD | lr=0.001] Epoch 644/4000: train_loss=2.1850  test_loss=2.2047  λ_max=2.6340\n",
      "[SGD | lr=0.001] Epoch 645/4000: train_loss=2.1851  test_loss=2.2047  λ_max=2.7876\n",
      "[SGD | lr=0.001] Epoch 646/4000: train_loss=2.1850  test_loss=2.2047  λ_max=2.6457\n",
      "[SGD | lr=0.001] Epoch 647/4000: train_loss=2.1850  test_loss=2.2047  λ_max=2.5366\n",
      "[SGD | lr=0.001] Epoch 648/4000: train_loss=2.1849  test_loss=2.2047  λ_max=2.7225\n",
      "[SGD | lr=0.001] Epoch 649/4000: train_loss=2.1849  test_loss=2.2047  λ_max=2.6660\n",
      "[SGD | lr=0.001] Iter 10400: loss=2.1870\n",
      "[SGD | lr=0.001] Epoch 650/4000: train_loss=2.1850  test_loss=2.2047  λ_max=2.6253\n",
      "[SGD | lr=0.001] Epoch 651/4000: train_loss=2.1849  test_loss=2.2047  λ_max=2.5917\n",
      "[SGD | lr=0.001] Epoch 652/4000: train_loss=2.1848  test_loss=2.2047  λ_max=2.7050\n",
      "[SGD | lr=0.001] Epoch 653/4000: train_loss=2.1848  test_loss=2.2046  λ_max=2.7384\n",
      "[SGD | lr=0.001] Epoch 654/4000: train_loss=2.1848  test_loss=2.2046  λ_max=2.7640\n",
      "[SGD | lr=0.001] Epoch 655/4000: train_loss=2.1849  test_loss=2.2046  λ_max=2.7366\n",
      "[SGD | lr=0.001] Epoch 656/4000: train_loss=2.1848  test_loss=2.2046  λ_max=2.7723\n",
      "[SGD | lr=0.001] Iter 10500: loss=2.1847\n",
      "[SGD | lr=0.001] Epoch 657/4000: train_loss=2.1848  test_loss=2.2046  λ_max=2.6832\n",
      "[SGD | lr=0.001] Epoch 658/4000: train_loss=2.1848  test_loss=2.2046  λ_max=2.7180\n",
      "[SGD | lr=0.001] Epoch 659/4000: train_loss=2.1847  test_loss=2.2046  λ_max=2.7230\n",
      "[SGD | lr=0.001] Epoch 660/4000: train_loss=2.1847  test_loss=2.2046  λ_max=2.8188\n",
      "[SGD | lr=0.001] Epoch 661/4000: train_loss=2.1847  test_loss=2.2046  λ_max=2.6682\n",
      "[SGD | lr=0.001] Epoch 662/4000: train_loss=2.1847  test_loss=2.2046  λ_max=2.7499\n",
      "[SGD | lr=0.001] Iter 10600: loss=2.1845\n",
      "[SGD | lr=0.001] Epoch 663/4000: train_loss=2.1846  test_loss=2.2046  λ_max=2.6715\n",
      "[SGD | lr=0.001] Epoch 664/4000: train_loss=2.1846  test_loss=2.2046  λ_max=2.8162\n",
      "[SGD | lr=0.001] Epoch 665/4000: train_loss=2.1845  test_loss=2.2046  λ_max=2.6972\n",
      "[SGD | lr=0.001] Epoch 666/4000: train_loss=2.1845  test_loss=2.2046  λ_max=2.7192\n",
      "[SGD | lr=0.001] Epoch 667/4000: train_loss=2.1846  test_loss=2.2046  λ_max=2.6610\n",
      "[SGD | lr=0.001] Epoch 668/4000: train_loss=2.1846  test_loss=2.2046  λ_max=2.7671\n",
      "[SGD | lr=0.001] Iter 10700: loss=2.1850\n",
      "[SGD | lr=0.001] Epoch 669/4000: train_loss=2.1845  test_loss=2.2046  λ_max=2.6143\n",
      "[SGD | lr=0.001] Epoch 670/4000: train_loss=2.1844  test_loss=2.2046  λ_max=2.7650\n",
      "[SGD | lr=0.001] Epoch 671/4000: train_loss=2.1845  test_loss=2.2046  λ_max=2.7339\n",
      "[SGD | lr=0.001] Epoch 672/4000: train_loss=2.1843  test_loss=2.2045  λ_max=2.6915\n",
      "[SGD | lr=0.001] Epoch 673/4000: train_loss=2.1844  test_loss=2.2045  λ_max=2.6994\n",
      "[SGD | lr=0.001] Epoch 674/4000: train_loss=2.1844  test_loss=2.2045  λ_max=2.7753\n",
      "[SGD | lr=0.001] Iter 10800: loss=2.1802\n",
      "[SGD | lr=0.001] Epoch 675/4000: train_loss=2.1842  test_loss=2.2045  λ_max=2.7819\n",
      "[SGD | lr=0.001] Epoch 676/4000: train_loss=2.1843  test_loss=2.2045  λ_max=2.6852\n",
      "[SGD | lr=0.001] Epoch 677/4000: train_loss=2.1842  test_loss=2.2045  λ_max=2.7595\n",
      "[SGD | lr=0.001] Epoch 678/4000: train_loss=2.1842  test_loss=2.2045  λ_max=2.7757\n",
      "[SGD | lr=0.001] Epoch 679/4000: train_loss=2.1842  test_loss=2.2045  λ_max=2.8347\n",
      "[SGD | lr=0.001] Epoch 680/4000: train_loss=2.1843  test_loss=2.2045  λ_max=2.6084\n",
      "[SGD | lr=0.001] Epoch 681/4000: train_loss=2.1842  test_loss=2.2045  λ_max=2.6858\n",
      "[SGD | lr=0.001] Iter 10900: loss=2.1838\n",
      "[SGD | lr=0.001] Epoch 682/4000: train_loss=2.1842  test_loss=2.2045  λ_max=2.7431\n",
      "[SGD | lr=0.001] Epoch 683/4000: train_loss=2.1841  test_loss=2.2045  λ_max=2.5808\n",
      "[SGD | lr=0.001] Epoch 684/4000: train_loss=2.1841  test_loss=2.2045  λ_max=2.7611\n",
      "[SGD | lr=0.001] Epoch 685/4000: train_loss=2.1840  test_loss=2.2045  λ_max=2.8159\n",
      "[SGD | lr=0.001] Epoch 686/4000: train_loss=2.1840  test_loss=2.2045  λ_max=2.6624\n",
      "[SGD | lr=0.001] Epoch 687/4000: train_loss=2.1840  test_loss=2.2045  λ_max=2.7453\n",
      "[SGD | lr=0.001] Iter 11000: loss=2.1835\n",
      "[SGD | lr=0.001] Epoch 688/4000: train_loss=2.1840  test_loss=2.2045  λ_max=2.7070\n",
      "[SGD | lr=0.001] Epoch 689/4000: train_loss=2.1840  test_loss=2.2045  λ_max=2.6757\n",
      "[SGD | lr=0.001] Epoch 690/4000: train_loss=2.1840  test_loss=2.2044  λ_max=2.7088\n",
      "[SGD | lr=0.001] Epoch 691/4000: train_loss=2.1840  test_loss=2.2044  λ_max=2.7229\n",
      "[SGD | lr=0.001] Epoch 692/4000: train_loss=2.1839  test_loss=2.2044  λ_max=2.7390\n",
      "[SGD | lr=0.001] Epoch 693/4000: train_loss=2.1839  test_loss=2.2044  λ_max=2.8197\n",
      "[SGD | lr=0.001] Iter 11100: loss=2.1828\n",
      "[SGD | lr=0.001] Epoch 694/4000: train_loss=2.1839  test_loss=2.2044  λ_max=2.6599\n",
      "[SGD | lr=0.001] Epoch 695/4000: train_loss=2.1838  test_loss=2.2044  λ_max=2.6790\n",
      "[SGD | lr=0.001] Epoch 696/4000: train_loss=2.1839  test_loss=2.2044  λ_max=2.6219\n",
      "[SGD | lr=0.001] Epoch 697/4000: train_loss=2.1837  test_loss=2.2044  λ_max=2.8016\n",
      "[SGD | lr=0.001] Epoch 698/4000: train_loss=2.1837  test_loss=2.2044  λ_max=2.7542\n",
      "[SGD | lr=0.001] Epoch 699/4000: train_loss=2.1837  test_loss=2.2044  λ_max=2.5838\n",
      "[SGD | lr=0.001] Iter 11200: loss=2.1839\n",
      "[SGD | lr=0.001] Epoch 700/4000: train_loss=2.1837  test_loss=2.2044  λ_max=2.7758\n",
      "[SGD | lr=0.001] Epoch 701/4000: train_loss=2.1837  test_loss=2.2044  λ_max=2.5468\n",
      "[SGD | lr=0.001] Epoch 702/4000: train_loss=2.1836  test_loss=2.2044  λ_max=2.7215\n",
      "[SGD | lr=0.001] Epoch 703/4000: train_loss=2.1836  test_loss=2.2044  λ_max=2.6811\n",
      "[SGD | lr=0.001] Epoch 704/4000: train_loss=2.1837  test_loss=2.2044  λ_max=2.7453\n",
      "[SGD | lr=0.001] Epoch 705/4000: train_loss=2.1836  test_loss=2.2044  λ_max=2.7189\n",
      "[SGD | lr=0.001] Epoch 706/4000: train_loss=2.1835  test_loss=2.2044  λ_max=2.7074\n",
      "[SGD | lr=0.001] Iter 11300: loss=2.1826\n",
      "[SGD | lr=0.001] Epoch 707/4000: train_loss=2.1835  test_loss=2.2044  λ_max=2.7124\n",
      "[SGD | lr=0.001] Epoch 708/4000: train_loss=2.1835  test_loss=2.2044  λ_max=2.6995\n",
      "[SGD | lr=0.001] Epoch 709/4000: train_loss=2.1835  test_loss=2.2043  λ_max=2.7396\n",
      "[SGD | lr=0.001] Epoch 710/4000: train_loss=2.1835  test_loss=2.2043  λ_max=2.6823\n",
      "[SGD | lr=0.001] Epoch 711/4000: train_loss=2.1834  test_loss=2.2043  λ_max=2.6547\n",
      "[SGD | lr=0.001] Epoch 712/4000: train_loss=2.1834  test_loss=2.2043  λ_max=2.6611\n",
      "[SGD | lr=0.001] Iter 11400: loss=2.1823\n",
      "[SGD | lr=0.001] Epoch 713/4000: train_loss=2.1835  test_loss=2.2043  λ_max=2.7835\n",
      "[SGD | lr=0.001] Epoch 714/4000: train_loss=2.1835  test_loss=2.2043  λ_max=2.8197\n",
      "[SGD | lr=0.001] Epoch 715/4000: train_loss=2.1833  test_loss=2.2043  λ_max=2.7607\n",
      "[SGD | lr=0.001] Epoch 716/4000: train_loss=2.1834  test_loss=2.2043  λ_max=2.6664\n",
      "[SGD | lr=0.001] Epoch 717/4000: train_loss=2.1833  test_loss=2.2043  λ_max=2.8455\n",
      "[SGD | lr=0.001] Epoch 718/4000: train_loss=2.1833  test_loss=2.2043  λ_max=2.7483\n",
      "[SGD | lr=0.001] Iter 11500: loss=2.1835\n",
      "[SGD | lr=0.001] Epoch 719/4000: train_loss=2.1833  test_loss=2.2043  λ_max=2.6101\n",
      "[SGD | lr=0.001] Epoch 720/4000: train_loss=2.1832  test_loss=2.2043  λ_max=2.7145\n",
      "[SGD | lr=0.001] Epoch 721/4000: train_loss=2.1833  test_loss=2.2043  λ_max=2.6598\n",
      "[SGD | lr=0.001] Epoch 722/4000: train_loss=2.1832  test_loss=2.2043  λ_max=2.8081\n",
      "[SGD | lr=0.001] Epoch 723/4000: train_loss=2.1832  test_loss=2.2043  λ_max=2.6973\n",
      "[SGD | lr=0.001] Epoch 724/4000: train_loss=2.1832  test_loss=2.2043  λ_max=2.8012\n",
      "[SGD | lr=0.001] Iter 11600: loss=2.1855\n",
      "[SGD | lr=0.001] Epoch 725/4000: train_loss=2.1832  test_loss=2.2043  λ_max=2.6179\n",
      "[SGD | lr=0.001] Epoch 726/4000: train_loss=2.1832  test_loss=2.2043  λ_max=2.6821\n",
      "[SGD | lr=0.001] Epoch 727/4000: train_loss=2.1830  test_loss=2.2043  λ_max=2.6728\n",
      "[SGD | lr=0.001] Epoch 728/4000: train_loss=2.1830  test_loss=2.2043  λ_max=2.7131\n",
      "[SGD | lr=0.001] Epoch 729/4000: train_loss=2.1830  test_loss=2.2043  λ_max=2.7556\n",
      "[SGD | lr=0.001] Epoch 730/4000: train_loss=2.1830  test_loss=2.2043  λ_max=2.6924\n",
      "[SGD | lr=0.001] Epoch 731/4000: train_loss=2.1830  test_loss=2.2042  λ_max=2.6540\n",
      "[SGD | lr=0.001] Iter 11700: loss=2.1809\n",
      "[SGD | lr=0.001] Epoch 732/4000: train_loss=2.1830  test_loss=2.2042  λ_max=2.6489\n",
      "[SGD | lr=0.001] Epoch 733/4000: train_loss=2.1829  test_loss=2.2042  λ_max=2.7264\n",
      "[SGD | lr=0.001] Epoch 734/4000: train_loss=2.1829  test_loss=2.2042  λ_max=2.7060\n",
      "[SGD | lr=0.001] Epoch 735/4000: train_loss=2.1829  test_loss=2.2042  λ_max=2.7953\n",
      "[SGD | lr=0.001] Epoch 736/4000: train_loss=2.1828  test_loss=2.2042  λ_max=2.5846\n",
      "[SGD | lr=0.001] Epoch 737/4000: train_loss=2.1828  test_loss=2.2042  λ_max=2.7388\n",
      "[SGD | lr=0.001] Iter 11800: loss=2.1832\n",
      "[SGD | lr=0.001] Epoch 738/4000: train_loss=2.1828  test_loss=2.2042  λ_max=2.6881\n",
      "[SGD | lr=0.001] Epoch 739/4000: train_loss=2.1828  test_loss=2.2042  λ_max=2.8075\n",
      "[SGD | lr=0.001] Epoch 740/4000: train_loss=2.1829  test_loss=2.2042  λ_max=2.6902\n",
      "[SGD | lr=0.001] Epoch 741/4000: train_loss=2.1828  test_loss=2.2042  λ_max=2.8026\n",
      "[SGD | lr=0.001] Epoch 742/4000: train_loss=2.1827  test_loss=2.2042  λ_max=2.7082\n",
      "[SGD | lr=0.001] Epoch 743/4000: train_loss=2.1827  test_loss=2.2042  λ_max=2.7978\n",
      "[SGD | lr=0.001] Iter 11900: loss=2.1821\n",
      "[SGD | lr=0.001] Epoch 744/4000: train_loss=2.1826  test_loss=2.2042  λ_max=2.6857\n",
      "[SGD | lr=0.001] Epoch 745/4000: train_loss=2.1826  test_loss=2.2042  λ_max=2.6646\n",
      "[SGD | lr=0.001] Epoch 746/4000: train_loss=2.1826  test_loss=2.2042  λ_max=2.8310\n",
      "[SGD | lr=0.001] Epoch 747/4000: train_loss=2.1826  test_loss=2.2042  λ_max=2.7127\n",
      "[SGD | lr=0.001] Epoch 748/4000: train_loss=2.1825  test_loss=2.2042  λ_max=2.6825\n",
      "[SGD | lr=0.001] Epoch 749/4000: train_loss=2.1825  test_loss=2.2042  λ_max=2.5945\n",
      "[SGD | lr=0.001] Iter 12000: loss=2.1837\n",
      "[SGD | lr=0.001] Epoch 750/4000: train_loss=2.1825  test_loss=2.2042  λ_max=2.8347\n",
      "[SGD | lr=0.001] Epoch 751/4000: train_loss=2.1825  test_loss=2.2041  λ_max=2.7757\n",
      "[SGD | lr=0.001] Epoch 752/4000: train_loss=2.1825  test_loss=2.2041  λ_max=2.7924\n",
      "[SGD | lr=0.001] Epoch 753/4000: train_loss=2.1824  test_loss=2.2041  λ_max=2.6714\n",
      "[SGD | lr=0.001] Epoch 754/4000: train_loss=2.1824  test_loss=2.2041  λ_max=2.7898\n",
      "[SGD | lr=0.001] Epoch 755/4000: train_loss=2.1824  test_loss=2.2041  λ_max=2.7952\n",
      "[SGD | lr=0.001] Epoch 756/4000: train_loss=2.1824  test_loss=2.2041  λ_max=2.7208\n",
      "[SGD | lr=0.001] Iter 12100: loss=2.1838\n",
      "[SGD | lr=0.001] Epoch 757/4000: train_loss=2.1822  test_loss=2.2041  λ_max=2.7966\n",
      "[SGD | lr=0.001] Epoch 758/4000: train_loss=2.1823  test_loss=2.2041  λ_max=2.7647\n",
      "[SGD | lr=0.001] Epoch 759/4000: train_loss=2.1823  test_loss=2.2041  λ_max=2.7815\n",
      "[SGD | lr=0.001] Epoch 760/4000: train_loss=2.1823  test_loss=2.2041  λ_max=2.7829\n",
      "[SGD | lr=0.001] Epoch 761/4000: train_loss=2.1822  test_loss=2.2041  λ_max=2.7189\n",
      "[SGD | lr=0.001] Epoch 762/4000: train_loss=2.1821  test_loss=2.2041  λ_max=2.8062\n",
      "[SGD | lr=0.001] Iter 12200: loss=2.1806\n",
      "[SGD | lr=0.001] Epoch 763/4000: train_loss=2.1822  test_loss=2.2041  λ_max=2.8554\n",
      "[SGD | lr=0.001] Epoch 764/4000: train_loss=2.1822  test_loss=2.2041  λ_max=2.8578\n",
      "[SGD | lr=0.001] Epoch 765/4000: train_loss=2.1822  test_loss=2.2041  λ_max=2.6037\n",
      "[SGD | lr=0.001] Epoch 766/4000: train_loss=2.1821  test_loss=2.2041  λ_max=2.6803\n",
      "[SGD | lr=0.001] Epoch 767/4000: train_loss=2.1821  test_loss=2.2041  λ_max=2.7474\n",
      "[SGD | lr=0.001] Epoch 768/4000: train_loss=2.1820  test_loss=2.2041  λ_max=2.8137\n",
      "[SGD | lr=0.001] Iter 12300: loss=2.1817\n",
      "[SGD | lr=0.001] Epoch 769/4000: train_loss=2.1820  test_loss=2.2041  λ_max=2.6614\n",
      "[SGD | lr=0.001] Epoch 770/4000: train_loss=2.1820  test_loss=2.2041  λ_max=2.7745\n",
      "[SGD | lr=0.001] Epoch 771/4000: train_loss=2.1820  test_loss=2.2041  λ_max=2.8018\n",
      "[SGD | lr=0.001] Epoch 772/4000: train_loss=2.1820  test_loss=2.2041  λ_max=2.7590\n",
      "[SGD | lr=0.001] Epoch 773/4000: train_loss=2.1819  test_loss=2.2041  λ_max=2.6649\n",
      "[SGD | lr=0.001] Epoch 774/4000: train_loss=2.1819  test_loss=2.2041  λ_max=2.6436\n",
      "[SGD | lr=0.001] Iter 12400: loss=2.1839\n",
      "[SGD | lr=0.001] Epoch 775/4000: train_loss=2.1819  test_loss=2.2041  λ_max=2.7432\n",
      "[SGD | lr=0.001] Epoch 776/4000: train_loss=2.1818  test_loss=2.2041  λ_max=2.7837\n",
      "[SGD | lr=0.001] Epoch 777/4000: train_loss=2.1818  test_loss=2.2041  λ_max=2.7130\n",
      "[SGD | lr=0.001] Epoch 778/4000: train_loss=2.1818  test_loss=2.2040  λ_max=2.7256\n",
      "[SGD | lr=0.001] Epoch 779/4000: train_loss=2.1819  test_loss=2.2040  λ_max=2.6875\n",
      "[SGD | lr=0.001] Epoch 780/4000: train_loss=2.1818  test_loss=2.2040  λ_max=2.8090\n",
      "[SGD | lr=0.001] Epoch 781/4000: train_loss=2.1817  test_loss=2.2040  λ_max=2.8155\n",
      "[SGD | lr=0.001] Iter 12500: loss=2.1823\n",
      "[SGD | lr=0.001] Epoch 782/4000: train_loss=2.1818  test_loss=2.2040  λ_max=2.6728\n",
      "[SGD | lr=0.001] Epoch 783/4000: train_loss=2.1817  test_loss=2.2040  λ_max=2.8267\n",
      "[SGD | lr=0.001] Epoch 784/4000: train_loss=2.1817  test_loss=2.2040  λ_max=2.8754\n",
      "[SGD | lr=0.001] Epoch 785/4000: train_loss=2.1817  test_loss=2.2040  λ_max=2.7994\n",
      "[SGD | lr=0.001] Epoch 786/4000: train_loss=2.1816  test_loss=2.2040  λ_max=2.8429\n",
      "[SGD | lr=0.001] Epoch 787/4000: train_loss=2.1816  test_loss=2.2040  λ_max=2.7009\n",
      "[SGD | lr=0.001] Iter 12600: loss=2.1840\n",
      "[SGD | lr=0.001] Epoch 788/4000: train_loss=2.1815  test_loss=2.2040  λ_max=2.6940\n",
      "[SGD | lr=0.001] Epoch 789/4000: train_loss=2.1815  test_loss=2.2040  λ_max=2.6629\n",
      "[SGD | lr=0.001] Epoch 790/4000: train_loss=2.1816  test_loss=2.2040  λ_max=2.7750\n",
      "[SGD | lr=0.001] Epoch 791/4000: train_loss=2.1814  test_loss=2.2040  λ_max=2.6912\n",
      "[SGD | lr=0.001] Epoch 792/4000: train_loss=2.1814  test_loss=2.2040  λ_max=2.8084\n",
      "[SGD | lr=0.001] Epoch 793/4000: train_loss=2.1814  test_loss=2.2040  λ_max=2.8166\n",
      "[SGD | lr=0.001] Iter 12700: loss=2.1823\n",
      "[SGD | lr=0.001] Epoch 794/4000: train_loss=2.1815  test_loss=2.2040  λ_max=2.8220\n",
      "[SGD | lr=0.001] Epoch 795/4000: train_loss=2.1814  test_loss=2.2040  λ_max=2.7605\n",
      "[SGD | lr=0.001] Epoch 796/4000: train_loss=2.1814  test_loss=2.2040  λ_max=2.7027\n",
      "[SGD | lr=0.001] Epoch 797/4000: train_loss=2.1812  test_loss=2.2040  λ_max=2.8388\n",
      "[SGD | lr=0.001] Epoch 798/4000: train_loss=2.1814  test_loss=2.2040  λ_max=2.9110\n",
      "[SGD | lr=0.001] Epoch 799/4000: train_loss=2.1813  test_loss=2.2040  λ_max=2.7175\n",
      "[SGD | lr=0.001] Iter 12800: loss=2.1859\n",
      "[SGD | lr=0.001] Epoch 800/4000: train_loss=2.1814  test_loss=2.2040  λ_max=2.8963\n",
      "[SGD | lr=0.001] Epoch 801/4000: train_loss=2.1813  test_loss=2.2040  λ_max=2.8544\n",
      "[SGD | lr=0.001] Epoch 802/4000: train_loss=2.1812  test_loss=2.2040  λ_max=2.7891\n",
      "[SGD | lr=0.001] Epoch 803/4000: train_loss=2.1812  test_loss=2.2040  λ_max=2.8040\n",
      "[SGD | lr=0.001] Epoch 804/4000: train_loss=2.1812  test_loss=2.2040  λ_max=2.8774\n",
      "[SGD | lr=0.001] Epoch 805/4000: train_loss=2.1810  test_loss=2.2039  λ_max=2.8088\n",
      "[SGD | lr=0.001] Epoch 806/4000: train_loss=2.1811  test_loss=2.2039  λ_max=2.7769\n",
      "[SGD | lr=0.001] Iter 12900: loss=2.1835\n",
      "[SGD | lr=0.001] Epoch 807/4000: train_loss=2.1810  test_loss=2.2039  λ_max=2.7474\n",
      "[SGD | lr=0.001] Epoch 808/4000: train_loss=2.1811  test_loss=2.2039  λ_max=2.8207\n",
      "[SGD | lr=0.001] Epoch 809/4000: train_loss=2.1811  test_loss=2.2039  λ_max=2.6931\n",
      "[SGD | lr=0.001] Epoch 810/4000: train_loss=2.1810  test_loss=2.2039  λ_max=2.8468\n",
      "[SGD | lr=0.001] Epoch 811/4000: train_loss=2.1810  test_loss=2.2039  λ_max=2.8245\n",
      "[SGD | lr=0.001] Epoch 812/4000: train_loss=2.1809  test_loss=2.2039  λ_max=2.8600\n",
      "[SGD | lr=0.001] Iter 13000: loss=2.1827\n",
      "[SGD | lr=0.001] Epoch 813/4000: train_loss=2.1809  test_loss=2.2039  λ_max=2.8329\n",
      "[SGD | lr=0.001] Epoch 814/4000: train_loss=2.1809  test_loss=2.2039  λ_max=2.6351\n",
      "[SGD | lr=0.001] Epoch 815/4000: train_loss=2.1809  test_loss=2.2039  λ_max=2.7753\n",
      "[SGD | lr=0.001] Epoch 816/4000: train_loss=2.1809  test_loss=2.2039  λ_max=2.8976\n",
      "[SGD | lr=0.001] Epoch 817/4000: train_loss=2.1808  test_loss=2.2039  λ_max=2.8360\n",
      "[SGD | lr=0.001] Epoch 818/4000: train_loss=2.1807  test_loss=2.2039  λ_max=2.8590\n",
      "[SGD | lr=0.001] Iter 13100: loss=2.1804\n",
      "[SGD | lr=0.001] Epoch 819/4000: train_loss=2.1808  test_loss=2.2039  λ_max=2.7588\n",
      "[SGD | lr=0.001] Epoch 820/4000: train_loss=2.1808  test_loss=2.2039  λ_max=2.7796\n",
      "[SGD | lr=0.001] Epoch 821/4000: train_loss=2.1807  test_loss=2.2039  λ_max=2.7502\n",
      "[SGD | lr=0.001] Epoch 822/4000: train_loss=2.1807  test_loss=2.2039  λ_max=2.8026\n",
      "[SGD | lr=0.001] Epoch 823/4000: train_loss=2.1807  test_loss=2.2039  λ_max=2.8030\n",
      "[SGD | lr=0.001] Epoch 824/4000: train_loss=2.1806  test_loss=2.2039  λ_max=2.6980\n",
      "[SGD | lr=0.001] Iter 13200: loss=2.1837\n",
      "[SGD | lr=0.001] Epoch 825/4000: train_loss=2.1807  test_loss=2.2039  λ_max=2.6720\n",
      "[SGD | lr=0.001] Epoch 826/4000: train_loss=2.1806  test_loss=2.2039  λ_max=2.7028\n",
      "[SGD | lr=0.001] Epoch 827/4000: train_loss=2.1805  test_loss=2.2039  λ_max=2.7556\n",
      "[SGD | lr=0.001] Epoch 828/4000: train_loss=2.1805  test_loss=2.2039  λ_max=2.8023\n",
      "[SGD | lr=0.001] Epoch 829/4000: train_loss=2.1805  test_loss=2.2039  λ_max=2.8418\n",
      "[SGD | lr=0.001] Epoch 830/4000: train_loss=2.1805  test_loss=2.2039  λ_max=2.8571\n",
      "[SGD | lr=0.001] Epoch 831/4000: train_loss=2.1805  test_loss=2.2039  λ_max=2.8411\n",
      "[SGD | lr=0.001] Iter 13300: loss=2.1816\n",
      "[SGD | lr=0.001] Epoch 832/4000: train_loss=2.1804  test_loss=2.2039  λ_max=2.8109\n",
      "[SGD | lr=0.001] Epoch 833/4000: train_loss=2.1804  test_loss=2.2039  λ_max=2.7652\n",
      "[SGD | lr=0.001] Epoch 834/4000: train_loss=2.1804  test_loss=2.2039  λ_max=2.6882\n",
      "[SGD | lr=0.001] Epoch 835/4000: train_loss=2.1804  test_loss=2.2039  λ_max=2.9243\n",
      "[SGD | lr=0.001] Epoch 836/4000: train_loss=2.1804  test_loss=2.2039  λ_max=2.9085\n",
      "[SGD | lr=0.001] Epoch 837/4000: train_loss=2.1804  test_loss=2.2039  λ_max=2.8691\n",
      "[SGD | lr=0.001] Iter 13400: loss=2.1803\n",
      "[SGD | lr=0.001] Epoch 838/4000: train_loss=2.1803  test_loss=2.2039  λ_max=2.7315\n",
      "[SGD | lr=0.001] Epoch 839/4000: train_loss=2.1803  test_loss=2.2039  λ_max=2.7517\n",
      "[SGD | lr=0.001] Epoch 840/4000: train_loss=2.1802  test_loss=2.2039  λ_max=2.7311\n",
      "[SGD | lr=0.001] Epoch 841/4000: train_loss=2.1802  test_loss=2.2039  λ_max=2.7338\n",
      "[SGD | lr=0.001] Epoch 842/4000: train_loss=2.1802  test_loss=2.2039  λ_max=2.8239\n",
      "[SGD | lr=0.001] Epoch 843/4000: train_loss=2.1802  test_loss=2.2039  λ_max=2.8283\n",
      "[SGD | lr=0.001] Iter 13500: loss=2.1797\n",
      "[SGD | lr=0.001] Epoch 844/4000: train_loss=2.1801  test_loss=2.2039  λ_max=2.7558\n",
      "[SGD | lr=0.001] Epoch 845/4000: train_loss=2.1801  test_loss=2.2039  λ_max=2.8592\n",
      "[SGD | lr=0.001] Epoch 846/4000: train_loss=2.1801  test_loss=2.2039  λ_max=2.7419\n",
      "[SGD | lr=0.001] Epoch 847/4000: train_loss=2.1801  test_loss=2.2039  λ_max=2.8497\n",
      "[SGD | lr=0.001] Epoch 848/4000: train_loss=2.1800  test_loss=2.2038  λ_max=2.7367\n",
      "[SGD | lr=0.001] Epoch 849/4000: train_loss=2.1801  test_loss=2.2038  λ_max=2.8303\n",
      "[SGD | lr=0.001] Iter 13600: loss=2.1782\n",
      "[SGD | lr=0.001] Epoch 850/4000: train_loss=2.1799  test_loss=2.2038  λ_max=2.9286\n",
      "[SGD | lr=0.001] Epoch 851/4000: train_loss=2.1800  test_loss=2.2038  λ_max=2.8586\n",
      "[SGD | lr=0.001] Epoch 852/4000: train_loss=2.1800  test_loss=2.2038  λ_max=2.7853\n",
      "[SGD | lr=0.001] Epoch 853/4000: train_loss=2.1799  test_loss=2.2038  λ_max=2.7278\n",
      "[SGD | lr=0.001] Epoch 854/4000: train_loss=2.1799  test_loss=2.2038  λ_max=2.7953\n",
      "[SGD | lr=0.001] Epoch 855/4000: train_loss=2.1798  test_loss=2.2038  λ_max=2.8358\n",
      "[SGD | lr=0.001] Epoch 856/4000: train_loss=2.1798  test_loss=2.2038  λ_max=2.9249\n",
      "[SGD | lr=0.001] Iter 13700: loss=2.1786\n",
      "[SGD | lr=0.001] Epoch 857/4000: train_loss=2.1799  test_loss=2.2038  λ_max=2.8158\n",
      "[SGD | lr=0.001] Epoch 858/4000: train_loss=2.1797  test_loss=2.2038  λ_max=2.7478\n",
      "[SGD | lr=0.001] Epoch 859/4000: train_loss=2.1798  test_loss=2.2038  λ_max=2.7733\n",
      "[SGD | lr=0.001] Epoch 860/4000: train_loss=2.1798  test_loss=2.2038  λ_max=2.8808\n",
      "[SGD | lr=0.001] Epoch 861/4000: train_loss=2.1797  test_loss=2.2038  λ_max=2.8095\n",
      "[SGD | lr=0.001] Epoch 862/4000: train_loss=2.1797  test_loss=2.2038  λ_max=2.7405\n",
      "[SGD | lr=0.001] Iter 13800: loss=2.1787\n",
      "[SGD | lr=0.001] Epoch 863/4000: train_loss=2.1796  test_loss=2.2038  λ_max=2.7585\n",
      "[SGD | lr=0.001] Epoch 864/4000: train_loss=2.1796  test_loss=2.2038  λ_max=2.8212\n",
      "[SGD | lr=0.001] Epoch 865/4000: train_loss=2.1796  test_loss=2.2038  λ_max=2.8036\n",
      "[SGD | lr=0.001] Epoch 866/4000: train_loss=2.1795  test_loss=2.2038  λ_max=2.6976\n",
      "[SGD | lr=0.001] Epoch 867/4000: train_loss=2.1795  test_loss=2.2038  λ_max=2.7130\n",
      "[SGD | lr=0.001] Epoch 868/4000: train_loss=2.1795  test_loss=2.2038  λ_max=2.7638\n",
      "[SGD | lr=0.001] Iter 13900: loss=2.1776\n",
      "[SGD | lr=0.001] Epoch 869/4000: train_loss=2.1795  test_loss=2.2038  λ_max=2.7844\n",
      "[SGD | lr=0.001] Epoch 870/4000: train_loss=2.1794  test_loss=2.2038  λ_max=2.7168\n",
      "[SGD | lr=0.001] Epoch 871/4000: train_loss=2.1794  test_loss=2.2038  λ_max=2.7690\n",
      "[SGD | lr=0.001] Epoch 872/4000: train_loss=2.1793  test_loss=2.2038  λ_max=2.8787\n",
      "[SGD | lr=0.001] Epoch 873/4000: train_loss=2.1794  test_loss=2.2038  λ_max=2.8734\n",
      "[SGD | lr=0.001] Epoch 874/4000: train_loss=2.1793  test_loss=2.2038  λ_max=2.7930\n",
      "[SGD | lr=0.001] Iter 14000: loss=2.1783\n",
      "[SGD | lr=0.001] Epoch 875/4000: train_loss=2.1793  test_loss=2.2038  λ_max=2.9021\n",
      "[SGD | lr=0.001] Epoch 876/4000: train_loss=2.1792  test_loss=2.2038  λ_max=2.7589\n",
      "[SGD | lr=0.001] Epoch 877/4000: train_loss=2.1792  test_loss=2.2038  λ_max=2.7762\n",
      "[SGD | lr=0.001] Epoch 878/4000: train_loss=2.1792  test_loss=2.2038  λ_max=2.7028\n",
      "[SGD | lr=0.001] Epoch 879/4000: train_loss=2.1792  test_loss=2.2038  λ_max=2.8036\n",
      "[SGD | lr=0.001] Epoch 880/4000: train_loss=2.1792  test_loss=2.2038  λ_max=2.7617\n",
      "[SGD | lr=0.001] Epoch 881/4000: train_loss=2.1792  test_loss=2.2038  λ_max=2.9273\n",
      "[SGD | lr=0.001] Iter 14100: loss=2.1767\n",
      "[SGD | lr=0.001] Epoch 882/4000: train_loss=2.1792  test_loss=2.2038  λ_max=2.9174\n",
      "[SGD | lr=0.001] Epoch 883/4000: train_loss=2.1792  test_loss=2.2038  λ_max=2.7341\n",
      "[SGD | lr=0.001] Epoch 884/4000: train_loss=2.1791  test_loss=2.2038  λ_max=2.8949\n",
      "[SGD | lr=0.001] Epoch 885/4000: train_loss=2.1790  test_loss=2.2038  λ_max=2.7886\n",
      "[SGD | lr=0.001] Epoch 886/4000: train_loss=2.1789  test_loss=2.2038  λ_max=2.7085\n",
      "[SGD | lr=0.001] Epoch 887/4000: train_loss=2.1789  test_loss=2.2038  λ_max=2.7709\n",
      "[SGD | lr=0.001] Iter 14200: loss=2.1781\n",
      "[SGD | lr=0.001] Epoch 888/4000: train_loss=2.1789  test_loss=2.2038  λ_max=2.8991\n",
      "[SGD | lr=0.001] Epoch 889/4000: train_loss=2.1789  test_loss=2.2038  λ_max=2.8676\n",
      "[SGD | lr=0.001] Epoch 890/4000: train_loss=2.1788  test_loss=2.2038  λ_max=2.8419\n",
      "[SGD | lr=0.001] Epoch 891/4000: train_loss=2.1788  test_loss=2.2038  λ_max=2.8180\n",
      "[SGD | lr=0.001] Epoch 892/4000: train_loss=2.1788  test_loss=2.2038  λ_max=2.6803\n",
      "[SGD | lr=0.001] Epoch 893/4000: train_loss=2.1789  test_loss=2.2038  λ_max=2.9094\n",
      "[SGD | lr=0.001] Iter 14300: loss=2.1798\n",
      "[SGD | lr=0.001] Epoch 894/4000: train_loss=2.1788  test_loss=2.2038  λ_max=2.8016\n",
      "[SGD | lr=0.001] Epoch 895/4000: train_loss=2.1788  test_loss=2.2038  λ_max=2.8301\n",
      "[SGD | lr=0.001] Epoch 896/4000: train_loss=2.1787  test_loss=2.2038  λ_max=2.8957\n",
      "[SGD | lr=0.001] Epoch 897/4000: train_loss=2.1788  test_loss=2.2038  λ_max=2.8235\n",
      "[SGD | lr=0.001] Epoch 898/4000: train_loss=2.1787  test_loss=2.2038  λ_max=2.8472\n",
      "[SGD | lr=0.001] Epoch 899/4000: train_loss=2.1787  test_loss=2.2038  λ_max=2.8471\n",
      "[SGD | lr=0.001] Iter 14400: loss=2.1794\n",
      "[SGD | lr=0.001] Epoch 900/4000: train_loss=2.1787  test_loss=2.2037  λ_max=2.8937\n",
      "[SGD | lr=0.001] Epoch 901/4000: train_loss=2.1787  test_loss=2.2037  λ_max=2.8154\n",
      "[SGD | lr=0.001] Epoch 902/4000: train_loss=2.1786  test_loss=2.2037  λ_max=2.8033\n",
      "[SGD | lr=0.001] Epoch 903/4000: train_loss=2.1785  test_loss=2.2037  λ_max=2.7430\n",
      "[SGD | lr=0.001] Epoch 904/4000: train_loss=2.1785  test_loss=2.2037  λ_max=2.7734\n",
      "[SGD | lr=0.001] Epoch 905/4000: train_loss=2.1785  test_loss=2.2037  λ_max=2.7727\n",
      "[SGD | lr=0.001] Epoch 906/4000: train_loss=2.1785  test_loss=2.2037  λ_max=2.8518\n",
      "[SGD | lr=0.001] Iter 14500: loss=2.1766\n",
      "[SGD | lr=0.001] Epoch 907/4000: train_loss=2.1784  test_loss=2.2037  λ_max=2.7889\n",
      "[SGD | lr=0.001] Epoch 908/4000: train_loss=2.1784  test_loss=2.2037  λ_max=2.8424\n",
      "[SGD | lr=0.001] Epoch 909/4000: train_loss=2.1784  test_loss=2.2037  λ_max=2.8267\n",
      "[SGD | lr=0.001] Epoch 910/4000: train_loss=2.1784  test_loss=2.2037  λ_max=2.8640\n",
      "[SGD | lr=0.001] Epoch 911/4000: train_loss=2.1783  test_loss=2.2037  λ_max=2.8745\n",
      "[SGD | lr=0.001] Epoch 912/4000: train_loss=2.1782  test_loss=2.2037  λ_max=2.7759\n",
      "[SGD | lr=0.001] Iter 14600: loss=2.1757\n",
      "[SGD | lr=0.001] Epoch 913/4000: train_loss=2.1782  test_loss=2.2037  λ_max=2.9289\n",
      "[SGD | lr=0.001] Epoch 914/4000: train_loss=2.1783  test_loss=2.2037  λ_max=2.8120\n",
      "[SGD | lr=0.001] Epoch 915/4000: train_loss=2.1782  test_loss=2.2037  λ_max=2.8197\n",
      "[SGD | lr=0.001] Epoch 916/4000: train_loss=2.1782  test_loss=2.2037  λ_max=2.9392\n",
      "[SGD | lr=0.001] Epoch 917/4000: train_loss=2.1781  test_loss=2.2037  λ_max=2.8266\n",
      "[SGD | lr=0.001] Epoch 918/4000: train_loss=2.1781  test_loss=2.2037  λ_max=2.9166\n",
      "[SGD | lr=0.001] Iter 14700: loss=2.1790\n",
      "[SGD | lr=0.001] Epoch 919/4000: train_loss=2.1782  test_loss=2.2037  λ_max=2.7242\n",
      "[SGD | lr=0.001] Epoch 920/4000: train_loss=2.1780  test_loss=2.2037  λ_max=2.7640\n",
      "[SGD | lr=0.001] Epoch 921/4000: train_loss=2.1780  test_loss=2.2037  λ_max=2.8267\n",
      "[SGD | lr=0.001] Epoch 922/4000: train_loss=2.1780  test_loss=2.2037  λ_max=2.7537\n",
      "[SGD | lr=0.001] Epoch 923/4000: train_loss=2.1781  test_loss=2.2037  λ_max=2.9478\n",
      "[SGD | lr=0.001] Epoch 924/4000: train_loss=2.1780  test_loss=2.2037  λ_max=2.8311\n",
      "[SGD | lr=0.001] Iter 14800: loss=2.1774\n",
      "[SGD | lr=0.001] Epoch 925/4000: train_loss=2.1779  test_loss=2.2037  λ_max=2.9517\n",
      "[SGD | lr=0.001] Epoch 926/4000: train_loss=2.1779  test_loss=2.2037  λ_max=2.9327\n",
      "[SGD | lr=0.001] Epoch 927/4000: train_loss=2.1779  test_loss=2.2037  λ_max=2.9636\n",
      "[SGD | lr=0.001] Epoch 928/4000: train_loss=2.1778  test_loss=2.2037  λ_max=2.9382\n",
      "[SGD | lr=0.001] Epoch 929/4000: train_loss=2.1779  test_loss=2.2037  λ_max=2.7550\n",
      "[SGD | lr=0.001] Epoch 930/4000: train_loss=2.1777  test_loss=2.2037  λ_max=2.8453\n",
      "[SGD | lr=0.001] Epoch 931/4000: train_loss=2.1778  test_loss=2.2037  λ_max=2.8926\n",
      "[SGD | lr=0.001] Iter 14900: loss=2.1805\n",
      "[SGD | lr=0.001] Epoch 932/4000: train_loss=2.1778  test_loss=2.2037  λ_max=2.9365\n",
      "[SGD | lr=0.001] Epoch 933/4000: train_loss=2.1776  test_loss=2.2037  λ_max=2.9615\n",
      "[SGD | lr=0.001] Epoch 934/4000: train_loss=2.1776  test_loss=2.2037  λ_max=2.9013\n",
      "[SGD | lr=0.001] Epoch 935/4000: train_loss=2.1777  test_loss=2.2037  λ_max=2.9794\n",
      "[SGD | lr=0.001] Epoch 936/4000: train_loss=2.1776  test_loss=2.2037  λ_max=2.8932\n",
      "[SGD | lr=0.001] Epoch 937/4000: train_loss=2.1777  test_loss=2.2037  λ_max=2.9385\n",
      "[SGD | lr=0.001] Iter 15000: loss=2.1779\n",
      "[SGD | lr=0.001] Epoch 938/4000: train_loss=2.1775  test_loss=2.2037  λ_max=2.9483\n",
      "[SGD | lr=0.001] Epoch 939/4000: train_loss=2.1776  test_loss=2.2037  λ_max=2.9131\n",
      "[SGD | lr=0.001] Epoch 940/4000: train_loss=2.1775  test_loss=2.2037  λ_max=2.7850\n",
      "[SGD | lr=0.001] Epoch 941/4000: train_loss=2.1775  test_loss=2.2037  λ_max=2.7444\n",
      "[SGD | lr=0.001] Epoch 942/4000: train_loss=2.1774  test_loss=2.2037  λ_max=2.9884\n",
      "[SGD | lr=0.001] Epoch 943/4000: train_loss=2.1774  test_loss=2.2037  λ_max=2.8111\n",
      "[SGD | lr=0.001] Iter 15100: loss=2.1776\n",
      "[SGD | lr=0.001] Epoch 944/4000: train_loss=2.1774  test_loss=2.2037  λ_max=2.7664\n",
      "[SGD | lr=0.001] Epoch 945/4000: train_loss=2.1774  test_loss=2.2037  λ_max=2.9740\n",
      "[SGD | lr=0.001] Epoch 946/4000: train_loss=2.1773  test_loss=2.2037  λ_max=2.8841\n",
      "[SGD | lr=0.001] Epoch 947/4000: train_loss=2.1774  test_loss=2.2037  λ_max=2.8892\n",
      "[SGD | lr=0.001] Epoch 948/4000: train_loss=2.1774  test_loss=2.2037  λ_max=2.9040\n",
      "[SGD | lr=0.001] Epoch 949/4000: train_loss=2.1772  test_loss=2.2037  λ_max=2.9594\n",
      "[SGD | lr=0.001] Iter 15200: loss=2.1800\n",
      "[SGD | lr=0.001] Epoch 950/4000: train_loss=2.1773  test_loss=2.2037  λ_max=2.9400\n",
      "[SGD | lr=0.001] Epoch 951/4000: train_loss=2.1772  test_loss=2.2037  λ_max=2.8324\n",
      "[SGD | lr=0.001] Epoch 952/4000: train_loss=2.1771  test_loss=2.2037  λ_max=2.9437\n",
      "[SGD | lr=0.001] Epoch 953/4000: train_loss=2.1771  test_loss=2.2037  λ_max=2.7958\n",
      "[SGD | lr=0.001] Epoch 954/4000: train_loss=2.1771  test_loss=2.2037  λ_max=2.8861\n",
      "[SGD | lr=0.001] Epoch 955/4000: train_loss=2.1771  test_loss=2.2037  λ_max=2.9344\n",
      "[SGD | lr=0.001] Epoch 956/4000: train_loss=2.1770  test_loss=2.2037  λ_max=2.8276\n",
      "[SGD | lr=0.001] Iter 15300: loss=2.1772\n",
      "[SGD | lr=0.001] Epoch 957/4000: train_loss=2.1770  test_loss=2.2037  λ_max=2.8588\n",
      "[SGD | lr=0.001] Epoch 958/4000: train_loss=2.1770  test_loss=2.2037  λ_max=2.8249\n",
      "[SGD | lr=0.001] Epoch 959/4000: train_loss=2.1770  test_loss=2.2037  λ_max=2.8517\n",
      "[SGD | lr=0.001] Epoch 960/4000: train_loss=2.1770  test_loss=2.2037  λ_max=2.9489\n",
      "[SGD | lr=0.001] Epoch 961/4000: train_loss=2.1769  test_loss=2.2037  λ_max=2.9325\n",
      "[SGD | lr=0.001] Epoch 962/4000: train_loss=2.1770  test_loss=2.2037  λ_max=2.9302\n",
      "[SGD | lr=0.001] Iter 15400: loss=2.1764\n",
      "[SGD | lr=0.001] Epoch 963/4000: train_loss=2.1768  test_loss=2.2037  λ_max=2.8094\n",
      "[SGD | lr=0.001] Epoch 964/4000: train_loss=2.1768  test_loss=2.2037  λ_max=2.8928\n",
      "[SGD | lr=0.001] Epoch 965/4000: train_loss=2.1768  test_loss=2.2037  λ_max=3.0113\n",
      "[SGD | lr=0.001] Epoch 966/4000: train_loss=2.1767  test_loss=2.2037  λ_max=2.8609\n",
      "[SGD | lr=0.001] Epoch 967/4000: train_loss=2.1768  test_loss=2.2037  λ_max=2.8741\n",
      "[SGD | lr=0.001] Epoch 968/4000: train_loss=2.1767  test_loss=2.2037  λ_max=3.0166\n",
      "[SGD | lr=0.001] Iter 15500: loss=2.1776\n",
      "[SGD | lr=0.001] Epoch 969/4000: train_loss=2.1766  test_loss=2.2037  λ_max=2.8973\n",
      "[SGD | lr=0.001] Epoch 970/4000: train_loss=2.1766  test_loss=2.2037  λ_max=2.9419\n",
      "[SGD | lr=0.001] Epoch 971/4000: train_loss=2.1766  test_loss=2.2037  λ_max=2.9859\n",
      "[SGD | lr=0.001] Epoch 972/4000: train_loss=2.1766  test_loss=2.2037  λ_max=2.9555\n",
      "[SGD | lr=0.001] Epoch 973/4000: train_loss=2.1766  test_loss=2.2037  λ_max=2.9024\n",
      "[SGD | lr=0.001] Epoch 974/4000: train_loss=2.1765  test_loss=2.2037  λ_max=2.9194\n",
      "[SGD | lr=0.001] Iter 15600: loss=2.1719\n",
      "[SGD | lr=0.001] Epoch 975/4000: train_loss=2.1764  test_loss=2.2037  λ_max=2.9596\n",
      "[SGD | lr=0.001] Epoch 976/4000: train_loss=2.1766  test_loss=2.2037  λ_max=2.9833\n",
      "[SGD | lr=0.001] Epoch 977/4000: train_loss=2.1765  test_loss=2.2037  λ_max=2.8035\n",
      "[SGD | lr=0.001] Epoch 978/4000: train_loss=2.1764  test_loss=2.2037  λ_max=2.9180\n",
      "[SGD | lr=0.001] Epoch 979/4000: train_loss=2.1764  test_loss=2.2037  λ_max=2.9952\n",
      "[SGD | lr=0.001] Epoch 980/4000: train_loss=2.1763  test_loss=2.2037  λ_max=3.0427\n",
      "[SGD | lr=0.001] Epoch 981/4000: train_loss=2.1763  test_loss=2.2037  λ_max=2.8646\n",
      "[SGD | lr=0.001] Iter 15700: loss=2.1783\n",
      "[SGD | lr=0.001] Epoch 982/4000: train_loss=2.1763  test_loss=2.2037  λ_max=3.0016\n",
      "[SGD | lr=0.001] Epoch 983/4000: train_loss=2.1763  test_loss=2.2037  λ_max=2.8605\n",
      "[SGD | lr=0.001] Epoch 984/4000: train_loss=2.1761  test_loss=2.2037  λ_max=2.9674\n",
      "[SGD | lr=0.001] Epoch 985/4000: train_loss=2.1762  test_loss=2.2037  λ_max=3.0273\n",
      "[SGD | lr=0.001] Epoch 986/4000: train_loss=2.1762  test_loss=2.2037  λ_max=2.9316\n",
      "[SGD | lr=0.001] Epoch 987/4000: train_loss=2.1762  test_loss=2.2037  λ_max=2.9459\n",
      "[SGD | lr=0.001] Iter 15800: loss=2.1746\n",
      "[SGD | lr=0.001] Epoch 988/4000: train_loss=2.1762  test_loss=2.2037  λ_max=3.0133\n",
      "[SGD | lr=0.001] Epoch 989/4000: train_loss=2.1761  test_loss=2.2037  λ_max=2.9626\n",
      "[SGD | lr=0.001] Epoch 990/4000: train_loss=2.1760  test_loss=2.2037  λ_max=2.8462\n",
      "[SGD | lr=0.001] Epoch 991/4000: train_loss=2.1761  test_loss=2.2037  λ_max=2.8605\n",
      "[SGD | lr=0.001] Epoch 992/4000: train_loss=2.1761  test_loss=2.2037  λ_max=2.8997\n",
      "[SGD | lr=0.001] Epoch 993/4000: train_loss=2.1760  test_loss=2.2037  λ_max=2.9807\n",
      "[SGD | lr=0.001] Iter 15900: loss=2.1762\n",
      "[SGD | lr=0.001] Epoch 994/4000: train_loss=2.1760  test_loss=2.2037  λ_max=2.9167\n",
      "[SGD | lr=0.001] Epoch 995/4000: train_loss=2.1760  test_loss=2.2037  λ_max=2.9257\n",
      "[SGD | lr=0.001] Epoch 996/4000: train_loss=2.1759  test_loss=2.2037  λ_max=3.0011\n",
      "[SGD | lr=0.001] Epoch 997/4000: train_loss=2.1759  test_loss=2.2037  λ_max=3.0371\n",
      "[SGD | lr=0.001] Epoch 998/4000: train_loss=2.1758  test_loss=2.2037  λ_max=2.9656\n",
      "[SGD | lr=0.001] Epoch 999/4000: train_loss=2.1759  test_loss=2.2037  λ_max=3.0117\n",
      "[SGD | lr=0.001] Iter 16000: loss=2.1760\n",
      "[SGD | lr=0.001] Epoch 1000/4000: train_loss=2.1758  test_loss=2.2037  λ_max=2.9003\n",
      "[SGD | lr=0.001] Epoch 1001/4000: train_loss=2.1757  test_loss=2.2037  λ_max=3.0563\n",
      "[SGD | lr=0.001] Epoch 1002/4000: train_loss=2.1757  test_loss=2.2037  λ_max=2.8908\n",
      "[SGD | lr=0.001] Epoch 1003/4000: train_loss=2.1756  test_loss=2.2037  λ_max=3.1136\n",
      "[SGD | lr=0.001] Epoch 1004/4000: train_loss=2.1757  test_loss=2.2037  λ_max=2.9748\n",
      "[SGD | lr=0.001] Epoch 1005/4000: train_loss=2.1756  test_loss=2.2037  λ_max=3.0241\n",
      "[SGD | lr=0.001] Epoch 1006/4000: train_loss=2.1756  test_loss=2.2037  λ_max=2.9002\n",
      "[SGD | lr=0.001] Iter 16100: loss=2.1792\n",
      "[SGD | lr=0.001] Epoch 1007/4000: train_loss=2.1756  test_loss=2.2037  λ_max=3.0019\n",
      "[SGD | lr=0.001] Epoch 1008/4000: train_loss=2.1755  test_loss=2.2037  λ_max=2.9510\n",
      "[SGD | lr=0.001] Epoch 1009/4000: train_loss=2.1755  test_loss=2.2037  λ_max=3.0416\n",
      "[SGD | lr=0.001] Epoch 1010/4000: train_loss=2.1754  test_loss=2.2037  λ_max=2.9793\n",
      "[SGD | lr=0.001] Epoch 1011/4000: train_loss=2.1754  test_loss=2.2037  λ_max=2.9444\n",
      "[SGD | lr=0.001] Epoch 1012/4000: train_loss=2.1754  test_loss=2.2037  λ_max=3.0410\n",
      "[SGD | lr=0.001] Iter 16200: loss=2.1757\n",
      "[SGD | lr=0.001] Epoch 1013/4000: train_loss=2.1754  test_loss=2.2037  λ_max=2.9286\n",
      "[SGD | lr=0.001] Epoch 1014/4000: train_loss=2.1755  test_loss=2.2037  λ_max=3.0812\n",
      "[SGD | lr=0.001] Epoch 1015/4000: train_loss=2.1753  test_loss=2.2037  λ_max=2.9398\n",
      "[SGD | lr=0.001] Epoch 1016/4000: train_loss=2.1753  test_loss=2.2037  λ_max=2.8983\n",
      "[SGD | lr=0.001] Epoch 1017/4000: train_loss=2.1752  test_loss=2.2037  λ_max=2.9329\n",
      "[SGD | lr=0.001] Epoch 1018/4000: train_loss=2.1752  test_loss=2.2037  λ_max=2.9677\n",
      "[SGD | lr=0.001] Iter 16300: loss=2.1749\n",
      "[SGD | lr=0.001] Epoch 1019/4000: train_loss=2.1751  test_loss=2.2037  λ_max=3.0614\n",
      "[SGD | lr=0.001] Epoch 1020/4000: train_loss=2.1751  test_loss=2.2037  λ_max=3.0257\n",
      "[SGD | lr=0.001] Epoch 1021/4000: train_loss=2.1752  test_loss=2.2037  λ_max=3.0773\n",
      "[SGD | lr=0.001] Epoch 1022/4000: train_loss=2.1752  test_loss=2.2037  λ_max=3.0092\n",
      "[SGD | lr=0.001] Epoch 1023/4000: train_loss=2.1751  test_loss=2.2037  λ_max=3.0447\n",
      "[SGD | lr=0.001] Epoch 1024/4000: train_loss=2.1751  test_loss=2.2037  λ_max=2.8954\n",
      "[SGD | lr=0.001] Iter 16400: loss=2.1740\n",
      "[SGD | lr=0.001] Epoch 1025/4000: train_loss=2.1750  test_loss=2.2037  λ_max=2.9520\n",
      "[SGD | lr=0.001] Epoch 1026/4000: train_loss=2.1749  test_loss=2.2037  λ_max=2.9157\n",
      "[SGD | lr=0.001] Epoch 1027/4000: train_loss=2.1749  test_loss=2.2037  λ_max=3.0317\n",
      "[SGD | lr=0.001] Epoch 1028/4000: train_loss=2.1749  test_loss=2.2037  λ_max=3.0563\n",
      "[SGD | lr=0.001] Epoch 1029/4000: train_loss=2.1749  test_loss=2.2037  λ_max=3.1097\n",
      "[SGD | lr=0.001] Epoch 1030/4000: train_loss=2.1748  test_loss=2.2037  λ_max=2.9549\n",
      "[SGD | lr=0.001] Epoch 1031/4000: train_loss=2.1748  test_loss=2.2037  λ_max=2.9892\n",
      "[SGD | lr=0.001] Iter 16500: loss=2.1718\n",
      "[SGD | lr=0.001] Epoch 1032/4000: train_loss=2.1748  test_loss=2.2037  λ_max=2.9829\n",
      "[SGD | lr=0.001] Epoch 1033/4000: train_loss=2.1748  test_loss=2.2037  λ_max=3.0117\n",
      "[SGD | lr=0.001] Epoch 1034/4000: train_loss=2.1748  test_loss=2.2037  λ_max=2.8564\n",
      "[SGD | lr=0.001] Epoch 1035/4000: train_loss=2.1747  test_loss=2.2037  λ_max=3.0114\n",
      "[SGD | lr=0.001] Epoch 1036/4000: train_loss=2.1747  test_loss=2.2037  λ_max=2.9660\n",
      "[SGD | lr=0.001] Epoch 1037/4000: train_loss=2.1747  test_loss=2.2037  λ_max=2.9447\n",
      "[SGD | lr=0.001] Iter 16600: loss=2.1738\n",
      "[SGD | lr=0.001] Epoch 1038/4000: train_loss=2.1746  test_loss=2.2037  λ_max=2.9601\n",
      "[SGD | lr=0.001] Epoch 1039/4000: train_loss=2.1746  test_loss=2.2037  λ_max=3.0021\n",
      "[SGD | lr=0.001] Epoch 1040/4000: train_loss=2.1744  test_loss=2.2037  λ_max=3.0686\n",
      "[SGD | lr=0.001] Epoch 1041/4000: train_loss=2.1744  test_loss=2.2037  λ_max=3.0627\n",
      "[SGD | lr=0.001] Epoch 1042/4000: train_loss=2.1744  test_loss=2.2037  λ_max=2.8301\n",
      "[SGD | lr=0.001] Epoch 1043/4000: train_loss=2.1744  test_loss=2.2037  λ_max=2.9813\n",
      "[SGD | lr=0.001] Iter 16700: loss=2.1742\n",
      "[SGD | lr=0.001] Epoch 1044/4000: train_loss=2.1745  test_loss=2.2037  λ_max=2.9886\n",
      "[SGD | lr=0.001] Epoch 1045/4000: train_loss=2.1744  test_loss=2.2037  λ_max=2.9315\n",
      "[SGD | lr=0.001] Epoch 1046/4000: train_loss=2.1743  test_loss=2.2037  λ_max=3.0380\n",
      "[SGD | lr=0.001] Epoch 1047/4000: train_loss=2.1743  test_loss=2.2037  λ_max=2.9568\n",
      "[SGD | lr=0.001] Epoch 1048/4000: train_loss=2.1743  test_loss=2.2037  λ_max=3.0468\n",
      "[SGD | lr=0.001] Epoch 1049/4000: train_loss=2.1741  test_loss=2.2037  λ_max=3.0976\n",
      "[SGD | lr=0.001] Iter 16800: loss=2.1755\n",
      "[SGD | lr=0.001] Epoch 1050/4000: train_loss=2.1742  test_loss=2.2037  λ_max=3.0558\n",
      "[SGD | lr=0.001] Epoch 1051/4000: train_loss=2.1742  test_loss=2.2037  λ_max=3.1298\n",
      "[SGD | lr=0.001] Epoch 1052/4000: train_loss=2.1741  test_loss=2.2037  λ_max=3.0819\n",
      "[SGD | lr=0.001] Epoch 1053/4000: train_loss=2.1741  test_loss=2.2037  λ_max=2.8694\n",
      "[SGD | lr=0.001] Epoch 1054/4000: train_loss=2.1740  test_loss=2.2037  λ_max=2.9460\n",
      "[SGD | lr=0.001] Epoch 1055/4000: train_loss=2.1740  test_loss=2.2037  λ_max=3.1061\n",
      "[SGD | lr=0.001] Epoch 1056/4000: train_loss=2.1740  test_loss=2.2037  λ_max=2.9552\n",
      "[SGD | lr=0.001] Iter 16900: loss=2.1712\n",
      "[SGD | lr=0.001] Epoch 1057/4000: train_loss=2.1739  test_loss=2.2037  λ_max=3.0921\n",
      "[SGD | lr=0.001] Epoch 1058/4000: train_loss=2.1739  test_loss=2.2037  λ_max=2.8983\n",
      "[SGD | lr=0.001] Epoch 1059/4000: train_loss=2.1739  test_loss=2.2037  λ_max=3.1468\n",
      "[SGD | lr=0.001] Epoch 1060/4000: train_loss=2.1739  test_loss=2.2037  λ_max=3.0350\n",
      "[SGD | lr=0.001] Epoch 1061/4000: train_loss=2.1739  test_loss=2.2037  λ_max=3.0471\n",
      "[SGD | lr=0.001] Epoch 1062/4000: train_loss=2.1738  test_loss=2.2037  λ_max=3.0544\n",
      "[SGD | lr=0.001] Iter 17000: loss=2.1734\n",
      "[SGD | lr=0.001] Epoch 1063/4000: train_loss=2.1739  test_loss=2.2037  λ_max=2.9145\n",
      "[SGD | lr=0.001] Epoch 1064/4000: train_loss=2.1738  test_loss=2.2037  λ_max=3.0263\n",
      "[SGD | lr=0.001] Epoch 1065/4000: train_loss=2.1737  test_loss=2.2037  λ_max=2.9680\n",
      "[SGD | lr=0.001] Epoch 1066/4000: train_loss=2.1737  test_loss=2.2037  λ_max=3.0683\n",
      "[SGD | lr=0.001] Epoch 1067/4000: train_loss=2.1736  test_loss=2.2037  λ_max=3.0386\n",
      "[SGD | lr=0.001] Epoch 1068/4000: train_loss=2.1736  test_loss=2.2037  λ_max=2.9856\n",
      "[SGD | lr=0.001] Iter 17100: loss=2.1752\n",
      "[SGD | lr=0.001] Epoch 1069/4000: train_loss=2.1736  test_loss=2.2037  λ_max=3.0051\n",
      "[SGD | lr=0.001] Epoch 1070/4000: train_loss=2.1736  test_loss=2.2037  λ_max=3.0264\n",
      "[SGD | lr=0.001] Epoch 1071/4000: train_loss=2.1735  test_loss=2.2037  λ_max=3.0571\n",
      "[SGD | lr=0.001] Epoch 1072/4000: train_loss=2.1735  test_loss=2.2037  λ_max=3.0935\n",
      "[SGD | lr=0.001] Epoch 1073/4000: train_loss=2.1734  test_loss=2.2037  λ_max=3.1092\n",
      "[SGD | lr=0.001] Epoch 1074/4000: train_loss=2.1735  test_loss=2.2037  λ_max=3.0473\n",
      "[SGD | lr=0.001] Iter 17200: loss=2.1730\n",
      "[SGD | lr=0.001] Epoch 1075/4000: train_loss=2.1734  test_loss=2.2037  λ_max=3.1023\n",
      "[SGD | lr=0.001] Epoch 1076/4000: train_loss=2.1734  test_loss=2.2037  λ_max=3.0167\n",
      "[SGD | lr=0.001] Epoch 1077/4000: train_loss=2.1733  test_loss=2.2037  λ_max=3.0849\n",
      "[SGD | lr=0.001] Epoch 1078/4000: train_loss=2.1731  test_loss=2.2037  λ_max=3.1447\n",
      "[SGD | lr=0.001] Epoch 1079/4000: train_loss=2.1731  test_loss=2.2037  λ_max=2.9491\n",
      "[SGD | lr=0.001] Epoch 1080/4000: train_loss=2.1733  test_loss=2.2037  λ_max=3.0732\n",
      "[SGD | lr=0.001] Epoch 1081/4000: train_loss=2.1733  test_loss=2.2037  λ_max=3.0754\n",
      "[SGD | lr=0.001] Iter 17300: loss=2.1746\n",
      "[SGD | lr=0.001] Epoch 1082/4000: train_loss=2.1732  test_loss=2.2037  λ_max=3.1413\n",
      "[SGD | lr=0.001] Epoch 1083/4000: train_loss=2.1731  test_loss=2.2037  λ_max=3.0794\n",
      "[SGD | lr=0.001] Epoch 1084/4000: train_loss=2.1730  test_loss=2.2037  λ_max=3.0329\n",
      "[SGD | lr=0.001] Epoch 1085/4000: train_loss=2.1731  test_loss=2.2037  λ_max=3.1356\n",
      "[SGD | lr=0.001] Epoch 1086/4000: train_loss=2.1730  test_loss=2.2037  λ_max=3.1347\n",
      "[SGD | lr=0.001] Epoch 1087/4000: train_loss=2.1730  test_loss=2.2037  λ_max=3.0828\n",
      "[SGD | lr=0.001] Iter 17400: loss=2.1741\n",
      "[SGD | lr=0.001] Epoch 1088/4000: train_loss=2.1729  test_loss=2.2037  λ_max=3.1226\n",
      "[SGD | lr=0.001] Epoch 1089/4000: train_loss=2.1729  test_loss=2.2037  λ_max=3.0354\n",
      "[SGD | lr=0.001] Epoch 1090/4000: train_loss=2.1729  test_loss=2.2037  λ_max=3.1944\n",
      "[SGD | lr=0.001] Epoch 1091/4000: train_loss=2.1729  test_loss=2.2037  λ_max=3.0606\n",
      "[SGD | lr=0.001] Epoch 1092/4000: train_loss=2.1728  test_loss=2.2037  λ_max=2.9817\n",
      "[SGD | lr=0.001] Epoch 1093/4000: train_loss=2.1727  test_loss=2.2037  λ_max=3.1895\n",
      "[SGD | lr=0.001] Iter 17500: loss=2.1737\n",
      "[SGD | lr=0.001] Epoch 1094/4000: train_loss=2.1727  test_loss=2.2037  λ_max=3.1676\n",
      "[SGD | lr=0.001] Epoch 1095/4000: train_loss=2.1727  test_loss=2.2037  λ_max=3.1635\n",
      "[SGD | lr=0.001] Epoch 1096/4000: train_loss=2.1726  test_loss=2.2037  λ_max=3.2097\n",
      "[SGD | lr=0.001] Epoch 1097/4000: train_loss=2.1725  test_loss=2.2037  λ_max=3.0545\n",
      "[SGD | lr=0.001] Epoch 1098/4000: train_loss=2.1726  test_loss=2.2037  λ_max=3.1601\n",
      "[SGD | lr=0.001] Epoch 1099/4000: train_loss=2.1725  test_loss=2.2037  λ_max=3.2089\n",
      "[SGD | lr=0.001] Iter 17600: loss=2.1713\n",
      "[SGD | lr=0.001] Epoch 1100/4000: train_loss=2.1725  test_loss=2.2037  λ_max=3.2382\n",
      "[SGD | lr=0.001] Epoch 1101/4000: train_loss=2.1724  test_loss=2.2037  λ_max=3.1744\n",
      "[SGD | lr=0.001] Epoch 1102/4000: train_loss=2.1724  test_loss=2.2037  λ_max=3.1966\n",
      "[SGD | lr=0.001] Epoch 1103/4000: train_loss=2.1724  test_loss=2.2038  λ_max=3.1840\n",
      "[SGD | lr=0.001] Epoch 1104/4000: train_loss=2.1724  test_loss=2.2038  λ_max=2.9156\n",
      "[SGD | lr=0.001] Epoch 1105/4000: train_loss=2.1724  test_loss=2.2038  λ_max=3.0023\n",
      "[SGD | lr=0.001] Epoch 1106/4000: train_loss=2.1723  test_loss=2.2038  λ_max=3.0981\n",
      "[SGD | lr=0.001] Iter 17700: loss=2.1735\n",
      "[SGD | lr=0.001] Epoch 1107/4000: train_loss=2.1723  test_loss=2.2038  λ_max=2.9617\n",
      "[SGD | lr=0.001] Epoch 1108/4000: train_loss=2.1723  test_loss=2.2038  λ_max=3.2181\n",
      "[SGD | lr=0.001] Epoch 1109/4000: train_loss=2.1722  test_loss=2.2038  λ_max=3.0601\n",
      "[SGD | lr=0.001] Epoch 1110/4000: train_loss=2.1722  test_loss=2.2038  λ_max=3.1640\n",
      "[SGD | lr=0.001] Epoch 1111/4000: train_loss=2.1722  test_loss=2.2038  λ_max=3.1219\n",
      "[SGD | lr=0.001] Epoch 1112/4000: train_loss=2.1720  test_loss=2.2038  λ_max=3.1451\n",
      "[SGD | lr=0.001] Iter 17800: loss=2.1731\n",
      "[SGD | lr=0.001] Epoch 1113/4000: train_loss=2.1720  test_loss=2.2038  λ_max=3.1358\n",
      "[SGD | lr=0.001] Epoch 1114/4000: train_loss=2.1721  test_loss=2.2038  λ_max=3.2653\n",
      "[SGD | lr=0.001] Epoch 1115/4000: train_loss=2.1720  test_loss=2.2038  λ_max=3.2499\n",
      "[SGD | lr=0.001] Epoch 1116/4000: train_loss=2.1720  test_loss=2.2038  λ_max=3.0536\n",
      "[SGD | lr=0.001] Epoch 1117/4000: train_loss=2.1718  test_loss=2.2038  λ_max=3.0984\n",
      "[SGD | lr=0.001] Epoch 1118/4000: train_loss=2.1718  test_loss=2.2038  λ_max=3.0018\n",
      "[SGD | lr=0.001] Iter 17900: loss=2.1711\n",
      "[SGD | lr=0.001] Epoch 1119/4000: train_loss=2.1719  test_loss=2.2038  λ_max=3.1987\n",
      "[SGD | lr=0.001] Epoch 1120/4000: train_loss=2.1719  test_loss=2.2038  λ_max=3.1845\n",
      "[SGD | lr=0.001] Epoch 1121/4000: train_loss=2.1717  test_loss=2.2038  λ_max=3.1668\n",
      "[SGD | lr=0.001] Epoch 1122/4000: train_loss=2.1719  test_loss=2.2038  λ_max=3.1843\n",
      "[SGD | lr=0.001] Epoch 1123/4000: train_loss=2.1718  test_loss=2.2038  λ_max=3.2409\n",
      "[SGD | lr=0.001] Epoch 1124/4000: train_loss=2.1717  test_loss=2.2038  λ_max=3.1551\n",
      "[SGD | lr=0.001] Iter 18000: loss=2.1732\n",
      "[SGD | lr=0.001] Epoch 1125/4000: train_loss=2.1717  test_loss=2.2038  λ_max=3.1415\n",
      "[SGD | lr=0.001] Epoch 1126/4000: train_loss=2.1717  test_loss=2.2038  λ_max=3.2690\n",
      "[SGD | lr=0.001] Epoch 1127/4000: train_loss=2.1715  test_loss=2.2038  λ_max=3.2705\n",
      "[SGD | lr=0.001] Epoch 1128/4000: train_loss=2.1715  test_loss=2.2038  λ_max=3.1829\n",
      "[SGD | lr=0.001] Epoch 1129/4000: train_loss=2.1715  test_loss=2.2038  λ_max=3.1718\n",
      "[SGD | lr=0.001] Epoch 1130/4000: train_loss=2.1716  test_loss=2.2038  λ_max=3.2091\n",
      "[SGD | lr=0.001] Epoch 1131/4000: train_loss=2.1714  test_loss=2.2038  λ_max=3.1606\n",
      "[SGD | lr=0.001] Iter 18100: loss=2.1724\n",
      "[SGD | lr=0.001] Epoch 1132/4000: train_loss=2.1714  test_loss=2.2038  λ_max=3.2965\n",
      "[SGD | lr=0.001] Epoch 1133/4000: train_loss=2.1713  test_loss=2.2038  λ_max=3.1338\n",
      "[SGD | lr=0.001] Epoch 1134/4000: train_loss=2.1714  test_loss=2.2038  λ_max=3.1372\n",
      "[SGD | lr=0.001] Epoch 1135/4000: train_loss=2.1713  test_loss=2.2038  λ_max=3.2011\n",
      "[SGD | lr=0.001] Epoch 1136/4000: train_loss=2.1712  test_loss=2.2038  λ_max=3.1357\n",
      "[SGD | lr=0.001] Epoch 1137/4000: train_loss=2.1711  test_loss=2.2038  λ_max=3.1935\n",
      "[SGD | lr=0.001] Iter 18200: loss=2.1706\n",
      "[SGD | lr=0.001] Epoch 1138/4000: train_loss=2.1712  test_loss=2.2038  λ_max=3.1900\n",
      "[SGD | lr=0.001] Epoch 1139/4000: train_loss=2.1712  test_loss=2.2038  λ_max=3.2477\n",
      "[SGD | lr=0.001] Epoch 1140/4000: train_loss=2.1712  test_loss=2.2038  λ_max=3.3092\n",
      "[SGD | lr=0.001] Epoch 1141/4000: train_loss=2.1711  test_loss=2.2038  λ_max=3.1795\n",
      "[SGD | lr=0.001] Epoch 1142/4000: train_loss=2.1711  test_loss=2.2038  λ_max=3.0588\n",
      "[SGD | lr=0.001] Epoch 1143/4000: train_loss=2.1710  test_loss=2.2038  λ_max=3.0895\n",
      "[SGD | lr=0.001] Iter 18300: loss=2.1710\n",
      "[SGD | lr=0.001] Epoch 1144/4000: train_loss=2.1709  test_loss=2.2038  λ_max=3.1436\n",
      "[SGD | lr=0.001] Epoch 1145/4000: train_loss=2.1709  test_loss=2.2038  λ_max=3.2304\n",
      "[SGD | lr=0.001] Epoch 1146/4000: train_loss=2.1709  test_loss=2.2039  λ_max=3.1581\n",
      "[SGD | lr=0.001] Epoch 1147/4000: train_loss=2.1709  test_loss=2.2039  λ_max=3.2443\n",
      "[SGD | lr=0.001] Epoch 1148/4000: train_loss=2.1707  test_loss=2.2039  λ_max=3.1317\n",
      "[SGD | lr=0.001] Epoch 1149/4000: train_loss=2.1708  test_loss=2.2039  λ_max=3.2116\n",
      "[SGD | lr=0.001] Iter 18400: loss=2.1690\n",
      "[SGD | lr=0.001] Epoch 1150/4000: train_loss=2.1707  test_loss=2.2039  λ_max=3.1239\n",
      "[SGD | lr=0.001] Epoch 1151/4000: train_loss=2.1707  test_loss=2.2039  λ_max=3.3246\n",
      "[SGD | lr=0.001] Epoch 1152/4000: train_loss=2.1707  test_loss=2.2039  λ_max=3.2913\n",
      "[SGD | lr=0.001] Epoch 1153/4000: train_loss=2.1706  test_loss=2.2039  λ_max=3.1589\n",
      "[SGD | lr=0.001] Epoch 1154/4000: train_loss=2.1705  test_loss=2.2039  λ_max=3.2335\n",
      "[SGD | lr=0.001] Epoch 1155/4000: train_loss=2.1706  test_loss=2.2039  λ_max=3.1571\n",
      "[SGD | lr=0.001] Epoch 1156/4000: train_loss=2.1706  test_loss=2.2039  λ_max=3.3381\n",
      "[SGD | lr=0.001] Iter 18500: loss=2.1736\n",
      "[SGD | lr=0.001] Epoch 1157/4000: train_loss=2.1705  test_loss=2.2039  λ_max=3.1120\n",
      "[SGD | lr=0.001] Epoch 1158/4000: train_loss=2.1704  test_loss=2.2039  λ_max=3.3237\n",
      "[SGD | lr=0.001] Epoch 1159/4000: train_loss=2.1704  test_loss=2.2039  λ_max=3.1955\n",
      "[SGD | lr=0.001] Epoch 1160/4000: train_loss=2.1704  test_loss=2.2039  λ_max=3.2522\n",
      "[SGD | lr=0.001] Epoch 1161/4000: train_loss=2.1704  test_loss=2.2039  λ_max=3.3035\n",
      "[SGD | lr=0.001] Epoch 1162/4000: train_loss=2.1703  test_loss=2.2039  λ_max=3.1746\n",
      "[SGD | lr=0.001] Iter 18600: loss=2.1710\n",
      "[SGD | lr=0.001] Epoch 1163/4000: train_loss=2.1703  test_loss=2.2039  λ_max=3.1565\n",
      "[SGD | lr=0.001] Epoch 1164/4000: train_loss=2.1702  test_loss=2.2039  λ_max=3.2440\n",
      "[SGD | lr=0.001] Epoch 1165/4000: train_loss=2.1702  test_loss=2.2039  λ_max=3.2287\n",
      "[SGD | lr=0.001] Epoch 1166/4000: train_loss=2.1701  test_loss=2.2039  λ_max=3.2385\n",
      "[SGD | lr=0.001] Epoch 1167/4000: train_loss=2.1702  test_loss=2.2039  λ_max=3.2709\n",
      "[SGD | lr=0.001] Epoch 1168/4000: train_loss=2.1700  test_loss=2.2039  λ_max=3.3058\n",
      "[SGD | lr=0.001] Iter 18700: loss=2.1690\n",
      "[SGD | lr=0.001] Epoch 1169/4000: train_loss=2.1700  test_loss=2.2039  λ_max=3.0669\n",
      "[SGD | lr=0.001] Epoch 1170/4000: train_loss=2.1700  test_loss=2.2039  λ_max=3.2462\n",
      "[SGD | lr=0.001] Epoch 1171/4000: train_loss=2.1700  test_loss=2.2039  λ_max=3.1719\n",
      "[SGD | lr=0.001] Epoch 1172/4000: train_loss=2.1700  test_loss=2.2039  λ_max=3.2688\n",
      "[SGD | lr=0.001] Epoch 1173/4000: train_loss=2.1699  test_loss=2.2039  λ_max=3.1792\n",
      "[SGD | lr=0.001] Epoch 1174/4000: train_loss=2.1698  test_loss=2.2040  λ_max=3.2911\n",
      "[SGD | lr=0.001] Iter 18800: loss=2.1709\n",
      "[SGD | lr=0.001] Epoch 1175/4000: train_loss=2.1698  test_loss=2.2040  λ_max=3.2122\n",
      "[SGD | lr=0.001] Epoch 1176/4000: train_loss=2.1698  test_loss=2.2040  λ_max=3.1164\n",
      "[SGD | lr=0.001] Epoch 1177/4000: train_loss=2.1697  test_loss=2.2040  λ_max=3.1931\n",
      "[SGD | lr=0.001] Epoch 1178/4000: train_loss=2.1696  test_loss=2.2040  λ_max=3.3723\n",
      "[SGD | lr=0.001] Epoch 1179/4000: train_loss=2.1697  test_loss=2.2040  λ_max=3.2792\n",
      "[SGD | lr=0.001] Epoch 1180/4000: train_loss=2.1696  test_loss=2.2040  λ_max=3.2323\n",
      "[SGD | lr=0.001] Epoch 1181/4000: train_loss=2.1695  test_loss=2.2040  λ_max=3.4126\n",
      "[SGD | lr=0.001] Iter 18900: loss=2.1681\n",
      "[SGD | lr=0.001] Epoch 1182/4000: train_loss=2.1694  test_loss=2.2040  λ_max=3.2103\n",
      "[SGD | lr=0.001] Epoch 1183/4000: train_loss=2.1695  test_loss=2.2040  λ_max=3.2851\n",
      "[SGD | lr=0.001] Epoch 1184/4000: train_loss=2.1695  test_loss=2.2040  λ_max=3.3203\n",
      "[SGD | lr=0.001] Epoch 1185/4000: train_loss=2.1694  test_loss=2.2040  λ_max=3.2113\n",
      "[SGD | lr=0.001] Epoch 1186/4000: train_loss=2.1693  test_loss=2.2040  λ_max=3.3181\n",
      "[SGD | lr=0.001] Epoch 1187/4000: train_loss=2.1692  test_loss=2.2040  λ_max=3.3254\n",
      "[SGD | lr=0.001] Iter 19000: loss=2.1687\n",
      "[SGD | lr=0.001] Epoch 1188/4000: train_loss=2.1693  test_loss=2.2040  λ_max=3.2519\n",
      "[SGD | lr=0.001] Epoch 1189/4000: train_loss=2.1693  test_loss=2.2040  λ_max=3.4112\n",
      "[SGD | lr=0.001] Epoch 1190/4000: train_loss=2.1691  test_loss=2.2040  λ_max=3.1022\n",
      "[SGD | lr=0.001] Epoch 1191/4000: train_loss=2.1692  test_loss=2.2040  λ_max=3.1266\n",
      "[SGD | lr=0.001] Epoch 1192/4000: train_loss=2.1691  test_loss=2.2040  λ_max=3.3069\n",
      "[SGD | lr=0.001] Epoch 1193/4000: train_loss=2.1691  test_loss=2.2040  λ_max=3.3328\n",
      "[SGD | lr=0.001] Iter 19100: loss=2.1706\n",
      "[SGD | lr=0.001] Epoch 1194/4000: train_loss=2.1691  test_loss=2.2040  λ_max=3.2153\n",
      "[SGD | lr=0.001] Epoch 1195/4000: train_loss=2.1690  test_loss=2.2040  λ_max=3.2169\n",
      "[SGD | lr=0.001] Epoch 1196/4000: train_loss=2.1689  test_loss=2.2040  λ_max=3.2917\n",
      "[SGD | lr=0.001] Epoch 1197/4000: train_loss=2.1690  test_loss=2.2040  λ_max=3.2224\n",
      "[SGD | lr=0.001] Epoch 1198/4000: train_loss=2.1689  test_loss=2.2040  λ_max=3.2679\n",
      "[SGD | lr=0.001] Epoch 1199/4000: train_loss=2.1688  test_loss=2.2041  λ_max=3.4241\n",
      "[SGD | lr=0.001] Iter 19200: loss=2.1691\n",
      "[SGD | lr=0.001] Epoch 1200/4000: train_loss=2.1688  test_loss=2.2041  λ_max=3.3117\n",
      "[SGD | lr=0.001] Epoch 1201/4000: train_loss=2.1688  test_loss=2.2041  λ_max=3.0235\n",
      "[SGD | lr=0.001] Epoch 1202/4000: train_loss=2.1687  test_loss=2.2041  λ_max=3.3952\n",
      "[SGD | lr=0.001] Epoch 1203/4000: train_loss=2.1687  test_loss=2.2041  λ_max=3.3918\n",
      "[SGD | lr=0.001] Epoch 1204/4000: train_loss=2.1687  test_loss=2.2041  λ_max=3.3714\n",
      "[SGD | lr=0.001] Epoch 1205/4000: train_loss=2.1687  test_loss=2.2041  λ_max=3.3937\n",
      "[SGD | lr=0.001] Epoch 1206/4000: train_loss=2.1687  test_loss=2.2041  λ_max=3.3989\n",
      "[SGD | lr=0.001] Iter 19300: loss=2.1671\n",
      "[SGD | lr=0.001] Epoch 1207/4000: train_loss=2.1685  test_loss=2.2041  λ_max=3.2899\n",
      "[SGD | lr=0.001] Epoch 1208/4000: train_loss=2.1685  test_loss=2.2041  λ_max=3.3152\n",
      "[SGD | lr=0.001] Epoch 1209/4000: train_loss=2.1684  test_loss=2.2041  λ_max=3.2061\n",
      "[SGD | lr=0.001] Epoch 1210/4000: train_loss=2.1684  test_loss=2.2041  λ_max=3.4732\n",
      "[SGD | lr=0.001] Epoch 1211/4000: train_loss=2.1684  test_loss=2.2041  λ_max=3.2923\n",
      "[SGD | lr=0.001] Epoch 1212/4000: train_loss=2.1684  test_loss=2.2041  λ_max=3.1405\n",
      "[SGD | lr=0.001] Iter 19400: loss=2.1687\n",
      "[SGD | lr=0.001] Epoch 1213/4000: train_loss=2.1683  test_loss=2.2041  λ_max=3.3228\n",
      "[SGD | lr=0.001] Epoch 1214/4000: train_loss=2.1681  test_loss=2.2041  λ_max=3.4377\n",
      "[SGD | lr=0.001] Epoch 1215/4000: train_loss=2.1683  test_loss=2.2041  λ_max=3.4700\n",
      "[SGD | lr=0.001] Epoch 1216/4000: train_loss=2.1683  test_loss=2.2041  λ_max=3.4763\n",
      "[SGD | lr=0.001] Epoch 1217/4000: train_loss=2.1681  test_loss=2.2041  λ_max=3.3307\n",
      "[SGD | lr=0.001] Epoch 1218/4000: train_loss=2.1680  test_loss=2.2042  λ_max=3.2718\n",
      "[SGD | lr=0.001] Iter 19500: loss=2.1704\n",
      "[SGD | lr=0.001] Epoch 1219/4000: train_loss=2.1680  test_loss=2.2042  λ_max=3.4404\n",
      "[SGD | lr=0.001] Epoch 1220/4000: train_loss=2.1680  test_loss=2.2042  λ_max=3.2585\n",
      "[SGD | lr=0.001] Epoch 1221/4000: train_loss=2.1679  test_loss=2.2042  λ_max=3.2882\n",
      "[SGD | lr=0.001] Epoch 1222/4000: train_loss=2.1679  test_loss=2.2042  λ_max=3.3285\n",
      "[SGD | lr=0.001] Epoch 1223/4000: train_loss=2.1679  test_loss=2.2042  λ_max=3.3925\n",
      "[SGD | lr=0.001] Epoch 1224/4000: train_loss=2.1678  test_loss=2.2042  λ_max=3.2708\n",
      "[SGD | lr=0.001] Iter 19600: loss=2.1670\n",
      "[SGD | lr=0.001] Epoch 1225/4000: train_loss=2.1678  test_loss=2.2042  λ_max=3.4395\n",
      "[SGD | lr=0.001] Epoch 1226/4000: train_loss=2.1677  test_loss=2.2042  λ_max=3.3538\n",
      "[SGD | lr=0.001] Epoch 1227/4000: train_loss=2.1679  test_loss=2.2042  λ_max=3.3547\n",
      "[SGD | lr=0.001] Epoch 1228/4000: train_loss=2.1677  test_loss=2.2042  λ_max=3.4510\n",
      "[SGD | lr=0.001] Epoch 1229/4000: train_loss=2.1676  test_loss=2.2042  λ_max=3.4922\n",
      "[SGD | lr=0.001] Epoch 1230/4000: train_loss=2.1678  test_loss=2.2042  λ_max=3.5123\n",
      "[SGD | lr=0.001] Epoch 1231/4000: train_loss=2.1676  test_loss=2.2042  λ_max=3.4687\n",
      "[SGD | lr=0.001] Iter 19700: loss=2.1654\n",
      "[SGD | lr=0.001] Epoch 1232/4000: train_loss=2.1675  test_loss=2.2042  λ_max=3.4377\n",
      "[SGD | lr=0.001] Epoch 1233/4000: train_loss=2.1675  test_loss=2.2042  λ_max=3.5114\n",
      "[SGD | lr=0.001] Epoch 1234/4000: train_loss=2.1674  test_loss=2.2042  λ_max=3.3324\n",
      "[SGD | lr=0.001] Epoch 1235/4000: train_loss=2.1673  test_loss=2.2042  λ_max=3.3040\n",
      "[SGD | lr=0.001] Epoch 1236/4000: train_loss=2.1673  test_loss=2.2042  λ_max=3.5100\n",
      "[SGD | lr=0.001] Epoch 1237/4000: train_loss=2.1673  test_loss=2.2042  λ_max=3.3018\n",
      "[SGD | lr=0.001] Iter 19800: loss=2.1680\n",
      "[SGD | lr=0.001] Epoch 1238/4000: train_loss=2.1673  test_loss=2.2043  λ_max=3.2922\n",
      "[SGD | lr=0.001] Epoch 1239/4000: train_loss=2.1672  test_loss=2.2043  λ_max=3.5068\n",
      "[SGD | lr=0.001] Epoch 1240/4000: train_loss=2.1671  test_loss=2.2043  λ_max=3.2930\n",
      "[SGD | lr=0.001] Epoch 1241/4000: train_loss=2.1671  test_loss=2.2043  λ_max=3.4175\n",
      "[SGD | lr=0.001] Epoch 1242/4000: train_loss=2.1671  test_loss=2.2043  λ_max=3.4255\n",
      "[SGD | lr=0.001] Epoch 1243/4000: train_loss=2.1670  test_loss=2.2043  λ_max=3.3203\n",
      "[SGD | lr=0.001] Iter 19900: loss=2.1640\n",
      "[SGD | lr=0.001] Epoch 1244/4000: train_loss=2.1669  test_loss=2.2043  λ_max=3.3759\n",
      "[SGD | lr=0.001] Epoch 1245/4000: train_loss=2.1670  test_loss=2.2043  λ_max=3.5214\n",
      "[SGD | lr=0.001] Epoch 1246/4000: train_loss=2.1670  test_loss=2.2043  λ_max=3.4618\n",
      "[SGD | lr=0.001] Epoch 1247/4000: train_loss=2.1668  test_loss=2.2043  λ_max=3.2709\n",
      "[SGD | lr=0.001] Epoch 1248/4000: train_loss=2.1668  test_loss=2.2043  λ_max=3.3993\n",
      "[SGD | lr=0.001] Epoch 1249/4000: train_loss=2.1668  test_loss=2.2043  λ_max=3.3409\n",
      "[SGD | lr=0.001] Iter 20000: loss=2.1728\n",
      "[SGD | lr=0.001] Epoch 1250/4000: train_loss=2.1669  test_loss=2.2043  λ_max=3.3158\n",
      "[SGD | lr=0.001] Epoch 1251/4000: train_loss=2.1667  test_loss=2.2043  λ_max=3.3076\n",
      "[SGD | lr=0.001] Epoch 1252/4000: train_loss=2.1665  test_loss=2.2043  λ_max=3.3258\n",
      "[SGD | lr=0.001] Epoch 1253/4000: train_loss=2.1666  test_loss=2.2043  λ_max=3.5046\n",
      "[SGD | lr=0.001] Epoch 1254/4000: train_loss=2.1667  test_loss=2.2043  λ_max=3.5342\n",
      "[SGD | lr=0.001] Epoch 1255/4000: train_loss=2.1665  test_loss=2.2043  λ_max=3.3377\n",
      "[SGD | lr=0.001] Epoch 1256/4000: train_loss=2.1665  test_loss=2.2044  λ_max=3.4951\n",
      "[SGD | lr=0.001] Iter 20100: loss=2.1665\n",
      "[SGD | lr=0.001] Epoch 1257/4000: train_loss=2.1664  test_loss=2.2044  λ_max=3.5406\n",
      "[SGD | lr=0.001] Epoch 1258/4000: train_loss=2.1664  test_loss=2.2044  λ_max=3.4353\n",
      "[SGD | lr=0.001] Epoch 1259/4000: train_loss=2.1663  test_loss=2.2044  λ_max=3.4422\n",
      "[SGD | lr=0.001] Epoch 1260/4000: train_loss=2.1663  test_loss=2.2044  λ_max=3.5574\n",
      "[SGD | lr=0.001] Epoch 1261/4000: train_loss=2.1662  test_loss=2.2044  λ_max=3.4661\n",
      "[SGD | lr=0.001] Epoch 1262/4000: train_loss=2.1662  test_loss=2.2044  λ_max=3.4420\n",
      "[SGD | lr=0.001] Iter 20200: loss=2.1673\n",
      "[SGD | lr=0.001] Epoch 1263/4000: train_loss=2.1662  test_loss=2.2044  λ_max=3.4460\n",
      "[SGD | lr=0.001] Epoch 1264/4000: train_loss=2.1661  test_loss=2.2044  λ_max=3.4903\n",
      "[SGD | lr=0.001] Epoch 1265/4000: train_loss=2.1661  test_loss=2.2044  λ_max=3.3605\n",
      "[SGD | lr=0.001] Epoch 1266/4000: train_loss=2.1661  test_loss=2.2044  λ_max=3.5439\n",
      "[SGD | lr=0.001] Epoch 1267/4000: train_loss=2.1659  test_loss=2.2044  λ_max=3.3541\n",
      "[SGD | lr=0.001] Epoch 1268/4000: train_loss=2.1659  test_loss=2.2044  λ_max=3.3148\n",
      "[SGD | lr=0.001] Iter 20300: loss=2.1695\n",
      "[SGD | lr=0.001] Epoch 1269/4000: train_loss=2.1660  test_loss=2.2044  λ_max=3.5925\n",
      "[SGD | lr=0.001] Epoch 1270/4000: train_loss=2.1659  test_loss=2.2044  λ_max=3.5972\n",
      "[SGD | lr=0.001] Epoch 1271/4000: train_loss=2.1658  test_loss=2.2044  λ_max=3.4241\n",
      "[SGD | lr=0.001] Epoch 1272/4000: train_loss=2.1657  test_loss=2.2045  λ_max=3.5223\n",
      "[SGD | lr=0.001] Epoch 1273/4000: train_loss=2.1657  test_loss=2.2045  λ_max=3.5499\n",
      "[SGD | lr=0.001] Epoch 1274/4000: train_loss=2.1658  test_loss=2.2045  λ_max=3.3732\n",
      "[SGD | lr=0.001] Iter 20400: loss=2.1715\n",
      "[SGD | lr=0.001] Epoch 1275/4000: train_loss=2.1658  test_loss=2.2045  λ_max=3.6070\n",
      "[SGD | lr=0.001] Epoch 1276/4000: train_loss=2.1656  test_loss=2.2045  λ_max=3.5556\n",
      "[SGD | lr=0.001] Epoch 1277/4000: train_loss=2.1656  test_loss=2.2045  λ_max=3.5897\n",
      "[SGD | lr=0.001] Epoch 1278/4000: train_loss=2.1655  test_loss=2.2045  λ_max=3.6411\n",
      "[SGD | lr=0.001] Epoch 1279/4000: train_loss=2.1653  test_loss=2.2045  λ_max=3.4800\n",
      "[SGD | lr=0.001] Epoch 1280/4000: train_loss=2.1654  test_loss=2.2045  λ_max=3.5125\n",
      "[SGD | lr=0.001] Epoch 1281/4000: train_loss=2.1654  test_loss=2.2045  λ_max=3.3917\n",
      "[SGD | lr=0.001] Iter 20500: loss=2.1640\n",
      "[SGD | lr=0.001] Epoch 1282/4000: train_loss=2.1653  test_loss=2.2045  λ_max=3.3525\n",
      "[SGD | lr=0.001] Epoch 1283/4000: train_loss=2.1653  test_loss=2.2045  λ_max=3.4699\n",
      "[SGD | lr=0.001] Epoch 1284/4000: train_loss=2.1651  test_loss=2.2045  λ_max=3.6173\n",
      "[SGD | lr=0.001] Epoch 1285/4000: train_loss=2.1651  test_loss=2.2045  λ_max=3.4703\n",
      "[SGD | lr=0.001] Epoch 1286/4000: train_loss=2.1653  test_loss=2.2045  λ_max=3.6565\n",
      "[SGD | lr=0.001] Epoch 1287/4000: train_loss=2.1651  test_loss=2.2046  λ_max=3.6484\n",
      "[SGD | lr=0.001] Iter 20600: loss=2.1683\n",
      "[SGD | lr=0.001] Epoch 1288/4000: train_loss=2.1650  test_loss=2.2046  λ_max=3.5763\n",
      "[SGD | lr=0.001] Epoch 1289/4000: train_loss=2.1650  test_loss=2.2046  λ_max=3.6722\n",
      "[SGD | lr=0.001] Epoch 1290/4000: train_loss=2.1650  test_loss=2.2046  λ_max=3.6906\n",
      "[SGD | lr=0.001] Epoch 1291/4000: train_loss=2.1649  test_loss=2.2046  λ_max=3.5565\n",
      "[SGD | lr=0.001] Epoch 1292/4000: train_loss=2.1649  test_loss=2.2046  λ_max=3.6726\n",
      "[SGD | lr=0.001] Epoch 1293/4000: train_loss=2.1649  test_loss=2.2046  λ_max=3.3850\n",
      "[SGD | lr=0.001] Iter 20700: loss=2.1655\n",
      "[SGD | lr=0.001] Epoch 1294/4000: train_loss=2.1647  test_loss=2.2046  λ_max=3.4405\n",
      "[SGD | lr=0.001] Epoch 1295/4000: train_loss=2.1647  test_loss=2.2046  λ_max=3.5214\n",
      "[SGD | lr=0.001] Epoch 1296/4000: train_loss=2.1648  test_loss=2.2046  λ_max=3.6628\n",
      "[SGD | lr=0.001] Epoch 1297/4000: train_loss=2.1646  test_loss=2.2046  λ_max=3.5047\n",
      "[SGD | lr=0.001] Epoch 1298/4000: train_loss=2.1646  test_loss=2.2046  λ_max=3.4986\n",
      "[SGD | lr=0.001] Epoch 1299/4000: train_loss=2.1645  test_loss=2.2046  λ_max=3.5978\n",
      "[SGD | lr=0.001] Iter 20800: loss=2.1665\n",
      "[SGD | lr=0.001] Epoch 1300/4000: train_loss=2.1645  test_loss=2.2046  λ_max=3.5289\n",
      "[SGD | lr=0.001] Epoch 1301/4000: train_loss=2.1645  test_loss=2.2047  λ_max=3.4832\n",
      "[SGD | lr=0.001] Epoch 1302/4000: train_loss=2.1644  test_loss=2.2047  λ_max=3.4977\n",
      "[SGD | lr=0.001] Epoch 1303/4000: train_loss=2.1643  test_loss=2.2047  λ_max=3.7022\n",
      "[SGD | lr=0.001] Epoch 1304/4000: train_loss=2.1642  test_loss=2.2047  λ_max=3.7321\n",
      "[SGD | lr=0.001] Epoch 1305/4000: train_loss=2.1641  test_loss=2.2047  λ_max=3.5307\n",
      "[SGD | lr=0.001] Epoch 1306/4000: train_loss=2.1642  test_loss=2.2047  λ_max=3.5892\n",
      "[SGD | lr=0.001] Iter 20900: loss=2.1632\n",
      "[SGD | lr=0.001] Epoch 1307/4000: train_loss=2.1642  test_loss=2.2047  λ_max=3.7716\n",
      "[SGD | lr=0.001] Epoch 1308/4000: train_loss=2.1641  test_loss=2.2047  λ_max=3.5273\n",
      "[SGD | lr=0.001] Epoch 1309/4000: train_loss=2.1640  test_loss=2.2047  λ_max=3.7686\n",
      "[SGD | lr=0.001] Epoch 1310/4000: train_loss=2.1640  test_loss=2.2047  λ_max=3.5731\n",
      "[SGD | lr=0.001] Epoch 1311/4000: train_loss=2.1640  test_loss=2.2047  λ_max=3.7442\n",
      "[SGD | lr=0.001] Epoch 1312/4000: train_loss=2.1640  test_loss=2.2047  λ_max=3.5187\n",
      "[SGD | lr=0.001] Iter 21000: loss=2.1673\n",
      "[SGD | lr=0.001] Epoch 1313/4000: train_loss=2.1639  test_loss=2.2047  λ_max=3.7683\n",
      "[SGD | lr=0.001] Epoch 1314/4000: train_loss=2.1638  test_loss=2.2048  λ_max=3.4900\n",
      "[SGD | lr=0.001] Epoch 1315/4000: train_loss=2.1638  test_loss=2.2048  λ_max=3.4588\n",
      "[SGD | lr=0.001] Epoch 1316/4000: train_loss=2.1637  test_loss=2.2048  λ_max=3.6951\n",
      "[SGD | lr=0.001] Epoch 1317/4000: train_loss=2.1637  test_loss=2.2048  λ_max=3.6333\n",
      "[SGD | lr=0.001] Epoch 1318/4000: train_loss=2.1635  test_loss=2.2048  λ_max=3.7685\n",
      "[SGD | lr=0.001] Iter 21100: loss=2.1669\n",
      "[SGD | lr=0.001] Epoch 1319/4000: train_loss=2.1636  test_loss=2.2048  λ_max=3.6686\n",
      "[SGD | lr=0.001] Epoch 1320/4000: train_loss=2.1635  test_loss=2.2048  λ_max=3.6600\n",
      "[SGD | lr=0.001] Epoch 1321/4000: train_loss=2.1636  test_loss=2.2048  λ_max=3.5206\n",
      "[SGD | lr=0.001] Epoch 1322/4000: train_loss=2.1634  test_loss=2.2048  λ_max=3.6905\n",
      "[SGD | lr=0.001] Epoch 1323/4000: train_loss=2.1634  test_loss=2.2048  λ_max=3.5372\n",
      "[SGD | lr=0.001] Epoch 1324/4000: train_loss=2.1634  test_loss=2.2048  λ_max=3.7026\n",
      "[SGD | lr=0.001] Iter 21200: loss=2.1668\n",
      "[SGD | lr=0.001] Epoch 1325/4000: train_loss=2.1634  test_loss=2.2048  λ_max=3.6845\n",
      "[SGD | lr=0.001] Epoch 1326/4000: train_loss=2.1632  test_loss=2.2049  λ_max=3.6853\n",
      "[SGD | lr=0.001] Epoch 1327/4000: train_loss=2.1631  test_loss=2.2049  λ_max=3.7168\n",
      "[SGD | lr=0.001] Epoch 1328/4000: train_loss=2.1630  test_loss=2.2049  λ_max=3.5430\n",
      "[SGD | lr=0.001] Epoch 1329/4000: train_loss=2.1630  test_loss=2.2049  λ_max=3.5272\n",
      "[SGD | lr=0.001] Epoch 1330/4000: train_loss=2.1632  test_loss=2.2049  λ_max=3.5648\n",
      "[SGD | lr=0.001] Epoch 1331/4000: train_loss=2.1631  test_loss=2.2049  λ_max=3.6804\n",
      "[SGD | lr=0.001] Iter 21300: loss=2.1623\n",
      "[SGD | lr=0.001] Epoch 1332/4000: train_loss=2.1629  test_loss=2.2049  λ_max=3.6817\n",
      "[SGD | lr=0.001] Epoch 1333/4000: train_loss=2.1629  test_loss=2.2049  λ_max=3.6494\n",
      "[SGD | lr=0.001] Epoch 1334/4000: train_loss=2.1627  test_loss=2.2049  λ_max=3.7126\n",
      "[SGD | lr=0.001] Epoch 1335/4000: train_loss=2.1628  test_loss=2.2049  λ_max=3.7607\n",
      "[SGD | lr=0.001] Epoch 1336/4000: train_loss=2.1628  test_loss=2.2050  λ_max=3.6911\n",
      "[SGD | lr=0.001] Epoch 1337/4000: train_loss=2.1627  test_loss=2.2050  λ_max=3.6831\n",
      "[SGD | lr=0.001] Iter 21400: loss=2.1619\n",
      "[SGD | lr=0.001] Epoch 1338/4000: train_loss=2.1627  test_loss=2.2050  λ_max=3.5652\n",
      "[SGD | lr=0.001] Epoch 1339/4000: train_loss=2.1626  test_loss=2.2050  λ_max=3.5481\n",
      "[SGD | lr=0.001] Epoch 1340/4000: train_loss=2.1625  test_loss=2.2050  λ_max=3.7435\n",
      "[SGD | lr=0.001] Epoch 1341/4000: train_loss=2.1623  test_loss=2.2050  λ_max=3.8957\n",
      "[SGD | lr=0.001] Epoch 1342/4000: train_loss=2.1624  test_loss=2.2050  λ_max=3.7750\n",
      "[SGD | lr=0.001] Epoch 1343/4000: train_loss=2.1625  test_loss=2.2050  λ_max=3.8206\n",
      "[SGD | lr=0.001] Iter 21500: loss=2.1652\n",
      "[SGD | lr=0.001] Epoch 1344/4000: train_loss=2.1622  test_loss=2.2050  λ_max=3.7264\n",
      "[SGD | lr=0.001] Epoch 1345/4000: train_loss=2.1623  test_loss=2.2050  λ_max=3.7995\n",
      "[SGD | lr=0.001] Epoch 1346/4000: train_loss=2.1623  test_loss=2.2050  λ_max=3.5945\n",
      "[SGD | lr=0.001] Epoch 1347/4000: train_loss=2.1621  test_loss=2.2050  λ_max=3.6855\n",
      "[SGD | lr=0.001] Epoch 1348/4000: train_loss=2.1621  test_loss=2.2051  λ_max=3.8827\n",
      "[SGD | lr=0.001] Epoch 1349/4000: train_loss=2.1621  test_loss=2.2051  λ_max=3.8073\n",
      "[SGD | lr=0.001] Iter 21600: loss=2.1650\n",
      "[SGD | lr=0.001] Epoch 1350/4000: train_loss=2.1621  test_loss=2.2051  λ_max=3.8814\n",
      "[SGD | lr=0.001] Epoch 1351/4000: train_loss=2.1620  test_loss=2.2051  λ_max=3.5426\n",
      "[SGD | lr=0.001] Epoch 1352/4000: train_loss=2.1619  test_loss=2.2051  λ_max=3.8027\n",
      "[SGD | lr=0.001] Epoch 1353/4000: train_loss=2.1618  test_loss=2.2051  λ_max=3.8117\n",
      "[SGD | lr=0.001] Epoch 1354/4000: train_loss=2.1619  test_loss=2.2051  λ_max=3.6789\n",
      "[SGD | lr=0.001] Epoch 1355/4000: train_loss=2.1618  test_loss=2.2051  λ_max=3.5625\n",
      "[SGD | lr=0.001] Epoch 1356/4000: train_loss=2.1616  test_loss=2.2051  λ_max=3.7808\n",
      "[SGD | lr=0.001] Iter 21700: loss=2.1622\n",
      "[SGD | lr=0.001] Epoch 1357/4000: train_loss=2.1617  test_loss=2.2051  λ_max=3.6750\n",
      "[SGD | lr=0.001] Epoch 1358/4000: train_loss=2.1616  test_loss=2.2051  λ_max=3.8459\n",
      "[SGD | lr=0.001] Epoch 1359/4000: train_loss=2.1617  test_loss=2.2052  λ_max=3.7739\n",
      "[SGD | lr=0.001] Epoch 1360/4000: train_loss=2.1615  test_loss=2.2052  λ_max=3.6432\n",
      "[SGD | lr=0.001] Epoch 1361/4000: train_loss=2.1616  test_loss=2.2052  λ_max=3.7177\n",
      "[SGD | lr=0.001] Epoch 1362/4000: train_loss=2.1615  test_loss=2.2052  λ_max=3.8516\n",
      "[SGD | lr=0.001] Iter 21800: loss=2.1625\n",
      "[SGD | lr=0.001] Epoch 1363/4000: train_loss=2.1613  test_loss=2.2052  λ_max=3.8576\n",
      "[SGD | lr=0.001] Epoch 1364/4000: train_loss=2.1613  test_loss=2.2052  λ_max=3.6645\n",
      "[SGD | lr=0.001] Epoch 1365/4000: train_loss=2.1613  test_loss=2.2052  λ_max=3.8467\n",
      "[SGD | lr=0.001] Epoch 1366/4000: train_loss=2.1613  test_loss=2.2052  λ_max=3.6724\n",
      "[SGD | lr=0.001] Epoch 1367/4000: train_loss=2.1611  test_loss=2.2052  λ_max=3.9079\n",
      "[SGD | lr=0.001] Epoch 1368/4000: train_loss=2.1613  test_loss=2.2052  λ_max=3.7421\n",
      "[SGD | lr=0.001] Iter 21900: loss=2.1604\n",
      "[SGD | lr=0.001] Epoch 1369/4000: train_loss=2.1611  test_loss=2.2053  λ_max=3.9082\n",
      "[SGD | lr=0.001] Epoch 1370/4000: train_loss=2.1610  test_loss=2.2053  λ_max=3.9058\n",
      "[SGD | lr=0.001] Epoch 1371/4000: train_loss=2.1609  test_loss=2.2053  λ_max=3.6430\n",
      "[SGD | lr=0.001] Epoch 1372/4000: train_loss=2.1609  test_loss=2.2053  λ_max=3.6089\n",
      "[SGD | lr=0.001] Epoch 1373/4000: train_loss=2.1608  test_loss=2.2053  λ_max=3.8997\n",
      "[SGD | lr=0.001] Epoch 1374/4000: train_loss=2.1607  test_loss=2.2053  λ_max=3.9326\n",
      "[SGD | lr=0.001] Iter 22000: loss=2.1618\n",
      "[SGD | lr=0.001] Epoch 1375/4000: train_loss=2.1608  test_loss=2.2053  λ_max=3.8595\n",
      "[SGD | lr=0.001] Epoch 1376/4000: train_loss=2.1608  test_loss=2.2053  λ_max=3.8710\n",
      "[SGD | lr=0.001] Epoch 1377/4000: train_loss=2.1607  test_loss=2.2053  λ_max=3.9282\n",
      "[SGD | lr=0.001] Epoch 1378/4000: train_loss=2.1606  test_loss=2.2054  λ_max=3.9061\n",
      "[SGD | lr=0.001] Epoch 1379/4000: train_loss=2.1606  test_loss=2.2054  λ_max=3.7896\n",
      "[SGD | lr=0.001] Epoch 1380/4000: train_loss=2.1606  test_loss=2.2054  λ_max=3.9630\n",
      "[SGD | lr=0.001] Epoch 1381/4000: train_loss=2.1603  test_loss=2.2054  λ_max=3.7933\n",
      "[SGD | lr=0.001] Iter 22100: loss=2.1602\n",
      "[SGD | lr=0.001] Epoch 1382/4000: train_loss=2.1603  test_loss=2.2054  λ_max=3.7657\n",
      "[SGD | lr=0.001] Epoch 1383/4000: train_loss=2.1604  test_loss=2.2054  λ_max=3.9271\n",
      "[SGD | lr=0.001] Epoch 1384/4000: train_loss=2.1603  test_loss=2.2054  λ_max=3.9481\n",
      "[SGD | lr=0.001] Epoch 1385/4000: train_loss=2.1603  test_loss=2.2054  λ_max=3.9993\n",
      "[SGD | lr=0.001] Epoch 1386/4000: train_loss=2.1602  test_loss=2.2054  λ_max=3.7303\n",
      "[SGD | lr=0.001] Epoch 1387/4000: train_loss=2.1602  test_loss=2.2054  λ_max=3.9867\n",
      "[SGD | lr=0.001] Iter 22200: loss=2.1595\n",
      "[SGD | lr=0.001] Epoch 1388/4000: train_loss=2.1601  test_loss=2.2055  λ_max=3.9400\n",
      "[SGD | lr=0.001] Epoch 1389/4000: train_loss=2.1600  test_loss=2.2055  λ_max=3.6145\n",
      "[SGD | lr=0.001] Epoch 1390/4000: train_loss=2.1599  test_loss=2.2055  λ_max=3.7441\n",
      "[SGD | lr=0.001] Epoch 1391/4000: train_loss=2.1599  test_loss=2.2055  λ_max=4.0480\n",
      "[SGD | lr=0.001] Epoch 1392/4000: train_loss=2.1598  test_loss=2.2055  λ_max=3.7920\n",
      "[SGD | lr=0.001] Epoch 1393/4000: train_loss=2.1598  test_loss=2.2055  λ_max=3.9190\n",
      "[SGD | lr=0.001] Iter 22300: loss=2.1623\n",
      "[SGD | lr=0.001] Epoch 1394/4000: train_loss=2.1597  test_loss=2.2055  λ_max=3.9964\n",
      "[SGD | lr=0.001] Epoch 1395/4000: train_loss=2.1597  test_loss=2.2055  λ_max=4.0439\n",
      "[SGD | lr=0.001] Epoch 1396/4000: train_loss=2.1595  test_loss=2.2055  λ_max=3.7627\n",
      "[SGD | lr=0.001] Epoch 1397/4000: train_loss=2.1596  test_loss=2.2056  λ_max=3.9961\n",
      "[SGD | lr=0.001] Epoch 1398/4000: train_loss=2.1594  test_loss=2.2056  λ_max=3.7126\n",
      "[SGD | lr=0.001] Epoch 1399/4000: train_loss=2.1594  test_loss=2.2056  λ_max=3.8820\n",
      "[SGD | lr=0.001] Iter 22400: loss=2.1606\n",
      "[SGD | lr=0.001] Epoch 1400/4000: train_loss=2.1594  test_loss=2.2056  λ_max=3.7976\n",
      "[SGD | lr=0.001] Epoch 1401/4000: train_loss=2.1594  test_loss=2.2056  λ_max=4.0330\n",
      "[SGD | lr=0.001] Epoch 1402/4000: train_loss=2.1593  test_loss=2.2056  λ_max=3.9444\n",
      "[SGD | lr=0.001] Epoch 1403/4000: train_loss=2.1592  test_loss=2.2056  λ_max=3.9585\n",
      "[SGD | lr=0.001] Epoch 1404/4000: train_loss=2.1592  test_loss=2.2056  λ_max=3.9549\n",
      "[SGD | lr=0.001] Epoch 1405/4000: train_loss=2.1591  test_loss=2.2057  λ_max=3.9057\n",
      "[SGD | lr=0.001] Epoch 1406/4000: train_loss=2.1589  test_loss=2.2057  λ_max=4.0121\n",
      "[SGD | lr=0.001] Iter 22500: loss=2.1579\n",
      "[SGD | lr=0.001] Epoch 1407/4000: train_loss=2.1590  test_loss=2.2057  λ_max=4.0199\n",
      "[SGD | lr=0.001] Epoch 1408/4000: train_loss=2.1590  test_loss=2.2057  λ_max=3.9442\n",
      "[SGD | lr=0.001] Epoch 1409/4000: train_loss=2.1589  test_loss=2.2057  λ_max=4.0838\n",
      "[SGD | lr=0.001] Epoch 1410/4000: train_loss=2.1589  test_loss=2.2057  λ_max=4.0709\n",
      "[SGD | lr=0.001] Epoch 1411/4000: train_loss=2.1587  test_loss=2.2057  λ_max=4.0567\n",
      "[SGD | lr=0.001] Epoch 1412/4000: train_loss=2.1588  test_loss=2.2057  λ_max=3.8348\n",
      "[SGD | lr=0.001] Iter 22600: loss=2.1595\n",
      "[SGD | lr=0.001] Epoch 1413/4000: train_loss=2.1586  test_loss=2.2057  λ_max=3.9265\n",
      "[SGD | lr=0.001] Epoch 1414/4000: train_loss=2.1585  test_loss=2.2058  λ_max=3.7257\n",
      "[SGD | lr=0.001] Epoch 1415/4000: train_loss=2.1585  test_loss=2.2058  λ_max=3.9472\n",
      "[SGD | lr=0.001] Epoch 1416/4000: train_loss=2.1585  test_loss=2.2058  λ_max=4.0057\n",
      "[SGD | lr=0.001] Epoch 1417/4000: train_loss=2.1584  test_loss=2.2058  λ_max=3.9172\n",
      "[SGD | lr=0.001] Epoch 1418/4000: train_loss=2.1584  test_loss=2.2058  λ_max=3.9331\n",
      "[SGD | lr=0.001] Iter 22700: loss=2.1579\n",
      "[SGD | lr=0.001] Epoch 1419/4000: train_loss=2.1583  test_loss=2.2058  λ_max=3.9758\n",
      "[SGD | lr=0.001] Epoch 1420/4000: train_loss=2.1583  test_loss=2.2058  λ_max=4.1040\n",
      "[SGD | lr=0.001] Epoch 1421/4000: train_loss=2.1582  test_loss=2.2058  λ_max=4.1803\n",
      "[SGD | lr=0.001] Epoch 1422/4000: train_loss=2.1581  test_loss=2.2059  λ_max=4.1013\n",
      "[SGD | lr=0.001] Epoch 1423/4000: train_loss=2.1579  test_loss=2.2059  λ_max=4.0901\n",
      "[SGD | lr=0.001] Epoch 1424/4000: train_loss=2.1581  test_loss=2.2059  λ_max=3.9423\n",
      "[SGD | lr=0.001] Iter 22800: loss=2.1563\n",
      "[SGD | lr=0.001] Epoch 1425/4000: train_loss=2.1579  test_loss=2.2059  λ_max=4.1217\n",
      "[SGD | lr=0.001] Epoch 1426/4000: train_loss=2.1580  test_loss=2.2059  λ_max=4.0298\n",
      "[SGD | lr=0.001] Epoch 1427/4000: train_loss=2.1578  test_loss=2.2059  λ_max=4.1025\n",
      "[SGD | lr=0.001] Epoch 1428/4000: train_loss=2.1578  test_loss=2.2059  λ_max=3.9564\n",
      "[SGD | lr=0.001] Epoch 1429/4000: train_loss=2.1577  test_loss=2.2059  λ_max=4.0936\n",
      "[SGD | lr=0.001] Epoch 1430/4000: train_loss=2.1576  test_loss=2.2060  λ_max=3.8795\n",
      "[SGD | lr=0.001] Epoch 1431/4000: train_loss=2.1577  test_loss=2.2060  λ_max=3.8877\n",
      "[SGD | lr=0.001] Iter 22900: loss=2.1598\n",
      "[SGD | lr=0.001] Epoch 1432/4000: train_loss=2.1575  test_loss=2.2060  λ_max=4.1613\n",
      "[SGD | lr=0.001] Epoch 1433/4000: train_loss=2.1575  test_loss=2.2060  λ_max=3.9548\n",
      "[SGD | lr=0.001] Epoch 1434/4000: train_loss=2.1575  test_loss=2.2060  λ_max=4.2175\n",
      "[SGD | lr=0.001] Epoch 1435/4000: train_loss=2.1574  test_loss=2.2060  λ_max=3.8685\n",
      "[SGD | lr=0.001] Epoch 1436/4000: train_loss=2.1573  test_loss=2.2060  λ_max=4.0080\n",
      "[SGD | lr=0.001] Epoch 1437/4000: train_loss=2.1573  test_loss=2.2061  λ_max=4.1528\n",
      "[SGD | lr=0.001] Iter 23000: loss=2.1601\n",
      "[SGD | lr=0.001] Epoch 1438/4000: train_loss=2.1573  test_loss=2.2061  λ_max=3.8942\n",
      "[SGD | lr=0.001] Epoch 1439/4000: train_loss=2.1572  test_loss=2.2061  λ_max=4.2208\n",
      "[SGD | lr=0.001] Epoch 1440/4000: train_loss=2.1572  test_loss=2.2061  λ_max=4.0317\n",
      "[SGD | lr=0.001] Epoch 1441/4000: train_loss=2.1571  test_loss=2.2061  λ_max=4.1905\n",
      "[SGD | lr=0.001] Epoch 1442/4000: train_loss=2.1570  test_loss=2.2061  λ_max=3.9200\n",
      "[SGD | lr=0.001] Epoch 1443/4000: train_loss=2.1570  test_loss=2.2061  λ_max=4.1201\n",
      "[SGD | lr=0.001] Iter 23100: loss=2.1576\n",
      "[SGD | lr=0.001] Epoch 1444/4000: train_loss=2.1568  test_loss=2.2062  λ_max=3.9600\n",
      "[SGD | lr=0.001] Epoch 1445/4000: train_loss=2.1567  test_loss=2.2062  λ_max=4.1779\n",
      "[SGD | lr=0.001] Epoch 1446/4000: train_loss=2.1567  test_loss=2.2062  λ_max=4.1485\n",
      "[SGD | lr=0.001] Epoch 1447/4000: train_loss=2.1568  test_loss=2.2062  λ_max=4.0904\n",
      "[SGD | lr=0.001] Epoch 1448/4000: train_loss=2.1566  test_loss=2.2062  λ_max=3.9199\n",
      "[SGD | lr=0.001] Epoch 1449/4000: train_loss=2.1566  test_loss=2.2062  λ_max=4.0746\n",
      "[SGD | lr=0.001] Iter 23200: loss=2.1548\n",
      "[SGD | lr=0.001] Epoch 1450/4000: train_loss=2.1565  test_loss=2.2062  λ_max=3.8887\n",
      "[SGD | lr=0.001] Epoch 1451/4000: train_loss=2.1564  test_loss=2.2062  λ_max=4.1083\n",
      "[SGD | lr=0.001] Epoch 1452/4000: train_loss=2.1563  test_loss=2.2063  λ_max=4.0010\n",
      "[SGD | lr=0.001] Epoch 1453/4000: train_loss=2.1563  test_loss=2.2063  λ_max=4.0644\n",
      "[SGD | lr=0.001] Epoch 1454/4000: train_loss=2.1563  test_loss=2.2063  λ_max=4.1485\n",
      "[SGD | lr=0.001] Epoch 1455/4000: train_loss=2.1562  test_loss=2.2063  λ_max=4.1378\n",
      "[SGD | lr=0.001] Epoch 1456/4000: train_loss=2.1561  test_loss=2.2063  λ_max=4.1511\n",
      "[SGD | lr=0.001] Iter 23300: loss=2.1519\n",
      "[SGD | lr=0.001] Epoch 1457/4000: train_loss=2.1561  test_loss=2.2063  λ_max=4.3228\n",
      "[SGD | lr=0.001] Epoch 1458/4000: train_loss=2.1561  test_loss=2.2063  λ_max=4.0941\n",
      "[SGD | lr=0.001] Epoch 1459/4000: train_loss=2.1559  test_loss=2.2063  λ_max=4.0965\n",
      "[SGD | lr=0.001] Epoch 1460/4000: train_loss=2.1558  test_loss=2.2064  λ_max=4.2976\n",
      "[SGD | lr=0.001] Epoch 1461/4000: train_loss=2.1558  test_loss=2.2064  λ_max=4.0462\n",
      "[SGD | lr=0.001] Epoch 1462/4000: train_loss=2.1558  test_loss=2.2064  λ_max=4.1073\n",
      "[SGD | lr=0.001] Iter 23400: loss=2.1553\n",
      "[SGD | lr=0.001] Epoch 1463/4000: train_loss=2.1557  test_loss=2.2064  λ_max=4.2044\n",
      "[SGD | lr=0.001] Epoch 1464/4000: train_loss=2.1557  test_loss=2.2064  λ_max=4.1834\n",
      "[SGD | lr=0.001] Epoch 1465/4000: train_loss=2.1557  test_loss=2.2064  λ_max=4.3423\n",
      "[SGD | lr=0.001] Epoch 1466/4000: train_loss=2.1555  test_loss=2.2064  λ_max=4.1489\n",
      "[SGD | lr=0.001] Epoch 1467/4000: train_loss=2.1555  test_loss=2.2065  λ_max=4.2143\n",
      "[SGD | lr=0.001] Epoch 1468/4000: train_loss=2.1554  test_loss=2.2065  λ_max=4.1841\n",
      "[SGD | lr=0.001] Iter 23500: loss=2.1537\n",
      "[SGD | lr=0.001] Epoch 1469/4000: train_loss=2.1554  test_loss=2.2065  λ_max=4.1633\n",
      "[SGD | lr=0.001] Epoch 1470/4000: train_loss=2.1554  test_loss=2.2065  λ_max=4.2251\n",
      "[SGD | lr=0.001] Epoch 1471/4000: train_loss=2.1552  test_loss=2.2065  λ_max=4.2716\n",
      "[SGD | lr=0.001] Epoch 1472/4000: train_loss=2.1552  test_loss=2.2065  λ_max=4.1306\n",
      "[SGD | lr=0.001] Epoch 1473/4000: train_loss=2.1550  test_loss=2.2065  λ_max=4.1778\n",
      "[SGD | lr=0.001] Epoch 1474/4000: train_loss=2.1549  test_loss=2.2066  λ_max=4.1538\n",
      "[SGD | lr=0.001] Iter 23600: loss=2.1557\n",
      "[SGD | lr=0.001] Epoch 1475/4000: train_loss=2.1550  test_loss=2.2066  λ_max=4.2702\n",
      "[SGD | lr=0.001] Epoch 1476/4000: train_loss=2.1549  test_loss=2.2066  λ_max=3.9967\n",
      "[SGD | lr=0.001] Epoch 1477/4000: train_loss=2.1549  test_loss=2.2066  λ_max=4.2335\n",
      "[SGD | lr=0.001] Epoch 1478/4000: train_loss=2.1548  test_loss=2.2066  λ_max=4.3971\n",
      "[SGD | lr=0.001] Epoch 1479/4000: train_loss=2.1547  test_loss=2.2066  λ_max=4.2172\n",
      "[SGD | lr=0.001] Epoch 1480/4000: train_loss=2.1546  test_loss=2.2066  λ_max=4.2055\n",
      "[SGD | lr=0.001] Epoch 1481/4000: train_loss=2.1545  test_loss=2.2067  λ_max=4.3935\n",
      "[SGD | lr=0.001] Iter 23700: loss=2.1574\n",
      "[SGD | lr=0.001] Epoch 1482/4000: train_loss=2.1546  test_loss=2.2067  λ_max=4.2756\n",
      "[SGD | lr=0.001] Epoch 1483/4000: train_loss=2.1544  test_loss=2.2067  λ_max=4.2646\n",
      "[SGD | lr=0.001] Epoch 1484/4000: train_loss=2.1543  test_loss=2.2067  λ_max=4.3500\n",
      "[SGD | lr=0.001] Epoch 1485/4000: train_loss=2.1544  test_loss=2.2067  λ_max=4.2655\n",
      "[SGD | lr=0.001] Epoch 1486/4000: train_loss=2.1541  test_loss=2.2067  λ_max=4.3809\n",
      "[SGD | lr=0.001] Epoch 1487/4000: train_loss=2.1542  test_loss=2.2067  λ_max=4.3985\n",
      "[SGD | lr=0.001] Iter 23800: loss=2.1536\n",
      "[SGD | lr=0.001] Epoch 1488/4000: train_loss=2.1543  test_loss=2.2068  λ_max=4.2485\n",
      "[SGD | lr=0.001] Epoch 1489/4000: train_loss=2.1542  test_loss=2.2068  λ_max=4.2302\n",
      "[SGD | lr=0.001] Epoch 1490/4000: train_loss=2.1541  test_loss=2.2068  λ_max=4.1862\n",
      "[SGD | lr=0.001] Epoch 1491/4000: train_loss=2.1540  test_loss=2.2068  λ_max=4.3105\n",
      "[SGD | lr=0.001] Epoch 1492/4000: train_loss=2.1539  test_loss=2.2068  λ_max=4.2846\n",
      "[SGD | lr=0.001] Epoch 1493/4000: train_loss=2.1538  test_loss=2.2068  λ_max=4.4148\n",
      "[SGD | lr=0.001] Iter 23900: loss=2.1518\n",
      "[SGD | lr=0.001] Epoch 1494/4000: train_loss=2.1539  test_loss=2.2069  λ_max=4.0643\n",
      "[SGD | lr=0.001] Epoch 1495/4000: train_loss=2.1537  test_loss=2.2069  λ_max=4.2360\n",
      "[SGD | lr=0.001] Epoch 1496/4000: train_loss=2.1537  test_loss=2.2069  λ_max=4.3480\n",
      "[SGD | lr=0.001] Epoch 1497/4000: train_loss=2.1536  test_loss=2.2069  λ_max=4.4211\n",
      "[SGD | lr=0.001] Epoch 1498/4000: train_loss=2.1536  test_loss=2.2069  λ_max=4.4427\n",
      "[SGD | lr=0.001] Epoch 1499/4000: train_loss=2.1534  test_loss=2.2069  λ_max=4.4160\n",
      "[SGD | lr=0.001] Iter 24000: loss=2.1561\n",
      "[SGD | lr=0.001] Epoch 1500/4000: train_loss=2.1535  test_loss=2.2070  λ_max=4.1701\n",
      "[SGD | lr=0.001] Epoch 1501/4000: train_loss=2.1534  test_loss=2.2070  λ_max=4.4461\n",
      "[SGD | lr=0.001] Epoch 1502/4000: train_loss=2.1532  test_loss=2.2070  λ_max=4.3171\n",
      "[SGD | lr=0.001] Epoch 1503/4000: train_loss=2.1531  test_loss=2.2070  λ_max=4.3823\n",
      "[SGD | lr=0.001] Epoch 1504/4000: train_loss=2.1532  test_loss=2.2070  λ_max=4.0848\n",
      "[SGD | lr=0.001] Epoch 1505/4000: train_loss=2.1530  test_loss=2.2070  λ_max=4.5190\n",
      "[SGD | lr=0.001] Epoch 1506/4000: train_loss=2.1530  test_loss=2.2070  λ_max=4.3570\n",
      "[SGD | lr=0.001] Iter 24100: loss=2.1540\n",
      "[SGD | lr=0.001] Epoch 1507/4000: train_loss=2.1529  test_loss=2.2071  λ_max=4.1995\n",
      "[SGD | lr=0.001] Epoch 1508/4000: train_loss=2.1530  test_loss=2.2071  λ_max=4.4703\n",
      "[SGD | lr=0.001] Epoch 1509/4000: train_loss=2.1528  test_loss=2.2071  λ_max=4.2577\n",
      "[SGD | lr=0.001] Epoch 1510/4000: train_loss=2.1526  test_loss=2.2071  λ_max=4.2467\n",
      "[SGD | lr=0.001] Epoch 1511/4000: train_loss=2.1526  test_loss=2.2071  λ_max=4.5007\n",
      "[SGD | lr=0.001] Epoch 1512/4000: train_loss=2.1526  test_loss=2.2071  λ_max=4.2870\n",
      "[SGD | lr=0.001] Iter 24200: loss=2.1570\n",
      "[SGD | lr=0.001] Epoch 1513/4000: train_loss=2.1526  test_loss=2.2071  λ_max=4.5358\n",
      "[SGD | lr=0.001] Epoch 1514/4000: train_loss=2.1526  test_loss=2.2072  λ_max=4.3508\n",
      "[SGD | lr=0.001] Epoch 1515/4000: train_loss=2.1524  test_loss=2.2072  λ_max=4.4391\n",
      "[SGD | lr=0.001] Epoch 1516/4000: train_loss=2.1524  test_loss=2.2072  λ_max=4.3992\n",
      "[SGD | lr=0.001] Epoch 1517/4000: train_loss=2.1522  test_loss=2.2072  λ_max=4.3086\n",
      "[SGD | lr=0.001] Epoch 1518/4000: train_loss=2.1522  test_loss=2.2072  λ_max=4.5814\n",
      "[SGD | lr=0.001] Iter 24300: loss=2.1521\n",
      "[SGD | lr=0.001] Epoch 1519/4000: train_loss=2.1521  test_loss=2.2073  λ_max=4.4263\n",
      "[SGD | lr=0.001] Epoch 1520/4000: train_loss=2.1522  test_loss=2.2073  λ_max=4.5467\n",
      "[SGD | lr=0.001] Epoch 1521/4000: train_loss=2.1519  test_loss=2.2073  λ_max=4.5122\n",
      "[SGD | lr=0.001] Epoch 1522/4000: train_loss=2.1520  test_loss=2.2073  λ_max=4.5377\n",
      "[SGD | lr=0.001] Epoch 1523/4000: train_loss=2.1519  test_loss=2.2073  λ_max=4.4347\n",
      "[SGD | lr=0.001] Epoch 1524/4000: train_loss=2.1518  test_loss=2.2073  λ_max=4.3430\n",
      "[SGD | lr=0.001] Iter 24400: loss=2.1517\n",
      "[SGD | lr=0.001] Epoch 1525/4000: train_loss=2.1517  test_loss=2.2073  λ_max=4.5593\n",
      "[SGD | lr=0.001] Epoch 1526/4000: train_loss=2.1517  test_loss=2.2074  λ_max=4.4492\n",
      "[SGD | lr=0.001] Epoch 1527/4000: train_loss=2.1515  test_loss=2.2074  λ_max=4.4224\n",
      "[SGD | lr=0.001] Epoch 1528/4000: train_loss=2.1515  test_loss=2.2074  λ_max=4.5499\n",
      "[SGD | lr=0.001] Epoch 1529/4000: train_loss=2.1515  test_loss=2.2074  λ_max=4.4236\n",
      "[SGD | lr=0.001] Epoch 1530/4000: train_loss=2.1514  test_loss=2.2074  λ_max=4.4778\n",
      "[SGD | lr=0.001] Epoch 1531/4000: train_loss=2.1513  test_loss=2.2074  λ_max=4.4763\n",
      "[SGD | lr=0.001] Iter 24500: loss=2.1527\n",
      "[SGD | lr=0.001] Epoch 1532/4000: train_loss=2.1513  test_loss=2.2075  λ_max=4.6274\n",
      "[SGD | lr=0.001] Epoch 1533/4000: train_loss=2.1513  test_loss=2.2075  λ_max=4.6204\n",
      "[SGD | lr=0.001] Epoch 1534/4000: train_loss=2.1512  test_loss=2.2075  λ_max=4.6473\n",
      "[SGD | lr=0.001] Epoch 1535/4000: train_loss=2.1511  test_loss=2.2075  λ_max=4.3098\n",
      "[SGD | lr=0.001] Epoch 1536/4000: train_loss=2.1511  test_loss=2.2075  λ_max=4.2344\n",
      "[SGD | lr=0.001] Epoch 1537/4000: train_loss=2.1509  test_loss=2.2076  λ_max=4.5319\n",
      "[SGD | lr=0.001] Iter 24600: loss=2.1474\n",
      "[SGD | lr=0.001] Epoch 1538/4000: train_loss=2.1509  test_loss=2.2076  λ_max=4.5727\n",
      "[SGD | lr=0.001] Epoch 1539/4000: train_loss=2.1508  test_loss=2.2076  λ_max=4.4542\n",
      "[SGD | lr=0.001] Epoch 1540/4000: train_loss=2.1507  test_loss=2.2076  λ_max=4.3777\n",
      "[SGD | lr=0.001] Epoch 1541/4000: train_loss=2.1506  test_loss=2.2076  λ_max=4.5117\n",
      "[SGD | lr=0.001] Epoch 1542/4000: train_loss=2.1506  test_loss=2.2076  λ_max=4.4325\n",
      "[SGD | lr=0.001] Epoch 1543/4000: train_loss=2.1504  test_loss=2.2077  λ_max=4.4214\n",
      "[SGD | lr=0.001] Iter 24700: loss=2.1509\n",
      "[SGD | lr=0.001] Epoch 1544/4000: train_loss=2.1504  test_loss=2.2077  λ_max=4.4405\n",
      "[SGD | lr=0.001] Epoch 1545/4000: train_loss=2.1502  test_loss=2.2077  λ_max=4.6573\n",
      "[SGD | lr=0.001] Epoch 1546/4000: train_loss=2.1502  test_loss=2.2077  λ_max=4.6731\n",
      "[SGD | lr=0.001] Epoch 1547/4000: train_loss=2.1502  test_loss=2.2077  λ_max=4.2572\n",
      "[SGD | lr=0.001] Epoch 1548/4000: train_loss=2.1500  test_loss=2.2077  λ_max=4.4254\n",
      "[SGD | lr=0.001] Epoch 1549/4000: train_loss=2.1501  test_loss=2.2078  λ_max=4.4958\n",
      "[SGD | lr=0.001] Iter 24800: loss=2.1471\n",
      "[SGD | lr=0.001] Epoch 1550/4000: train_loss=2.1500  test_loss=2.2078  λ_max=4.4349\n",
      "[SGD | lr=0.001] Epoch 1551/4000: train_loss=2.1499  test_loss=2.2078  λ_max=4.7620\n",
      "[SGD | lr=0.001] Epoch 1552/4000: train_loss=2.1498  test_loss=2.2078  λ_max=4.3107\n",
      "[SGD | lr=0.001] Epoch 1553/4000: train_loss=2.1498  test_loss=2.2078  λ_max=4.6867\n",
      "[SGD | lr=0.001] Epoch 1554/4000: train_loss=2.1497  test_loss=2.2079  λ_max=4.5983\n",
      "[SGD | lr=0.001] Epoch 1555/4000: train_loss=2.1497  test_loss=2.2079  λ_max=4.6846\n",
      "[SGD | lr=0.001] Epoch 1556/4000: train_loss=2.1496  test_loss=2.2079  λ_max=4.7394\n",
      "[SGD | lr=0.001] Iter 24900: loss=2.1483\n",
      "[SGD | lr=0.001] Epoch 1557/4000: train_loss=2.1494  test_loss=2.2079  λ_max=4.7561\n",
      "[SGD | lr=0.001] Epoch 1558/4000: train_loss=2.1494  test_loss=2.2079  λ_max=4.4681\n",
      "[SGD | lr=0.001] Epoch 1559/4000: train_loss=2.1495  test_loss=2.2079  λ_max=4.7175\n",
      "[SGD | lr=0.001] Epoch 1560/4000: train_loss=2.1494  test_loss=2.2080  λ_max=4.3718\n",
      "[SGD | lr=0.001] Epoch 1561/4000: train_loss=2.1493  test_loss=2.2080  λ_max=4.5024\n",
      "[SGD | lr=0.001] Epoch 1562/4000: train_loss=2.1493  test_loss=2.2080  λ_max=4.6503\n",
      "[SGD | lr=0.001] Iter 25000: loss=2.1512\n",
      "[SGD | lr=0.001] Epoch 1563/4000: train_loss=2.1490  test_loss=2.2080  λ_max=4.6030\n",
      "[SGD | lr=0.001] Epoch 1564/4000: train_loss=2.1490  test_loss=2.2080  λ_max=4.5733\n",
      "[SGD | lr=0.001] Epoch 1565/4000: train_loss=2.1489  test_loss=2.2080  λ_max=4.7659\n",
      "[SGD | lr=0.001] Epoch 1566/4000: train_loss=2.1489  test_loss=2.2081  λ_max=4.6865\n",
      "[SGD | lr=0.001] Epoch 1567/4000: train_loss=2.1489  test_loss=2.2081  λ_max=4.6806\n",
      "[SGD | lr=0.001] Epoch 1568/4000: train_loss=2.1488  test_loss=2.2081  λ_max=4.8455\n",
      "[SGD | lr=0.001] Iter 25100: loss=2.1503\n",
      "[SGD | lr=0.001] Epoch 1569/4000: train_loss=2.1487  test_loss=2.2081  λ_max=4.6975\n",
      "[SGD | lr=0.001] Epoch 1570/4000: train_loss=2.1488  test_loss=2.2081  λ_max=4.7307\n",
      "[SGD | lr=0.001] Epoch 1571/4000: train_loss=2.1485  test_loss=2.2081  λ_max=4.7082\n",
      "[SGD | lr=0.001] Epoch 1572/4000: train_loss=2.1485  test_loss=2.2082  λ_max=4.5554\n",
      "[SGD | lr=0.001] Epoch 1573/4000: train_loss=2.1484  test_loss=2.2082  λ_max=4.7682\n",
      "[SGD | lr=0.001] Epoch 1574/4000: train_loss=2.1483  test_loss=2.2082  λ_max=4.4494\n",
      "[SGD | lr=0.001] Iter 25200: loss=2.1455\n",
      "[SGD | lr=0.001] Epoch 1575/4000: train_loss=2.1482  test_loss=2.2082  λ_max=4.8388\n",
      "[SGD | lr=0.001] Epoch 1576/4000: train_loss=2.1482  test_loss=2.2082  λ_max=4.7143\n",
      "[SGD | lr=0.001] Epoch 1577/4000: train_loss=2.1481  test_loss=2.2083  λ_max=4.8426\n",
      "[SGD | lr=0.001] Epoch 1578/4000: train_loss=2.1480  test_loss=2.2083  λ_max=4.6413\n",
      "[SGD | lr=0.001] Epoch 1579/4000: train_loss=2.1479  test_loss=2.2083  λ_max=4.8041\n",
      "[SGD | lr=0.001] Epoch 1580/4000: train_loss=2.1477  test_loss=2.2083  λ_max=4.9161\n",
      "[SGD | lr=0.001] Epoch 1581/4000: train_loss=2.1478  test_loss=2.2083  λ_max=4.5139\n",
      "[SGD | lr=0.001] Iter 25300: loss=2.1493\n",
      "[SGD | lr=0.001] Epoch 1582/4000: train_loss=2.1477  test_loss=2.2083  λ_max=4.8404\n",
      "[SGD | lr=0.001] Epoch 1583/4000: train_loss=2.1476  test_loss=2.2084  λ_max=4.8208\n",
      "[SGD | lr=0.001] Epoch 1584/4000: train_loss=2.1476  test_loss=2.2084  λ_max=4.7758\n",
      "[SGD | lr=0.001] Epoch 1585/4000: train_loss=2.1475  test_loss=2.2084  λ_max=4.7677\n",
      "[SGD | lr=0.001] Epoch 1586/4000: train_loss=2.1475  test_loss=2.2084  λ_max=4.8765\n",
      "[SGD | lr=0.001] Epoch 1587/4000: train_loss=2.1475  test_loss=2.2084  λ_max=4.8632\n",
      "[SGD | lr=0.001] Iter 25400: loss=2.1453\n",
      "[SGD | lr=0.001] Epoch 1588/4000: train_loss=2.1473  test_loss=2.2084  λ_max=4.5862\n",
      "[SGD | lr=0.001] Epoch 1589/4000: train_loss=2.1472  test_loss=2.2085  λ_max=4.8573\n",
      "[SGD | lr=0.001] Epoch 1590/4000: train_loss=2.1472  test_loss=2.2085  λ_max=4.5549\n",
      "[SGD | lr=0.001] Epoch 1591/4000: train_loss=2.1470  test_loss=2.2085  λ_max=4.8639\n",
      "[SGD | lr=0.001] Epoch 1592/4000: train_loss=2.1470  test_loss=2.2085  λ_max=4.8183\n",
      "[SGD | lr=0.001] Epoch 1593/4000: train_loss=2.1469  test_loss=2.2085  λ_max=4.7346\n",
      "[SGD | lr=0.001] Iter 25500: loss=2.1456\n",
      "[SGD | lr=0.001] Epoch 1594/4000: train_loss=2.1470  test_loss=2.2086  λ_max=4.5358\n",
      "[SGD | lr=0.001] Epoch 1595/4000: train_loss=2.1468  test_loss=2.2086  λ_max=4.5827\n",
      "[SGD | lr=0.001] Epoch 1596/4000: train_loss=2.1466  test_loss=2.2086  λ_max=4.7033\n",
      "[SGD | lr=0.001] Epoch 1597/4000: train_loss=2.1466  test_loss=2.2086  λ_max=4.8275\n",
      "[SGD | lr=0.001] Epoch 1598/4000: train_loss=2.1465  test_loss=2.2086  λ_max=4.5335\n",
      "[SGD | lr=0.001] Epoch 1599/4000: train_loss=2.1464  test_loss=2.2086  λ_max=4.9868\n",
      "[SGD | lr=0.001] Iter 25600: loss=2.1485\n",
      "[SGD | lr=0.001] Epoch 1600/4000: train_loss=2.1464  test_loss=2.2087  λ_max=4.8315\n",
      "[SGD | lr=0.001] Epoch 1601/4000: train_loss=2.1463  test_loss=2.2087  λ_max=4.9219\n",
      "[SGD | lr=0.001] Epoch 1602/4000: train_loss=2.1462  test_loss=2.2087  λ_max=4.9352\n",
      "[SGD | lr=0.001] Epoch 1603/4000: train_loss=2.1460  test_loss=2.2087  λ_max=4.5586\n",
      "[SGD | lr=0.001] Epoch 1604/4000: train_loss=2.1461  test_loss=2.2088  λ_max=4.6993\n",
      "[SGD | lr=0.001] Epoch 1605/4000: train_loss=2.1460  test_loss=2.2088  λ_max=4.9597\n",
      "[SGD | lr=0.001] Epoch 1606/4000: train_loss=2.1460  test_loss=2.2088  λ_max=4.8902\n",
      "[SGD | lr=0.001] Iter 25700: loss=2.1495\n",
      "[SGD | lr=0.001] Epoch 1607/4000: train_loss=2.1458  test_loss=2.2088  λ_max=5.0075\n",
      "[SGD | lr=0.001] Epoch 1608/4000: train_loss=2.1459  test_loss=2.2088  λ_max=4.8455\n",
      "[SGD | lr=0.001] Epoch 1609/4000: train_loss=2.1457  test_loss=2.2088  λ_max=4.7112\n",
      "[SGD | lr=0.001] Epoch 1610/4000: train_loss=2.1456  test_loss=2.2089  λ_max=4.8588\n",
      "[SGD | lr=0.001] Epoch 1611/4000: train_loss=2.1455  test_loss=2.2089  λ_max=4.5459\n",
      "[SGD | lr=0.001] Epoch 1612/4000: train_loss=2.1455  test_loss=2.2089  λ_max=5.0232\n",
      "[SGD | lr=0.001] Iter 25800: loss=2.1452\n",
      "[SGD | lr=0.001] Epoch 1613/4000: train_loss=2.1453  test_loss=2.2089  λ_max=4.6581\n",
      "[SGD | lr=0.001] Epoch 1614/4000: train_loss=2.1452  test_loss=2.2089  λ_max=4.7636\n",
      "[SGD | lr=0.001] Epoch 1615/4000: train_loss=2.1452  test_loss=2.2090  λ_max=4.6829\n",
      "[SGD | lr=0.001] Epoch 1616/4000: train_loss=2.1452  test_loss=2.2090  λ_max=5.0085\n",
      "[SGD | lr=0.001] Epoch 1617/4000: train_loss=2.1451  test_loss=2.2090  λ_max=4.9853\n",
      "[SGD | lr=0.001] Epoch 1618/4000: train_loss=2.1450  test_loss=2.2090  λ_max=4.9517\n",
      "[SGD | lr=0.001] Iter 25900: loss=2.1468\n",
      "[SGD | lr=0.001] Epoch 1619/4000: train_loss=2.1449  test_loss=2.2090  λ_max=4.9786\n",
      "[SGD | lr=0.001] Epoch 1620/4000: train_loss=2.1448  test_loss=2.2091  λ_max=4.9983\n",
      "[SGD | lr=0.001] Epoch 1621/4000: train_loss=2.1448  test_loss=2.2091  λ_max=5.0014\n",
      "[SGD | lr=0.001] Epoch 1622/4000: train_loss=2.1447  test_loss=2.2091  λ_max=4.9118\n",
      "[SGD | lr=0.001] Epoch 1623/4000: train_loss=2.1446  test_loss=2.2091  λ_max=5.0663\n",
      "[SGD | lr=0.001] Epoch 1624/4000: train_loss=2.1446  test_loss=2.2091  λ_max=5.1172\n",
      "[SGD | lr=0.001] Iter 26000: loss=2.1451\n",
      "[SGD | lr=0.001] Epoch 1625/4000: train_loss=2.1445  test_loss=2.2092  λ_max=5.0578\n",
      "[SGD | lr=0.001] Epoch 1626/4000: train_loss=2.1444  test_loss=2.2092  λ_max=5.1143\n",
      "[SGD | lr=0.001] Epoch 1627/4000: train_loss=2.1444  test_loss=2.2092  λ_max=4.9350\n",
      "[SGD | lr=0.001] Epoch 1628/4000: train_loss=2.1441  test_loss=2.2092  λ_max=5.0828\n",
      "[SGD | lr=0.001] Epoch 1629/4000: train_loss=2.1442  test_loss=2.2092  λ_max=4.9724\n",
      "[SGD | lr=0.001] Epoch 1630/4000: train_loss=2.1440  test_loss=2.2093  λ_max=5.1118\n",
      "[SGD | lr=0.001] Epoch 1631/4000: train_loss=2.1440  test_loss=2.2093  λ_max=4.7676\n",
      "[SGD | lr=0.001] Iter 26100: loss=2.1441\n",
      "[SGD | lr=0.001] Epoch 1632/4000: train_loss=2.1437  test_loss=2.2093  λ_max=4.9893\n",
      "[SGD | lr=0.001] Epoch 1633/4000: train_loss=2.1438  test_loss=2.2093  λ_max=4.9488\n",
      "[SGD | lr=0.001] Epoch 1634/4000: train_loss=2.1438  test_loss=2.2093  λ_max=5.0525\n",
      "[SGD | lr=0.001] Epoch 1635/4000: train_loss=2.1437  test_loss=2.2094  λ_max=4.8798\n",
      "[SGD | lr=0.001] Epoch 1636/4000: train_loss=2.1436  test_loss=2.2094  λ_max=4.8398\n",
      "[SGD | lr=0.001] Epoch 1637/4000: train_loss=2.1436  test_loss=2.2094  λ_max=5.0116\n",
      "[SGD | lr=0.001] Iter 26200: loss=2.1433\n",
      "[SGD | lr=0.001] Epoch 1638/4000: train_loss=2.1433  test_loss=2.2094  λ_max=4.8709\n",
      "[SGD | lr=0.001] Epoch 1639/4000: train_loss=2.1432  test_loss=2.2094  λ_max=4.6640\n",
      "[SGD | lr=0.001] Epoch 1640/4000: train_loss=2.1433  test_loss=2.2095  λ_max=4.7885\n",
      "[SGD | lr=0.001] Epoch 1641/4000: train_loss=2.1431  test_loss=2.2095  λ_max=5.0505\n",
      "[SGD | lr=0.001] Epoch 1642/4000: train_loss=2.1431  test_loss=2.2095  λ_max=5.0607\n",
      "[SGD | lr=0.001] Epoch 1643/4000: train_loss=2.1430  test_loss=2.2095  λ_max=4.8330\n",
      "[SGD | lr=0.001] Iter 26300: loss=2.1385\n",
      "[SGD | lr=0.001] Epoch 1644/4000: train_loss=2.1428  test_loss=2.2095  λ_max=5.2380\n",
      "[SGD | lr=0.001] Epoch 1645/4000: train_loss=2.1428  test_loss=2.2096  λ_max=4.9726\n",
      "[SGD | lr=0.001] Epoch 1646/4000: train_loss=2.1427  test_loss=2.2096  λ_max=5.0260\n",
      "[SGD | lr=0.001] Epoch 1647/4000: train_loss=2.1427  test_loss=2.2096  λ_max=5.1554\n",
      "[SGD | lr=0.001] Epoch 1648/4000: train_loss=2.1426  test_loss=2.2096  λ_max=5.2501\n",
      "[SGD | lr=0.001] Epoch 1649/4000: train_loss=2.1426  test_loss=2.2096  λ_max=5.0818\n",
      "[SGD | lr=0.001] Iter 26400: loss=2.1440\n",
      "[SGD | lr=0.001] Epoch 1650/4000: train_loss=2.1425  test_loss=2.2097  λ_max=5.2009\n",
      "[SGD | lr=0.001] Epoch 1651/4000: train_loss=2.1425  test_loss=2.2097  λ_max=5.1306\n",
      "[SGD | lr=0.001] Epoch 1652/4000: train_loss=2.1423  test_loss=2.2097  λ_max=5.1479\n",
      "[SGD | lr=0.001] Epoch 1653/4000: train_loss=2.1422  test_loss=2.2097  λ_max=5.0362\n",
      "[SGD | lr=0.001] Epoch 1654/4000: train_loss=2.1422  test_loss=2.2097  λ_max=5.0070\n",
      "[SGD | lr=0.001] Epoch 1655/4000: train_loss=2.1421  test_loss=2.2098  λ_max=5.2411\n",
      "[SGD | lr=0.001] Epoch 1656/4000: train_loss=2.1420  test_loss=2.2098  λ_max=5.1280\n",
      "[SGD | lr=0.001] Iter 26500: loss=2.1386\n",
      "[SGD | lr=0.001] Epoch 1657/4000: train_loss=2.1418  test_loss=2.2098  λ_max=5.2076\n",
      "[SGD | lr=0.001] Epoch 1658/4000: train_loss=2.1419  test_loss=2.2098  λ_max=5.1943\n",
      "[SGD | lr=0.001] Epoch 1659/4000: train_loss=2.1416  test_loss=2.2098  λ_max=5.2082\n",
      "[SGD | lr=0.001] Epoch 1660/4000: train_loss=2.1417  test_loss=2.2099  λ_max=5.1190\n",
      "[SGD | lr=0.001] Epoch 1661/4000: train_loss=2.1416  test_loss=2.2099  λ_max=4.9223\n",
      "[SGD | lr=0.001] Epoch 1662/4000: train_loss=2.1413  test_loss=2.2099  λ_max=5.2197\n",
      "[SGD | lr=0.001] Iter 26600: loss=2.1439\n",
      "[SGD | lr=0.001] Epoch 1663/4000: train_loss=2.1414  test_loss=2.2099  λ_max=5.0406\n",
      "[SGD | lr=0.001] Epoch 1664/4000: train_loss=2.1413  test_loss=2.2099  λ_max=5.0129\n",
      "[SGD | lr=0.001] Epoch 1665/4000: train_loss=2.1413  test_loss=2.2100  λ_max=5.2840\n",
      "[SGD | lr=0.001] Epoch 1666/4000: train_loss=2.1410  test_loss=2.2100  λ_max=4.9780\n",
      "[SGD | lr=0.001] Epoch 1667/4000: train_loss=2.1409  test_loss=2.2100  λ_max=5.2368\n",
      "[SGD | lr=0.001] Epoch 1668/4000: train_loss=2.1410  test_loss=2.2100  λ_max=5.1690\n",
      "[SGD | lr=0.001] Iter 26700: loss=2.1407\n",
      "[SGD | lr=0.001] Epoch 1669/4000: train_loss=2.1410  test_loss=2.2100  λ_max=5.2838\n",
      "[SGD | lr=0.001] Epoch 1670/4000: train_loss=2.1409  test_loss=2.2101  λ_max=5.1581\n",
      "[SGD | lr=0.001] Epoch 1671/4000: train_loss=2.1407  test_loss=2.2101  λ_max=4.9529\n",
      "[SGD | lr=0.001] Epoch 1672/4000: train_loss=2.1406  test_loss=2.2101  λ_max=5.2327\n",
      "[SGD | lr=0.001] Epoch 1673/4000: train_loss=2.1405  test_loss=2.2101  λ_max=5.3610\n",
      "[SGD | lr=0.001] Epoch 1674/4000: train_loss=2.1406  test_loss=2.2102  λ_max=5.0644\n",
      "[SGD | lr=0.001] Iter 26800: loss=2.1393\n",
      "[SGD | lr=0.001] Epoch 1675/4000: train_loss=2.1404  test_loss=2.2102  λ_max=5.3398\n",
      "[SGD | lr=0.001] Epoch 1676/4000: train_loss=2.1402  test_loss=2.2102  λ_max=5.2906\n",
      "[SGD | lr=0.001] Epoch 1677/4000: train_loss=2.1402  test_loss=2.2102  λ_max=5.0913\n",
      "[SGD | lr=0.001] Epoch 1678/4000: train_loss=2.1402  test_loss=2.2102  λ_max=5.0473\n",
      "[SGD | lr=0.001] Epoch 1679/4000: train_loss=2.1402  test_loss=2.2102  λ_max=5.3313\n",
      "[SGD | lr=0.001] Epoch 1680/4000: train_loss=2.1400  test_loss=2.2103  λ_max=5.2795\n",
      "[SGD | lr=0.001] Epoch 1681/4000: train_loss=2.1399  test_loss=2.2103  λ_max=5.3956\n",
      "[SGD | lr=0.001] Iter 26900: loss=2.1441\n",
      "[SGD | lr=0.001] Epoch 1682/4000: train_loss=2.1399  test_loss=2.2103  λ_max=5.2407\n",
      "[SGD | lr=0.001] Epoch 1683/4000: train_loss=2.1398  test_loss=2.2103  λ_max=5.1220\n",
      "[SGD | lr=0.001] Epoch 1684/4000: train_loss=2.1396  test_loss=2.2104  λ_max=5.1771\n",
      "[SGD | lr=0.001] Epoch 1685/4000: train_loss=2.1396  test_loss=2.2104  λ_max=5.2358\n",
      "[SGD | lr=0.001] Epoch 1686/4000: train_loss=2.1394  test_loss=2.2104  λ_max=5.3767\n",
      "[SGD | lr=0.001] Epoch 1687/4000: train_loss=2.1394  test_loss=2.2104  λ_max=5.1866\n",
      "[SGD | lr=0.001] Iter 27000: loss=2.1382\n",
      "[SGD | lr=0.001] Epoch 1688/4000: train_loss=2.1393  test_loss=2.2104  λ_max=5.0913\n",
      "[SGD | lr=0.001] Epoch 1689/4000: train_loss=2.1392  test_loss=2.2105  λ_max=5.3236\n",
      "[SGD | lr=0.001] Epoch 1690/4000: train_loss=2.1389  test_loss=2.2105  λ_max=5.3218\n",
      "[SGD | lr=0.001] Epoch 1691/4000: train_loss=2.1391  test_loss=2.2105  λ_max=5.2499\n",
      "[SGD | lr=0.001] Epoch 1692/4000: train_loss=2.1389  test_loss=2.2105  λ_max=5.4501\n",
      "[SGD | lr=0.001] Epoch 1693/4000: train_loss=2.1388  test_loss=2.2105  λ_max=5.5060\n",
      "[SGD | lr=0.001] Iter 27100: loss=2.1367\n",
      "[SGD | lr=0.001] Epoch 1694/4000: train_loss=2.1387  test_loss=2.2106  λ_max=5.0323\n",
      "[SGD | lr=0.001] Epoch 1695/4000: train_loss=2.1387  test_loss=2.2106  λ_max=5.3749\n",
      "[SGD | lr=0.001] Epoch 1696/4000: train_loss=2.1385  test_loss=2.2106  λ_max=5.3472\n",
      "[SGD | lr=0.001] Epoch 1697/4000: train_loss=2.1385  test_loss=2.2106  λ_max=5.0345\n",
      "[SGD | lr=0.001] Epoch 1698/4000: train_loss=2.1383  test_loss=2.2107  λ_max=5.4488\n",
      "[SGD | lr=0.001] Epoch 1699/4000: train_loss=2.1381  test_loss=2.2107  λ_max=5.2744\n",
      "[SGD | lr=0.001] Iter 27200: loss=2.1375\n",
      "[SGD | lr=0.001] Epoch 1700/4000: train_loss=2.1382  test_loss=2.2107  λ_max=5.2164\n",
      "[SGD | lr=0.001] Epoch 1701/4000: train_loss=2.1381  test_loss=2.2107  λ_max=5.1642\n",
      "[SGD | lr=0.001] Epoch 1702/4000: train_loss=2.1381  test_loss=2.2107  λ_max=5.4871\n",
      "[SGD | lr=0.001] Epoch 1703/4000: train_loss=2.1378  test_loss=2.2108  λ_max=5.1711\n",
      "[SGD | lr=0.001] Epoch 1704/4000: train_loss=2.1381  test_loss=2.2108  λ_max=5.5118\n",
      "[SGD | lr=0.001] Epoch 1705/4000: train_loss=2.1379  test_loss=2.2108  λ_max=5.3056\n",
      "[SGD | lr=0.001] Epoch 1706/4000: train_loss=2.1377  test_loss=2.2108  λ_max=5.4511\n",
      "[SGD | lr=0.001] Iter 27300: loss=2.1344\n",
      "[SGD | lr=0.001] Epoch 1707/4000: train_loss=2.1377  test_loss=2.2108  λ_max=5.5012\n",
      "[SGD | lr=0.001] Epoch 1708/4000: train_loss=2.1376  test_loss=2.2109  λ_max=5.3371\n",
      "[SGD | lr=0.001] Epoch 1709/4000: train_loss=2.1374  test_loss=2.2109  λ_max=5.2690\n",
      "[SGD | lr=0.001] Epoch 1710/4000: train_loss=2.1373  test_loss=2.2109  λ_max=5.4300\n",
      "[SGD | lr=0.001] Epoch 1711/4000: train_loss=2.1372  test_loss=2.2109  λ_max=5.5442\n",
      "[SGD | lr=0.001] Epoch 1712/4000: train_loss=2.1371  test_loss=2.2109  λ_max=5.3906\n",
      "[SGD | lr=0.001] Iter 27400: loss=2.1420\n",
      "[SGD | lr=0.001] Epoch 1713/4000: train_loss=2.1371  test_loss=2.2110  λ_max=5.4276\n",
      "[SGD | lr=0.001] Epoch 1714/4000: train_loss=2.1369  test_loss=2.2110  λ_max=5.5408\n",
      "[SGD | lr=0.001] Epoch 1715/4000: train_loss=2.1370  test_loss=2.2110  λ_max=5.2582\n",
      "[SGD | lr=0.001] Epoch 1716/4000: train_loss=2.1368  test_loss=2.2110  λ_max=5.5100\n",
      "[SGD | lr=0.001] Epoch 1717/4000: train_loss=2.1368  test_loss=2.2110  λ_max=5.3278\n",
      "[SGD | lr=0.001] Epoch 1718/4000: train_loss=2.1366  test_loss=2.2111  λ_max=5.5584\n",
      "[SGD | lr=0.001] Iter 27500: loss=2.1377\n",
      "[SGD | lr=0.001] Epoch 1719/4000: train_loss=2.1366  test_loss=2.2111  λ_max=5.4963\n",
      "[SGD | lr=0.001] Epoch 1720/4000: train_loss=2.1366  test_loss=2.2111  λ_max=5.6124\n",
      "[SGD | lr=0.001] Epoch 1721/4000: train_loss=2.1365  test_loss=2.2111  λ_max=5.4476\n",
      "[SGD | lr=0.001] Epoch 1722/4000: train_loss=2.1364  test_loss=2.2111  λ_max=5.6592\n",
      "[SGD | lr=0.001] Epoch 1723/4000: train_loss=2.1363  test_loss=2.2112  λ_max=5.4659\n",
      "[SGD | lr=0.001] Epoch 1724/4000: train_loss=2.1362  test_loss=2.2112  λ_max=5.6355\n",
      "[SGD | lr=0.001] Iter 27600: loss=2.1374\n",
      "[SGD | lr=0.001] Epoch 1725/4000: train_loss=2.1361  test_loss=2.2112  λ_max=5.5340\n",
      "[SGD | lr=0.001] Epoch 1726/4000: train_loss=2.1360  test_loss=2.2112  λ_max=5.5953\n",
      "[SGD | lr=0.001] Epoch 1727/4000: train_loss=2.1359  test_loss=2.2112  λ_max=5.4429\n",
      "[SGD | lr=0.001] Epoch 1728/4000: train_loss=2.1358  test_loss=2.2113  λ_max=5.1661\n",
      "[SGD | lr=0.001] Epoch 1729/4000: train_loss=2.1358  test_loss=2.2113  λ_max=5.5670\n",
      "[SGD | lr=0.001] Epoch 1730/4000: train_loss=2.1354  test_loss=2.2113  λ_max=5.4089\n",
      "[SGD | lr=0.001] Epoch 1731/4000: train_loss=2.1354  test_loss=2.2113  λ_max=5.4986\n",
      "[SGD | lr=0.001] Iter 27700: loss=2.1328\n",
      "[SGD | lr=0.001] Epoch 1732/4000: train_loss=2.1356  test_loss=2.2113  λ_max=5.3624\n",
      "[SGD | lr=0.001] Epoch 1733/4000: train_loss=2.1352  test_loss=2.2114  λ_max=5.6053\n",
      "[SGD | lr=0.001] Epoch 1734/4000: train_loss=2.1353  test_loss=2.2114  λ_max=5.5968\n",
      "[SGD | lr=0.001] Epoch 1735/4000: train_loss=2.1350  test_loss=2.2114  λ_max=5.6662\n",
      "[SGD | lr=0.001] Epoch 1736/4000: train_loss=2.1353  test_loss=2.2114  λ_max=5.3601\n",
      "[SGD | lr=0.001] Epoch 1737/4000: train_loss=2.1349  test_loss=2.2114  λ_max=5.4003\n",
      "[SGD | lr=0.001] Iter 27800: loss=2.1312\n",
      "[SGD | lr=0.001] Epoch 1738/4000: train_loss=2.1349  test_loss=2.2115  λ_max=5.5769\n",
      "[SGD | lr=0.001] Epoch 1739/4000: train_loss=2.1348  test_loss=2.2115  λ_max=5.5538\n",
      "[SGD | lr=0.001] Epoch 1740/4000: train_loss=2.1348  test_loss=2.2115  λ_max=5.7005\n",
      "[SGD | lr=0.001] Epoch 1741/4000: train_loss=2.1347  test_loss=2.2115  λ_max=5.4759\n",
      "[SGD | lr=0.001] Epoch 1742/4000: train_loss=2.1345  test_loss=2.2115  λ_max=5.3433\n",
      "[SGD | lr=0.001] Epoch 1743/4000: train_loss=2.1343  test_loss=2.2116  λ_max=5.7414\n",
      "[SGD | lr=0.001] Iter 27900: loss=2.1372\n",
      "[SGD | lr=0.001] Epoch 1744/4000: train_loss=2.1342  test_loss=2.2116  λ_max=5.7545\n",
      "[SGD | lr=0.001] Epoch 1745/4000: train_loss=2.1342  test_loss=2.2116  λ_max=5.6314\n",
      "[SGD | lr=0.001] Epoch 1746/4000: train_loss=2.1341  test_loss=2.2116  λ_max=5.3320\n",
      "[SGD | lr=0.001] Epoch 1747/4000: train_loss=2.1340  test_loss=2.2117  λ_max=5.5550\n",
      "[SGD | lr=0.001] Epoch 1748/4000: train_loss=2.1341  test_loss=2.2117  λ_max=5.5717\n",
      "[SGD | lr=0.001] Epoch 1749/4000: train_loss=2.1336  test_loss=2.2117  λ_max=5.7473\n",
      "[SGD | lr=0.001] Iter 28000: loss=2.1376\n",
      "[SGD | lr=0.001] Epoch 1750/4000: train_loss=2.1338  test_loss=2.2117  λ_max=5.7638\n",
      "[SGD | lr=0.001] Epoch 1751/4000: train_loss=2.1338  test_loss=2.2117  λ_max=5.6303\n",
      "[SGD | lr=0.001] Epoch 1752/4000: train_loss=2.1335  test_loss=2.2118  λ_max=5.7340\n",
      "[SGD | lr=0.001] Epoch 1753/4000: train_loss=2.1334  test_loss=2.2118  λ_max=5.7883\n",
      "[SGD | lr=0.001] Epoch 1754/4000: train_loss=2.1333  test_loss=2.2118  λ_max=5.6661\n",
      "[SGD | lr=0.001] Epoch 1755/4000: train_loss=2.1333  test_loss=2.2118  λ_max=5.4079\n",
      "[SGD | lr=0.001] Epoch 1756/4000: train_loss=2.1332  test_loss=2.2118  λ_max=5.8431\n",
      "[SGD | lr=0.001] Iter 28100: loss=2.1327\n",
      "[SGD | lr=0.001] Epoch 1757/4000: train_loss=2.1330  test_loss=2.2119  λ_max=5.5602\n",
      "[SGD | lr=0.001] Epoch 1758/4000: train_loss=2.1331  test_loss=2.2119  λ_max=5.4220\n",
      "[SGD | lr=0.001] Epoch 1759/4000: train_loss=2.1327  test_loss=2.2119  λ_max=5.4837\n",
      "[SGD | lr=0.001] Epoch 1760/4000: train_loss=2.1330  test_loss=2.2119  λ_max=5.7907\n",
      "[SGD | lr=0.001] Epoch 1761/4000: train_loss=2.1327  test_loss=2.2119  λ_max=5.3201\n",
      "[SGD | lr=0.001] Epoch 1762/4000: train_loss=2.1326  test_loss=2.2120  λ_max=5.7298\n",
      "[SGD | lr=0.001] Iter 28200: loss=2.1379\n",
      "[SGD | lr=0.001] Epoch 1763/4000: train_loss=2.1326  test_loss=2.2120  λ_max=5.5900\n",
      "[SGD | lr=0.001] Epoch 1764/4000: train_loss=2.1324  test_loss=2.2120  λ_max=5.6607\n",
      "[SGD | lr=0.001] Epoch 1765/4000: train_loss=2.1324  test_loss=2.2120  λ_max=5.6188\n",
      "[SGD | lr=0.001] Epoch 1766/4000: train_loss=2.1323  test_loss=2.2120  λ_max=5.8990\n",
      "[SGD | lr=0.001] Epoch 1767/4000: train_loss=2.1321  test_loss=2.2121  λ_max=5.5662\n",
      "[SGD | lr=0.001] Epoch 1768/4000: train_loss=2.1320  test_loss=2.2121  λ_max=5.5970\n",
      "[SGD | lr=0.001] Iter 28300: loss=2.1301\n",
      "[SGD | lr=0.001] Epoch 1769/4000: train_loss=2.1319  test_loss=2.2121  λ_max=5.5575\n",
      "[SGD | lr=0.001] Epoch 1770/4000: train_loss=2.1317  test_loss=2.2121  λ_max=5.7366\n",
      "[SGD | lr=0.001] Epoch 1771/4000: train_loss=2.1318  test_loss=2.2121  λ_max=5.5945\n",
      "[SGD | lr=0.001] Epoch 1772/4000: train_loss=2.1315  test_loss=2.2122  λ_max=5.7763\n",
      "[SGD | lr=0.001] Epoch 1773/4000: train_loss=2.1316  test_loss=2.2122  λ_max=5.7687\n",
      "[SGD | lr=0.001] Epoch 1774/4000: train_loss=2.1314  test_loss=2.2122  λ_max=5.3324\n",
      "[SGD | lr=0.001] Iter 28400: loss=2.1273\n",
      "[SGD | lr=0.001] Epoch 1775/4000: train_loss=2.1313  test_loss=2.2122  λ_max=5.7947\n",
      "[SGD | lr=0.001] Epoch 1776/4000: train_loss=2.1312  test_loss=2.2122  λ_max=5.6397\n",
      "[SGD | lr=0.001] Epoch 1777/4000: train_loss=2.1311  test_loss=2.2123  λ_max=5.6046\n",
      "[SGD | lr=0.001] Epoch 1778/4000: train_loss=2.1311  test_loss=2.2123  λ_max=5.4133\n",
      "[SGD | lr=0.001] Epoch 1779/4000: train_loss=2.1309  test_loss=2.2123  λ_max=5.7596\n",
      "[SGD | lr=0.001] Epoch 1780/4000: train_loss=2.1308  test_loss=2.2123  λ_max=5.8965\n",
      "[SGD | lr=0.001] Epoch 1781/4000: train_loss=2.1307  test_loss=2.2123  λ_max=5.6307\n",
      "[SGD | lr=0.001] Iter 28500: loss=2.1291\n",
      "[SGD | lr=0.001] Epoch 1782/4000: train_loss=2.1306  test_loss=2.2124  λ_max=5.7323\n",
      "[SGD | lr=0.001] Epoch 1783/4000: train_loss=2.1307  test_loss=2.2124  λ_max=5.5350\n",
      "[SGD | lr=0.001] Epoch 1784/4000: train_loss=2.1304  test_loss=2.2124  λ_max=5.9103\n",
      "[SGD | lr=0.001] Epoch 1785/4000: train_loss=2.1304  test_loss=2.2124  λ_max=5.6309\n",
      "[SGD | lr=0.001] Epoch 1786/4000: train_loss=2.1302  test_loss=2.2124  λ_max=5.9534\n",
      "[SGD | lr=0.001] Epoch 1787/4000: train_loss=2.1302  test_loss=2.2125  λ_max=5.6061\n",
      "[SGD | lr=0.001] Iter 28600: loss=2.1267\n",
      "[SGD | lr=0.001] Epoch 1788/4000: train_loss=2.1301  test_loss=2.2125  λ_max=5.7671\n",
      "[SGD | lr=0.001] Epoch 1789/4000: train_loss=2.1299  test_loss=2.2125  λ_max=6.0091\n",
      "[SGD | lr=0.001] Epoch 1790/4000: train_loss=2.1298  test_loss=2.2125  λ_max=5.5903\n",
      "[SGD | lr=0.001] Epoch 1791/4000: train_loss=2.1296  test_loss=2.2125  λ_max=5.8348\n",
      "[SGD | lr=0.001] Epoch 1792/4000: train_loss=2.1298  test_loss=2.2126  λ_max=6.0307\n",
      "[SGD | lr=0.001] Epoch 1793/4000: train_loss=2.1298  test_loss=2.2126  λ_max=5.6380\n",
      "[SGD | lr=0.001] Iter 28700: loss=2.1249\n",
      "[SGD | lr=0.001] Epoch 1794/4000: train_loss=2.1296  test_loss=2.2126  λ_max=5.9894\n",
      "[SGD | lr=0.001] Epoch 1795/4000: train_loss=2.1296  test_loss=2.2126  λ_max=5.9600\n",
      "[SGD | lr=0.001] Epoch 1796/4000: train_loss=2.1292  test_loss=2.2126  λ_max=5.9726\n",
      "[SGD | lr=0.001] Epoch 1797/4000: train_loss=2.1293  test_loss=2.2127  λ_max=5.8860\n",
      "[SGD | lr=0.001] Epoch 1798/4000: train_loss=2.1292  test_loss=2.2127  λ_max=5.9128\n",
      "[SGD | lr=0.001] Epoch 1799/4000: train_loss=2.1291  test_loss=2.2127  λ_max=5.9534\n",
      "[SGD | lr=0.001] Iter 28800: loss=2.1333\n",
      "[SGD | lr=0.001] Epoch 1800/4000: train_loss=2.1291  test_loss=2.2127  λ_max=6.0101\n",
      "[SGD | lr=0.001] Epoch 1801/4000: train_loss=2.1287  test_loss=2.2127  λ_max=5.9203\n",
      "[SGD | lr=0.001] Epoch 1802/4000: train_loss=2.1287  test_loss=2.2128  λ_max=6.0702\n",
      "[SGD | lr=0.001] Epoch 1803/4000: train_loss=2.1286  test_loss=2.2128  λ_max=6.0027\n",
      "[SGD | lr=0.001] Epoch 1804/4000: train_loss=2.1286  test_loss=2.2128  λ_max=6.1349\n",
      "[SGD | lr=0.001] Epoch 1805/4000: train_loss=2.1285  test_loss=2.2128  λ_max=6.1427\n",
      "[SGD | lr=0.001] Epoch 1806/4000: train_loss=2.1282  test_loss=2.2128  λ_max=5.9881\n",
      "[SGD | lr=0.001] Iter 28900: loss=2.1284\n",
      "[SGD | lr=0.001] Epoch 1807/4000: train_loss=2.1284  test_loss=2.2128  λ_max=5.9221\n",
      "[SGD | lr=0.001] Epoch 1808/4000: train_loss=2.1282  test_loss=2.2129  λ_max=6.0882\n",
      "[SGD | lr=0.001] Epoch 1809/4000: train_loss=2.1281  test_loss=2.2129  λ_max=5.9273\n",
      "[SGD | lr=0.001] Epoch 1810/4000: train_loss=2.1280  test_loss=2.2129  λ_max=5.8687\n",
      "[SGD | lr=0.001] Epoch 1811/4000: train_loss=2.1279  test_loss=2.2129  λ_max=5.7481\n",
      "[SGD | lr=0.001] Epoch 1812/4000: train_loss=2.1278  test_loss=2.2129  λ_max=6.1300\n",
      "[SGD | lr=0.001] Iter 29000: loss=2.1264\n",
      "[SGD | lr=0.001] Epoch 1813/4000: train_loss=2.1277  test_loss=2.2130  λ_max=6.0320\n",
      "[SGD | lr=0.001] Epoch 1814/4000: train_loss=2.1276  test_loss=2.2130  λ_max=5.8089\n",
      "[SGD | lr=0.001] Epoch 1815/4000: train_loss=2.1274  test_loss=2.2130  λ_max=5.7951\n",
      "[SGD | lr=0.001] Epoch 1816/4000: train_loss=2.1274  test_loss=2.2130  λ_max=5.8489\n",
      "[SGD | lr=0.001] Epoch 1817/4000: train_loss=2.1273  test_loss=2.2130  λ_max=5.5810\n",
      "[SGD | lr=0.001] Epoch 1818/4000: train_loss=2.1272  test_loss=2.2131  λ_max=6.1772\n",
      "[SGD | lr=0.001] Iter 29100: loss=2.1271\n",
      "[SGD | lr=0.001] Epoch 1819/4000: train_loss=2.1272  test_loss=2.2131  λ_max=5.8884\n",
      "[SGD | lr=0.001] Epoch 1820/4000: train_loss=2.1271  test_loss=2.2131  λ_max=5.8379\n",
      "[SGD | lr=0.001] Epoch 1821/4000: train_loss=2.1270  test_loss=2.2131  λ_max=5.8338\n",
      "[SGD | lr=0.001] Epoch 1822/4000: train_loss=2.1268  test_loss=2.2131  λ_max=6.2331\n",
      "[SGD | lr=0.001] Epoch 1823/4000: train_loss=2.1265  test_loss=2.2132  λ_max=6.0390\n",
      "[SGD | lr=0.001] Epoch 1824/4000: train_loss=2.1266  test_loss=2.2132  λ_max=5.8098\n",
      "[SGD | lr=0.001] Iter 29200: loss=2.1236\n",
      "[SGD | lr=0.001] Epoch 1825/4000: train_loss=2.1264  test_loss=2.2132  λ_max=5.8626\n",
      "[SGD | lr=0.001] Epoch 1826/4000: train_loss=2.1264  test_loss=2.2132  λ_max=5.6921\n",
      "[SGD | lr=0.001] Epoch 1827/4000: train_loss=2.1263  test_loss=2.2132  λ_max=5.8688\n",
      "[SGD | lr=0.001] Epoch 1828/4000: train_loss=2.1262  test_loss=2.2133  λ_max=5.7016\n",
      "[SGD | lr=0.001] Epoch 1829/4000: train_loss=2.1258  test_loss=2.2133  λ_max=5.9249\n",
      "[SGD | lr=0.001] Epoch 1830/4000: train_loss=2.1261  test_loss=2.2133  λ_max=6.0804\n",
      "[SGD | lr=0.001] Epoch 1831/4000: train_loss=2.1259  test_loss=2.2133  λ_max=6.2799\n",
      "[SGD | lr=0.001] Iter 29300: loss=2.1281\n",
      "[SGD | lr=0.001] Epoch 1832/4000: train_loss=2.1258  test_loss=2.2133  λ_max=6.1385\n",
      "[SGD | lr=0.001] Epoch 1833/4000: train_loss=2.1257  test_loss=2.2134  λ_max=6.2038\n",
      "[SGD | lr=0.001] Epoch 1834/4000: train_loss=2.1255  test_loss=2.2134  λ_max=5.8731\n",
      "[SGD | lr=0.001] Epoch 1835/4000: train_loss=2.1253  test_loss=2.2134  λ_max=6.0419\n",
      "[SGD | lr=0.001] Epoch 1836/4000: train_loss=2.1252  test_loss=2.2134  λ_max=5.9101\n",
      "[SGD | lr=0.001] Epoch 1837/4000: train_loss=2.1253  test_loss=2.2134  λ_max=6.1387\n",
      "[SGD | lr=0.001] Iter 29400: loss=2.1257\n",
      "[SGD | lr=0.001] Epoch 1838/4000: train_loss=2.1251  test_loss=2.2134  λ_max=6.1196\n",
      "[SGD | lr=0.001] Epoch 1839/4000: train_loss=2.1250  test_loss=2.2135  λ_max=5.9560\n",
      "[SGD | lr=0.001] Epoch 1840/4000: train_loss=2.1249  test_loss=2.2135  λ_max=6.0356\n",
      "[SGD | lr=0.001] Epoch 1841/4000: train_loss=2.1248  test_loss=2.2135  λ_max=6.2937\n",
      "[SGD | lr=0.001] Epoch 1842/4000: train_loss=2.1246  test_loss=2.2135  λ_max=5.9355\n",
      "[SGD | lr=0.001] Epoch 1843/4000: train_loss=2.1247  test_loss=2.2135  λ_max=5.9908\n",
      "[SGD | lr=0.001] Iter 29500: loss=2.1272\n",
      "[SGD | lr=0.001] Epoch 1844/4000: train_loss=2.1244  test_loss=2.2136  λ_max=6.3204\n",
      "[SGD | lr=0.001] Epoch 1845/4000: train_loss=2.1243  test_loss=2.2136  λ_max=5.8918\n",
      "[SGD | lr=0.001] Epoch 1846/4000: train_loss=2.1242  test_loss=2.2136  λ_max=5.7562\n",
      "[SGD | lr=0.001] Epoch 1847/4000: train_loss=2.1241  test_loss=2.2136  λ_max=5.7434\n",
      "[SGD | lr=0.001] Epoch 1848/4000: train_loss=2.1243  test_loss=2.2136  λ_max=6.3676\n",
      "[SGD | lr=0.001] Epoch 1849/4000: train_loss=2.1242  test_loss=2.2136  λ_max=6.0136\n",
      "[SGD | lr=0.001] Iter 29600: loss=2.1303\n",
      "[SGD | lr=0.001] Epoch 1850/4000: train_loss=2.1240  test_loss=2.2137  λ_max=5.9845\n",
      "[SGD | lr=0.001] Epoch 1851/4000: train_loss=2.1240  test_loss=2.2137  λ_max=6.3264\n",
      "[SGD | lr=0.001] Epoch 1852/4000: train_loss=2.1238  test_loss=2.2137  λ_max=6.0159\n",
      "[SGD | lr=0.001] Epoch 1853/4000: train_loss=2.1234  test_loss=2.2137  λ_max=6.2393\n",
      "[SGD | lr=0.001] Epoch 1854/4000: train_loss=2.1236  test_loss=2.2138  λ_max=6.2704\n",
      "[SGD | lr=0.001] Epoch 1855/4000: train_loss=2.1232  test_loss=2.2138  λ_max=5.7597\n",
      "[SGD | lr=0.001] Epoch 1856/4000: train_loss=2.1233  test_loss=2.2138  λ_max=6.2406\n",
      "[SGD | lr=0.001] Iter 29700: loss=2.1273\n",
      "[SGD | lr=0.001] Epoch 1857/4000: train_loss=2.1232  test_loss=2.2138  λ_max=6.3612\n",
      "[SGD | lr=0.001] Epoch 1858/4000: train_loss=2.1227  test_loss=2.2138  λ_max=6.4317\n",
      "[SGD | lr=0.001] Epoch 1859/4000: train_loss=2.1230  test_loss=2.2139  λ_max=6.3564\n",
      "[SGD | lr=0.001] Epoch 1860/4000: train_loss=2.1229  test_loss=2.2139  λ_max=6.1872\n",
      "[SGD | lr=0.001] Epoch 1861/4000: train_loss=2.1228  test_loss=2.2139  λ_max=6.1635\n",
      "[SGD | lr=0.001] Epoch 1862/4000: train_loss=2.1227  test_loss=2.2139  λ_max=6.0630\n",
      "[SGD | lr=0.001] Iter 29800: loss=2.1176\n",
      "[SGD | lr=0.001] Epoch 1863/4000: train_loss=2.1225  test_loss=2.2139  λ_max=6.4326\n",
      "[SGD | lr=0.001] Epoch 1864/4000: train_loss=2.1223  test_loss=2.2140  λ_max=6.4293\n",
      "[SGD | lr=0.001] Epoch 1865/4000: train_loss=2.1224  test_loss=2.2140  λ_max=6.0397\n",
      "[SGD | lr=0.001] Epoch 1866/4000: train_loss=2.1222  test_loss=2.2140  λ_max=6.2493\n",
      "[SGD | lr=0.001] Epoch 1867/4000: train_loss=2.1221  test_loss=2.2140  λ_max=6.3343\n",
      "[SGD | lr=0.001] Epoch 1868/4000: train_loss=2.1220  test_loss=2.2140  λ_max=6.4605\n",
      "[SGD | lr=0.001] Iter 29900: loss=2.1227\n",
      "[SGD | lr=0.001] Epoch 1869/4000: train_loss=2.1218  test_loss=2.2140  λ_max=6.4586\n",
      "[SGD | lr=0.001] Epoch 1870/4000: train_loss=2.1218  test_loss=2.2140  λ_max=6.0326\n",
      "[SGD | lr=0.001] Epoch 1871/4000: train_loss=2.1217  test_loss=2.2141  λ_max=6.3807\n",
      "[SGD | lr=0.001] Epoch 1872/4000: train_loss=2.1214  test_loss=2.2141  λ_max=6.3555\n",
      "[SGD | lr=0.001] Epoch 1873/4000: train_loss=2.1213  test_loss=2.2141  λ_max=6.4961\n",
      "[SGD | lr=0.001] Epoch 1874/4000: train_loss=2.1214  test_loss=2.2141  λ_max=6.0923\n",
      "[SGD | lr=0.001] Iter 30000: loss=2.1222\n",
      "[SGD | lr=0.001] Epoch 1875/4000: train_loss=2.1212  test_loss=2.2141  λ_max=6.1818\n",
      "[SGD | lr=0.001] Epoch 1876/4000: train_loss=2.1211  test_loss=2.2142  λ_max=6.2933\n",
      "[SGD | lr=0.001] Epoch 1877/4000: train_loss=2.1210  test_loss=2.2142  λ_max=6.3229\n",
      "[SGD | lr=0.001] Epoch 1878/4000: train_loss=2.1209  test_loss=2.2142  λ_max=6.1569\n",
      "[SGD | lr=0.001] Epoch 1879/4000: train_loss=2.1208  test_loss=2.2142  λ_max=6.2681\n",
      "[SGD | lr=0.001] Epoch 1880/4000: train_loss=2.1206  test_loss=2.2142  λ_max=6.2162\n",
      "[SGD | lr=0.001] Epoch 1881/4000: train_loss=2.1207  test_loss=2.2143  λ_max=6.1993\n",
      "[SGD | lr=0.001] Iter 30100: loss=2.1240\n",
      "[SGD | lr=0.001] Epoch 1882/4000: train_loss=2.1205  test_loss=2.2143  λ_max=6.4194\n",
      "[SGD | lr=0.001] Epoch 1883/4000: train_loss=2.1203  test_loss=2.2143  λ_max=6.5721\n",
      "[SGD | lr=0.001] Epoch 1884/4000: train_loss=2.1202  test_loss=2.2143  λ_max=6.0582\n",
      "[SGD | lr=0.001] Epoch 1885/4000: train_loss=2.1201  test_loss=2.2143  λ_max=6.5520\n",
      "[SGD | lr=0.001] Epoch 1886/4000: train_loss=2.1199  test_loss=2.2144  λ_max=6.0650\n",
      "[SGD | lr=0.001] Epoch 1887/4000: train_loss=2.1198  test_loss=2.2144  λ_max=6.4542\n",
      "[SGD | lr=0.001] Iter 30200: loss=2.1193\n",
      "[SGD | lr=0.001] Epoch 1888/4000: train_loss=2.1197  test_loss=2.2144  λ_max=6.3259\n",
      "[SGD | lr=0.001] Epoch 1889/4000: train_loss=2.1198  test_loss=2.2144  λ_max=6.3361\n",
      "[SGD | lr=0.001] Epoch 1890/4000: train_loss=2.1195  test_loss=2.2144  λ_max=6.3880\n",
      "[SGD | lr=0.001] Epoch 1891/4000: train_loss=2.1195  test_loss=2.2145  λ_max=6.1947\n",
      "[SGD | lr=0.001] Epoch 1892/4000: train_loss=2.1194  test_loss=2.2145  λ_max=6.4192\n",
      "[SGD | lr=0.001] Epoch 1893/4000: train_loss=2.1192  test_loss=2.2145  λ_max=6.5816\n",
      "[SGD | lr=0.001] Iter 30300: loss=2.1173\n",
      "[SGD | lr=0.001] Epoch 1894/4000: train_loss=2.1191  test_loss=2.2145  λ_max=6.2866\n",
      "[SGD | lr=0.001] Epoch 1895/4000: train_loss=2.1191  test_loss=2.2145  λ_max=6.0792\n",
      "[SGD | lr=0.001] Epoch 1896/4000: train_loss=2.1189  test_loss=2.2145  λ_max=6.3295\n",
      "[SGD | lr=0.001] Epoch 1897/4000: train_loss=2.1188  test_loss=2.2146  λ_max=6.2713\n",
      "[SGD | lr=0.001] Epoch 1898/4000: train_loss=2.1186  test_loss=2.2146  λ_max=6.4192\n",
      "[SGD | lr=0.001] Epoch 1899/4000: train_loss=2.1186  test_loss=2.2146  λ_max=6.6096\n",
      "[SGD | lr=0.001] Iter 30400: loss=2.1188\n",
      "[SGD | lr=0.001] Epoch 1900/4000: train_loss=2.1185  test_loss=2.2146  λ_max=6.1505\n",
      "[SGD | lr=0.001] Epoch 1901/4000: train_loss=2.1182  test_loss=2.2146  λ_max=6.4244\n",
      "[SGD | lr=0.001] Epoch 1902/4000: train_loss=2.1182  test_loss=2.2147  λ_max=6.6834\n",
      "[SGD | lr=0.001] Epoch 1903/4000: train_loss=2.1180  test_loss=2.2147  λ_max=6.5453\n",
      "[SGD | lr=0.001] Epoch 1904/4000: train_loss=2.1180  test_loss=2.2147  λ_max=6.5695\n",
      "[SGD | lr=0.001] Epoch 1905/4000: train_loss=2.1181  test_loss=2.2147  λ_max=6.5491\n",
      "[SGD | lr=0.001] Epoch 1906/4000: train_loss=2.1179  test_loss=2.2147  λ_max=6.5463\n",
      "[SGD | lr=0.001] Iter 30500: loss=2.1190\n",
      "[SGD | lr=0.001] Epoch 1907/4000: train_loss=2.1177  test_loss=2.2148  λ_max=6.5405\n",
      "[SGD | lr=0.001] Epoch 1908/4000: train_loss=2.1178  test_loss=2.2148  λ_max=6.5895\n",
      "[SGD | lr=0.001] Epoch 1909/4000: train_loss=2.1175  test_loss=2.2148  λ_max=6.4912\n",
      "[SGD | lr=0.001] Epoch 1910/4000: train_loss=2.1173  test_loss=2.2148  λ_max=6.7155\n",
      "[SGD | lr=0.001] Epoch 1911/4000: train_loss=2.1173  test_loss=2.2148  λ_max=6.3968\n",
      "[SGD | lr=0.001] Epoch 1912/4000: train_loss=2.1171  test_loss=2.2148  λ_max=6.7119\n",
      "[SGD | lr=0.001] Iter 30600: loss=2.1170\n",
      "[SGD | lr=0.001] Epoch 1913/4000: train_loss=2.1171  test_loss=2.2149  λ_max=6.1070\n",
      "[SGD | lr=0.001] Epoch 1914/4000: train_loss=2.1168  test_loss=2.2149  λ_max=6.7476\n",
      "[SGD | lr=0.001] Epoch 1915/4000: train_loss=2.1166  test_loss=2.2149  λ_max=6.1556\n",
      "[SGD | lr=0.001] Epoch 1916/4000: train_loss=2.1168  test_loss=2.2149  λ_max=6.7368\n",
      "[SGD | lr=0.001] Epoch 1917/4000: train_loss=2.1165  test_loss=2.2149  λ_max=6.5543\n",
      "[SGD | lr=0.001] Epoch 1918/4000: train_loss=2.1163  test_loss=2.2149  λ_max=6.4458\n",
      "[SGD | lr=0.001] Iter 30700: loss=2.1185\n",
      "[SGD | lr=0.001] Epoch 1919/4000: train_loss=2.1163  test_loss=2.2150  λ_max=6.4376\n",
      "[SGD | lr=0.001] Epoch 1920/4000: train_loss=2.1164  test_loss=2.2150  λ_max=6.8084\n",
      "[SGD | lr=0.001] Epoch 1921/4000: train_loss=2.1161  test_loss=2.2150  λ_max=6.3100\n",
      "[SGD | lr=0.001] Epoch 1922/4000: train_loss=2.1161  test_loss=2.2150  λ_max=6.7153\n",
      "[SGD | lr=0.001] Epoch 1923/4000: train_loss=2.1160  test_loss=2.2150  λ_max=6.4797\n",
      "[SGD | lr=0.001] Epoch 1924/4000: train_loss=2.1156  test_loss=2.2150  λ_max=6.7816\n",
      "[SGD | lr=0.001] Iter 30800: loss=2.1203\n",
      "[SGD | lr=0.001] Epoch 1925/4000: train_loss=2.1158  test_loss=2.2151  λ_max=6.7586\n",
      "[SGD | lr=0.001] Epoch 1926/4000: train_loss=2.1155  test_loss=2.2151  λ_max=6.5909\n",
      "[SGD | lr=0.001] Epoch 1927/4000: train_loss=2.1155  test_loss=2.2151  λ_max=6.7510\n",
      "[SGD | lr=0.001] Epoch 1928/4000: train_loss=2.1153  test_loss=2.2151  λ_max=6.6684\n",
      "[SGD | lr=0.001] Epoch 1929/4000: train_loss=2.1152  test_loss=2.2151  λ_max=6.6298\n",
      "[SGD | lr=0.001] Epoch 1930/4000: train_loss=2.1150  test_loss=2.2151  λ_max=6.1751\n",
      "[SGD | lr=0.001] Epoch 1931/4000: train_loss=2.1152  test_loss=2.2152  λ_max=6.6070\n",
      "[SGD | lr=0.001] Iter 30900: loss=2.1177\n",
      "[SGD | lr=0.001] Epoch 1932/4000: train_loss=2.1149  test_loss=2.2152  λ_max=6.7062\n",
      "[SGD | lr=0.001] Epoch 1933/4000: train_loss=2.1147  test_loss=2.2152  λ_max=6.4994\n",
      "[SGD | lr=0.001] Epoch 1934/4000: train_loss=2.1146  test_loss=2.2152  λ_max=6.5831\n",
      "[SGD | lr=0.001] Epoch 1935/4000: train_loss=2.1145  test_loss=2.2152  λ_max=6.7142\n",
      "[SGD | lr=0.001] Epoch 1936/4000: train_loss=2.1144  test_loss=2.2153  λ_max=6.3294\n",
      "[SGD | lr=0.001] Epoch 1937/4000: train_loss=2.1142  test_loss=2.2153  λ_max=6.4166\n",
      "[SGD | lr=0.001] Iter 31000: loss=2.1128\n",
      "[SGD | lr=0.001] Epoch 1938/4000: train_loss=2.1143  test_loss=2.2153  λ_max=6.4713\n",
      "[SGD | lr=0.001] Epoch 1939/4000: train_loss=2.1142  test_loss=2.2153  λ_max=6.8323\n",
      "[SGD | lr=0.001] Epoch 1940/4000: train_loss=2.1140  test_loss=2.2153  λ_max=6.3466\n",
      "[SGD | lr=0.001] Epoch 1941/4000: train_loss=2.1139  test_loss=2.2153  λ_max=6.6702\n",
      "[SGD | lr=0.001] Epoch 1942/4000: train_loss=2.1135  test_loss=2.2154  λ_max=6.8911\n",
      "[SGD | lr=0.001] Epoch 1943/4000: train_loss=2.1135  test_loss=2.2154  λ_max=6.6945\n",
      "[SGD | lr=0.001] Iter 31100: loss=2.1165\n",
      "[SGD | lr=0.001] Epoch 1944/4000: train_loss=2.1136  test_loss=2.2154  λ_max=6.7971\n",
      "[SGD | lr=0.001] Epoch 1945/4000: train_loss=2.1131  test_loss=2.2154  λ_max=6.8033\n",
      "[SGD | lr=0.001] Epoch 1946/4000: train_loss=2.1132  test_loss=2.2154  λ_max=6.8440\n",
      "[SGD | lr=0.001] Epoch 1947/4000: train_loss=2.1131  test_loss=2.2155  λ_max=6.9207\n",
      "[SGD | lr=0.001] Epoch 1948/4000: train_loss=2.1131  test_loss=2.2155  λ_max=6.9078\n",
      "[SGD | lr=0.001] Epoch 1949/4000: train_loss=2.1130  test_loss=2.2155  λ_max=6.4581\n",
      "[SGD | lr=0.001] Iter 31200: loss=2.1131\n",
      "[SGD | lr=0.001] Epoch 1950/4000: train_loss=2.1128  test_loss=2.2155  λ_max=6.6171\n",
      "[SGD | lr=0.001] Epoch 1951/4000: train_loss=2.1126  test_loss=2.2155  λ_max=6.7314\n",
      "[SGD | lr=0.001] Epoch 1952/4000: train_loss=2.1126  test_loss=2.2155  λ_max=6.9020\n",
      "[SGD | lr=0.001] Epoch 1953/4000: train_loss=2.1126  test_loss=2.2155  λ_max=6.7310\n",
      "[SGD | lr=0.001] Epoch 1954/4000: train_loss=2.1122  test_loss=2.2156  λ_max=6.5362\n",
      "[SGD | lr=0.001] Epoch 1955/4000: train_loss=2.1123  test_loss=2.2156  λ_max=6.9656\n",
      "[SGD | lr=0.001] Epoch 1956/4000: train_loss=2.1121  test_loss=2.2156  λ_max=6.8884\n",
      "[SGD | lr=0.001] Iter 31300: loss=2.1091\n",
      "[SGD | lr=0.001] Epoch 1957/4000: train_loss=2.1119  test_loss=2.2156  λ_max=6.9463\n",
      "[SGD | lr=0.001] Epoch 1958/4000: train_loss=2.1119  test_loss=2.2156  λ_max=6.5181\n",
      "[SGD | lr=0.001] Epoch 1959/4000: train_loss=2.1117  test_loss=2.2156  λ_max=7.0481\n",
      "[SGD | lr=0.001] Epoch 1960/4000: train_loss=2.1114  test_loss=2.2156  λ_max=6.6409\n",
      "[SGD | lr=0.001] Epoch 1961/4000: train_loss=2.1112  test_loss=2.2157  λ_max=6.4077\n",
      "[SGD | lr=0.001] Epoch 1962/4000: train_loss=2.1114  test_loss=2.2157  λ_max=6.8136\n",
      "[SGD | lr=0.001] Iter 31400: loss=2.1157\n",
      "[SGD | lr=0.001] Epoch 1963/4000: train_loss=2.1113  test_loss=2.2157  λ_max=6.8031\n",
      "[SGD | lr=0.001] Epoch 1964/4000: train_loss=2.1113  test_loss=2.2157  λ_max=6.5405\n",
      "[SGD | lr=0.001] Epoch 1965/4000: train_loss=2.1111  test_loss=2.2157  λ_max=6.7825\n",
      "[SGD | lr=0.001] Epoch 1966/4000: train_loss=2.1109  test_loss=2.2158  λ_max=6.7648\n",
      "[SGD | lr=0.001] Epoch 1967/4000: train_loss=2.1108  test_loss=2.2158  λ_max=6.9058\n",
      "[SGD | lr=0.001] Epoch 1968/4000: train_loss=2.1108  test_loss=2.2158  λ_max=6.7709\n",
      "[SGD | lr=0.001] Iter 31500: loss=2.1078\n",
      "[SGD | lr=0.001] Epoch 1969/4000: train_loss=2.1104  test_loss=2.2158  λ_max=6.6289\n",
      "[SGD | lr=0.001] Epoch 1970/4000: train_loss=2.1103  test_loss=2.2158  λ_max=6.7488\n",
      "[SGD | lr=0.001] Epoch 1971/4000: train_loss=2.1104  test_loss=2.2158  λ_max=7.0904\n",
      "[SGD | lr=0.001] Epoch 1972/4000: train_loss=2.1101  test_loss=2.2158  λ_max=7.0364\n",
      "[SGD | lr=0.001] Epoch 1973/4000: train_loss=2.1099  test_loss=2.2159  λ_max=6.9084\n",
      "[SGD | lr=0.001] Epoch 1974/4000: train_loss=2.1099  test_loss=2.2159  λ_max=6.9529\n",
      "[SGD | lr=0.001] Iter 31600: loss=2.1114\n",
      "[SGD | lr=0.001] Epoch 1975/4000: train_loss=2.1099  test_loss=2.2159  λ_max=6.8691\n",
      "[SGD | lr=0.001] Epoch 1976/4000: train_loss=2.1094  test_loss=2.2159  λ_max=6.6889\n",
      "[SGD | lr=0.001] Epoch 1977/4000: train_loss=2.1095  test_loss=2.2159  λ_max=6.6472\n",
      "[SGD | lr=0.001] Epoch 1978/4000: train_loss=2.1095  test_loss=2.2160  λ_max=6.9168\n",
      "[SGD | lr=0.001] Epoch 1979/4000: train_loss=2.1096  test_loss=2.2160  λ_max=6.6841\n",
      "[SGD | lr=0.001] Epoch 1980/4000: train_loss=2.1091  test_loss=2.2160  λ_max=6.9992\n",
      "[SGD | lr=0.001] Epoch 1981/4000: train_loss=2.1092  test_loss=2.2160  λ_max=6.6324\n",
      "[SGD | lr=0.001] Iter 31700: loss=2.1076\n",
      "[SGD | lr=0.001] Epoch 1982/4000: train_loss=2.1090  test_loss=2.2160  λ_max=6.7132\n",
      "[SGD | lr=0.001] Epoch 1983/4000: train_loss=2.1089  test_loss=2.2160  λ_max=7.1258\n",
      "[SGD | lr=0.001] Epoch 1984/4000: train_loss=2.1088  test_loss=2.2161  λ_max=7.1316\n",
      "[SGD | lr=0.001] Epoch 1985/4000: train_loss=2.1086  test_loss=2.2161  λ_max=6.9122\n",
      "[SGD | lr=0.001] Epoch 1986/4000: train_loss=2.1085  test_loss=2.2161  λ_max=6.7701\n",
      "[SGD | lr=0.001] Epoch 1987/4000: train_loss=2.1087  test_loss=2.2161  λ_max=7.0795\n",
      "[SGD | lr=0.001] Iter 31800: loss=2.1099\n",
      "[SGD | lr=0.001] Epoch 1988/4000: train_loss=2.1081  test_loss=2.2161  λ_max=6.9324\n",
      "[SGD | lr=0.001] Epoch 1989/4000: train_loss=2.1081  test_loss=2.2161  λ_max=6.7146\n",
      "[SGD | lr=0.001] Epoch 1990/4000: train_loss=2.1081  test_loss=2.2161  λ_max=6.9366\n",
      "[SGD | lr=0.001] Epoch 1991/4000: train_loss=2.1079  test_loss=2.2162  λ_max=6.8445\n",
      "[SGD | lr=0.001] Epoch 1992/4000: train_loss=2.1079  test_loss=2.2162  λ_max=6.9149\n",
      "[SGD | lr=0.001] Epoch 1993/4000: train_loss=2.1076  test_loss=2.2162  λ_max=7.1861\n",
      "[SGD | lr=0.001] Iter 31900: loss=2.1027\n",
      "[SGD | lr=0.001] Epoch 1994/4000: train_loss=2.1074  test_loss=2.2162  λ_max=6.8852\n",
      "[SGD | lr=0.001] Epoch 1995/4000: train_loss=2.1074  test_loss=2.2162  λ_max=7.2255\n",
      "[SGD | lr=0.001] Epoch 1996/4000: train_loss=2.1074  test_loss=2.2162  λ_max=6.9855\n",
      "[SGD | lr=0.001] Epoch 1997/4000: train_loss=2.1069  test_loss=2.2163  λ_max=7.0894\n",
      "[SGD | lr=0.001] Epoch 1998/4000: train_loss=2.1072  test_loss=2.2163  λ_max=7.0814\n",
      "[SGD | lr=0.001] Epoch 1999/4000: train_loss=2.1069  test_loss=2.2163  λ_max=7.0467\n",
      "[SGD | lr=0.001] Iter 32000: loss=2.1086\n",
      "[SGD | lr=0.001] Epoch 2000/4000: train_loss=2.1068  test_loss=2.2163  λ_max=7.2161\n",
      "[SGD | lr=0.001] Epoch 2001/4000: train_loss=2.1068  test_loss=2.2163  λ_max=7.0658\n",
      "[SGD | lr=0.001] Epoch 2002/4000: train_loss=2.1065  test_loss=2.2163  λ_max=7.1961\n",
      "[SGD | lr=0.001] Epoch 2003/4000: train_loss=2.1064  test_loss=2.2164  λ_max=7.1745\n",
      "[SGD | lr=0.001] Epoch 2004/4000: train_loss=2.1063  test_loss=2.2164  λ_max=7.1267\n",
      "[SGD | lr=0.001] Epoch 2005/4000: train_loss=2.1063  test_loss=2.2164  λ_max=7.2844\n",
      "[SGD | lr=0.001] Epoch 2006/4000: train_loss=2.1060  test_loss=2.2164  λ_max=7.3048\n",
      "[SGD | lr=0.001] Iter 32100: loss=2.1053\n",
      "[SGD | lr=0.001] Epoch 2007/4000: train_loss=2.1060  test_loss=2.2164  λ_max=6.8108\n",
      "[SGD | lr=0.001] Epoch 2008/4000: train_loss=2.1058  test_loss=2.2164  λ_max=6.7925\n",
      "[SGD | lr=0.001] Epoch 2009/4000: train_loss=2.1056  test_loss=2.2164  λ_max=7.0747\n",
      "[SGD | lr=0.001] Epoch 2010/4000: train_loss=2.1056  test_loss=2.2165  λ_max=7.0525\n",
      "[SGD | lr=0.001] Epoch 2011/4000: train_loss=2.1054  test_loss=2.2165  λ_max=7.2945\n",
      "[SGD | lr=0.001] Epoch 2012/4000: train_loss=2.1054  test_loss=2.2165  λ_max=7.1829\n",
      "[SGD | lr=0.001] Iter 32200: loss=2.0976\n",
      "[SGD | lr=0.001] Epoch 2013/4000: train_loss=2.1052  test_loss=2.2165  λ_max=7.3394\n",
      "[SGD | lr=0.001] Epoch 2014/4000: train_loss=2.1051  test_loss=2.2165  λ_max=6.8501\n",
      "[SGD | lr=0.001] Epoch 2015/4000: train_loss=2.1049  test_loss=2.2165  λ_max=7.2163\n",
      "[SGD | lr=0.001] Epoch 2016/4000: train_loss=2.1047  test_loss=2.2165  λ_max=7.3569\n",
      "[SGD | lr=0.001] Epoch 2017/4000: train_loss=2.1047  test_loss=2.2166  λ_max=7.0051\n",
      "[SGD | lr=0.001] Epoch 2018/4000: train_loss=2.1046  test_loss=2.2166  λ_max=7.2158\n",
      "[SGD | lr=0.001] Iter 32300: loss=2.1044\n",
      "[SGD | lr=0.001] Epoch 2019/4000: train_loss=2.1045  test_loss=2.2166  λ_max=6.7953\n",
      "[SGD | lr=0.001] Epoch 2020/4000: train_loss=2.1044  test_loss=2.2166  λ_max=6.9699\n",
      "[SGD | lr=0.001] Epoch 2021/4000: train_loss=2.1042  test_loss=2.2166  λ_max=6.9932\n",
      "[SGD | lr=0.001] Epoch 2022/4000: train_loss=2.1040  test_loss=2.2166  λ_max=7.2682\n",
      "[SGD | lr=0.001] Epoch 2023/4000: train_loss=2.1040  test_loss=2.2166  λ_max=7.3336\n",
      "[SGD | lr=0.001] Epoch 2024/4000: train_loss=2.1037  test_loss=2.2166  λ_max=7.1513\n",
      "[SGD | lr=0.001] Iter 32400: loss=2.1074\n",
      "[SGD | lr=0.001] Epoch 2025/4000: train_loss=2.1038  test_loss=2.2167  λ_max=7.0645\n",
      "[SGD | lr=0.001] Epoch 2026/4000: train_loss=2.1036  test_loss=2.2167  λ_max=7.3844\n",
      "[SGD | lr=0.001] Epoch 2027/4000: train_loss=2.1035  test_loss=2.2167  λ_max=7.1947\n",
      "[SGD | lr=0.001] Epoch 2028/4000: train_loss=2.1031  test_loss=2.2167  λ_max=7.0425\n",
      "[SGD | lr=0.001] Epoch 2029/4000: train_loss=2.1032  test_loss=2.2167  λ_max=7.0159\n",
      "[SGD | lr=0.001] Epoch 2030/4000: train_loss=2.1031  test_loss=2.2167  λ_max=7.3774\n",
      "[SGD | lr=0.001] Epoch 2031/4000: train_loss=2.1030  test_loss=2.2167  λ_max=7.0918\n",
      "[SGD | lr=0.001] Iter 32500: loss=2.1016\n",
      "[SGD | lr=0.001] Epoch 2032/4000: train_loss=2.1028  test_loss=2.2167  λ_max=7.2238\n",
      "[SGD | lr=0.001] Epoch 2033/4000: train_loss=2.1028  test_loss=2.2168  λ_max=7.0512\n",
      "[SGD | lr=0.001] Epoch 2034/4000: train_loss=2.1027  test_loss=2.2168  λ_max=7.3776\n",
      "[SGD | lr=0.001] Epoch 2035/4000: train_loss=2.1026  test_loss=2.2168  λ_max=6.9227\n",
      "[SGD | lr=0.001] Epoch 2036/4000: train_loss=2.1023  test_loss=2.2168  λ_max=7.2171\n",
      "[SGD | lr=0.001] Epoch 2037/4000: train_loss=2.1024  test_loss=2.2168  λ_max=7.2700\n",
      "[SGD | lr=0.001] Iter 32600: loss=2.0998\n",
      "[SGD | lr=0.001] Epoch 2038/4000: train_loss=2.1021  test_loss=2.2168  λ_max=7.3519\n",
      "[SGD | lr=0.001] Epoch 2039/4000: train_loss=2.1021  test_loss=2.2168  λ_max=7.4905\n",
      "[SGD | lr=0.001] Epoch 2040/4000: train_loss=2.1017  test_loss=2.2168  λ_max=7.4432\n",
      "[SGD | lr=0.001] Epoch 2041/4000: train_loss=2.1018  test_loss=2.2168  λ_max=6.9718\n",
      "[SGD | lr=0.001] Epoch 2042/4000: train_loss=2.1016  test_loss=2.2169  λ_max=6.8265\n",
      "[SGD | lr=0.001] Epoch 2043/4000: train_loss=2.1015  test_loss=2.2169  λ_max=7.3388\n",
      "[SGD | lr=0.001] Iter 32700: loss=2.0976\n",
      "[SGD | lr=0.001] Epoch 2044/4000: train_loss=2.1015  test_loss=2.2169  λ_max=7.4105\n",
      "[SGD | lr=0.001] Epoch 2045/4000: train_loss=2.1012  test_loss=2.2169  λ_max=7.3463\n",
      "[SGD | lr=0.001] Epoch 2046/4000: train_loss=2.1010  test_loss=2.2169  λ_max=7.0944\n",
      "[SGD | lr=0.001] Epoch 2047/4000: train_loss=2.1008  test_loss=2.2169  λ_max=7.4705\n",
      "[SGD | lr=0.001] Epoch 2048/4000: train_loss=2.1010  test_loss=2.2169  λ_max=7.4254\n",
      "[SGD | lr=0.001] Epoch 2049/4000: train_loss=2.1007  test_loss=2.2170  λ_max=7.1048\n",
      "[SGD | lr=0.001] Iter 32800: loss=2.0924\n",
      "[SGD | lr=0.001] Epoch 2050/4000: train_loss=2.1004  test_loss=2.2170  λ_max=7.4305\n",
      "[SGD | lr=0.001] Epoch 2051/4000: train_loss=2.1004  test_loss=2.2170  λ_max=7.2066\n",
      "[SGD | lr=0.001] Epoch 2052/4000: train_loss=2.1003  test_loss=2.2170  λ_max=7.0774\n",
      "[SGD | lr=0.001] Epoch 2053/4000: train_loss=2.1000  test_loss=2.2170  λ_max=7.2813\n",
      "[SGD | lr=0.001] Epoch 2054/4000: train_loss=2.1000  test_loss=2.2170  λ_max=6.7273\n",
      "[SGD | lr=0.001] Epoch 2055/4000: train_loss=2.1000  test_loss=2.2170  λ_max=7.2577\n",
      "[SGD | lr=0.001] Epoch 2056/4000: train_loss=2.0998  test_loss=2.2171  λ_max=7.3664\n",
      "[SGD | lr=0.001] Iter 32900: loss=2.1003\n",
      "[SGD | lr=0.001] Epoch 2057/4000: train_loss=2.0996  test_loss=2.2171  λ_max=7.2341\n",
      "[SGD | lr=0.001] Epoch 2058/4000: train_loss=2.0995  test_loss=2.2171  λ_max=7.4912\n",
      "[SGD | lr=0.001] Epoch 2059/4000: train_loss=2.0995  test_loss=2.2171  λ_max=7.1527\n",
      "[SGD | lr=0.001] Epoch 2060/4000: train_loss=2.0995  test_loss=2.2171  λ_max=7.3953\n",
      "[SGD | lr=0.001] Epoch 2061/4000: train_loss=2.0991  test_loss=2.2171  λ_max=7.3826\n",
      "[SGD | lr=0.001] Epoch 2062/4000: train_loss=2.0990  test_loss=2.2171  λ_max=7.2067\n",
      "[SGD | lr=0.001] Iter 33000: loss=2.1072\n",
      "[SGD | lr=0.001] Epoch 2063/4000: train_loss=2.0988  test_loss=2.2171  λ_max=7.6047\n",
      "[SGD | lr=0.001] Epoch 2064/4000: train_loss=2.0989  test_loss=2.2171  λ_max=7.2710\n",
      "[SGD | lr=0.001] Epoch 2065/4000: train_loss=2.0987  test_loss=2.2172  λ_max=7.2662\n",
      "[SGD | lr=0.001] Epoch 2066/4000: train_loss=2.0984  test_loss=2.2172  λ_max=7.6234\n",
      "[SGD | lr=0.001] Epoch 2067/4000: train_loss=2.0985  test_loss=2.2172  λ_max=7.4741\n",
      "[SGD | lr=0.001] Epoch 2068/4000: train_loss=2.0981  test_loss=2.2172  λ_max=7.5385\n",
      "[SGD | lr=0.001] Iter 33100: loss=2.0987\n",
      "[SGD | lr=0.001] Epoch 2069/4000: train_loss=2.0982  test_loss=2.2172  λ_max=7.1887\n",
      "[SGD | lr=0.001] Epoch 2070/4000: train_loss=2.0980  test_loss=2.2172  λ_max=7.1897\n",
      "[SGD | lr=0.001] Epoch 2071/4000: train_loss=2.0979  test_loss=2.2172  λ_max=7.5734\n",
      "[SGD | lr=0.001] Epoch 2072/4000: train_loss=2.0978  test_loss=2.2172  λ_max=7.2667\n",
      "[SGD | lr=0.001] Epoch 2073/4000: train_loss=2.0977  test_loss=2.2172  λ_max=6.9166\n",
      "[SGD | lr=0.001] Epoch 2074/4000: train_loss=2.0974  test_loss=2.2173  λ_max=7.5566\n",
      "[SGD | lr=0.001] Iter 33200: loss=2.0931\n",
      "[SGD | lr=0.001] Epoch 2075/4000: train_loss=2.0973  test_loss=2.2173  λ_max=7.5415\n",
      "[SGD | lr=0.001] Epoch 2076/4000: train_loss=2.0973  test_loss=2.2173  λ_max=7.5915\n",
      "[SGD | lr=0.001] Epoch 2077/4000: train_loss=2.0971  test_loss=2.2173  λ_max=7.2064\n",
      "[SGD | lr=0.001] Epoch 2078/4000: train_loss=2.0970  test_loss=2.2173  λ_max=7.3957\n",
      "[SGD | lr=0.001] Epoch 2079/4000: train_loss=2.0967  test_loss=2.2173  λ_max=7.5972\n",
      "[SGD | lr=0.001] Epoch 2080/4000: train_loss=2.0967  test_loss=2.2173  λ_max=7.5510\n",
      "[SGD | lr=0.001] Epoch 2081/4000: train_loss=2.0965  test_loss=2.2173  λ_max=7.0501\n",
      "[SGD | lr=0.001] Iter 33300: loss=2.0965\n",
      "[SGD | lr=0.001] Epoch 2082/4000: train_loss=2.0967  test_loss=2.2173  λ_max=7.5241\n",
      "[SGD | lr=0.001] Epoch 2083/4000: train_loss=2.0961  test_loss=2.2174  λ_max=7.4287\n",
      "[SGD | lr=0.001] Epoch 2084/4000: train_loss=2.0960  test_loss=2.2174  λ_max=7.2938\n",
      "[SGD | lr=0.001] Epoch 2085/4000: train_loss=2.0962  test_loss=2.2174  λ_max=7.3228\n",
      "[SGD | lr=0.001] Epoch 2086/4000: train_loss=2.0957  test_loss=2.2174  λ_max=7.3554\n",
      "[SGD | lr=0.001] Epoch 2087/4000: train_loss=2.0960  test_loss=2.2174  λ_max=7.4890\n",
      "[SGD | lr=0.001] Iter 33400: loss=2.0902\n",
      "[SGD | lr=0.001] Epoch 2088/4000: train_loss=2.0957  test_loss=2.2174  λ_max=7.2658\n",
      "[SGD | lr=0.001] Epoch 2089/4000: train_loss=2.0955  test_loss=2.2174  λ_max=7.5265\n",
      "[SGD | lr=0.001] Epoch 2090/4000: train_loss=2.0955  test_loss=2.2174  λ_max=7.6313\n",
      "[SGD | lr=0.001] Epoch 2091/4000: train_loss=2.0952  test_loss=2.2175  λ_max=7.5782\n",
      "[SGD | lr=0.001] Epoch 2092/4000: train_loss=2.0950  test_loss=2.2175  λ_max=7.4029\n",
      "[SGD | lr=0.001] Epoch 2093/4000: train_loss=2.0950  test_loss=2.2175  λ_max=7.7690\n",
      "[SGD | lr=0.001] Iter 33500: loss=2.0966\n",
      "[SGD | lr=0.001] Epoch 2094/4000: train_loss=2.0949  test_loss=2.2175  λ_max=7.6185\n",
      "[SGD | lr=0.001] Epoch 2095/4000: train_loss=2.0947  test_loss=2.2175  λ_max=7.3486\n",
      "[SGD | lr=0.001] Epoch 2096/4000: train_loss=2.0947  test_loss=2.2175  λ_max=7.3334\n",
      "[SGD | lr=0.001] Epoch 2097/4000: train_loss=2.0945  test_loss=2.2175  λ_max=7.5825\n",
      "[SGD | lr=0.001] Epoch 2098/4000: train_loss=2.0943  test_loss=2.2175  λ_max=7.5960\n",
      "[SGD | lr=0.001] Epoch 2099/4000: train_loss=2.0940  test_loss=2.2175  λ_max=7.2675\n",
      "[SGD | lr=0.001] Iter 33600: loss=2.0964\n",
      "[SGD | lr=0.001] Epoch 2100/4000: train_loss=2.0941  test_loss=2.2175  λ_max=7.8020\n",
      "[SGD | lr=0.001] Epoch 2101/4000: train_loss=2.0938  test_loss=2.2176  λ_max=7.5484\n",
      "[SGD | lr=0.001] Epoch 2102/4000: train_loss=2.0940  test_loss=2.2176  λ_max=7.3212\n",
      "[SGD | lr=0.001] Epoch 2103/4000: train_loss=2.0936  test_loss=2.2176  λ_max=7.3022\n",
      "[SGD | lr=0.001] Epoch 2104/4000: train_loss=2.0935  test_loss=2.2176  λ_max=7.7004\n",
      "[SGD | lr=0.001] Epoch 2105/4000: train_loss=2.0935  test_loss=2.2176  λ_max=7.8035\n",
      "[SGD | lr=0.001] Epoch 2106/4000: train_loss=2.0934  test_loss=2.2176  λ_max=7.6376\n",
      "[SGD | lr=0.001] Iter 33700: loss=2.0982\n",
      "[SGD | lr=0.001] Epoch 2107/4000: train_loss=2.0931  test_loss=2.2176  λ_max=7.0902\n",
      "[SGD | lr=0.001] Epoch 2108/4000: train_loss=2.0932  test_loss=2.2176  λ_max=7.2893\n",
      "[SGD | lr=0.001] Epoch 2109/4000: train_loss=2.0930  test_loss=2.2176  λ_max=7.5370\n",
      "[SGD | lr=0.001] Epoch 2110/4000: train_loss=2.0927  test_loss=2.2177  λ_max=7.2460\n",
      "[SGD | lr=0.001] Epoch 2111/4000: train_loss=2.0926  test_loss=2.2177  λ_max=7.8102\n",
      "[SGD | lr=0.001] Epoch 2112/4000: train_loss=2.0925  test_loss=2.2177  λ_max=7.5182\n",
      "[SGD | lr=0.001] Iter 33800: loss=2.0852\n",
      "[SGD | lr=0.001] Epoch 2113/4000: train_loss=2.0923  test_loss=2.2177  λ_max=7.5754\n",
      "[SGD | lr=0.001] Epoch 2114/4000: train_loss=2.0921  test_loss=2.2177  λ_max=7.6882\n",
      "[SGD | lr=0.001] Epoch 2115/4000: train_loss=2.0919  test_loss=2.2177  λ_max=7.5712\n",
      "[SGD | lr=0.001] Epoch 2116/4000: train_loss=2.0920  test_loss=2.2177  λ_max=7.6818\n",
      "[SGD | lr=0.001] Epoch 2117/4000: train_loss=2.0919  test_loss=2.2177  λ_max=7.5313\n",
      "[SGD | lr=0.001] Epoch 2118/4000: train_loss=2.0917  test_loss=2.2177  λ_max=7.8576\n",
      "[SGD | lr=0.001] Iter 33900: loss=2.0893\n",
      "[SGD | lr=0.001] Epoch 2119/4000: train_loss=2.0914  test_loss=2.2177  λ_max=7.7188\n",
      "[SGD | lr=0.001] Epoch 2120/4000: train_loss=2.0912  test_loss=2.2178  λ_max=7.8187\n",
      "[SGD | lr=0.001] Epoch 2121/4000: train_loss=2.0914  test_loss=2.2178  λ_max=7.7126\n",
      "[SGD | lr=0.001] Epoch 2122/4000: train_loss=2.0911  test_loss=2.2178  λ_max=7.7512\n",
      "[SGD | lr=0.001] Epoch 2123/4000: train_loss=2.0908  test_loss=2.2178  λ_max=7.4190\n",
      "[SGD | lr=0.001] Epoch 2124/4000: train_loss=2.0909  test_loss=2.2178  λ_max=7.7005\n",
      "[SGD | lr=0.001] Iter 34000: loss=2.0838\n",
      "[SGD | lr=0.001] Epoch 2125/4000: train_loss=2.0906  test_loss=2.2178  λ_max=7.6506\n",
      "[SGD | lr=0.001] Epoch 2126/4000: train_loss=2.0907  test_loss=2.2178  λ_max=7.7952\n",
      "[SGD | lr=0.001] Epoch 2127/4000: train_loss=2.0905  test_loss=2.2178  λ_max=7.3270\n",
      "[SGD | lr=0.001] Epoch 2128/4000: train_loss=2.0905  test_loss=2.2178  λ_max=7.5765\n",
      "[SGD | lr=0.001] Epoch 2129/4000: train_loss=2.0902  test_loss=2.2179  λ_max=7.7306\n",
      "[SGD | lr=0.001] Epoch 2130/4000: train_loss=2.0900  test_loss=2.2179  λ_max=7.6051\n",
      "[SGD | lr=0.001] Epoch 2131/4000: train_loss=2.0899  test_loss=2.2179  λ_max=7.6833\n",
      "[SGD | lr=0.001] Iter 34100: loss=2.0895\n",
      "[SGD | lr=0.001] Epoch 2132/4000: train_loss=2.0897  test_loss=2.2179  λ_max=7.8327\n",
      "[SGD | lr=0.001] Epoch 2133/4000: train_loss=2.0896  test_loss=2.2179  λ_max=7.6217\n",
      "[SGD | lr=0.001] Epoch 2134/4000: train_loss=2.0895  test_loss=2.2179  λ_max=7.5480\n",
      "[SGD | lr=0.001] Epoch 2135/4000: train_loss=2.0898  test_loss=2.2179  λ_max=7.9806\n",
      "[SGD | lr=0.001] Epoch 2136/4000: train_loss=2.0893  test_loss=2.2179  λ_max=7.9494\n",
      "[SGD | lr=0.001] Epoch 2137/4000: train_loss=2.0888  test_loss=2.2179  λ_max=7.7351\n",
      "[SGD | lr=0.001] Iter 34200: loss=2.0879\n",
      "[SGD | lr=0.001] Epoch 2138/4000: train_loss=2.0894  test_loss=2.2179  λ_max=7.5533\n",
      "[SGD | lr=0.001] Epoch 2139/4000: train_loss=2.0888  test_loss=2.2179  λ_max=7.8651\n",
      "[SGD | lr=0.001] Epoch 2140/4000: train_loss=2.0888  test_loss=2.2179  λ_max=7.9980\n",
      "[SGD | lr=0.001] Epoch 2141/4000: train_loss=2.0886  test_loss=2.2179  λ_max=7.7061\n",
      "[SGD | lr=0.001] Epoch 2142/4000: train_loss=2.0884  test_loss=2.2180  λ_max=7.9006\n",
      "[SGD | lr=0.001] Epoch 2143/4000: train_loss=2.0881  test_loss=2.2180  λ_max=7.5781\n",
      "[SGD | lr=0.001] Iter 34300: loss=2.0924\n",
      "[SGD | lr=0.001] Epoch 2144/4000: train_loss=2.0882  test_loss=2.2180  λ_max=7.8496\n",
      "[SGD | lr=0.001] Epoch 2145/4000: train_loss=2.0879  test_loss=2.2180  λ_max=7.9194\n",
      "[SGD | lr=0.001] Epoch 2146/4000: train_loss=2.0878  test_loss=2.2180  λ_max=7.7394\n",
      "[SGD | lr=0.001] Epoch 2147/4000: train_loss=2.0876  test_loss=2.2180  λ_max=7.7067\n",
      "[SGD | lr=0.001] Epoch 2148/4000: train_loss=2.0875  test_loss=2.2180  λ_max=7.6257\n",
      "[SGD | lr=0.001] Epoch 2149/4000: train_loss=2.0874  test_loss=2.2180  λ_max=7.5789\n",
      "[SGD | lr=0.001] Iter 34400: loss=2.0934\n",
      "[SGD | lr=0.001] Epoch 2150/4000: train_loss=2.0875  test_loss=2.2180  λ_max=7.7344\n",
      "[SGD | lr=0.001] Epoch 2151/4000: train_loss=2.0872  test_loss=2.2180  λ_max=7.4781\n",
      "[SGD | lr=0.001] Epoch 2152/4000: train_loss=2.0873  test_loss=2.2180  λ_max=7.8038\n",
      "[SGD | lr=0.001] Epoch 2153/4000: train_loss=2.0869  test_loss=2.2180  λ_max=8.0591\n",
      "[SGD | lr=0.001] Epoch 2154/4000: train_loss=2.0869  test_loss=2.2180  λ_max=8.0735\n",
      "[SGD | lr=0.001] Epoch 2155/4000: train_loss=2.0869  test_loss=2.2181  λ_max=7.5827\n",
      "[SGD | lr=0.001] Epoch 2156/4000: train_loss=2.0863  test_loss=2.2181  λ_max=7.8699\n",
      "[SGD | lr=0.001] Iter 34500: loss=2.0884\n",
      "[SGD | lr=0.001] Epoch 2157/4000: train_loss=2.0863  test_loss=2.2181  λ_max=7.9687\n",
      "[SGD | lr=0.001] Epoch 2158/4000: train_loss=2.0861  test_loss=2.2181  λ_max=7.8297\n",
      "[SGD | lr=0.001] Epoch 2159/4000: train_loss=2.0861  test_loss=2.2181  λ_max=7.9104\n",
      "[SGD | lr=0.001] Epoch 2160/4000: train_loss=2.0858  test_loss=2.2181  λ_max=7.5558\n",
      "[SGD | lr=0.001] Epoch 2161/4000: train_loss=2.0856  test_loss=2.2181  λ_max=7.7797\n",
      "[SGD | lr=0.001] Epoch 2162/4000: train_loss=2.0855  test_loss=2.2181  λ_max=7.9337\n",
      "[SGD | lr=0.001] Iter 34600: loss=2.0874\n",
      "[SGD | lr=0.001] Epoch 2163/4000: train_loss=2.0853  test_loss=2.2181  λ_max=8.0689\n",
      "[SGD | lr=0.001] Epoch 2164/4000: train_loss=2.0854  test_loss=2.2181  λ_max=7.9748\n",
      "[SGD | lr=0.001] Epoch 2165/4000: train_loss=2.0853  test_loss=2.2181  λ_max=7.8355\n",
      "[SGD | lr=0.001] Epoch 2166/4000: train_loss=2.0853  test_loss=2.2181  λ_max=7.9148\n",
      "[SGD | lr=0.001] Epoch 2167/4000: train_loss=2.0850  test_loss=2.2181  λ_max=8.0696\n",
      "[SGD | lr=0.001] Epoch 2168/4000: train_loss=2.0847  test_loss=2.2181  λ_max=8.1341\n",
      "[SGD | lr=0.001] Iter 34700: loss=2.0822\n",
      "[SGD | lr=0.001] Epoch 2169/4000: train_loss=2.0846  test_loss=2.2181  λ_max=7.9751\n",
      "[SGD | lr=0.001] Epoch 2170/4000: train_loss=2.0845  test_loss=2.2181  λ_max=8.1047\n",
      "[SGD | lr=0.001] Epoch 2171/4000: train_loss=2.0845  test_loss=2.2181  λ_max=7.2722\n",
      "[SGD | lr=0.001] Epoch 2172/4000: train_loss=2.0841  test_loss=2.2182  λ_max=7.5473\n",
      "[SGD | lr=0.001] Epoch 2173/4000: train_loss=2.0840  test_loss=2.2182  λ_max=7.9851\n",
      "[SGD | lr=0.001] Epoch 2174/4000: train_loss=2.0839  test_loss=2.2182  λ_max=8.0723\n",
      "[SGD | lr=0.001] Iter 34800: loss=2.0852\n",
      "[SGD | lr=0.001] Epoch 2175/4000: train_loss=2.0839  test_loss=2.2182  λ_max=7.9643\n",
      "[SGD | lr=0.001] Epoch 2176/4000: train_loss=2.0836  test_loss=2.2182  λ_max=8.0487\n",
      "[SGD | lr=0.001] Epoch 2177/4000: train_loss=2.0834  test_loss=2.2182  λ_max=8.2313\n",
      "[SGD | lr=0.001] Epoch 2178/4000: train_loss=2.0835  test_loss=2.2182  λ_max=8.1905\n",
      "[SGD | lr=0.001] Epoch 2179/4000: train_loss=2.0834  test_loss=2.2182  λ_max=7.7198\n",
      "[SGD | lr=0.001] Epoch 2180/4000: train_loss=2.0830  test_loss=2.2182  λ_max=8.0661\n",
      "[SGD | lr=0.001] Epoch 2181/4000: train_loss=2.0830  test_loss=2.2182  λ_max=7.8794\n",
      "[SGD | lr=0.001] Iter 34900: loss=2.0847\n",
      "[SGD | lr=0.001] Epoch 2182/4000: train_loss=2.0830  test_loss=2.2182  λ_max=7.7777\n",
      "[SGD | lr=0.001] Epoch 2183/4000: train_loss=2.0827  test_loss=2.2182  λ_max=8.2313\n",
      "[SGD | lr=0.001] Epoch 2184/4000: train_loss=2.0826  test_loss=2.2182  λ_max=7.9435\n",
      "[SGD | lr=0.001] Epoch 2185/4000: train_loss=2.0825  test_loss=2.2182  λ_max=7.7683\n",
      "[SGD | lr=0.001] Epoch 2186/4000: train_loss=2.0823  test_loss=2.2182  λ_max=7.9748\n",
      "[SGD | lr=0.001] Epoch 2187/4000: train_loss=2.0823  test_loss=2.2182  λ_max=8.0757\n",
      "[SGD | lr=0.001] Iter 35000: loss=2.0835\n",
      "[SGD | lr=0.001] Epoch 2188/4000: train_loss=2.0819  test_loss=2.2182  λ_max=7.6495\n",
      "[SGD | lr=0.001] Epoch 2189/4000: train_loss=2.0819  test_loss=2.2182  λ_max=7.8876\n",
      "[SGD | lr=0.001] Epoch 2190/4000: train_loss=2.0819  test_loss=2.2182  λ_max=8.1291\n",
      "[SGD | lr=0.001] Epoch 2191/4000: train_loss=2.0817  test_loss=2.2182  λ_max=7.9113\n",
      "[SGD | lr=0.001] Epoch 2192/4000: train_loss=2.0815  test_loss=2.2182  λ_max=7.7240\n",
      "[SGD | lr=0.001] Epoch 2193/4000: train_loss=2.0816  test_loss=2.2182  λ_max=8.2015\n",
      "[SGD | lr=0.001] Iter 35100: loss=2.0801\n",
      "[SGD | lr=0.001] Epoch 2194/4000: train_loss=2.0813  test_loss=2.2182  λ_max=7.8983\n",
      "[SGD | lr=0.001] Epoch 2195/4000: train_loss=2.0812  test_loss=2.2183  λ_max=8.2834\n",
      "[SGD | lr=0.001] Epoch 2196/4000: train_loss=2.0808  test_loss=2.2183  λ_max=8.0785\n",
      "[SGD | lr=0.001] Epoch 2197/4000: train_loss=2.0808  test_loss=2.2183  λ_max=8.1371\n",
      "[SGD | lr=0.001] Epoch 2198/4000: train_loss=2.0808  test_loss=2.2183  λ_max=7.9132\n",
      "[SGD | lr=0.001] Epoch 2199/4000: train_loss=2.0805  test_loss=2.2183  λ_max=8.2174\n",
      "[SGD | lr=0.001] Iter 35200: loss=2.0788\n",
      "[SGD | lr=0.001] Epoch 2200/4000: train_loss=2.0803  test_loss=2.2183  λ_max=7.9099\n",
      "[SGD | lr=0.001] Epoch 2201/4000: train_loss=2.0803  test_loss=2.2183  λ_max=7.7112\n",
      "[SGD | lr=0.001] Epoch 2202/4000: train_loss=2.0799  test_loss=2.2183  λ_max=8.2473\n",
      "[SGD | lr=0.001] Epoch 2203/4000: train_loss=2.0799  test_loss=2.2183  λ_max=7.4694\n",
      "[SGD | lr=0.001] Epoch 2204/4000: train_loss=2.0797  test_loss=2.2183  λ_max=7.8453\n",
      "[SGD | lr=0.001] Epoch 2205/4000: train_loss=2.0798  test_loss=2.2183  λ_max=8.2951\n",
      "[SGD | lr=0.001] Epoch 2206/4000: train_loss=2.0796  test_loss=2.2183  λ_max=8.2003\n",
      "[SGD | lr=0.001] Iter 35300: loss=2.0811\n",
      "[SGD | lr=0.001] Epoch 2207/4000: train_loss=2.0793  test_loss=2.2183  λ_max=7.9680\n",
      "[SGD | lr=0.001] Epoch 2208/4000: train_loss=2.0793  test_loss=2.2183  λ_max=8.0372\n",
      "[SGD | lr=0.001] Epoch 2209/4000: train_loss=2.0793  test_loss=2.2183  λ_max=7.8594\n",
      "[SGD | lr=0.001] Epoch 2210/4000: train_loss=2.0789  test_loss=2.2183  λ_max=7.9800\n",
      "[SGD | lr=0.001] Epoch 2211/4000: train_loss=2.0790  test_loss=2.2183  λ_max=8.2832\n",
      "[SGD | lr=0.001] Epoch 2212/4000: train_loss=2.0788  test_loss=2.2183  λ_max=7.9348\n",
      "[SGD | lr=0.001] Iter 35400: loss=2.0787\n",
      "[SGD | lr=0.001] Epoch 2213/4000: train_loss=2.0786  test_loss=2.2183  λ_max=7.6523\n",
      "[SGD | lr=0.001] Epoch 2214/4000: train_loss=2.0782  test_loss=2.2183  λ_max=7.9268\n",
      "[SGD | lr=0.001] Epoch 2215/4000: train_loss=2.0783  test_loss=2.2183  λ_max=7.6117\n",
      "[SGD | lr=0.001] Epoch 2216/4000: train_loss=2.0781  test_loss=2.2183  λ_max=7.7458\n",
      "[SGD | lr=0.001] Epoch 2217/4000: train_loss=2.0781  test_loss=2.2183  λ_max=7.8918\n",
      "[SGD | lr=0.001] Epoch 2218/4000: train_loss=2.0780  test_loss=2.2183  λ_max=8.3258\n",
      "[SGD | lr=0.001] Iter 35500: loss=2.0795\n",
      "[SGD | lr=0.001] Epoch 2219/4000: train_loss=2.0776  test_loss=2.2183  λ_max=8.0839\n",
      "[SGD | lr=0.001] Epoch 2220/4000: train_loss=2.0774  test_loss=2.2183  λ_max=8.3581\n",
      "[SGD | lr=0.001] Epoch 2221/4000: train_loss=2.0774  test_loss=2.2183  λ_max=8.2264\n",
      "[SGD | lr=0.001] Epoch 2222/4000: train_loss=2.0773  test_loss=2.2183  λ_max=8.0423\n",
      "[SGD | lr=0.001] Epoch 2223/4000: train_loss=2.0774  test_loss=2.2183  λ_max=8.0624\n",
      "[SGD | lr=0.001] Epoch 2224/4000: train_loss=2.0767  test_loss=2.2183  λ_max=8.2586\n",
      "[SGD | lr=0.001] Iter 35600: loss=2.0701\n",
      "[SGD | lr=0.001] Epoch 2225/4000: train_loss=2.0767  test_loss=2.2183  λ_max=8.0112\n",
      "[SGD | lr=0.001] Epoch 2226/4000: train_loss=2.0768  test_loss=2.2183  λ_max=8.2380\n",
      "[SGD | lr=0.001] Epoch 2227/4000: train_loss=2.0764  test_loss=2.2183  λ_max=7.9822\n",
      "[SGD | lr=0.001] Epoch 2228/4000: train_loss=2.0765  test_loss=2.2183  λ_max=8.0921\n",
      "[SGD | lr=0.001] Epoch 2229/4000: train_loss=2.0761  test_loss=2.2183  λ_max=8.3845\n",
      "[SGD | lr=0.001] Epoch 2230/4000: train_loss=2.0762  test_loss=2.2183  λ_max=8.1142\n",
      "[SGD | lr=0.001] Epoch 2231/4000: train_loss=2.0762  test_loss=2.2183  λ_max=7.9212\n",
      "[SGD | lr=0.001] Iter 35700: loss=2.0788\n",
      "[SGD | lr=0.001] Epoch 2232/4000: train_loss=2.0758  test_loss=2.2184  λ_max=8.1646\n",
      "[SGD | lr=0.001] Epoch 2233/4000: train_loss=2.0757  test_loss=2.2184  λ_max=8.2627\n",
      "[SGD | lr=0.001] Epoch 2234/4000: train_loss=2.0757  test_loss=2.2184  λ_max=8.5026\n",
      "[SGD | lr=0.001] Epoch 2235/4000: train_loss=2.0752  test_loss=2.2184  λ_max=8.1126\n",
      "[SGD | lr=0.001] Epoch 2236/4000: train_loss=2.0754  test_loss=2.2183  λ_max=8.1292\n",
      "[SGD | lr=0.001] Epoch 2237/4000: train_loss=2.0749  test_loss=2.2183  λ_max=8.3460\n",
      "[SGD | lr=0.001] Iter 35800: loss=2.0756\n",
      "[SGD | lr=0.001] Epoch 2238/4000: train_loss=2.0750  test_loss=2.2183  λ_max=8.2906\n",
      "[SGD | lr=0.001] Epoch 2239/4000: train_loss=2.0748  test_loss=2.2184  λ_max=8.2948\n",
      "[SGD | lr=0.001] Epoch 2240/4000: train_loss=2.0748  test_loss=2.2184  λ_max=8.4670\n",
      "[SGD | lr=0.001] Epoch 2241/4000: train_loss=2.0744  test_loss=2.2184  λ_max=7.9390\n",
      "[SGD | lr=0.001] Epoch 2242/4000: train_loss=2.0742  test_loss=2.2184  λ_max=7.9637\n",
      "[SGD | lr=0.001] Epoch 2243/4000: train_loss=2.0744  test_loss=2.2184  λ_max=8.1504\n",
      "[SGD | lr=0.001] Iter 35900: loss=2.0715\n",
      "[SGD | lr=0.001] Epoch 2244/4000: train_loss=2.0740  test_loss=2.2184  λ_max=8.3881\n",
      "[SGD | lr=0.001] Epoch 2245/4000: train_loss=2.0740  test_loss=2.2184  λ_max=8.4312\n",
      "[SGD | lr=0.001] Epoch 2246/4000: train_loss=2.0737  test_loss=2.2184  λ_max=8.1614\n",
      "[SGD | lr=0.001] Epoch 2247/4000: train_loss=2.0737  test_loss=2.2184  λ_max=8.0797\n",
      "[SGD | lr=0.001] Epoch 2248/4000: train_loss=2.0735  test_loss=2.2184  λ_max=8.3189\n",
      "[SGD | lr=0.001] Epoch 2249/4000: train_loss=2.0734  test_loss=2.2184  λ_max=7.9000\n",
      "[SGD | lr=0.001] Iter 36000: loss=2.0785\n",
      "[SGD | lr=0.001] Epoch 2250/4000: train_loss=2.0734  test_loss=2.2184  λ_max=8.0956\n",
      "[SGD | lr=0.001] Epoch 2251/4000: train_loss=2.0732  test_loss=2.2184  λ_max=8.0358\n",
      "[SGD | lr=0.001] Epoch 2252/4000: train_loss=2.0728  test_loss=2.2184  λ_max=8.1883\n",
      "[SGD | lr=0.001] Epoch 2253/4000: train_loss=2.0727  test_loss=2.2184  λ_max=7.8570\n",
      "[SGD | lr=0.001] Epoch 2254/4000: train_loss=2.0727  test_loss=2.2184  λ_max=7.7446\n",
      "[SGD | lr=0.001] Epoch 2255/4000: train_loss=2.0726  test_loss=2.2184  λ_max=8.4010\n",
      "[SGD | lr=0.001] Epoch 2256/4000: train_loss=2.0725  test_loss=2.2184  λ_max=8.4595\n",
      "[SGD | lr=0.001] Iter 36100: loss=2.0695\n",
      "[SGD | lr=0.001] Epoch 2257/4000: train_loss=2.0722  test_loss=2.2184  λ_max=8.3659\n",
      "[SGD | lr=0.001] Epoch 2258/4000: train_loss=2.0718  test_loss=2.2184  λ_max=8.3807\n",
      "[SGD | lr=0.001] Epoch 2259/4000: train_loss=2.0722  test_loss=2.2184  λ_max=8.5040\n",
      "[SGD | lr=0.001] Epoch 2260/4000: train_loss=2.0718  test_loss=2.2184  λ_max=7.9684\n",
      "[SGD | lr=0.001] Epoch 2261/4000: train_loss=2.0716  test_loss=2.2184  λ_max=8.1464\n",
      "[SGD | lr=0.001] Epoch 2262/4000: train_loss=2.0715  test_loss=2.2184  λ_max=8.6150\n",
      "[SGD | lr=0.001] Iter 36200: loss=2.0743\n",
      "[SGD | lr=0.001] Epoch 2263/4000: train_loss=2.0714  test_loss=2.2184  λ_max=8.3518\n",
      "[SGD | lr=0.001] Epoch 2264/4000: train_loss=2.0711  test_loss=2.2184  λ_max=8.6541\n",
      "[SGD | lr=0.001] Epoch 2265/4000: train_loss=2.0712  test_loss=2.2184  λ_max=8.6459\n",
      "[SGD | lr=0.001] Epoch 2266/4000: train_loss=2.0709  test_loss=2.2184  λ_max=8.0220\n",
      "[SGD | lr=0.001] Epoch 2267/4000: train_loss=2.0709  test_loss=2.2184  λ_max=8.3752\n",
      "[SGD | lr=0.001] Epoch 2268/4000: train_loss=2.0707  test_loss=2.2184  λ_max=8.4435\n",
      "[SGD | lr=0.001] Iter 36300: loss=2.0689\n",
      "[SGD | lr=0.001] Epoch 2269/4000: train_loss=2.0704  test_loss=2.2184  λ_max=8.3577\n",
      "[SGD | lr=0.001] Epoch 2270/4000: train_loss=2.0701  test_loss=2.2184  λ_max=8.2060\n",
      "[SGD | lr=0.001] Epoch 2271/4000: train_loss=2.0702  test_loss=2.2184  λ_max=8.3001\n",
      "[SGD | lr=0.001] Epoch 2272/4000: train_loss=2.0700  test_loss=2.2184  λ_max=8.2259\n",
      "[SGD | lr=0.001] Epoch 2273/4000: train_loss=2.0700  test_loss=2.2184  λ_max=8.6629\n",
      "[SGD | lr=0.001] Epoch 2274/4000: train_loss=2.0697  test_loss=2.2184  λ_max=8.1376\n",
      "[SGD | lr=0.001] Iter 36400: loss=2.0675\n",
      "[SGD | lr=0.001] Epoch 2275/4000: train_loss=2.0696  test_loss=2.2183  λ_max=8.3487\n",
      "[SGD | lr=0.001] Epoch 2276/4000: train_loss=2.0694  test_loss=2.2183  λ_max=8.2002\n",
      "[SGD | lr=0.001] Epoch 2277/4000: train_loss=2.0693  test_loss=2.2183  λ_max=8.6457\n",
      "[SGD | lr=0.001] Epoch 2278/4000: train_loss=2.0690  test_loss=2.2183  λ_max=8.2169\n",
      "[SGD | lr=0.001] Epoch 2279/4000: train_loss=2.0688  test_loss=2.2183  λ_max=8.3206\n",
      "[SGD | lr=0.001] Epoch 2280/4000: train_loss=2.0690  test_loss=2.2183  λ_max=8.4707\n",
      "[SGD | lr=0.001] Epoch 2281/4000: train_loss=2.0689  test_loss=2.2183  λ_max=8.3521\n",
      "[SGD | lr=0.001] Iter 36500: loss=2.0650\n",
      "[SGD | lr=0.001] Epoch 2282/4000: train_loss=2.0684  test_loss=2.2183  λ_max=8.0811\n",
      "[SGD | lr=0.001] Epoch 2283/4000: train_loss=2.0685  test_loss=2.2183  λ_max=8.1117\n",
      "[SGD | lr=0.001] Epoch 2284/4000: train_loss=2.0684  test_loss=2.2183  λ_max=8.4285\n",
      "[SGD | lr=0.001] Epoch 2285/4000: train_loss=2.0682  test_loss=2.2183  λ_max=8.2057\n",
      "[SGD | lr=0.001] Epoch 2286/4000: train_loss=2.0679  test_loss=2.2183  λ_max=8.1665\n",
      "[SGD | lr=0.001] Epoch 2287/4000: train_loss=2.0679  test_loss=2.2183  λ_max=8.4594\n",
      "[SGD | lr=0.001] Iter 36600: loss=2.0640\n",
      "[SGD | lr=0.001] Epoch 2288/4000: train_loss=2.0678  test_loss=2.2183  λ_max=8.1511\n",
      "[SGD | lr=0.001] Epoch 2289/4000: train_loss=2.0675  test_loss=2.2183  λ_max=8.5874\n",
      "[SGD | lr=0.001] Epoch 2290/4000: train_loss=2.0676  test_loss=2.2183  λ_max=8.6289\n",
      "[SGD | lr=0.001] Epoch 2291/4000: train_loss=2.0673  test_loss=2.2183  λ_max=8.4620\n",
      "[SGD | lr=0.001] Epoch 2292/4000: train_loss=2.0670  test_loss=2.2183  λ_max=8.4218\n",
      "[SGD | lr=0.001] Epoch 2293/4000: train_loss=2.0669  test_loss=2.2183  λ_max=8.7080\n",
      "[SGD | lr=0.001] Iter 36700: loss=2.0684\n",
      "[SGD | lr=0.001] Epoch 2294/4000: train_loss=2.0666  test_loss=2.2183  λ_max=8.0261\n",
      "[SGD | lr=0.001] Epoch 2295/4000: train_loss=2.0667  test_loss=2.2183  λ_max=8.5367\n",
      "[SGD | lr=0.001] Epoch 2296/4000: train_loss=2.0665  test_loss=2.2183  λ_max=8.6727\n",
      "[SGD | lr=0.001] Epoch 2297/4000: train_loss=2.0664  test_loss=2.2183  λ_max=8.4973\n",
      "[SGD | lr=0.001] Epoch 2298/4000: train_loss=2.0661  test_loss=2.2183  λ_max=8.7794\n",
      "[SGD | lr=0.001] Epoch 2299/4000: train_loss=2.0660  test_loss=2.2183  λ_max=8.1869\n",
      "[SGD | lr=0.001] Iter 36800: loss=2.0606\n",
      "[SGD | lr=0.001] Epoch 2300/4000: train_loss=2.0658  test_loss=2.2183  λ_max=8.3165\n",
      "[SGD | lr=0.001] Epoch 2301/4000: train_loss=2.0660  test_loss=2.2183  λ_max=8.5251\n",
      "[SGD | lr=0.001] Epoch 2302/4000: train_loss=2.0655  test_loss=2.2183  λ_max=8.4930\n",
      "[SGD | lr=0.001] Epoch 2303/4000: train_loss=2.0655  test_loss=2.2182  λ_max=8.3758\n",
      "[SGD | lr=0.001] Epoch 2304/4000: train_loss=2.0652  test_loss=2.2182  λ_max=8.7169\n",
      "[SGD | lr=0.001] Epoch 2305/4000: train_loss=2.0652  test_loss=2.2182  λ_max=8.5710\n",
      "[SGD | lr=0.001] Epoch 2306/4000: train_loss=2.0652  test_loss=2.2182  λ_max=8.7411\n",
      "[SGD | lr=0.001] Iter 36900: loss=2.0675\n",
      "[SGD | lr=0.001] Epoch 2307/4000: train_loss=2.0651  test_loss=2.2182  λ_max=8.6529\n",
      "[SGD | lr=0.001] Epoch 2308/4000: train_loss=2.0649  test_loss=2.2182  λ_max=8.4676\n",
      "[SGD | lr=0.001] Epoch 2309/4000: train_loss=2.0645  test_loss=2.2182  λ_max=8.8630\n",
      "[SGD | lr=0.001] Epoch 2310/4000: train_loss=2.0645  test_loss=2.2182  λ_max=8.5668\n",
      "[SGD | lr=0.001] Epoch 2311/4000: train_loss=2.0642  test_loss=2.2182  λ_max=8.6755\n",
      "[SGD | lr=0.001] Epoch 2312/4000: train_loss=2.0642  test_loss=2.2182  λ_max=8.4364\n",
      "[SGD | lr=0.001] Iter 37000: loss=2.0646\n",
      "[SGD | lr=0.001] Epoch 2313/4000: train_loss=2.0640  test_loss=2.2182  λ_max=8.5436\n",
      "[SGD | lr=0.001] Epoch 2314/4000: train_loss=2.0639  test_loss=2.2182  λ_max=8.7906\n",
      "[SGD | lr=0.001] Epoch 2315/4000: train_loss=2.0638  test_loss=2.2182  λ_max=8.4716\n",
      "[SGD | lr=0.001] Epoch 2316/4000: train_loss=2.0636  test_loss=2.2182  λ_max=8.6521\n",
      "[SGD | lr=0.001] Epoch 2317/4000: train_loss=2.0637  test_loss=2.2181  λ_max=8.5903\n",
      "[SGD | lr=0.001] Epoch 2318/4000: train_loss=2.0633  test_loss=2.2181  λ_max=8.0618\n",
      "[SGD | lr=0.001] Iter 37100: loss=2.0605\n",
      "[SGD | lr=0.001] Epoch 2319/4000: train_loss=2.0631  test_loss=2.2181  λ_max=8.5055\n",
      "[SGD | lr=0.001] Epoch 2320/4000: train_loss=2.0631  test_loss=2.2181  λ_max=8.8021\n",
      "[SGD | lr=0.001] Epoch 2321/4000: train_loss=2.0628  test_loss=2.2181  λ_max=8.2288\n",
      "[SGD | lr=0.001] Epoch 2322/4000: train_loss=2.0625  test_loss=2.2181  λ_max=8.7084\n",
      "[SGD | lr=0.001] Epoch 2323/4000: train_loss=2.0626  test_loss=2.2181  λ_max=8.4364\n",
      "[SGD | lr=0.001] Epoch 2324/4000: train_loss=2.0624  test_loss=2.2181  λ_max=8.7403\n",
      "[SGD | lr=0.001] Iter 37200: loss=2.0627\n",
      "[SGD | lr=0.001] Epoch 2325/4000: train_loss=2.0623  test_loss=2.2181  λ_max=8.4600\n",
      "[SGD | lr=0.001] Epoch 2326/4000: train_loss=2.0619  test_loss=2.2181  λ_max=8.6750\n",
      "[SGD | lr=0.001] Epoch 2327/4000: train_loss=2.0621  test_loss=2.2181  λ_max=8.5488\n",
      "[SGD | lr=0.001] Epoch 2328/4000: train_loss=2.0620  test_loss=2.2181  λ_max=8.6468\n",
      "[SGD | lr=0.001] Epoch 2329/4000: train_loss=2.0616  test_loss=2.2181  λ_max=8.5690\n",
      "[SGD | lr=0.001] Epoch 2330/4000: train_loss=2.0614  test_loss=2.2180  λ_max=8.8483\n",
      "[SGD | lr=0.001] Epoch 2331/4000: train_loss=2.0615  test_loss=2.2180  λ_max=8.5604\n",
      "[SGD | lr=0.001] Iter 37300: loss=2.0584\n",
      "[SGD | lr=0.001] Epoch 2332/4000: train_loss=2.0613  test_loss=2.2180  λ_max=8.2404\n",
      "[SGD | lr=0.001] Epoch 2333/4000: train_loss=2.0610  test_loss=2.2180  λ_max=8.4869\n",
      "[SGD | lr=0.001] Epoch 2334/4000: train_loss=2.0609  test_loss=2.2180  λ_max=8.5769\n",
      "[SGD | lr=0.001] Epoch 2335/4000: train_loss=2.0605  test_loss=2.2180  λ_max=8.2556\n",
      "[SGD | lr=0.001] Epoch 2336/4000: train_loss=2.0605  test_loss=2.2180  λ_max=8.2834\n",
      "[SGD | lr=0.001] Epoch 2337/4000: train_loss=2.0604  test_loss=2.2180  λ_max=8.6627\n",
      "[SGD | lr=0.001] Iter 37400: loss=2.0660\n",
      "[SGD | lr=0.001] Epoch 2338/4000: train_loss=2.0604  test_loss=2.2180  λ_max=8.4019\n",
      "[SGD | lr=0.001] Epoch 2339/4000: train_loss=2.0603  test_loss=2.2180  λ_max=8.8275\n",
      "[SGD | lr=0.001] Epoch 2340/4000: train_loss=2.0600  test_loss=2.2180  λ_max=8.7883\n",
      "[SGD | lr=0.001] Epoch 2341/4000: train_loss=2.0597  test_loss=2.2180  λ_max=8.7946\n",
      "[SGD | lr=0.001] Epoch 2342/4000: train_loss=2.0597  test_loss=2.2179  λ_max=8.9195\n",
      "[SGD | lr=0.001] Epoch 2343/4000: train_loss=2.0595  test_loss=2.2179  λ_max=8.6919\n",
      "[SGD | lr=0.001] Iter 37500: loss=2.0538\n",
      "[SGD | lr=0.001] Epoch 2344/4000: train_loss=2.0593  test_loss=2.2179  λ_max=8.5665\n",
      "[SGD | lr=0.001] Epoch 2345/4000: train_loss=2.0593  test_loss=2.2179  λ_max=8.8436\n",
      "[SGD | lr=0.001] Epoch 2346/4000: train_loss=2.0591  test_loss=2.2179  λ_max=8.8882\n",
      "[SGD | lr=0.001] Epoch 2347/4000: train_loss=2.0588  test_loss=2.2179  λ_max=8.6103\n",
      "[SGD | lr=0.001] Epoch 2348/4000: train_loss=2.0587  test_loss=2.2179  λ_max=8.2581\n",
      "[SGD | lr=0.001] Epoch 2349/4000: train_loss=2.0586  test_loss=2.2179  λ_max=8.6233\n",
      "[SGD | lr=0.001] Iter 37600: loss=2.0644\n",
      "[SGD | lr=0.001] Epoch 2350/4000: train_loss=2.0587  test_loss=2.2179  λ_max=8.9544\n",
      "[SGD | lr=0.001] Epoch 2351/4000: train_loss=2.0583  test_loss=2.2179  λ_max=8.4463\n",
      "[SGD | lr=0.001] Epoch 2352/4000: train_loss=2.0581  test_loss=2.2179  λ_max=8.6869\n",
      "[SGD | lr=0.001] Epoch 2353/4000: train_loss=2.0581  test_loss=2.2178  λ_max=8.8368\n",
      "[SGD | lr=0.001] Epoch 2354/4000: train_loss=2.0579  test_loss=2.2178  λ_max=8.0682\n",
      "[SGD | lr=0.001] Epoch 2355/4000: train_loss=2.0576  test_loss=2.2178  λ_max=8.7621\n",
      "[SGD | lr=0.001] Epoch 2356/4000: train_loss=2.0575  test_loss=2.2178  λ_max=8.8191\n",
      "[SGD | lr=0.001] Iter 37700: loss=2.0615\n",
      "[SGD | lr=0.001] Epoch 2357/4000: train_loss=2.0574  test_loss=2.2178  λ_max=8.5628\n",
      "[SGD | lr=0.001] Epoch 2358/4000: train_loss=2.0574  test_loss=2.2178  λ_max=8.8118\n",
      "[SGD | lr=0.001] Epoch 2359/4000: train_loss=2.0571  test_loss=2.2178  λ_max=8.6702\n",
      "[SGD | lr=0.001] Epoch 2360/4000: train_loss=2.0570  test_loss=2.2178  λ_max=8.6593\n",
      "[SGD | lr=0.001] Epoch 2361/4000: train_loss=2.0569  test_loss=2.2178  λ_max=9.0566\n",
      "[SGD | lr=0.001] Epoch 2362/4000: train_loss=2.0568  test_loss=2.2178  λ_max=8.7858\n",
      "[SGD | lr=0.001] Iter 37800: loss=2.0525\n",
      "[SGD | lr=0.001] Epoch 2363/4000: train_loss=2.0566  test_loss=2.2177  λ_max=8.8777\n",
      "[SGD | lr=0.001] Epoch 2364/4000: train_loss=2.0565  test_loss=2.2177  λ_max=8.3771\n",
      "[SGD | lr=0.001] Epoch 2365/4000: train_loss=2.0565  test_loss=2.2177  λ_max=8.9292\n",
      "[SGD | lr=0.001] Epoch 2366/4000: train_loss=2.0562  test_loss=2.2177  λ_max=8.8454\n",
      "[SGD | lr=0.001] Epoch 2367/4000: train_loss=2.0559  test_loss=2.2177  λ_max=8.8836\n",
      "[SGD | lr=0.001] Epoch 2368/4000: train_loss=2.0558  test_loss=2.2177  λ_max=8.3739\n",
      "[SGD | lr=0.001] Iter 37900: loss=2.0518\n",
      "[SGD | lr=0.001] Epoch 2369/4000: train_loss=2.0556  test_loss=2.2177  λ_max=8.9125\n",
      "[SGD | lr=0.001] Epoch 2370/4000: train_loss=2.0557  test_loss=2.2177  λ_max=8.7941\n",
      "[SGD | lr=0.001] Epoch 2371/4000: train_loss=2.0551  test_loss=2.2177  λ_max=8.7487\n",
      "[SGD | lr=0.001] Epoch 2372/4000: train_loss=2.0552  test_loss=2.2177  λ_max=8.9688\n",
      "[SGD | lr=0.001] Epoch 2373/4000: train_loss=2.0551  test_loss=2.2176  λ_max=9.0249\n",
      "[SGD | lr=0.001] Epoch 2374/4000: train_loss=2.0549  test_loss=2.2176  λ_max=8.9211\n",
      "[SGD | lr=0.001] Iter 38000: loss=2.0551\n",
      "[SGD | lr=0.001] Epoch 2375/4000: train_loss=2.0548  test_loss=2.2176  λ_max=8.9004\n",
      "[SGD | lr=0.001] Epoch 2376/4000: train_loss=2.0545  test_loss=2.2176  λ_max=9.1332\n",
      "[SGD | lr=0.001] Epoch 2377/4000: train_loss=2.0544  test_loss=2.2176  λ_max=8.7979\n",
      "[SGD | lr=0.001] Epoch 2378/4000: train_loss=2.0542  test_loss=2.2176  λ_max=9.0678\n",
      "[SGD | lr=0.001] Epoch 2379/4000: train_loss=2.0543  test_loss=2.2176  λ_max=8.6763\n",
      "[SGD | lr=0.001] Epoch 2380/4000: train_loss=2.0540  test_loss=2.2175  λ_max=9.1145\n",
      "[SGD | lr=0.001] Epoch 2381/4000: train_loss=2.0539  test_loss=2.2175  λ_max=8.7355\n",
      "[SGD | lr=0.001] Iter 38100: loss=2.0558\n",
      "[SGD | lr=0.001] Epoch 2382/4000: train_loss=2.0538  test_loss=2.2175  λ_max=9.1333\n",
      "[SGD | lr=0.001] Epoch 2383/4000: train_loss=2.0536  test_loss=2.2175  λ_max=9.0606\n",
      "[SGD | lr=0.001] Epoch 2384/4000: train_loss=2.0534  test_loss=2.2175  λ_max=9.1025\n",
      "[SGD | lr=0.001] Epoch 2385/4000: train_loss=2.0533  test_loss=2.2175  λ_max=9.1719\n",
      "[SGD | lr=0.001] Epoch 2386/4000: train_loss=2.0531  test_loss=2.2175  λ_max=9.0276\n",
      "[SGD | lr=0.001] Epoch 2387/4000: train_loss=2.0532  test_loss=2.2174  λ_max=9.1441\n",
      "[SGD | lr=0.001] Iter 38200: loss=2.0546\n",
      "[SGD | lr=0.001] Epoch 2388/4000: train_loss=2.0529  test_loss=2.2174  λ_max=9.1021\n",
      "[SGD | lr=0.001] Epoch 2389/4000: train_loss=2.0526  test_loss=2.2174  λ_max=8.9531\n",
      "[SGD | lr=0.001] Epoch 2390/4000: train_loss=2.0527  test_loss=2.2174  λ_max=8.9468\n",
      "[SGD | lr=0.001] Epoch 2391/4000: train_loss=2.0524  test_loss=2.2174  λ_max=8.9884\n",
      "[SGD | lr=0.001] Epoch 2392/4000: train_loss=2.0523  test_loss=2.2174  λ_max=8.8147\n",
      "[SGD | lr=0.001] Epoch 2393/4000: train_loss=2.0520  test_loss=2.2174  λ_max=9.1451\n",
      "[SGD | lr=0.001] Iter 38300: loss=2.0610\n",
      "[SGD | lr=0.001] Epoch 2394/4000: train_loss=2.0520  test_loss=2.2173  λ_max=8.9102\n",
      "[SGD | lr=0.001] Epoch 2395/4000: train_loss=2.0518  test_loss=2.2173  λ_max=8.9277\n",
      "[SGD | lr=0.001] Epoch 2396/4000: train_loss=2.0515  test_loss=2.2173  λ_max=9.0909\n",
      "[SGD | lr=0.001] Epoch 2397/4000: train_loss=2.0515  test_loss=2.2173  λ_max=9.0434\n",
      "[SGD | lr=0.001] Epoch 2398/4000: train_loss=2.0512  test_loss=2.2173  λ_max=8.5997\n",
      "[SGD | lr=0.001] Epoch 2399/4000: train_loss=2.0510  test_loss=2.2173  λ_max=9.0851\n",
      "[SGD | lr=0.001] Iter 38400: loss=2.0569\n",
      "[SGD | lr=0.001] Epoch 2400/4000: train_loss=2.0511  test_loss=2.2173  λ_max=8.4813\n",
      "[SGD | lr=0.001] Epoch 2401/4000: train_loss=2.0509  test_loss=2.2173  λ_max=9.0041\n",
      "[SGD | lr=0.001] Epoch 2402/4000: train_loss=2.0507  test_loss=2.2172  λ_max=8.9380\n",
      "[SGD | lr=0.001] Epoch 2403/4000: train_loss=2.0507  test_loss=2.2172  λ_max=8.2691\n",
      "[SGD | lr=0.001] Epoch 2404/4000: train_loss=2.0502  test_loss=2.2172  λ_max=8.9594\n",
      "[SGD | lr=0.001] Epoch 2405/4000: train_loss=2.0504  test_loss=2.2172  λ_max=8.8192\n",
      "[SGD | lr=0.001] Epoch 2406/4000: train_loss=2.0501  test_loss=2.2172  λ_max=9.2132\n",
      "[SGD | lr=0.001] Iter 38500: loss=2.0526\n",
      "[SGD | lr=0.001] Epoch 2407/4000: train_loss=2.0498  test_loss=2.2172  λ_max=9.0954\n",
      "[SGD | lr=0.001] Epoch 2408/4000: train_loss=2.0498  test_loss=2.2172  λ_max=8.8393\n",
      "[SGD | lr=0.001] Epoch 2409/4000: train_loss=2.0496  test_loss=2.2172  λ_max=9.2339\n",
      "[SGD | lr=0.001] Epoch 2410/4000: train_loss=2.0496  test_loss=2.2171  λ_max=8.9149\n",
      "[SGD | lr=0.001] Epoch 2411/4000: train_loss=2.0494  test_loss=2.2171  λ_max=8.7762\n",
      "[SGD | lr=0.001] Epoch 2412/4000: train_loss=2.0492  test_loss=2.2171  λ_max=9.1507\n",
      "[SGD | lr=0.001] Iter 38600: loss=2.0473\n",
      "[SGD | lr=0.001] Epoch 2413/4000: train_loss=2.0491  test_loss=2.2171  λ_max=9.1742\n",
      "[SGD | lr=0.001] Epoch 2414/4000: train_loss=2.0488  test_loss=2.2171  λ_max=8.4368\n",
      "[SGD | lr=0.001] Epoch 2415/4000: train_loss=2.0486  test_loss=2.2171  λ_max=9.2911\n",
      "[SGD | lr=0.001] Epoch 2416/4000: train_loss=2.0484  test_loss=2.2171  λ_max=9.0791\n",
      "[SGD | lr=0.001] Epoch 2417/4000: train_loss=2.0484  test_loss=2.2170  λ_max=9.0375\n",
      "[SGD | lr=0.001] Epoch 2418/4000: train_loss=2.0482  test_loss=2.2170  λ_max=8.5777\n",
      "[SGD | lr=0.001] Iter 38700: loss=2.0470\n",
      "[SGD | lr=0.001] Epoch 2419/4000: train_loss=2.0481  test_loss=2.2170  λ_max=8.9346\n",
      "[SGD | lr=0.001] Epoch 2420/4000: train_loss=2.0479  test_loss=2.2170  λ_max=8.7554\n",
      "[SGD | lr=0.001] Epoch 2421/4000: train_loss=2.0478  test_loss=2.2170  λ_max=8.8701\n",
      "[SGD | lr=0.001] Epoch 2422/4000: train_loss=2.0477  test_loss=2.2170  λ_max=9.3096\n",
      "[SGD | lr=0.001] Epoch 2423/4000: train_loss=2.0475  test_loss=2.2170  λ_max=9.1990\n",
      "[SGD | lr=0.001] Epoch 2424/4000: train_loss=2.0474  test_loss=2.2169  λ_max=9.0935\n",
      "[SGD | lr=0.001] Iter 38800: loss=2.0545\n",
      "[SGD | lr=0.001] Epoch 2425/4000: train_loss=2.0474  test_loss=2.2169  λ_max=8.9398\n",
      "[SGD | lr=0.001] Epoch 2426/4000: train_loss=2.0470  test_loss=2.2169  λ_max=8.7685\n",
      "[SGD | lr=0.001] Epoch 2427/4000: train_loss=2.0469  test_loss=2.2169  λ_max=9.1795\n",
      "[SGD | lr=0.001] Epoch 2428/4000: train_loss=2.0468  test_loss=2.2169  λ_max=9.0321\n",
      "[SGD | lr=0.001] Epoch 2429/4000: train_loss=2.0469  test_loss=2.2169  λ_max=9.1289\n",
      "[SGD | lr=0.001] Epoch 2430/4000: train_loss=2.0463  test_loss=2.2169  λ_max=9.2379\n",
      "[SGD | lr=0.001] Epoch 2431/4000: train_loss=2.0462  test_loss=2.2169  λ_max=8.8668\n",
      "[SGD | lr=0.001] Iter 38900: loss=2.0498\n",
      "[SGD | lr=0.001] Epoch 2432/4000: train_loss=2.0461  test_loss=2.2168  λ_max=8.6871\n",
      "[SGD | lr=0.001] Epoch 2433/4000: train_loss=2.0460  test_loss=2.2168  λ_max=8.8442\n",
      "[SGD | lr=0.001] Epoch 2434/4000: train_loss=2.0459  test_loss=2.2168  λ_max=8.7345\n",
      "[SGD | lr=0.001] Epoch 2435/4000: train_loss=2.0454  test_loss=2.2168  λ_max=8.7430\n",
      "[SGD | lr=0.001] Epoch 2436/4000: train_loss=2.0456  test_loss=2.2168  λ_max=9.3849\n",
      "[SGD | lr=0.001] Epoch 2437/4000: train_loss=2.0452  test_loss=2.2168  λ_max=8.8150\n",
      "[SGD | lr=0.001] Iter 39000: loss=2.0490\n",
      "[SGD | lr=0.001] Epoch 2438/4000: train_loss=2.0453  test_loss=2.2167  λ_max=8.6946\n",
      "[SGD | lr=0.001] Epoch 2439/4000: train_loss=2.0452  test_loss=2.2167  λ_max=9.4183\n",
      "[SGD | lr=0.001] Epoch 2440/4000: train_loss=2.0450  test_loss=2.2167  λ_max=9.1448\n",
      "[SGD | lr=0.001] Epoch 2441/4000: train_loss=2.0448  test_loss=2.2167  λ_max=9.3693\n",
      "[SGD | lr=0.001] Epoch 2442/4000: train_loss=2.0447  test_loss=2.2167  λ_max=9.0399\n",
      "[SGD | lr=0.001] Epoch 2443/4000: train_loss=2.0446  test_loss=2.2167  λ_max=8.8440\n",
      "[SGD | lr=0.001] Iter 39100: loss=2.0420\n",
      "[SGD | lr=0.001] Epoch 2444/4000: train_loss=2.0443  test_loss=2.2166  λ_max=9.3565\n",
      "[SGD | lr=0.001] Epoch 2445/4000: train_loss=2.0440  test_loss=2.2166  λ_max=9.1360\n",
      "[SGD | lr=0.001] Epoch 2446/4000: train_loss=2.0441  test_loss=2.2166  λ_max=9.1513\n",
      "[SGD | lr=0.001] Epoch 2447/4000: train_loss=2.0439  test_loss=2.2166  λ_max=9.3540\n",
      "[SGD | lr=0.001] Epoch 2448/4000: train_loss=2.0439  test_loss=2.2166  λ_max=9.4064\n",
      "[SGD | lr=0.001] Epoch 2449/4000: train_loss=2.0436  test_loss=2.2165  λ_max=9.1386\n",
      "[SGD | lr=0.001] Iter 39200: loss=2.0396\n",
      "[SGD | lr=0.001] Epoch 2450/4000: train_loss=2.0433  test_loss=2.2165  λ_max=9.0686\n",
      "[SGD | lr=0.001] Epoch 2451/4000: train_loss=2.0431  test_loss=2.2165  λ_max=8.9622\n",
      "[SGD | lr=0.001] Epoch 2452/4000: train_loss=2.0430  test_loss=2.2165  λ_max=9.0084\n",
      "[SGD | lr=0.001] Epoch 2453/4000: train_loss=2.0428  test_loss=2.2165  λ_max=9.3292\n",
      "[SGD | lr=0.001] Epoch 2454/4000: train_loss=2.0429  test_loss=2.2165  λ_max=9.0023\n",
      "[SGD | lr=0.001] Epoch 2455/4000: train_loss=2.0426  test_loss=2.2164  λ_max=9.1142\n",
      "[SGD | lr=0.001] Epoch 2456/4000: train_loss=2.0425  test_loss=2.2164  λ_max=9.2592\n",
      "[SGD | lr=0.001] Iter 39300: loss=2.0409\n",
      "[SGD | lr=0.001] Epoch 2457/4000: train_loss=2.0423  test_loss=2.2164  λ_max=9.5501\n",
      "[SGD | lr=0.001] Epoch 2458/4000: train_loss=2.0421  test_loss=2.2164  λ_max=9.2242\n",
      "[SGD | lr=0.001] Epoch 2459/4000: train_loss=2.0420  test_loss=2.2164  λ_max=9.1931\n",
      "[SGD | lr=0.001] Epoch 2460/4000: train_loss=2.0418  test_loss=2.2164  λ_max=9.2299\n",
      "[SGD | lr=0.001] Epoch 2461/4000: train_loss=2.0417  test_loss=2.2163  λ_max=9.3766\n",
      "[SGD | lr=0.001] Epoch 2462/4000: train_loss=2.0415  test_loss=2.2163  λ_max=9.1524\n",
      "[SGD | lr=0.001] Iter 39400: loss=2.0485\n",
      "[SGD | lr=0.001] Epoch 2463/4000: train_loss=2.0414  test_loss=2.2163  λ_max=8.9390\n",
      "[SGD | lr=0.001] Epoch 2464/4000: train_loss=2.0415  test_loss=2.2163  λ_max=9.1613\n",
      "[SGD | lr=0.001] Epoch 2465/4000: train_loss=2.0409  test_loss=2.2163  λ_max=9.1722\n",
      "[SGD | lr=0.001] Epoch 2466/4000: train_loss=2.0411  test_loss=2.2163  λ_max=9.0031\n",
      "[SGD | lr=0.001] Epoch 2467/4000: train_loss=2.0406  test_loss=2.2163  λ_max=9.3936\n",
      "[SGD | lr=0.001] Epoch 2468/4000: train_loss=2.0407  test_loss=2.2162  λ_max=9.3901\n",
      "[SGD | lr=0.001] Iter 39500: loss=2.0403\n",
      "[SGD | lr=0.001] Epoch 2469/4000: train_loss=2.0404  test_loss=2.2162  λ_max=9.4153\n",
      "[SGD | lr=0.001] Epoch 2470/4000: train_loss=2.0404  test_loss=2.2162  λ_max=9.3262\n",
      "[SGD | lr=0.001] Epoch 2471/4000: train_loss=2.0401  test_loss=2.2162  λ_max=9.3697\n",
      "[SGD | lr=0.001] Epoch 2472/4000: train_loss=2.0400  test_loss=2.2162  λ_max=9.5104\n",
      "[SGD | lr=0.001] Epoch 2473/4000: train_loss=2.0401  test_loss=2.2161  λ_max=9.4254\n",
      "[SGD | lr=0.001] Epoch 2474/4000: train_loss=2.0398  test_loss=2.2161  λ_max=9.2785\n",
      "[SGD | lr=0.001] Iter 39600: loss=2.0469\n",
      "[SGD | lr=0.001] Epoch 2475/4000: train_loss=2.0397  test_loss=2.2161  λ_max=8.7535\n",
      "[SGD | lr=0.001] Epoch 2476/4000: train_loss=2.0394  test_loss=2.2161  λ_max=9.4209\n",
      "[SGD | lr=0.001] Epoch 2477/4000: train_loss=2.0393  test_loss=2.2161  λ_max=9.3433\n",
      "[SGD | lr=0.001] Epoch 2478/4000: train_loss=2.0391  test_loss=2.2160  λ_max=9.0516\n",
      "[SGD | lr=0.001] Epoch 2479/4000: train_loss=2.0390  test_loss=2.2160  λ_max=9.3567\n",
      "[SGD | lr=0.001] Epoch 2480/4000: train_loss=2.0389  test_loss=2.2160  λ_max=9.3782\n",
      "[SGD | lr=0.001] Epoch 2481/4000: train_loss=2.0386  test_loss=2.2160  λ_max=9.3983\n",
      "[SGD | lr=0.001] Iter 39700: loss=2.0427\n",
      "[SGD | lr=0.001] Epoch 2482/4000: train_loss=2.0385  test_loss=2.2160  λ_max=9.2198\n",
      "[SGD | lr=0.001] Epoch 2483/4000: train_loss=2.0383  test_loss=2.2159  λ_max=9.1892\n",
      "[SGD | lr=0.001] Epoch 2484/4000: train_loss=2.0380  test_loss=2.2159  λ_max=9.3599\n",
      "[SGD | lr=0.001] Epoch 2485/4000: train_loss=2.0380  test_loss=2.2159  λ_max=9.4698\n",
      "[SGD | lr=0.001] Epoch 2486/4000: train_loss=2.0377  test_loss=2.2159  λ_max=9.5440\n",
      "[SGD | lr=0.001] Epoch 2487/4000: train_loss=2.0378  test_loss=2.2159  λ_max=9.4984\n",
      "[SGD | lr=0.001] Iter 39800: loss=2.0320\n",
      "[SGD | lr=0.001] Epoch 2488/4000: train_loss=2.0375  test_loss=2.2158  λ_max=9.5499\n",
      "[SGD | lr=0.001] Epoch 2489/4000: train_loss=2.0374  test_loss=2.2158  λ_max=9.3910\n",
      "[SGD | lr=0.001] Epoch 2490/4000: train_loss=2.0370  test_loss=2.2158  λ_max=9.3648\n",
      "[SGD | lr=0.001] Epoch 2491/4000: train_loss=2.0371  test_loss=2.2158  λ_max=9.3784\n",
      "[SGD | lr=0.001] Epoch 2492/4000: train_loss=2.0369  test_loss=2.2158  λ_max=9.4208\n",
      "[SGD | lr=0.001] Epoch 2493/4000: train_loss=2.0367  test_loss=2.2158  λ_max=8.8304\n",
      "[SGD | lr=0.001] Iter 39900: loss=2.0313\n",
      "[SGD | lr=0.001] Epoch 2494/4000: train_loss=2.0365  test_loss=2.2157  λ_max=9.4883\n",
      "[SGD | lr=0.001] Epoch 2495/4000: train_loss=2.0365  test_loss=2.2157  λ_max=9.0623\n",
      "[SGD | lr=0.001] Epoch 2496/4000: train_loss=2.0363  test_loss=2.2157  λ_max=9.3268\n",
      "[SGD | lr=0.001] Epoch 2497/4000: train_loss=2.0363  test_loss=2.2157  λ_max=9.2424\n",
      "[SGD | lr=0.001] Epoch 2498/4000: train_loss=2.0358  test_loss=2.2157  λ_max=9.6387\n",
      "[SGD | lr=0.001] Epoch 2499/4000: train_loss=2.0359  test_loss=2.2156  λ_max=8.6437\n",
      "[SGD | lr=0.001] Iter 40000: loss=2.0361\n",
      "[SGD | lr=0.001] Epoch 2500/4000: train_loss=2.0357  test_loss=2.2156  λ_max=9.2220\n",
      "[SGD | lr=0.001] Epoch 2501/4000: train_loss=2.0355  test_loss=2.2156  λ_max=9.5134\n",
      "[SGD | lr=0.001] Epoch 2502/4000: train_loss=2.0354  test_loss=2.2156  λ_max=9.1021\n",
      "[SGD | lr=0.001] Epoch 2503/4000: train_loss=2.0352  test_loss=2.2156  λ_max=9.4977\n",
      "[SGD | lr=0.001] Epoch 2504/4000: train_loss=2.0349  test_loss=2.2155  λ_max=9.1829\n",
      "[SGD | lr=0.001] Epoch 2505/4000: train_loss=2.0350  test_loss=2.2155  λ_max=9.3735\n",
      "[SGD | lr=0.001] Epoch 2506/4000: train_loss=2.0349  test_loss=2.2155  λ_max=8.9464\n",
      "[SGD | lr=0.001] Iter 40100: loss=2.0336\n",
      "[SGD | lr=0.001] Epoch 2507/4000: train_loss=2.0347  test_loss=2.2155  λ_max=9.7936\n",
      "[SGD | lr=0.001] Epoch 2508/4000: train_loss=2.0342  test_loss=2.2155  λ_max=9.2287\n",
      "[SGD | lr=0.001] Epoch 2509/4000: train_loss=2.0343  test_loss=2.2154  λ_max=8.7381\n",
      "[SGD | lr=0.001] Epoch 2510/4000: train_loss=2.0343  test_loss=2.2154  λ_max=9.1550\n",
      "[SGD | lr=0.001] Epoch 2511/4000: train_loss=2.0340  test_loss=2.2154  λ_max=9.5631\n",
      "[SGD | lr=0.001] Epoch 2512/4000: train_loss=2.0340  test_loss=2.2154  λ_max=9.3444\n",
      "[SGD | lr=0.001] Iter 40200: loss=2.0345\n",
      "[SGD | lr=0.001] Epoch 2513/4000: train_loss=2.0337  test_loss=2.2154  λ_max=9.6617\n",
      "[SGD | lr=0.001] Epoch 2514/4000: train_loss=2.0335  test_loss=2.2153  λ_max=8.7926\n",
      "[SGD | lr=0.001] Epoch 2515/4000: train_loss=2.0334  test_loss=2.2153  λ_max=9.5722\n",
      "[SGD | lr=0.001] Epoch 2516/4000: train_loss=2.0331  test_loss=2.2153  λ_max=9.0068\n",
      "[SGD | lr=0.001] Epoch 2517/4000: train_loss=2.0332  test_loss=2.2153  λ_max=9.1882\n",
      "[SGD | lr=0.001] Epoch 2518/4000: train_loss=2.0329  test_loss=2.2153  λ_max=9.5794\n",
      "[SGD | lr=0.001] Iter 40300: loss=2.0319\n",
      "[SGD | lr=0.001] Epoch 2519/4000: train_loss=2.0328  test_loss=2.2152  λ_max=9.2779\n",
      "[SGD | lr=0.001] Epoch 2520/4000: train_loss=2.0329  test_loss=2.2152  λ_max=9.1223\n",
      "[SGD | lr=0.001] Epoch 2521/4000: train_loss=2.0324  test_loss=2.2152  λ_max=9.6211\n",
      "[SGD | lr=0.001] Epoch 2522/4000: train_loss=2.0324  test_loss=2.2152  λ_max=9.8475\n",
      "[SGD | lr=0.001] Epoch 2523/4000: train_loss=2.0319  test_loss=2.2152  λ_max=9.6834\n",
      "[SGD | lr=0.001] Epoch 2524/4000: train_loss=2.0319  test_loss=2.2151  λ_max=9.7993\n",
      "[SGD | lr=0.001] Iter 40400: loss=2.0287\n",
      "[SGD | lr=0.001] Epoch 2525/4000: train_loss=2.0318  test_loss=2.2151  λ_max=9.5860\n",
      "[SGD | lr=0.001] Epoch 2526/4000: train_loss=2.0317  test_loss=2.2151  λ_max=9.8450\n",
      "[SGD | lr=0.001] Epoch 2527/4000: train_loss=2.0317  test_loss=2.2151  λ_max=9.7956\n",
      "[SGD | lr=0.001] Epoch 2528/4000: train_loss=2.0316  test_loss=2.2151  λ_max=9.4552\n",
      "[SGD | lr=0.001] Epoch 2529/4000: train_loss=2.0312  test_loss=2.2151  λ_max=9.5911\n",
      "[SGD | lr=0.001] Epoch 2530/4000: train_loss=2.0314  test_loss=2.2150  λ_max=9.6989\n",
      "[SGD | lr=0.001] Epoch 2531/4000: train_loss=2.0310  test_loss=2.2150  λ_max=9.5553\n",
      "[SGD | lr=0.001] Iter 40500: loss=2.0328\n",
      "[SGD | lr=0.001] Epoch 2532/4000: train_loss=2.0311  test_loss=2.2150  λ_max=9.3557\n",
      "[SGD | lr=0.001] Epoch 2533/4000: train_loss=2.0307  test_loss=2.2150  λ_max=9.0721\n",
      "[SGD | lr=0.001] Epoch 2534/4000: train_loss=2.0306  test_loss=2.2149  λ_max=9.6046\n",
      "[SGD | lr=0.001] Epoch 2535/4000: train_loss=2.0303  test_loss=2.2149  λ_max=9.8319\n",
      "[SGD | lr=0.001] Epoch 2536/4000: train_loss=2.0301  test_loss=2.2149  λ_max=9.6339\n",
      "[SGD | lr=0.001] Epoch 2537/4000: train_loss=2.0300  test_loss=2.2149  λ_max=9.8407\n",
      "[SGD | lr=0.001] Iter 40600: loss=2.0348\n",
      "[SGD | lr=0.001] Epoch 2538/4000: train_loss=2.0298  test_loss=2.2149  λ_max=9.3605\n",
      "[SGD | lr=0.001] Epoch 2539/4000: train_loss=2.0296  test_loss=2.2148  λ_max=9.4986\n",
      "[SGD | lr=0.001] Epoch 2540/4000: train_loss=2.0295  test_loss=2.2148  λ_max=9.8807\n",
      "[SGD | lr=0.001] Epoch 2541/4000: train_loss=2.0292  test_loss=2.2148  λ_max=9.4328\n",
      "[SGD | lr=0.001] Epoch 2542/4000: train_loss=2.0292  test_loss=2.2148  λ_max=9.7747\n",
      "[SGD | lr=0.001] Epoch 2543/4000: train_loss=2.0288  test_loss=2.2148  λ_max=9.4768\n",
      "[SGD | lr=0.001] Iter 40700: loss=2.0311\n",
      "[SGD | lr=0.001] Epoch 2544/4000: train_loss=2.0290  test_loss=2.2147  λ_max=8.9615\n",
      "[SGD | lr=0.001] Epoch 2545/4000: train_loss=2.0287  test_loss=2.2147  λ_max=9.5903\n",
      "[SGD | lr=0.001] Epoch 2546/4000: train_loss=2.0287  test_loss=2.2147  λ_max=9.3277\n",
      "[SGD | lr=0.001] Epoch 2547/4000: train_loss=2.0284  test_loss=2.2147  λ_max=9.6844\n",
      "[SGD | lr=0.001] Epoch 2548/4000: train_loss=2.0284  test_loss=2.2146  λ_max=9.7529\n",
      "[SGD | lr=0.001] Epoch 2549/4000: train_loss=2.0282  test_loss=2.2146  λ_max=9.2493\n",
      "[SGD | lr=0.001] Iter 40800: loss=2.0185\n",
      "[SGD | lr=0.001] Epoch 2550/4000: train_loss=2.0277  test_loss=2.2146  λ_max=9.6293\n",
      "[SGD | lr=0.001] Epoch 2551/4000: train_loss=2.0279  test_loss=2.2146  λ_max=9.7858\n",
      "[SGD | lr=0.001] Epoch 2552/4000: train_loss=2.0278  test_loss=2.2145  λ_max=9.7086\n",
      "[SGD | lr=0.001] Epoch 2553/4000: train_loss=2.0275  test_loss=2.2145  λ_max=9.2613\n",
      "[SGD | lr=0.001] Epoch 2554/4000: train_loss=2.0271  test_loss=2.2145  λ_max=9.5134\n",
      "[SGD | lr=0.001] Epoch 2555/4000: train_loss=2.0272  test_loss=2.2145  λ_max=9.6279\n",
      "[SGD | lr=0.001] Epoch 2556/4000: train_loss=2.0269  test_loss=2.2144  λ_max=9.1416\n",
      "[SGD | lr=0.001] Iter 40900: loss=2.0290\n",
      "[SGD | lr=0.001] Epoch 2557/4000: train_loss=2.0268  test_loss=2.2144  λ_max=9.7041\n",
      "[SGD | lr=0.001] Epoch 2558/4000: train_loss=2.0267  test_loss=2.2144  λ_max=9.6367\n",
      "[SGD | lr=0.001] Epoch 2559/4000: train_loss=2.0265  test_loss=2.2144  λ_max=9.4938\n",
      "[SGD | lr=0.001] Epoch 2560/4000: train_loss=2.0265  test_loss=2.2144  λ_max=9.7277\n",
      "[SGD | lr=0.001] Epoch 2561/4000: train_loss=2.0263  test_loss=2.2143  λ_max=9.6797\n",
      "[SGD | lr=0.001] Epoch 2562/4000: train_loss=2.0261  test_loss=2.2143  λ_max=9.5998\n",
      "[SGD | lr=0.001] Iter 41000: loss=2.0310\n",
      "[SGD | lr=0.001] Epoch 2563/4000: train_loss=2.0255  test_loss=2.2143  λ_max=9.4839\n",
      "[SGD | lr=0.001] Epoch 2564/4000: train_loss=2.0258  test_loss=2.2143  λ_max=9.6941\n",
      "[SGD | lr=0.001] Epoch 2565/4000: train_loss=2.0257  test_loss=2.2143  λ_max=9.3325\n",
      "[SGD | lr=0.001] Epoch 2566/4000: train_loss=2.0256  test_loss=2.2142  λ_max=9.8190\n",
      "[SGD | lr=0.001] Epoch 2567/4000: train_loss=2.0255  test_loss=2.2142  λ_max=9.7327\n",
      "[SGD | lr=0.001] Epoch 2568/4000: train_loss=2.0253  test_loss=2.2142  λ_max=9.6032\n",
      "[SGD | lr=0.001] Iter 41100: loss=2.0247\n",
      "[SGD | lr=0.001] Epoch 2569/4000: train_loss=2.0250  test_loss=2.2142  λ_max=9.2879\n",
      "[SGD | lr=0.001] Epoch 2570/4000: train_loss=2.0249  test_loss=2.2141  λ_max=9.8766\n",
      "[SGD | lr=0.001] Epoch 2571/4000: train_loss=2.0246  test_loss=2.2141  λ_max=9.3416\n",
      "[SGD | lr=0.001] Epoch 2572/4000: train_loss=2.0246  test_loss=2.2141  λ_max=9.7545\n",
      "[SGD | lr=0.001] Epoch 2573/4000: train_loss=2.0243  test_loss=2.2141  λ_max=9.8832\n",
      "[SGD | lr=0.001] Epoch 2574/4000: train_loss=2.0242  test_loss=2.2140  λ_max=9.7560\n",
      "[SGD | lr=0.001] Iter 41200: loss=2.0241\n",
      "[SGD | lr=0.001] Epoch 2575/4000: train_loss=2.0241  test_loss=2.2140  λ_max=9.8263\n",
      "[SGD | lr=0.001] Epoch 2576/4000: train_loss=2.0239  test_loss=2.2140  λ_max=9.9913\n",
      "[SGD | lr=0.001] Epoch 2577/4000: train_loss=2.0237  test_loss=2.2140  λ_max=9.6196\n",
      "[SGD | lr=0.001] Epoch 2578/4000: train_loss=2.0237  test_loss=2.2139  λ_max=9.3190\n",
      "[SGD | lr=0.001] Epoch 2579/4000: train_loss=2.0235  test_loss=2.2139  λ_max=9.8105\n",
      "[SGD | lr=0.001] Epoch 2580/4000: train_loss=2.0230  test_loss=2.2139  λ_max=9.5346\n",
      "[SGD | lr=0.001] Epoch 2581/4000: train_loss=2.0232  test_loss=2.2139  λ_max=9.9826\n",
      "[SGD | lr=0.001] Iter 41300: loss=2.0219\n",
      "[SGD | lr=0.001] Epoch 2582/4000: train_loss=2.0232  test_loss=2.2139  λ_max=9.6448\n",
      "[SGD | lr=0.001] Epoch 2583/4000: train_loss=2.0230  test_loss=2.2138  λ_max=9.9491\n",
      "[SGD | lr=0.001] Epoch 2584/4000: train_loss=2.0228  test_loss=2.2138  λ_max=9.9343\n",
      "[SGD | lr=0.001] Epoch 2585/4000: train_loss=2.0226  test_loss=2.2138  λ_max=9.3756\n",
      "[SGD | lr=0.001] Epoch 2586/4000: train_loss=2.0225  test_loss=2.2137  λ_max=9.2698\n",
      "[SGD | lr=0.001] Epoch 2587/4000: train_loss=2.0224  test_loss=2.2137  λ_max=10.1597\n",
      "[SGD | lr=0.001] Iter 41400: loss=2.0278\n",
      "[SGD | lr=0.001] Epoch 2588/4000: train_loss=2.0222  test_loss=2.2137  λ_max=9.7850\n",
      "[SGD | lr=0.001] Epoch 2589/4000: train_loss=2.0218  test_loss=2.2137  λ_max=9.5874\n",
      "[SGD | lr=0.001] Epoch 2590/4000: train_loss=2.0220  test_loss=2.2136  λ_max=9.4681\n",
      "[SGD | lr=0.001] Epoch 2591/4000: train_loss=2.0216  test_loss=2.2136  λ_max=9.5808\n",
      "[SGD | lr=0.001] Epoch 2592/4000: train_loss=2.0215  test_loss=2.2136  λ_max=9.6765\n",
      "[SGD | lr=0.001] Epoch 2593/4000: train_loss=2.0214  test_loss=2.2136  λ_max=9.5266\n",
      "[SGD | lr=0.001] Iter 41500: loss=2.0245\n",
      "[SGD | lr=0.001] Epoch 2594/4000: train_loss=2.0210  test_loss=2.2136  λ_max=9.8220\n",
      "[SGD | lr=0.001] Epoch 2595/4000: train_loss=2.0209  test_loss=2.2135  λ_max=9.6419\n",
      "[SGD | lr=0.001] Epoch 2596/4000: train_loss=2.0208  test_loss=2.2135  λ_max=10.1108\n",
      "[SGD | lr=0.001] Epoch 2597/4000: train_loss=2.0206  test_loss=2.2135  λ_max=10.0272\n",
      "[SGD | lr=0.001] Epoch 2598/4000: train_loss=2.0204  test_loss=2.2134  λ_max=9.8649\n",
      "[SGD | lr=0.001] Epoch 2599/4000: train_loss=2.0206  test_loss=2.2134  λ_max=9.6158\n",
      "[SGD | lr=0.001] Iter 41600: loss=2.0222\n",
      "[SGD | lr=0.001] Epoch 2600/4000: train_loss=2.0203  test_loss=2.2134  λ_max=9.8852\n",
      "[SGD | lr=0.001] Epoch 2601/4000: train_loss=2.0199  test_loss=2.2134  λ_max=9.6988\n",
      "[SGD | lr=0.001] Epoch 2602/4000: train_loss=2.0198  test_loss=2.2133  λ_max=9.5544\n",
      "[SGD | lr=0.001] Epoch 2603/4000: train_loss=2.0198  test_loss=2.2133  λ_max=9.9423\n",
      "[SGD | lr=0.001] Epoch 2604/4000: train_loss=2.0194  test_loss=2.2133  λ_max=9.4509\n",
      "[SGD | lr=0.001] Epoch 2605/4000: train_loss=2.0193  test_loss=2.2133  λ_max=9.7416\n",
      "[SGD | lr=0.001] Epoch 2606/4000: train_loss=2.0192  test_loss=2.2132  λ_max=10.0526\n",
      "[SGD | lr=0.001] Iter 41700: loss=2.0147\n",
      "[SGD | lr=0.001] Epoch 2607/4000: train_loss=2.0191  test_loss=2.2132  λ_max=10.2768\n",
      "[SGD | lr=0.001] Epoch 2608/4000: train_loss=2.0191  test_loss=2.2132  λ_max=9.9293\n",
      "[SGD | lr=0.001] Epoch 2609/4000: train_loss=2.0191  test_loss=2.2132  λ_max=10.1035\n",
      "[SGD | lr=0.001] Epoch 2610/4000: train_loss=2.0186  test_loss=2.2131  λ_max=10.0783\n",
      "[SGD | lr=0.001] Epoch 2611/4000: train_loss=2.0186  test_loss=2.2131  λ_max=10.2110\n",
      "[SGD | lr=0.001] Epoch 2612/4000: train_loss=2.0181  test_loss=2.2131  λ_max=9.9829\n",
      "[SGD | lr=0.001] Iter 41800: loss=2.0179\n",
      "[SGD | lr=0.001] Epoch 2613/4000: train_loss=2.0182  test_loss=2.2131  λ_max=9.8338\n",
      "[SGD | lr=0.001] Epoch 2614/4000: train_loss=2.0182  test_loss=2.2131  λ_max=9.9877\n",
      "[SGD | lr=0.001] Epoch 2615/4000: train_loss=2.0178  test_loss=2.2130  λ_max=9.9724\n",
      "[SGD | lr=0.001] Epoch 2616/4000: train_loss=2.0181  test_loss=2.2130  λ_max=9.4785\n",
      "[SGD | lr=0.001] Epoch 2617/4000: train_loss=2.0175  test_loss=2.2130  λ_max=9.9676\n",
      "[SGD | lr=0.001] Epoch 2618/4000: train_loss=2.0173  test_loss=2.2130  λ_max=10.0412\n",
      "[SGD | lr=0.001] Iter 41900: loss=2.0239\n",
      "[SGD | lr=0.001] Epoch 2619/4000: train_loss=2.0173  test_loss=2.2129  λ_max=9.6791\n",
      "[SGD | lr=0.001] Epoch 2620/4000: train_loss=2.0169  test_loss=2.2129  λ_max=10.1661\n",
      "[SGD | lr=0.001] Epoch 2621/4000: train_loss=2.0168  test_loss=2.2129  λ_max=9.8328\n",
      "[SGD | lr=0.001] Epoch 2622/4000: train_loss=2.0167  test_loss=2.2129  λ_max=10.2259\n",
      "[SGD | lr=0.001] Epoch 2623/4000: train_loss=2.0167  test_loss=2.2128  λ_max=9.9933\n",
      "[SGD | lr=0.001] Epoch 2624/4000: train_loss=2.0165  test_loss=2.2128  λ_max=9.2772\n",
      "[SGD | lr=0.001] Iter 42000: loss=2.0095\n",
      "[SGD | lr=0.001] Epoch 2625/4000: train_loss=2.0162  test_loss=2.2128  λ_max=9.9692\n",
      "[SGD | lr=0.001] Epoch 2626/4000: train_loss=2.0164  test_loss=2.2128  λ_max=10.2555\n",
      "[SGD | lr=0.001] Epoch 2627/4000: train_loss=2.0162  test_loss=2.2127  λ_max=9.8602\n",
      "[SGD | lr=0.001] Epoch 2628/4000: train_loss=2.0159  test_loss=2.2127  λ_max=9.7620\n",
      "[SGD | lr=0.001] Epoch 2629/4000: train_loss=2.0160  test_loss=2.2127  λ_max=9.6557\n",
      "[SGD | lr=0.001] Epoch 2630/4000: train_loss=2.0153  test_loss=2.2127  λ_max=9.3351\n",
      "[SGD | lr=0.001] Epoch 2631/4000: train_loss=2.0153  test_loss=2.2126  λ_max=9.6367\n",
      "[SGD | lr=0.001] Iter 42100: loss=2.0111\n",
      "[SGD | lr=0.001] Epoch 2632/4000: train_loss=2.0154  test_loss=2.2126  λ_max=10.0806\n",
      "[SGD | lr=0.001] Epoch 2633/4000: train_loss=2.0150  test_loss=2.2126  λ_max=9.9764\n",
      "[SGD | lr=0.001] Epoch 2634/4000: train_loss=2.0148  test_loss=2.2126  λ_max=9.9346\n",
      "[SGD | lr=0.001] Epoch 2635/4000: train_loss=2.0146  test_loss=2.2125  λ_max=10.2317\n",
      "[SGD | lr=0.001] Epoch 2636/4000: train_loss=2.0146  test_loss=2.2125  λ_max=9.8294\n",
      "[SGD | lr=0.001] Epoch 2637/4000: train_loss=2.0146  test_loss=2.2125  λ_max=10.1397\n",
      "[SGD | lr=0.001] Iter 42200: loss=2.0114\n",
      "[SGD | lr=0.001] Epoch 2638/4000: train_loss=2.0142  test_loss=2.2125  λ_max=9.9807\n",
      "[SGD | lr=0.001] Epoch 2639/4000: train_loss=2.0140  test_loss=2.2124  λ_max=10.1772\n",
      "[SGD | lr=0.001] Epoch 2640/4000: train_loss=2.0139  test_loss=2.2124  λ_max=10.0248\n",
      "[SGD | lr=0.001] Epoch 2641/4000: train_loss=2.0138  test_loss=2.2124  λ_max=9.7800\n",
      "[SGD | lr=0.001] Epoch 2642/4000: train_loss=2.0136  test_loss=2.2124  λ_max=10.1086\n",
      "[SGD | lr=0.001] Epoch 2643/4000: train_loss=2.0135  test_loss=2.2123  λ_max=9.6672\n",
      "[SGD | lr=0.001] Iter 42300: loss=2.0122\n",
      "[SGD | lr=0.001] Epoch 2644/4000: train_loss=2.0134  test_loss=2.2123  λ_max=10.0555\n",
      "[SGD | lr=0.001] Epoch 2645/4000: train_loss=2.0134  test_loss=2.2123  λ_max=9.7646\n",
      "[SGD | lr=0.001] Epoch 2646/4000: train_loss=2.0130  test_loss=2.2123  λ_max=9.6581\n",
      "[SGD | lr=0.001] Epoch 2647/4000: train_loss=2.0129  test_loss=2.2122  λ_max=9.8876\n",
      "[SGD | lr=0.001] Epoch 2648/4000: train_loss=2.0128  test_loss=2.2122  λ_max=9.5767\n",
      "[SGD | lr=0.001] Epoch 2649/4000: train_loss=2.0126  test_loss=2.2122  λ_max=10.0388\n",
      "[SGD | lr=0.001] Iter 42400: loss=2.0169\n",
      "[SGD | lr=0.001] Epoch 2650/4000: train_loss=2.0126  test_loss=2.2122  λ_max=9.8635\n",
      "[SGD | lr=0.001] Epoch 2651/4000: train_loss=2.0124  test_loss=2.2121  λ_max=9.6451\n",
      "[SGD | lr=0.001] Epoch 2652/4000: train_loss=2.0122  test_loss=2.2121  λ_max=9.9415\n",
      "[SGD | lr=0.001] Epoch 2653/4000: train_loss=2.0121  test_loss=2.2121  λ_max=9.8893\n",
      "[SGD | lr=0.001] Epoch 2654/4000: train_loss=2.0119  test_loss=2.2121  λ_max=9.6845\n",
      "[SGD | lr=0.001] Epoch 2655/4000: train_loss=2.0118  test_loss=2.2120  λ_max=9.9262\n",
      "[SGD | lr=0.001] Epoch 2656/4000: train_loss=2.0114  test_loss=2.2120  λ_max=9.5665\n",
      "[SGD | lr=0.001] Iter 42500: loss=2.0143\n",
      "[SGD | lr=0.001] Epoch 2657/4000: train_loss=2.0113  test_loss=2.2120  λ_max=10.0839\n",
      "[SGD | lr=0.001] Epoch 2658/4000: train_loss=2.0111  test_loss=2.2120  λ_max=9.9809\n",
      "[SGD | lr=0.001] Epoch 2659/4000: train_loss=2.0113  test_loss=2.2119  λ_max=9.5663\n",
      "[SGD | lr=0.001] Epoch 2660/4000: train_loss=2.0110  test_loss=2.2119  λ_max=8.9822\n",
      "[SGD | lr=0.001] Epoch 2661/4000: train_loss=2.0109  test_loss=2.2119  λ_max=10.3495\n",
      "[SGD | lr=0.001] Epoch 2662/4000: train_loss=2.0107  test_loss=2.2118  λ_max=9.9245\n",
      "[SGD | lr=0.001] Iter 42600: loss=2.0140\n",
      "[SGD | lr=0.001] Epoch 2663/4000: train_loss=2.0104  test_loss=2.2118  λ_max=9.8138\n",
      "[SGD | lr=0.001] Epoch 2664/4000: train_loss=2.0102  test_loss=2.2118  λ_max=10.1365\n",
      "[SGD | lr=0.001] Epoch 2665/4000: train_loss=2.0102  test_loss=2.2118  λ_max=10.2005\n",
      "[SGD | lr=0.001] Epoch 2666/4000: train_loss=2.0097  test_loss=2.2117  λ_max=10.2106\n",
      "[SGD | lr=0.001] Epoch 2667/4000: train_loss=2.0100  test_loss=2.2117  λ_max=9.6338\n",
      "[SGD | lr=0.001] Epoch 2668/4000: train_loss=2.0095  test_loss=2.2117  λ_max=9.9508\n",
      "[SGD | lr=0.001] Iter 42700: loss=2.0124\n",
      "[SGD | lr=0.001] Epoch 2669/4000: train_loss=2.0096  test_loss=2.2116  λ_max=10.3941\n",
      "[SGD | lr=0.001] Epoch 2670/4000: train_loss=2.0094  test_loss=2.2116  λ_max=9.7576\n",
      "[SGD | lr=0.001] Epoch 2671/4000: train_loss=2.0090  test_loss=2.2116  λ_max=9.6920\n",
      "[SGD | lr=0.001] Epoch 2672/4000: train_loss=2.0090  test_loss=2.2116  λ_max=9.7466\n",
      "[SGD | lr=0.001] Epoch 2673/4000: train_loss=2.0089  test_loss=2.2115  λ_max=10.5333\n",
      "[SGD | lr=0.001] Epoch 2674/4000: train_loss=2.0086  test_loss=2.2115  λ_max=10.2570\n",
      "[SGD | lr=0.001] Iter 42800: loss=2.0065\n",
      "[SGD | lr=0.001] Epoch 2675/4000: train_loss=2.0085  test_loss=2.2115  λ_max=9.8691\n",
      "[SGD | lr=0.001] Epoch 2676/4000: train_loss=2.0083  test_loss=2.2115  λ_max=10.0618\n",
      "[SGD | lr=0.001] Epoch 2677/4000: train_loss=2.0083  test_loss=2.2114  λ_max=10.0858\n",
      "[SGD | lr=0.001] Epoch 2678/4000: train_loss=2.0082  test_loss=2.2114  λ_max=10.4359\n",
      "[SGD | lr=0.001] Epoch 2679/4000: train_loss=2.0081  test_loss=2.2114  λ_max=10.4156\n",
      "[SGD | lr=0.001] Epoch 2680/4000: train_loss=2.0079  test_loss=2.2114  λ_max=10.2458\n",
      "[SGD | lr=0.001] Epoch 2681/4000: train_loss=2.0076  test_loss=2.2113  λ_max=10.2397\n",
      "[SGD | lr=0.001] Iter 42900: loss=2.0090\n",
      "[SGD | lr=0.001] Epoch 2682/4000: train_loss=2.0077  test_loss=2.2113  λ_max=9.8339\n",
      "[SGD | lr=0.001] Epoch 2683/4000: train_loss=2.0074  test_loss=2.2113  λ_max=9.9349\n",
      "[SGD | lr=0.001] Epoch 2684/4000: train_loss=2.0070  test_loss=2.2112  λ_max=9.8877\n",
      "[SGD | lr=0.001] Epoch 2685/4000: train_loss=2.0069  test_loss=2.2112  λ_max=10.0698\n",
      "[SGD | lr=0.001] Epoch 2686/4000: train_loss=2.0070  test_loss=2.2112  λ_max=9.9536\n",
      "[SGD | lr=0.001] Epoch 2687/4000: train_loss=2.0068  test_loss=2.2112  λ_max=9.4438\n",
      "[SGD | lr=0.001] Iter 43000: loss=2.0059\n",
      "[SGD | lr=0.001] Epoch 2688/4000: train_loss=2.0064  test_loss=2.2111  λ_max=10.0954\n",
      "[SGD | lr=0.001] Epoch 2689/4000: train_loss=2.0065  test_loss=2.2111  λ_max=10.2789\n",
      "[SGD | lr=0.001] Epoch 2690/4000: train_loss=2.0064  test_loss=2.2111  λ_max=9.9384\n",
      "[SGD | lr=0.001] Epoch 2691/4000: train_loss=2.0060  test_loss=2.2111  λ_max=10.3168\n",
      "[SGD | lr=0.001] Epoch 2692/4000: train_loss=2.0060  test_loss=2.2110  λ_max=9.8598\n",
      "[SGD | lr=0.001] Epoch 2693/4000: train_loss=2.0059  test_loss=2.2110  λ_max=9.9162\n",
      "[SGD | lr=0.001] Iter 43100: loss=2.0098\n",
      "[SGD | lr=0.001] Epoch 2694/4000: train_loss=2.0057  test_loss=2.2110  λ_max=10.3677\n",
      "[SGD | lr=0.001] Epoch 2695/4000: train_loss=2.0053  test_loss=2.2109  λ_max=10.2492\n",
      "[SGD | lr=0.001] Epoch 2696/4000: train_loss=2.0051  test_loss=2.2109  λ_max=9.8518\n",
      "[SGD | lr=0.001] Epoch 2697/4000: train_loss=2.0053  test_loss=2.2109  λ_max=9.7873\n",
      "[SGD | lr=0.001] Epoch 2698/4000: train_loss=2.0050  test_loss=2.2109  λ_max=9.9514\n",
      "[SGD | lr=0.001] Epoch 2699/4000: train_loss=2.0046  test_loss=2.2108  λ_max=10.2971\n",
      "[SGD | lr=0.001] Iter 43200: loss=2.0148\n",
      "[SGD | lr=0.001] Epoch 2700/4000: train_loss=2.0049  test_loss=2.2108  λ_max=9.6085\n",
      "[SGD | lr=0.001] Epoch 2701/4000: train_loss=2.0047  test_loss=2.2107  λ_max=10.1513\n",
      "[SGD | lr=0.001] Epoch 2702/4000: train_loss=2.0045  test_loss=2.2107  λ_max=9.8774\n",
      "[SGD | lr=0.001] Epoch 2703/4000: train_loss=2.0045  test_loss=2.2107  λ_max=9.7896\n",
      "[SGD | lr=0.001] Epoch 2704/4000: train_loss=2.0040  test_loss=2.2107  λ_max=10.4571\n",
      "[SGD | lr=0.001] Epoch 2705/4000: train_loss=2.0041  test_loss=2.2106  λ_max=10.5543\n",
      "[SGD | lr=0.001] Epoch 2706/4000: train_loss=2.0040  test_loss=2.2106  λ_max=9.8726\n",
      "[SGD | lr=0.001] Iter 43300: loss=2.0131\n",
      "[SGD | lr=0.001] Epoch 2707/4000: train_loss=2.0037  test_loss=2.2106  λ_max=9.8751\n",
      "[SGD | lr=0.001] Epoch 2708/4000: train_loss=2.0034  test_loss=2.2105  λ_max=9.2337\n",
      "[SGD | lr=0.001] Epoch 2709/4000: train_loss=2.0030  test_loss=2.2105  λ_max=10.2709\n",
      "[SGD | lr=0.001] Epoch 2710/4000: train_loss=2.0031  test_loss=2.2105  λ_max=10.4902\n",
      "[SGD | lr=0.001] Epoch 2711/4000: train_loss=2.0030  test_loss=2.2105  λ_max=10.1921\n",
      "[SGD | lr=0.001] Epoch 2712/4000: train_loss=2.0029  test_loss=2.2104  λ_max=10.0262\n",
      "[SGD | lr=0.001] Iter 43400: loss=2.0062\n",
      "[SGD | lr=0.001] Epoch 2713/4000: train_loss=2.0028  test_loss=2.2104  λ_max=10.0280\n",
      "[SGD | lr=0.001] Epoch 2714/4000: train_loss=2.0026  test_loss=2.2104  λ_max=10.1684\n",
      "[SGD | lr=0.001] Epoch 2715/4000: train_loss=2.0022  test_loss=2.2103  λ_max=10.4493\n",
      "[SGD | lr=0.001] Epoch 2716/4000: train_loss=2.0024  test_loss=2.2103  λ_max=10.4913\n",
      "[SGD | lr=0.001] Epoch 2717/4000: train_loss=2.0021  test_loss=2.2103  λ_max=10.3558\n",
      "[SGD | lr=0.001] Epoch 2718/4000: train_loss=2.0021  test_loss=2.2103  λ_max=9.6765\n",
      "[SGD | lr=0.001] Iter 43500: loss=2.0032\n",
      "[SGD | lr=0.001] Epoch 2719/4000: train_loss=2.0020  test_loss=2.2102  λ_max=10.1972\n",
      "[SGD | lr=0.001] Epoch 2720/4000: train_loss=2.0016  test_loss=2.2102  λ_max=10.5006\n",
      "[SGD | lr=0.001] Epoch 2721/4000: train_loss=2.0014  test_loss=2.2102  λ_max=10.2676\n",
      "[SGD | lr=0.001] Epoch 2722/4000: train_loss=2.0014  test_loss=2.2101  λ_max=10.1850\n",
      "[SGD | lr=0.001] Epoch 2723/4000: train_loss=2.0011  test_loss=2.2101  λ_max=10.5990\n",
      "[SGD | lr=0.001] Epoch 2724/4000: train_loss=2.0012  test_loss=2.2101  λ_max=10.0814\n",
      "[SGD | lr=0.001] Iter 43600: loss=2.0069\n",
      "[SGD | lr=0.001] Epoch 2725/4000: train_loss=2.0010  test_loss=2.2101  λ_max=10.6531\n",
      "[SGD | lr=0.001] Epoch 2726/4000: train_loss=2.0006  test_loss=2.2100  λ_max=10.5547\n",
      "[SGD | lr=0.001] Epoch 2727/4000: train_loss=2.0005  test_loss=2.2100  λ_max=10.2669\n",
      "[SGD | lr=0.001] Epoch 2728/4000: train_loss=2.0006  test_loss=2.2100  λ_max=10.1881\n",
      "[SGD | lr=0.001] Epoch 2729/4000: train_loss=2.0003  test_loss=2.2099  λ_max=9.9602\n",
      "[SGD | lr=0.001] Epoch 2730/4000: train_loss=2.0000  test_loss=2.2099  λ_max=10.6283\n",
      "[SGD | lr=0.001] Epoch 2731/4000: train_loss=1.9998  test_loss=2.2099  λ_max=9.9831\n",
      "[SGD | lr=0.001] Iter 43700: loss=2.0025\n",
      "[SGD | lr=0.001] Epoch 2732/4000: train_loss=1.9999  test_loss=2.2099  λ_max=10.0914\n",
      "[SGD | lr=0.001] Epoch 2733/4000: train_loss=1.9998  test_loss=2.2098  λ_max=10.1675\n",
      "[SGD | lr=0.001] Epoch 2734/4000: train_loss=1.9995  test_loss=2.2098  λ_max=10.5278\n",
      "[SGD | lr=0.001] Epoch 2735/4000: train_loss=1.9993  test_loss=2.2098  λ_max=10.1963\n",
      "[SGD | lr=0.001] Epoch 2736/4000: train_loss=1.9991  test_loss=2.2097  λ_max=10.5476\n",
      "[SGD | lr=0.001] Epoch 2737/4000: train_loss=1.9991  test_loss=2.2097  λ_max=10.2510\n",
      "[SGD | lr=0.001] Iter 43800: loss=1.9978\n",
      "[SGD | lr=0.001] Epoch 2738/4000: train_loss=1.9987  test_loss=2.2097  λ_max=10.5629\n",
      "[SGD | lr=0.001] Epoch 2739/4000: train_loss=1.9987  test_loss=2.2096  λ_max=10.4156\n",
      "[SGD | lr=0.001] Epoch 2740/4000: train_loss=1.9983  test_loss=2.2096  λ_max=10.6549\n",
      "[SGD | lr=0.001] Epoch 2741/4000: train_loss=1.9984  test_loss=2.2096  λ_max=9.9210\n",
      "[SGD | lr=0.001] Epoch 2742/4000: train_loss=1.9979  test_loss=2.2096  λ_max=10.4739\n",
      "[SGD | lr=0.001] Epoch 2743/4000: train_loss=1.9980  test_loss=2.2095  λ_max=10.2676\n",
      "[SGD | lr=0.001] Iter 43900: loss=1.9973\n",
      "[SGD | lr=0.001] Epoch 2744/4000: train_loss=1.9979  test_loss=2.2095  λ_max=10.1516\n",
      "[SGD | lr=0.001] Epoch 2745/4000: train_loss=1.9978  test_loss=2.2095  λ_max=10.3196\n",
      "[SGD | lr=0.001] Epoch 2746/4000: train_loss=1.9976  test_loss=2.2094  λ_max=10.5894\n",
      "[SGD | lr=0.001] Epoch 2747/4000: train_loss=1.9975  test_loss=2.2094  λ_max=10.0766\n",
      "[SGD | lr=0.001] Epoch 2748/4000: train_loss=1.9974  test_loss=2.2094  λ_max=10.7955\n",
      "[SGD | lr=0.001] Epoch 2749/4000: train_loss=1.9969  test_loss=2.2093  λ_max=10.4894\n",
      "[SGD | lr=0.001] Iter 44000: loss=1.9997\n",
      "[SGD | lr=0.001] Epoch 2750/4000: train_loss=1.9970  test_loss=2.2093  λ_max=10.5170\n",
      "[SGD | lr=0.001] Epoch 2751/4000: train_loss=1.9968  test_loss=2.2093  λ_max=10.2277\n",
      "[SGD | lr=0.001] Epoch 2752/4000: train_loss=1.9966  test_loss=2.2093  λ_max=10.6089\n",
      "[SGD | lr=0.001] Epoch 2753/4000: train_loss=1.9964  test_loss=2.2092  λ_max=10.4066\n",
      "[SGD | lr=0.001] Epoch 2754/4000: train_loss=1.9963  test_loss=2.2092  λ_max=10.1768\n",
      "[SGD | lr=0.001] Epoch 2755/4000: train_loss=1.9960  test_loss=2.2092  λ_max=10.2065\n",
      "[SGD | lr=0.001] Epoch 2756/4000: train_loss=1.9960  test_loss=2.2091  λ_max=10.5217\n",
      "[SGD | lr=0.001] Iter 44100: loss=2.0005\n",
      "[SGD | lr=0.001] Epoch 2757/4000: train_loss=1.9960  test_loss=2.2091  λ_max=10.2383\n",
      "[SGD | lr=0.001] Epoch 2758/4000: train_loss=1.9958  test_loss=2.2091  λ_max=9.7043\n",
      "[SGD | lr=0.001] Epoch 2759/4000: train_loss=1.9956  test_loss=2.2091  λ_max=10.6159\n",
      "[SGD | lr=0.001] Epoch 2760/4000: train_loss=1.9953  test_loss=2.2090  λ_max=10.1767\n",
      "[SGD | lr=0.001] Epoch 2761/4000: train_loss=1.9952  test_loss=2.2090  λ_max=10.2125\n",
      "[SGD | lr=0.001] Epoch 2762/4000: train_loss=1.9949  test_loss=2.2090  λ_max=10.3879\n",
      "[SGD | lr=0.001] Iter 44200: loss=1.9952\n",
      "[SGD | lr=0.001] Epoch 2763/4000: train_loss=1.9951  test_loss=2.2089  λ_max=10.7263\n",
      "[SGD | lr=0.001] Epoch 2764/4000: train_loss=1.9949  test_loss=2.2089  λ_max=10.6015\n",
      "[SGD | lr=0.001] Epoch 2765/4000: train_loss=1.9947  test_loss=2.2089  λ_max=10.3067\n",
      "[SGD | lr=0.001] Epoch 2766/4000: train_loss=1.9945  test_loss=2.2088  λ_max=10.3916\n",
      "[SGD | lr=0.001] Epoch 2767/4000: train_loss=1.9944  test_loss=2.2088  λ_max=9.8312\n",
      "[SGD | lr=0.001] Epoch 2768/4000: train_loss=1.9942  test_loss=2.2088  λ_max=10.6591\n",
      "[SGD | lr=0.001] Iter 44300: loss=1.9907\n",
      "[SGD | lr=0.001] Epoch 2769/4000: train_loss=1.9941  test_loss=2.2088  λ_max=10.1151\n",
      "[SGD | lr=0.001] Epoch 2770/4000: train_loss=1.9940  test_loss=2.2087  λ_max=10.3003\n",
      "[SGD | lr=0.001] Epoch 2771/4000: train_loss=1.9937  test_loss=2.2087  λ_max=10.4464\n",
      "[SGD | lr=0.001] Epoch 2772/4000: train_loss=1.9938  test_loss=2.2087  λ_max=10.2382\n",
      "[SGD | lr=0.001] Epoch 2773/4000: train_loss=1.9933  test_loss=2.2086  λ_max=10.5415\n",
      "[SGD | lr=0.001] Epoch 2774/4000: train_loss=1.9935  test_loss=2.2086  λ_max=10.3123\n",
      "[SGD | lr=0.001] Iter 44400: loss=1.9972\n",
      "[SGD | lr=0.001] Epoch 2775/4000: train_loss=1.9932  test_loss=2.2086  λ_max=10.0359\n",
      "[SGD | lr=0.001] Epoch 2776/4000: train_loss=1.9929  test_loss=2.2086  λ_max=10.4573\n",
      "[SGD | lr=0.001] Epoch 2777/4000: train_loss=1.9925  test_loss=2.2085  λ_max=10.5835\n",
      "[SGD | lr=0.001] Epoch 2778/4000: train_loss=1.9928  test_loss=2.2085  λ_max=10.5840\n",
      "[SGD | lr=0.001] Epoch 2779/4000: train_loss=1.9926  test_loss=2.2085  λ_max=10.5674\n",
      "[SGD | lr=0.001] Epoch 2780/4000: train_loss=1.9923  test_loss=2.2084  λ_max=10.6060\n",
      "[SGD | lr=0.001] Epoch 2781/4000: train_loss=1.9923  test_loss=2.2084  λ_max=10.3974\n",
      "[SGD | lr=0.001] Iter 44500: loss=1.9910\n",
      "[SGD | lr=0.001] Epoch 2782/4000: train_loss=1.9920  test_loss=2.2084  λ_max=10.8453\n",
      "[SGD | lr=0.001] Epoch 2783/4000: train_loss=1.9918  test_loss=2.2083  λ_max=10.8253\n",
      "[SGD | lr=0.001] Epoch 2784/4000: train_loss=1.9919  test_loss=2.2083  λ_max=10.2529\n",
      "[SGD | lr=0.001] Epoch 2785/4000: train_loss=1.9915  test_loss=2.2083  λ_max=10.6741\n",
      "[SGD | lr=0.001] Epoch 2786/4000: train_loss=1.9917  test_loss=2.2082  λ_max=10.7138\n",
      "[SGD | lr=0.001] Epoch 2787/4000: train_loss=1.9913  test_loss=2.2082  λ_max=10.5697\n",
      "[SGD | lr=0.001] Iter 44600: loss=1.9935\n",
      "[SGD | lr=0.001] Epoch 2788/4000: train_loss=1.9908  test_loss=2.2082  λ_max=10.4203\n",
      "[SGD | lr=0.001] Epoch 2789/4000: train_loss=1.9910  test_loss=2.2082  λ_max=10.3262\n",
      "[SGD | lr=0.001] Epoch 2790/4000: train_loss=1.9907  test_loss=2.2081  λ_max=10.0869\n",
      "[SGD | lr=0.001] Epoch 2791/4000: train_loss=1.9909  test_loss=2.2081  λ_max=10.5544\n",
      "[SGD | lr=0.001] Epoch 2792/4000: train_loss=1.9905  test_loss=2.2081  λ_max=10.5975\n",
      "[SGD | lr=0.001] Epoch 2793/4000: train_loss=1.9903  test_loss=2.2080  λ_max=10.5024\n",
      "[SGD | lr=0.001] Iter 44700: loss=1.9902\n",
      "[SGD | lr=0.001] Epoch 2794/4000: train_loss=1.9901  test_loss=2.2080  λ_max=10.7343\n",
      "[SGD | lr=0.001] Epoch 2795/4000: train_loss=1.9902  test_loss=2.2080  λ_max=9.7223\n",
      "[SGD | lr=0.001] Epoch 2796/4000: train_loss=1.9898  test_loss=2.2079  λ_max=10.1705\n",
      "[SGD | lr=0.001] Epoch 2797/4000: train_loss=1.9898  test_loss=2.2079  λ_max=10.3551\n",
      "[SGD | lr=0.001] Epoch 2798/4000: train_loss=1.9897  test_loss=2.2079  λ_max=10.8861\n",
      "[SGD | lr=0.001] Epoch 2799/4000: train_loss=1.9894  test_loss=2.2078  λ_max=10.4526\n",
      "[SGD | lr=0.001] Iter 44800: loss=1.9896\n",
      "[SGD | lr=0.001] Epoch 2800/4000: train_loss=1.9893  test_loss=2.2078  λ_max=9.6573\n",
      "[SGD | lr=0.001] Epoch 2801/4000: train_loss=1.9891  test_loss=2.2078  λ_max=10.4364\n",
      "[SGD | lr=0.001] Epoch 2802/4000: train_loss=1.9890  test_loss=2.2078  λ_max=10.4045\n",
      "[SGD | lr=0.001] Epoch 2803/4000: train_loss=1.9890  test_loss=2.2077  λ_max=10.1500\n",
      "[SGD | lr=0.001] Epoch 2804/4000: train_loss=1.9887  test_loss=2.2077  λ_max=10.8130\n",
      "[SGD | lr=0.001] Epoch 2805/4000: train_loss=1.9885  test_loss=2.2077  λ_max=10.6413\n",
      "[SGD | lr=0.001] Epoch 2806/4000: train_loss=1.9883  test_loss=2.2076  λ_max=10.8525\n",
      "[SGD | lr=0.001] Iter 44900: loss=1.9882\n",
      "[SGD | lr=0.001] Epoch 2807/4000: train_loss=1.9882  test_loss=2.2076  λ_max=10.7038\n",
      "[SGD | lr=0.001] Epoch 2808/4000: train_loss=1.9881  test_loss=2.2075  λ_max=10.4572\n",
      "[SGD | lr=0.001] Epoch 2809/4000: train_loss=1.9880  test_loss=2.2075  λ_max=10.9459\n",
      "[SGD | lr=0.001] Epoch 2810/4000: train_loss=1.9878  test_loss=2.2075  λ_max=10.1066\n",
      "[SGD | lr=0.001] Epoch 2811/4000: train_loss=1.9877  test_loss=2.2075  λ_max=10.2238\n",
      "[SGD | lr=0.001] Epoch 2812/4000: train_loss=1.9874  test_loss=2.2074  λ_max=10.7989\n",
      "[SGD | lr=0.001] Iter 45000: loss=1.9800\n",
      "[SGD | lr=0.001] Epoch 2813/4000: train_loss=1.9874  test_loss=2.2074  λ_max=10.8111\n",
      "[SGD | lr=0.001] Epoch 2814/4000: train_loss=1.9871  test_loss=2.2074  λ_max=10.9506\n",
      "[SGD | lr=0.001] Epoch 2815/4000: train_loss=1.9866  test_loss=2.2073  λ_max=10.4778\n",
      "[SGD | lr=0.001] Epoch 2816/4000: train_loss=1.9867  test_loss=2.2073  λ_max=10.4536\n",
      "[SGD | lr=0.001] Epoch 2817/4000: train_loss=1.9866  test_loss=2.2073  λ_max=10.6260\n",
      "[SGD | lr=0.001] Epoch 2818/4000: train_loss=1.9863  test_loss=2.2072  λ_max=10.2854\n",
      "[SGD | lr=0.001] Iter 45100: loss=1.9866\n",
      "[SGD | lr=0.001] Epoch 2819/4000: train_loss=1.9863  test_loss=2.2072  λ_max=10.5449\n",
      "[SGD | lr=0.001] Epoch 2820/4000: train_loss=1.9863  test_loss=2.2072  λ_max=10.6655\n",
      "[SGD | lr=0.001] Epoch 2821/4000: train_loss=1.9862  test_loss=2.2071  λ_max=10.7117\n",
      "[SGD | lr=0.001] Epoch 2822/4000: train_loss=1.9860  test_loss=2.2071  λ_max=10.8950\n",
      "[SGD | lr=0.001] Epoch 2823/4000: train_loss=1.9857  test_loss=2.2071  λ_max=10.8971\n",
      "[SGD | lr=0.001] Epoch 2824/4000: train_loss=1.9856  test_loss=2.2071  λ_max=10.3736\n",
      "[SGD | lr=0.001] Iter 45200: loss=1.9864\n",
      "[SGD | lr=0.001] Epoch 2825/4000: train_loss=1.9854  test_loss=2.2070  λ_max=10.3322\n",
      "[SGD | lr=0.001] Epoch 2826/4000: train_loss=1.9855  test_loss=2.2070  λ_max=10.4925\n",
      "[SGD | lr=0.001] Epoch 2827/4000: train_loss=1.9852  test_loss=2.2070  λ_max=10.5575\n",
      "[SGD | lr=0.001] Epoch 2828/4000: train_loss=1.9850  test_loss=2.2069  λ_max=10.1893\n",
      "[SGD | lr=0.001] Epoch 2829/4000: train_loss=1.9847  test_loss=2.2069  λ_max=10.7733\n",
      "[SGD | lr=0.001] Epoch 2830/4000: train_loss=1.9847  test_loss=2.2069  λ_max=10.8609\n",
      "[SGD | lr=0.001] Epoch 2831/4000: train_loss=1.9845  test_loss=2.2069  λ_max=10.3095\n",
      "[SGD | lr=0.001] Iter 45300: loss=1.9808\n",
      "[SGD | lr=0.001] Epoch 2832/4000: train_loss=1.9845  test_loss=2.2068  λ_max=10.9440\n",
      "[SGD | lr=0.001] Epoch 2833/4000: train_loss=1.9841  test_loss=2.2068  λ_max=10.3855\n",
      "[SGD | lr=0.001] Epoch 2834/4000: train_loss=1.9841  test_loss=2.2068  λ_max=10.7066\n",
      "[SGD | lr=0.001] Epoch 2835/4000: train_loss=1.9840  test_loss=2.2067  λ_max=10.8385\n",
      "[SGD | lr=0.001] Epoch 2836/4000: train_loss=1.9836  test_loss=2.2067  λ_max=10.8275\n",
      "[SGD | lr=0.001] Epoch 2837/4000: train_loss=1.9836  test_loss=2.2066  λ_max=10.1599\n",
      "[SGD | lr=0.001] Iter 45400: loss=1.9840\n",
      "[SGD | lr=0.001] Epoch 2838/4000: train_loss=1.9832  test_loss=2.2066  λ_max=10.8124\n",
      "[SGD | lr=0.001] Epoch 2839/4000: train_loss=1.9831  test_loss=2.2066  λ_max=10.8349\n",
      "[SGD | lr=0.001] Epoch 2840/4000: train_loss=1.9833  test_loss=2.2066  λ_max=10.6702\n",
      "[SGD | lr=0.001] Epoch 2841/4000: train_loss=1.9831  test_loss=2.2065  λ_max=10.6088\n",
      "[SGD | lr=0.001] Epoch 2842/4000: train_loss=1.9826  test_loss=2.2065  λ_max=10.8967\n",
      "[SGD | lr=0.001] Epoch 2843/4000: train_loss=1.9826  test_loss=2.2065  λ_max=11.1153\n",
      "[SGD | lr=0.001] Iter 45500: loss=1.9780\n",
      "[SGD | lr=0.001] Epoch 2844/4000: train_loss=1.9824  test_loss=2.2064  λ_max=11.0786\n",
      "[SGD | lr=0.001] Epoch 2845/4000: train_loss=1.9824  test_loss=2.2064  λ_max=9.7173\n",
      "[SGD | lr=0.001] Epoch 2846/4000: train_loss=1.9822  test_loss=2.2064  λ_max=10.8518\n",
      "[SGD | lr=0.001] Epoch 2847/4000: train_loss=1.9820  test_loss=2.2064  λ_max=10.9945\n",
      "[SGD | lr=0.001] Epoch 2848/4000: train_loss=1.9818  test_loss=2.2063  λ_max=10.9293\n",
      "[SGD | lr=0.001] Epoch 2849/4000: train_loss=1.9818  test_loss=2.2063  λ_max=10.7432\n",
      "[SGD | lr=0.001] Iter 45600: loss=1.9749\n",
      "[SGD | lr=0.001] Epoch 2850/4000: train_loss=1.9814  test_loss=2.2063  λ_max=10.4636\n",
      "[SGD | lr=0.001] Epoch 2851/4000: train_loss=1.9815  test_loss=2.2062  λ_max=10.4382\n",
      "[SGD | lr=0.001] Epoch 2852/4000: train_loss=1.9814  test_loss=2.2062  λ_max=10.3350\n",
      "[SGD | lr=0.001] Epoch 2853/4000: train_loss=1.9810  test_loss=2.2062  λ_max=10.9518\n",
      "[SGD | lr=0.001] Epoch 2854/4000: train_loss=1.9808  test_loss=2.2061  λ_max=10.9936\n",
      "[SGD | lr=0.001] Epoch 2855/4000: train_loss=1.9806  test_loss=2.2061  λ_max=10.9986\n",
      "[SGD | lr=0.001] Epoch 2856/4000: train_loss=1.9806  test_loss=2.2061  λ_max=11.0518\n",
      "[SGD | lr=0.001] Iter 45700: loss=1.9860\n",
      "[SGD | lr=0.001] Epoch 2857/4000: train_loss=1.9806  test_loss=2.2060  λ_max=10.9017\n",
      "[SGD | lr=0.001] Epoch 2858/4000: train_loss=1.9803  test_loss=2.2060  λ_max=10.5156\n",
      "[SGD | lr=0.001] Epoch 2859/4000: train_loss=1.9802  test_loss=2.2060  λ_max=11.0443\n",
      "[SGD | lr=0.001] Epoch 2860/4000: train_loss=1.9802  test_loss=2.2060  λ_max=10.9565\n",
      "[SGD | lr=0.001] Epoch 2861/4000: train_loss=1.9798  test_loss=2.2059  λ_max=11.2240\n",
      "[SGD | lr=0.001] Epoch 2862/4000: train_loss=1.9800  test_loss=2.2059  λ_max=11.2475\n",
      "[SGD | lr=0.001] Iter 45800: loss=1.9739\n",
      "[SGD | lr=0.001] Epoch 2863/4000: train_loss=1.9798  test_loss=2.2059  λ_max=10.9815\n",
      "[SGD | lr=0.001] Epoch 2864/4000: train_loss=1.9792  test_loss=2.2058  λ_max=10.4543\n",
      "[SGD | lr=0.001] Epoch 2865/4000: train_loss=1.9793  test_loss=2.2058  λ_max=11.1385\n",
      "[SGD | lr=0.001] Epoch 2866/4000: train_loss=1.9793  test_loss=2.2058  λ_max=11.1733\n",
      "[SGD | lr=0.001] Epoch 2867/4000: train_loss=1.9791  test_loss=2.2057  λ_max=11.2494\n",
      "[SGD | lr=0.001] Epoch 2868/4000: train_loss=1.9787  test_loss=2.2057  λ_max=11.1923\n",
      "[SGD | lr=0.001] Iter 45900: loss=1.9838\n",
      "[SGD | lr=0.001] Epoch 2869/4000: train_loss=1.9784  test_loss=2.2057  λ_max=11.2082\n",
      "[SGD | lr=0.001] Epoch 2870/4000: train_loss=1.9787  test_loss=2.2056  λ_max=11.1319\n",
      "[SGD | lr=0.001] Epoch 2871/4000: train_loss=1.9784  test_loss=2.2056  λ_max=11.3167\n",
      "[SGD | lr=0.001] Epoch 2872/4000: train_loss=1.9782  test_loss=2.2056  λ_max=10.9249\n",
      "[SGD | lr=0.001] Epoch 2873/4000: train_loss=1.9780  test_loss=2.2055  λ_max=11.2208\n",
      "[SGD | lr=0.001] Epoch 2874/4000: train_loss=1.9780  test_loss=2.2055  λ_max=10.6729\n",
      "[SGD | lr=0.001] Iter 46000: loss=1.9857\n",
      "[SGD | lr=0.001] Epoch 2875/4000: train_loss=1.9779  test_loss=2.2055  λ_max=11.0601\n",
      "[SGD | lr=0.001] Epoch 2876/4000: train_loss=1.9778  test_loss=2.2054  λ_max=10.7737\n",
      "[SGD | lr=0.001] Epoch 2877/4000: train_loss=1.9774  test_loss=2.2054  λ_max=10.3668\n",
      "[SGD | lr=0.001] Epoch 2878/4000: train_loss=1.9773  test_loss=2.2054  λ_max=9.7589\n",
      "[SGD | lr=0.001] Epoch 2879/4000: train_loss=1.9771  test_loss=2.2054  λ_max=11.3058\n",
      "[SGD | lr=0.001] Epoch 2880/4000: train_loss=1.9770  test_loss=2.2053  λ_max=10.3987\n",
      "[SGD | lr=0.001] Epoch 2881/4000: train_loss=1.9771  test_loss=2.2053  λ_max=11.1322\n",
      "[SGD | lr=0.001] Iter 46100: loss=1.9791\n",
      "[SGD | lr=0.001] Epoch 2882/4000: train_loss=1.9767  test_loss=2.2053  λ_max=11.0795\n",
      "[SGD | lr=0.001] Epoch 2883/4000: train_loss=1.9767  test_loss=2.2052  λ_max=10.4465\n",
      "[SGD | lr=0.001] Epoch 2884/4000: train_loss=1.9761  test_loss=2.2052  λ_max=10.7690\n",
      "[SGD | lr=0.001] Epoch 2885/4000: train_loss=1.9763  test_loss=2.2052  λ_max=11.0300\n",
      "[SGD | lr=0.001] Epoch 2886/4000: train_loss=1.9760  test_loss=2.2051  λ_max=10.7743\n",
      "[SGD | lr=0.001] Epoch 2887/4000: train_loss=1.9760  test_loss=2.2051  λ_max=10.5514\n",
      "[SGD | lr=0.001] Iter 46200: loss=1.9741\n",
      "[SGD | lr=0.001] Epoch 2888/4000: train_loss=1.9760  test_loss=2.2051  λ_max=11.1555\n",
      "[SGD | lr=0.001] Epoch 2889/4000: train_loss=1.9755  test_loss=2.2050  λ_max=10.4846\n",
      "[SGD | lr=0.001] Epoch 2890/4000: train_loss=1.9753  test_loss=2.2050  λ_max=10.9911\n",
      "[SGD | lr=0.001] Epoch 2891/4000: train_loss=1.9751  test_loss=2.2050  λ_max=11.0965\n",
      "[SGD | lr=0.001] Epoch 2892/4000: train_loss=1.9752  test_loss=2.2049  λ_max=11.2933\n",
      "[SGD | lr=0.001] Epoch 2893/4000: train_loss=1.9749  test_loss=2.2049  λ_max=10.9964\n",
      "[SGD | lr=0.001] Iter 46300: loss=1.9738\n",
      "[SGD | lr=0.001] Epoch 2894/4000: train_loss=1.9748  test_loss=2.2049  λ_max=11.3297\n",
      "[SGD | lr=0.001] Epoch 2895/4000: train_loss=1.9748  test_loss=2.2049  λ_max=10.8069\n",
      "[SGD | lr=0.001] Epoch 2896/4000: train_loss=1.9743  test_loss=2.2048  λ_max=11.3966\n",
      "[SGD | lr=0.001] Epoch 2897/4000: train_loss=1.9743  test_loss=2.2048  λ_max=11.1825\n",
      "[SGD | lr=0.001] Epoch 2898/4000: train_loss=1.9742  test_loss=2.2047  λ_max=10.3657\n",
      "[SGD | lr=0.001] Epoch 2899/4000: train_loss=1.9742  test_loss=2.2047  λ_max=10.6379\n",
      "[SGD | lr=0.001] Iter 46400: loss=1.9639\n",
      "[SGD | lr=0.001] Epoch 2900/4000: train_loss=1.9737  test_loss=2.2047  λ_max=11.4399\n",
      "[SGD | lr=0.001] Epoch 2901/4000: train_loss=1.9738  test_loss=2.2046  λ_max=10.6391\n",
      "[SGD | lr=0.001] Epoch 2902/4000: train_loss=1.9735  test_loss=2.2046  λ_max=10.6930\n",
      "[SGD | lr=0.001] Epoch 2903/4000: train_loss=1.9734  test_loss=2.2046  λ_max=10.8843\n",
      "[SGD | lr=0.001] Epoch 2904/4000: train_loss=1.9736  test_loss=2.2045  λ_max=11.1328\n",
      "[SGD | lr=0.001] Epoch 2905/4000: train_loss=1.9732  test_loss=2.2045  λ_max=11.3060\n",
      "[SGD | lr=0.001] Epoch 2906/4000: train_loss=1.9732  test_loss=2.2045  λ_max=11.3123\n",
      "[SGD | lr=0.001] Iter 46500: loss=1.9690\n",
      "[SGD | lr=0.001] Epoch 2907/4000: train_loss=1.9726  test_loss=2.2045  λ_max=11.4286\n",
      "[SGD | lr=0.001] Epoch 2908/4000: train_loss=1.9724  test_loss=2.2044  λ_max=11.2031\n",
      "[SGD | lr=0.001] Epoch 2909/4000: train_loss=1.9726  test_loss=2.2044  λ_max=11.3139\n",
      "[SGD | lr=0.001] Epoch 2910/4000: train_loss=1.9725  test_loss=2.2044  λ_max=10.8392\n",
      "[SGD | lr=0.001] Epoch 2911/4000: train_loss=1.9722  test_loss=2.2043  λ_max=11.4222\n",
      "[SGD | lr=0.001] Epoch 2912/4000: train_loss=1.9721  test_loss=2.2043  λ_max=10.7594\n",
      "[SGD | lr=0.001] Iter 46600: loss=1.9654\n",
      "[SGD | lr=0.001] Epoch 2913/4000: train_loss=1.9719  test_loss=2.2043  λ_max=11.1327\n",
      "[SGD | lr=0.001] Epoch 2914/4000: train_loss=1.9717  test_loss=2.2042  λ_max=10.8423\n",
      "[SGD | lr=0.001] Epoch 2915/4000: train_loss=1.9716  test_loss=2.2042  λ_max=11.4469\n",
      "[SGD | lr=0.001] Epoch 2916/4000: train_loss=1.9713  test_loss=2.2042  λ_max=10.7290\n",
      "[SGD | lr=0.001] Epoch 2917/4000: train_loss=1.9713  test_loss=2.2041  λ_max=10.7281\n",
      "[SGD | lr=0.001] Epoch 2918/4000: train_loss=1.9711  test_loss=2.2041  λ_max=10.3770\n",
      "[SGD | lr=0.001] Iter 46700: loss=1.9726\n",
      "[SGD | lr=0.001] Epoch 2919/4000: train_loss=1.9710  test_loss=2.2041  λ_max=10.9940\n",
      "[SGD | lr=0.001] Epoch 2920/4000: train_loss=1.9708  test_loss=2.2041  λ_max=11.2830\n",
      "[SGD | lr=0.001] Epoch 2921/4000: train_loss=1.9706  test_loss=2.2040  λ_max=10.5101\n",
      "[SGD | lr=0.001] Epoch 2922/4000: train_loss=1.9705  test_loss=2.2040  λ_max=10.9378\n",
      "[SGD | lr=0.001] Epoch 2923/4000: train_loss=1.9703  test_loss=2.2040  λ_max=11.1913\n",
      "[SGD | lr=0.001] Epoch 2924/4000: train_loss=1.9702  test_loss=2.2039  λ_max=11.3922\n",
      "[SGD | lr=0.001] Iter 46800: loss=1.9640\n",
      "[SGD | lr=0.001] Epoch 2925/4000: train_loss=1.9700  test_loss=2.2039  λ_max=11.5197\n",
      "[SGD | lr=0.001] Epoch 2926/4000: train_loss=1.9701  test_loss=2.2039  λ_max=10.7229\n",
      "[SGD | lr=0.001] Epoch 2927/4000: train_loss=1.9697  test_loss=2.2038  λ_max=11.2868\n",
      "[SGD | lr=0.001] Epoch 2928/4000: train_loss=1.9694  test_loss=2.2038  λ_max=11.0842\n",
      "[SGD | lr=0.001] Epoch 2929/4000: train_loss=1.9695  test_loss=2.2037  λ_max=10.5623\n",
      "[SGD | lr=0.001] Epoch 2930/4000: train_loss=1.9695  test_loss=2.2037  λ_max=10.9816\n",
      "[SGD | lr=0.001] Epoch 2931/4000: train_loss=1.9692  test_loss=2.2037  λ_max=10.7438\n",
      "[SGD | lr=0.001] Iter 46900: loss=1.9690\n",
      "[SGD | lr=0.001] Epoch 2932/4000: train_loss=1.9692  test_loss=2.2037  λ_max=10.7500\n",
      "[SGD | lr=0.001] Epoch 2933/4000: train_loss=1.9690  test_loss=2.2036  λ_max=11.4628\n",
      "[SGD | lr=0.001] Epoch 2934/4000: train_loss=1.9686  test_loss=2.2036  λ_max=11.3661\n",
      "[SGD | lr=0.001] Epoch 2935/4000: train_loss=1.9687  test_loss=2.2036  λ_max=11.0687\n",
      "[SGD | lr=0.001] Epoch 2936/4000: train_loss=1.9686  test_loss=2.2035  λ_max=11.4349\n",
      "[SGD | lr=0.001] Epoch 2937/4000: train_loss=1.9685  test_loss=2.2035  λ_max=11.0013\n",
      "[SGD | lr=0.001] Iter 47000: loss=1.9623\n",
      "[SGD | lr=0.001] Epoch 2938/4000: train_loss=1.9683  test_loss=2.2035  λ_max=10.7784\n",
      "[SGD | lr=0.001] Epoch 2939/4000: train_loss=1.9679  test_loss=2.2034  λ_max=11.3175\n",
      "[SGD | lr=0.001] Epoch 2940/4000: train_loss=1.9680  test_loss=2.2034  λ_max=11.1559\n",
      "[SGD | lr=0.001] Epoch 2941/4000: train_loss=1.9675  test_loss=2.2034  λ_max=11.1573\n",
      "[SGD | lr=0.001] Epoch 2942/4000: train_loss=1.9674  test_loss=2.2033  λ_max=11.4484\n",
      "[SGD | lr=0.001] Epoch 2943/4000: train_loss=1.9674  test_loss=2.2033  λ_max=11.1192\n",
      "[SGD | lr=0.001] Iter 47100: loss=1.9762\n",
      "[SGD | lr=0.001] Epoch 2944/4000: train_loss=1.9673  test_loss=2.2033  λ_max=11.1642\n",
      "[SGD | lr=0.001] Epoch 2945/4000: train_loss=1.9672  test_loss=2.2032  λ_max=10.7799\n",
      "[SGD | lr=0.001] Epoch 2946/4000: train_loss=1.9669  test_loss=2.2032  λ_max=10.9548\n",
      "[SGD | lr=0.001] Epoch 2947/4000: train_loss=1.9664  test_loss=2.2032  λ_max=11.0015\n",
      "[SGD | lr=0.001] Epoch 2948/4000: train_loss=1.9664  test_loss=2.2031  λ_max=10.4320\n",
      "[SGD | lr=0.001] Epoch 2949/4000: train_loss=1.9665  test_loss=2.2031  λ_max=11.1186\n",
      "[SGD | lr=0.001] Iter 47200: loss=1.9693\n",
      "[SGD | lr=0.001] Epoch 2950/4000: train_loss=1.9664  test_loss=2.2031  λ_max=11.2434\n",
      "[SGD | lr=0.001] Epoch 2951/4000: train_loss=1.9661  test_loss=2.2030  λ_max=11.1624\n",
      "[SGD | lr=0.001] Epoch 2952/4000: train_loss=1.9661  test_loss=2.2030  λ_max=11.3828\n",
      "[SGD | lr=0.001] Epoch 2953/4000: train_loss=1.9661  test_loss=2.2030  λ_max=10.9867\n",
      "[SGD | lr=0.001] Epoch 2954/4000: train_loss=1.9657  test_loss=2.2029  λ_max=10.9590\n",
      "[SGD | lr=0.001] Epoch 2955/4000: train_loss=1.9656  test_loss=2.2029  λ_max=11.5235\n",
      "[SGD | lr=0.001] Epoch 2956/4000: train_loss=1.9652  test_loss=2.2029  λ_max=10.4010\n",
      "[SGD | lr=0.001] Iter 47300: loss=1.9629\n",
      "[SGD | lr=0.001] Epoch 2957/4000: train_loss=1.9652  test_loss=2.2028  λ_max=11.1496\n",
      "[SGD | lr=0.001] Epoch 2958/4000: train_loss=1.9651  test_loss=2.2028  λ_max=11.1333\n",
      "[SGD | lr=0.001] Epoch 2959/4000: train_loss=1.9649  test_loss=2.2028  λ_max=11.2038\n",
      "[SGD | lr=0.001] Epoch 2960/4000: train_loss=1.9649  test_loss=2.2027  λ_max=10.6711\n",
      "[SGD | lr=0.001] Epoch 2961/4000: train_loss=1.9647  test_loss=2.2027  λ_max=10.8441\n",
      "[SGD | lr=0.001] Epoch 2962/4000: train_loss=1.9643  test_loss=2.2027  λ_max=11.4095\n",
      "[SGD | lr=0.001] Iter 47400: loss=1.9598\n",
      "[SGD | lr=0.001] Epoch 2963/4000: train_loss=1.9644  test_loss=2.2026  λ_max=10.9924\n",
      "[SGD | lr=0.001] Epoch 2964/4000: train_loss=1.9642  test_loss=2.2026  λ_max=11.1411\n",
      "[SGD | lr=0.001] Epoch 2965/4000: train_loss=1.9639  test_loss=2.2026  λ_max=11.0137\n",
      "[SGD | lr=0.001] Epoch 2966/4000: train_loss=1.9638  test_loss=2.2025  λ_max=11.3581\n",
      "[SGD | lr=0.001] Epoch 2967/4000: train_loss=1.9639  test_loss=2.2025  λ_max=10.6962\n",
      "[SGD | lr=0.001] Epoch 2968/4000: train_loss=1.9635  test_loss=2.2025  λ_max=11.7003\n",
      "[SGD | lr=0.001] Iter 47500: loss=1.9659\n",
      "[SGD | lr=0.001] Epoch 2969/4000: train_loss=1.9633  test_loss=2.2025  λ_max=11.2120\n",
      "[SGD | lr=0.001] Epoch 2970/4000: train_loss=1.9632  test_loss=2.2024  λ_max=11.0982\n",
      "[SGD | lr=0.001] Epoch 2971/4000: train_loss=1.9632  test_loss=2.2024  λ_max=11.0759\n",
      "[SGD | lr=0.001] Epoch 2972/4000: train_loss=1.9630  test_loss=2.2023  λ_max=11.7672\n",
      "[SGD | lr=0.001] Epoch 2973/4000: train_loss=1.9628  test_loss=2.2023  λ_max=11.3208\n",
      "[SGD | lr=0.001] Epoch 2974/4000: train_loss=1.9630  test_loss=2.2023  λ_max=11.5456\n",
      "[SGD | lr=0.001] Iter 47600: loss=1.9643\n",
      "[SGD | lr=0.001] Epoch 2975/4000: train_loss=1.9626  test_loss=2.2023  λ_max=11.0406\n",
      "[SGD | lr=0.001] Epoch 2976/4000: train_loss=1.9625  test_loss=2.2022  λ_max=11.2859\n",
      "[SGD | lr=0.001] Epoch 2977/4000: train_loss=1.9624  test_loss=2.2022  λ_max=11.4620\n",
      "[SGD | lr=0.001] Epoch 2978/4000: train_loss=1.9618  test_loss=2.2022  λ_max=11.7193\n",
      "[SGD | lr=0.001] Epoch 2979/4000: train_loss=1.9618  test_loss=2.2021  λ_max=10.7395\n",
      "[SGD | lr=0.001] Epoch 2980/4000: train_loss=1.9618  test_loss=2.2021  λ_max=11.1422\n",
      "[SGD | lr=0.001] Epoch 2981/4000: train_loss=1.9615  test_loss=2.2021  λ_max=10.9599\n",
      "[SGD | lr=0.001] Iter 47700: loss=1.9568\n",
      "[SGD | lr=0.001] Epoch 2982/4000: train_loss=1.9615  test_loss=2.2020  λ_max=11.2971\n",
      "[SGD | lr=0.001] Epoch 2983/4000: train_loss=1.9613  test_loss=2.2020  λ_max=11.7732\n",
      "[SGD | lr=0.001] Epoch 2984/4000: train_loss=1.9613  test_loss=2.2020  λ_max=11.3121\n",
      "[SGD | lr=0.001] Epoch 2985/4000: train_loss=1.9609  test_loss=2.2019  λ_max=11.2045\n",
      "[SGD | lr=0.001] Epoch 2986/4000: train_loss=1.9609  test_loss=2.2019  λ_max=11.3687\n",
      "[SGD | lr=0.001] Epoch 2987/4000: train_loss=1.9607  test_loss=2.2019  λ_max=10.9457\n",
      "[SGD | lr=0.001] Iter 47800: loss=1.9663\n",
      "[SGD | lr=0.001] Epoch 2988/4000: train_loss=1.9606  test_loss=2.2018  λ_max=10.7014\n",
      "[SGD | lr=0.001] Epoch 2989/4000: train_loss=1.9606  test_loss=2.2018  λ_max=11.2107\n",
      "[SGD | lr=0.001] Epoch 2990/4000: train_loss=1.9604  test_loss=2.2018  λ_max=11.2425\n",
      "[SGD | lr=0.001] Epoch 2991/4000: train_loss=1.9602  test_loss=2.2017  λ_max=11.3082\n",
      "[SGD | lr=0.001] Epoch 2992/4000: train_loss=1.9600  test_loss=2.2017  λ_max=11.6035\n",
      "[SGD | lr=0.001] Epoch 2993/4000: train_loss=1.9599  test_loss=2.2017  λ_max=11.6647\n",
      "[SGD | lr=0.001] Iter 47900: loss=1.9557\n",
      "[SGD | lr=0.001] Epoch 2994/4000: train_loss=1.9598  test_loss=2.2016  λ_max=11.6866\n",
      "[SGD | lr=0.001] Epoch 2995/4000: train_loss=1.9596  test_loss=2.2016  λ_max=11.5106\n",
      "[SGD | lr=0.001] Epoch 2996/4000: train_loss=1.9593  test_loss=2.2016  λ_max=11.6778\n",
      "[SGD | lr=0.001] Epoch 2997/4000: train_loss=1.9592  test_loss=2.2015  λ_max=11.1429\n",
      "[SGD | lr=0.001] Epoch 2998/4000: train_loss=1.9590  test_loss=2.2015  λ_max=11.7370\n",
      "[SGD | lr=0.001] Epoch 2999/4000: train_loss=1.9590  test_loss=2.2015  λ_max=10.9718\n",
      "[SGD | lr=0.001] Iter 48000: loss=1.9556\n",
      "[SGD | lr=0.001] Epoch 3000/4000: train_loss=1.9587  test_loss=2.2014  λ_max=11.2356\n",
      "[SGD | lr=0.001] Epoch 3001/4000: train_loss=1.9587  test_loss=2.2014  λ_max=11.3894\n",
      "[SGD | lr=0.001] Epoch 3002/4000: train_loss=1.9583  test_loss=2.2014  λ_max=11.4817\n",
      "[SGD | lr=0.001] Epoch 3003/4000: train_loss=1.9586  test_loss=2.2013  λ_max=11.3449\n",
      "[SGD | lr=0.001] Epoch 3004/4000: train_loss=1.9579  test_loss=2.2013  λ_max=11.7544\n",
      "[SGD | lr=0.001] Epoch 3005/4000: train_loss=1.9582  test_loss=2.2013  λ_max=11.1458\n",
      "[SGD | lr=0.001] Epoch 3006/4000: train_loss=1.9580  test_loss=2.2012  λ_max=11.4232\n",
      "[SGD | lr=0.001] Iter 48100: loss=1.9481\n",
      "[SGD | lr=0.001] Epoch 3007/4000: train_loss=1.9576  test_loss=2.2012  λ_max=11.6428\n",
      "[SGD | lr=0.001] Epoch 3008/4000: train_loss=1.9577  test_loss=2.2012  λ_max=11.2502\n",
      "[SGD | lr=0.001] Epoch 3009/4000: train_loss=1.9577  test_loss=2.2011  λ_max=11.0689\n",
      "[SGD | lr=0.001] Epoch 3010/4000: train_loss=1.9573  test_loss=2.2011  λ_max=11.1323\n",
      "[SGD | lr=0.001] Epoch 3011/4000: train_loss=1.9571  test_loss=2.2011  λ_max=11.3553\n",
      "[SGD | lr=0.001] Epoch 3012/4000: train_loss=1.9569  test_loss=2.2010  λ_max=11.6899\n",
      "[SGD | lr=0.001] Iter 48200: loss=1.9615\n",
      "[SGD | lr=0.001] Epoch 3013/4000: train_loss=1.9569  test_loss=2.2010  λ_max=10.8918\n",
      "[SGD | lr=0.001] Epoch 3014/4000: train_loss=1.9568  test_loss=2.2010  λ_max=11.2250\n",
      "[SGD | lr=0.001] Epoch 3015/4000: train_loss=1.9567  test_loss=2.2009  λ_max=11.3198\n",
      "[SGD | lr=0.001] Epoch 3016/4000: train_loss=1.9564  test_loss=2.2009  λ_max=11.8169\n",
      "[SGD | lr=0.001] Epoch 3017/4000: train_loss=1.9562  test_loss=2.2009  λ_max=11.6623\n",
      "[SGD | lr=0.001] Epoch 3018/4000: train_loss=1.9563  test_loss=2.2008  λ_max=11.8408\n",
      "[SGD | lr=0.001] Iter 48300: loss=1.9572\n",
      "[SGD | lr=0.001] Epoch 3019/4000: train_loss=1.9560  test_loss=2.2008  λ_max=11.2802\n",
      "[SGD | lr=0.001] Epoch 3020/4000: train_loss=1.9556  test_loss=2.2008  λ_max=11.2902\n",
      "[SGD | lr=0.001] Epoch 3021/4000: train_loss=1.9557  test_loss=2.2007  λ_max=11.3104\n",
      "[SGD | lr=0.001] Epoch 3022/4000: train_loss=1.9554  test_loss=2.2007  λ_max=11.7965\n",
      "[SGD | lr=0.001] Epoch 3023/4000: train_loss=1.9557  test_loss=2.2007  λ_max=11.3161\n",
      "[SGD | lr=0.001] Epoch 3024/4000: train_loss=1.9555  test_loss=2.2006  λ_max=11.8811\n",
      "[SGD | lr=0.001] Iter 48400: loss=1.9508\n",
      "[SGD | lr=0.001] Epoch 3025/4000: train_loss=1.9549  test_loss=2.2006  λ_max=11.8456\n",
      "[SGD | lr=0.001] Epoch 3026/4000: train_loss=1.9549  test_loss=2.2006  λ_max=11.3672\n",
      "[SGD | lr=0.001] Epoch 3027/4000: train_loss=1.9546  test_loss=2.2005  λ_max=11.1770\n",
      "[SGD | lr=0.001] Epoch 3028/4000: train_loss=1.9545  test_loss=2.2005  λ_max=11.5340\n",
      "[SGD | lr=0.001] Epoch 3029/4000: train_loss=1.9546  test_loss=2.2005  λ_max=11.4320\n",
      "[SGD | lr=0.001] Epoch 3030/4000: train_loss=1.9542  test_loss=2.2004  λ_max=11.3502\n",
      "[SGD | lr=0.001] Epoch 3031/4000: train_loss=1.9541  test_loss=2.2004  λ_max=11.7845\n",
      "[SGD | lr=0.001] Iter 48500: loss=1.9510\n",
      "[SGD | lr=0.001] Epoch 3032/4000: train_loss=1.9539  test_loss=2.2003  λ_max=10.8049\n",
      "[SGD | lr=0.001] Epoch 3033/4000: train_loss=1.9540  test_loss=2.2003  λ_max=11.5105\n",
      "[SGD | lr=0.001] Epoch 3034/4000: train_loss=1.9535  test_loss=2.2003  λ_max=11.4324\n",
      "[SGD | lr=0.001] Epoch 3035/4000: train_loss=1.9533  test_loss=2.2003  λ_max=10.1635\n",
      "[SGD | lr=0.001] Epoch 3036/4000: train_loss=1.9533  test_loss=2.2002  λ_max=11.5874\n",
      "[SGD | lr=0.001] Epoch 3037/4000: train_loss=1.9532  test_loss=2.2002  λ_max=11.4142\n",
      "[SGD | lr=0.001] Iter 48600: loss=1.9552\n",
      "[SGD | lr=0.001] Epoch 3038/4000: train_loss=1.9530  test_loss=2.2002  λ_max=11.1518\n",
      "[SGD | lr=0.001] Epoch 3039/4000: train_loss=1.9530  test_loss=2.2001  λ_max=11.5049\n",
      "[SGD | lr=0.001] Epoch 3040/4000: train_loss=1.9526  test_loss=2.2001  λ_max=11.3383\n",
      "[SGD | lr=0.001] Epoch 3041/4000: train_loss=1.9525  test_loss=2.2001  λ_max=11.8389\n",
      "[SGD | lr=0.001] Epoch 3042/4000: train_loss=1.9524  test_loss=2.2000  λ_max=10.9353\n",
      "[SGD | lr=0.001] Epoch 3043/4000: train_loss=1.9522  test_loss=2.2000  λ_max=11.3957\n",
      "[SGD | lr=0.001] Iter 48700: loss=1.9504\n",
      "[SGD | lr=0.001] Epoch 3044/4000: train_loss=1.9521  test_loss=2.2000  λ_max=11.7284\n",
      "[SGD | lr=0.001] Epoch 3045/4000: train_loss=1.9519  test_loss=2.1999  λ_max=11.3396\n",
      "[SGD | lr=0.001] Epoch 3046/4000: train_loss=1.9515  test_loss=2.1999  λ_max=11.0653\n",
      "[SGD | lr=0.001] Epoch 3047/4000: train_loss=1.9516  test_loss=2.1999  λ_max=11.5294\n",
      "[SGD | lr=0.001] Epoch 3048/4000: train_loss=1.9516  test_loss=2.1998  λ_max=11.5596\n",
      "[SGD | lr=0.001] Epoch 3049/4000: train_loss=1.9513  test_loss=2.1998  λ_max=11.7227\n",
      "[SGD | lr=0.001] Iter 48800: loss=1.9417\n",
      "[SGD | lr=0.001] Epoch 3050/4000: train_loss=1.9510  test_loss=2.1998  λ_max=11.5790\n",
      "[SGD | lr=0.001] Epoch 3051/4000: train_loss=1.9510  test_loss=2.1997  λ_max=11.9117\n",
      "[SGD | lr=0.001] Epoch 3052/4000: train_loss=1.9509  test_loss=2.1997  λ_max=11.0999\n",
      "[SGD | lr=0.001] Epoch 3053/4000: train_loss=1.9508  test_loss=2.1997  λ_max=11.3867\n",
      "[SGD | lr=0.001] Epoch 3054/4000: train_loss=1.9506  test_loss=2.1996  λ_max=12.0075\n",
      "[SGD | lr=0.001] Epoch 3055/4000: train_loss=1.9505  test_loss=2.1996  λ_max=11.9125\n",
      "[SGD | lr=0.001] Epoch 3056/4000: train_loss=1.9504  test_loss=2.1996  λ_max=11.8483\n",
      "[SGD | lr=0.001] Iter 48900: loss=1.9492\n",
      "[SGD | lr=0.001] Epoch 3057/4000: train_loss=1.9500  test_loss=2.1995  λ_max=11.8593\n",
      "[SGD | lr=0.001] Epoch 3058/4000: train_loss=1.9499  test_loss=2.1995  λ_max=10.8441\n",
      "[SGD | lr=0.001] Epoch 3059/4000: train_loss=1.9499  test_loss=2.1995  λ_max=11.8585\n",
      "[SGD | lr=0.001] Epoch 3060/4000: train_loss=1.9498  test_loss=2.1994  λ_max=10.9506\n",
      "[SGD | lr=0.001] Epoch 3061/4000: train_loss=1.9498  test_loss=2.1994  λ_max=11.6123\n",
      "[SGD | lr=0.001] Epoch 3062/4000: train_loss=1.9498  test_loss=2.1994  λ_max=11.5797\n",
      "[SGD | lr=0.001] Iter 49000: loss=1.9580\n",
      "[SGD | lr=0.001] Epoch 3063/4000: train_loss=1.9495  test_loss=2.1993  λ_max=11.0799\n",
      "[SGD | lr=0.001] Epoch 3064/4000: train_loss=1.9492  test_loss=2.1993  λ_max=11.1551\n",
      "[SGD | lr=0.001] Epoch 3065/4000: train_loss=1.9493  test_loss=2.1993  λ_max=11.6128\n",
      "[SGD | lr=0.001] Epoch 3066/4000: train_loss=1.9489  test_loss=2.1992  λ_max=11.1517\n",
      "[SGD | lr=0.001] Epoch 3067/4000: train_loss=1.9489  test_loss=2.1992  λ_max=11.2747\n",
      "[SGD | lr=0.001] Epoch 3068/4000: train_loss=1.9485  test_loss=2.1991  λ_max=11.4490\n",
      "[SGD | lr=0.001] Iter 49100: loss=1.9432\n",
      "[SGD | lr=0.001] Epoch 3069/4000: train_loss=1.9484  test_loss=2.1991  λ_max=11.0756\n",
      "[SGD | lr=0.001] Epoch 3070/4000: train_loss=1.9483  test_loss=2.1991  λ_max=11.4957\n",
      "[SGD | lr=0.001] Epoch 3071/4000: train_loss=1.9485  test_loss=2.1990  λ_max=11.3165\n",
      "[SGD | lr=0.001] Epoch 3072/4000: train_loss=1.9483  test_loss=2.1990  λ_max=11.9106\n",
      "[SGD | lr=0.001] Epoch 3073/4000: train_loss=1.9477  test_loss=2.1990  λ_max=11.3837\n",
      "[SGD | lr=0.001] Epoch 3074/4000: train_loss=1.9476  test_loss=2.1990  λ_max=11.5862\n",
      "[SGD | lr=0.001] Iter 49200: loss=1.9529\n",
      "[SGD | lr=0.001] Epoch 3075/4000: train_loss=1.9477  test_loss=2.1989  λ_max=11.0414\n",
      "[SGD | lr=0.001] Epoch 3076/4000: train_loss=1.9476  test_loss=2.1989  λ_max=11.5365\n",
      "[SGD | lr=0.001] Epoch 3077/4000: train_loss=1.9473  test_loss=2.1988  λ_max=11.3154\n",
      "[SGD | lr=0.001] Epoch 3078/4000: train_loss=1.9469  test_loss=2.1988  λ_max=11.2381\n",
      "[SGD | lr=0.001] Epoch 3079/4000: train_loss=1.9471  test_loss=2.1988  λ_max=11.8096\n",
      "[SGD | lr=0.001] Epoch 3080/4000: train_loss=1.9468  test_loss=2.1988  λ_max=11.4290\n",
      "[SGD | lr=0.001] Epoch 3081/4000: train_loss=1.9465  test_loss=2.1987  λ_max=11.1617\n",
      "[SGD | lr=0.001] Iter 49300: loss=1.9469\n",
      "[SGD | lr=0.001] Epoch 3082/4000: train_loss=1.9467  test_loss=2.1987  λ_max=11.5335\n",
      "[SGD | lr=0.001] Epoch 3083/4000: train_loss=1.9463  test_loss=2.1987  λ_max=11.7581\n",
      "[SGD | lr=0.001] Epoch 3084/4000: train_loss=1.9461  test_loss=2.1986  λ_max=11.1716\n",
      "[SGD | lr=0.001] Epoch 3085/4000: train_loss=1.9460  test_loss=2.1986  λ_max=11.1336\n",
      "[SGD | lr=0.001] Epoch 3086/4000: train_loss=1.9461  test_loss=2.1985  λ_max=11.2297\n",
      "[SGD | lr=0.001] Epoch 3087/4000: train_loss=1.9459  test_loss=2.1985  λ_max=11.9677\n",
      "[SGD | lr=0.001] Iter 49400: loss=1.9489\n",
      "[SGD | lr=0.001] Epoch 3088/4000: train_loss=1.9456  test_loss=2.1985  λ_max=11.5317\n",
      "[SGD | lr=0.001] Epoch 3089/4000: train_loss=1.9452  test_loss=2.1984  λ_max=11.8645\n",
      "[SGD | lr=0.001] Epoch 3090/4000: train_loss=1.9455  test_loss=2.1984  λ_max=11.5869\n",
      "[SGD | lr=0.001] Epoch 3091/4000: train_loss=1.9450  test_loss=2.1984  λ_max=11.8264\n",
      "[SGD | lr=0.001] Epoch 3092/4000: train_loss=1.9450  test_loss=2.1983  λ_max=12.0678\n",
      "[SGD | lr=0.001] Epoch 3093/4000: train_loss=1.9447  test_loss=2.1983  λ_max=11.9175\n",
      "[SGD | lr=0.001] Iter 49500: loss=1.9454\n",
      "[SGD | lr=0.001] Epoch 3094/4000: train_loss=1.9446  test_loss=2.1983  λ_max=11.5265\n",
      "[SGD | lr=0.001] Epoch 3095/4000: train_loss=1.9446  test_loss=2.1982  λ_max=11.4494\n",
      "[SGD | lr=0.001] Epoch 3096/4000: train_loss=1.9446  test_loss=2.1982  λ_max=11.2717\n",
      "[SGD | lr=0.001] Epoch 3097/4000: train_loss=1.9441  test_loss=2.1982  λ_max=11.4442\n",
      "[SGD | lr=0.001] Epoch 3098/4000: train_loss=1.9442  test_loss=2.1981  λ_max=11.1767\n",
      "[SGD | lr=0.001] Epoch 3099/4000: train_loss=1.9440  test_loss=2.1981  λ_max=11.7582\n",
      "[SGD | lr=0.001] Iter 49600: loss=1.9367\n",
      "[SGD | lr=0.001] Epoch 3100/4000: train_loss=1.9437  test_loss=2.1981  λ_max=11.6220\n",
      "[SGD | lr=0.001] Epoch 3101/4000: train_loss=1.9437  test_loss=2.1980  λ_max=11.9076\n",
      "[SGD | lr=0.001] Epoch 3102/4000: train_loss=1.9436  test_loss=2.1980  λ_max=11.4938\n",
      "[SGD | lr=0.001] Epoch 3103/4000: train_loss=1.9433  test_loss=2.1980  λ_max=11.5355\n",
      "[SGD | lr=0.001] Epoch 3104/4000: train_loss=1.9434  test_loss=2.1979  λ_max=11.5772\n",
      "[SGD | lr=0.001] Epoch 3105/4000: train_loss=1.9431  test_loss=2.1979  λ_max=12.0638\n",
      "[SGD | lr=0.001] Epoch 3106/4000: train_loss=1.9430  test_loss=2.1979  λ_max=11.5335\n",
      "[SGD | lr=0.001] Iter 49700: loss=1.9402\n",
      "[SGD | lr=0.001] Epoch 3107/4000: train_loss=1.9428  test_loss=2.1979  λ_max=11.5348\n",
      "[SGD | lr=0.001] Epoch 3108/4000: train_loss=1.9427  test_loss=2.1978  λ_max=11.4060\n",
      "[SGD | lr=0.001] Epoch 3109/4000: train_loss=1.9425  test_loss=2.1978  λ_max=11.6949\n",
      "[SGD | lr=0.001] Epoch 3110/4000: train_loss=1.9422  test_loss=2.1977  λ_max=11.8371\n",
      "[SGD | lr=0.001] Epoch 3111/4000: train_loss=1.9422  test_loss=2.1977  λ_max=11.7441\n",
      "[SGD | lr=0.001] Epoch 3112/4000: train_loss=1.9421  test_loss=2.1977  λ_max=11.6324\n",
      "[SGD | lr=0.001] Iter 49800: loss=1.9510\n",
      "[SGD | lr=0.001] Epoch 3113/4000: train_loss=1.9417  test_loss=2.1976  λ_max=11.5100\n",
      "[SGD | lr=0.001] Epoch 3114/4000: train_loss=1.9417  test_loss=2.1976  λ_max=11.3697\n",
      "[SGD | lr=0.001] Epoch 3115/4000: train_loss=1.9417  test_loss=2.1976  λ_max=11.4902\n",
      "[SGD | lr=0.001] Epoch 3116/4000: train_loss=1.9414  test_loss=2.1975  λ_max=11.6217\n",
      "[SGD | lr=0.001] Epoch 3117/4000: train_loss=1.9413  test_loss=2.1975  λ_max=11.6736\n",
      "[SGD | lr=0.001] Epoch 3118/4000: train_loss=1.9412  test_loss=2.1975  λ_max=11.2502\n",
      "[SGD | lr=0.001] Iter 49900: loss=1.9336\n",
      "[SGD | lr=0.001] Epoch 3119/4000: train_loss=1.9408  test_loss=2.1974  λ_max=11.8615\n",
      "[SGD | lr=0.001] Epoch 3120/4000: train_loss=1.9411  test_loss=2.1974  λ_max=12.1447\n",
      "[SGD | lr=0.001] Epoch 3121/4000: train_loss=1.9403  test_loss=2.1974  λ_max=11.8765\n",
      "[SGD | lr=0.001] Epoch 3122/4000: train_loss=1.9407  test_loss=2.1973  λ_max=11.5558\n",
      "[SGD | lr=0.001] Epoch 3123/4000: train_loss=1.9403  test_loss=2.1973  λ_max=11.8273\n",
      "[SGD | lr=0.001] Epoch 3124/4000: train_loss=1.9404  test_loss=2.1972  λ_max=11.1999\n",
      "[SGD | lr=0.001] Iter 50000: loss=1.9416\n",
      "[SGD | lr=0.001] Epoch 3125/4000: train_loss=1.9402  test_loss=2.1972  λ_max=10.8903\n",
      "[SGD | lr=0.001] Epoch 3126/4000: train_loss=1.9401  test_loss=2.1972  λ_max=11.6405\n",
      "[SGD | lr=0.001] Epoch 3127/4000: train_loss=1.9399  test_loss=2.1972  λ_max=11.4665\n",
      "[SGD | lr=0.001] Epoch 3128/4000: train_loss=1.9396  test_loss=2.1971  λ_max=12.0124\n",
      "[SGD | lr=0.001] Epoch 3129/4000: train_loss=1.9395  test_loss=2.1971  λ_max=11.6220\n",
      "[SGD | lr=0.001] Epoch 3130/4000: train_loss=1.9393  test_loss=2.1971  λ_max=12.2191\n",
      "[SGD | lr=0.001] Epoch 3131/4000: train_loss=1.9393  test_loss=2.1970  λ_max=10.8701\n",
      "[SGD | lr=0.001] Iter 50100: loss=1.9365\n",
      "[SGD | lr=0.001] Epoch 3132/4000: train_loss=1.9393  test_loss=2.1970  λ_max=11.9482\n",
      "[SGD | lr=0.001] Epoch 3133/4000: train_loss=1.9392  test_loss=2.1970  λ_max=12.1595\n",
      "[SGD | lr=0.001] Epoch 3134/4000: train_loss=1.9390  test_loss=2.1969  λ_max=11.4792\n",
      "[SGD | lr=0.001] Epoch 3135/4000: train_loss=1.9388  test_loss=2.1969  λ_max=11.4240\n",
      "[SGD | lr=0.001] Epoch 3136/4000: train_loss=1.9382  test_loss=2.1969  λ_max=11.5342\n",
      "[SGD | lr=0.001] Epoch 3137/4000: train_loss=1.9382  test_loss=2.1968  λ_max=11.0162\n",
      "[SGD | lr=0.001] Iter 50200: loss=1.9321\n",
      "[SGD | lr=0.001] Epoch 3138/4000: train_loss=1.9379  test_loss=2.1968  λ_max=12.2757\n",
      "[SGD | lr=0.001] Epoch 3139/4000: train_loss=1.9383  test_loss=2.1968  λ_max=12.0984\n",
      "[SGD | lr=0.001] Epoch 3140/4000: train_loss=1.9378  test_loss=2.1967  λ_max=11.4502\n",
      "[SGD | lr=0.001] Epoch 3141/4000: train_loss=1.9379  test_loss=2.1967  λ_max=11.3041\n",
      "[SGD | lr=0.001] Epoch 3142/4000: train_loss=1.9378  test_loss=2.1967  λ_max=11.2872\n",
      "[SGD | lr=0.001] Epoch 3143/4000: train_loss=1.9375  test_loss=2.1966  λ_max=12.0117\n",
      "[SGD | lr=0.001] Iter 50300: loss=1.9386\n",
      "[SGD | lr=0.001] Epoch 3144/4000: train_loss=1.9373  test_loss=2.1966  λ_max=11.5256\n",
      "[SGD | lr=0.001] Epoch 3145/4000: train_loss=1.9373  test_loss=2.1966  λ_max=12.1186\n",
      "[SGD | lr=0.001] Epoch 3146/4000: train_loss=1.9371  test_loss=2.1965  λ_max=11.5714\n",
      "[SGD | lr=0.001] Epoch 3147/4000: train_loss=1.9370  test_loss=2.1965  λ_max=11.8858\n",
      "[SGD | lr=0.001] Epoch 3148/4000: train_loss=1.9368  test_loss=2.1965  λ_max=12.2866\n",
      "[SGD | lr=0.001] Epoch 3149/4000: train_loss=1.9365  test_loss=2.1964  λ_max=11.4179\n",
      "[SGD | lr=0.001] Iter 50400: loss=1.9247\n",
      "[SGD | lr=0.001] Epoch 3150/4000: train_loss=1.9362  test_loss=2.1964  λ_max=11.8991\n",
      "[SGD | lr=0.001] Epoch 3151/4000: train_loss=1.9361  test_loss=2.1964  λ_max=11.7975\n",
      "[SGD | lr=0.001] Epoch 3152/4000: train_loss=1.9361  test_loss=2.1963  λ_max=11.9097\n",
      "[SGD | lr=0.001] Epoch 3153/4000: train_loss=1.9362  test_loss=2.1963  λ_max=11.7948\n",
      "[SGD | lr=0.001] Epoch 3154/4000: train_loss=1.9360  test_loss=2.1963  λ_max=11.7629\n",
      "[SGD | lr=0.001] Epoch 3155/4000: train_loss=1.9356  test_loss=2.1962  λ_max=12.1591\n",
      "[SGD | lr=0.001] Epoch 3156/4000: train_loss=1.9357  test_loss=2.1962  λ_max=11.3698\n",
      "[SGD | lr=0.001] Iter 50500: loss=1.9346\n",
      "[SGD | lr=0.001] Epoch 3157/4000: train_loss=1.9355  test_loss=2.1962  λ_max=11.7479\n",
      "[SGD | lr=0.001] Epoch 3158/4000: train_loss=1.9353  test_loss=2.1961  λ_max=11.6816\n",
      "[SGD | lr=0.001] Epoch 3159/4000: train_loss=1.9347  test_loss=2.1961  λ_max=11.7876\n",
      "[SGD | lr=0.001] Epoch 3160/4000: train_loss=1.9349  test_loss=2.1961  λ_max=11.6300\n",
      "[SGD | lr=0.001] Epoch 3161/4000: train_loss=1.9349  test_loss=2.1960  λ_max=12.1390\n",
      "[SGD | lr=0.001] Epoch 3162/4000: train_loss=1.9348  test_loss=2.1960  λ_max=11.1987\n",
      "[SGD | lr=0.001] Iter 50600: loss=1.9335\n",
      "[SGD | lr=0.001] Epoch 3163/4000: train_loss=1.9344  test_loss=2.1960  λ_max=12.2085\n",
      "[SGD | lr=0.001] Epoch 3164/4000: train_loss=1.9341  test_loss=2.1959  λ_max=11.9323\n",
      "[SGD | lr=0.001] Epoch 3165/4000: train_loss=1.9341  test_loss=2.1959  λ_max=11.8362\n",
      "[SGD | lr=0.001] Epoch 3166/4000: train_loss=1.9342  test_loss=2.1959  λ_max=11.4064\n",
      "[SGD | lr=0.001] Epoch 3167/4000: train_loss=1.9340  test_loss=2.1958  λ_max=11.7294\n",
      "[SGD | lr=0.001] Epoch 3168/4000: train_loss=1.9338  test_loss=2.1958  λ_max=11.5266\n",
      "[SGD | lr=0.001] Iter 50700: loss=1.9313\n",
      "[SGD | lr=0.001] Epoch 3169/4000: train_loss=1.9334  test_loss=2.1958  λ_max=12.5007\n",
      "[SGD | lr=0.001] Epoch 3170/4000: train_loss=1.9334  test_loss=2.1957  λ_max=11.4296\n",
      "[SGD | lr=0.001] Epoch 3171/4000: train_loss=1.9332  test_loss=2.1957  λ_max=11.5608\n",
      "[SGD | lr=0.001] Epoch 3172/4000: train_loss=1.9330  test_loss=2.1957  λ_max=12.1014\n",
      "[SGD | lr=0.001] Epoch 3173/4000: train_loss=1.9327  test_loss=2.1956  λ_max=11.8379\n",
      "[SGD | lr=0.001] Epoch 3174/4000: train_loss=1.9327  test_loss=2.1956  λ_max=11.3573\n",
      "[SGD | lr=0.001] Iter 50800: loss=1.9334\n",
      "[SGD | lr=0.001] Epoch 3175/4000: train_loss=1.9328  test_loss=2.1956  λ_max=12.4733\n",
      "[SGD | lr=0.001] Epoch 3176/4000: train_loss=1.9326  test_loss=2.1955  λ_max=11.8110\n",
      "[SGD | lr=0.001] Epoch 3177/4000: train_loss=1.9324  test_loss=2.1955  λ_max=11.9394\n",
      "[SGD | lr=0.001] Epoch 3178/4000: train_loss=1.9323  test_loss=2.1955  λ_max=12.1992\n",
      "[SGD | lr=0.001] Epoch 3179/4000: train_loss=1.9318  test_loss=2.1954  λ_max=12.4855\n",
      "[SGD | lr=0.001] Epoch 3180/4000: train_loss=1.9320  test_loss=2.1954  λ_max=11.4399\n",
      "[SGD | lr=0.001] Epoch 3181/4000: train_loss=1.9319  test_loss=2.1954  λ_max=11.2771\n",
      "[SGD | lr=0.001] Iter 50900: loss=1.9312\n",
      "[SGD | lr=0.001] Epoch 3182/4000: train_loss=1.9317  test_loss=2.1954  λ_max=12.0703\n",
      "[SGD | lr=0.001] Epoch 3183/4000: train_loss=1.9317  test_loss=2.1953  λ_max=12.4877\n",
      "[SGD | lr=0.001] Epoch 3184/4000: train_loss=1.9315  test_loss=2.1953  λ_max=12.2618\n",
      "[SGD | lr=0.001] Epoch 3185/4000: train_loss=1.9313  test_loss=2.1953  λ_max=11.5770\n",
      "[SGD | lr=0.001] Epoch 3186/4000: train_loss=1.9313  test_loss=2.1952  λ_max=12.2643\n",
      "[SGD | lr=0.001] Epoch 3187/4000: train_loss=1.9310  test_loss=2.1952  λ_max=11.7189\n",
      "[SGD | lr=0.001] Iter 51000: loss=1.9261\n",
      "[SGD | lr=0.001] Epoch 3188/4000: train_loss=1.9307  test_loss=2.1952  λ_max=12.0186\n",
      "[SGD | lr=0.001] Epoch 3189/4000: train_loss=1.9308  test_loss=2.1951  λ_max=12.4823\n",
      "[SGD | lr=0.001] Epoch 3190/4000: train_loss=1.9305  test_loss=2.1951  λ_max=12.4357\n",
      "[SGD | lr=0.001] Epoch 3191/4000: train_loss=1.9305  test_loss=2.1950  λ_max=12.2806\n",
      "[SGD | lr=0.001] Epoch 3192/4000: train_loss=1.9304  test_loss=2.1950  λ_max=12.2668\n",
      "[SGD | lr=0.001] Epoch 3193/4000: train_loss=1.9302  test_loss=2.1950  λ_max=11.9390\n",
      "[SGD | lr=0.001] Iter 51100: loss=1.9336\n",
      "[SGD | lr=0.001] Epoch 3194/4000: train_loss=1.9300  test_loss=2.1950  λ_max=12.3892\n",
      "[SGD | lr=0.001] Epoch 3195/4000: train_loss=1.9299  test_loss=2.1949  λ_max=12.0797\n",
      "[SGD | lr=0.001] Epoch 3196/4000: train_loss=1.9298  test_loss=2.1949  λ_max=11.8136\n",
      "[SGD | lr=0.001] Epoch 3197/4000: train_loss=1.9294  test_loss=2.1949  λ_max=12.0437\n",
      "[SGD | lr=0.001] Epoch 3198/4000: train_loss=1.9295  test_loss=2.1948  λ_max=12.0952\n",
      "[SGD | lr=0.001] Epoch 3199/4000: train_loss=1.9291  test_loss=2.1948  λ_max=11.6919\n",
      "[SGD | lr=0.001] Iter 51200: loss=1.9228\n",
      "[SGD | lr=0.001] Epoch 3200/4000: train_loss=1.9290  test_loss=2.1948  λ_max=12.0892\n",
      "[SGD | lr=0.001] Epoch 3201/4000: train_loss=1.9290  test_loss=2.1947  λ_max=12.4041\n",
      "[SGD | lr=0.001] Epoch 3202/4000: train_loss=1.9289  test_loss=2.1947  λ_max=11.5648\n",
      "[SGD | lr=0.001] Epoch 3203/4000: train_loss=1.9287  test_loss=2.1947  λ_max=11.0794\n",
      "[SGD | lr=0.001] Epoch 3204/4000: train_loss=1.9283  test_loss=2.1946  λ_max=12.3608\n",
      "[SGD | lr=0.001] Epoch 3205/4000: train_loss=1.9286  test_loss=2.1946  λ_max=11.8172\n",
      "[SGD | lr=0.001] Epoch 3206/4000: train_loss=1.9283  test_loss=2.1946  λ_max=12.1158\n",
      "[SGD | lr=0.001] Iter 51300: loss=1.9277\n",
      "[SGD | lr=0.001] Epoch 3207/4000: train_loss=1.9281  test_loss=2.1945  λ_max=11.6281\n",
      "[SGD | lr=0.001] Epoch 3208/4000: train_loss=1.9278  test_loss=2.1945  λ_max=11.4307\n",
      "[SGD | lr=0.001] Epoch 3209/4000: train_loss=1.9279  test_loss=2.1945  λ_max=11.6715\n",
      "[SGD | lr=0.001] Epoch 3210/4000: train_loss=1.9278  test_loss=2.1944  λ_max=11.9066\n",
      "[SGD | lr=0.001] Epoch 3211/4000: train_loss=1.9276  test_loss=2.1944  λ_max=12.2454\n",
      "[SGD | lr=0.001] Epoch 3212/4000: train_loss=1.9273  test_loss=2.1944  λ_max=11.5917\n",
      "[SGD | lr=0.001] Iter 51400: loss=1.9271\n",
      "[SGD | lr=0.001] Epoch 3213/4000: train_loss=1.9273  test_loss=2.1943  λ_max=11.9930\n",
      "[SGD | lr=0.001] Epoch 3214/4000: train_loss=1.9268  test_loss=2.1943  λ_max=11.0723\n",
      "[SGD | lr=0.001] Epoch 3215/4000: train_loss=1.9268  test_loss=2.1943  λ_max=12.3772\n",
      "[SGD | lr=0.001] Epoch 3216/4000: train_loss=1.9269  test_loss=2.1942  λ_max=12.4176\n",
      "[SGD | lr=0.001] Epoch 3217/4000: train_loss=1.9267  test_loss=2.1942  λ_max=11.7288\n",
      "[SGD | lr=0.001] Epoch 3218/4000: train_loss=1.9264  test_loss=2.1942  λ_max=11.9930\n",
      "[SGD | lr=0.001] Iter 51500: loss=1.9343\n",
      "[SGD | lr=0.001] Epoch 3219/4000: train_loss=1.9264  test_loss=2.1941  λ_max=11.7003\n",
      "[SGD | lr=0.001] Epoch 3220/4000: train_loss=1.9261  test_loss=2.1941  λ_max=11.7148\n",
      "[SGD | lr=0.001] Epoch 3221/4000: train_loss=1.9260  test_loss=2.1941  λ_max=11.8017\n",
      "[SGD | lr=0.001] Epoch 3222/4000: train_loss=1.9258  test_loss=2.1940  λ_max=11.7564\n",
      "[SGD | lr=0.001] Epoch 3223/4000: train_loss=1.9257  test_loss=2.1940  λ_max=11.9524\n",
      "[SGD | lr=0.001] Epoch 3224/4000: train_loss=1.9257  test_loss=2.1940  λ_max=12.0871\n",
      "[SGD | lr=0.001] Iter 51600: loss=1.9325\n",
      "[SGD | lr=0.001] Epoch 3225/4000: train_loss=1.9256  test_loss=2.1939  λ_max=12.1004\n",
      "[SGD | lr=0.001] Epoch 3226/4000: train_loss=1.9252  test_loss=2.1939  λ_max=12.1774\n",
      "[SGD | lr=0.001] Epoch 3227/4000: train_loss=1.9255  test_loss=2.1939  λ_max=12.3881\n",
      "[SGD | lr=0.001] Epoch 3228/4000: train_loss=1.9251  test_loss=2.1938  λ_max=12.2102\n",
      "[SGD | lr=0.001] Epoch 3229/4000: train_loss=1.9249  test_loss=2.1938  λ_max=12.5997\n",
      "[SGD | lr=0.001] Epoch 3230/4000: train_loss=1.9246  test_loss=2.1938  λ_max=12.7129\n",
      "[SGD | lr=0.001] Epoch 3231/4000: train_loss=1.9245  test_loss=2.1937  λ_max=11.6321\n",
      "[SGD | lr=0.001] Iter 51700: loss=1.9197\n",
      "[SGD | lr=0.001] Epoch 3232/4000: train_loss=1.9246  test_loss=2.1937  λ_max=11.6614\n",
      "[SGD | lr=0.001] Epoch 3233/4000: train_loss=1.9244  test_loss=2.1937  λ_max=12.3574\n",
      "[SGD | lr=0.001] Epoch 3234/4000: train_loss=1.9240  test_loss=2.1936  λ_max=12.0745\n",
      "[SGD | lr=0.001] Epoch 3235/4000: train_loss=1.9242  test_loss=2.1936  λ_max=11.5766\n",
      "[SGD | lr=0.001] Epoch 3236/4000: train_loss=1.9238  test_loss=2.1936  λ_max=11.7181\n",
      "[SGD | lr=0.001] Epoch 3237/4000: train_loss=1.9235  test_loss=2.1935  λ_max=11.5498\n",
      "[SGD | lr=0.001] Iter 51800: loss=1.9246\n",
      "[SGD | lr=0.001] Epoch 3238/4000: train_loss=1.9235  test_loss=2.1935  λ_max=11.2324\n",
      "[SGD | lr=0.001] Epoch 3239/4000: train_loss=1.9237  test_loss=2.1935  λ_max=12.3062\n",
      "[SGD | lr=0.001] Epoch 3240/4000: train_loss=1.9234  test_loss=2.1934  λ_max=11.9375\n",
      "[SGD | lr=0.001] Epoch 3241/4000: train_loss=1.9231  test_loss=2.1934  λ_max=12.5319\n",
      "[SGD | lr=0.001] Epoch 3242/4000: train_loss=1.9229  test_loss=2.1934  λ_max=12.6242\n",
      "[SGD | lr=0.001] Epoch 3243/4000: train_loss=1.9228  test_loss=2.1933  λ_max=12.0498\n",
      "[SGD | lr=0.001] Iter 51900: loss=1.9205\n",
      "[SGD | lr=0.001] Epoch 3244/4000: train_loss=1.9229  test_loss=2.1933  λ_max=12.2701\n",
      "[SGD | lr=0.001] Epoch 3245/4000: train_loss=1.9226  test_loss=2.1933  λ_max=12.3687\n",
      "[SGD | lr=0.001] Epoch 3246/4000: train_loss=1.9223  test_loss=2.1932  λ_max=12.1529\n",
      "[SGD | lr=0.001] Epoch 3247/4000: train_loss=1.9222  test_loss=2.1932  λ_max=12.6612\n",
      "[SGD | lr=0.001] Epoch 3248/4000: train_loss=1.9221  test_loss=2.1932  λ_max=12.2925\n",
      "[SGD | lr=0.001] Epoch 3249/4000: train_loss=1.9222  test_loss=2.1931  λ_max=12.0846\n",
      "[SGD | lr=0.001] Iter 52000: loss=1.9193\n",
      "[SGD | lr=0.001] Epoch 3250/4000: train_loss=1.9218  test_loss=2.1931  λ_max=11.7584\n",
      "[SGD | lr=0.001] Epoch 3251/4000: train_loss=1.9214  test_loss=2.1931  λ_max=11.7595\n",
      "[SGD | lr=0.001] Epoch 3252/4000: train_loss=1.9212  test_loss=2.1930  λ_max=12.4100\n",
      "[SGD | lr=0.001] Epoch 3253/4000: train_loss=1.9214  test_loss=2.1930  λ_max=11.9111\n",
      "[SGD | lr=0.001] Epoch 3254/4000: train_loss=1.9211  test_loss=2.1930  λ_max=12.5562\n",
      "[SGD | lr=0.001] Epoch 3255/4000: train_loss=1.9211  test_loss=2.1929  λ_max=12.1035\n",
      "[SGD | lr=0.001] Epoch 3256/4000: train_loss=1.9210  test_loss=2.1929  λ_max=12.2491\n",
      "[SGD | lr=0.001] Iter 52100: loss=1.9228\n",
      "[SGD | lr=0.001] Epoch 3257/4000: train_loss=1.9208  test_loss=2.1929  λ_max=12.5055\n",
      "[SGD | lr=0.001] Epoch 3258/4000: train_loss=1.9208  test_loss=2.1928  λ_max=11.5552\n",
      "[SGD | lr=0.001] Epoch 3259/4000: train_loss=1.9205  test_loss=2.1928  λ_max=12.6613\n",
      "[SGD | lr=0.001] Epoch 3260/4000: train_loss=1.9205  test_loss=2.1928  λ_max=12.1233\n",
      "[SGD | lr=0.001] Epoch 3261/4000: train_loss=1.9202  test_loss=2.1928  λ_max=12.4144\n",
      "[SGD | lr=0.001] Epoch 3262/4000: train_loss=1.9200  test_loss=2.1927  λ_max=11.8535\n",
      "[SGD | lr=0.001] Iter 52200: loss=1.9246\n",
      "[SGD | lr=0.001] Epoch 3263/4000: train_loss=1.9198  test_loss=2.1927  λ_max=12.2346\n",
      "[SGD | lr=0.001] Epoch 3264/4000: train_loss=1.9200  test_loss=2.1926  λ_max=11.5340\n",
      "[SGD | lr=0.001] Epoch 3265/4000: train_loss=1.9196  test_loss=2.1926  λ_max=12.0990\n",
      "[SGD | lr=0.001] Epoch 3266/4000: train_loss=1.9196  test_loss=2.1926  λ_max=12.5030\n",
      "[SGD | lr=0.001] Epoch 3267/4000: train_loss=1.9192  test_loss=2.1925  λ_max=11.8576\n",
      "[SGD | lr=0.001] Epoch 3268/4000: train_loss=1.9192  test_loss=2.1925  λ_max=12.5955\n",
      "[SGD | lr=0.001] Iter 52300: loss=1.9250\n",
      "[SGD | lr=0.001] Epoch 3269/4000: train_loss=1.9190  test_loss=2.1925  λ_max=12.2781\n",
      "[SGD | lr=0.001] Epoch 3270/4000: train_loss=1.9190  test_loss=2.1924  λ_max=12.0119\n",
      "[SGD | lr=0.001] Epoch 3271/4000: train_loss=1.9187  test_loss=2.1924  λ_max=11.9496\n",
      "[SGD | lr=0.001] Epoch 3272/4000: train_loss=1.9187  test_loss=2.1924  λ_max=11.7850\n",
      "[SGD | lr=0.001] Epoch 3273/4000: train_loss=1.9186  test_loss=2.1923  λ_max=11.7693\n",
      "[SGD | lr=0.001] Epoch 3274/4000: train_loss=1.9185  test_loss=2.1923  λ_max=12.5324\n",
      "[SGD | lr=0.001] Iter 52400: loss=1.9179\n",
      "[SGD | lr=0.001] Epoch 3275/4000: train_loss=1.9182  test_loss=2.1923  λ_max=12.5972\n",
      "[SGD | lr=0.001] Epoch 3276/4000: train_loss=1.9183  test_loss=2.1922  λ_max=12.0350\n",
      "[SGD | lr=0.001] Epoch 3277/4000: train_loss=1.9181  test_loss=2.1922  λ_max=12.2257\n",
      "[SGD | lr=0.001] Epoch 3278/4000: train_loss=1.9178  test_loss=2.1922  λ_max=12.4472\n",
      "[SGD | lr=0.001] Epoch 3279/4000: train_loss=1.9179  test_loss=2.1921  λ_max=11.8017\n",
      "[SGD | lr=0.001] Epoch 3280/4000: train_loss=1.9172  test_loss=2.1921  λ_max=12.8756\n",
      "[SGD | lr=0.001] Epoch 3281/4000: train_loss=1.9174  test_loss=2.1921  λ_max=11.6959\n",
      "[SGD | lr=0.001] Iter 52500: loss=1.9102\n",
      "[SGD | lr=0.001] Epoch 3282/4000: train_loss=1.9171  test_loss=2.1920  λ_max=12.4811\n",
      "[SGD | lr=0.001] Epoch 3283/4000: train_loss=1.9167  test_loss=2.1920  λ_max=11.7133\n",
      "[SGD | lr=0.001] Epoch 3284/4000: train_loss=1.9168  test_loss=2.1920  λ_max=11.8062\n",
      "[SGD | lr=0.001] Epoch 3285/4000: train_loss=1.9167  test_loss=2.1920  λ_max=12.0532\n",
      "[SGD | lr=0.001] Epoch 3286/4000: train_loss=1.9165  test_loss=2.1919  λ_max=12.4289\n",
      "[SGD | lr=0.001] Epoch 3287/4000: train_loss=1.9165  test_loss=2.1919  λ_max=12.8097\n",
      "[SGD | lr=0.001] Iter 52600: loss=1.9207\n",
      "[SGD | lr=0.001] Epoch 3288/4000: train_loss=1.9161  test_loss=2.1919  λ_max=12.2794\n",
      "[SGD | lr=0.001] Epoch 3289/4000: train_loss=1.9160  test_loss=2.1918  λ_max=11.9789\n",
      "[SGD | lr=0.001] Epoch 3290/4000: train_loss=1.9159  test_loss=2.1918  λ_max=12.1038\n",
      "[SGD | lr=0.001] Epoch 3291/4000: train_loss=1.9160  test_loss=2.1917  λ_max=12.4702\n",
      "[SGD | lr=0.001] Epoch 3292/4000: train_loss=1.9156  test_loss=2.1917  λ_max=12.4612\n",
      "[SGD | lr=0.001] Epoch 3293/4000: train_loss=1.9158  test_loss=2.1917  λ_max=11.5599\n",
      "[SGD | lr=0.001] Iter 52700: loss=1.9182\n",
      "[SGD | lr=0.001] Epoch 3294/4000: train_loss=1.9155  test_loss=2.1917  λ_max=12.2415\n",
      "[SGD | lr=0.001] Epoch 3295/4000: train_loss=1.9154  test_loss=2.1916  λ_max=12.0273\n",
      "[SGD | lr=0.001] Epoch 3296/4000: train_loss=1.9153  test_loss=2.1916  λ_max=12.5824\n",
      "[SGD | lr=0.001] Epoch 3297/4000: train_loss=1.9151  test_loss=2.1916  λ_max=12.7908\n",
      "[SGD | lr=0.001] Epoch 3298/4000: train_loss=1.9150  test_loss=2.1915  λ_max=12.1759\n",
      "[SGD | lr=0.001] Epoch 3299/4000: train_loss=1.9148  test_loss=2.1915  λ_max=12.5586\n",
      "[SGD | lr=0.001] Iter 52800: loss=1.9214\n",
      "[SGD | lr=0.001] Epoch 3300/4000: train_loss=1.9148  test_loss=2.1915  λ_max=12.9869\n",
      "[SGD | lr=0.001] Epoch 3301/4000: train_loss=1.9146  test_loss=2.1914  λ_max=12.6876\n",
      "[SGD | lr=0.001] Epoch 3302/4000: train_loss=1.9143  test_loss=2.1914  λ_max=12.3160\n",
      "[SGD | lr=0.001] Epoch 3303/4000: train_loss=1.9144  test_loss=2.1914  λ_max=12.3724\n",
      "[SGD | lr=0.001] Epoch 3304/4000: train_loss=1.9141  test_loss=2.1913  λ_max=12.0290\n",
      "[SGD | lr=0.001] Epoch 3305/4000: train_loss=1.9136  test_loss=2.1913  λ_max=12.1942\n",
      "[SGD | lr=0.001] Epoch 3306/4000: train_loss=1.9137  test_loss=2.1913  λ_max=11.7895\n",
      "[SGD | lr=0.001] Iter 52900: loss=1.9086\n",
      "[SGD | lr=0.001] Epoch 3307/4000: train_loss=1.9137  test_loss=2.1912  λ_max=12.7686\n",
      "[SGD | lr=0.001] Epoch 3308/4000: train_loss=1.9134  test_loss=2.1912  λ_max=12.7338\n",
      "[SGD | lr=0.001] Epoch 3309/4000: train_loss=1.9133  test_loss=2.1912  λ_max=11.7913\n",
      "[SGD | lr=0.001] Epoch 3310/4000: train_loss=1.9132  test_loss=2.1911  λ_max=12.1722\n",
      "[SGD | lr=0.001] Epoch 3311/4000: train_loss=1.9130  test_loss=2.1911  λ_max=12.6484\n",
      "[SGD | lr=0.001] Epoch 3312/4000: train_loss=1.9128  test_loss=2.1911  λ_max=12.4821\n",
      "[SGD | lr=0.001] Iter 53000: loss=1.9170\n",
      "[SGD | lr=0.001] Epoch 3313/4000: train_loss=1.9128  test_loss=2.1910  λ_max=12.4293\n",
      "[SGD | lr=0.001] Epoch 3314/4000: train_loss=1.9125  test_loss=2.1910  λ_max=12.2682\n",
      "[SGD | lr=0.001] Epoch 3315/4000: train_loss=1.9124  test_loss=2.1909  λ_max=12.8712\n",
      "[SGD | lr=0.001] Epoch 3316/4000: train_loss=1.9122  test_loss=2.1909  λ_max=12.5741\n",
      "[SGD | lr=0.001] Epoch 3317/4000: train_loss=1.9123  test_loss=2.1909  λ_max=13.1053\n",
      "[SGD | lr=0.001] Epoch 3318/4000: train_loss=1.9118  test_loss=2.1909  λ_max=12.0568\n",
      "[SGD | lr=0.001] Iter 53100: loss=1.9112\n",
      "[SGD | lr=0.001] Epoch 3319/4000: train_loss=1.9118  test_loss=2.1908  λ_max=11.6158\n",
      "[SGD | lr=0.001] Epoch 3320/4000: train_loss=1.9117  test_loss=2.1908  λ_max=12.0717\n",
      "[SGD | lr=0.001] Epoch 3321/4000: train_loss=1.9115  test_loss=2.1907  λ_max=12.4115\n",
      "[SGD | lr=0.001] Epoch 3322/4000: train_loss=1.9113  test_loss=2.1907  λ_max=12.3394\n",
      "[SGD | lr=0.001] Epoch 3323/4000: train_loss=1.9112  test_loss=2.1907  λ_max=11.7486\n",
      "[SGD | lr=0.001] Epoch 3324/4000: train_loss=1.9110  test_loss=2.1907  λ_max=12.1466\n",
      "[SGD | lr=0.001] Iter 53200: loss=1.9185\n",
      "[SGD | lr=0.001] Epoch 3325/4000: train_loss=1.9112  test_loss=2.1906  λ_max=12.1416\n",
      "[SGD | lr=0.001] Epoch 3326/4000: train_loss=1.9108  test_loss=2.1906  λ_max=12.6654\n",
      "[SGD | lr=0.001] Epoch 3327/4000: train_loss=1.9106  test_loss=2.1905  λ_max=12.1202\n",
      "[SGD | lr=0.001] Epoch 3328/4000: train_loss=1.9104  test_loss=2.1905  λ_max=12.7784\n",
      "[SGD | lr=0.001] Epoch 3329/4000: train_loss=1.9106  test_loss=2.1905  λ_max=12.4059\n",
      "[SGD | lr=0.001] Epoch 3330/4000: train_loss=1.9105  test_loss=2.1904  λ_max=12.7148\n",
      "[SGD | lr=0.001] Epoch 3331/4000: train_loss=1.9102  test_loss=2.1904  λ_max=12.7202\n",
      "[SGD | lr=0.001] Iter 53300: loss=1.9072\n",
      "[SGD | lr=0.001] Epoch 3332/4000: train_loss=1.9100  test_loss=2.1904  λ_max=12.6219\n",
      "[SGD | lr=0.001] Epoch 3333/4000: train_loss=1.9099  test_loss=2.1903  λ_max=12.8337\n",
      "[SGD | lr=0.001] Epoch 3334/4000: train_loss=1.9099  test_loss=2.1903  λ_max=12.5693\n",
      "[SGD | lr=0.001] Epoch 3335/4000: train_loss=1.9098  test_loss=2.1903  λ_max=12.2556\n",
      "[SGD | lr=0.001] Epoch 3336/4000: train_loss=1.9095  test_loss=2.1902  λ_max=12.0004\n",
      "[SGD | lr=0.001] Epoch 3337/4000: train_loss=1.9092  test_loss=2.1902  λ_max=12.4049\n",
      "[SGD | lr=0.001] Iter 53400: loss=1.9088\n",
      "[SGD | lr=0.001] Epoch 3338/4000: train_loss=1.9094  test_loss=2.1902  λ_max=12.2897\n",
      "[SGD | lr=0.001] Epoch 3339/4000: train_loss=1.9088  test_loss=2.1902  λ_max=11.6102\n",
      "[SGD | lr=0.001] Epoch 3340/4000: train_loss=1.9091  test_loss=2.1901  λ_max=12.6327\n",
      "[SGD | lr=0.001] Epoch 3341/4000: train_loss=1.9087  test_loss=2.1901  λ_max=12.2646\n",
      "[SGD | lr=0.001] Epoch 3342/4000: train_loss=1.9085  test_loss=2.1901  λ_max=12.4865\n",
      "[SGD | lr=0.001] Epoch 3343/4000: train_loss=1.9084  test_loss=2.1900  λ_max=12.3122\n",
      "[SGD | lr=0.001] Iter 53500: loss=1.9133\n",
      "[SGD | lr=0.001] Epoch 3344/4000: train_loss=1.9083  test_loss=2.1900  λ_max=12.3313\n",
      "[SGD | lr=0.001] Epoch 3345/4000: train_loss=1.9078  test_loss=2.1900  λ_max=12.8077\n",
      "[SGD | lr=0.001] Epoch 3346/4000: train_loss=1.9081  test_loss=2.1899  λ_max=12.7427\n",
      "[SGD | lr=0.001] Epoch 3347/4000: train_loss=1.9077  test_loss=2.1899  λ_max=13.1165\n",
      "[SGD | lr=0.001] Epoch 3348/4000: train_loss=1.9079  test_loss=2.1899  λ_max=12.7669\n",
      "[SGD | lr=0.001] Epoch 3349/4000: train_loss=1.9078  test_loss=2.1898  λ_max=12.5778\n",
      "[SGD | lr=0.001] Iter 53600: loss=1.9148\n",
      "[SGD | lr=0.001] Epoch 3350/4000: train_loss=1.9076  test_loss=2.1898  λ_max=13.1300\n",
      "[SGD | lr=0.001] Epoch 3351/4000: train_loss=1.9070  test_loss=2.1898  λ_max=13.0459\n",
      "[SGD | lr=0.001] Epoch 3352/4000: train_loss=1.9073  test_loss=2.1897  λ_max=12.2735\n",
      "[SGD | lr=0.001] Epoch 3353/4000: train_loss=1.9070  test_loss=2.1897  λ_max=12.2773\n",
      "[SGD | lr=0.001] Epoch 3354/4000: train_loss=1.9066  test_loss=2.1897  λ_max=13.1949\n",
      "[SGD | lr=0.001] Epoch 3355/4000: train_loss=1.9067  test_loss=2.1896  λ_max=12.1473\n",
      "[SGD | lr=0.001] Epoch 3356/4000: train_loss=1.9065  test_loss=2.1896  λ_max=12.3897\n",
      "[SGD | lr=0.001] Iter 53700: loss=1.9052\n",
      "[SGD | lr=0.001] Epoch 3357/4000: train_loss=1.9064  test_loss=2.1896  λ_max=12.8375\n",
      "[SGD | lr=0.001] Epoch 3358/4000: train_loss=1.9062  test_loss=2.1895  λ_max=12.2072\n",
      "[SGD | lr=0.001] Epoch 3359/4000: train_loss=1.9061  test_loss=2.1895  λ_max=12.1280\n",
      "[SGD | lr=0.001] Epoch 3360/4000: train_loss=1.9060  test_loss=2.1895  λ_max=11.9018\n",
      "[SGD | lr=0.001] Epoch 3361/4000: train_loss=1.9059  test_loss=2.1894  λ_max=12.3346\n",
      "[SGD | lr=0.001] Epoch 3362/4000: train_loss=1.9057  test_loss=2.1894  λ_max=12.0449\n",
      "[SGD | lr=0.001] Iter 53800: loss=1.9067\n",
      "[SGD | lr=0.001] Epoch 3363/4000: train_loss=1.9057  test_loss=2.1894  λ_max=12.7302\n",
      "[SGD | lr=0.001] Epoch 3364/4000: train_loss=1.9054  test_loss=2.1893  λ_max=12.3780\n",
      "[SGD | lr=0.001] Epoch 3365/4000: train_loss=1.9053  test_loss=2.1893  λ_max=12.1694\n",
      "[SGD | lr=0.001] Epoch 3366/4000: train_loss=1.9051  test_loss=2.1893  λ_max=11.9158\n",
      "[SGD | lr=0.001] Epoch 3367/4000: train_loss=1.9050  test_loss=2.1892  λ_max=12.4189\n",
      "[SGD | lr=0.001] Epoch 3368/4000: train_loss=1.9048  test_loss=2.1892  λ_max=12.6035\n",
      "[SGD | lr=0.001] Iter 53900: loss=1.9025\n",
      "[SGD | lr=0.001] Epoch 3369/4000: train_loss=1.9045  test_loss=2.1892  λ_max=13.2978\n",
      "[SGD | lr=0.001] Epoch 3370/4000: train_loss=1.9047  test_loss=2.1891  λ_max=13.0223\n",
      "[SGD | lr=0.001] Epoch 3371/4000: train_loss=1.9043  test_loss=2.1891  λ_max=13.0185\n",
      "[SGD | lr=0.001] Epoch 3372/4000: train_loss=1.9045  test_loss=2.1891  λ_max=12.2080\n",
      "[SGD | lr=0.001] Epoch 3373/4000: train_loss=1.9042  test_loss=2.1891  λ_max=12.4372\n",
      "[SGD | lr=0.001] Epoch 3374/4000: train_loss=1.9041  test_loss=2.1890  λ_max=12.5186\n",
      "[SGD | lr=0.001] Iter 54000: loss=1.9021\n",
      "[SGD | lr=0.001] Epoch 3375/4000: train_loss=1.9038  test_loss=2.1890  λ_max=13.0947\n",
      "[SGD | lr=0.001] Epoch 3376/4000: train_loss=1.9037  test_loss=2.1890  λ_max=12.8822\n",
      "[SGD | lr=0.001] Epoch 3377/4000: train_loss=1.9037  test_loss=2.1889  λ_max=12.6445\n",
      "[SGD | lr=0.001] Epoch 3378/4000: train_loss=1.9034  test_loss=2.1889  λ_max=12.8015\n",
      "[SGD | lr=0.001] Epoch 3379/4000: train_loss=1.9031  test_loss=2.1889  λ_max=11.7687\n",
      "[SGD | lr=0.001] Epoch 3380/4000: train_loss=1.9033  test_loss=2.1888  λ_max=12.3791\n",
      "[SGD | lr=0.001] Epoch 3381/4000: train_loss=1.9030  test_loss=2.1888  λ_max=12.9475\n",
      "[SGD | lr=0.001] Iter 54100: loss=1.8927\n",
      "[SGD | lr=0.001] Epoch 3382/4000: train_loss=1.9029  test_loss=2.1888  λ_max=13.3633\n",
      "[SGD | lr=0.001] Epoch 3383/4000: train_loss=1.9028  test_loss=2.1887  λ_max=13.1548\n",
      "[SGD | lr=0.001] Epoch 3384/4000: train_loss=1.9028  test_loss=2.1887  λ_max=12.3748\n",
      "[SGD | lr=0.001] Epoch 3385/4000: train_loss=1.9023  test_loss=2.1887  λ_max=11.8746\n",
      "[SGD | lr=0.001] Epoch 3386/4000: train_loss=1.9022  test_loss=2.1886  λ_max=13.1077\n",
      "[SGD | lr=0.001] Epoch 3387/4000: train_loss=1.9019  test_loss=2.1886  λ_max=12.3504\n",
      "[SGD | lr=0.001] Iter 54200: loss=1.9022\n",
      "[SGD | lr=0.001] Epoch 3388/4000: train_loss=1.9019  test_loss=2.1886  λ_max=12.4638\n",
      "[SGD | lr=0.001] Epoch 3389/4000: train_loss=1.9017  test_loss=2.1885  λ_max=12.0239\n",
      "[SGD | lr=0.001] Epoch 3390/4000: train_loss=1.9016  test_loss=2.1885  λ_max=12.4366\n",
      "[SGD | lr=0.001] Epoch 3391/4000: train_loss=1.9015  test_loss=2.1885  λ_max=12.6854\n",
      "[SGD | lr=0.001] Epoch 3392/4000: train_loss=1.9014  test_loss=2.1884  λ_max=13.3230\n",
      "[SGD | lr=0.001] Epoch 3393/4000: train_loss=1.9012  test_loss=2.1884  λ_max=13.1351\n",
      "[SGD | lr=0.001] Iter 54300: loss=1.8983\n",
      "[SGD | lr=0.001] Epoch 3394/4000: train_loss=1.9012  test_loss=2.1884  λ_max=12.5530\n",
      "[SGD | lr=0.001] Epoch 3395/4000: train_loss=1.9012  test_loss=2.1883  λ_max=12.7264\n",
      "[SGD | lr=0.001] Epoch 3396/4000: train_loss=1.9006  test_loss=2.1883  λ_max=12.1324\n",
      "[SGD | lr=0.001] Epoch 3397/4000: train_loss=1.9007  test_loss=2.1883  λ_max=12.5440\n",
      "[SGD | lr=0.001] Epoch 3398/4000: train_loss=1.9005  test_loss=2.1882  λ_max=13.3722\n",
      "[SGD | lr=0.001] Epoch 3399/4000: train_loss=1.9005  test_loss=2.1882  λ_max=12.2831\n",
      "[SGD | lr=0.001] Iter 54400: loss=1.9050\n",
      "[SGD | lr=0.001] Epoch 3400/4000: train_loss=1.9004  test_loss=2.1882  λ_max=12.9607\n",
      "[SGD | lr=0.001] Epoch 3401/4000: train_loss=1.9001  test_loss=2.1881  λ_max=12.8560\n",
      "[SGD | lr=0.001] Epoch 3402/4000: train_loss=1.9000  test_loss=2.1881  λ_max=13.2362\n",
      "[SGD | lr=0.001] Epoch 3403/4000: train_loss=1.8999  test_loss=2.1881  λ_max=12.6186\n",
      "[SGD | lr=0.001] Epoch 3404/4000: train_loss=1.8997  test_loss=2.1880  λ_max=12.4317\n",
      "[SGD | lr=0.001] Epoch 3405/4000: train_loss=1.8997  test_loss=2.1880  λ_max=13.0279\n",
      "[SGD | lr=0.001] Epoch 3406/4000: train_loss=1.8995  test_loss=2.1880  λ_max=12.3982\n",
      "[SGD | lr=0.001] Iter 54500: loss=1.8969\n",
      "[SGD | lr=0.001] Epoch 3407/4000: train_loss=1.8993  test_loss=2.1879  λ_max=12.5363\n",
      "[SGD | lr=0.001] Epoch 3408/4000: train_loss=1.8992  test_loss=2.1879  λ_max=13.1519\n",
      "[SGD | lr=0.001] Epoch 3409/4000: train_loss=1.8989  test_loss=2.1879  λ_max=12.5810\n",
      "[SGD | lr=0.001] Epoch 3410/4000: train_loss=1.8992  test_loss=2.1878  λ_max=12.4620\n",
      "[SGD | lr=0.001] Epoch 3411/4000: train_loss=1.8987  test_loss=2.1878  λ_max=12.8552\n",
      "[SGD | lr=0.001] Epoch 3412/4000: train_loss=1.8985  test_loss=2.1878  λ_max=13.2955\n",
      "[SGD | lr=0.001] Iter 54600: loss=1.8888\n",
      "[SGD | lr=0.001] Epoch 3413/4000: train_loss=1.8982  test_loss=2.1877  λ_max=12.3342\n",
      "[SGD | lr=0.001] Epoch 3414/4000: train_loss=1.8984  test_loss=2.1877  λ_max=12.6688\n",
      "[SGD | lr=0.001] Epoch 3415/4000: train_loss=1.8982  test_loss=2.1877  λ_max=13.3831\n",
      "[SGD | lr=0.001] Epoch 3416/4000: train_loss=1.8982  test_loss=2.1876  λ_max=13.0842\n",
      "[SGD | lr=0.001] Epoch 3417/4000: train_loss=1.8979  test_loss=2.1876  λ_max=13.3550\n",
      "[SGD | lr=0.001] Epoch 3418/4000: train_loss=1.8977  test_loss=2.1876  λ_max=12.5950\n",
      "[SGD | lr=0.001] Iter 54700: loss=1.9035\n",
      "[SGD | lr=0.001] Epoch 3419/4000: train_loss=1.8979  test_loss=2.1876  λ_max=12.2704\n",
      "[SGD | lr=0.001] Epoch 3420/4000: train_loss=1.8973  test_loss=2.1875  λ_max=12.5193\n",
      "[SGD | lr=0.001] Epoch 3421/4000: train_loss=1.8975  test_loss=2.1875  λ_max=12.2092\n",
      "[SGD | lr=0.001] Epoch 3422/4000: train_loss=1.8971  test_loss=2.1874  λ_max=12.8987\n",
      "[SGD | lr=0.001] Epoch 3423/4000: train_loss=1.8970  test_loss=2.1874  λ_max=12.5658\n",
      "[SGD | lr=0.001] Epoch 3424/4000: train_loss=1.8969  test_loss=2.1874  λ_max=13.3993\n",
      "[SGD | lr=0.001] Iter 54800: loss=1.9035\n",
      "[SGD | lr=0.001] Epoch 3425/4000: train_loss=1.8969  test_loss=2.1873  λ_max=12.7491\n",
      "[SGD | lr=0.001] Epoch 3426/4000: train_loss=1.8968  test_loss=2.1873  λ_max=13.2230\n",
      "[SGD | lr=0.001] Epoch 3427/4000: train_loss=1.8966  test_loss=2.1873  λ_max=13.1234\n",
      "[SGD | lr=0.001] Epoch 3428/4000: train_loss=1.8964  test_loss=2.1873  λ_max=13.0987\n",
      "[SGD | lr=0.001] Epoch 3429/4000: train_loss=1.8962  test_loss=2.1872  λ_max=13.3386\n",
      "[SGD | lr=0.001] Epoch 3430/4000: train_loss=1.8958  test_loss=2.1872  λ_max=12.5764\n",
      "[SGD | lr=0.001] Epoch 3431/4000: train_loss=1.8961  test_loss=2.1871  λ_max=13.4709\n",
      "[SGD | lr=0.001] Iter 54900: loss=1.8932\n",
      "[SGD | lr=0.001] Epoch 3432/4000: train_loss=1.8955  test_loss=2.1871  λ_max=12.6846\n",
      "[SGD | lr=0.001] Epoch 3433/4000: train_loss=1.8957  test_loss=2.1871  λ_max=13.2401\n",
      "[SGD | lr=0.001] Epoch 3434/4000: train_loss=1.8956  test_loss=2.1870  λ_max=12.5412\n",
      "[SGD | lr=0.001] Epoch 3435/4000: train_loss=1.8954  test_loss=2.1870  λ_max=12.8289\n",
      "[SGD | lr=0.001] Epoch 3436/4000: train_loss=1.8953  test_loss=2.1870  λ_max=12.3874\n",
      "[SGD | lr=0.001] Epoch 3437/4000: train_loss=1.8951  test_loss=2.1869  λ_max=13.0021\n",
      "[SGD | lr=0.001] Iter 55000: loss=1.8933\n",
      "[SGD | lr=0.001] Epoch 3438/4000: train_loss=1.8949  test_loss=2.1869  λ_max=12.9355\n",
      "[SGD | lr=0.001] Epoch 3439/4000: train_loss=1.8950  test_loss=2.1869  λ_max=13.2466\n",
      "[SGD | lr=0.001] Epoch 3440/4000: train_loss=1.8948  test_loss=2.1869  λ_max=12.9000\n",
      "[SGD | lr=0.001] Epoch 3441/4000: train_loss=1.8943  test_loss=2.1868  λ_max=12.5775\n",
      "[SGD | lr=0.001] Epoch 3442/4000: train_loss=1.8944  test_loss=2.1868  λ_max=12.6359\n",
      "[SGD | lr=0.001] Epoch 3443/4000: train_loss=1.8942  test_loss=2.1867  λ_max=13.3147\n",
      "[SGD | lr=0.001] Iter 55100: loss=1.8906\n",
      "[SGD | lr=0.001] Epoch 3444/4000: train_loss=1.8939  test_loss=2.1867  λ_max=13.1409\n",
      "[SGD | lr=0.001] Epoch 3445/4000: train_loss=1.8940  test_loss=2.1867  λ_max=12.5898\n",
      "[SGD | lr=0.001] Epoch 3446/4000: train_loss=1.8938  test_loss=2.1867  λ_max=12.7034\n",
      "[SGD | lr=0.001] Epoch 3447/4000: train_loss=1.8936  test_loss=2.1866  λ_max=12.4305\n",
      "[SGD | lr=0.001] Epoch 3448/4000: train_loss=1.8936  test_loss=2.1866  λ_max=13.3194\n",
      "[SGD | lr=0.001] Epoch 3449/4000: train_loss=1.8935  test_loss=2.1866  λ_max=13.0557\n",
      "[SGD | lr=0.001] Iter 55200: loss=1.8962\n",
      "[SGD | lr=0.001] Epoch 3450/4000: train_loss=1.8933  test_loss=2.1865  λ_max=12.5485\n",
      "[SGD | lr=0.001] Epoch 3451/4000: train_loss=1.8930  test_loss=2.1865  λ_max=12.4016\n",
      "[SGD | lr=0.001] Epoch 3452/4000: train_loss=1.8931  test_loss=2.1865  λ_max=13.5683\n",
      "[SGD | lr=0.001] Epoch 3453/4000: train_loss=1.8928  test_loss=2.1864  λ_max=13.4527\n",
      "[SGD | lr=0.001] Epoch 3454/4000: train_loss=1.8926  test_loss=2.1864  λ_max=13.1442\n",
      "[SGD | lr=0.001] Epoch 3455/4000: train_loss=1.8924  test_loss=2.1864  λ_max=12.4573\n",
      "[SGD | lr=0.001] Epoch 3456/4000: train_loss=1.8926  test_loss=2.1863  λ_max=13.1419\n",
      "[SGD | lr=0.001] Iter 55300: loss=1.8896\n",
      "[SGD | lr=0.001] Epoch 3457/4000: train_loss=1.8924  test_loss=2.1863  λ_max=12.7109\n",
      "[SGD | lr=0.001] Epoch 3458/4000: train_loss=1.8921  test_loss=2.1863  λ_max=12.7654\n",
      "[SGD | lr=0.001] Epoch 3459/4000: train_loss=1.8920  test_loss=2.1862  λ_max=13.4247\n",
      "[SGD | lr=0.001] Epoch 3460/4000: train_loss=1.8919  test_loss=2.1862  λ_max=13.5526\n",
      "[SGD | lr=0.001] Epoch 3461/4000: train_loss=1.8916  test_loss=2.1862  λ_max=13.2799\n",
      "[SGD | lr=0.001] Epoch 3462/4000: train_loss=1.8914  test_loss=2.1862  λ_max=12.6554\n",
      "[SGD | lr=0.001] Iter 55400: loss=1.8910\n",
      "[SGD | lr=0.001] Epoch 3463/4000: train_loss=1.8914  test_loss=2.1861  λ_max=12.6203\n",
      "[SGD | lr=0.001] Epoch 3464/4000: train_loss=1.8911  test_loss=2.1861  λ_max=12.7297\n",
      "[SGD | lr=0.001] Epoch 3465/4000: train_loss=1.8909  test_loss=2.1861  λ_max=12.8818\n",
      "[SGD | lr=0.001] Epoch 3466/4000: train_loss=1.8910  test_loss=2.1860  λ_max=12.7217\n",
      "[SGD | lr=0.001] Epoch 3467/4000: train_loss=1.8909  test_loss=2.1860  λ_max=13.3544\n",
      "[SGD | lr=0.001] Epoch 3468/4000: train_loss=1.8908  test_loss=2.1860  λ_max=13.3570\n",
      "[SGD | lr=0.001] Iter 55500: loss=1.8876\n",
      "[SGD | lr=0.001] Epoch 3469/4000: train_loss=1.8908  test_loss=2.1859  λ_max=12.3612\n",
      "[SGD | lr=0.001] Epoch 3470/4000: train_loss=1.8904  test_loss=2.1859  λ_max=12.6697\n",
      "[SGD | lr=0.001] Epoch 3471/4000: train_loss=1.8902  test_loss=2.1859  λ_max=12.8949\n",
      "[SGD | lr=0.001] Epoch 3472/4000: train_loss=1.8902  test_loss=2.1858  λ_max=12.8873\n",
      "[SGD | lr=0.001] Epoch 3473/4000: train_loss=1.8898  test_loss=2.1858  λ_max=12.8834\n",
      "[SGD | lr=0.001] Epoch 3474/4000: train_loss=1.8899  test_loss=2.1857  λ_max=12.7974\n",
      "[SGD | lr=0.001] Iter 55600: loss=1.8926\n",
      "[SGD | lr=0.001] Epoch 3475/4000: train_loss=1.8898  test_loss=2.1857  λ_max=13.0217\n",
      "[SGD | lr=0.001] Epoch 3476/4000: train_loss=1.8896  test_loss=2.1857  λ_max=13.0538\n",
      "[SGD | lr=0.001] Epoch 3477/4000: train_loss=1.8894  test_loss=2.1857  λ_max=12.8439\n",
      "[SGD | lr=0.001] Epoch 3478/4000: train_loss=1.8894  test_loss=2.1856  λ_max=12.6971\n",
      "[SGD | lr=0.001] Epoch 3479/4000: train_loss=1.8890  test_loss=2.1856  λ_max=13.0467\n",
      "[SGD | lr=0.001] Epoch 3480/4000: train_loss=1.8892  test_loss=2.1856  λ_max=12.6798\n",
      "[SGD | lr=0.001] Epoch 3481/4000: train_loss=1.8889  test_loss=2.1855  λ_max=13.1180\n",
      "[SGD | lr=0.001] Iter 55700: loss=1.8864\n",
      "[SGD | lr=0.001] Epoch 3482/4000: train_loss=1.8889  test_loss=2.1855  λ_max=12.7522\n",
      "[SGD | lr=0.001] Epoch 3483/4000: train_loss=1.8889  test_loss=2.1855  λ_max=13.0457\n",
      "[SGD | lr=0.001] Epoch 3484/4000: train_loss=1.8885  test_loss=2.1854  λ_max=12.5545\n",
      "[SGD | lr=0.001] Epoch 3485/4000: train_loss=1.8884  test_loss=2.1854  λ_max=12.8808\n",
      "[SGD | lr=0.001] Epoch 3486/4000: train_loss=1.8881  test_loss=2.1854  λ_max=13.1330\n",
      "[SGD | lr=0.001] Epoch 3487/4000: train_loss=1.8880  test_loss=2.1854  λ_max=13.0492\n",
      "[SGD | lr=0.001] Iter 55800: loss=1.8875\n",
      "[SGD | lr=0.001] Epoch 3488/4000: train_loss=1.8879  test_loss=2.1853  λ_max=12.6148\n",
      "[SGD | lr=0.001] Epoch 3489/4000: train_loss=1.8881  test_loss=2.1853  λ_max=12.8733\n",
      "[SGD | lr=0.001] Epoch 3490/4000: train_loss=1.8876  test_loss=2.1853  λ_max=13.3297\n",
      "[SGD | lr=0.001] Epoch 3491/4000: train_loss=1.8876  test_loss=2.1852  λ_max=12.5715\n",
      "[SGD | lr=0.001] Epoch 3492/4000: train_loss=1.8874  test_loss=2.1852  λ_max=12.7512\n",
      "[SGD | lr=0.001] Epoch 3493/4000: train_loss=1.8874  test_loss=2.1852  λ_max=13.5885\n",
      "[SGD | lr=0.001] Iter 55900: loss=1.8839\n",
      "[SGD | lr=0.001] Epoch 3494/4000: train_loss=1.8871  test_loss=2.1851  λ_max=13.5641\n",
      "[SGD | lr=0.001] Epoch 3495/4000: train_loss=1.8868  test_loss=2.1851  λ_max=13.3773\n",
      "[SGD | lr=0.001] Epoch 3496/4000: train_loss=1.8868  test_loss=2.1851  λ_max=12.8881\n",
      "[SGD | lr=0.001] Epoch 3497/4000: train_loss=1.8866  test_loss=2.1850  λ_max=13.5755\n",
      "[SGD | lr=0.001] Epoch 3498/4000: train_loss=1.8866  test_loss=2.1850  λ_max=13.1743\n",
      "[SGD | lr=0.001] Epoch 3499/4000: train_loss=1.8865  test_loss=2.1850  λ_max=13.6013\n",
      "[SGD | lr=0.001] Iter 56000: loss=1.8845\n",
      "[SGD | lr=0.001] Epoch 3500/4000: train_loss=1.8862  test_loss=2.1849  λ_max=13.7441\n",
      "[SGD | lr=0.001] Epoch 3501/4000: train_loss=1.8859  test_loss=2.1849  λ_max=13.5464\n",
      "[SGD | lr=0.001] Epoch 3502/4000: train_loss=1.8860  test_loss=2.1849  λ_max=13.4396\n",
      "[SGD | lr=0.001] Epoch 3503/4000: train_loss=1.8855  test_loss=2.1848  λ_max=12.9552\n",
      "[SGD | lr=0.001] Epoch 3504/4000: train_loss=1.8855  test_loss=2.1848  λ_max=13.7606\n",
      "[SGD | lr=0.001] Epoch 3505/4000: train_loss=1.8857  test_loss=2.1848  λ_max=12.5787\n",
      "[SGD | lr=0.001] Epoch 3506/4000: train_loss=1.8855  test_loss=2.1848  λ_max=12.7957\n",
      "[SGD | lr=0.001] Iter 56100: loss=1.8909\n",
      "[SGD | lr=0.001] Epoch 3507/4000: train_loss=1.8852  test_loss=2.1847  λ_max=12.8920\n",
      "[SGD | lr=0.001] Epoch 3508/4000: train_loss=1.8852  test_loss=2.1847  λ_max=12.7583\n",
      "[SGD | lr=0.001] Epoch 3509/4000: train_loss=1.8851  test_loss=2.1847  λ_max=12.6912\n",
      "[SGD | lr=0.001] Epoch 3510/4000: train_loss=1.8848  test_loss=2.1846  λ_max=13.1936\n",
      "[SGD | lr=0.001] Epoch 3511/4000: train_loss=1.8847  test_loss=2.1846  λ_max=13.7611\n",
      "[SGD | lr=0.001] Epoch 3512/4000: train_loss=1.8847  test_loss=2.1846  λ_max=13.2209\n",
      "[SGD | lr=0.001] Iter 56200: loss=1.8786\n",
      "[SGD | lr=0.001] Epoch 3513/4000: train_loss=1.8844  test_loss=2.1846  λ_max=12.9479\n",
      "[SGD | lr=0.001] Epoch 3514/4000: train_loss=1.8844  test_loss=2.1845  λ_max=12.5696\n",
      "[SGD | lr=0.001] Epoch 3515/4000: train_loss=1.8839  test_loss=2.1845  λ_max=13.1064\n",
      "[SGD | lr=0.001] Epoch 3516/4000: train_loss=1.8840  test_loss=2.1844  λ_max=13.4761\n",
      "[SGD | lr=0.001] Epoch 3517/4000: train_loss=1.8841  test_loss=2.1844  λ_max=13.3454\n",
      "[SGD | lr=0.001] Epoch 3518/4000: train_loss=1.8836  test_loss=2.1844  λ_max=13.2070\n",
      "[SGD | lr=0.001] Iter 56300: loss=1.8815\n",
      "[SGD | lr=0.001] Epoch 3519/4000: train_loss=1.8835  test_loss=2.1843  λ_max=13.0823\n",
      "[SGD | lr=0.001] Epoch 3520/4000: train_loss=1.8835  test_loss=2.1843  λ_max=12.8492\n",
      "[SGD | lr=0.001] Epoch 3521/4000: train_loss=1.8835  test_loss=2.1843  λ_max=12.9912\n",
      "[SGD | lr=0.001] Epoch 3522/4000: train_loss=1.8834  test_loss=2.1843  λ_max=12.6846\n",
      "[SGD | lr=0.001] Epoch 3523/4000: train_loss=1.8831  test_loss=2.1842  λ_max=13.0082\n",
      "[SGD | lr=0.001] Epoch 3524/4000: train_loss=1.8828  test_loss=2.1842  λ_max=13.6834\n",
      "[SGD | lr=0.001] Iter 56400: loss=1.8852\n",
      "[SGD | lr=0.001] Epoch 3525/4000: train_loss=1.8828  test_loss=2.1842  λ_max=13.3726\n",
      "[SGD | lr=0.001] Epoch 3526/4000: train_loss=1.8826  test_loss=2.1841  λ_max=13.3315\n",
      "[SGD | lr=0.001] Epoch 3527/4000: train_loss=1.8826  test_loss=2.1841  λ_max=13.8202\n",
      "[SGD | lr=0.001] Epoch 3528/4000: train_loss=1.8823  test_loss=2.1841  λ_max=13.4897\n",
      "[SGD | lr=0.001] Epoch 3529/4000: train_loss=1.8823  test_loss=2.1840  λ_max=12.1005\n",
      "[SGD | lr=0.001] Epoch 3530/4000: train_loss=1.8822  test_loss=2.1840  λ_max=13.4131\n",
      "[SGD | lr=0.001] Epoch 3531/4000: train_loss=1.8819  test_loss=2.1840  λ_max=12.8359\n",
      "[SGD | lr=0.001] Iter 56500: loss=1.8843\n",
      "[SGD | lr=0.001] Epoch 3532/4000: train_loss=1.8817  test_loss=2.1839  λ_max=13.1560\n",
      "[SGD | lr=0.001] Epoch 3533/4000: train_loss=1.8815  test_loss=2.1839  λ_max=13.5616\n",
      "[SGD | lr=0.001] Epoch 3534/4000: train_loss=1.8818  test_loss=2.1839  λ_max=13.9640\n",
      "[SGD | lr=0.001] Epoch 3535/4000: train_loss=1.8813  test_loss=2.1838  λ_max=13.3879\n",
      "[SGD | lr=0.001] Epoch 3536/4000: train_loss=1.8813  test_loss=2.1838  λ_max=13.9107\n",
      "[SGD | lr=0.001] Epoch 3537/4000: train_loss=1.8812  test_loss=2.1838  λ_max=12.7641\n",
      "[SGD | lr=0.001] Iter 56600: loss=1.8788\n",
      "[SGD | lr=0.001] Epoch 3538/4000: train_loss=1.8811  test_loss=2.1837  λ_max=13.1080\n",
      "[SGD | lr=0.001] Epoch 3539/4000: train_loss=1.8807  test_loss=2.1837  λ_max=12.5622\n",
      "[SGD | lr=0.001] Epoch 3540/4000: train_loss=1.8807  test_loss=2.1837  λ_max=12.9728\n",
      "[SGD | lr=0.001] Epoch 3541/4000: train_loss=1.8806  test_loss=2.1837  λ_max=13.6938\n",
      "[SGD | lr=0.001] Epoch 3542/4000: train_loss=1.8804  test_loss=2.1836  λ_max=13.1154\n",
      "[SGD | lr=0.001] Epoch 3543/4000: train_loss=1.8802  test_loss=2.1836  λ_max=13.6361\n",
      "[SGD | lr=0.001] Iter 56700: loss=1.8879\n",
      "[SGD | lr=0.001] Epoch 3544/4000: train_loss=1.8800  test_loss=2.1836  λ_max=13.6397\n",
      "[SGD | lr=0.001] Epoch 3545/4000: train_loss=1.8798  test_loss=2.1835  λ_max=13.1451\n",
      "[SGD | lr=0.001] Epoch 3546/4000: train_loss=1.8798  test_loss=2.1835  λ_max=13.6839\n",
      "[SGD | lr=0.001] Epoch 3547/4000: train_loss=1.8796  test_loss=2.1835  λ_max=13.6743\n",
      "[SGD | lr=0.001] Epoch 3548/4000: train_loss=1.8795  test_loss=2.1834  λ_max=13.0126\n",
      "[SGD | lr=0.001] Epoch 3549/4000: train_loss=1.8797  test_loss=2.1834  λ_max=13.7302\n",
      "[SGD | lr=0.001] Iter 56800: loss=1.8817\n",
      "[SGD | lr=0.001] Epoch 3550/4000: train_loss=1.8794  test_loss=2.1834  λ_max=12.7960\n",
      "[SGD | lr=0.001] Epoch 3551/4000: train_loss=1.8795  test_loss=2.1834  λ_max=13.1799\n",
      "[SGD | lr=0.001] Epoch 3552/4000: train_loss=1.8791  test_loss=2.1833  λ_max=13.5727\n",
      "[SGD | lr=0.001] Epoch 3553/4000: train_loss=1.8790  test_loss=2.1833  λ_max=13.7941\n",
      "[SGD | lr=0.001] Epoch 3554/4000: train_loss=1.8786  test_loss=2.1833  λ_max=12.4222\n",
      "[SGD | lr=0.001] Epoch 3555/4000: train_loss=1.8788  test_loss=2.1832  λ_max=13.1574\n",
      "[SGD | lr=0.001] Epoch 3556/4000: train_loss=1.8784  test_loss=2.1832  λ_max=13.2100\n",
      "[SGD | lr=0.001] Iter 56900: loss=1.8771\n",
      "[SGD | lr=0.001] Epoch 3557/4000: train_loss=1.8781  test_loss=2.1832  λ_max=13.8143\n",
      "[SGD | lr=0.001] Epoch 3558/4000: train_loss=1.8781  test_loss=2.1831  λ_max=12.9720\n",
      "[SGD | lr=0.001] Epoch 3559/4000: train_loss=1.8783  test_loss=2.1831  λ_max=13.6813\n",
      "[SGD | lr=0.001] Epoch 3560/4000: train_loss=1.8779  test_loss=2.1831  λ_max=13.0918\n",
      "[SGD | lr=0.001] Epoch 3561/4000: train_loss=1.8776  test_loss=2.1830  λ_max=13.1634\n",
      "[SGD | lr=0.001] Epoch 3562/4000: train_loss=1.8775  test_loss=2.1830  λ_max=13.2158\n",
      "[SGD | lr=0.001] Iter 57000: loss=1.8817\n",
      "[SGD | lr=0.001] Epoch 3563/4000: train_loss=1.8775  test_loss=2.1830  λ_max=12.6048\n",
      "[SGD | lr=0.001] Epoch 3564/4000: train_loss=1.8775  test_loss=2.1830  λ_max=13.5564\n",
      "[SGD | lr=0.001] Epoch 3565/4000: train_loss=1.8771  test_loss=2.1829  λ_max=13.6860\n",
      "[SGD | lr=0.001] Epoch 3566/4000: train_loss=1.8772  test_loss=2.1829  λ_max=13.4426\n",
      "[SGD | lr=0.001] Epoch 3567/4000: train_loss=1.8769  test_loss=2.1828  λ_max=13.9782\n",
      "[SGD | lr=0.001] Epoch 3568/4000: train_loss=1.8767  test_loss=2.1828  λ_max=13.8904\n",
      "[SGD | lr=0.001] Iter 57100: loss=1.8738\n",
      "[SGD | lr=0.001] Epoch 3569/4000: train_loss=1.8770  test_loss=2.1828  λ_max=14.0157\n",
      "[SGD | lr=0.001] Epoch 3570/4000: train_loss=1.8765  test_loss=2.1828  λ_max=12.8862\n",
      "[SGD | lr=0.001] Epoch 3571/4000: train_loss=1.8764  test_loss=2.1827  λ_max=13.4374\n",
      "[SGD | lr=0.001] Epoch 3572/4000: train_loss=1.8763  test_loss=2.1827  λ_max=13.2662\n",
      "[SGD | lr=0.001] Epoch 3573/4000: train_loss=1.8760  test_loss=2.1827  λ_max=13.4074\n",
      "[SGD | lr=0.001] Epoch 3574/4000: train_loss=1.8758  test_loss=2.1826  λ_max=13.1101\n",
      "[SGD | lr=0.001] Iter 57200: loss=1.8763\n",
      "[SGD | lr=0.001] Epoch 3575/4000: train_loss=1.8759  test_loss=2.1826  λ_max=14.0149\n",
      "[SGD | lr=0.001] Epoch 3576/4000: train_loss=1.8757  test_loss=2.1826  λ_max=14.1096\n",
      "[SGD | lr=0.001] Epoch 3577/4000: train_loss=1.8757  test_loss=2.1826  λ_max=14.1363\n",
      "[SGD | lr=0.001] Epoch 3578/4000: train_loss=1.8752  test_loss=2.1825  λ_max=13.9832\n",
      "[SGD | lr=0.001] Epoch 3579/4000: train_loss=1.8755  test_loss=2.1825  λ_max=13.0821\n",
      "[SGD | lr=0.001] Epoch 3580/4000: train_loss=1.8751  test_loss=2.1825  λ_max=13.6612\n",
      "[SGD | lr=0.001] Epoch 3581/4000: train_loss=1.8750  test_loss=2.1824  λ_max=13.7380\n",
      "[SGD | lr=0.001] Iter 57300: loss=1.8816\n",
      "[SGD | lr=0.001] Epoch 3582/4000: train_loss=1.8748  test_loss=2.1824  λ_max=13.0230\n",
      "[SGD | lr=0.001] Epoch 3583/4000: train_loss=1.8748  test_loss=2.1824  λ_max=12.8641\n",
      "[SGD | lr=0.001] Epoch 3584/4000: train_loss=1.8747  test_loss=2.1823  λ_max=12.8764\n",
      "[SGD | lr=0.001] Epoch 3585/4000: train_loss=1.8745  test_loss=2.1823  λ_max=13.3009\n",
      "[SGD | lr=0.001] Epoch 3586/4000: train_loss=1.8743  test_loss=2.1823  λ_max=13.1795\n",
      "[SGD | lr=0.001] Epoch 3587/4000: train_loss=1.8739  test_loss=2.1822  λ_max=13.9286\n",
      "[SGD | lr=0.001] Iter 57400: loss=1.8790\n",
      "[SGD | lr=0.001] Epoch 3588/4000: train_loss=1.8740  test_loss=2.1822  λ_max=13.5049\n",
      "[SGD | lr=0.001] Epoch 3589/4000: train_loss=1.8740  test_loss=2.1822  λ_max=14.1390\n",
      "[SGD | lr=0.001] Epoch 3590/4000: train_loss=1.8739  test_loss=2.1822  λ_max=13.9030\n",
      "[SGD | lr=0.001] Epoch 3591/4000: train_loss=1.8736  test_loss=2.1821  λ_max=13.2819\n",
      "[SGD | lr=0.001] Epoch 3592/4000: train_loss=1.8734  test_loss=2.1821  λ_max=13.2057\n",
      "[SGD | lr=0.001] Epoch 3593/4000: train_loss=1.8733  test_loss=2.1821  λ_max=13.8441\n",
      "[SGD | lr=0.001] Iter 57500: loss=1.8704\n",
      "[SGD | lr=0.001] Epoch 3594/4000: train_loss=1.8731  test_loss=2.1820  λ_max=13.1088\n",
      "[SGD | lr=0.001] Epoch 3595/4000: train_loss=1.8731  test_loss=2.1820  λ_max=13.2488\n",
      "[SGD | lr=0.001] Epoch 3596/4000: train_loss=1.8729  test_loss=2.1820  λ_max=12.9495\n",
      "[SGD | lr=0.001] Epoch 3597/4000: train_loss=1.8726  test_loss=2.1819  λ_max=13.3951\n",
      "[SGD | lr=0.001] Epoch 3598/4000: train_loss=1.8726  test_loss=2.1819  λ_max=13.3258\n",
      "[SGD | lr=0.001] Epoch 3599/4000: train_loss=1.8728  test_loss=2.1819  λ_max=13.6812\n",
      "[SGD | lr=0.001] Iter 57600: loss=1.8790\n",
      "[SGD | lr=0.001] Epoch 3600/4000: train_loss=1.8726  test_loss=2.1819  λ_max=13.4412\n",
      "[SGD | lr=0.001] Epoch 3601/4000: train_loss=1.8722  test_loss=2.1818  λ_max=13.9680\n",
      "[SGD | lr=0.001] Epoch 3602/4000: train_loss=1.8722  test_loss=2.1818  λ_max=14.0871\n",
      "[SGD | lr=0.001] Epoch 3603/4000: train_loss=1.8720  test_loss=2.1817  λ_max=13.0382\n",
      "[SGD | lr=0.001] Epoch 3604/4000: train_loss=1.8718  test_loss=2.1817  λ_max=13.7058\n",
      "[SGD | lr=0.001] Epoch 3605/4000: train_loss=1.8718  test_loss=2.1817  λ_max=13.7466\n",
      "[SGD | lr=0.001] Epoch 3606/4000: train_loss=1.8716  test_loss=2.1816  λ_max=13.1744\n",
      "[SGD | lr=0.001] Iter 57700: loss=1.8731\n",
      "[SGD | lr=0.001] Epoch 3607/4000: train_loss=1.8715  test_loss=2.1816  λ_max=13.6393\n",
      "[SGD | lr=0.001] Epoch 3608/4000: train_loss=1.8714  test_loss=2.1816  λ_max=13.3027\n",
      "[SGD | lr=0.001] Epoch 3609/4000: train_loss=1.8712  test_loss=2.1816  λ_max=14.1166\n",
      "[SGD | lr=0.001] Epoch 3610/4000: train_loss=1.8709  test_loss=2.1815  λ_max=13.8048\n",
      "[SGD | lr=0.001] Epoch 3611/4000: train_loss=1.8709  test_loss=2.1815  λ_max=14.1170\n",
      "[SGD | lr=0.001] Epoch 3612/4000: train_loss=1.8709  test_loss=2.1815  λ_max=13.4708\n",
      "[SGD | lr=0.001] Iter 57800: loss=1.8732\n",
      "[SGD | lr=0.001] Epoch 3613/4000: train_loss=1.8705  test_loss=2.1815  λ_max=13.2423\n",
      "[SGD | lr=0.001] Epoch 3614/4000: train_loss=1.8706  test_loss=2.1814  λ_max=14.2230\n",
      "[SGD | lr=0.001] Epoch 3615/4000: train_loss=1.8703  test_loss=2.1814  λ_max=14.0804\n",
      "[SGD | lr=0.001] Epoch 3616/4000: train_loss=1.8703  test_loss=2.1813  λ_max=13.8692\n",
      "[SGD | lr=0.001] Epoch 3617/4000: train_loss=1.8700  test_loss=2.1813  λ_max=13.0117\n",
      "[SGD | lr=0.001] Epoch 3618/4000: train_loss=1.8700  test_loss=2.1813  λ_max=13.2351\n",
      "[SGD | lr=0.001] Iter 57900: loss=1.8688\n",
      "[SGD | lr=0.001] Epoch 3619/4000: train_loss=1.8697  test_loss=2.1813  λ_max=14.0496\n",
      "[SGD | lr=0.001] Epoch 3620/4000: train_loss=1.8697  test_loss=2.1812  λ_max=13.1632\n",
      "[SGD | lr=0.001] Epoch 3621/4000: train_loss=1.8696  test_loss=2.1812  λ_max=13.6232\n",
      "[SGD | lr=0.001] Epoch 3622/4000: train_loss=1.8693  test_loss=2.1812  λ_max=12.7365\n",
      "[SGD | lr=0.001] Epoch 3623/4000: train_loss=1.8694  test_loss=2.1811  λ_max=14.2667\n",
      "[SGD | lr=0.001] Epoch 3624/4000: train_loss=1.8690  test_loss=2.1811  λ_max=13.3400\n",
      "[SGD | lr=0.001] Iter 58000: loss=1.8650\n",
      "[SGD | lr=0.001] Epoch 3625/4000: train_loss=1.8689  test_loss=2.1811  λ_max=13.7990\n",
      "[SGD | lr=0.001] Epoch 3626/4000: train_loss=1.8687  test_loss=2.1811  λ_max=13.1653\n",
      "[SGD | lr=0.001] Epoch 3627/4000: train_loss=1.8689  test_loss=2.1810  λ_max=13.3433\n",
      "[SGD | lr=0.001] Epoch 3628/4000: train_loss=1.8687  test_loss=2.1810  λ_max=13.3894\n",
      "[SGD | lr=0.001] Epoch 3629/4000: train_loss=1.8683  test_loss=2.1809  λ_max=13.9757\n",
      "[SGD | lr=0.001] Epoch 3630/4000: train_loss=1.8684  test_loss=2.1809  λ_max=14.2766\n",
      "[SGD | lr=0.001] Epoch 3631/4000: train_loss=1.8682  test_loss=2.1809  λ_max=14.5000\n",
      "[SGD | lr=0.001] Iter 58100: loss=1.8636\n",
      "[SGD | lr=0.001] Epoch 3632/4000: train_loss=1.8681  test_loss=2.1809  λ_max=14.2742\n",
      "[SGD | lr=0.001] Epoch 3633/4000: train_loss=1.8679  test_loss=2.1808  λ_max=13.2416\n",
      "[SGD | lr=0.001] Epoch 3634/4000: train_loss=1.8678  test_loss=2.1808  λ_max=13.6023\n",
      "[SGD | lr=0.001] Epoch 3635/4000: train_loss=1.8675  test_loss=2.1808  λ_max=13.5108\n",
      "[SGD | lr=0.001] Epoch 3636/4000: train_loss=1.8676  test_loss=2.1807  λ_max=12.9379\n",
      "[SGD | lr=0.001] Epoch 3637/4000: train_loss=1.8675  test_loss=2.1807  λ_max=14.4480\n",
      "[SGD | lr=0.001] Iter 58200: loss=1.8637\n",
      "[SGD | lr=0.001] Epoch 3638/4000: train_loss=1.8671  test_loss=2.1807  λ_max=14.4596\n",
      "[SGD | lr=0.001] Epoch 3639/4000: train_loss=1.8672  test_loss=2.1806  λ_max=13.5320\n",
      "[SGD | lr=0.001] Epoch 3640/4000: train_loss=1.8669  test_loss=2.1806  λ_max=14.2755\n",
      "[SGD | lr=0.001] Epoch 3641/4000: train_loss=1.8667  test_loss=2.1806  λ_max=13.5179\n",
      "[SGD | lr=0.001] Epoch 3642/4000: train_loss=1.8667  test_loss=2.1806  λ_max=14.0510\n",
      "[SGD | lr=0.001] Epoch 3643/4000: train_loss=1.8665  test_loss=2.1805  λ_max=13.4810\n",
      "[SGD | lr=0.001] Iter 58300: loss=1.8711\n",
      "[SGD | lr=0.001] Epoch 3644/4000: train_loss=1.8663  test_loss=2.1805  λ_max=14.1343\n",
      "[SGD | lr=0.001] Epoch 3645/4000: train_loss=1.8663  test_loss=2.1805  λ_max=13.6780\n",
      "[SGD | lr=0.001] Epoch 3646/4000: train_loss=1.8662  test_loss=2.1804  λ_max=13.9096\n",
      "[SGD | lr=0.001] Epoch 3647/4000: train_loss=1.8663  test_loss=2.1804  λ_max=13.5676\n",
      "[SGD | lr=0.001] Epoch 3648/4000: train_loss=1.8658  test_loss=2.1804  λ_max=13.8037\n",
      "[SGD | lr=0.001] Epoch 3649/4000: train_loss=1.8656  test_loss=2.1804  λ_max=13.5171\n",
      "[SGD | lr=0.001] Iter 58400: loss=1.8672\n",
      "[SGD | lr=0.001] Epoch 3650/4000: train_loss=1.8656  test_loss=2.1803  λ_max=13.6467\n",
      "[SGD | lr=0.001] Epoch 3651/4000: train_loss=1.8653  test_loss=2.1803  λ_max=13.5376\n",
      "[SGD | lr=0.001] Epoch 3652/4000: train_loss=1.8654  test_loss=2.1803  λ_max=14.3883\n",
      "[SGD | lr=0.001] Epoch 3653/4000: train_loss=1.8653  test_loss=2.1803  λ_max=13.3688\n",
      "[SGD | lr=0.001] Epoch 3654/4000: train_loss=1.8651  test_loss=2.1802  λ_max=13.4829\n",
      "[SGD | lr=0.001] Epoch 3655/4000: train_loss=1.8649  test_loss=2.1802  λ_max=13.5447\n",
      "[SGD | lr=0.001] Epoch 3656/4000: train_loss=1.8651  test_loss=2.1801  λ_max=14.3440\n",
      "[SGD | lr=0.001] Iter 58500: loss=1.8681\n",
      "[SGD | lr=0.001] Epoch 3657/4000: train_loss=1.8645  test_loss=2.1801  λ_max=13.1472\n",
      "[SGD | lr=0.001] Epoch 3658/4000: train_loss=1.8644  test_loss=2.1801  λ_max=13.0716\n",
      "[SGD | lr=0.001] Epoch 3659/4000: train_loss=1.8645  test_loss=2.1801  λ_max=13.8214\n",
      "[SGD | lr=0.001] Epoch 3660/4000: train_loss=1.8641  test_loss=2.1800  λ_max=14.5366\n",
      "[SGD | lr=0.001] Epoch 3661/4000: train_loss=1.8641  test_loss=2.1800  λ_max=14.4350\n",
      "[SGD | lr=0.001] Epoch 3662/4000: train_loss=1.8640  test_loss=2.1800  λ_max=14.0945\n",
      "[SGD | lr=0.001] Iter 58600: loss=1.8698\n",
      "[SGD | lr=0.001] Epoch 3663/4000: train_loss=1.8641  test_loss=2.1799  λ_max=14.2952\n",
      "[SGD | lr=0.001] Epoch 3664/4000: train_loss=1.8638  test_loss=2.1799  λ_max=13.1080\n",
      "[SGD | lr=0.001] Epoch 3665/4000: train_loss=1.8634  test_loss=2.1799  λ_max=13.3328\n",
      "[SGD | lr=0.001] Epoch 3666/4000: train_loss=1.8635  test_loss=2.1798  λ_max=13.6039\n",
      "[SGD | lr=0.001] Epoch 3667/4000: train_loss=1.8631  test_loss=2.1798  λ_max=14.3264\n",
      "[SGD | lr=0.001] Epoch 3668/4000: train_loss=1.8632  test_loss=2.1798  λ_max=13.1302\n",
      "[SGD | lr=0.001] Iter 58700: loss=1.8653\n",
      "[SGD | lr=0.001] Epoch 3669/4000: train_loss=1.8630  test_loss=2.1798  λ_max=13.0134\n",
      "[SGD | lr=0.001] Epoch 3670/4000: train_loss=1.8628  test_loss=2.1797  λ_max=14.2454\n",
      "[SGD | lr=0.001] Epoch 3671/4000: train_loss=1.8629  test_loss=2.1797  λ_max=14.3726\n",
      "[SGD | lr=0.001] Epoch 3672/4000: train_loss=1.8626  test_loss=2.1797  λ_max=14.4593\n",
      "[SGD | lr=0.001] Epoch 3673/4000: train_loss=1.8624  test_loss=2.1796  λ_max=13.8300\n",
      "[SGD | lr=0.001] Epoch 3674/4000: train_loss=1.8624  test_loss=2.1796  λ_max=14.4914\n",
      "[SGD | lr=0.001] Iter 58800: loss=1.8693\n",
      "[SGD | lr=0.001] Epoch 3675/4000: train_loss=1.8623  test_loss=2.1796  λ_max=14.3391\n",
      "[SGD | lr=0.001] Epoch 3676/4000: train_loss=1.8622  test_loss=2.1795  λ_max=14.4691\n",
      "[SGD | lr=0.001] Epoch 3677/4000: train_loss=1.8620  test_loss=2.1795  λ_max=14.2573\n",
      "[SGD | lr=0.001] Epoch 3678/4000: train_loss=1.8616  test_loss=2.1795  λ_max=14.2879\n",
      "[SGD | lr=0.001] Epoch 3679/4000: train_loss=1.8619  test_loss=2.1795  λ_max=14.6204\n",
      "[SGD | lr=0.001] Epoch 3680/4000: train_loss=1.8616  test_loss=2.1795  λ_max=14.5276\n",
      "[SGD | lr=0.001] Epoch 3681/4000: train_loss=1.8614  test_loss=2.1794  λ_max=13.5061\n",
      "[SGD | lr=0.001] Iter 58900: loss=1.8640\n",
      "[SGD | lr=0.001] Epoch 3682/4000: train_loss=1.8613  test_loss=2.1794  λ_max=13.9102\n",
      "[SGD | lr=0.001] Epoch 3683/4000: train_loss=1.8612  test_loss=2.1793  λ_max=14.1464\n",
      "[SGD | lr=0.001] Epoch 3684/4000: train_loss=1.8610  test_loss=2.1793  λ_max=13.2846\n",
      "[SGD | lr=0.001] Epoch 3685/4000: train_loss=1.8606  test_loss=2.1793  λ_max=13.5945\n",
      "[SGD | lr=0.001] Epoch 3686/4000: train_loss=1.8607  test_loss=2.1793  λ_max=14.3715\n",
      "[SGD | lr=0.001] Epoch 3687/4000: train_loss=1.8606  test_loss=2.1792  λ_max=13.8727\n",
      "[SGD | lr=0.001] Iter 59000: loss=1.8564\n",
      "[SGD | lr=0.001] Epoch 3688/4000: train_loss=1.8605  test_loss=2.1792  λ_max=14.6341\n",
      "[SGD | lr=0.001] Epoch 3689/4000: train_loss=1.8604  test_loss=2.1792  λ_max=14.5509\n",
      "[SGD | lr=0.001] Epoch 3690/4000: train_loss=1.8603  test_loss=2.1792  λ_max=14.6011\n",
      "[SGD | lr=0.001] Epoch 3691/4000: train_loss=1.8601  test_loss=2.1791  λ_max=13.3383\n",
      "[SGD | lr=0.001] Epoch 3692/4000: train_loss=1.8599  test_loss=2.1791  λ_max=14.0185\n",
      "[SGD | lr=0.001] Epoch 3693/4000: train_loss=1.8599  test_loss=2.1791  λ_max=14.0380\n",
      "[SGD | lr=0.001] Iter 59100: loss=1.8594\n",
      "[SGD | lr=0.001] Epoch 3694/4000: train_loss=1.8595  test_loss=2.1790  λ_max=14.3344\n",
      "[SGD | lr=0.001] Epoch 3695/4000: train_loss=1.8596  test_loss=2.1790  λ_max=13.9773\n",
      "[SGD | lr=0.001] Epoch 3696/4000: train_loss=1.8592  test_loss=2.1790  λ_max=14.0729\n",
      "[SGD | lr=0.001] Epoch 3697/4000: train_loss=1.8589  test_loss=2.1790  λ_max=13.6540\n",
      "[SGD | lr=0.001] Epoch 3698/4000: train_loss=1.8588  test_loss=2.1789  λ_max=13.5825\n",
      "[SGD | lr=0.001] Epoch 3699/4000: train_loss=1.8588  test_loss=2.1789  λ_max=14.6028\n",
      "[SGD | lr=0.001] Iter 59200: loss=1.8600\n",
      "[SGD | lr=0.001] Epoch 3700/4000: train_loss=1.8588  test_loss=2.1789  λ_max=13.2004\n",
      "[SGD | lr=0.001] Epoch 3701/4000: train_loss=1.8587  test_loss=2.1788  λ_max=13.5651\n",
      "[SGD | lr=0.001] Epoch 3702/4000: train_loss=1.8586  test_loss=2.1788  λ_max=14.2477\n",
      "[SGD | lr=0.001] Epoch 3703/4000: train_loss=1.8583  test_loss=2.1788  λ_max=13.9719\n",
      "[SGD | lr=0.001] Epoch 3704/4000: train_loss=1.8582  test_loss=2.1787  λ_max=13.2832\n",
      "[SGD | lr=0.001] Epoch 3705/4000: train_loss=1.8581  test_loss=2.1787  λ_max=13.9576\n",
      "[SGD | lr=0.001] Epoch 3706/4000: train_loss=1.8582  test_loss=2.1787  λ_max=13.3537\n",
      "[SGD | lr=0.001] Iter 59300: loss=1.8563\n",
      "[SGD | lr=0.001] Epoch 3707/4000: train_loss=1.8579  test_loss=2.1786  λ_max=13.8184\n",
      "[SGD | lr=0.001] Epoch 3708/4000: train_loss=1.8576  test_loss=2.1786  λ_max=13.3442\n",
      "[SGD | lr=0.001] Epoch 3709/4000: train_loss=1.8577  test_loss=2.1786  λ_max=14.4737\n",
      "[SGD | lr=0.001] Epoch 3710/4000: train_loss=1.8576  test_loss=2.1786  λ_max=14.6046\n",
      "[SGD | lr=0.001] Epoch 3711/4000: train_loss=1.8574  test_loss=2.1785  λ_max=13.8674\n",
      "[SGD | lr=0.001] Epoch 3712/4000: train_loss=1.8574  test_loss=2.1785  λ_max=14.8565\n",
      "[SGD | lr=0.001] Iter 59400: loss=1.8561\n",
      "[SGD | lr=0.001] Epoch 3713/4000: train_loss=1.8570  test_loss=2.1785  λ_max=14.1011\n",
      "[SGD | lr=0.001] Epoch 3714/4000: train_loss=1.8570  test_loss=2.1784  λ_max=13.2913\n",
      "[SGD | lr=0.001] Epoch 3715/4000: train_loss=1.8566  test_loss=2.1784  λ_max=13.3800\n",
      "[SGD | lr=0.001] Epoch 3716/4000: train_loss=1.8567  test_loss=2.1784  λ_max=14.2907\n",
      "[SGD | lr=0.001] Epoch 3717/4000: train_loss=1.8565  test_loss=2.1784  λ_max=14.2085\n",
      "[SGD | lr=0.001] Epoch 3718/4000: train_loss=1.8565  test_loss=2.1783  λ_max=13.7381\n",
      "[SGD | lr=0.001] Iter 59500: loss=1.8598\n",
      "[SGD | lr=0.001] Epoch 3719/4000: train_loss=1.8561  test_loss=2.1783  λ_max=14.0037\n",
      "[SGD | lr=0.001] Epoch 3720/4000: train_loss=1.8559  test_loss=2.1783  λ_max=14.6196\n",
      "[SGD | lr=0.001] Epoch 3721/4000: train_loss=1.8559  test_loss=2.1782  λ_max=13.4628\n",
      "[SGD | lr=0.001] Epoch 3722/4000: train_loss=1.8560  test_loss=2.1782  λ_max=14.6251\n",
      "[SGD | lr=0.001] Epoch 3723/4000: train_loss=1.8557  test_loss=2.1782  λ_max=14.4582\n",
      "[SGD | lr=0.001] Epoch 3724/4000: train_loss=1.8557  test_loss=2.1781  λ_max=14.7974\n",
      "[SGD | lr=0.001] Iter 59600: loss=1.8478\n",
      "[SGD | lr=0.001] Epoch 3725/4000: train_loss=1.8552  test_loss=2.1781  λ_max=13.8876\n",
      "[SGD | lr=0.001] Epoch 3726/4000: train_loss=1.8551  test_loss=2.1781  λ_max=14.2768\n",
      "[SGD | lr=0.001] Epoch 3727/4000: train_loss=1.8553  test_loss=2.1781  λ_max=13.6159\n",
      "[SGD | lr=0.001] Epoch 3728/4000: train_loss=1.8549  test_loss=2.1780  λ_max=13.6543\n",
      "[SGD | lr=0.001] Epoch 3729/4000: train_loss=1.8549  test_loss=2.1780  λ_max=13.8066\n",
      "[SGD | lr=0.001] Epoch 3730/4000: train_loss=1.8548  test_loss=2.1780  λ_max=14.6020\n",
      "[SGD | lr=0.001] Epoch 3731/4000: train_loss=1.8545  test_loss=2.1780  λ_max=14.6326\n",
      "[SGD | lr=0.001] Iter 59700: loss=1.8618\n",
      "[SGD | lr=0.001] Epoch 3732/4000: train_loss=1.8548  test_loss=2.1779  λ_max=13.9194\n",
      "[SGD | lr=0.001] Epoch 3733/4000: train_loss=1.8544  test_loss=2.1779  λ_max=14.0260\n",
      "[SGD | lr=0.001] Epoch 3734/4000: train_loss=1.8542  test_loss=2.1779  λ_max=13.6643\n",
      "[SGD | lr=0.001] Epoch 3735/4000: train_loss=1.8539  test_loss=2.1778  λ_max=13.9341\n",
      "[SGD | lr=0.001] Epoch 3736/4000: train_loss=1.8542  test_loss=2.1778  λ_max=14.3604\n",
      "[SGD | lr=0.001] Epoch 3737/4000: train_loss=1.8536  test_loss=2.1778  λ_max=14.0294\n",
      "[SGD | lr=0.001] Iter 59800: loss=1.8495\n",
      "[SGD | lr=0.001] Epoch 3738/4000: train_loss=1.8539  test_loss=2.1777  λ_max=14.4788\n",
      "[SGD | lr=0.001] Epoch 3739/4000: train_loss=1.8534  test_loss=2.1777  λ_max=14.2987\n",
      "[SGD | lr=0.001] Epoch 3740/4000: train_loss=1.8535  test_loss=2.1777  λ_max=13.8920\n",
      "[SGD | lr=0.001] Epoch 3741/4000: train_loss=1.8534  test_loss=2.1777  λ_max=13.9191\n",
      "[SGD | lr=0.001] Epoch 3742/4000: train_loss=1.8529  test_loss=2.1776  λ_max=14.7959\n",
      "[SGD | lr=0.001] Epoch 3743/4000: train_loss=1.8531  test_loss=2.1776  λ_max=14.7837\n",
      "[SGD | lr=0.001] Iter 59900: loss=1.8560\n",
      "[SGD | lr=0.001] Epoch 3744/4000: train_loss=1.8528  test_loss=2.1776  λ_max=14.3923\n",
      "[SGD | lr=0.001] Epoch 3745/4000: train_loss=1.8529  test_loss=2.1776  λ_max=13.6736\n",
      "[SGD | lr=0.001] Epoch 3746/4000: train_loss=1.8526  test_loss=2.1775  λ_max=14.5893\n",
      "[SGD | lr=0.001] Epoch 3747/4000: train_loss=1.8526  test_loss=2.1775  λ_max=14.0612\n",
      "[SGD | lr=0.001] Epoch 3748/4000: train_loss=1.8523  test_loss=2.1775  λ_max=14.7030\n",
      "[SGD | lr=0.001] Epoch 3749/4000: train_loss=1.8523  test_loss=2.1774  λ_max=13.0373\n",
      "[SGD | lr=0.001] Iter 60000: loss=1.8528\n",
      "[SGD | lr=0.001] Epoch 3750/4000: train_loss=1.8521  test_loss=2.1774  λ_max=14.8232\n",
      "[SGD | lr=0.001] Epoch 3751/4000: train_loss=1.8520  test_loss=2.1774  λ_max=14.2060\n",
      "[SGD | lr=0.001] Epoch 3752/4000: train_loss=1.8518  test_loss=2.1774  λ_max=13.8229\n",
      "[SGD | lr=0.001] Epoch 3753/4000: train_loss=1.8517  test_loss=2.1773  λ_max=13.8844\n",
      "[SGD | lr=0.001] Epoch 3754/4000: train_loss=1.8515  test_loss=2.1773  λ_max=14.2849\n",
      "[SGD | lr=0.001] Epoch 3755/4000: train_loss=1.8515  test_loss=2.1773  λ_max=13.9679\n",
      "[SGD | lr=0.001] Epoch 3756/4000: train_loss=1.8513  test_loss=2.1772  λ_max=14.4084\n",
      "[SGD | lr=0.001] Iter 60100: loss=1.8435\n",
      "[SGD | lr=0.001] Epoch 3757/4000: train_loss=1.8512  test_loss=2.1772  λ_max=14.6313\n",
      "[SGD | lr=0.001] Epoch 3758/4000: train_loss=1.8508  test_loss=2.1772  λ_max=13.5929\n",
      "[SGD | lr=0.001] Epoch 3759/4000: train_loss=1.8510  test_loss=2.1772  λ_max=13.9345\n",
      "[SGD | lr=0.001] Epoch 3760/4000: train_loss=1.8509  test_loss=2.1771  λ_max=13.6723\n",
      "[SGD | lr=0.001] Epoch 3761/4000: train_loss=1.8506  test_loss=2.1771  λ_max=14.8958\n",
      "[SGD | lr=0.001] Epoch 3762/4000: train_loss=1.8503  test_loss=2.1771  λ_max=13.8742\n",
      "[SGD | lr=0.001] Iter 60200: loss=1.8504\n",
      "[SGD | lr=0.001] Epoch 3763/4000: train_loss=1.8504  test_loss=2.1770  λ_max=13.9014\n",
      "[SGD | lr=0.001] Epoch 3764/4000: train_loss=1.8502  test_loss=2.1770  λ_max=14.0858\n",
      "[SGD | lr=0.001] Epoch 3765/4000: train_loss=1.8502  test_loss=2.1770  λ_max=13.9860\n",
      "[SGD | lr=0.001] Epoch 3766/4000: train_loss=1.8499  test_loss=2.1770  λ_max=14.1710\n",
      "[SGD | lr=0.001] Epoch 3767/4000: train_loss=1.8498  test_loss=2.1769  λ_max=15.0324\n",
      "[SGD | lr=0.001] Epoch 3768/4000: train_loss=1.8495  test_loss=2.1769  λ_max=13.8796\n",
      "[SGD | lr=0.001] Iter 60300: loss=1.8486\n",
      "[SGD | lr=0.001] Epoch 3769/4000: train_loss=1.8496  test_loss=2.1769  λ_max=13.7688\n",
      "[SGD | lr=0.001] Epoch 3770/4000: train_loss=1.8495  test_loss=2.1769  λ_max=13.7403\n",
      "[SGD | lr=0.001] Epoch 3771/4000: train_loss=1.8493  test_loss=2.1768  λ_max=14.0894\n",
      "[SGD | lr=0.001] Epoch 3772/4000: train_loss=1.8490  test_loss=2.1768  λ_max=13.6966\n",
      "[SGD | lr=0.001] Epoch 3773/4000: train_loss=1.8491  test_loss=2.1768  λ_max=14.7979\n",
      "[SGD | lr=0.001] Epoch 3774/4000: train_loss=1.8491  test_loss=2.1767  λ_max=14.7400\n",
      "[SGD | lr=0.001] Iter 60400: loss=1.8473\n",
      "[SGD | lr=0.001] Epoch 3775/4000: train_loss=1.8487  test_loss=2.1767  λ_max=14.2489\n",
      "[SGD | lr=0.001] Epoch 3776/4000: train_loss=1.8483  test_loss=2.1767  λ_max=14.1876\n",
      "[SGD | lr=0.001] Epoch 3777/4000: train_loss=1.8483  test_loss=2.1766  λ_max=14.1610\n",
      "[SGD | lr=0.001] Epoch 3778/4000: train_loss=1.8486  test_loss=2.1766  λ_max=13.6843\n",
      "[SGD | lr=0.001] Epoch 3779/4000: train_loss=1.8481  test_loss=2.1766  λ_max=14.4752\n",
      "[SGD | lr=0.001] Epoch 3780/4000: train_loss=1.8483  test_loss=2.1765  λ_max=13.8833\n",
      "[SGD | lr=0.001] Epoch 3781/4000: train_loss=1.8479  test_loss=2.1765  λ_max=14.4387\n",
      "[SGD | lr=0.001] Iter 60500: loss=1.8545\n",
      "[SGD | lr=0.001] Epoch 3782/4000: train_loss=1.8478  test_loss=2.1765  λ_max=14.0372\n",
      "[SGD | lr=0.001] Epoch 3783/4000: train_loss=1.8476  test_loss=2.1765  λ_max=14.8622\n",
      "[SGD | lr=0.001] Epoch 3784/4000: train_loss=1.8473  test_loss=2.1764  λ_max=14.9966\n",
      "[SGD | lr=0.001] Epoch 3785/4000: train_loss=1.8474  test_loss=2.1764  λ_max=15.1858\n",
      "[SGD | lr=0.001] Epoch 3786/4000: train_loss=1.8476  test_loss=2.1764  λ_max=14.6708\n",
      "[SGD | lr=0.001] Epoch 3787/4000: train_loss=1.8471  test_loss=2.1764  λ_max=14.9878\n",
      "[SGD | lr=0.001] Iter 60600: loss=1.8487\n",
      "[SGD | lr=0.001] Epoch 3788/4000: train_loss=1.8471  test_loss=2.1763  λ_max=14.0631\n",
      "[SGD | lr=0.001] Epoch 3789/4000: train_loss=1.8468  test_loss=2.1763  λ_max=15.1462\n",
      "[SGD | lr=0.001] Epoch 3790/4000: train_loss=1.8466  test_loss=2.1763  λ_max=14.1546\n",
      "[SGD | lr=0.001] Epoch 3791/4000: train_loss=1.8466  test_loss=2.1762  λ_max=15.0239\n",
      "[SGD | lr=0.001] Epoch 3792/4000: train_loss=1.8462  test_loss=2.1762  λ_max=15.0878\n",
      "[SGD | lr=0.001] Epoch 3793/4000: train_loss=1.8463  test_loss=2.1762  λ_max=15.0031\n",
      "[SGD | lr=0.001] Iter 60700: loss=1.8544\n",
      "[SGD | lr=0.001] Epoch 3794/4000: train_loss=1.8462  test_loss=2.1761  λ_max=14.5286\n",
      "[SGD | lr=0.001] Epoch 3795/4000: train_loss=1.8460  test_loss=2.1761  λ_max=14.0513\n",
      "[SGD | lr=0.001] Epoch 3796/4000: train_loss=1.8459  test_loss=2.1761  λ_max=13.9879\n",
      "[SGD | lr=0.001] Epoch 3797/4000: train_loss=1.8458  test_loss=2.1761  λ_max=14.1328\n",
      "[SGD | lr=0.001] Epoch 3798/4000: train_loss=1.8455  test_loss=2.1760  λ_max=13.2594\n",
      "[SGD | lr=0.001] Epoch 3799/4000: train_loss=1.8456  test_loss=2.1760  λ_max=14.6410\n",
      "[SGD | lr=0.001] Iter 60800: loss=1.8498\n",
      "[SGD | lr=0.001] Epoch 3800/4000: train_loss=1.8455  test_loss=2.1760  λ_max=14.2430\n",
      "[SGD | lr=0.001] Epoch 3801/4000: train_loss=1.8452  test_loss=2.1759  λ_max=14.6835\n",
      "[SGD | lr=0.001] Epoch 3802/4000: train_loss=1.8450  test_loss=2.1759  λ_max=15.1120\n",
      "[SGD | lr=0.001] Epoch 3803/4000: train_loss=1.8451  test_loss=2.1759  λ_max=14.2100\n",
      "[SGD | lr=0.001] Epoch 3804/4000: train_loss=1.8447  test_loss=2.1759  λ_max=13.7192\n",
      "[SGD | lr=0.001] Epoch 3805/4000: train_loss=1.8445  test_loss=2.1758  λ_max=14.5145\n",
      "[SGD | lr=0.001] Epoch 3806/4000: train_loss=1.8445  test_loss=2.1758  λ_max=14.2960\n",
      "[SGD | lr=0.001] Iter 60900: loss=1.8463\n",
      "[SGD | lr=0.001] Epoch 3807/4000: train_loss=1.8445  test_loss=2.1758  λ_max=13.5264\n",
      "[SGD | lr=0.001] Epoch 3808/4000: train_loss=1.8446  test_loss=2.1758  λ_max=14.2520\n",
      "[SGD | lr=0.001] Epoch 3809/4000: train_loss=1.8442  test_loss=2.1757  λ_max=13.7008\n",
      "[SGD | lr=0.001] Epoch 3810/4000: train_loss=1.8441  test_loss=2.1757  λ_max=14.0156\n",
      "[SGD | lr=0.001] Epoch 3811/4000: train_loss=1.8439  test_loss=2.1757  λ_max=14.2479\n",
      "[SGD | lr=0.001] Epoch 3812/4000: train_loss=1.8437  test_loss=2.1756  λ_max=14.7269\n",
      "[SGD | lr=0.001] Iter 61000: loss=1.8428\n",
      "[SGD | lr=0.001] Epoch 3813/4000: train_loss=1.8436  test_loss=2.1756  λ_max=14.2217\n",
      "[SGD | lr=0.001] Epoch 3814/4000: train_loss=1.8436  test_loss=2.1756  λ_max=14.1661\n",
      "[SGD | lr=0.001] Epoch 3815/4000: train_loss=1.8432  test_loss=2.1755  λ_max=14.7795\n",
      "[SGD | lr=0.001] Epoch 3816/4000: train_loss=1.8431  test_loss=2.1755  λ_max=14.2939\n",
      "[SGD | lr=0.001] Epoch 3817/4000: train_loss=1.8432  test_loss=2.1755  λ_max=15.0403\n",
      "[SGD | lr=0.001] Epoch 3818/4000: train_loss=1.8432  test_loss=2.1755  λ_max=14.9785\n",
      "[SGD | lr=0.001] Iter 61100: loss=1.8449\n",
      "[SGD | lr=0.001] Epoch 3819/4000: train_loss=1.8426  test_loss=2.1754  λ_max=14.4526\n",
      "[SGD | lr=0.001] Epoch 3820/4000: train_loss=1.8427  test_loss=2.1754  λ_max=14.5902\n",
      "[SGD | lr=0.001] Epoch 3821/4000: train_loss=1.8426  test_loss=2.1754  λ_max=13.8668\n",
      "[SGD | lr=0.001] Epoch 3822/4000: train_loss=1.8424  test_loss=2.1754  λ_max=14.6514\n",
      "[SGD | lr=0.001] Epoch 3823/4000: train_loss=1.8425  test_loss=2.1754  λ_max=13.5931\n",
      "[SGD | lr=0.001] Epoch 3824/4000: train_loss=1.8422  test_loss=2.1753  λ_max=13.1831\n",
      "[SGD | lr=0.001] Iter 61200: loss=1.8389\n",
      "[SGD | lr=0.001] Epoch 3825/4000: train_loss=1.8420  test_loss=2.1753  λ_max=14.5425\n",
      "[SGD | lr=0.001] Epoch 3826/4000: train_loss=1.8419  test_loss=2.1752  λ_max=14.0153\n",
      "[SGD | lr=0.001] Epoch 3827/4000: train_loss=1.8418  test_loss=2.1752  λ_max=14.1258\n",
      "[SGD | lr=0.001] Epoch 3828/4000: train_loss=1.8414  test_loss=2.1752  λ_max=14.8902\n",
      "[SGD | lr=0.001] Epoch 3829/4000: train_loss=1.8417  test_loss=2.1751  λ_max=14.7281\n",
      "[SGD | lr=0.001] Epoch 3830/4000: train_loss=1.8416  test_loss=2.1751  λ_max=14.1871\n",
      "[SGD | lr=0.001] Epoch 3831/4000: train_loss=1.8413  test_loss=2.1751  λ_max=15.3924\n",
      "[SGD | lr=0.001] Iter 61300: loss=1.8420\n",
      "[SGD | lr=0.001] Epoch 3832/4000: train_loss=1.8412  test_loss=2.1751  λ_max=14.9374\n",
      "[SGD | lr=0.001] Epoch 3833/4000: train_loss=1.8409  test_loss=2.1750  λ_max=14.8172\n",
      "[SGD | lr=0.001] Epoch 3834/4000: train_loss=1.8410  test_loss=2.1750  λ_max=14.3943\n",
      "[SGD | lr=0.001] Epoch 3835/4000: train_loss=1.8409  test_loss=2.1750  λ_max=15.1612\n",
      "[SGD | lr=0.001] Epoch 3836/4000: train_loss=1.8404  test_loss=2.1750  λ_max=13.9722\n",
      "[SGD | lr=0.001] Epoch 3837/4000: train_loss=1.8405  test_loss=2.1749  λ_max=15.1606\n",
      "[SGD | lr=0.001] Iter 61400: loss=1.8357\n",
      "[SGD | lr=0.001] Epoch 3838/4000: train_loss=1.8404  test_loss=2.1749  λ_max=14.7933\n",
      "[SGD | lr=0.001] Epoch 3839/4000: train_loss=1.8403  test_loss=2.1749  λ_max=15.0159\n",
      "[SGD | lr=0.001] Epoch 3840/4000: train_loss=1.8400  test_loss=2.1748  λ_max=14.4460\n",
      "[SGD | lr=0.001] Epoch 3841/4000: train_loss=1.8400  test_loss=2.1748  λ_max=15.2520\n",
      "[SGD | lr=0.001] Epoch 3842/4000: train_loss=1.8400  test_loss=2.1748  λ_max=15.2132\n",
      "[SGD | lr=0.001] Epoch 3843/4000: train_loss=1.8399  test_loss=2.1748  λ_max=14.2523\n",
      "[SGD | lr=0.001] Iter 61500: loss=1.8425\n",
      "[SGD | lr=0.001] Epoch 3844/4000: train_loss=1.8395  test_loss=2.1747  λ_max=14.5290\n",
      "[SGD | lr=0.001] Epoch 3845/4000: train_loss=1.8394  test_loss=2.1747  λ_max=15.2781\n",
      "[SGD | lr=0.001] Epoch 3846/4000: train_loss=1.8394  test_loss=2.1747  λ_max=14.2122\n",
      "[SGD | lr=0.001] Epoch 3847/4000: train_loss=1.8391  test_loss=2.1746  λ_max=15.1682\n",
      "[SGD | lr=0.001] Epoch 3848/4000: train_loss=1.8392  test_loss=2.1746  λ_max=14.2395\n",
      "[SGD | lr=0.001] Epoch 3849/4000: train_loss=1.8389  test_loss=2.1746  λ_max=15.0134\n",
      "[SGD | lr=0.001] Iter 61600: loss=1.8372\n",
      "[SGD | lr=0.001] Epoch 3850/4000: train_loss=1.8387  test_loss=2.1746  λ_max=14.1674\n",
      "[SGD | lr=0.001] Epoch 3851/4000: train_loss=1.8383  test_loss=2.1745  λ_max=15.1739\n",
      "[SGD | lr=0.001] Epoch 3852/4000: train_loss=1.8383  test_loss=2.1745  λ_max=15.0104\n",
      "[SGD | lr=0.001] Epoch 3853/4000: train_loss=1.8384  test_loss=2.1745  λ_max=13.8693\n",
      "[SGD | lr=0.001] Epoch 3854/4000: train_loss=1.8382  test_loss=2.1744  λ_max=14.9933\n",
      "[SGD | lr=0.001] Epoch 3855/4000: train_loss=1.8381  test_loss=2.1744  λ_max=14.4321\n",
      "[SGD | lr=0.001] Epoch 3856/4000: train_loss=1.8380  test_loss=2.1744  λ_max=13.6761\n",
      "[SGD | lr=0.001] Iter 61700: loss=1.8404\n",
      "[SGD | lr=0.001] Epoch 3857/4000: train_loss=1.8379  test_loss=2.1743  λ_max=15.3252\n",
      "[SGD | lr=0.001] Epoch 3858/4000: train_loss=1.8376  test_loss=2.1743  λ_max=15.4572\n",
      "[SGD | lr=0.001] Epoch 3859/4000: train_loss=1.8377  test_loss=2.1743  λ_max=15.1270\n",
      "[SGD | lr=0.001] Epoch 3860/4000: train_loss=1.8376  test_loss=2.1743  λ_max=15.0121\n",
      "[SGD | lr=0.001] Epoch 3861/4000: train_loss=1.8371  test_loss=2.1743  λ_max=14.4796\n",
      "[SGD | lr=0.001] Epoch 3862/4000: train_loss=1.8373  test_loss=2.1742  λ_max=14.9539\n",
      "[SGD | lr=0.001] Iter 61800: loss=1.8326\n",
      "[SGD | lr=0.001] Epoch 3863/4000: train_loss=1.8369  test_loss=2.1742  λ_max=15.0834\n",
      "[SGD | lr=0.001] Epoch 3864/4000: train_loss=1.8368  test_loss=2.1741  λ_max=14.2910\n",
      "[SGD | lr=0.001] Epoch 3865/4000: train_loss=1.8366  test_loss=2.1741  λ_max=13.9267\n",
      "[SGD | lr=0.001] Epoch 3866/4000: train_loss=1.8363  test_loss=2.1741  λ_max=14.0891\n",
      "[SGD | lr=0.001] Epoch 3867/4000: train_loss=1.8367  test_loss=2.1741  λ_max=14.7761\n",
      "[SGD | lr=0.001] Epoch 3868/4000: train_loss=1.8364  test_loss=2.1741  λ_max=15.1300\n",
      "[SGD | lr=0.001] Iter 61900: loss=1.8381\n",
      "[SGD | lr=0.001] Epoch 3869/4000: train_loss=1.8363  test_loss=2.1740  λ_max=14.8010\n",
      "[SGD | lr=0.001] Epoch 3870/4000: train_loss=1.8362  test_loss=2.1740  λ_max=13.7638\n",
      "[SGD | lr=0.001] Epoch 3871/4000: train_loss=1.8359  test_loss=2.1740  λ_max=14.1211\n",
      "[SGD | lr=0.001] Epoch 3872/4000: train_loss=1.8362  test_loss=2.1739  λ_max=14.3561\n",
      "[SGD | lr=0.001] Epoch 3873/4000: train_loss=1.8359  test_loss=2.1739  λ_max=14.5480\n",
      "[SGD | lr=0.001] Epoch 3874/4000: train_loss=1.8359  test_loss=2.1739  λ_max=15.3592\n",
      "[SGD | lr=0.001] Iter 62000: loss=1.8408\n",
      "[SGD | lr=0.001] Epoch 3875/4000: train_loss=1.8356  test_loss=2.1738  λ_max=14.3900\n",
      "[SGD | lr=0.001] Epoch 3876/4000: train_loss=1.8355  test_loss=2.1738  λ_max=14.6593\n",
      "[SGD | lr=0.001] Epoch 3877/4000: train_loss=1.8353  test_loss=2.1738  λ_max=15.1244\n",
      "[SGD | lr=0.001] Epoch 3878/4000: train_loss=1.8352  test_loss=2.1738  λ_max=15.1411\n",
      "[SGD | lr=0.001] Epoch 3879/4000: train_loss=1.8349  test_loss=2.1738  λ_max=15.2653\n",
      "[SGD | lr=0.001] Epoch 3880/4000: train_loss=1.8347  test_loss=2.1737  λ_max=15.2065\n",
      "[SGD | lr=0.001] Epoch 3881/4000: train_loss=1.8348  test_loss=2.1737  λ_max=15.4997\n",
      "[SGD | lr=0.001] Iter 62100: loss=1.8384\n",
      "[SGD | lr=0.001] Epoch 3882/4000: train_loss=1.8347  test_loss=2.1736  λ_max=15.2023\n",
      "[SGD | lr=0.001] Epoch 3883/4000: train_loss=1.8343  test_loss=2.1736  λ_max=14.4464\n",
      "[SGD | lr=0.001] Epoch 3884/4000: train_loss=1.8341  test_loss=2.1736  λ_max=14.2077\n",
      "[SGD | lr=0.001] Epoch 3885/4000: train_loss=1.8340  test_loss=2.1736  λ_max=15.2978\n",
      "[SGD | lr=0.001] Epoch 3886/4000: train_loss=1.8336  test_loss=2.1736  λ_max=15.1007\n",
      "[SGD | lr=0.001] Epoch 3887/4000: train_loss=1.8338  test_loss=2.1735  λ_max=14.9292\n",
      "[SGD | lr=0.001] Iter 62200: loss=1.8386\n",
      "[SGD | lr=0.001] Epoch 3888/4000: train_loss=1.8338  test_loss=2.1735  λ_max=15.5402\n",
      "[SGD | lr=0.001] Epoch 3889/4000: train_loss=1.8336  test_loss=2.1735  λ_max=14.5350\n",
      "[SGD | lr=0.001] Epoch 3890/4000: train_loss=1.8334  test_loss=2.1734  λ_max=15.4420\n",
      "[SGD | lr=0.001] Epoch 3891/4000: train_loss=1.8332  test_loss=2.1734  λ_max=15.4283\n",
      "[SGD | lr=0.001] Epoch 3892/4000: train_loss=1.8332  test_loss=2.1734  λ_max=14.6481\n",
      "[SGD | lr=0.001] Epoch 3893/4000: train_loss=1.8331  test_loss=2.1734  λ_max=14.9786\n",
      "[SGD | lr=0.001] Iter 62300: loss=1.8316\n",
      "[SGD | lr=0.001] Epoch 3894/4000: train_loss=1.8330  test_loss=2.1733  λ_max=14.1695\n",
      "[SGD | lr=0.001] Epoch 3895/4000: train_loss=1.8326  test_loss=2.1733  λ_max=14.3787\n",
      "[SGD | lr=0.001] Epoch 3896/4000: train_loss=1.8329  test_loss=2.1733  λ_max=13.9828\n",
      "[SGD | lr=0.001] Epoch 3897/4000: train_loss=1.8328  test_loss=2.1732  λ_max=14.2995\n",
      "[SGD | lr=0.001] Epoch 3898/4000: train_loss=1.8325  test_loss=2.1732  λ_max=15.0437\n",
      "[SGD | lr=0.001] Epoch 3899/4000: train_loss=1.8322  test_loss=2.1732  λ_max=14.5902\n",
      "[SGD | lr=0.001] Iter 62400: loss=1.8283\n",
      "[SGD | lr=0.001] Epoch 3900/4000: train_loss=1.8321  test_loss=2.1732  λ_max=14.1258\n",
      "[SGD | lr=0.001] Epoch 3901/4000: train_loss=1.8319  test_loss=2.1731  λ_max=14.8979\n",
      "[SGD | lr=0.001] Epoch 3902/4000: train_loss=1.8319  test_loss=2.1731  λ_max=15.1538\n",
      "[SGD | lr=0.001] Epoch 3903/4000: train_loss=1.8318  test_loss=2.1731  λ_max=15.0389\n",
      "[SGD | lr=0.001] Epoch 3904/4000: train_loss=1.8317  test_loss=2.1730  λ_max=13.9706\n",
      "[SGD | lr=0.001] Epoch 3905/4000: train_loss=1.8317  test_loss=2.1730  λ_max=14.9623\n",
      "[SGD | lr=0.001] Epoch 3906/4000: train_loss=1.8314  test_loss=2.1730  λ_max=14.9290\n",
      "[SGD | lr=0.001] Iter 62500: loss=1.8389\n",
      "[SGD | lr=0.001] Epoch 3907/4000: train_loss=1.8314  test_loss=2.1730  λ_max=15.4385\n",
      "[SGD | lr=0.001] Epoch 3908/4000: train_loss=1.8313  test_loss=2.1729  λ_max=14.7001\n",
      "[SGD | lr=0.001] Epoch 3909/4000: train_loss=1.8310  test_loss=2.1729  λ_max=15.2683\n",
      "[SGD | lr=0.001] Epoch 3910/4000: train_loss=1.8310  test_loss=2.1729  λ_max=14.2457\n",
      "[SGD | lr=0.001] Epoch 3911/4000: train_loss=1.8307  test_loss=2.1728  λ_max=15.5000\n",
      "[SGD | lr=0.001] Epoch 3912/4000: train_loss=1.8305  test_loss=2.1728  λ_max=14.5214\n",
      "[SGD | lr=0.001] Iter 62600: loss=1.8270\n",
      "[SGD | lr=0.001] Epoch 3913/4000: train_loss=1.8305  test_loss=2.1728  λ_max=15.0539\n",
      "[SGD | lr=0.001] Epoch 3914/4000: train_loss=1.8304  test_loss=2.1728  λ_max=15.6808\n",
      "[SGD | lr=0.001] Epoch 3915/4000: train_loss=1.8303  test_loss=2.1727  λ_max=14.4400\n",
      "[SGD | lr=0.001] Epoch 3916/4000: train_loss=1.8303  test_loss=2.1727  λ_max=15.1175\n",
      "[SGD | lr=0.001] Epoch 3917/4000: train_loss=1.8299  test_loss=2.1727  λ_max=15.4855\n",
      "[SGD | lr=0.001] Epoch 3918/4000: train_loss=1.8302  test_loss=2.1726  λ_max=14.7469\n",
      "[SGD | lr=0.001] Iter 62700: loss=1.8362\n",
      "[SGD | lr=0.001] Epoch 3919/4000: train_loss=1.8298  test_loss=2.1726  λ_max=14.6632\n",
      "[SGD | lr=0.001] Epoch 3920/4000: train_loss=1.8296  test_loss=2.1726  λ_max=14.1746\n",
      "[SGD | lr=0.001] Epoch 3921/4000: train_loss=1.8295  test_loss=2.1726  λ_max=14.7503\n",
      "[SGD | lr=0.001] Epoch 3922/4000: train_loss=1.8291  test_loss=2.1725  λ_max=14.3765\n",
      "[SGD | lr=0.001] Epoch 3923/4000: train_loss=1.8290  test_loss=2.1725  λ_max=14.2483\n",
      "[SGD | lr=0.001] Epoch 3924/4000: train_loss=1.8291  test_loss=2.1725  λ_max=15.0121\n",
      "[SGD | lr=0.001] Iter 62800: loss=1.8354\n",
      "[SGD | lr=0.001] Epoch 3925/4000: train_loss=1.8291  test_loss=2.1725  λ_max=15.1760\n",
      "[SGD | lr=0.001] Epoch 3926/4000: train_loss=1.8287  test_loss=2.1724  λ_max=14.6303\n",
      "[SGD | lr=0.001] Epoch 3927/4000: train_loss=1.8289  test_loss=2.1724  λ_max=15.5855\n",
      "[SGD | lr=0.001] Epoch 3928/4000: train_loss=1.8288  test_loss=2.1724  λ_max=15.4539\n",
      "[SGD | lr=0.001] Epoch 3929/4000: train_loss=1.8283  test_loss=2.1723  λ_max=15.4464\n",
      "[SGD | lr=0.001] Epoch 3930/4000: train_loss=1.8284  test_loss=2.1723  λ_max=15.2396\n",
      "[SGD | lr=0.001] Epoch 3931/4000: train_loss=1.8281  test_loss=2.1723  λ_max=14.4720\n",
      "[SGD | lr=0.001] Iter 62900: loss=1.8198\n",
      "[SGD | lr=0.001] Epoch 3932/4000: train_loss=1.8281  test_loss=2.1723  λ_max=14.3997\n",
      "[SGD | lr=0.001] Epoch 3933/4000: train_loss=1.8278  test_loss=2.1723  λ_max=13.7680\n",
      "[SGD | lr=0.001] Epoch 3934/4000: train_loss=1.8275  test_loss=2.1722  λ_max=15.3400\n",
      "[SGD | lr=0.001] Epoch 3935/4000: train_loss=1.8278  test_loss=2.1722  λ_max=14.9170\n",
      "[SGD | lr=0.001] Epoch 3936/4000: train_loss=1.8274  test_loss=2.1722  λ_max=14.4873\n",
      "[SGD | lr=0.001] Epoch 3937/4000: train_loss=1.8273  test_loss=2.1721  λ_max=14.9934\n",
      "[SGD | lr=0.001] Iter 63000: loss=1.8225\n",
      "[SGD | lr=0.001] Epoch 3938/4000: train_loss=1.8270  test_loss=2.1721  λ_max=15.3454\n",
      "[SGD | lr=0.001] Epoch 3939/4000: train_loss=1.8273  test_loss=2.1721  λ_max=15.0899\n",
      "[SGD | lr=0.001] Epoch 3940/4000: train_loss=1.8268  test_loss=2.1720  λ_max=14.3948\n",
      "[SGD | lr=0.001] Epoch 3941/4000: train_loss=1.8268  test_loss=2.1720  λ_max=15.2064\n",
      "[SGD | lr=0.001] Epoch 3942/4000: train_loss=1.8266  test_loss=2.1720  λ_max=15.0365\n",
      "[SGD | lr=0.001] Epoch 3943/4000: train_loss=1.8267  test_loss=2.1720  λ_max=14.7085\n",
      "[SGD | lr=0.001] Iter 63100: loss=1.8264\n",
      "[SGD | lr=0.001] Epoch 3944/4000: train_loss=1.8263  test_loss=2.1719  λ_max=15.5779\n",
      "[SGD | lr=0.001] Epoch 3945/4000: train_loss=1.8264  test_loss=2.1719  λ_max=13.9089\n",
      "[SGD | lr=0.001] Epoch 3946/4000: train_loss=1.8262  test_loss=2.1719  λ_max=14.7225\n",
      "[SGD | lr=0.001] Epoch 3947/4000: train_loss=1.8258  test_loss=2.1719  λ_max=15.5513\n",
      "[SGD | lr=0.001] Epoch 3948/4000: train_loss=1.8259  test_loss=2.1718  λ_max=14.1383\n",
      "[SGD | lr=0.001] Epoch 3949/4000: train_loss=1.8258  test_loss=2.1718  λ_max=15.5905\n",
      "[SGD | lr=0.001] Iter 63200: loss=1.8283\n",
      "[SGD | lr=0.001] Epoch 3950/4000: train_loss=1.8257  test_loss=2.1718  λ_max=14.2299\n",
      "[SGD | lr=0.001] Epoch 3951/4000: train_loss=1.8254  test_loss=2.1717  λ_max=15.4140\n",
      "[SGD | lr=0.001] Epoch 3952/4000: train_loss=1.8253  test_loss=2.1717  λ_max=14.6103\n",
      "[SGD | lr=0.001] Epoch 3953/4000: train_loss=1.8253  test_loss=2.1717  λ_max=15.3223\n",
      "[SGD | lr=0.001] Epoch 3954/4000: train_loss=1.8252  test_loss=2.1717  λ_max=15.0794\n",
      "[SGD | lr=0.001] Epoch 3955/4000: train_loss=1.8250  test_loss=2.1716  λ_max=15.6192\n",
      "[SGD | lr=0.001] Epoch 3956/4000: train_loss=1.8247  test_loss=2.1716  λ_max=14.2716\n",
      "[SGD | lr=0.001] Iter 63300: loss=1.8338\n",
      "[SGD | lr=0.001] Epoch 3957/4000: train_loss=1.8249  test_loss=2.1716  λ_max=14.3549\n",
      "[SGD | lr=0.001] Epoch 3958/4000: train_loss=1.8249  test_loss=2.1715  λ_max=14.6216\n",
      "[SGD | lr=0.001] Epoch 3959/4000: train_loss=1.8244  test_loss=2.1715  λ_max=14.2520\n",
      "[SGD | lr=0.001] Epoch 3960/4000: train_loss=1.8244  test_loss=2.1715  λ_max=14.6990\n",
      "[SGD | lr=0.001] Epoch 3961/4000: train_loss=1.8240  test_loss=2.1715  λ_max=14.4732\n",
      "[SGD | lr=0.001] Epoch 3962/4000: train_loss=1.8241  test_loss=2.1714  λ_max=14.6443\n",
      "[SGD | lr=0.001] Iter 63400: loss=1.8249\n",
      "[SGD | lr=0.001] Epoch 3963/4000: train_loss=1.8239  test_loss=2.1714  λ_max=15.2147\n",
      "[SGD | lr=0.001] Epoch 3964/4000: train_loss=1.8238  test_loss=2.1714  λ_max=15.7855\n",
      "[SGD | lr=0.001] Epoch 3965/4000: train_loss=1.8240  test_loss=2.1714  λ_max=14.6957\n",
      "[SGD | lr=0.001] Epoch 3966/4000: train_loss=1.8236  test_loss=2.1713  λ_max=14.9822\n",
      "[SGD | lr=0.001] Epoch 3967/4000: train_loss=1.8236  test_loss=2.1713  λ_max=15.6381\n",
      "[SGD | lr=0.001] Epoch 3968/4000: train_loss=1.8231  test_loss=2.1713  λ_max=15.4840\n",
      "[SGD | lr=0.001] Iter 63500: loss=1.8204\n",
      "[SGD | lr=0.001] Epoch 3969/4000: train_loss=1.8232  test_loss=2.1713  λ_max=15.9082\n",
      "[SGD | lr=0.001] Epoch 3970/4000: train_loss=1.8230  test_loss=2.1712  λ_max=14.8573\n",
      "[SGD | lr=0.001] Epoch 3971/4000: train_loss=1.8230  test_loss=2.1712  λ_max=15.4726\n",
      "[SGD | lr=0.001] Epoch 3972/4000: train_loss=1.8230  test_loss=2.1712  λ_max=15.9459\n",
      "[SGD | lr=0.001] Epoch 3973/4000: train_loss=1.8227  test_loss=2.1711  λ_max=14.2108\n",
      "[SGD | lr=0.001] Epoch 3974/4000: train_loss=1.8228  test_loss=2.1711  λ_max=15.7514\n",
      "[SGD | lr=0.001] Iter 63600: loss=1.8228\n",
      "[SGD | lr=0.001] Epoch 3975/4000: train_loss=1.8224  test_loss=2.1711  λ_max=15.7484\n",
      "[SGD | lr=0.001] Epoch 3976/4000: train_loss=1.8222  test_loss=2.1710  λ_max=15.1765\n",
      "[SGD | lr=0.001] Epoch 3977/4000: train_loss=1.8221  test_loss=2.1710  λ_max=15.0912\n",
      "[SGD | lr=0.001] Epoch 3978/4000: train_loss=1.8219  test_loss=2.1710  λ_max=15.6670\n",
      "[SGD | lr=0.001] Epoch 3979/4000: train_loss=1.8221  test_loss=2.1710  λ_max=14.9043\n",
      "[SGD | lr=0.001] Epoch 3980/4000: train_loss=1.8216  test_loss=2.1709  λ_max=15.4853\n",
      "[SGD | lr=0.001] Epoch 3981/4000: train_loss=1.8218  test_loss=2.1709  λ_max=15.3367\n",
      "[SGD | lr=0.001] Iter 63700: loss=1.8237\n",
      "[SGD | lr=0.001] Epoch 3982/4000: train_loss=1.8215  test_loss=2.1709  λ_max=14.6896\n",
      "[SGD | lr=0.001] Epoch 3983/4000: train_loss=1.8216  test_loss=2.1709  λ_max=15.9002\n",
      "[SGD | lr=0.001] Epoch 3984/4000: train_loss=1.8214  test_loss=2.1708  λ_max=14.9438\n",
      "[SGD | lr=0.001] Epoch 3985/4000: train_loss=1.8209  test_loss=2.1708  λ_max=15.2357\n",
      "[SGD | lr=0.001] Epoch 3986/4000: train_loss=1.8211  test_loss=2.1708  λ_max=15.6073\n",
      "[SGD | lr=0.001] Epoch 3987/4000: train_loss=1.8212  test_loss=2.1708  λ_max=15.0559\n",
      "[SGD | lr=0.001] Iter 63800: loss=1.8246\n",
      "[SGD | lr=0.001] Epoch 3988/4000: train_loss=1.8207  test_loss=2.1707  λ_max=15.5979\n",
      "[SGD | lr=0.001] Epoch 3989/4000: train_loss=1.8206  test_loss=2.1707  λ_max=15.4557\n",
      "[SGD | lr=0.001] Epoch 3990/4000: train_loss=1.8203  test_loss=2.1707  λ_max=15.2940\n",
      "[SGD | lr=0.001] Epoch 3991/4000: train_loss=1.8203  test_loss=2.1706  λ_max=15.3322\n",
      "[SGD | lr=0.001] Epoch 3992/4000: train_loss=1.8203  test_loss=2.1706  λ_max=14.7630\n",
      "[SGD | lr=0.001] Epoch 3993/4000: train_loss=1.8202  test_loss=2.1706  λ_max=15.6530\n",
      "[SGD | lr=0.001] Iter 63900: loss=1.8254\n",
      "[SGD | lr=0.001] Epoch 3994/4000: train_loss=1.8199  test_loss=2.1706  λ_max=15.6904\n",
      "[SGD | lr=0.001] Epoch 3995/4000: train_loss=1.8199  test_loss=2.1705  λ_max=14.9764\n",
      "[SGD | lr=0.001] Epoch 3996/4000: train_loss=1.8198  test_loss=2.1705  λ_max=14.4741\n",
      "[SGD | lr=0.001] Epoch 3997/4000: train_loss=1.8196  test_loss=2.1705  λ_max=15.4396\n",
      "[SGD | lr=0.001] Epoch 3998/4000: train_loss=1.8195  test_loss=2.1705  λ_max=15.3847\n",
      "[SGD | lr=0.001] Epoch 3999/4000: train_loss=1.8193  test_loss=2.1705  λ_max=15.2182\n",
      "[SGD | lr=0.001] Iter 64000: loss=1.8193\n",
      "[SGD | lr=0.001] Epoch 4000/4000: train_loss=1.8192  test_loss=2.1704  λ_max=15.8449\n",
      "Saved data → results/SGD_lr0.001.npz\n",
      "Saved plot → results/SGD_lr0.001_sharpness.png\n",
      "Saved combined plot → results/SGD_combined_sharpness.png\n",
      "\n",
      "### Running Adam with lr=0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (/home/aradilla/.cache/huggingface/datasets/sapientinc___csv/sapientinc--sudoku-extreme-798989c95bd556dd/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n",
      "Found cached dataset csv (/home/aradilla/.cache/huggingface/datasets/sapientinc___csv/sapientinc--sudoku-extreme-798989c95bd556dd/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Adam | lr=0.1] Epoch 1/4000: train_loss=18.9806  test_loss=10.8910  λ_max=9.1692\n",
      "[Adam | lr=0.1] Epoch 2/4000: train_loss=6.0996  test_loss=3.3791  λ_max=45.2610\n",
      "[Adam | lr=0.1] Epoch 3/4000: train_loss=3.2113  test_loss=2.4452  λ_max=40.8970\n",
      "[Adam | lr=0.1] Epoch 4/4000: train_loss=2.7145  test_loss=2.2639  λ_max=48.3098\n",
      "[Adam | lr=0.1] Epoch 5/4000: train_loss=2.3194  test_loss=2.2902  λ_max=38.5606\n",
      "[Adam | lr=0.1] Epoch 6/4000: train_loss=2.2421  test_loss=2.2353  λ_max=70.3400\n",
      "[Adam | lr=0.1] Iter 100: loss=2.2374\n",
      "[Adam | lr=0.1] Epoch 7/4000: train_loss=2.2190  test_loss=2.2238  λ_max=61.5477\n",
      "[Adam | lr=0.1] Epoch 8/4000: train_loss=2.2076  test_loss=2.2054  λ_max=61.3692\n",
      "[Adam | lr=0.1] Epoch 9/4000: train_loss=2.2010  test_loss=2.1996  λ_max=54.7191\n",
      "[Adam | lr=0.1] Epoch 10/4000: train_loss=2.1997  test_loss=2.2060  λ_max=48.9371\n",
      "[Adam | lr=0.1] Epoch 11/4000: train_loss=2.2041  test_loss=2.2111  λ_max=47.7152\n",
      "[Adam | lr=0.1] Epoch 12/4000: train_loss=2.2032  test_loss=2.2012  λ_max=52.9275\n",
      "[Adam | lr=0.1] Iter 200: loss=2.2014\n",
      "[Adam | lr=0.1] Epoch 13/4000: train_loss=2.2006  test_loss=2.2023  λ_max=59.5737\n",
      "[Adam | lr=0.1] Epoch 14/4000: train_loss=2.2098  test_loss=2.2006  λ_max=56.0649\n",
      "[Adam | lr=0.1] Epoch 15/4000: train_loss=2.2152  test_loss=2.2487  λ_max=36.9267\n",
      "[Adam | lr=0.1] Epoch 16/4000: train_loss=2.2208  test_loss=2.2206  λ_max=42.1292\n",
      "[Adam | lr=0.1] Epoch 17/4000: train_loss=2.2107  test_loss=2.2947  λ_max=30.9620\n",
      "[Adam | lr=0.1] Epoch 18/4000: train_loss=2.2246  test_loss=2.2269  λ_max=60.1621\n",
      "[Adam | lr=0.1] Iter 300: loss=2.2225\n",
      "[Adam | lr=0.1] Epoch 19/4000: train_loss=2.2167  test_loss=2.2380  λ_max=52.5383\n",
      "[Adam | lr=0.1] Epoch 20/4000: train_loss=2.2129  test_loss=2.2023  λ_max=49.1850\n",
      "[Adam | lr=0.1] Epoch 21/4000: train_loss=2.2170  test_loss=2.2218  λ_max=50.8052\n",
      "[Adam | lr=0.1] Epoch 22/4000: train_loss=2.2060  test_loss=2.2018  λ_max=49.3709\n",
      "[Adam | lr=0.1] Epoch 23/4000: train_loss=2.2077  test_loss=2.2014  λ_max=45.8560\n",
      "[Adam | lr=0.1] Epoch 24/4000: train_loss=2.2189  test_loss=2.2011  λ_max=43.1401\n",
      "[Adam | lr=0.1] Iter 400: loss=2.2061\n",
      "[Adam | lr=0.1] Epoch 25/4000: train_loss=2.2183  test_loss=2.2060  λ_max=45.2473\n",
      "[Adam | lr=0.1] Epoch 26/4000: train_loss=2.2102  test_loss=2.2409  λ_max=47.2173\n",
      "[Adam | lr=0.1] Epoch 27/4000: train_loss=2.2314  test_loss=2.2422  λ_max=30.3260\n",
      "[Adam | lr=0.1] Epoch 28/4000: train_loss=2.2108  test_loss=2.2025  λ_max=37.6786\n",
      "[Adam | lr=0.1] Epoch 29/4000: train_loss=2.2022  test_loss=2.2055  λ_max=35.2616\n",
      "[Adam | lr=0.1] Epoch 30/4000: train_loss=2.2005  test_loss=2.2052  λ_max=34.7548\n",
      "[Adam | lr=0.1] Epoch 31/4000: train_loss=2.2054  test_loss=2.1995  λ_max=37.8327\n",
      "[Adam | lr=0.1] Iter 500: loss=2.1982\n",
      "[Adam | lr=0.1] Epoch 32/4000: train_loss=2.2016  test_loss=2.2467  λ_max=38.5066\n",
      "[Adam | lr=0.1] Epoch 33/4000: train_loss=2.2168  test_loss=2.2296  λ_max=27.5599\n",
      "[Adam | lr=0.1] Epoch 34/4000: train_loss=2.2111  test_loss=2.2038  λ_max=35.1152\n",
      "[Adam | lr=0.1] Epoch 35/4000: train_loss=2.2020  test_loss=2.2257  λ_max=27.4614\n",
      "[Adam | lr=0.1] Epoch 36/4000: train_loss=2.2066  test_loss=2.2013  λ_max=32.8215\n",
      "[Adam | lr=0.1] Epoch 37/4000: train_loss=2.2005  test_loss=2.2078  λ_max=36.0589\n",
      "[Adam | lr=0.1] Iter 600: loss=2.2009\n",
      "[Adam | lr=0.1] Epoch 38/4000: train_loss=2.1992  test_loss=2.2039  λ_max=31.4132\n",
      "[Adam | lr=0.1] Epoch 39/4000: train_loss=2.2059  test_loss=2.2180  λ_max=35.8810\n",
      "[Adam | lr=0.1] Epoch 40/4000: train_loss=2.2065  test_loss=2.2165  λ_max=32.9380\n",
      "[Adam | lr=0.1] Epoch 41/4000: train_loss=2.2032  test_loss=2.2025  λ_max=30.4229\n",
      "[Adam | lr=0.1] Epoch 42/4000: train_loss=2.1960  test_loss=2.2000  λ_max=28.4891\n",
      "[Adam | lr=0.1] Epoch 43/4000: train_loss=2.1966  test_loss=2.2046  λ_max=28.4097\n",
      "[Adam | lr=0.1] Iter 700: loss=2.1949\n",
      "[Adam | lr=0.1] Epoch 44/4000: train_loss=2.1988  test_loss=2.2079  λ_max=26.4126\n",
      "[Adam | lr=0.1] Epoch 45/4000: train_loss=2.1993  test_loss=2.2009  λ_max=27.7122\n",
      "[Adam | lr=0.1] Epoch 46/4000: train_loss=2.1992  test_loss=2.2026  λ_max=27.4995\n",
      "[Adam | lr=0.1] Epoch 47/4000: train_loss=2.1948  test_loss=2.2062  λ_max=26.9770\n",
      "[Adam | lr=0.1] Epoch 48/4000: train_loss=2.2028  test_loss=2.2089  λ_max=28.0433\n",
      "[Adam | lr=0.1] Epoch 49/4000: train_loss=2.1944  test_loss=2.2071  λ_max=27.5788\n",
      "[Adam | lr=0.1] Iter 800: loss=2.2024\n",
      "[Adam | lr=0.1] Epoch 50/4000: train_loss=2.1936  test_loss=2.2078  λ_max=26.0465\n",
      "[Adam | lr=0.1] Epoch 51/4000: train_loss=2.1993  test_loss=2.2070  λ_max=24.0295\n",
      "[Adam | lr=0.1] Epoch 52/4000: train_loss=2.1978  test_loss=2.2224  λ_max=25.4924\n",
      "[Adam | lr=0.1] Epoch 53/4000: train_loss=2.1986  test_loss=2.2161  λ_max=21.8414\n",
      "[Adam | lr=0.1] Epoch 54/4000: train_loss=2.1899  test_loss=2.2056  λ_max=23.5889\n",
      "[Adam | lr=0.1] Epoch 55/4000: train_loss=2.1933  test_loss=2.2274  λ_max=19.9444\n",
      "[Adam | lr=0.1] Epoch 56/4000: train_loss=2.1919  test_loss=2.2100  λ_max=22.8982\n",
      "[Adam | lr=0.1] Iter 900: loss=2.1832\n",
      "[Adam | lr=0.1] Epoch 57/4000: train_loss=2.1878  test_loss=2.2200  λ_max=19.0551\n",
      "[Adam | lr=0.1] Epoch 58/4000: train_loss=2.1837  test_loss=2.1995  λ_max=21.3373\n",
      "[Adam | lr=0.1] Epoch 59/4000: train_loss=2.1842  test_loss=2.2214  λ_max=22.4771\n",
      "[Adam | lr=0.1] Epoch 60/4000: train_loss=2.1818  test_loss=2.2031  λ_max=19.7248\n",
      "[Adam | lr=0.1] Epoch 61/4000: train_loss=2.1688  test_loss=2.2014  λ_max=19.7969\n",
      "[Adam | lr=0.1] Epoch 62/4000: train_loss=2.1655  test_loss=2.2018  λ_max=19.0796\n",
      "[Adam | lr=0.1] Iter 1000: loss=2.1584\n",
      "[Adam | lr=0.1] Epoch 63/4000: train_loss=2.1608  test_loss=2.1988  λ_max=18.7455\n",
      "[Adam | lr=0.1] Epoch 64/4000: train_loss=2.1541  test_loss=2.2004  λ_max=18.3889\n",
      "[Adam | lr=0.1] Epoch 65/4000: train_loss=2.1478  test_loss=2.1984  λ_max=18.3724\n",
      "[Adam | lr=0.1] Epoch 66/4000: train_loss=2.1443  test_loss=2.2043  λ_max=18.7405\n",
      "[Adam | lr=0.1] Epoch 67/4000: train_loss=2.1403  test_loss=2.1983  λ_max=18.6673\n",
      "[Adam | lr=0.1] Epoch 68/4000: train_loss=2.1353  test_loss=2.2145  λ_max=17.4769\n",
      "[Adam | lr=0.1] Iter 1100: loss=2.1280\n",
      "[Adam | lr=0.1] Epoch 69/4000: train_loss=2.1296  test_loss=2.2024  λ_max=17.4483\n",
      "[Adam | lr=0.1] Epoch 70/4000: train_loss=2.1214  test_loss=2.1977  λ_max=17.4336\n",
      "[Adam | lr=0.1] Epoch 71/4000: train_loss=2.1100  test_loss=2.1987  λ_max=16.4289\n",
      "[Adam | lr=0.1] Epoch 72/4000: train_loss=2.1031  test_loss=2.2013  λ_max=17.1180\n",
      "[Adam | lr=0.1] Epoch 73/4000: train_loss=2.0909  test_loss=2.2006  λ_max=16.0136\n",
      "[Adam | lr=0.1] Epoch 74/4000: train_loss=2.0817  test_loss=2.2015  λ_max=15.6784\n",
      "[Adam | lr=0.1] Iter 1200: loss=2.0787\n",
      "[Adam | lr=0.1] Epoch 75/4000: train_loss=2.0650  test_loss=2.2055  λ_max=15.7700\n",
      "[Adam | lr=0.1] Epoch 76/4000: train_loss=2.0574  test_loss=2.1991  λ_max=15.9611\n",
      "[Adam | lr=0.1] Epoch 77/4000: train_loss=2.0407  test_loss=2.2063  λ_max=14.8479\n",
      "[Adam | lr=0.1] Epoch 78/4000: train_loss=2.0313  test_loss=2.2078  λ_max=15.0111\n",
      "[Adam | lr=0.1] Epoch 79/4000: train_loss=2.0199  test_loss=2.2007  λ_max=14.6185\n",
      "[Adam | lr=0.1] Epoch 80/4000: train_loss=2.0052  test_loss=2.2061  λ_max=14.4873\n",
      "[Adam | lr=0.1] Epoch 81/4000: train_loss=1.9934  test_loss=2.2124  λ_max=14.0736\n",
      "[Adam | lr=0.1] Iter 1300: loss=1.9681\n",
      "[Adam | lr=0.1] Epoch 82/4000: train_loss=1.9815  test_loss=2.2051  λ_max=13.6863\n",
      "[Adam | lr=0.1] Epoch 83/4000: train_loss=1.9701  test_loss=2.2094  λ_max=13.8248\n",
      "[Adam | lr=0.1] Epoch 84/4000: train_loss=1.9558  test_loss=2.2110  λ_max=13.9525\n",
      "[Adam | lr=0.1] Epoch 85/4000: train_loss=1.9412  test_loss=2.2103  λ_max=13.5396\n",
      "[Adam | lr=0.1] Epoch 86/4000: train_loss=1.9276  test_loss=2.2134  λ_max=13.6677\n",
      "[Adam | lr=0.1] Epoch 87/4000: train_loss=1.9143  test_loss=2.2124  λ_max=12.9048\n",
      "[Adam | lr=0.1] Iter 1400: loss=1.8850\n",
      "[Adam | lr=0.1] Epoch 88/4000: train_loss=1.8985  test_loss=2.2081  λ_max=12.8073\n",
      "[Adam | lr=0.1] Epoch 89/4000: train_loss=1.8845  test_loss=2.2116  λ_max=12.5381\n",
      "[Adam | lr=0.1] Epoch 90/4000: train_loss=1.8684  test_loss=2.2032  λ_max=12.3090\n",
      "[Adam | lr=0.1] Epoch 91/4000: train_loss=1.8508  test_loss=2.2155  λ_max=12.1719\n",
      "[Adam | lr=0.1] Epoch 92/4000: train_loss=1.8309  test_loss=2.2206  λ_max=12.4192\n",
      "[Adam | lr=0.1] Epoch 93/4000: train_loss=1.8132  test_loss=2.2192  λ_max=11.7428\n",
      "[Adam | lr=0.1] Iter 1500: loss=1.8153\n",
      "[Adam | lr=0.1] Epoch 94/4000: train_loss=1.7950  test_loss=2.2239  λ_max=12.1041\n",
      "[Adam | lr=0.1] Epoch 95/4000: train_loss=1.7726  test_loss=2.2244  λ_max=11.8414\n",
      "[Adam | lr=0.1] Epoch 96/4000: train_loss=1.7496  test_loss=2.2497  λ_max=11.3256\n",
      "[Adam | lr=0.1] Epoch 97/4000: train_loss=1.7264  test_loss=2.2371  λ_max=11.5100\n",
      "[Adam | lr=0.1] Epoch 98/4000: train_loss=1.7016  test_loss=2.2441  λ_max=11.0209\n",
      "[Adam | lr=0.1] Epoch 99/4000: train_loss=1.6837  test_loss=2.2726  λ_max=10.4945\n",
      "[Adam | lr=0.1] Iter 1600: loss=1.7018\n",
      "[Adam | lr=0.1] Epoch 100/4000: train_loss=1.6623  test_loss=2.2760  λ_max=10.3667\n",
      "[Adam | lr=0.1] Epoch 101/4000: train_loss=1.6348  test_loss=2.2941  λ_max=10.1544\n",
      "[Adam | lr=0.1] Epoch 102/4000: train_loss=1.6093  test_loss=2.3056  λ_max=9.7829\n",
      "[Adam | lr=0.1] Epoch 103/4000: train_loss=1.5825  test_loss=2.3095  λ_max=9.7527\n",
      "[Adam | lr=0.1] Epoch 104/4000: train_loss=1.5577  test_loss=2.3252  λ_max=9.6751\n",
      "[Adam | lr=0.1] Epoch 105/4000: train_loss=1.5334  test_loss=2.3366  λ_max=9.3027\n",
      "[Adam | lr=0.1] Epoch 106/4000: train_loss=1.5059  test_loss=2.3510  λ_max=9.0258\n",
      "[Adam | lr=0.1] Iter 1700: loss=1.4244\n",
      "[Adam | lr=0.1] Epoch 107/4000: train_loss=1.4772  test_loss=2.3711  λ_max=8.6526\n",
      "[Adam | lr=0.1] Epoch 108/4000: train_loss=1.4476  test_loss=2.3980  λ_max=8.4132\n",
      "[Adam | lr=0.1] Epoch 109/4000: train_loss=1.4216  test_loss=2.4026  λ_max=8.4367\n",
      "[Adam | lr=0.1] Epoch 110/4000: train_loss=1.3944  test_loss=2.4590  λ_max=8.0829\n",
      "[Adam | lr=0.1] Epoch 111/4000: train_loss=1.3669  test_loss=2.5011  λ_max=8.0840\n",
      "[Adam | lr=0.1] Epoch 112/4000: train_loss=1.3346  test_loss=2.5367  λ_max=7.8388\n",
      "[Adam | lr=0.1] Iter 1800: loss=1.2903\n",
      "[Adam | lr=0.1] Epoch 113/4000: train_loss=1.3058  test_loss=2.5404  λ_max=7.5121\n",
      "[Adam | lr=0.1] Epoch 114/4000: train_loss=1.2731  test_loss=2.5702  λ_max=7.2554\n",
      "[Adam | lr=0.1] Epoch 115/4000: train_loss=1.2430  test_loss=2.6341  λ_max=7.0049\n",
      "[Adam | lr=0.1] Epoch 116/4000: train_loss=1.2133  test_loss=2.6478  λ_max=6.7434\n",
      "[Adam | lr=0.1] Epoch 117/4000: train_loss=1.1880  test_loss=2.7254  λ_max=6.4155\n",
      "[Adam | lr=0.1] Epoch 118/4000: train_loss=1.1576  test_loss=2.7285  λ_max=6.3295\n",
      "[Adam | lr=0.1] Iter 1900: loss=1.2032\n",
      "[Adam | lr=0.1] Epoch 119/4000: train_loss=1.1323  test_loss=2.7990  λ_max=6.2019\n",
      "[Adam | lr=0.1] Epoch 120/4000: train_loss=1.1034  test_loss=2.8439  λ_max=6.1253\n",
      "[Adam | lr=0.1] Epoch 121/4000: train_loss=1.0762  test_loss=2.8651  λ_max=5.8557\n",
      "[Adam | lr=0.1] Epoch 122/4000: train_loss=1.0470  test_loss=3.0452  λ_max=5.4448\n",
      "[Adam | lr=0.1] Epoch 123/4000: train_loss=1.0212  test_loss=3.0278  λ_max=5.3943\n",
      "[Adam | lr=0.1] Epoch 124/4000: train_loss=0.9940  test_loss=3.1242  λ_max=5.3231\n",
      "[Adam | lr=0.1] Iter 2000: loss=1.1069\n",
      "[Adam | lr=0.1] Epoch 125/4000: train_loss=0.9694  test_loss=3.1811  λ_max=5.1288\n",
      "[Adam | lr=0.1] Epoch 126/4000: train_loss=0.9382  test_loss=3.2391  λ_max=5.0120\n",
      "[Adam | lr=0.1] Epoch 127/4000: train_loss=0.9129  test_loss=3.3503  λ_max=4.7105\n",
      "[Adam | lr=0.1] Epoch 128/4000: train_loss=0.8925  test_loss=3.3327  λ_max=4.7103\n",
      "[Adam | lr=0.1] Epoch 129/4000: train_loss=0.8693  test_loss=3.5215  λ_max=4.3962\n",
      "[Adam | lr=0.1] Epoch 130/4000: train_loss=0.8353  test_loss=3.6810  λ_max=4.2387\n",
      "[Adam | lr=0.1] Epoch 131/4000: train_loss=0.8083  test_loss=3.7232  λ_max=4.0670\n",
      "[Adam | lr=0.1] Iter 2100: loss=0.6738\n",
      "[Adam | lr=0.1] Epoch 132/4000: train_loss=0.7811  test_loss=3.8246  λ_max=3.9595\n",
      "[Adam | lr=0.1] Epoch 133/4000: train_loss=0.7628  test_loss=3.8534  λ_max=3.8190\n",
      "[Adam | lr=0.1] Epoch 134/4000: train_loss=0.7473  test_loss=3.9450  λ_max=3.7741\n",
      "[Adam | lr=0.1] Epoch 135/4000: train_loss=0.7167  test_loss=4.0467  λ_max=3.7495\n",
      "[Adam | lr=0.1] Epoch 136/4000: train_loss=0.6852  test_loss=4.3257  λ_max=3.3447\n",
      "[Adam | lr=0.1] Epoch 137/4000: train_loss=0.6642  test_loss=4.4316  λ_max=3.3954\n",
      "[Adam | lr=0.1] Iter 2200: loss=0.6406\n",
      "[Adam | lr=0.1] Epoch 138/4000: train_loss=0.6536  test_loss=4.5218  λ_max=3.2277\n",
      "[Adam | lr=0.1] Epoch 139/4000: train_loss=0.6390  test_loss=4.6160  λ_max=2.8720\n",
      "[Adam | lr=0.1] Epoch 140/4000: train_loss=0.6193  test_loss=4.7741  λ_max=3.0852\n",
      "[Adam | lr=0.1] Epoch 141/4000: train_loss=0.6005  test_loss=4.8731  λ_max=3.1005\n",
      "[Adam | lr=0.1] Epoch 142/4000: train_loss=0.5667  test_loss=4.9601  λ_max=2.9951\n",
      "[Adam | lr=0.1] Epoch 143/4000: train_loss=0.5495  test_loss=5.1819  λ_max=2.9106\n",
      "[Adam | lr=0.1] Iter 2300: loss=0.5926\n",
      "[Adam | lr=0.1] Epoch 144/4000: train_loss=0.5375  test_loss=5.4438  λ_max=2.7307\n",
      "[Adam | lr=0.1] Epoch 145/4000: train_loss=0.5224  test_loss=5.5508  λ_max=2.8421\n",
      "[Adam | lr=0.1] Epoch 146/4000: train_loss=0.5092  test_loss=5.5424  λ_max=2.9263\n",
      "[Adam | lr=0.1] Epoch 147/4000: train_loss=0.4845  test_loss=5.7031  λ_max=2.8122\n",
      "[Adam | lr=0.1] Epoch 148/4000: train_loss=0.4625  test_loss=5.8595  λ_max=2.5167\n",
      "[Adam | lr=0.1] Epoch 149/4000: train_loss=0.4497  test_loss=6.0069  λ_max=2.7809\n",
      "[Adam | lr=0.1] Iter 2400: loss=0.5440\n",
      "[Adam | lr=0.1] Epoch 150/4000: train_loss=0.4337  test_loss=6.3236  λ_max=2.5650\n",
      "[Adam | lr=0.1] Epoch 151/4000: train_loss=0.4023  test_loss=6.5431  λ_max=2.7840\n",
      "[Adam | lr=0.1] Epoch 152/4000: train_loss=0.3900  test_loss=6.7327  λ_max=2.7173\n",
      "[Adam | lr=0.1] Epoch 153/4000: train_loss=0.3818  test_loss=6.8407  λ_max=2.6469\n",
      "[Adam | lr=0.1] Epoch 154/4000: train_loss=0.3696  test_loss=7.0284  λ_max=2.5012\n",
      "[Adam | lr=0.1] Epoch 155/4000: train_loss=0.3584  test_loss=7.1624  λ_max=2.6306\n",
      "[Adam | lr=0.1] Epoch 156/4000: train_loss=0.3395  test_loss=7.4232  λ_max=2.7208\n",
      "[Adam | lr=0.1] Iter 2500: loss=0.2781\n",
      "[Adam | lr=0.1] Epoch 157/4000: train_loss=0.3210  test_loss=7.6734  λ_max=2.3462\n",
      "[Adam | lr=0.1] Epoch 158/4000: train_loss=0.3179  test_loss=7.7661  λ_max=2.7308\n",
      "[Adam | lr=0.1] Epoch 159/4000: train_loss=0.3207  test_loss=7.8153  λ_max=2.9801\n",
      "[Adam | lr=0.1] Epoch 160/4000: train_loss=0.3138  test_loss=7.9274  λ_max=2.6403\n",
      "[Adam | lr=0.1] Epoch 161/4000: train_loss=0.3004  test_loss=8.2272  λ_max=2.8882\n",
      "[Adam | lr=0.1] Epoch 162/4000: train_loss=0.2893  test_loss=8.3132  λ_max=2.8686\n",
      "[Adam | lr=0.1] Iter 2600: loss=0.2765\n",
      "[Adam | lr=0.1] Epoch 163/4000: train_loss=0.2795  test_loss=8.6271  λ_max=2.6966\n",
      "[Adam | lr=0.1] Epoch 164/4000: train_loss=0.2783  test_loss=8.6773  λ_max=2.6149\n",
      "[Adam | lr=0.1] Epoch 165/4000: train_loss=0.2695  test_loss=8.8747  λ_max=2.5692\n",
      "[Adam | lr=0.1] Epoch 166/4000: train_loss=0.2556  test_loss=8.9689  λ_max=2.5374\n",
      "[Adam | lr=0.1] Epoch 167/4000: train_loss=0.2438  test_loss=9.3976  λ_max=2.7295\n",
      "[Adam | lr=0.1] Epoch 168/4000: train_loss=0.2254  test_loss=9.6110  λ_max=2.5970\n",
      "[Adam | lr=0.1] Iter 2700: loss=0.2420\n",
      "[Adam | lr=0.1] Epoch 169/4000: train_loss=0.2157  test_loss=9.7572  λ_max=2.6476\n",
      "[Adam | lr=0.1] Epoch 170/4000: train_loss=0.2036  test_loss=9.9073  λ_max=2.6894\n",
      "[Adam | lr=0.1] Epoch 171/4000: train_loss=0.1926  test_loss=10.2950  λ_max=2.5171\n",
      "[Adam | lr=0.1] Epoch 172/4000: train_loss=0.1953  test_loss=10.3707  λ_max=2.5916\n",
      "[Adam | lr=0.1] Epoch 173/4000: train_loss=0.2033  test_loss=10.7809  λ_max=2.5017\n",
      "[Adam | lr=0.1] Epoch 174/4000: train_loss=0.2103  test_loss=10.6168  λ_max=2.5629\n",
      "[Adam | lr=0.1] Iter 2800: loss=0.2772\n",
      "[Adam | lr=0.1] Epoch 175/4000: train_loss=0.2146  test_loss=10.6435  λ_max=2.5015\n",
      "[Adam | lr=0.1] Epoch 176/4000: train_loss=0.2181  test_loss=10.7339  λ_max=2.2477\n",
      "[Adam | lr=0.1] Epoch 177/4000: train_loss=0.2090  test_loss=10.8990  λ_max=2.7147\n",
      "[Adam | lr=0.1] Epoch 178/4000: train_loss=0.1929  test_loss=10.9646  λ_max=2.7469\n",
      "[Adam | lr=0.1] Epoch 179/4000: train_loss=0.1812  test_loss=11.1109  λ_max=2.9419\n",
      "[Adam | lr=0.1] Epoch 180/4000: train_loss=0.1645  test_loss=11.4846  λ_max=2.6784\n",
      "[Adam | lr=0.1] Epoch 181/4000: train_loss=0.1458  test_loss=11.6952  λ_max=2.7216\n",
      "[Adam | lr=0.1] Iter 2900: loss=0.1135\n",
      "[Adam | lr=0.1] Epoch 182/4000: train_loss=0.1401  test_loss=11.9861  λ_max=2.4426\n",
      "[Adam | lr=0.1] Epoch 183/4000: train_loss=0.1330  test_loss=12.5414  λ_max=2.4738\n",
      "[Adam | lr=0.1] Epoch 184/4000: train_loss=0.1252  test_loss=12.6946  λ_max=2.4748\n",
      "[Adam | lr=0.1] Epoch 185/4000: train_loss=0.1237  test_loss=12.9164  λ_max=2.2350\n",
      "[Adam | lr=0.1] Epoch 186/4000: train_loss=0.1309  test_loss=13.2255  λ_max=2.2278\n",
      "[Adam | lr=0.1] Epoch 187/4000: train_loss=0.1428  test_loss=13.0430  λ_max=2.5418\n",
      "[Adam | lr=0.1] Iter 3000: loss=0.1361\n",
      "[Adam | lr=0.1] Epoch 188/4000: train_loss=0.1511  test_loss=13.0477  λ_max=2.0052\n",
      "[Adam | lr=0.1] Epoch 189/4000: train_loss=0.1641  test_loss=13.2561  λ_max=2.5059\n",
      "[Adam | lr=0.1] Epoch 190/4000: train_loss=0.1670  test_loss=13.2011  λ_max=2.6659\n",
      "[Adam | lr=0.1] Epoch 191/4000: train_loss=0.1813  test_loss=13.0134  λ_max=2.5616\n",
      "[Adam | lr=0.1] Epoch 192/4000: train_loss=0.1947  test_loss=12.8823  λ_max=2.8073\n",
      "[Adam | lr=0.1] Epoch 193/4000: train_loss=0.1941  test_loss=12.8055  λ_max=2.7077\n",
      "[Adam | lr=0.1] Iter 3100: loss=0.2128\n",
      "[Adam | lr=0.1] Epoch 194/4000: train_loss=0.1741  test_loss=12.7250  λ_max=2.8931\n",
      "[Adam | lr=0.1] Epoch 195/4000: train_loss=0.1475  test_loss=12.9005  λ_max=2.3646\n",
      "[Adam | lr=0.1] Epoch 196/4000: train_loss=0.1246  test_loss=13.0679  λ_max=2.9435\n",
      "[Adam | lr=0.1] Epoch 197/4000: train_loss=0.1039  test_loss=13.6291  λ_max=2.6388\n",
      "[Adam | lr=0.1] Epoch 198/4000: train_loss=0.0857  test_loss=13.7686  λ_max=2.6137\n",
      "[Adam | lr=0.1] Epoch 199/4000: train_loss=0.0730  test_loss=14.5748  λ_max=2.7603\n",
      "[Adam | lr=0.1] Iter 3200: loss=0.0961\n",
      "[Adam | lr=0.1] Epoch 200/4000: train_loss=0.0616  test_loss=14.7219  λ_max=2.4936\n",
      "[Adam | lr=0.1] Epoch 201/4000: train_loss=0.0554  test_loss=15.1407  λ_max=2.4549\n",
      "[Adam | lr=0.1] Epoch 202/4000: train_loss=0.0524  test_loss=15.4217  λ_max=2.3497\n",
      "[Adam | lr=0.1] Epoch 203/4000: train_loss=0.0549  test_loss=16.0871  λ_max=2.0686\n",
      "[Adam | lr=0.1] Epoch 204/4000: train_loss=0.0606  test_loss=16.5319  λ_max=2.2889\n",
      "[Adam | lr=0.1] Epoch 205/4000: train_loss=0.0715  test_loss=16.3458  λ_max=2.4137\n",
      "[Adam | lr=0.1] Epoch 206/4000: train_loss=0.0911  test_loss=16.3213  λ_max=2.3368\n",
      "[Adam | lr=0.1] Iter 3300: loss=0.0837\n",
      "[Adam | lr=0.1] Epoch 207/4000: train_loss=0.1185  test_loss=16.2511  λ_max=2.1304\n",
      "[Adam | lr=0.1] Epoch 208/4000: train_loss=0.1687  test_loss=15.8672  λ_max=2.4588\n",
      "[Adam | lr=0.1] Epoch 209/4000: train_loss=0.2192  test_loss=15.2045  λ_max=2.6442\n",
      "[Adam | lr=0.1] Epoch 210/4000: train_loss=0.2539  test_loss=14.4421  λ_max=3.2190\n",
      "[Adam | lr=0.1] Epoch 211/4000: train_loss=0.2682  test_loss=13.7327  λ_max=3.1296\n",
      "[Adam | lr=0.1] Epoch 212/4000: train_loss=0.2344  test_loss=13.2568  λ_max=3.1943\n",
      "[Adam | lr=0.1] Iter 3400: loss=0.1735\n",
      "[Adam | lr=0.1] Epoch 213/4000: train_loss=0.1842  test_loss=13.3947  λ_max=3.3216\n",
      "[Adam | lr=0.1] Epoch 214/4000: train_loss=0.1446  test_loss=13.6773  λ_max=3.4092\n",
      "[Adam | lr=0.1] Epoch 215/4000: train_loss=0.1086  test_loss=14.2090  λ_max=3.2183\n",
      "[Adam | lr=0.1] Epoch 216/4000: train_loss=0.0763  test_loss=15.0719  λ_max=3.1617\n",
      "[Adam | lr=0.1] Epoch 217/4000: train_loss=0.0572  test_loss=15.3546  λ_max=2.9453\n",
      "[Adam | lr=0.1] Epoch 218/4000: train_loss=0.0422  test_loss=15.8119  λ_max=2.8220\n",
      "[Adam | lr=0.1] Iter 3500: loss=0.0346\n",
      "[Adam | lr=0.1] Epoch 219/4000: train_loss=0.0321  test_loss=16.2515  λ_max=2.7029\n",
      "[Adam | lr=0.1] Epoch 220/4000: train_loss=0.0236  test_loss=16.8582  λ_max=2.7737\n",
      "[Adam | lr=0.1] Epoch 221/4000: train_loss=0.0170  test_loss=17.2253  λ_max=2.6138\n",
      "[Adam | lr=0.1] Epoch 222/4000: train_loss=0.0117  test_loss=17.7778  λ_max=2.2321\n",
      "[Adam | lr=0.1] Epoch 223/4000: train_loss=0.0076  test_loss=18.1320  λ_max=2.4339\n",
      "[Adam | lr=0.1] Epoch 224/4000: train_loss=0.0044  test_loss=18.4170  λ_max=2.4722\n",
      "[Adam | lr=0.1] Iter 3600: loss=0.0023\n",
      "[Adam | lr=0.1] Epoch 225/4000: train_loss=0.0022  test_loss=18.6194  λ_max=2.3630\n",
      "[Adam | lr=0.1] Epoch 226/4000: train_loss=0.0011  test_loss=18.8788  λ_max=2.2966\n",
      "[Adam | lr=0.1] Epoch 227/4000: train_loss=0.0007  test_loss=18.9836  λ_max=2.2921\n",
      "[Adam | lr=0.1] Epoch 228/4000: train_loss=0.0006  test_loss=19.0916  λ_max=2.2504\n",
      "[Adam | lr=0.1] Epoch 229/4000: train_loss=0.0004  test_loss=19.2265  λ_max=2.2727\n",
      "[Adam | lr=0.1] Epoch 230/4000: train_loss=0.0003  test_loss=19.3657  λ_max=2.1300\n",
      "[Adam | lr=0.1] Epoch 231/4000: train_loss=0.0003  test_loss=19.4347  λ_max=2.1373\n",
      "[Adam | lr=0.1] Iter 3700: loss=0.0003\n",
      "[Adam | lr=0.1] Epoch 232/4000: train_loss=0.0002  test_loss=19.4864  λ_max=2.0678\n",
      "[Adam | lr=0.1] Epoch 233/4000: train_loss=0.0002  test_loss=19.5512  λ_max=2.0852\n",
      "[Adam | lr=0.1] Epoch 234/4000: train_loss=0.0002  test_loss=19.6119  λ_max=2.1052\n",
      "[Adam | lr=0.1] Epoch 235/4000: train_loss=0.0002  test_loss=19.6651  λ_max=2.0904\n",
      "[Adam | lr=0.1] Epoch 236/4000: train_loss=0.0002  test_loss=19.7221  λ_max=2.1477\n",
      "[Adam | lr=0.1] Epoch 237/4000: train_loss=0.0002  test_loss=19.7723  λ_max=2.1573\n",
      "[Adam | lr=0.1] Iter 3800: loss=0.0002\n",
      "[Adam | lr=0.1] Epoch 238/4000: train_loss=0.0002  test_loss=19.8191  λ_max=1.8747\n",
      "[Adam | lr=0.1] Epoch 239/4000: train_loss=0.0002  test_loss=19.8668  λ_max=2.0454\n",
      "[Adam | lr=0.1] Epoch 240/4000: train_loss=0.0001  test_loss=19.9100  λ_max=2.1305\n",
      "[Adam | lr=0.1] Epoch 241/4000: train_loss=0.0001  test_loss=19.9549  λ_max=2.1568\n",
      "[Adam | lr=0.1] Epoch 242/4000: train_loss=0.0001  test_loss=19.9994  λ_max=2.1360\n",
      "[Adam | lr=0.1] Epoch 243/4000: train_loss=0.0001  test_loss=20.0378  λ_max=2.1268\n",
      "[Adam | lr=0.1] Iter 3900: loss=0.0001\n",
      "[Adam | lr=0.1] Epoch 244/4000: train_loss=0.0001  test_loss=20.0763  λ_max=2.0164\n",
      "[Adam | lr=0.1] Epoch 245/4000: train_loss=0.0001  test_loss=20.1161  λ_max=1.9239\n",
      "[Adam | lr=0.1] Epoch 246/4000: train_loss=0.0001  test_loss=20.1564  λ_max=2.0920\n",
      "[Adam | lr=0.1] Epoch 247/4000: train_loss=0.0001  test_loss=20.1913  λ_max=1.9009\n",
      "[Adam | lr=0.1] Epoch 248/4000: train_loss=0.0001  test_loss=20.2260  λ_max=1.9925\n",
      "[Adam | lr=0.1] Epoch 249/4000: train_loss=0.0001  test_loss=20.2643  λ_max=1.9548\n",
      "[Adam | lr=0.1] Iter 4000: loss=0.0001\n",
      "[Adam | lr=0.1] Epoch 250/4000: train_loss=0.0001  test_loss=20.2969  λ_max=2.0276\n",
      "[Adam | lr=0.1] Epoch 251/4000: train_loss=0.0001  test_loss=20.3314  λ_max=2.0289\n",
      "[Adam | lr=0.1] Epoch 252/4000: train_loss=0.0001  test_loss=20.3646  λ_max=2.0924\n",
      "[Adam | lr=0.1] Epoch 253/4000: train_loss=0.0001  test_loss=20.3979  λ_max=2.0577\n",
      "[Adam | lr=0.1] Epoch 254/4000: train_loss=0.0001  test_loss=20.4281  λ_max=1.9696\n",
      "[Adam | lr=0.1] Epoch 255/4000: train_loss=0.0001  test_loss=20.4608  λ_max=2.0413\n",
      "[Adam | lr=0.1] Epoch 256/4000: train_loss=0.0001  test_loss=20.4916  λ_max=2.0511\n",
      "[Adam | lr=0.1] Iter 4100: loss=0.0001\n",
      "[Adam | lr=0.1] Epoch 257/4000: train_loss=0.0001  test_loss=20.5221  λ_max=2.0688\n",
      "[Adam | lr=0.1] Epoch 258/4000: train_loss=0.0001  test_loss=20.5518  λ_max=1.9152\n",
      "[Adam | lr=0.1] Epoch 259/4000: train_loss=0.0001  test_loss=20.5810  λ_max=2.0313\n",
      "[Adam | lr=0.1] Epoch 260/4000: train_loss=0.0001  test_loss=20.6109  λ_max=2.0160\n",
      "[Adam | lr=0.1] Epoch 261/4000: train_loss=0.0001  test_loss=20.6394  λ_max=2.0010\n",
      "[Adam | lr=0.1] Epoch 262/4000: train_loss=0.0001  test_loss=20.6680  λ_max=2.0315\n",
      "[Adam | lr=0.1] Iter 4200: loss=0.0001\n",
      "[Adam | lr=0.1] Epoch 263/4000: train_loss=0.0001  test_loss=20.6974  λ_max=2.0457\n",
      "[Adam | lr=0.1] Epoch 264/4000: train_loss=0.0001  test_loss=20.7248  λ_max=1.9064\n",
      "[Adam | lr=0.1] Epoch 265/4000: train_loss=0.0001  test_loss=20.7535  λ_max=1.9731\n",
      "[Adam | lr=0.1] Epoch 266/4000: train_loss=0.0001  test_loss=20.7788  λ_max=1.8871\n",
      "[Adam | lr=0.1] Epoch 267/4000: train_loss=0.0001  test_loss=20.8054  λ_max=2.0153\n",
      "[Adam | lr=0.1] Epoch 268/4000: train_loss=0.0001  test_loss=20.8322  λ_max=1.9735\n",
      "[Adam | lr=0.1] Iter 4300: loss=0.0001\n",
      "[Adam | lr=0.1] Epoch 269/4000: train_loss=0.0001  test_loss=20.8593  λ_max=1.9696\n",
      "[Adam | lr=0.1] Epoch 270/4000: train_loss=0.0001  test_loss=20.8828  λ_max=1.9220\n",
      "[Adam | lr=0.1] Epoch 271/4000: train_loss=0.0001  test_loss=20.9096  λ_max=1.9364\n",
      "[Adam | lr=0.1] Epoch 272/4000: train_loss=0.0001  test_loss=20.9340  λ_max=1.9954\n",
      "[Adam | lr=0.1] Epoch 273/4000: train_loss=0.0001  test_loss=20.9591  λ_max=2.0102\n",
      "[Adam | lr=0.1] Epoch 274/4000: train_loss=0.0001  test_loss=20.9841  λ_max=2.0053\n",
      "[Adam | lr=0.1] Iter 4400: loss=0.0001\n",
      "[Adam | lr=0.1] Epoch 275/4000: train_loss=0.0001  test_loss=21.0099  λ_max=1.9107\n",
      "[Adam | lr=0.1] Epoch 276/4000: train_loss=0.0001  test_loss=21.0336  λ_max=1.9184\n",
      "[Adam | lr=0.1] Epoch 277/4000: train_loss=0.0001  test_loss=21.0566  λ_max=1.9411\n",
      "[Adam | lr=0.1] Epoch 278/4000: train_loss=0.0001  test_loss=21.0812  λ_max=1.8749\n",
      "[Adam | lr=0.1] Epoch 279/4000: train_loss=0.0001  test_loss=21.1055  λ_max=1.9190\n",
      "[Adam | lr=0.1] Epoch 280/4000: train_loss=0.0001  test_loss=21.1293  λ_max=1.9418\n",
      "[Adam | lr=0.1] Epoch 281/4000: train_loss=0.0001  test_loss=21.1526  λ_max=1.8967\n",
      "[Adam | lr=0.1] Iter 4500: loss=0.0001\n",
      "[Adam | lr=0.1] Epoch 282/4000: train_loss=0.0001  test_loss=21.1759  λ_max=1.9044\n",
      "[Adam | lr=0.1] Epoch 283/4000: train_loss=0.0001  test_loss=21.1971  λ_max=1.9421\n",
      "[Adam | lr=0.1] Epoch 284/4000: train_loss=0.0001  test_loss=21.2194  λ_max=1.8065\n",
      "[Adam | lr=0.1] Epoch 285/4000: train_loss=0.0000  test_loss=21.2431  λ_max=1.8581\n",
      "[Adam | lr=0.1] Epoch 286/4000: train_loss=0.0000  test_loss=21.2654  λ_max=1.9663\n",
      "[Adam | lr=0.1] Epoch 287/4000: train_loss=0.0000  test_loss=21.2873  λ_max=1.8662\n",
      "[Adam | lr=0.1] Iter 4600: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 288/4000: train_loss=0.0000  test_loss=21.3094  λ_max=1.9751\n",
      "[Adam | lr=0.1] Epoch 289/4000: train_loss=0.0000  test_loss=21.3315  λ_max=1.9740\n",
      "[Adam | lr=0.1] Epoch 290/4000: train_loss=0.0000  test_loss=21.3518  λ_max=1.7301\n",
      "[Adam | lr=0.1] Epoch 291/4000: train_loss=0.0000  test_loss=21.3738  λ_max=1.9712\n",
      "[Adam | lr=0.1] Epoch 292/4000: train_loss=0.0000  test_loss=21.3947  λ_max=1.8679\n",
      "[Adam | lr=0.1] Epoch 293/4000: train_loss=0.0000  test_loss=21.4169  λ_max=1.9604\n",
      "[Adam | lr=0.1] Iter 4700: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 294/4000: train_loss=0.0000  test_loss=21.4380  λ_max=1.9258\n",
      "[Adam | lr=0.1] Epoch 295/4000: train_loss=0.0000  test_loss=21.4593  λ_max=1.7927\n",
      "[Adam | lr=0.1] Epoch 296/4000: train_loss=0.0000  test_loss=21.4797  λ_max=1.9158\n",
      "[Adam | lr=0.1] Epoch 297/4000: train_loss=0.0000  test_loss=21.5012  λ_max=1.9062\n",
      "[Adam | lr=0.1] Epoch 298/4000: train_loss=0.0000  test_loss=21.5226  λ_max=1.8791\n",
      "[Adam | lr=0.1] Epoch 299/4000: train_loss=0.0000  test_loss=21.5421  λ_max=1.8504\n",
      "[Adam | lr=0.1] Iter 4800: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 300/4000: train_loss=0.0000  test_loss=21.5639  λ_max=1.9686\n",
      "[Adam | lr=0.1] Epoch 301/4000: train_loss=0.0000  test_loss=21.5825  λ_max=1.8399\n",
      "[Adam | lr=0.1] Epoch 302/4000: train_loss=0.0000  test_loss=21.6031  λ_max=1.6844\n",
      "[Adam | lr=0.1] Epoch 303/4000: train_loss=0.0000  test_loss=21.6245  λ_max=1.8852\n",
      "[Adam | lr=0.1] Epoch 304/4000: train_loss=0.0000  test_loss=21.6435  λ_max=1.8358\n",
      "[Adam | lr=0.1] Epoch 305/4000: train_loss=0.0000  test_loss=21.6634  λ_max=1.9127\n",
      "[Adam | lr=0.1] Epoch 306/4000: train_loss=0.0000  test_loss=21.6837  λ_max=1.7763\n",
      "[Adam | lr=0.1] Iter 4900: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 307/4000: train_loss=0.0000  test_loss=21.7038  λ_max=1.8868\n",
      "[Adam | lr=0.1] Epoch 308/4000: train_loss=0.0000  test_loss=21.7225  λ_max=1.8619\n",
      "[Adam | lr=0.1] Epoch 309/4000: train_loss=0.0000  test_loss=21.7421  λ_max=1.8661\n",
      "[Adam | lr=0.1] Epoch 310/4000: train_loss=0.0000  test_loss=21.7618  λ_max=1.8270\n",
      "[Adam | lr=0.1] Epoch 311/4000: train_loss=0.0000  test_loss=21.7819  λ_max=1.9381\n",
      "[Adam | lr=0.1] Epoch 312/4000: train_loss=0.0000  test_loss=21.8007  λ_max=1.8736\n",
      "[Adam | lr=0.1] Iter 5000: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 313/4000: train_loss=0.0000  test_loss=21.8197  λ_max=1.8340\n",
      "[Adam | lr=0.1] Epoch 314/4000: train_loss=0.0000  test_loss=21.8390  λ_max=1.9024\n",
      "[Adam | lr=0.1] Epoch 315/4000: train_loss=0.0000  test_loss=21.8589  λ_max=1.9234\n",
      "[Adam | lr=0.1] Epoch 316/4000: train_loss=0.0000  test_loss=21.8777  λ_max=1.8915\n",
      "[Adam | lr=0.1] Epoch 317/4000: train_loss=0.0000  test_loss=21.8965  λ_max=1.7201\n",
      "[Adam | lr=0.1] Epoch 318/4000: train_loss=0.0000  test_loss=21.9152  λ_max=1.7903\n",
      "[Adam | lr=0.1] Iter 5100: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 319/4000: train_loss=0.0000  test_loss=21.9325  λ_max=1.7639\n",
      "[Adam | lr=0.1] Epoch 320/4000: train_loss=0.0000  test_loss=21.9519  λ_max=1.9337\n",
      "[Adam | lr=0.1] Epoch 321/4000: train_loss=0.0000  test_loss=21.9702  λ_max=1.8349\n",
      "[Adam | lr=0.1] Epoch 322/4000: train_loss=0.0000  test_loss=21.9889  λ_max=1.8983\n",
      "[Adam | lr=0.1] Epoch 323/4000: train_loss=0.0000  test_loss=22.0069  λ_max=1.8812\n",
      "[Adam | lr=0.1] Epoch 324/4000: train_loss=0.0000  test_loss=22.0262  λ_max=1.9166\n",
      "[Adam | lr=0.1] Iter 5200: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 325/4000: train_loss=0.0000  test_loss=22.0444  λ_max=1.8548\n",
      "[Adam | lr=0.1] Epoch 326/4000: train_loss=0.0000  test_loss=22.0630  λ_max=1.7906\n",
      "[Adam | lr=0.1] Epoch 327/4000: train_loss=0.0000  test_loss=22.0810  λ_max=1.8845\n",
      "[Adam | lr=0.1] Epoch 328/4000: train_loss=0.0000  test_loss=22.0994  λ_max=1.6992\n",
      "[Adam | lr=0.1] Epoch 329/4000: train_loss=0.0000  test_loss=22.1174  λ_max=1.8609\n",
      "[Adam | lr=0.1] Epoch 330/4000: train_loss=0.0000  test_loss=22.1356  λ_max=1.8706\n",
      "[Adam | lr=0.1] Epoch 331/4000: train_loss=0.0000  test_loss=22.1528  λ_max=1.7742\n",
      "[Adam | lr=0.1] Iter 5300: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 332/4000: train_loss=0.0000  test_loss=22.1711  λ_max=1.8629\n",
      "[Adam | lr=0.1] Epoch 333/4000: train_loss=0.0000  test_loss=22.1886  λ_max=1.9051\n",
      "[Adam | lr=0.1] Epoch 334/4000: train_loss=0.0000  test_loss=22.2067  λ_max=1.8870\n",
      "[Adam | lr=0.1] Epoch 335/4000: train_loss=0.0000  test_loss=22.2237  λ_max=1.9082\n",
      "[Adam | lr=0.1] Epoch 336/4000: train_loss=0.0000  test_loss=22.2418  λ_max=1.8832\n",
      "[Adam | lr=0.1] Epoch 337/4000: train_loss=0.0000  test_loss=22.2582  λ_max=1.8930\n",
      "[Adam | lr=0.1] Iter 5400: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 338/4000: train_loss=0.0000  test_loss=22.2764  λ_max=1.8911\n",
      "[Adam | lr=0.1] Epoch 339/4000: train_loss=0.0000  test_loss=22.2940  λ_max=1.9011\n",
      "[Adam | lr=0.1] Epoch 340/4000: train_loss=0.0000  test_loss=22.3113  λ_max=1.7635\n",
      "[Adam | lr=0.1] Epoch 341/4000: train_loss=0.0000  test_loss=22.3284  λ_max=1.7569\n",
      "[Adam | lr=0.1] Epoch 342/4000: train_loss=0.0000  test_loss=22.3460  λ_max=1.6859\n",
      "[Adam | lr=0.1] Epoch 343/4000: train_loss=0.0000  test_loss=22.3632  λ_max=1.8482\n",
      "[Adam | lr=0.1] Iter 5500: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 344/4000: train_loss=0.0000  test_loss=22.3803  λ_max=1.8159\n",
      "[Adam | lr=0.1] Epoch 345/4000: train_loss=0.0000  test_loss=22.3985  λ_max=1.8060\n",
      "[Adam | lr=0.1] Epoch 346/4000: train_loss=0.0000  test_loss=22.4144  λ_max=1.7709\n",
      "[Adam | lr=0.1] Epoch 347/4000: train_loss=0.0000  test_loss=22.4316  λ_max=1.8422\n",
      "[Adam | lr=0.1] Epoch 348/4000: train_loss=0.0000  test_loss=22.4487  λ_max=1.6278\n",
      "[Adam | lr=0.1] Epoch 349/4000: train_loss=0.0000  test_loss=22.4657  λ_max=1.8150\n",
      "[Adam | lr=0.1] Iter 5600: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 350/4000: train_loss=0.0000  test_loss=22.4837  λ_max=1.7732\n",
      "[Adam | lr=0.1] Epoch 351/4000: train_loss=0.0000  test_loss=22.5000  λ_max=1.8026\n",
      "[Adam | lr=0.1] Epoch 352/4000: train_loss=0.0000  test_loss=22.5168  λ_max=1.8720\n",
      "[Adam | lr=0.1] Epoch 353/4000: train_loss=0.0000  test_loss=22.5335  λ_max=1.7363\n",
      "[Adam | lr=0.1] Epoch 354/4000: train_loss=0.0000  test_loss=22.5498  λ_max=1.7578\n",
      "[Adam | lr=0.1] Epoch 355/4000: train_loss=0.0000  test_loss=22.5672  λ_max=1.7705\n",
      "[Adam | lr=0.1] Epoch 356/4000: train_loss=0.0000  test_loss=22.5848  λ_max=1.7935\n",
      "[Adam | lr=0.1] Iter 5700: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 357/4000: train_loss=0.0000  test_loss=22.6005  λ_max=1.7819\n",
      "[Adam | lr=0.1] Epoch 358/4000: train_loss=0.0000  test_loss=22.6172  λ_max=1.7814\n",
      "[Adam | lr=0.1] Epoch 359/4000: train_loss=0.0000  test_loss=22.6341  λ_max=1.8725\n",
      "[Adam | lr=0.1] Epoch 360/4000: train_loss=0.0000  test_loss=22.6502  λ_max=1.8661\n",
      "[Adam | lr=0.1] Epoch 361/4000: train_loss=0.0000  test_loss=22.6671  λ_max=1.8663\n",
      "[Adam | lr=0.1] Epoch 362/4000: train_loss=0.0000  test_loss=22.6832  λ_max=1.7267\n",
      "[Adam | lr=0.1] Iter 5800: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 363/4000: train_loss=0.0000  test_loss=22.7000  λ_max=1.7913\n",
      "[Adam | lr=0.1] Epoch 364/4000: train_loss=0.0000  test_loss=22.7170  λ_max=1.7230\n",
      "[Adam | lr=0.1] Epoch 365/4000: train_loss=0.0000  test_loss=22.7334  λ_max=1.8533\n",
      "[Adam | lr=0.1] Epoch 366/4000: train_loss=0.0000  test_loss=22.7498  λ_max=1.7381\n",
      "[Adam | lr=0.1] Epoch 367/4000: train_loss=0.0000  test_loss=22.7652  λ_max=1.7384\n",
      "[Adam | lr=0.1] Epoch 368/4000: train_loss=0.0000  test_loss=22.7823  λ_max=1.8378\n",
      "[Adam | lr=0.1] Iter 5900: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 369/4000: train_loss=0.0000  test_loss=22.7984  λ_max=1.7880\n",
      "[Adam | lr=0.1] Epoch 370/4000: train_loss=0.0000  test_loss=22.8141  λ_max=1.8406\n",
      "[Adam | lr=0.1] Epoch 371/4000: train_loss=0.0000  test_loss=22.8307  λ_max=1.7409\n",
      "[Adam | lr=0.1] Epoch 372/4000: train_loss=0.0000  test_loss=22.8474  λ_max=1.7442\n",
      "[Adam | lr=0.1] Epoch 373/4000: train_loss=0.0000  test_loss=22.8633  λ_max=1.8349\n",
      "[Adam | lr=0.1] Epoch 374/4000: train_loss=0.0000  test_loss=22.8786  λ_max=1.7699\n",
      "[Adam | lr=0.1] Iter 6000: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 375/4000: train_loss=0.0000  test_loss=22.8957  λ_max=1.6867\n",
      "[Adam | lr=0.1] Epoch 376/4000: train_loss=0.0000  test_loss=22.9117  λ_max=1.8103\n",
      "[Adam | lr=0.1] Epoch 377/4000: train_loss=0.0000  test_loss=22.9268  λ_max=1.7600\n",
      "[Adam | lr=0.1] Epoch 378/4000: train_loss=0.0000  test_loss=22.9428  λ_max=1.7675\n",
      "[Adam | lr=0.1] Epoch 379/4000: train_loss=0.0000  test_loss=22.9596  λ_max=1.8152\n",
      "[Adam | lr=0.1] Epoch 380/4000: train_loss=0.0000  test_loss=22.9756  λ_max=1.8131\n",
      "[Adam | lr=0.1] Epoch 381/4000: train_loss=0.0000  test_loss=22.9916  λ_max=1.7934\n",
      "[Adam | lr=0.1] Iter 6100: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 382/4000: train_loss=0.0000  test_loss=23.0064  λ_max=1.8486\n",
      "[Adam | lr=0.1] Epoch 383/4000: train_loss=0.0000  test_loss=23.0230  λ_max=1.7830\n",
      "[Adam | lr=0.1] Epoch 384/4000: train_loss=0.0000  test_loss=23.0383  λ_max=1.7283\n",
      "[Adam | lr=0.1] Epoch 385/4000: train_loss=0.0000  test_loss=23.0549  λ_max=1.8543\n",
      "[Adam | lr=0.1] Epoch 386/4000: train_loss=0.0000  test_loss=23.0708  λ_max=1.8360\n",
      "[Adam | lr=0.1] Epoch 387/4000: train_loss=0.0000  test_loss=23.0866  λ_max=1.7017\n",
      "[Adam | lr=0.1] Iter 6200: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 388/4000: train_loss=0.0000  test_loss=23.1029  λ_max=1.8317\n",
      "[Adam | lr=0.1] Epoch 389/4000: train_loss=0.0000  test_loss=23.1180  λ_max=1.7256\n",
      "[Adam | lr=0.1] Epoch 390/4000: train_loss=0.0000  test_loss=23.1332  λ_max=1.7028\n",
      "[Adam | lr=0.1] Epoch 391/4000: train_loss=0.0000  test_loss=23.1497  λ_max=1.8474\n",
      "[Adam | lr=0.1] Epoch 392/4000: train_loss=0.0000  test_loss=23.1648  λ_max=1.6974\n",
      "[Adam | lr=0.1] Epoch 393/4000: train_loss=0.0000  test_loss=23.1810  λ_max=1.7351\n",
      "[Adam | lr=0.1] Iter 6300: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 394/4000: train_loss=0.0000  test_loss=23.1970  λ_max=1.8259\n",
      "[Adam | lr=0.1] Epoch 395/4000: train_loss=0.0000  test_loss=23.2123  λ_max=1.5324\n",
      "[Adam | lr=0.1] Epoch 396/4000: train_loss=0.0000  test_loss=23.2282  λ_max=1.8094\n",
      "[Adam | lr=0.1] Epoch 397/4000: train_loss=0.0000  test_loss=23.2443  λ_max=1.7735\n",
      "[Adam | lr=0.1] Epoch 398/4000: train_loss=0.0000  test_loss=23.2596  λ_max=1.8173\n",
      "[Adam | lr=0.1] Epoch 399/4000: train_loss=0.0000  test_loss=23.2752  λ_max=1.8362\n",
      "[Adam | lr=0.1] Iter 6400: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 400/4000: train_loss=0.0000  test_loss=23.2910  λ_max=1.7973\n",
      "[Adam | lr=0.1] Epoch 401/4000: train_loss=0.0000  test_loss=23.3062  λ_max=1.8362\n",
      "[Adam | lr=0.1] Epoch 402/4000: train_loss=0.0000  test_loss=23.3220  λ_max=1.8276\n",
      "[Adam | lr=0.1] Epoch 403/4000: train_loss=0.0000  test_loss=23.3370  λ_max=1.8075\n",
      "[Adam | lr=0.1] Epoch 404/4000: train_loss=0.0000  test_loss=23.3533  λ_max=1.7732\n",
      "[Adam | lr=0.1] Epoch 405/4000: train_loss=0.0000  test_loss=23.3680  λ_max=1.7190\n",
      "[Adam | lr=0.1] Epoch 406/4000: train_loss=0.0000  test_loss=23.3834  λ_max=1.7732\n",
      "[Adam | lr=0.1] Iter 6500: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 407/4000: train_loss=0.0000  test_loss=23.3983  λ_max=1.7435\n",
      "[Adam | lr=0.1] Epoch 408/4000: train_loss=0.0000  test_loss=23.4151  λ_max=1.8244\n",
      "[Adam | lr=0.1] Epoch 409/4000: train_loss=0.0000  test_loss=23.4299  λ_max=1.6971\n",
      "[Adam | lr=0.1] Epoch 410/4000: train_loss=0.0000  test_loss=23.4448  λ_max=1.6813\n",
      "[Adam | lr=0.1] Epoch 411/4000: train_loss=0.0000  test_loss=23.4606  λ_max=1.6843\n",
      "[Adam | lr=0.1] Epoch 412/4000: train_loss=0.0000  test_loss=23.4763  λ_max=1.7646\n",
      "[Adam | lr=0.1] Iter 6600: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 413/4000: train_loss=0.0000  test_loss=23.4913  λ_max=1.8268\n",
      "[Adam | lr=0.1] Epoch 414/4000: train_loss=0.0000  test_loss=23.5062  λ_max=1.7178\n",
      "[Adam | lr=0.1] Epoch 415/4000: train_loss=0.0000  test_loss=23.5221  λ_max=1.5804\n",
      "[Adam | lr=0.1] Epoch 416/4000: train_loss=0.0000  test_loss=23.5377  λ_max=1.6806\n",
      "[Adam | lr=0.1] Epoch 417/4000: train_loss=0.0000  test_loss=23.5530  λ_max=1.7180\n",
      "[Adam | lr=0.1] Epoch 418/4000: train_loss=0.0000  test_loss=23.5682  λ_max=1.6859\n",
      "[Adam | lr=0.1] Iter 6700: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 419/4000: train_loss=0.0000  test_loss=23.5826  λ_max=1.7390\n",
      "[Adam | lr=0.1] Epoch 420/4000: train_loss=0.0000  test_loss=23.5984  λ_max=1.8005\n",
      "[Adam | lr=0.1] Epoch 421/4000: train_loss=0.0000  test_loss=23.6134  λ_max=1.7844\n",
      "[Adam | lr=0.1] Epoch 422/4000: train_loss=0.0000  test_loss=23.6293  λ_max=1.7958\n",
      "[Adam | lr=0.1] Epoch 423/4000: train_loss=0.0000  test_loss=23.6442  λ_max=1.7611\n",
      "[Adam | lr=0.1] Epoch 424/4000: train_loss=0.0000  test_loss=23.6592  λ_max=1.7703\n",
      "[Adam | lr=0.1] Iter 6800: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 425/4000: train_loss=0.0000  test_loss=23.6747  λ_max=1.7505\n",
      "[Adam | lr=0.1] Epoch 426/4000: train_loss=0.0000  test_loss=23.6900  λ_max=1.6719\n",
      "[Adam | lr=0.1] Epoch 427/4000: train_loss=0.0000  test_loss=23.7051  λ_max=1.8066\n",
      "[Adam | lr=0.1] Epoch 428/4000: train_loss=0.0000  test_loss=23.7197  λ_max=1.7211\n",
      "[Adam | lr=0.1] Epoch 429/4000: train_loss=0.0000  test_loss=23.7352  λ_max=1.7275\n",
      "[Adam | lr=0.1] Epoch 430/4000: train_loss=0.0000  test_loss=23.7509  λ_max=1.7268\n",
      "[Adam | lr=0.1] Epoch 431/4000: train_loss=0.0000  test_loss=23.7646  λ_max=1.8006\n",
      "[Adam | lr=0.1] Iter 6900: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 432/4000: train_loss=0.0000  test_loss=23.7805  λ_max=1.7685\n",
      "[Adam | lr=0.1] Epoch 433/4000: train_loss=0.0000  test_loss=23.7955  λ_max=1.6943\n",
      "[Adam | lr=0.1] Epoch 434/4000: train_loss=0.0000  test_loss=23.8100  λ_max=1.7315\n",
      "[Adam | lr=0.1] Epoch 435/4000: train_loss=0.0000  test_loss=23.8254  λ_max=1.7644\n",
      "[Adam | lr=0.1] Epoch 436/4000: train_loss=0.0000  test_loss=23.8407  λ_max=1.7344\n",
      "[Adam | lr=0.1] Epoch 437/4000: train_loss=0.0000  test_loss=23.8556  λ_max=1.7836\n",
      "[Adam | lr=0.1] Iter 7000: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 438/4000: train_loss=0.0000  test_loss=23.8705  λ_max=1.7718\n",
      "[Adam | lr=0.1] Epoch 439/4000: train_loss=0.0000  test_loss=23.8863  λ_max=1.7433\n",
      "[Adam | lr=0.1] Epoch 440/4000: train_loss=0.0000  test_loss=23.9007  λ_max=1.7679\n",
      "[Adam | lr=0.1] Epoch 441/4000: train_loss=0.0000  test_loss=23.9155  λ_max=1.5832\n",
      "[Adam | lr=0.1] Epoch 442/4000: train_loss=0.0000  test_loss=23.9312  λ_max=1.6465\n",
      "[Adam | lr=0.1] Epoch 443/4000: train_loss=0.0000  test_loss=23.9458  λ_max=1.7433\n",
      "[Adam | lr=0.1] Iter 7100: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 444/4000: train_loss=0.0000  test_loss=23.9599  λ_max=1.6909\n",
      "[Adam | lr=0.1] Epoch 445/4000: train_loss=0.0000  test_loss=23.9750  λ_max=1.7797\n",
      "[Adam | lr=0.1] Epoch 446/4000: train_loss=0.0000  test_loss=23.9905  λ_max=1.6419\n",
      "[Adam | lr=0.1] Epoch 447/4000: train_loss=0.0000  test_loss=24.0057  λ_max=1.7901\n",
      "[Adam | lr=0.1] Epoch 448/4000: train_loss=0.0000  test_loss=24.0209  λ_max=1.6846\n",
      "[Adam | lr=0.1] Epoch 449/4000: train_loss=0.0000  test_loss=24.0357  λ_max=1.7604\n",
      "[Adam | lr=0.1] Iter 7200: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 450/4000: train_loss=0.0000  test_loss=24.0501  λ_max=1.7772\n",
      "[Adam | lr=0.1] Epoch 451/4000: train_loss=0.0000  test_loss=24.0656  λ_max=1.6473\n",
      "[Adam | lr=0.1] Epoch 452/4000: train_loss=0.0000  test_loss=24.0805  λ_max=1.7650\n",
      "[Adam | lr=0.1] Epoch 453/4000: train_loss=0.0000  test_loss=24.0954  λ_max=1.6434\n",
      "[Adam | lr=0.1] Epoch 454/4000: train_loss=0.0000  test_loss=24.1100  λ_max=1.7749\n",
      "[Adam | lr=0.1] Epoch 455/4000: train_loss=0.0000  test_loss=24.1256  λ_max=1.7868\n",
      "[Adam | lr=0.1] Epoch 456/4000: train_loss=0.0000  test_loss=24.1407  λ_max=1.7707\n",
      "[Adam | lr=0.1] Iter 7300: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 457/4000: train_loss=0.0000  test_loss=24.1551  λ_max=1.6277\n",
      "[Adam | lr=0.1] Epoch 458/4000: train_loss=0.0000  test_loss=24.1700  λ_max=1.7149\n",
      "[Adam | lr=0.1] Epoch 459/4000: train_loss=0.0000  test_loss=24.1848  λ_max=1.7408\n",
      "[Adam | lr=0.1] Epoch 460/4000: train_loss=0.0000  test_loss=24.2004  λ_max=1.7610\n",
      "[Adam | lr=0.1] Epoch 461/4000: train_loss=0.0000  test_loss=24.2140  λ_max=1.7413\n",
      "[Adam | lr=0.1] Epoch 462/4000: train_loss=0.0000  test_loss=24.2295  λ_max=1.7081\n",
      "[Adam | lr=0.1] Iter 7400: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 463/4000: train_loss=0.0000  test_loss=24.2440  λ_max=1.7206\n",
      "[Adam | lr=0.1] Epoch 464/4000: train_loss=0.0000  test_loss=24.2599  λ_max=1.6573\n",
      "[Adam | lr=0.1] Epoch 465/4000: train_loss=0.0000  test_loss=24.2735  λ_max=1.6077\n",
      "[Adam | lr=0.1] Epoch 466/4000: train_loss=0.0000  test_loss=24.2885  λ_max=1.7692\n",
      "[Adam | lr=0.1] Epoch 467/4000: train_loss=0.0000  test_loss=24.3031  λ_max=1.7849\n",
      "[Adam | lr=0.1] Epoch 468/4000: train_loss=0.0000  test_loss=24.3189  λ_max=1.6236\n",
      "[Adam | lr=0.1] Iter 7500: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 469/4000: train_loss=0.0000  test_loss=24.3334  λ_max=1.6106\n",
      "[Adam | lr=0.1] Epoch 470/4000: train_loss=0.0000  test_loss=24.3473  λ_max=1.6412\n",
      "[Adam | lr=0.1] Epoch 471/4000: train_loss=0.0000  test_loss=24.3635  λ_max=1.7222\n",
      "[Adam | lr=0.1] Epoch 472/4000: train_loss=0.0000  test_loss=24.3785  λ_max=1.7597\n",
      "[Adam | lr=0.1] Epoch 473/4000: train_loss=0.0000  test_loss=24.3923  λ_max=1.6500\n",
      "[Adam | lr=0.1] Epoch 474/4000: train_loss=0.0000  test_loss=24.4080  λ_max=1.6997\n",
      "[Adam | lr=0.1] Iter 7600: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 475/4000: train_loss=0.0000  test_loss=24.4218  λ_max=1.7346\n",
      "[Adam | lr=0.1] Epoch 476/4000: train_loss=0.0000  test_loss=24.4376  λ_max=1.5463\n",
      "[Adam | lr=0.1] Epoch 477/4000: train_loss=0.0000  test_loss=24.4518  λ_max=1.6269\n",
      "[Adam | lr=0.1] Epoch 478/4000: train_loss=0.0000  test_loss=24.4666  λ_max=1.6600\n",
      "[Adam | lr=0.1] Epoch 479/4000: train_loss=0.0000  test_loss=24.4815  λ_max=1.6274\n",
      "[Adam | lr=0.1] Epoch 480/4000: train_loss=0.0000  test_loss=24.4957  λ_max=1.7555\n",
      "[Adam | lr=0.1] Epoch 481/4000: train_loss=0.0000  test_loss=24.5106  λ_max=1.6080\n",
      "[Adam | lr=0.1] Iter 7700: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 482/4000: train_loss=0.0000  test_loss=24.5256  λ_max=1.6762\n",
      "[Adam | lr=0.1] Epoch 483/4000: train_loss=0.0000  test_loss=24.5403  λ_max=1.7401\n",
      "[Adam | lr=0.1] Epoch 484/4000: train_loss=0.0000  test_loss=24.5550  λ_max=1.5621\n",
      "[Adam | lr=0.1] Epoch 485/4000: train_loss=0.0000  test_loss=24.5703  λ_max=1.6441\n",
      "[Adam | lr=0.1] Epoch 486/4000: train_loss=0.0000  test_loss=24.5842  λ_max=1.6231\n",
      "[Adam | lr=0.1] Epoch 487/4000: train_loss=0.0000  test_loss=24.5995  λ_max=1.6655\n",
      "[Adam | lr=0.1] Iter 7800: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 488/4000: train_loss=0.0000  test_loss=24.6142  λ_max=1.7472\n",
      "[Adam | lr=0.1] Epoch 489/4000: train_loss=0.0000  test_loss=24.6289  λ_max=1.7675\n",
      "[Adam | lr=0.1] Epoch 490/4000: train_loss=0.0000  test_loss=24.6440  λ_max=1.5460\n",
      "[Adam | lr=0.1] Epoch 491/4000: train_loss=0.0000  test_loss=24.6579  λ_max=1.6626\n",
      "[Adam | lr=0.1] Epoch 492/4000: train_loss=0.0000  test_loss=24.6730  λ_max=1.6794\n",
      "[Adam | lr=0.1] Epoch 493/4000: train_loss=0.0000  test_loss=24.6870  λ_max=1.5965\n",
      "[Adam | lr=0.1] Iter 7900: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 494/4000: train_loss=0.0000  test_loss=24.7017  λ_max=1.7707\n",
      "[Adam | lr=0.1] Epoch 495/4000: train_loss=0.0000  test_loss=24.7172  λ_max=1.5871\n",
      "[Adam | lr=0.1] Epoch 496/4000: train_loss=0.0000  test_loss=24.7309  λ_max=1.7623\n",
      "[Adam | lr=0.1] Epoch 497/4000: train_loss=0.0000  test_loss=24.7458  λ_max=1.5827\n",
      "[Adam | lr=0.1] Epoch 498/4000: train_loss=0.0000  test_loss=24.7606  λ_max=1.7513\n",
      "[Adam | lr=0.1] Epoch 499/4000: train_loss=0.0000  test_loss=24.7752  λ_max=1.5774\n",
      "[Adam | lr=0.1] Iter 8000: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 500/4000: train_loss=0.0000  test_loss=24.7903  λ_max=1.6406\n",
      "[Adam | lr=0.1] Epoch 501/4000: train_loss=0.0000  test_loss=24.8043  λ_max=1.5884\n",
      "[Adam | lr=0.1] Epoch 502/4000: train_loss=0.0000  test_loss=24.8192  λ_max=1.5447\n",
      "[Adam | lr=0.1] Epoch 503/4000: train_loss=0.0000  test_loss=24.8335  λ_max=1.5521\n",
      "[Adam | lr=0.1] Epoch 504/4000: train_loss=0.0000  test_loss=24.8489  λ_max=1.5643\n",
      "[Adam | lr=0.1] Epoch 505/4000: train_loss=0.0000  test_loss=24.8635  λ_max=1.6117\n",
      "[Adam | lr=0.1] Epoch 506/4000: train_loss=0.0000  test_loss=24.8778  λ_max=1.6234\n",
      "[Adam | lr=0.1] Iter 8100: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 507/4000: train_loss=0.0000  test_loss=24.8927  λ_max=1.7474\n",
      "[Adam | lr=0.1] Epoch 508/4000: train_loss=0.0000  test_loss=24.9075  λ_max=1.6449\n",
      "[Adam | lr=0.1] Epoch 509/4000: train_loss=0.0000  test_loss=24.9225  λ_max=1.7345\n",
      "[Adam | lr=0.1] Epoch 510/4000: train_loss=0.0000  test_loss=24.9360  λ_max=1.6588\n",
      "[Adam | lr=0.1] Epoch 511/4000: train_loss=0.0000  test_loss=24.9510  λ_max=1.6523\n",
      "[Adam | lr=0.1] Epoch 512/4000: train_loss=0.0000  test_loss=24.9665  λ_max=1.7328\n",
      "[Adam | lr=0.1] Iter 8200: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 513/4000: train_loss=0.0000  test_loss=24.9802  λ_max=1.6093\n",
      "[Adam | lr=0.1] Epoch 514/4000: train_loss=0.0000  test_loss=24.9951  λ_max=1.5900\n",
      "[Adam | lr=0.1] Epoch 515/4000: train_loss=0.0000  test_loss=25.0098  λ_max=1.7103\n",
      "[Adam | lr=0.1] Epoch 516/4000: train_loss=0.0000  test_loss=25.0246  λ_max=1.6038\n",
      "[Adam | lr=0.1] Epoch 517/4000: train_loss=0.0000  test_loss=25.0386  λ_max=1.7303\n",
      "[Adam | lr=0.1] Epoch 518/4000: train_loss=0.0000  test_loss=25.0543  λ_max=1.6008\n",
      "[Adam | lr=0.1] Iter 8300: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 519/4000: train_loss=0.0000  test_loss=25.0690  λ_max=1.6640\n",
      "[Adam | lr=0.1] Epoch 520/4000: train_loss=0.0000  test_loss=25.0828  λ_max=1.5154\n",
      "[Adam | lr=0.1] Epoch 521/4000: train_loss=0.0000  test_loss=25.0977  λ_max=1.6272\n",
      "[Adam | lr=0.1] Epoch 522/4000: train_loss=0.0000  test_loss=25.1130  λ_max=1.7026\n",
      "[Adam | lr=0.1] Epoch 523/4000: train_loss=0.0000  test_loss=25.1266  λ_max=1.6491\n",
      "[Adam | lr=0.1] Epoch 524/4000: train_loss=0.0000  test_loss=25.1419  λ_max=1.7399\n",
      "[Adam | lr=0.1] Iter 8400: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 525/4000: train_loss=0.0000  test_loss=25.1556  λ_max=1.7357\n",
      "[Adam | lr=0.1] Epoch 526/4000: train_loss=0.0000  test_loss=25.1706  λ_max=1.5460\n",
      "[Adam | lr=0.1] Epoch 527/4000: train_loss=0.0000  test_loss=25.1850  λ_max=1.5951\n",
      "[Adam | lr=0.1] Epoch 528/4000: train_loss=0.0000  test_loss=25.1999  λ_max=1.7139\n",
      "[Adam | lr=0.1] Epoch 529/4000: train_loss=0.0000  test_loss=25.2155  λ_max=1.7269\n",
      "[Adam | lr=0.1] Epoch 530/4000: train_loss=0.0000  test_loss=25.2297  λ_max=1.7353\n",
      "[Adam | lr=0.1] Epoch 531/4000: train_loss=0.0000  test_loss=25.2441  λ_max=1.7301\n",
      "[Adam | lr=0.1] Iter 8500: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 532/4000: train_loss=0.0000  test_loss=25.2573  λ_max=1.7036\n",
      "[Adam | lr=0.1] Epoch 533/4000: train_loss=0.0000  test_loss=25.2737  λ_max=1.4979\n",
      "[Adam | lr=0.1] Epoch 534/4000: train_loss=0.0000  test_loss=25.2877  λ_max=1.5899\n",
      "[Adam | lr=0.1] Epoch 535/4000: train_loss=0.0000  test_loss=25.3024  λ_max=1.6490\n",
      "[Adam | lr=0.1] Epoch 536/4000: train_loss=0.0000  test_loss=25.3161  λ_max=1.5755\n",
      "[Adam | lr=0.1] Epoch 537/4000: train_loss=0.0000  test_loss=25.3316  λ_max=1.5459\n",
      "[Adam | lr=0.1] Iter 8600: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 538/4000: train_loss=0.0000  test_loss=25.3463  λ_max=1.7432\n",
      "[Adam | lr=0.1] Epoch 539/4000: train_loss=0.0000  test_loss=25.3604  λ_max=1.6978\n",
      "[Adam | lr=0.1] Epoch 540/4000: train_loss=0.0000  test_loss=25.3757  λ_max=1.6558\n",
      "[Adam | lr=0.1] Epoch 541/4000: train_loss=0.0000  test_loss=25.3898  λ_max=1.6511\n",
      "[Adam | lr=0.1] Epoch 542/4000: train_loss=0.0000  test_loss=25.4047  λ_max=1.6020\n",
      "[Adam | lr=0.1] Epoch 543/4000: train_loss=0.0000  test_loss=25.4191  λ_max=1.7038\n",
      "[Adam | lr=0.1] Iter 8700: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 544/4000: train_loss=0.0000  test_loss=25.4344  λ_max=1.6362\n",
      "[Adam | lr=0.1] Epoch 545/4000: train_loss=0.0000  test_loss=25.4474  λ_max=1.7116\n",
      "[Adam | lr=0.1] Epoch 546/4000: train_loss=0.0000  test_loss=25.4632  λ_max=1.6361\n",
      "[Adam | lr=0.1] Epoch 547/4000: train_loss=0.0000  test_loss=25.4780  λ_max=1.7144\n",
      "[Adam | lr=0.1] Epoch 548/4000: train_loss=0.0000  test_loss=25.4919  λ_max=1.6852\n",
      "[Adam | lr=0.1] Epoch 549/4000: train_loss=0.0000  test_loss=25.5066  λ_max=1.6945\n",
      "[Adam | lr=0.1] Iter 8800: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 550/4000: train_loss=0.0000  test_loss=25.5212  λ_max=1.7226\n",
      "[Adam | lr=0.1] Epoch 551/4000: train_loss=0.0000  test_loss=25.5353  λ_max=1.5742\n",
      "[Adam | lr=0.1] Epoch 552/4000: train_loss=0.0000  test_loss=25.5502  λ_max=1.6426\n",
      "[Adam | lr=0.1] Epoch 553/4000: train_loss=0.0000  test_loss=25.5645  λ_max=1.7342\n",
      "[Adam | lr=0.1] Epoch 554/4000: train_loss=0.0000  test_loss=25.5789  λ_max=1.6864\n",
      "[Adam | lr=0.1] Epoch 555/4000: train_loss=0.0000  test_loss=25.5937  λ_max=1.6392\n",
      "[Adam | lr=0.1] Epoch 556/4000: train_loss=0.0000  test_loss=25.6089  λ_max=1.6379\n",
      "[Adam | lr=0.1] Iter 8900: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 557/4000: train_loss=0.0000  test_loss=25.6233  λ_max=1.5729\n",
      "[Adam | lr=0.1] Epoch 558/4000: train_loss=0.0000  test_loss=25.6368  λ_max=1.7288\n",
      "[Adam | lr=0.1] Epoch 559/4000: train_loss=0.0000  test_loss=25.6521  λ_max=1.6365\n",
      "[Adam | lr=0.1] Epoch 560/4000: train_loss=0.0000  test_loss=25.6669  λ_max=1.7128\n",
      "[Adam | lr=0.1] Epoch 561/4000: train_loss=0.0000  test_loss=25.6812  λ_max=1.6444\n",
      "[Adam | lr=0.1] Epoch 562/4000: train_loss=0.0000  test_loss=25.6958  λ_max=1.6239\n",
      "[Adam | lr=0.1] Iter 9000: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 563/4000: train_loss=0.0000  test_loss=25.7103  λ_max=1.6746\n",
      "[Adam | lr=0.1] Epoch 564/4000: train_loss=0.0000  test_loss=25.7252  λ_max=1.7191\n",
      "[Adam | lr=0.1] Epoch 565/4000: train_loss=0.0000  test_loss=25.7399  λ_max=1.5992\n",
      "[Adam | lr=0.1] Epoch 566/4000: train_loss=0.0000  test_loss=25.7541  λ_max=1.7167\n",
      "[Adam | lr=0.1] Epoch 567/4000: train_loss=0.0000  test_loss=25.7692  λ_max=1.7146\n",
      "[Adam | lr=0.1] Epoch 568/4000: train_loss=0.0000  test_loss=25.7830  λ_max=1.5537\n",
      "[Adam | lr=0.1] Iter 9100: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 569/4000: train_loss=0.0000  test_loss=25.7977  λ_max=1.6546\n",
      "[Adam | lr=0.1] Epoch 570/4000: train_loss=0.0000  test_loss=25.8122  λ_max=1.6798\n",
      "[Adam | lr=0.1] Epoch 571/4000: train_loss=0.0000  test_loss=25.8269  λ_max=1.7002\n",
      "[Adam | lr=0.1] Epoch 572/4000: train_loss=0.0000  test_loss=25.8425  λ_max=1.5183\n",
      "[Adam | lr=0.1] Epoch 573/4000: train_loss=0.0000  test_loss=25.8563  λ_max=1.5898\n",
      "[Adam | lr=0.1] Epoch 574/4000: train_loss=0.0000  test_loss=25.8706  λ_max=1.6110\n",
      "[Adam | lr=0.1] Iter 9200: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 575/4000: train_loss=0.0000  test_loss=25.8853  λ_max=1.6523\n",
      "[Adam | lr=0.1] Epoch 576/4000: train_loss=0.0000  test_loss=25.8995  λ_max=1.5665\n",
      "[Adam | lr=0.1] Epoch 577/4000: train_loss=0.0000  test_loss=25.9151  λ_max=1.6982\n",
      "[Adam | lr=0.1] Epoch 578/4000: train_loss=0.0000  test_loss=25.9289  λ_max=1.6837\n",
      "[Adam | lr=0.1] Epoch 579/4000: train_loss=0.0000  test_loss=25.9436  λ_max=1.6839\n",
      "[Adam | lr=0.1] Epoch 580/4000: train_loss=0.0000  test_loss=25.9583  λ_max=1.6242\n",
      "[Adam | lr=0.1] Epoch 581/4000: train_loss=0.0000  test_loss=25.9736  λ_max=1.4918\n",
      "[Adam | lr=0.1] Iter 9300: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 582/4000: train_loss=0.0000  test_loss=25.9873  λ_max=1.6903\n",
      "[Adam | lr=0.1] Epoch 583/4000: train_loss=0.0000  test_loss=26.0026  λ_max=1.6630\n",
      "[Adam | lr=0.1] Epoch 584/4000: train_loss=0.0000  test_loss=26.0167  λ_max=1.6595\n",
      "[Adam | lr=0.1] Epoch 585/4000: train_loss=0.0000  test_loss=26.0321  λ_max=1.4807\n",
      "[Adam | lr=0.1] Epoch 586/4000: train_loss=0.0000  test_loss=26.0460  λ_max=1.7194\n",
      "[Adam | lr=0.1] Epoch 587/4000: train_loss=0.0000  test_loss=26.0612  λ_max=1.6710\n",
      "[Adam | lr=0.1] Iter 9400: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 588/4000: train_loss=0.0000  test_loss=26.0760  λ_max=1.5390\n",
      "[Adam | lr=0.1] Epoch 589/4000: train_loss=0.0000  test_loss=26.0903  λ_max=1.6556\n",
      "[Adam | lr=0.1] Epoch 590/4000: train_loss=0.0000  test_loss=26.1049  λ_max=1.6023\n",
      "[Adam | lr=0.1] Epoch 591/4000: train_loss=0.0000  test_loss=26.1197  λ_max=1.5034\n",
      "[Adam | lr=0.1] Epoch 592/4000: train_loss=0.0000  test_loss=26.1338  λ_max=1.6222\n",
      "[Adam | lr=0.1] Epoch 593/4000: train_loss=0.0000  test_loss=26.1485  λ_max=1.6600\n",
      "[Adam | lr=0.1] Iter 9500: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 594/4000: train_loss=0.0000  test_loss=26.1635  λ_max=1.7112\n",
      "[Adam | lr=0.1] Epoch 595/4000: train_loss=0.0000  test_loss=26.1778  λ_max=1.6529\n",
      "[Adam | lr=0.1] Epoch 596/4000: train_loss=0.0000  test_loss=26.1927  λ_max=1.5845\n",
      "[Adam | lr=0.1] Epoch 597/4000: train_loss=0.0000  test_loss=26.2076  λ_max=1.5937\n",
      "[Adam | lr=0.1] Epoch 598/4000: train_loss=0.0000  test_loss=26.2222  λ_max=1.6396\n",
      "[Adam | lr=0.1] Epoch 599/4000: train_loss=0.0000  test_loss=26.2362  λ_max=1.5797\n",
      "[Adam | lr=0.1] Iter 9600: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 600/4000: train_loss=0.0000  test_loss=26.2509  λ_max=1.6749\n",
      "[Adam | lr=0.1] Epoch 601/4000: train_loss=0.0000  test_loss=26.2655  λ_max=1.5379\n",
      "[Adam | lr=0.1] Epoch 602/4000: train_loss=0.0000  test_loss=26.2801  λ_max=1.6968\n",
      "[Adam | lr=0.1] Epoch 603/4000: train_loss=0.0000  test_loss=26.2945  λ_max=1.6277\n",
      "[Adam | lr=0.1] Epoch 604/4000: train_loss=0.0000  test_loss=26.3090  λ_max=1.4776\n",
      "[Adam | lr=0.1] Epoch 605/4000: train_loss=0.0000  test_loss=26.3238  λ_max=1.6792\n",
      "[Adam | lr=0.1] Epoch 606/4000: train_loss=0.0000  test_loss=26.3373  λ_max=1.5694\n",
      "[Adam | lr=0.1] Iter 9700: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 607/4000: train_loss=0.0000  test_loss=26.3528  λ_max=1.6446\n",
      "[Adam | lr=0.1] Epoch 608/4000: train_loss=0.0000  test_loss=26.3682  λ_max=1.6299\n",
      "[Adam | lr=0.1] Epoch 609/4000: train_loss=0.0000  test_loss=26.3813  λ_max=1.6752\n",
      "[Adam | lr=0.1] Epoch 610/4000: train_loss=0.0000  test_loss=26.3972  λ_max=1.5914\n",
      "[Adam | lr=0.1] Epoch 611/4000: train_loss=0.0000  test_loss=26.4118  λ_max=1.5781\n",
      "[Adam | lr=0.1] Epoch 612/4000: train_loss=0.0000  test_loss=26.4260  λ_max=1.6453\n",
      "[Adam | lr=0.1] Iter 9800: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 613/4000: train_loss=0.0000  test_loss=26.4406  λ_max=1.6524\n",
      "[Adam | lr=0.1] Epoch 614/4000: train_loss=0.0000  test_loss=26.4550  λ_max=1.5697\n",
      "[Adam | lr=0.1] Epoch 615/4000: train_loss=0.0000  test_loss=26.4696  λ_max=1.5467\n",
      "[Adam | lr=0.1] Epoch 616/4000: train_loss=0.0000  test_loss=26.4843  λ_max=1.6098\n",
      "[Adam | lr=0.1] Epoch 617/4000: train_loss=0.0000  test_loss=26.4991  λ_max=1.6683\n",
      "[Adam | lr=0.1] Epoch 618/4000: train_loss=0.0000  test_loss=26.5137  λ_max=1.5918\n",
      "[Adam | lr=0.1] Iter 9900: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 619/4000: train_loss=0.0000  test_loss=26.5288  λ_max=1.6913\n",
      "[Adam | lr=0.1] Epoch 620/4000: train_loss=0.0000  test_loss=26.5433  λ_max=1.5823\n",
      "[Adam | lr=0.1] Epoch 621/4000: train_loss=0.0000  test_loss=26.5570  λ_max=1.6306\n",
      "[Adam | lr=0.1] Epoch 622/4000: train_loss=0.0000  test_loss=26.5721  λ_max=1.6992\n",
      "[Adam | lr=0.1] Epoch 623/4000: train_loss=0.0000  test_loss=26.5869  λ_max=1.6656\n",
      "[Adam | lr=0.1] Epoch 624/4000: train_loss=0.0000  test_loss=26.6008  λ_max=1.6433\n",
      "[Adam | lr=0.1] Iter 10000: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 625/4000: train_loss=0.0000  test_loss=26.6168  λ_max=1.6078\n",
      "[Adam | lr=0.1] Epoch 626/4000: train_loss=0.0000  test_loss=26.6312  λ_max=1.6414\n",
      "[Adam | lr=0.1] Epoch 627/4000: train_loss=0.0000  test_loss=26.6458  λ_max=1.4991\n",
      "[Adam | lr=0.1] Epoch 628/4000: train_loss=0.0000  test_loss=26.6598  λ_max=1.6526\n",
      "[Adam | lr=0.1] Epoch 629/4000: train_loss=0.0000  test_loss=26.6757  λ_max=1.6101\n",
      "[Adam | lr=0.1] Epoch 630/4000: train_loss=0.0000  test_loss=26.6895  λ_max=1.6345\n",
      "[Adam | lr=0.1] Epoch 631/4000: train_loss=0.0000  test_loss=26.7044  λ_max=1.6942\n",
      "[Adam | lr=0.1] Iter 10100: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 632/4000: train_loss=0.0000  test_loss=26.7191  λ_max=1.5703\n",
      "[Adam | lr=0.1] Epoch 633/4000: train_loss=0.0000  test_loss=26.7335  λ_max=1.5102\n",
      "[Adam | lr=0.1] Epoch 634/4000: train_loss=0.0000  test_loss=26.7483  λ_max=1.6823\n",
      "[Adam | lr=0.1] Epoch 635/4000: train_loss=0.0000  test_loss=26.7627  λ_max=1.6799\n",
      "[Adam | lr=0.1] Epoch 636/4000: train_loss=0.0000  test_loss=26.7776  λ_max=1.6281\n",
      "[Adam | lr=0.1] Epoch 637/4000: train_loss=0.0000  test_loss=26.7928  λ_max=1.6734\n",
      "[Adam | lr=0.1] Iter 10200: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 638/4000: train_loss=0.0000  test_loss=26.8067  λ_max=1.5898\n",
      "[Adam | lr=0.1] Epoch 639/4000: train_loss=0.0000  test_loss=26.8219  λ_max=1.6801\n",
      "[Adam | lr=0.1] Epoch 640/4000: train_loss=0.0000  test_loss=26.8359  λ_max=1.5891\n",
      "[Adam | lr=0.1] Epoch 641/4000: train_loss=0.0000  test_loss=26.8520  λ_max=1.6846\n",
      "[Adam | lr=0.1] Epoch 642/4000: train_loss=0.0000  test_loss=26.8659  λ_max=1.4830\n",
      "[Adam | lr=0.1] Epoch 643/4000: train_loss=0.0000  test_loss=26.8808  λ_max=1.5617\n",
      "[Adam | lr=0.1] Iter 10300: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 644/4000: train_loss=0.0000  test_loss=26.8959  λ_max=1.6690\n",
      "[Adam | lr=0.1] Epoch 645/4000: train_loss=0.0000  test_loss=26.9094  λ_max=1.5170\n",
      "[Adam | lr=0.1] Epoch 646/4000: train_loss=0.0000  test_loss=26.9237  λ_max=1.6450\n",
      "[Adam | lr=0.1] Epoch 647/4000: train_loss=0.0000  test_loss=26.9388  λ_max=1.4984\n",
      "[Adam | lr=0.1] Epoch 648/4000: train_loss=0.0000  test_loss=26.9535  λ_max=1.6844\n",
      "[Adam | lr=0.1] Epoch 649/4000: train_loss=0.0000  test_loss=26.9671  λ_max=1.5047\n",
      "[Adam | lr=0.1] Iter 10400: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 650/4000: train_loss=0.0000  test_loss=26.9830  λ_max=1.6885\n",
      "[Adam | lr=0.1] Epoch 651/4000: train_loss=0.0000  test_loss=26.9974  λ_max=1.6829\n",
      "[Adam | lr=0.1] Epoch 652/4000: train_loss=0.0000  test_loss=27.0132  λ_max=1.5530\n",
      "[Adam | lr=0.1] Epoch 653/4000: train_loss=0.0000  test_loss=27.0262  λ_max=1.6517\n",
      "[Adam | lr=0.1] Epoch 654/4000: train_loss=0.0000  test_loss=27.0418  λ_max=1.6117\n",
      "[Adam | lr=0.1] Epoch 655/4000: train_loss=0.0000  test_loss=27.0569  λ_max=1.5596\n",
      "[Adam | lr=0.1] Epoch 656/4000: train_loss=0.0000  test_loss=27.0708  λ_max=1.5383\n",
      "[Adam | lr=0.1] Iter 10500: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 657/4000: train_loss=0.0000  test_loss=27.0858  λ_max=1.5981\n",
      "[Adam | lr=0.1] Epoch 658/4000: train_loss=0.0000  test_loss=27.1009  λ_max=1.6152\n",
      "[Adam | lr=0.1] Epoch 659/4000: train_loss=0.0000  test_loss=27.1149  λ_max=1.5161\n",
      "[Adam | lr=0.1] Epoch 660/4000: train_loss=0.0000  test_loss=27.1302  λ_max=1.5841\n",
      "[Adam | lr=0.1] Epoch 661/4000: train_loss=0.0000  test_loss=27.1448  λ_max=1.6807\n",
      "[Adam | lr=0.1] Epoch 662/4000: train_loss=0.0000  test_loss=27.1597  λ_max=1.5903\n",
      "[Adam | lr=0.1] Iter 10600: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 663/4000: train_loss=0.0000  test_loss=27.1738  λ_max=1.6685\n",
      "[Adam | lr=0.1] Epoch 664/4000: train_loss=0.0000  test_loss=27.1891  λ_max=1.6356\n",
      "[Adam | lr=0.1] Epoch 665/4000: train_loss=0.0000  test_loss=27.2048  λ_max=1.6481\n",
      "[Adam | lr=0.1] Epoch 666/4000: train_loss=0.0000  test_loss=27.2182  λ_max=1.6183\n",
      "[Adam | lr=0.1] Epoch 667/4000: train_loss=0.0000  test_loss=27.2337  λ_max=1.6826\n",
      "[Adam | lr=0.1] Epoch 668/4000: train_loss=0.0000  test_loss=27.2480  λ_max=1.5588\n",
      "[Adam | lr=0.1] Iter 10700: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 669/4000: train_loss=0.0000  test_loss=27.2626  λ_max=1.5576\n",
      "[Adam | lr=0.1] Epoch 670/4000: train_loss=0.0000  test_loss=27.2777  λ_max=1.6733\n",
      "[Adam | lr=0.1] Epoch 671/4000: train_loss=0.0000  test_loss=27.2921  λ_max=1.6776\n",
      "[Adam | lr=0.1] Epoch 672/4000: train_loss=0.0000  test_loss=27.3065  λ_max=1.6765\n",
      "[Adam | lr=0.1] Epoch 673/4000: train_loss=0.0000  test_loss=27.3218  λ_max=1.6053\n",
      "[Adam | lr=0.1] Epoch 674/4000: train_loss=0.0000  test_loss=27.3361  λ_max=1.5153\n",
      "[Adam | lr=0.1] Iter 10800: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 675/4000: train_loss=0.0000  test_loss=27.3515  λ_max=1.5805\n",
      "[Adam | lr=0.1] Epoch 676/4000: train_loss=0.0000  test_loss=27.3656  λ_max=1.6217\n",
      "[Adam | lr=0.1] Epoch 677/4000: train_loss=0.0000  test_loss=27.3798  λ_max=1.6798\n",
      "[Adam | lr=0.1] Epoch 678/4000: train_loss=0.0000  test_loss=27.3960  λ_max=1.6781\n",
      "[Adam | lr=0.1] Epoch 679/4000: train_loss=0.0000  test_loss=27.4101  λ_max=1.4269\n",
      "[Adam | lr=0.1] Epoch 680/4000: train_loss=0.0000  test_loss=27.4257  λ_max=1.6216\n",
      "[Adam | lr=0.1] Epoch 681/4000: train_loss=0.0000  test_loss=27.4399  λ_max=1.6389\n",
      "[Adam | lr=0.1] Iter 10900: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 682/4000: train_loss=0.0000  test_loss=27.4543  λ_max=1.6155\n",
      "[Adam | lr=0.1] Epoch 683/4000: train_loss=0.0000  test_loss=27.4692  λ_max=1.5587\n",
      "[Adam | lr=0.1] Epoch 684/4000: train_loss=0.0000  test_loss=27.4852  λ_max=1.6733\n",
      "[Adam | lr=0.1] Epoch 685/4000: train_loss=0.0000  test_loss=27.4987  λ_max=1.6378\n",
      "[Adam | lr=0.1] Epoch 686/4000: train_loss=0.0000  test_loss=27.5140  λ_max=1.5606\n",
      "[Adam | lr=0.1] Epoch 687/4000: train_loss=0.0000  test_loss=27.5284  λ_max=1.5457\n",
      "[Adam | lr=0.1] Iter 11000: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 688/4000: train_loss=0.0000  test_loss=27.5430  λ_max=1.5241\n",
      "[Adam | lr=0.1] Epoch 689/4000: train_loss=0.0000  test_loss=27.5579  λ_max=1.6745\n",
      "[Adam | lr=0.1] Epoch 690/4000: train_loss=0.0000  test_loss=27.5726  λ_max=1.6432\n",
      "[Adam | lr=0.1] Epoch 691/4000: train_loss=0.0000  test_loss=27.5866  λ_max=1.5252\n",
      "[Adam | lr=0.1] Epoch 692/4000: train_loss=0.0000  test_loss=27.6023  λ_max=1.6504\n",
      "[Adam | lr=0.1] Epoch 693/4000: train_loss=0.0000  test_loss=27.6166  λ_max=1.5983\n",
      "[Adam | lr=0.1] Iter 11100: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 694/4000: train_loss=0.0000  test_loss=27.6317  λ_max=1.5137\n",
      "[Adam | lr=0.1] Epoch 695/4000: train_loss=0.0000  test_loss=27.6467  λ_max=1.6700\n",
      "[Adam | lr=0.1] Epoch 696/4000: train_loss=0.0000  test_loss=27.6610  λ_max=1.6439\n",
      "[Adam | lr=0.1] Epoch 697/4000: train_loss=0.0000  test_loss=27.6759  λ_max=1.4241\n",
      "[Adam | lr=0.1] Epoch 698/4000: train_loss=0.0000  test_loss=27.6903  λ_max=1.6222\n",
      "[Adam | lr=0.1] Epoch 699/4000: train_loss=0.0000  test_loss=27.7050  λ_max=1.5003\n",
      "[Adam | lr=0.1] Iter 11200: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 700/4000: train_loss=0.0000  test_loss=27.7196  λ_max=1.4666\n",
      "[Adam | lr=0.1] Epoch 701/4000: train_loss=0.0000  test_loss=27.7337  λ_max=1.4890\n",
      "[Adam | lr=0.1] Epoch 702/4000: train_loss=0.0000  test_loss=27.7500  λ_max=1.6410\n",
      "[Adam | lr=0.1] Epoch 703/4000: train_loss=0.0000  test_loss=27.7649  λ_max=1.6544\n",
      "[Adam | lr=0.1] Epoch 704/4000: train_loss=0.0000  test_loss=27.7790  λ_max=1.6670\n",
      "[Adam | lr=0.1] Epoch 705/4000: train_loss=0.0000  test_loss=27.7941  λ_max=1.6583\n",
      "[Adam | lr=0.1] Epoch 706/4000: train_loss=0.0000  test_loss=27.8092  λ_max=1.5726\n",
      "[Adam | lr=0.1] Iter 11300: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 707/4000: train_loss=0.0000  test_loss=27.8234  λ_max=1.5312\n",
      "[Adam | lr=0.1] Epoch 708/4000: train_loss=0.0000  test_loss=27.8382  λ_max=1.6585\n",
      "[Adam | lr=0.1] Epoch 709/4000: train_loss=0.0000  test_loss=27.8526  λ_max=1.6502\n",
      "[Adam | lr=0.1] Epoch 710/4000: train_loss=0.0000  test_loss=27.8677  λ_max=1.6502\n",
      "[Adam | lr=0.1] Epoch 711/4000: train_loss=0.0000  test_loss=27.8817  λ_max=1.5371\n",
      "[Adam | lr=0.1] Epoch 712/4000: train_loss=0.0000  test_loss=27.8970  λ_max=1.5938\n",
      "[Adam | lr=0.1] Iter 11400: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 713/4000: train_loss=0.0000  test_loss=27.9119  λ_max=1.5193\n",
      "[Adam | lr=0.1] Epoch 714/4000: train_loss=0.0000  test_loss=27.9262  λ_max=1.5456\n",
      "[Adam | lr=0.1] Epoch 715/4000: train_loss=0.0000  test_loss=27.9416  λ_max=1.5472\n",
      "[Adam | lr=0.1] Epoch 716/4000: train_loss=0.0000  test_loss=27.9558  λ_max=1.5518\n",
      "[Adam | lr=0.1] Epoch 717/4000: train_loss=0.0000  test_loss=27.9714  λ_max=1.5220\n",
      "[Adam | lr=0.1] Epoch 718/4000: train_loss=0.0000  test_loss=27.9859  λ_max=1.4650\n",
      "[Adam | lr=0.1] Iter 11500: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 719/4000: train_loss=0.0000  test_loss=28.0000  λ_max=1.6473\n",
      "[Adam | lr=0.1] Epoch 720/4000: train_loss=0.0000  test_loss=28.0154  λ_max=1.5510\n",
      "[Adam | lr=0.1] Epoch 721/4000: train_loss=0.0000  test_loss=28.0305  λ_max=1.5985\n",
      "[Adam | lr=0.1] Epoch 722/4000: train_loss=0.0000  test_loss=28.0444  λ_max=1.5582\n",
      "[Adam | lr=0.1] Epoch 723/4000: train_loss=0.0000  test_loss=28.0591  λ_max=1.6561\n",
      "[Adam | lr=0.1] Epoch 724/4000: train_loss=0.0000  test_loss=28.0747  λ_max=1.5935\n",
      "[Adam | lr=0.1] Iter 11600: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 725/4000: train_loss=0.0000  test_loss=28.0880  λ_max=1.6482\n",
      "[Adam | lr=0.1] Epoch 726/4000: train_loss=0.0000  test_loss=28.1042  λ_max=1.5340\n",
      "[Adam | lr=0.1] Epoch 727/4000: train_loss=0.0000  test_loss=28.1183  λ_max=1.6122\n",
      "[Adam | lr=0.1] Epoch 728/4000: train_loss=0.0000  test_loss=28.1328  λ_max=1.5333\n",
      "[Adam | lr=0.1] Epoch 729/4000: train_loss=0.0000  test_loss=28.1482  λ_max=1.5311\n",
      "[Adam | lr=0.1] Epoch 730/4000: train_loss=0.0000  test_loss=28.1623  λ_max=1.4969\n",
      "[Adam | lr=0.1] Epoch 731/4000: train_loss=0.0000  test_loss=28.1769  λ_max=1.5141\n",
      "[Adam | lr=0.1] Iter 11700: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 732/4000: train_loss=0.0000  test_loss=28.1922  λ_max=1.6010\n",
      "[Adam | lr=0.1] Epoch 733/4000: train_loss=0.0000  test_loss=28.2068  λ_max=1.6608\n",
      "[Adam | lr=0.1] Epoch 734/4000: train_loss=0.0000  test_loss=28.2216  λ_max=1.5363\n",
      "[Adam | lr=0.1] Epoch 735/4000: train_loss=0.0000  test_loss=28.2362  λ_max=1.6183\n",
      "[Adam | lr=0.1] Epoch 736/4000: train_loss=0.0000  test_loss=28.2513  λ_max=1.5646\n",
      "[Adam | lr=0.1] Epoch 737/4000: train_loss=0.0000  test_loss=28.2663  λ_max=1.6364\n",
      "[Adam | lr=0.1] Iter 11800: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 738/4000: train_loss=0.0000  test_loss=28.2806  λ_max=1.5255\n",
      "[Adam | lr=0.1] Epoch 739/4000: train_loss=0.0000  test_loss=28.2959  λ_max=1.5180\n",
      "[Adam | lr=0.1] Epoch 740/4000: train_loss=0.0000  test_loss=28.3096  λ_max=1.6589\n",
      "[Adam | lr=0.1] Epoch 741/4000: train_loss=0.0000  test_loss=28.3247  λ_max=1.5680\n",
      "[Adam | lr=0.1] Epoch 742/4000: train_loss=0.0000  test_loss=28.3393  λ_max=1.5153\n",
      "[Adam | lr=0.1] Epoch 743/4000: train_loss=0.0000  test_loss=28.3547  λ_max=1.5466\n",
      "[Adam | lr=0.1] Iter 11900: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 744/4000: train_loss=0.0000  test_loss=28.3696  λ_max=1.5716\n",
      "[Adam | lr=0.1] Epoch 745/4000: train_loss=0.0000  test_loss=28.3841  λ_max=1.4867\n",
      "[Adam | lr=0.1] Epoch 746/4000: train_loss=0.0000  test_loss=28.3984  λ_max=1.6215\n",
      "[Adam | lr=0.1] Epoch 747/4000: train_loss=0.0000  test_loss=28.4136  λ_max=1.5064\n",
      "[Adam | lr=0.1] Epoch 748/4000: train_loss=0.0000  test_loss=28.4281  λ_max=1.5658\n",
      "[Adam | lr=0.1] Epoch 749/4000: train_loss=0.0000  test_loss=28.4424  λ_max=1.4192\n",
      "[Adam | lr=0.1] Iter 12000: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 750/4000: train_loss=0.0000  test_loss=28.4578  λ_max=1.5447\n",
      "[Adam | lr=0.1] Epoch 751/4000: train_loss=0.0000  test_loss=28.4722  λ_max=1.4997\n",
      "[Adam | lr=0.1] Epoch 752/4000: train_loss=0.0000  test_loss=28.4872  λ_max=1.5399\n",
      "[Adam | lr=0.1] Epoch 753/4000: train_loss=0.0000  test_loss=28.5022  λ_max=1.4905\n",
      "[Adam | lr=0.1] Epoch 754/4000: train_loss=0.0000  test_loss=28.5163  λ_max=1.4929\n",
      "[Adam | lr=0.1] Epoch 755/4000: train_loss=0.0000  test_loss=28.5310  λ_max=1.6137\n",
      "[Adam | lr=0.1] Epoch 756/4000: train_loss=0.0000  test_loss=28.5466  λ_max=1.6404\n",
      "[Adam | lr=0.1] Iter 12100: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 757/4000: train_loss=0.0000  test_loss=28.5607  λ_max=1.4018\n",
      "[Adam | lr=0.1] Epoch 758/4000: train_loss=0.0000  test_loss=28.5747  λ_max=1.5240\n",
      "[Adam | lr=0.1] Epoch 759/4000: train_loss=0.0000  test_loss=28.5902  λ_max=1.6379\n",
      "[Adam | lr=0.1] Epoch 760/4000: train_loss=0.0000  test_loss=28.6040  λ_max=1.5365\n",
      "[Adam | lr=0.1] Epoch 761/4000: train_loss=0.0000  test_loss=28.6196  λ_max=1.6511\n",
      "[Adam | lr=0.1] Epoch 762/4000: train_loss=0.0000  test_loss=28.6342  λ_max=1.5816\n",
      "[Adam | lr=0.1] Iter 12200: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 763/4000: train_loss=0.0000  test_loss=28.6480  λ_max=1.4784\n",
      "[Adam | lr=0.1] Epoch 764/4000: train_loss=0.0000  test_loss=28.6636  λ_max=1.5986\n",
      "[Adam | lr=0.1] Epoch 765/4000: train_loss=0.0000  test_loss=28.6786  λ_max=1.6476\n",
      "[Adam | lr=0.1] Epoch 766/4000: train_loss=0.0000  test_loss=28.6922  λ_max=1.4681\n",
      "[Adam | lr=0.1] Epoch 767/4000: train_loss=0.0000  test_loss=28.7076  λ_max=1.5727\n",
      "[Adam | lr=0.1] Epoch 768/4000: train_loss=0.0000  test_loss=28.7225  λ_max=1.5729\n",
      "[Adam | lr=0.1] Iter 12300: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 769/4000: train_loss=0.0000  test_loss=28.7374  λ_max=1.6065\n",
      "[Adam | lr=0.1] Epoch 770/4000: train_loss=0.0000  test_loss=28.7518  λ_max=1.5798\n",
      "[Adam | lr=0.1] Epoch 771/4000: train_loss=0.0000  test_loss=28.7669  λ_max=1.6458\n",
      "[Adam | lr=0.1] Epoch 772/4000: train_loss=0.0000  test_loss=28.7817  λ_max=1.5373\n",
      "[Adam | lr=0.1] Epoch 773/4000: train_loss=0.0000  test_loss=28.7961  λ_max=1.5381\n",
      "[Adam | lr=0.1] Epoch 774/4000: train_loss=0.0000  test_loss=28.8115  λ_max=1.5039\n",
      "[Adam | lr=0.1] Iter 12400: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 775/4000: train_loss=0.0000  test_loss=28.8250  λ_max=1.5302\n",
      "[Adam | lr=0.1] Epoch 776/4000: train_loss=0.0000  test_loss=28.8402  λ_max=1.6218\n",
      "[Adam | lr=0.1] Epoch 777/4000: train_loss=0.0000  test_loss=28.8546  λ_max=1.3934\n",
      "[Adam | lr=0.1] Epoch 778/4000: train_loss=0.0000  test_loss=28.8700  λ_max=1.5340\n",
      "[Adam | lr=0.1] Epoch 779/4000: train_loss=0.0000  test_loss=28.8848  λ_max=1.6353\n",
      "[Adam | lr=0.1] Epoch 780/4000: train_loss=0.0000  test_loss=28.8988  λ_max=1.5845\n",
      "[Adam | lr=0.1] Epoch 781/4000: train_loss=0.0000  test_loss=28.9137  λ_max=1.4817\n",
      "[Adam | lr=0.1] Iter 12500: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 782/4000: train_loss=0.0000  test_loss=28.9284  λ_max=1.6302\n",
      "[Adam | lr=0.1] Epoch 783/4000: train_loss=0.0000  test_loss=28.9434  λ_max=1.4936\n",
      "[Adam | lr=0.1] Epoch 784/4000: train_loss=0.0000  test_loss=28.9580  λ_max=1.6479\n",
      "[Adam | lr=0.1] Epoch 785/4000: train_loss=0.0000  test_loss=28.9738  λ_max=1.4957\n",
      "[Adam | lr=0.1] Epoch 786/4000: train_loss=0.0000  test_loss=28.9875  λ_max=1.4792\n",
      "[Adam | lr=0.1] Epoch 787/4000: train_loss=0.0000  test_loss=29.0017  λ_max=1.5150\n",
      "[Adam | lr=0.1] Iter 12600: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 788/4000: train_loss=0.0000  test_loss=29.0170  λ_max=1.6246\n",
      "[Adam | lr=0.1] Epoch 789/4000: train_loss=0.0000  test_loss=29.0320  λ_max=1.6179\n",
      "[Adam | lr=0.1] Epoch 790/4000: train_loss=0.0000  test_loss=29.0468  λ_max=1.5124\n",
      "[Adam | lr=0.1] Epoch 791/4000: train_loss=0.0000  test_loss=29.0604  λ_max=1.4574\n",
      "[Adam | lr=0.1] Epoch 792/4000: train_loss=0.0000  test_loss=29.0763  λ_max=1.6283\n",
      "[Adam | lr=0.1] Epoch 793/4000: train_loss=0.0000  test_loss=29.0908  λ_max=1.6435\n",
      "[Adam | lr=0.1] Iter 12700: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 794/4000: train_loss=0.0000  test_loss=29.1056  λ_max=1.5644\n",
      "[Adam | lr=0.1] Epoch 795/4000: train_loss=0.0000  test_loss=29.1203  λ_max=1.4465\n",
      "[Adam | lr=0.1] Epoch 796/4000: train_loss=0.0000  test_loss=29.1341  λ_max=1.6200\n",
      "[Adam | lr=0.1] Epoch 797/4000: train_loss=0.0000  test_loss=29.1496  λ_max=1.6224\n",
      "[Adam | lr=0.1] Epoch 798/4000: train_loss=0.0000  test_loss=29.1643  λ_max=1.6355\n",
      "[Adam | lr=0.1] Epoch 799/4000: train_loss=0.0000  test_loss=29.1790  λ_max=1.6301\n",
      "[Adam | lr=0.1] Iter 12800: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 800/4000: train_loss=0.0000  test_loss=29.1935  λ_max=1.4826\n",
      "[Adam | lr=0.1] Epoch 801/4000: train_loss=0.0000  test_loss=29.2090  λ_max=1.6006\n",
      "[Adam | lr=0.1] Epoch 802/4000: train_loss=0.0000  test_loss=29.2226  λ_max=1.5654\n",
      "[Adam | lr=0.1] Epoch 803/4000: train_loss=0.0000  test_loss=29.2366  λ_max=1.4914\n",
      "[Adam | lr=0.1] Epoch 804/4000: train_loss=0.0000  test_loss=29.2524  λ_max=1.6346\n",
      "[Adam | lr=0.1] Epoch 805/4000: train_loss=0.0000  test_loss=29.2668  λ_max=1.4383\n",
      "[Adam | lr=0.1] Epoch 806/4000: train_loss=0.0000  test_loss=29.2822  λ_max=1.5524\n",
      "[Adam | lr=0.1] Iter 12900: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 807/4000: train_loss=0.0000  test_loss=29.2965  λ_max=1.4926\n",
      "[Adam | lr=0.1] Epoch 808/4000: train_loss=0.0000  test_loss=29.3099  λ_max=1.5575\n",
      "[Adam | lr=0.1] Epoch 809/4000: train_loss=0.0000  test_loss=29.3262  λ_max=1.6070\n",
      "[Adam | lr=0.1] Epoch 810/4000: train_loss=0.0000  test_loss=29.3397  λ_max=1.6378\n",
      "[Adam | lr=0.1] Epoch 811/4000: train_loss=0.0000  test_loss=29.3535  λ_max=1.4775\n",
      "[Adam | lr=0.1] Epoch 812/4000: train_loss=0.0000  test_loss=29.3699  λ_max=1.6402\n",
      "[Adam | lr=0.1] Iter 13000: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 813/4000: train_loss=0.0000  test_loss=29.3836  λ_max=1.5797\n",
      "[Adam | lr=0.1] Epoch 814/4000: train_loss=0.0000  test_loss=29.3980  λ_max=1.5013\n",
      "[Adam | lr=0.1] Epoch 815/4000: train_loss=0.0000  test_loss=29.4126  λ_max=1.5048\n",
      "[Adam | lr=0.1] Epoch 816/4000: train_loss=0.0000  test_loss=29.4270  λ_max=1.4040\n",
      "[Adam | lr=0.1] Epoch 817/4000: train_loss=0.0000  test_loss=29.4418  λ_max=1.5992\n",
      "[Adam | lr=0.1] Epoch 818/4000: train_loss=0.0000  test_loss=29.4571  λ_max=1.5847\n",
      "[Adam | lr=0.1] Iter 13100: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 819/4000: train_loss=0.0000  test_loss=29.4708  λ_max=1.5735\n",
      "[Adam | lr=0.1] Epoch 820/4000: train_loss=0.0000  test_loss=29.4859  λ_max=1.5444\n",
      "[Adam | lr=0.1] Epoch 821/4000: train_loss=0.0000  test_loss=29.5008  λ_max=1.6222\n",
      "[Adam | lr=0.1] Epoch 822/4000: train_loss=0.0000  test_loss=29.5157  λ_max=1.6295\n",
      "[Adam | lr=0.1] Epoch 823/4000: train_loss=0.0000  test_loss=29.5285  λ_max=1.6132\n",
      "[Adam | lr=0.1] Epoch 824/4000: train_loss=0.0000  test_loss=29.5441  λ_max=1.3555\n",
      "[Adam | lr=0.1] Iter 13200: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 825/4000: train_loss=0.0000  test_loss=29.5585  λ_max=1.5738\n",
      "[Adam | lr=0.1] Epoch 826/4000: train_loss=0.0000  test_loss=29.5728  λ_max=1.6352\n",
      "[Adam | lr=0.1] Epoch 827/4000: train_loss=0.0000  test_loss=29.5871  λ_max=1.6361\n",
      "[Adam | lr=0.1] Epoch 828/4000: train_loss=0.0000  test_loss=29.6016  λ_max=1.5917\n",
      "[Adam | lr=0.1] Epoch 829/4000: train_loss=0.0000  test_loss=29.6161  λ_max=1.4987\n",
      "[Adam | lr=0.1] Epoch 830/4000: train_loss=0.0000  test_loss=29.6313  λ_max=1.5934\n",
      "[Adam | lr=0.1] Epoch 831/4000: train_loss=0.0000  test_loss=29.6458  λ_max=1.5291\n",
      "[Adam | lr=0.1] Iter 13300: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 832/4000: train_loss=0.0000  test_loss=29.6613  λ_max=1.5959\n",
      "[Adam | lr=0.1] Epoch 833/4000: train_loss=0.0000  test_loss=29.6750  λ_max=1.5990\n",
      "[Adam | lr=0.1] Epoch 834/4000: train_loss=0.0000  test_loss=29.6881  λ_max=1.4988\n",
      "[Adam | lr=0.1] Epoch 835/4000: train_loss=0.0000  test_loss=29.7044  λ_max=1.5257\n",
      "[Adam | lr=0.1] Epoch 836/4000: train_loss=0.0000  test_loss=29.7174  λ_max=1.6278\n",
      "[Adam | lr=0.1] Epoch 837/4000: train_loss=0.0000  test_loss=29.7327  λ_max=1.6221\n",
      "[Adam | lr=0.1] Iter 13400: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 838/4000: train_loss=0.0000  test_loss=29.7473  λ_max=1.6371\n",
      "[Adam | lr=0.1] Epoch 839/4000: train_loss=0.0000  test_loss=29.7612  λ_max=1.5275\n",
      "[Adam | lr=0.1] Epoch 840/4000: train_loss=0.0000  test_loss=29.7760  λ_max=1.4676\n",
      "[Adam | lr=0.1] Epoch 841/4000: train_loss=0.0000  test_loss=29.7911  λ_max=1.5806\n",
      "[Adam | lr=0.1] Epoch 842/4000: train_loss=0.0000  test_loss=29.8047  λ_max=1.5465\n",
      "[Adam | lr=0.1] Epoch 843/4000: train_loss=0.0000  test_loss=29.8189  λ_max=1.5402\n",
      "[Adam | lr=0.1] Iter 13500: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 844/4000: train_loss=0.0000  test_loss=29.8332  λ_max=1.6315\n",
      "[Adam | lr=0.1] Epoch 845/4000: train_loss=0.0000  test_loss=29.8486  λ_max=1.5959\n",
      "[Adam | lr=0.1] Epoch 846/4000: train_loss=0.0000  test_loss=29.8620  λ_max=1.6122\n",
      "[Adam | lr=0.1] Epoch 847/4000: train_loss=0.0000  test_loss=29.8767  λ_max=1.5420\n",
      "[Adam | lr=0.1] Epoch 848/4000: train_loss=0.0000  test_loss=29.8919  λ_max=1.5643\n",
      "[Adam | lr=0.1] Epoch 849/4000: train_loss=0.0000  test_loss=29.9054  λ_max=1.4760\n",
      "[Adam | lr=0.1] Iter 13600: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 850/4000: train_loss=0.0000  test_loss=29.9200  λ_max=1.5743\n",
      "[Adam | lr=0.1] Epoch 851/4000: train_loss=0.0000  test_loss=29.9338  λ_max=1.4896\n",
      "[Adam | lr=0.1] Epoch 852/4000: train_loss=0.0000  test_loss=29.9489  λ_max=1.5533\n",
      "[Adam | lr=0.1] Epoch 853/4000: train_loss=0.0000  test_loss=29.9632  λ_max=1.5932\n",
      "[Adam | lr=0.1] Epoch 854/4000: train_loss=0.0000  test_loss=29.9780  λ_max=1.5253\n",
      "[Adam | lr=0.1] Epoch 855/4000: train_loss=0.0000  test_loss=29.9918  λ_max=1.5906\n",
      "[Adam | lr=0.1] Epoch 856/4000: train_loss=0.0000  test_loss=30.0058  λ_max=1.5605\n",
      "[Adam | lr=0.1] Iter 13700: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 857/4000: train_loss=0.0000  test_loss=30.0204  λ_max=1.6094\n",
      "[Adam | lr=0.1] Epoch 858/4000: train_loss=0.0000  test_loss=30.0337  λ_max=1.5725\n",
      "[Adam | lr=0.1] Epoch 859/4000: train_loss=0.0000  test_loss=30.0489  λ_max=1.5852\n",
      "[Adam | lr=0.1] Epoch 860/4000: train_loss=0.0000  test_loss=30.0629  λ_max=1.4848\n",
      "[Adam | lr=0.1] Epoch 861/4000: train_loss=0.0000  test_loss=30.0772  λ_max=1.3820\n",
      "[Adam | lr=0.1] Epoch 862/4000: train_loss=0.0000  test_loss=30.0919  λ_max=1.5896\n",
      "[Adam | lr=0.1] Iter 13800: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 863/4000: train_loss=0.0000  test_loss=30.1053  λ_max=1.4949\n",
      "[Adam | lr=0.1] Epoch 864/4000: train_loss=0.0000  test_loss=30.1207  λ_max=1.5904\n",
      "[Adam | lr=0.1] Epoch 865/4000: train_loss=0.0000  test_loss=30.1336  λ_max=1.4476\n",
      "[Adam | lr=0.1] Epoch 866/4000: train_loss=0.0000  test_loss=30.1493  λ_max=1.4528\n",
      "[Adam | lr=0.1] Epoch 867/4000: train_loss=0.0000  test_loss=30.1631  λ_max=1.4281\n",
      "[Adam | lr=0.1] Epoch 868/4000: train_loss=0.0000  test_loss=30.1762  λ_max=1.5555\n",
      "[Adam | lr=0.1] Iter 13900: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 869/4000: train_loss=0.0000  test_loss=30.1916  λ_max=1.5163\n",
      "[Adam | lr=0.1] Epoch 870/4000: train_loss=0.0000  test_loss=30.2046  λ_max=1.5498\n",
      "[Adam | lr=0.1] Epoch 871/4000: train_loss=0.0000  test_loss=30.2200  λ_max=1.5368\n",
      "[Adam | lr=0.1] Epoch 872/4000: train_loss=0.0000  test_loss=30.2338  λ_max=1.5039\n",
      "[Adam | lr=0.1] Epoch 873/4000: train_loss=0.0000  test_loss=30.2483  λ_max=1.5183\n",
      "[Adam | lr=0.1] Epoch 874/4000: train_loss=0.0000  test_loss=30.2615  λ_max=1.5858\n",
      "[Adam | lr=0.1] Iter 14000: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 875/4000: train_loss=0.0000  test_loss=30.2763  λ_max=1.5282\n",
      "[Adam | lr=0.1] Epoch 876/4000: train_loss=0.0000  test_loss=30.2900  λ_max=1.5419\n",
      "[Adam | lr=0.1] Epoch 877/4000: train_loss=0.0000  test_loss=30.3038  λ_max=1.4525\n",
      "[Adam | lr=0.1] Epoch 878/4000: train_loss=0.0000  test_loss=30.3192  λ_max=1.4814\n",
      "[Adam | lr=0.1] Epoch 879/4000: train_loss=0.0000  test_loss=30.3327  λ_max=1.4243\n",
      "[Adam | lr=0.1] Epoch 880/4000: train_loss=0.0000  test_loss=30.3470  λ_max=1.5387\n",
      "[Adam | lr=0.1] Epoch 881/4000: train_loss=0.0000  test_loss=30.3612  λ_max=1.3989\n",
      "[Adam | lr=0.1] Iter 14100: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 882/4000: train_loss=0.0000  test_loss=30.3748  λ_max=1.5116\n",
      "[Adam | lr=0.1] Epoch 883/4000: train_loss=0.0000  test_loss=30.3885  λ_max=1.6039\n",
      "[Adam | lr=0.1] Epoch 884/4000: train_loss=0.0000  test_loss=30.4029  λ_max=1.3931\n",
      "[Adam | lr=0.1] Epoch 885/4000: train_loss=0.0000  test_loss=30.4169  λ_max=1.5696\n",
      "[Adam | lr=0.1] Epoch 886/4000: train_loss=0.0000  test_loss=30.4308  λ_max=1.4026\n",
      "[Adam | lr=0.1] Epoch 887/4000: train_loss=0.0000  test_loss=30.4446  λ_max=1.5714\n",
      "[Adam | lr=0.1] Iter 14200: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 888/4000: train_loss=0.0000  test_loss=30.4592  λ_max=1.5150\n",
      "[Adam | lr=0.1] Epoch 889/4000: train_loss=0.0000  test_loss=30.4732  λ_max=1.5938\n",
      "[Adam | lr=0.1] Epoch 890/4000: train_loss=0.0000  test_loss=30.4874  λ_max=1.5661\n",
      "[Adam | lr=0.1] Epoch 891/4000: train_loss=0.0000  test_loss=30.5003  λ_max=1.5680\n",
      "[Adam | lr=0.1] Epoch 892/4000: train_loss=0.0000  test_loss=30.5152  λ_max=1.4999\n",
      "[Adam | lr=0.1] Epoch 893/4000: train_loss=0.0000  test_loss=30.5276  λ_max=1.5693\n",
      "[Adam | lr=0.1] Iter 14300: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 894/4000: train_loss=0.0000  test_loss=30.5424  λ_max=1.6061\n",
      "[Adam | lr=0.1] Epoch 895/4000: train_loss=0.0000  test_loss=30.5547  λ_max=1.4286\n",
      "[Adam | lr=0.1] Epoch 896/4000: train_loss=0.0000  test_loss=30.5706  λ_max=1.4888\n",
      "[Adam | lr=0.1] Epoch 897/4000: train_loss=0.0000  test_loss=30.5837  λ_max=1.5289\n",
      "[Adam | lr=0.1] Epoch 898/4000: train_loss=0.0000  test_loss=30.5969  λ_max=1.6104\n",
      "[Adam | lr=0.1] Epoch 899/4000: train_loss=0.0000  test_loss=30.6108  λ_max=1.5428\n",
      "[Adam | lr=0.1] Iter 14400: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 900/4000: train_loss=0.0000  test_loss=30.6247  λ_max=1.4855\n",
      "[Adam | lr=0.1] Epoch 901/4000: train_loss=0.0000  test_loss=30.6378  λ_max=1.3889\n",
      "[Adam | lr=0.1] Epoch 902/4000: train_loss=0.0000  test_loss=30.6515  λ_max=1.5659\n",
      "[Adam | lr=0.1] Epoch 903/4000: train_loss=0.0000  test_loss=30.6651  λ_max=1.4501\n",
      "[Adam | lr=0.1] Epoch 904/4000: train_loss=0.0000  test_loss=30.6803  λ_max=1.5902\n",
      "[Adam | lr=0.1] Epoch 905/4000: train_loss=0.0000  test_loss=30.6939  λ_max=1.5582\n",
      "[Adam | lr=0.1] Epoch 906/4000: train_loss=0.0000  test_loss=30.7076  λ_max=1.4658\n",
      "[Adam | lr=0.1] Iter 14500: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 907/4000: train_loss=0.0000  test_loss=30.7207  λ_max=1.6021\n",
      "[Adam | lr=0.1] Epoch 908/4000: train_loss=0.0000  test_loss=30.7356  λ_max=1.5334\n",
      "[Adam | lr=0.1] Epoch 909/4000: train_loss=0.0000  test_loss=30.7487  λ_max=1.4741\n",
      "[Adam | lr=0.1] Epoch 910/4000: train_loss=0.0000  test_loss=30.7627  λ_max=1.6126\n",
      "[Adam | lr=0.1] Epoch 911/4000: train_loss=0.0000  test_loss=30.7757  λ_max=1.4487\n",
      "[Adam | lr=0.1] Epoch 912/4000: train_loss=0.0000  test_loss=30.7910  λ_max=1.5670\n",
      "[Adam | lr=0.1] Iter 14600: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 913/4000: train_loss=0.0000  test_loss=30.8038  λ_max=1.5880\n",
      "[Adam | lr=0.1] Epoch 914/4000: train_loss=0.0000  test_loss=30.8179  λ_max=1.5793\n",
      "[Adam | lr=0.1] Epoch 915/4000: train_loss=0.0000  test_loss=30.8320  λ_max=1.6011\n",
      "[Adam | lr=0.1] Epoch 916/4000: train_loss=0.0000  test_loss=30.8453  λ_max=1.4020\n",
      "[Adam | lr=0.1] Epoch 917/4000: train_loss=0.0000  test_loss=30.8585  λ_max=1.5634\n",
      "[Adam | lr=0.1] Epoch 918/4000: train_loss=0.0000  test_loss=30.8720  λ_max=1.4814\n",
      "[Adam | lr=0.1] Iter 14700: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 919/4000: train_loss=0.0000  test_loss=30.8861  λ_max=1.5897\n",
      "[Adam | lr=0.1] Epoch 920/4000: train_loss=0.0000  test_loss=30.8988  λ_max=1.5330\n",
      "[Adam | lr=0.1] Epoch 921/4000: train_loss=0.0000  test_loss=30.9127  λ_max=1.5751\n",
      "[Adam | lr=0.1] Epoch 922/4000: train_loss=0.0000  test_loss=30.9260  λ_max=1.4868\n",
      "[Adam | lr=0.1] Epoch 923/4000: train_loss=0.0000  test_loss=30.9398  λ_max=1.4291\n",
      "[Adam | lr=0.1] Epoch 924/4000: train_loss=0.0000  test_loss=30.9544  λ_max=1.5185\n",
      "[Adam | lr=0.1] Iter 14800: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 925/4000: train_loss=0.0000  test_loss=30.9659  λ_max=1.5206\n",
      "[Adam | lr=0.1] Epoch 926/4000: train_loss=0.0000  test_loss=30.9810  λ_max=1.5383\n",
      "[Adam | lr=0.1] Epoch 927/4000: train_loss=0.0000  test_loss=30.9935  λ_max=1.5826\n",
      "[Adam | lr=0.1] Epoch 928/4000: train_loss=0.0000  test_loss=31.0083  λ_max=1.5583\n",
      "[Adam | lr=0.1] Epoch 929/4000: train_loss=0.0000  test_loss=31.0205  λ_max=1.5576\n",
      "[Adam | lr=0.1] Epoch 930/4000: train_loss=0.0000  test_loss=31.0347  λ_max=1.4669\n",
      "[Adam | lr=0.1] Epoch 931/4000: train_loss=0.0000  test_loss=31.0475  λ_max=1.6082\n",
      "[Adam | lr=0.1] Iter 14900: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 932/4000: train_loss=0.0000  test_loss=31.0608  λ_max=1.5169\n",
      "[Adam | lr=0.1] Epoch 933/4000: train_loss=0.0000  test_loss=31.0738  λ_max=1.6022\n",
      "[Adam | lr=0.1] Epoch 934/4000: train_loss=0.0000  test_loss=31.0880  λ_max=1.4965\n",
      "[Adam | lr=0.1] Epoch 935/4000: train_loss=0.0000  test_loss=31.0998  λ_max=1.6027\n",
      "[Adam | lr=0.1] Epoch 936/4000: train_loss=0.0000  test_loss=31.1139  λ_max=1.4849\n",
      "[Adam | lr=0.1] Epoch 937/4000: train_loss=0.0000  test_loss=31.1269  λ_max=1.4058\n",
      "[Adam | lr=0.1] Iter 15000: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 938/4000: train_loss=0.0000  test_loss=31.1388  λ_max=1.4471\n",
      "[Adam | lr=0.1] Epoch 939/4000: train_loss=0.0000  test_loss=31.1525  λ_max=1.5320\n",
      "[Adam | lr=0.1] Epoch 940/4000: train_loss=0.0000  test_loss=31.1667  λ_max=1.3895\n",
      "[Adam | lr=0.1] Epoch 941/4000: train_loss=0.0000  test_loss=31.1796  λ_max=1.4627\n",
      "[Adam | lr=0.1] Epoch 942/4000: train_loss=0.0000  test_loss=31.1923  λ_max=1.5810\n",
      "[Adam | lr=0.1] Epoch 943/4000: train_loss=0.0000  test_loss=31.2057  λ_max=1.5876\n",
      "[Adam | lr=0.1] Iter 15100: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 944/4000: train_loss=0.0000  test_loss=31.2186  λ_max=1.5809\n",
      "[Adam | lr=0.1] Epoch 945/4000: train_loss=0.0000  test_loss=31.2313  λ_max=1.5460\n",
      "[Adam | lr=0.1] Epoch 946/4000: train_loss=0.0000  test_loss=31.2446  λ_max=1.5036\n",
      "[Adam | lr=0.1] Epoch 947/4000: train_loss=0.0000  test_loss=31.2564  λ_max=1.4254\n",
      "[Adam | lr=0.1] Epoch 948/4000: train_loss=0.0000  test_loss=31.2707  λ_max=1.5407\n",
      "[Adam | lr=0.1] Epoch 949/4000: train_loss=0.0000  test_loss=31.2829  λ_max=1.5468\n",
      "[Adam | lr=0.1] Iter 15200: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 950/4000: train_loss=0.0000  test_loss=31.2951  λ_max=1.4961\n",
      "[Adam | lr=0.1] Epoch 951/4000: train_loss=0.0000  test_loss=31.3080  λ_max=1.5601\n",
      "[Adam | lr=0.1] Epoch 952/4000: train_loss=0.0000  test_loss=31.3207  λ_max=1.4514\n",
      "[Adam | lr=0.1] Epoch 953/4000: train_loss=0.0000  test_loss=31.3339  λ_max=1.5185\n",
      "[Adam | lr=0.1] Epoch 954/4000: train_loss=0.0000  test_loss=31.3465  λ_max=1.4921\n",
      "[Adam | lr=0.1] Epoch 955/4000: train_loss=0.0000  test_loss=31.3596  λ_max=1.5121\n",
      "[Adam | lr=0.1] Epoch 956/4000: train_loss=0.0000  test_loss=31.3708  λ_max=1.5790\n",
      "[Adam | lr=0.1] Iter 15300: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 957/4000: train_loss=0.0000  test_loss=31.3841  λ_max=1.5978\n",
      "[Adam | lr=0.1] Epoch 958/4000: train_loss=0.0000  test_loss=31.3968  λ_max=1.5551\n",
      "[Adam | lr=0.1] Epoch 959/4000: train_loss=0.0000  test_loss=31.4095  λ_max=1.5614\n",
      "[Adam | lr=0.1] Epoch 960/4000: train_loss=0.0000  test_loss=31.4216  λ_max=1.4154\n",
      "[Adam | lr=0.1] Epoch 961/4000: train_loss=0.0000  test_loss=31.4344  λ_max=1.5353\n",
      "[Adam | lr=0.1] Epoch 962/4000: train_loss=0.0000  test_loss=31.4472  λ_max=1.5205\n",
      "[Adam | lr=0.1] Iter 15400: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 963/4000: train_loss=0.0000  test_loss=31.4590  λ_max=1.4784\n",
      "[Adam | lr=0.1] Epoch 964/4000: train_loss=0.0000  test_loss=31.4722  λ_max=1.5191\n",
      "[Adam | lr=0.1] Epoch 965/4000: train_loss=0.0000  test_loss=31.4837  λ_max=1.4635\n",
      "[Adam | lr=0.1] Epoch 966/4000: train_loss=0.0000  test_loss=31.4965  λ_max=1.5078\n",
      "[Adam | lr=0.1] Epoch 967/4000: train_loss=0.0000  test_loss=31.5089  λ_max=1.4747\n",
      "[Adam | lr=0.1] Epoch 968/4000: train_loss=0.0000  test_loss=31.5207  λ_max=1.4839\n",
      "[Adam | lr=0.1] Iter 15500: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 969/4000: train_loss=0.0000  test_loss=31.5334  λ_max=1.4815\n",
      "[Adam | lr=0.1] Epoch 970/4000: train_loss=0.0000  test_loss=31.5456  λ_max=1.3985\n",
      "[Adam | lr=0.1] Epoch 971/4000: train_loss=0.0000  test_loss=31.5580  λ_max=1.5979\n",
      "[Adam | lr=0.1] Epoch 972/4000: train_loss=0.0000  test_loss=31.5703  λ_max=1.5486\n",
      "[Adam | lr=0.1] Epoch 973/4000: train_loss=0.0000  test_loss=31.5816  λ_max=1.4635\n",
      "[Adam | lr=0.1] Epoch 974/4000: train_loss=0.0000  test_loss=31.5944  λ_max=1.4719\n",
      "[Adam | lr=0.1] Iter 15600: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 975/4000: train_loss=0.0000  test_loss=31.6062  λ_max=1.4704\n",
      "[Adam | lr=0.1] Epoch 976/4000: train_loss=0.0000  test_loss=31.6172  λ_max=1.5405\n",
      "[Adam | lr=0.1] Epoch 977/4000: train_loss=0.0000  test_loss=31.6300  λ_max=1.4522\n",
      "[Adam | lr=0.1] Epoch 978/4000: train_loss=0.0000  test_loss=31.6417  λ_max=1.5022\n",
      "[Adam | lr=0.1] Epoch 979/4000: train_loss=0.0000  test_loss=31.6526  λ_max=1.5511\n",
      "[Adam | lr=0.1] Epoch 980/4000: train_loss=0.0000  test_loss=31.6647  λ_max=1.5106\n",
      "[Adam | lr=0.1] Epoch 981/4000: train_loss=0.0000  test_loss=31.6768  λ_max=1.5467\n",
      "[Adam | lr=0.1] Iter 15700: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 982/4000: train_loss=0.0000  test_loss=31.6888  λ_max=1.4574\n",
      "[Adam | lr=0.1] Epoch 983/4000: train_loss=0.0000  test_loss=31.6987  λ_max=1.4357\n",
      "[Adam | lr=0.1] Epoch 984/4000: train_loss=0.0000  test_loss=31.7111  λ_max=1.5000\n",
      "[Adam | lr=0.1] Epoch 985/4000: train_loss=0.0000  test_loss=31.7222  λ_max=1.4579\n",
      "[Adam | lr=0.1] Epoch 986/4000: train_loss=0.0000  test_loss=31.7349  λ_max=1.5756\n",
      "[Adam | lr=0.1] Epoch 987/4000: train_loss=0.0000  test_loss=31.7445  λ_max=1.4613\n",
      "[Adam | lr=0.1] Iter 15800: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 988/4000: train_loss=0.0000  test_loss=31.7561  λ_max=1.3642\n",
      "[Adam | lr=0.1] Epoch 989/4000: train_loss=0.0000  test_loss=31.7676  λ_max=1.5093\n",
      "[Adam | lr=0.1] Epoch 990/4000: train_loss=0.0000  test_loss=31.7791  λ_max=1.4690\n",
      "[Adam | lr=0.1] Epoch 991/4000: train_loss=0.0000  test_loss=31.7898  λ_max=1.4860\n",
      "[Adam | lr=0.1] Epoch 992/4000: train_loss=0.0000  test_loss=31.8011  λ_max=1.4631\n",
      "[Adam | lr=0.1] Epoch 993/4000: train_loss=0.0000  test_loss=31.8118  λ_max=1.4211\n",
      "[Adam | lr=0.1] Iter 15900: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 994/4000: train_loss=0.0000  test_loss=31.8232  λ_max=1.5339\n",
      "[Adam | lr=0.1] Epoch 995/4000: train_loss=0.0000  test_loss=31.8340  λ_max=1.4363\n",
      "[Adam | lr=0.1] Epoch 996/4000: train_loss=0.0000  test_loss=31.8446  λ_max=1.5909\n",
      "[Adam | lr=0.1] Epoch 997/4000: train_loss=0.0000  test_loss=31.8560  λ_max=1.4233\n",
      "[Adam | lr=0.1] Epoch 998/4000: train_loss=0.0000  test_loss=31.8666  λ_max=1.5463\n",
      "[Adam | lr=0.1] Epoch 999/4000: train_loss=0.0000  test_loss=31.8779  λ_max=1.4599\n",
      "[Adam | lr=0.1] Iter 16000: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 1000/4000: train_loss=0.0000  test_loss=31.8884  λ_max=1.5257\n",
      "[Adam | lr=0.1] Epoch 1001/4000: train_loss=0.0000  test_loss=31.8990  λ_max=1.5195\n",
      "[Adam | lr=0.1] Epoch 1002/4000: train_loss=0.0000  test_loss=31.9100  λ_max=1.4547\n",
      "[Adam | lr=0.1] Epoch 1003/4000: train_loss=0.0000  test_loss=31.9210  λ_max=1.4779\n",
      "[Adam | lr=0.1] Epoch 1004/4000: train_loss=0.0000  test_loss=31.9308  λ_max=1.5547\n",
      "[Adam | lr=0.1] Epoch 1005/4000: train_loss=0.0000  test_loss=31.9427  λ_max=1.5892\n",
      "[Adam | lr=0.1] Epoch 1006/4000: train_loss=0.0000  test_loss=31.9526  λ_max=1.5752\n",
      "[Adam | lr=0.1] Iter 16100: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 1007/4000: train_loss=0.0000  test_loss=31.9626  λ_max=1.4202\n",
      "[Adam | lr=0.1] Epoch 1008/4000: train_loss=0.0000  test_loss=31.9736  λ_max=1.5735\n",
      "[Adam | lr=0.1] Epoch 1009/4000: train_loss=0.0000  test_loss=31.9842  λ_max=1.5681\n",
      "[Adam | lr=0.1] Epoch 1010/4000: train_loss=0.0000  test_loss=31.9946  λ_max=1.4657\n",
      "[Adam | lr=0.1] Epoch 1011/4000: train_loss=0.0000  test_loss=32.0044  λ_max=1.5381\n",
      "[Adam | lr=0.1] Epoch 1012/4000: train_loss=0.0000  test_loss=32.0142  λ_max=1.5838\n",
      "[Adam | lr=0.1] Iter 16200: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 1013/4000: train_loss=0.0000  test_loss=32.0251  λ_max=1.4468\n",
      "[Adam | lr=0.1] Epoch 1014/4000: train_loss=0.0000  test_loss=32.0345  λ_max=1.4914\n",
      "[Adam | lr=0.1] Epoch 1015/4000: train_loss=0.0000  test_loss=32.0446  λ_max=1.4531\n",
      "[Adam | lr=0.1] Epoch 1016/4000: train_loss=0.0000  test_loss=32.0546  λ_max=1.5766\n",
      "[Adam | lr=0.1] Epoch 1017/4000: train_loss=0.0000  test_loss=32.0637  λ_max=1.4930\n",
      "[Adam | lr=0.1] Epoch 1018/4000: train_loss=0.0000  test_loss=32.0747  λ_max=1.4641\n",
      "[Adam | lr=0.1] Iter 16300: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 1019/4000: train_loss=0.0000  test_loss=32.0835  λ_max=1.5077\n",
      "[Adam | lr=0.1] Epoch 1020/4000: train_loss=0.0000  test_loss=32.0943  λ_max=1.4704\n",
      "[Adam | lr=0.1] Epoch 1021/4000: train_loss=0.0000  test_loss=32.1026  λ_max=1.5332\n",
      "[Adam | lr=0.1] Epoch 1022/4000: train_loss=0.0000  test_loss=32.1119  λ_max=1.3931\n",
      "[Adam | lr=0.1] Epoch 1023/4000: train_loss=0.0000  test_loss=32.1226  λ_max=1.5484\n",
      "[Adam | lr=0.1] Epoch 1024/4000: train_loss=0.0000  test_loss=32.1306  λ_max=1.5664\n",
      "[Adam | lr=0.1] Iter 16400: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 1025/4000: train_loss=0.0000  test_loss=32.1399  λ_max=1.4900\n",
      "[Adam | lr=0.1] Epoch 1026/4000: train_loss=0.0000  test_loss=32.1499  λ_max=1.3688\n",
      "[Adam | lr=0.1] Epoch 1027/4000: train_loss=0.0000  test_loss=32.1589  λ_max=1.4673\n",
      "[Adam | lr=0.1] Epoch 1028/4000: train_loss=0.0000  test_loss=32.1685  λ_max=1.5484\n",
      "[Adam | lr=0.1] Epoch 1029/4000: train_loss=0.0000  test_loss=32.1773  λ_max=1.5059\n",
      "[Adam | lr=0.1] Epoch 1030/4000: train_loss=0.0000  test_loss=32.1886  λ_max=1.4892\n",
      "[Adam | lr=0.1] Epoch 1031/4000: train_loss=0.0000  test_loss=32.1955  λ_max=1.4908\n",
      "[Adam | lr=0.1] Iter 16500: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 1032/4000: train_loss=0.0000  test_loss=32.2055  λ_max=1.5693\n",
      "[Adam | lr=0.1] Epoch 1033/4000: train_loss=0.0000  test_loss=32.2142  λ_max=1.4569\n",
      "[Adam | lr=0.1] Epoch 1034/4000: train_loss=0.0000  test_loss=32.2244  λ_max=1.5716\n",
      "[Adam | lr=0.1] Epoch 1035/4000: train_loss=0.0000  test_loss=32.2324  λ_max=1.4872\n",
      "[Adam | lr=0.1] Epoch 1036/4000: train_loss=0.0000  test_loss=32.2413  λ_max=1.5063\n",
      "[Adam | lr=0.1] Epoch 1037/4000: train_loss=0.0000  test_loss=32.2498  λ_max=1.5785\n",
      "[Adam | lr=0.1] Iter 16600: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 1038/4000: train_loss=0.0000  test_loss=32.2586  λ_max=1.4341\n",
      "[Adam | lr=0.1] Epoch 1039/4000: train_loss=0.0000  test_loss=32.2681  λ_max=1.4565\n",
      "[Adam | lr=0.1] Epoch 1040/4000: train_loss=0.0000  test_loss=32.2767  λ_max=1.4719\n",
      "[Adam | lr=0.1] Epoch 1041/4000: train_loss=0.0000  test_loss=32.2844  λ_max=1.5203\n",
      "[Adam | lr=0.1] Epoch 1042/4000: train_loss=0.0000  test_loss=32.2944  λ_max=1.5360\n",
      "[Adam | lr=0.1] Epoch 1043/4000: train_loss=0.0000  test_loss=32.3032  λ_max=1.4253\n",
      "[Adam | lr=0.1] Iter 16700: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 1044/4000: train_loss=0.0000  test_loss=32.3113  λ_max=1.4540\n",
      "[Adam | lr=0.1] Epoch 1045/4000: train_loss=0.0000  test_loss=32.3192  λ_max=1.4795\n",
      "[Adam | lr=0.1] Epoch 1046/4000: train_loss=0.0000  test_loss=32.3279  λ_max=1.5246\n",
      "[Adam | lr=0.1] Epoch 1047/4000: train_loss=0.0000  test_loss=32.3364  λ_max=1.4979\n",
      "[Adam | lr=0.1] Epoch 1048/4000: train_loss=0.0000  test_loss=32.3437  λ_max=1.4997\n",
      "[Adam | lr=0.1] Epoch 1049/4000: train_loss=0.0000  test_loss=32.3532  λ_max=1.5691\n",
      "[Adam | lr=0.1] Iter 16800: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 1050/4000: train_loss=0.0000  test_loss=32.3616  λ_max=1.4824\n",
      "[Adam | lr=0.1] Epoch 1051/4000: train_loss=0.0000  test_loss=32.3686  λ_max=1.3835\n",
      "[Adam | lr=0.1] Epoch 1052/4000: train_loss=0.0000  test_loss=32.3756  λ_max=1.5015\n",
      "[Adam | lr=0.1] Epoch 1053/4000: train_loss=0.0000  test_loss=32.3842  λ_max=1.4754\n",
      "[Adam | lr=0.1] Epoch 1054/4000: train_loss=0.0000  test_loss=32.3914  λ_max=1.4691\n",
      "[Adam | lr=0.1] Epoch 1055/4000: train_loss=0.0000  test_loss=32.3994  λ_max=1.5174\n",
      "[Adam | lr=0.1] Epoch 1056/4000: train_loss=0.0000  test_loss=32.4055  λ_max=1.5350\n",
      "[Adam | lr=0.1] Iter 16900: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 1057/4000: train_loss=0.0000  test_loss=32.4131  λ_max=1.4838\n",
      "[Adam | lr=0.1] Epoch 1058/4000: train_loss=0.0000  test_loss=32.4222  λ_max=1.5053\n",
      "[Adam | lr=0.1] Epoch 1059/4000: train_loss=0.0000  test_loss=32.4273  λ_max=1.5114\n",
      "[Adam | lr=0.1] Epoch 1060/4000: train_loss=0.0000  test_loss=32.4353  λ_max=1.4836\n",
      "[Adam | lr=0.1] Epoch 1061/4000: train_loss=0.0000  test_loss=32.4419  λ_max=1.4697\n",
      "[Adam | lr=0.1] Epoch 1062/4000: train_loss=0.0000  test_loss=32.4498  λ_max=1.4468\n",
      "[Adam | lr=0.1] Iter 17000: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 1063/4000: train_loss=0.0000  test_loss=32.4573  λ_max=1.5341\n",
      "[Adam | lr=0.1] Epoch 1064/4000: train_loss=0.0000  test_loss=32.4633  λ_max=1.5415\n",
      "[Adam | lr=0.1] Epoch 1065/4000: train_loss=0.0000  test_loss=32.4715  λ_max=1.5575\n",
      "[Adam | lr=0.1] Epoch 1066/4000: train_loss=0.0000  test_loss=32.4767  λ_max=1.4671\n",
      "[Adam | lr=0.1] Epoch 1067/4000: train_loss=0.0000  test_loss=32.4826  λ_max=1.5166\n",
      "[Adam | lr=0.1] Epoch 1068/4000: train_loss=0.0000  test_loss=32.4906  λ_max=1.5680\n",
      "[Adam | lr=0.1] Iter 17100: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 1069/4000: train_loss=0.0000  test_loss=32.4953  λ_max=1.4513\n",
      "[Adam | lr=0.1] Epoch 1070/4000: train_loss=0.0000  test_loss=32.5030  λ_max=1.3667\n",
      "[Adam | lr=0.1] Epoch 1071/4000: train_loss=0.0000  test_loss=32.5093  λ_max=1.4498\n",
      "[Adam | lr=0.1] Epoch 1072/4000: train_loss=0.0000  test_loss=32.5157  λ_max=1.4997\n",
      "[Adam | lr=0.1] Epoch 1073/4000: train_loss=0.0000  test_loss=32.5209  λ_max=1.5458\n",
      "[Adam | lr=0.1] Epoch 1074/4000: train_loss=0.0000  test_loss=32.5276  λ_max=1.5408\n",
      "[Adam | lr=0.1] Iter 17200: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 1075/4000: train_loss=0.0000  test_loss=32.5339  λ_max=1.4778\n",
      "[Adam | lr=0.1] Epoch 1076/4000: train_loss=0.0000  test_loss=32.5388  λ_max=1.4569\n",
      "[Adam | lr=0.1] Epoch 1077/4000: train_loss=0.0000  test_loss=32.5449  λ_max=1.4605\n",
      "[Adam | lr=0.1] Epoch 1078/4000: train_loss=0.0000  test_loss=32.5511  λ_max=1.4938\n",
      "[Adam | lr=0.1] Epoch 1079/4000: train_loss=0.0000  test_loss=32.5558  λ_max=1.4479\n",
      "[Adam | lr=0.1] Epoch 1080/4000: train_loss=0.0000  test_loss=32.5627  λ_max=1.4365\n",
      "[Adam | lr=0.1] Epoch 1081/4000: train_loss=0.0000  test_loss=32.5665  λ_max=1.3894\n",
      "[Adam | lr=0.1] Iter 17300: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 1082/4000: train_loss=0.0000  test_loss=32.5740  λ_max=1.5406\n",
      "[Adam | lr=0.1] Epoch 1083/4000: train_loss=0.0000  test_loss=32.5786  λ_max=1.4676\n",
      "[Adam | lr=0.1] Epoch 1084/4000: train_loss=0.0000  test_loss=32.5834  λ_max=1.4659\n",
      "[Adam | lr=0.1] Epoch 1085/4000: train_loss=0.0000  test_loss=32.5886  λ_max=1.3918\n",
      "[Adam | lr=0.1] Epoch 1086/4000: train_loss=0.0000  test_loss=32.5944  λ_max=1.5586\n",
      "[Adam | lr=0.1] Epoch 1087/4000: train_loss=0.0000  test_loss=32.5983  λ_max=1.4525\n",
      "[Adam | lr=0.1] Iter 17400: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 1088/4000: train_loss=0.0000  test_loss=32.6040  λ_max=1.4285\n",
      "[Adam | lr=0.1] Epoch 1089/4000: train_loss=0.0000  test_loss=32.6092  λ_max=1.4432\n",
      "[Adam | lr=0.1] Epoch 1090/4000: train_loss=0.0000  test_loss=32.6137  λ_max=1.5153\n",
      "[Adam | lr=0.1] Epoch 1091/4000: train_loss=0.0000  test_loss=32.6175  λ_max=1.3773\n",
      "[Adam | lr=0.1] Epoch 1092/4000: train_loss=0.0000  test_loss=32.6214  λ_max=1.4473\n",
      "[Adam | lr=0.1] Epoch 1093/4000: train_loss=0.0000  test_loss=32.6270  λ_max=1.3905\n",
      "[Adam | lr=0.1] Iter 17500: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 1094/4000: train_loss=0.0000  test_loss=32.6307  λ_max=1.5266\n",
      "[Adam | lr=0.1] Epoch 1095/4000: train_loss=0.0000  test_loss=32.6355  λ_max=1.4494\n",
      "[Adam | lr=0.1] Epoch 1096/4000: train_loss=0.0000  test_loss=32.6398  λ_max=1.5719\n",
      "[Adam | lr=0.1] Epoch 1097/4000: train_loss=0.0000  test_loss=32.6443  λ_max=1.4820\n",
      "[Adam | lr=0.1] Epoch 1098/4000: train_loss=0.0000  test_loss=32.6472  λ_max=1.4697\n",
      "[Adam | lr=0.1] Epoch 1099/4000: train_loss=0.0000  test_loss=32.6520  λ_max=1.5398\n",
      "[Adam | lr=0.1] Iter 17600: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 1100/4000: train_loss=0.0000  test_loss=32.6559  λ_max=1.4682\n",
      "[Adam | lr=0.1] Epoch 1101/4000: train_loss=0.0000  test_loss=32.6583  λ_max=1.4434\n",
      "[Adam | lr=0.1] Epoch 1102/4000: train_loss=0.0000  test_loss=32.6636  λ_max=1.5704\n",
      "[Adam | lr=0.1] Epoch 1103/4000: train_loss=0.0000  test_loss=32.6656  λ_max=1.5019\n",
      "[Adam | lr=0.1] Epoch 1104/4000: train_loss=0.0000  test_loss=32.6712  λ_max=1.4861\n",
      "[Adam | lr=0.1] Epoch 1105/4000: train_loss=0.0000  test_loss=32.6736  λ_max=1.5439\n",
      "[Adam | lr=0.1] Epoch 1106/4000: train_loss=0.0000  test_loss=32.6772  λ_max=1.5350\n",
      "[Adam | lr=0.1] Iter 17700: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 1107/4000: train_loss=0.0000  test_loss=32.6798  λ_max=1.4435\n",
      "[Adam | lr=0.1] Epoch 1108/4000: train_loss=0.0000  test_loss=32.6828  λ_max=1.4723\n",
      "[Adam | lr=0.1] Epoch 1109/4000: train_loss=0.0000  test_loss=32.6866  λ_max=1.5566\n",
      "[Adam | lr=0.1] Epoch 1110/4000: train_loss=0.0000  test_loss=32.6885  λ_max=1.5705\n",
      "[Adam | lr=0.1] Epoch 1111/4000: train_loss=0.0000  test_loss=32.6921  λ_max=1.5604\n",
      "[Adam | lr=0.1] Epoch 1112/4000: train_loss=0.0000  test_loss=32.6948  λ_max=1.4884\n",
      "[Adam | lr=0.1] Iter 17800: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 1113/4000: train_loss=0.0000  test_loss=32.6973  λ_max=1.5290\n",
      "[Adam | lr=0.1] Epoch 1114/4000: train_loss=0.0000  test_loss=32.7004  λ_max=1.4450\n",
      "[Adam | lr=0.1] Epoch 1115/4000: train_loss=0.0000  test_loss=32.7024  λ_max=1.4648\n",
      "[Adam | lr=0.1] Epoch 1116/4000: train_loss=0.0000  test_loss=32.7060  λ_max=1.4979\n",
      "[Adam | lr=0.1] Epoch 1117/4000: train_loss=0.0000  test_loss=32.7072  λ_max=1.4508\n",
      "[Adam | lr=0.1] Epoch 1118/4000: train_loss=0.0000  test_loss=32.7095  λ_max=1.5648\n",
      "[Adam | lr=0.1] Iter 17900: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 1119/4000: train_loss=0.0000  test_loss=32.7126  λ_max=1.4736\n",
      "[Adam | lr=0.1] Epoch 1120/4000: train_loss=0.0000  test_loss=32.7141  λ_max=1.4590\n",
      "[Adam | lr=0.1] Epoch 1121/4000: train_loss=0.0000  test_loss=32.7166  λ_max=1.4948\n",
      "[Adam | lr=0.1] Epoch 1122/4000: train_loss=0.0000  test_loss=32.7175  λ_max=1.4397\n",
      "[Adam | lr=0.1] Epoch 1123/4000: train_loss=0.0000  test_loss=32.7203  λ_max=1.5781\n",
      "[Adam | lr=0.1] Epoch 1124/4000: train_loss=0.0000  test_loss=32.7216  λ_max=1.4698\n",
      "[Adam | lr=0.1] Iter 18000: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 1125/4000: train_loss=0.0000  test_loss=32.7240  λ_max=1.5682\n",
      "[Adam | lr=0.1] Epoch 1126/4000: train_loss=0.0000  test_loss=32.7248  λ_max=1.5613\n",
      "[Adam | lr=0.1] Epoch 1127/4000: train_loss=0.0000  test_loss=32.7266  λ_max=1.5312\n",
      "[Adam | lr=0.1] Epoch 1128/4000: train_loss=0.0000  test_loss=32.7286  λ_max=1.5217\n",
      "[Adam | lr=0.1] Epoch 1129/4000: train_loss=0.0000  test_loss=32.7294  λ_max=1.4075\n",
      "[Adam | lr=0.1] Epoch 1130/4000: train_loss=0.0000  test_loss=32.7314  λ_max=1.5107\n",
      "[Adam | lr=0.1] Epoch 1131/4000: train_loss=0.0000  test_loss=32.7322  λ_max=1.5018\n",
      "[Adam | lr=0.1] Iter 18100: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 1132/4000: train_loss=0.0000  test_loss=32.7338  λ_max=1.4873\n",
      "[Adam | lr=0.1] Epoch 1133/4000: train_loss=0.0000  test_loss=32.7348  λ_max=1.4746\n",
      "[Adam | lr=0.1] Epoch 1134/4000: train_loss=0.0000  test_loss=32.7360  λ_max=1.4731\n",
      "[Adam | lr=0.1] Epoch 1135/4000: train_loss=0.0000  test_loss=32.7367  λ_max=1.4728\n",
      "[Adam | lr=0.1] Epoch 1136/4000: train_loss=0.0000  test_loss=32.7385  λ_max=1.5550\n",
      "[Adam | lr=0.1] Epoch 1137/4000: train_loss=0.0000  test_loss=32.7383  λ_max=1.4823\n",
      "[Adam | lr=0.1] Iter 18200: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 1138/4000: train_loss=0.0000  test_loss=32.7395  λ_max=1.5119\n",
      "[Adam | lr=0.1] Epoch 1139/4000: train_loss=0.0000  test_loss=32.7400  λ_max=1.3692\n",
      "[Adam | lr=0.1] Epoch 1140/4000: train_loss=0.0000  test_loss=32.7411  λ_max=1.5199\n",
      "[Adam | lr=0.1] Epoch 1141/4000: train_loss=0.0000  test_loss=32.7414  λ_max=1.5232\n",
      "[Adam | lr=0.1] Epoch 1142/4000: train_loss=0.0000  test_loss=32.7406  λ_max=1.5079\n",
      "[Adam | lr=0.1] Epoch 1143/4000: train_loss=0.0000  test_loss=32.7419  λ_max=1.4100\n",
      "[Adam | lr=0.1] Iter 18300: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 1144/4000: train_loss=0.0000  test_loss=32.7436  λ_max=1.4721\n",
      "[Adam | lr=0.1] Epoch 1145/4000: train_loss=0.0000  test_loss=32.7415  λ_max=1.5310\n",
      "[Adam | lr=0.1] Epoch 1146/4000: train_loss=0.0000  test_loss=32.7442  λ_max=1.4812\n",
      "[Adam | lr=0.1] Epoch 1147/4000: train_loss=0.0000  test_loss=32.7427  λ_max=1.4760\n",
      "[Adam | lr=0.1] Epoch 1148/4000: train_loss=0.0000  test_loss=32.7445  λ_max=1.4649\n",
      "[Adam | lr=0.1] Epoch 1149/4000: train_loss=0.0000  test_loss=32.7435  λ_max=1.4523\n",
      "[Adam | lr=0.1] Iter 18400: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 1150/4000: train_loss=0.0000  test_loss=32.7434  λ_max=1.4228\n",
      "[Adam | lr=0.1] Epoch 1151/4000: train_loss=0.0000  test_loss=32.7440  λ_max=1.4793\n",
      "[Adam | lr=0.1] Epoch 1152/4000: train_loss=0.0000  test_loss=32.7433  λ_max=1.5307\n",
      "[Adam | lr=0.1] Epoch 1153/4000: train_loss=0.0000  test_loss=32.7427  λ_max=1.4260\n",
      "[Adam | lr=0.1] Epoch 1154/4000: train_loss=0.0000  test_loss=32.7430  λ_max=1.4908\n",
      "[Adam | lr=0.1] Epoch 1155/4000: train_loss=0.0000  test_loss=32.7435  λ_max=1.3353\n",
      "[Adam | lr=0.1] Epoch 1156/4000: train_loss=0.0000  test_loss=32.7399  λ_max=1.5636\n",
      "[Adam | lr=0.1] Iter 18500: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 1157/4000: train_loss=0.0000  test_loss=32.7429  λ_max=1.3948\n",
      "[Adam | lr=0.1] Epoch 1158/4000: train_loss=0.0000  test_loss=32.7405  λ_max=1.4111\n",
      "[Adam | lr=0.1] Epoch 1159/4000: train_loss=0.0000  test_loss=32.7405  λ_max=1.5168\n",
      "[Adam | lr=0.1] Epoch 1160/4000: train_loss=0.0000  test_loss=32.7394  λ_max=1.4337\n",
      "[Adam | lr=0.1] Epoch 1161/4000: train_loss=0.0000  test_loss=32.7395  λ_max=1.4429\n",
      "[Adam | lr=0.1] Epoch 1162/4000: train_loss=0.0000  test_loss=32.7372  λ_max=1.3430\n",
      "[Adam | lr=0.1] Iter 18600: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 1163/4000: train_loss=0.0000  test_loss=32.7370  λ_max=1.4484\n",
      "[Adam | lr=0.1] Epoch 1164/4000: train_loss=0.0000  test_loss=32.7350  λ_max=1.5358\n",
      "[Adam | lr=0.1] Epoch 1165/4000: train_loss=0.0000  test_loss=32.7356  λ_max=1.4689\n",
      "[Adam | lr=0.1] Epoch 1166/4000: train_loss=0.0000  test_loss=32.7336  λ_max=1.5385\n",
      "[Adam | lr=0.1] Epoch 1167/4000: train_loss=0.0000  test_loss=32.7321  λ_max=1.5205\n",
      "[Adam | lr=0.1] Epoch 1168/4000: train_loss=0.0000  test_loss=32.7325  λ_max=1.3594\n",
      "[Adam | lr=0.1] Iter 18700: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 1169/4000: train_loss=0.0000  test_loss=32.7299  λ_max=1.4554\n",
      "[Adam | lr=0.1] Epoch 1170/4000: train_loss=0.0000  test_loss=32.7294  λ_max=1.4185\n",
      "[Adam | lr=0.1] Epoch 1171/4000: train_loss=0.0000  test_loss=32.7282  λ_max=1.4649\n",
      "[Adam | lr=0.1] Epoch 1172/4000: train_loss=0.0000  test_loss=32.7271  λ_max=1.4615\n",
      "[Adam | lr=0.1] Epoch 1173/4000: train_loss=0.0000  test_loss=32.7250  λ_max=1.5775\n",
      "[Adam | lr=0.1] Epoch 1174/4000: train_loss=0.0000  test_loss=32.7237  λ_max=1.4172\n",
      "[Adam | lr=0.1] Iter 18800: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 1175/4000: train_loss=0.0000  test_loss=32.7217  λ_max=1.5269\n",
      "[Adam | lr=0.1] Epoch 1176/4000: train_loss=0.0000  test_loss=32.7218  λ_max=1.3884\n",
      "[Adam | lr=0.1] Epoch 1177/4000: train_loss=0.0000  test_loss=32.7181  λ_max=1.4688\n",
      "[Adam | lr=0.1] Epoch 1178/4000: train_loss=0.0000  test_loss=32.7195  λ_max=1.4502\n",
      "[Adam | lr=0.1] Epoch 1179/4000: train_loss=0.0000  test_loss=32.7160  λ_max=1.3921\n",
      "[Adam | lr=0.1] Epoch 1180/4000: train_loss=0.0000  test_loss=32.7145  λ_max=1.5441\n",
      "[Adam | lr=0.1] Epoch 1181/4000: train_loss=0.0000  test_loss=32.7138  λ_max=1.4763\n",
      "[Adam | lr=0.1] Iter 18900: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 1182/4000: train_loss=0.0000  test_loss=32.7119  λ_max=1.5618\n",
      "[Adam | lr=0.1] Epoch 1183/4000: train_loss=0.0000  test_loss=32.7102  λ_max=1.5351\n",
      "[Adam | lr=0.1] Epoch 1184/4000: train_loss=0.0000  test_loss=32.7078  λ_max=1.5083\n",
      "[Adam | lr=0.1] Epoch 1185/4000: train_loss=0.0000  test_loss=32.7059  λ_max=1.4273\n",
      "[Adam | lr=0.1] Epoch 1186/4000: train_loss=0.0000  test_loss=32.7051  λ_max=1.5646\n",
      "[Adam | lr=0.1] Epoch 1187/4000: train_loss=0.0000  test_loss=32.7028  λ_max=1.5548\n",
      "[Adam | lr=0.1] Iter 19000: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 1188/4000: train_loss=0.0000  test_loss=32.7015  λ_max=1.5712\n",
      "[Adam | lr=0.1] Epoch 1189/4000: train_loss=0.0000  test_loss=32.6994  λ_max=1.4355\n",
      "[Adam | lr=0.1] Epoch 1190/4000: train_loss=0.0000  test_loss=32.6974  λ_max=1.4871\n",
      "[Adam | lr=0.1] Epoch 1191/4000: train_loss=0.0000  test_loss=32.6958  λ_max=1.4940\n",
      "[Adam | lr=0.1] Epoch 1192/4000: train_loss=0.0000  test_loss=32.6946  λ_max=1.4875\n",
      "[Adam | lr=0.1] Epoch 1193/4000: train_loss=0.0000  test_loss=32.6913  λ_max=1.4729\n",
      "[Adam | lr=0.1] Iter 19100: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 1194/4000: train_loss=0.0000  test_loss=32.6904  λ_max=1.4715\n",
      "[Adam | lr=0.1] Epoch 1195/4000: train_loss=0.0000  test_loss=32.6876  λ_max=1.5181\n",
      "[Adam | lr=0.1] Epoch 1196/4000: train_loss=0.0000  test_loss=32.6863  λ_max=1.5500\n",
      "[Adam | lr=0.1] Epoch 1197/4000: train_loss=0.0000  test_loss=32.6830  λ_max=1.5008\n",
      "[Adam | lr=0.1] Epoch 1198/4000: train_loss=0.0000  test_loss=32.6813  λ_max=1.5632\n",
      "[Adam | lr=0.1] Epoch 1199/4000: train_loss=0.0000  test_loss=32.6795  λ_max=1.4398\n",
      "[Adam | lr=0.1] Iter 19200: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 1200/4000: train_loss=0.0000  test_loss=32.6797  λ_max=1.5544\n",
      "[Adam | lr=0.1] Epoch 1201/4000: train_loss=0.0000  test_loss=32.6740  λ_max=1.5777\n",
      "[Adam | lr=0.1] Epoch 1202/4000: train_loss=0.0000  test_loss=32.6740  λ_max=1.5203\n",
      "[Adam | lr=0.1] Epoch 1203/4000: train_loss=0.0000  test_loss=32.6724  λ_max=1.4990\n",
      "[Adam | lr=0.1] Epoch 1204/4000: train_loss=0.0000  test_loss=32.6685  λ_max=1.5729\n",
      "[Adam | lr=0.1] Epoch 1205/4000: train_loss=0.0000  test_loss=32.6679  λ_max=1.4576\n",
      "[Adam | lr=0.1] Epoch 1206/4000: train_loss=0.0000  test_loss=32.6639  λ_max=1.5615\n",
      "[Adam | lr=0.1] Iter 19300: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 1207/4000: train_loss=0.0000  test_loss=32.6629  λ_max=1.5347\n",
      "[Adam | lr=0.1] Epoch 1208/4000: train_loss=0.0000  test_loss=32.6604  λ_max=1.4574\n",
      "[Adam | lr=0.1] Epoch 1209/4000: train_loss=0.0000  test_loss=32.6578  λ_max=1.5376\n",
      "[Adam | lr=0.1] Epoch 1210/4000: train_loss=0.0000  test_loss=32.6549  λ_max=1.4533\n",
      "[Adam | lr=0.1] Epoch 1211/4000: train_loss=0.0000  test_loss=32.6534  λ_max=1.5041\n",
      "[Adam | lr=0.1] Epoch 1212/4000: train_loss=0.0000  test_loss=32.6518  λ_max=1.4222\n",
      "[Adam | lr=0.1] Iter 19400: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 1213/4000: train_loss=0.0000  test_loss=32.6490  λ_max=1.4322\n",
      "[Adam | lr=0.1] Epoch 1214/4000: train_loss=0.0000  test_loss=32.6454  λ_max=1.5085\n",
      "[Adam | lr=0.1] Epoch 1215/4000: train_loss=0.0000  test_loss=32.6441  λ_max=1.5677\n",
      "[Adam | lr=0.1] Epoch 1216/4000: train_loss=0.0000  test_loss=32.6440  λ_max=1.4645\n",
      "[Adam | lr=0.1] Epoch 1217/4000: train_loss=0.0000  test_loss=32.6391  λ_max=1.4125\n",
      "[Adam | lr=0.1] Epoch 1218/4000: train_loss=0.0000  test_loss=32.6351  λ_max=1.4808\n",
      "[Adam | lr=0.1] Iter 19500: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 1219/4000: train_loss=0.0000  test_loss=32.6356  λ_max=1.5450\n",
      "[Adam | lr=0.1] Epoch 1220/4000: train_loss=0.0000  test_loss=32.6313  λ_max=1.5857\n",
      "[Adam | lr=0.1] Epoch 1221/4000: train_loss=0.0000  test_loss=32.6294  λ_max=1.4870\n",
      "[Adam | lr=0.1] Epoch 1222/4000: train_loss=0.0000  test_loss=32.6259  λ_max=1.5325\n",
      "[Adam | lr=0.1] Epoch 1223/4000: train_loss=0.0000  test_loss=32.6246  λ_max=1.4803\n",
      "[Adam | lr=0.1] Epoch 1224/4000: train_loss=0.0000  test_loss=32.6228  λ_max=1.5411\n",
      "[Adam | lr=0.1] Iter 19600: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 1225/4000: train_loss=0.0000  test_loss=32.6197  λ_max=1.5877\n",
      "[Adam | lr=0.1] Epoch 1226/4000: train_loss=0.0000  test_loss=32.6171  λ_max=1.5554\n",
      "[Adam | lr=0.1] Epoch 1227/4000: train_loss=0.0000  test_loss=32.6152  λ_max=1.5316\n",
      "[Adam | lr=0.1] Epoch 1228/4000: train_loss=0.0000  test_loss=32.6121  λ_max=1.5010\n",
      "[Adam | lr=0.1] Epoch 1229/4000: train_loss=0.0000  test_loss=32.6105  λ_max=1.4961\n",
      "[Adam | lr=0.1] Epoch 1230/4000: train_loss=0.0000  test_loss=32.6087  λ_max=1.5522\n",
      "[Adam | lr=0.1] Epoch 1231/4000: train_loss=0.0000  test_loss=32.6033  λ_max=1.4197\n",
      "[Adam | lr=0.1] Iter 19700: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 1232/4000: train_loss=0.0000  test_loss=32.6012  λ_max=1.5647\n",
      "[Adam | lr=0.1] Epoch 1233/4000: train_loss=0.0000  test_loss=32.6009  λ_max=1.5802\n",
      "[Adam | lr=0.1] Epoch 1234/4000: train_loss=0.0000  test_loss=32.5966  λ_max=1.5397\n",
      "[Adam | lr=0.1] Epoch 1235/4000: train_loss=0.0000  test_loss=32.5946  λ_max=1.6014\n",
      "[Adam | lr=0.1] Epoch 1236/4000: train_loss=0.0000  test_loss=32.5918  λ_max=1.5094\n",
      "[Adam | lr=0.1] Epoch 1237/4000: train_loss=0.0000  test_loss=32.5875  λ_max=1.4505\n",
      "[Adam | lr=0.1] Iter 19800: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 1238/4000: train_loss=0.0000  test_loss=32.5871  λ_max=1.4455\n",
      "[Adam | lr=0.1] Epoch 1239/4000: train_loss=0.0000  test_loss=32.5839  λ_max=1.5624\n",
      "[Adam | lr=0.1] Epoch 1240/4000: train_loss=0.0000  test_loss=32.5799  λ_max=1.5356\n",
      "[Adam | lr=0.1] Epoch 1241/4000: train_loss=0.0000  test_loss=32.5773  λ_max=1.5542\n",
      "[Adam | lr=0.1] Epoch 1242/4000: train_loss=0.0000  test_loss=32.5763  λ_max=1.5206\n",
      "[Adam | lr=0.1] Epoch 1243/4000: train_loss=0.0000  test_loss=32.5735  λ_max=1.5101\n",
      "[Adam | lr=0.1] Iter 19900: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 1244/4000: train_loss=0.0000  test_loss=32.5713  λ_max=1.5574\n",
      "[Adam | lr=0.1] Epoch 1245/4000: train_loss=0.0000  test_loss=32.5669  λ_max=1.5440\n",
      "[Adam | lr=0.1] Epoch 1246/4000: train_loss=0.0000  test_loss=32.5650  λ_max=1.4409\n",
      "[Adam | lr=0.1] Epoch 1247/4000: train_loss=0.0000  test_loss=32.5638  λ_max=1.4931\n",
      "[Adam | lr=0.1] Epoch 1248/4000: train_loss=0.0000  test_loss=32.5586  λ_max=1.5535\n",
      "[Adam | lr=0.1] Epoch 1249/4000: train_loss=0.0000  test_loss=32.5560  λ_max=1.5040\n",
      "[Adam | lr=0.1] Iter 20000: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 1250/4000: train_loss=0.0000  test_loss=32.5557  λ_max=1.5723\n",
      "[Adam | lr=0.1] Epoch 1251/4000: train_loss=0.0000  test_loss=32.5533  λ_max=1.5690\n",
      "[Adam | lr=0.1] Epoch 1252/4000: train_loss=0.0000  test_loss=32.5506  λ_max=1.5846\n",
      "[Adam | lr=0.1] Epoch 1253/4000: train_loss=0.0000  test_loss=32.5468  λ_max=1.5094\n",
      "[Adam | lr=0.1] Epoch 1254/4000: train_loss=0.0000  test_loss=32.5446  λ_max=1.5242\n",
      "[Adam | lr=0.1] Epoch 1255/4000: train_loss=0.0000  test_loss=32.5440  λ_max=1.5730\n",
      "[Adam | lr=0.1] Epoch 1256/4000: train_loss=0.0000  test_loss=32.5385  λ_max=1.5441\n",
      "[Adam | lr=0.1] Iter 20100: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 1257/4000: train_loss=0.0000  test_loss=32.5373  λ_max=1.5398\n",
      "[Adam | lr=0.1] Epoch 1258/4000: train_loss=0.0000  test_loss=32.5337  λ_max=1.4751\n",
      "[Adam | lr=0.1] Epoch 1259/4000: train_loss=0.0000  test_loss=32.5324  λ_max=1.5929\n",
      "[Adam | lr=0.1] Epoch 1260/4000: train_loss=0.0000  test_loss=32.5286  λ_max=1.5697\n",
      "[Adam | lr=0.1] Epoch 1261/4000: train_loss=0.0000  test_loss=32.5270  λ_max=1.4640\n",
      "[Adam | lr=0.1] Epoch 1262/4000: train_loss=0.0000  test_loss=32.5268  λ_max=1.4958\n",
      "[Adam | lr=0.1] Iter 20200: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 1263/4000: train_loss=0.0000  test_loss=32.5222  λ_max=1.4570\n",
      "[Adam | lr=0.1] Epoch 1264/4000: train_loss=0.0000  test_loss=32.5209  λ_max=1.5736\n",
      "[Adam | lr=0.1] Epoch 1265/4000: train_loss=0.0000  test_loss=32.5190  λ_max=1.5053\n",
      "[Adam | lr=0.1] Epoch 1266/4000: train_loss=0.0000  test_loss=32.5151  λ_max=1.5623\n",
      "[Adam | lr=0.1] Epoch 1267/4000: train_loss=0.0000  test_loss=32.5157  λ_max=1.5401\n",
      "[Adam | lr=0.1] Epoch 1268/4000: train_loss=0.0000  test_loss=32.5133  λ_max=1.5299\n",
      "[Adam | lr=0.1] Iter 20300: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 1269/4000: train_loss=0.0000  test_loss=32.5121  λ_max=1.6195\n",
      "[Adam | lr=0.1] Epoch 1270/4000: train_loss=0.0000  test_loss=32.5068  λ_max=1.6119\n",
      "[Adam | lr=0.1] Epoch 1271/4000: train_loss=0.0000  test_loss=32.5035  λ_max=1.5906\n",
      "[Adam | lr=0.1] Epoch 1272/4000: train_loss=0.0000  test_loss=32.5054  λ_max=1.5898\n",
      "[Adam | lr=0.1] Epoch 1273/4000: train_loss=0.0000  test_loss=32.5019  λ_max=1.5727\n",
      "[Adam | lr=0.1] Epoch 1274/4000: train_loss=0.0000  test_loss=32.4974  λ_max=1.5921\n",
      "[Adam | lr=0.1] Iter 20400: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 1275/4000: train_loss=0.0000  test_loss=32.4956  λ_max=1.6212\n",
      "[Adam | lr=0.1] Epoch 1276/4000: train_loss=0.0000  test_loss=32.4953  λ_max=1.5504\n",
      "[Adam | lr=0.1] Epoch 1277/4000: train_loss=0.0000  test_loss=32.4949  λ_max=1.5572\n",
      "[Adam | lr=0.1] Epoch 1278/4000: train_loss=0.0000  test_loss=32.4918  λ_max=1.5677\n",
      "[Adam | lr=0.1] Epoch 1279/4000: train_loss=0.0000  test_loss=32.4877  λ_max=1.5041\n",
      "[Adam | lr=0.1] Epoch 1280/4000: train_loss=0.0000  test_loss=32.4851  λ_max=1.5656\n",
      "[Adam | lr=0.1] Epoch 1281/4000: train_loss=0.0000  test_loss=32.4856  λ_max=1.5744\n",
      "[Adam | lr=0.1] Iter 20500: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 1282/4000: train_loss=0.0000  test_loss=32.4823  λ_max=1.5714\n",
      "[Adam | lr=0.1] Epoch 1283/4000: train_loss=0.0000  test_loss=32.4794  λ_max=1.4604\n",
      "[Adam | lr=0.1] Epoch 1284/4000: train_loss=0.0000  test_loss=32.4807  λ_max=1.5876\n",
      "[Adam | lr=0.1] Epoch 1285/4000: train_loss=0.0000  test_loss=32.4774  λ_max=1.5421\n",
      "[Adam | lr=0.1] Epoch 1286/4000: train_loss=0.0000  test_loss=32.4761  λ_max=1.5358\n",
      "[Adam | lr=0.1] Epoch 1287/4000: train_loss=0.0000  test_loss=32.4745  λ_max=1.5864\n",
      "[Adam | lr=0.1] Iter 20600: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 1288/4000: train_loss=0.0000  test_loss=32.4728  λ_max=1.5676\n",
      "[Adam | lr=0.1] Epoch 1289/4000: train_loss=0.0000  test_loss=32.4704  λ_max=1.5550\n",
      "[Adam | lr=0.1] Epoch 1290/4000: train_loss=0.0000  test_loss=32.4698  λ_max=1.5545\n",
      "[Adam | lr=0.1] Epoch 1291/4000: train_loss=0.0000  test_loss=32.4702  λ_max=1.4932\n",
      "[Adam | lr=0.1] Epoch 1292/4000: train_loss=0.0000  test_loss=32.4662  λ_max=1.4608\n",
      "[Adam | lr=0.1] Epoch 1293/4000: train_loss=0.0000  test_loss=32.4649  λ_max=1.5858\n",
      "[Adam | lr=0.1] Iter 20700: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 1294/4000: train_loss=0.0000  test_loss=32.4625  λ_max=1.6227\n",
      "[Adam | lr=0.1] Epoch 1295/4000: train_loss=0.0000  test_loss=32.4638  λ_max=1.5295\n",
      "[Adam | lr=0.1] Epoch 1296/4000: train_loss=0.0000  test_loss=32.4612  λ_max=1.5988\n",
      "[Adam | lr=0.1] Epoch 1297/4000: train_loss=0.0000  test_loss=32.4606  λ_max=1.5765\n",
      "[Adam | lr=0.1] Epoch 1298/4000: train_loss=0.0000  test_loss=32.4605  λ_max=1.5001\n",
      "[Adam | lr=0.1] Epoch 1299/4000: train_loss=0.0000  test_loss=32.4597  λ_max=1.4519\n",
      "[Adam | lr=0.1] Iter 20800: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 1300/4000: train_loss=0.0000  test_loss=32.4544  λ_max=1.5517\n",
      "[Adam | lr=0.1] Epoch 1301/4000: train_loss=0.0000  test_loss=32.4597  λ_max=1.4741\n",
      "[Adam | lr=0.1] Epoch 1302/4000: train_loss=0.0000  test_loss=32.4545  λ_max=1.5829\n",
      "[Adam | lr=0.1] Epoch 1303/4000: train_loss=0.0000  test_loss=32.4541  λ_max=1.5355\n",
      "[Adam | lr=0.1] Epoch 1304/4000: train_loss=0.0000  test_loss=32.4531  λ_max=1.5853\n",
      "[Adam | lr=0.1] Epoch 1305/4000: train_loss=0.0000  test_loss=32.4527  λ_max=1.6176\n",
      "[Adam | lr=0.1] Epoch 1306/4000: train_loss=0.0000  test_loss=32.4530  λ_max=1.4674\n",
      "[Adam | lr=0.1] Iter 20900: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 1307/4000: train_loss=0.0000  test_loss=32.4517  λ_max=1.5815\n",
      "[Adam | lr=0.1] Epoch 1308/4000: train_loss=0.0000  test_loss=32.4535  λ_max=1.5215\n",
      "[Adam | lr=0.1] Epoch 1309/4000: train_loss=0.0000  test_loss=32.4524  λ_max=1.6396\n",
      "[Adam | lr=0.1] Epoch 1310/4000: train_loss=0.0000  test_loss=32.4510  λ_max=1.6472\n",
      "[Adam | lr=0.1] Epoch 1311/4000: train_loss=0.0000  test_loss=32.4518  λ_max=1.6047\n",
      "[Adam | lr=0.1] Epoch 1312/4000: train_loss=0.0000  test_loss=32.4489  λ_max=1.6075\n",
      "[Adam | lr=0.1] Iter 21000: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 1313/4000: train_loss=0.0000  test_loss=32.4504  λ_max=1.6264\n",
      "[Adam | lr=0.1] Epoch 1314/4000: train_loss=0.0000  test_loss=32.4499  λ_max=1.5584\n",
      "[Adam | lr=0.1] Epoch 1315/4000: train_loss=0.0000  test_loss=32.4552  λ_max=1.6294\n",
      "[Adam | lr=0.1] Epoch 1316/4000: train_loss=0.0000  test_loss=32.4521  λ_max=1.5796\n",
      "[Adam | lr=0.1] Epoch 1317/4000: train_loss=0.0000  test_loss=32.4487  λ_max=1.5597\n",
      "[Adam | lr=0.1] Epoch 1318/4000: train_loss=0.0000  test_loss=32.4506  λ_max=1.5815\n",
      "[Adam | lr=0.1] Iter 21100: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 1319/4000: train_loss=0.0000  test_loss=32.4520  λ_max=1.5666\n",
      "[Adam | lr=0.1] Epoch 1320/4000: train_loss=0.0000  test_loss=32.4519  λ_max=1.6163\n",
      "[Adam | lr=0.1] Epoch 1321/4000: train_loss=0.0000  test_loss=32.4535  λ_max=1.6129\n",
      "[Adam | lr=0.1] Epoch 1322/4000: train_loss=0.0000  test_loss=32.4573  λ_max=1.6335\n",
      "[Adam | lr=0.1] Epoch 1323/4000: train_loss=0.0000  test_loss=32.4570  λ_max=1.6069\n",
      "[Adam | lr=0.1] Epoch 1324/4000: train_loss=0.0000  test_loss=32.4550  λ_max=1.5408\n",
      "[Adam | lr=0.1] Iter 21200: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 1325/4000: train_loss=0.0000  test_loss=32.4563  λ_max=1.6054\n",
      "[Adam | lr=0.1] Epoch 1326/4000: train_loss=0.0000  test_loss=32.4594  λ_max=1.5302\n",
      "[Adam | lr=0.1] Epoch 1327/4000: train_loss=0.0000  test_loss=32.4564  λ_max=1.5825\n",
      "[Adam | lr=0.1] Epoch 1328/4000: train_loss=0.0000  test_loss=32.4591  λ_max=1.6268\n",
      "[Adam | lr=0.1] Epoch 1329/4000: train_loss=0.0000  test_loss=32.4647  λ_max=1.5719\n",
      "[Adam | lr=0.1] Epoch 1330/4000: train_loss=0.0000  test_loss=32.4654  λ_max=1.5635\n",
      "[Adam | lr=0.1] Epoch 1331/4000: train_loss=0.0000  test_loss=32.4667  λ_max=1.5740\n",
      "[Adam | lr=0.1] Iter 21300: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 1332/4000: train_loss=0.0000  test_loss=32.4671  λ_max=1.6490\n",
      "[Adam | lr=0.1] Epoch 1333/4000: train_loss=0.0000  test_loss=32.4703  λ_max=1.5594\n",
      "[Adam | lr=0.1] Epoch 1334/4000: train_loss=0.0000  test_loss=32.4753  λ_max=1.6066\n",
      "[Adam | lr=0.1] Epoch 1335/4000: train_loss=0.0000  test_loss=32.4739  λ_max=1.5865\n",
      "[Adam | lr=0.1] Epoch 1336/4000: train_loss=0.0000  test_loss=32.4780  λ_max=1.6529\n",
      "[Adam | lr=0.1] Epoch 1337/4000: train_loss=0.0000  test_loss=32.4799  λ_max=1.6610\n",
      "[Adam | lr=0.1] Iter 21400: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 1338/4000: train_loss=0.0000  test_loss=32.4860  λ_max=1.5869\n",
      "[Adam | lr=0.1] Epoch 1339/4000: train_loss=0.0000  test_loss=32.4857  λ_max=1.5534\n",
      "[Adam | lr=0.1] Epoch 1340/4000: train_loss=0.0000  test_loss=32.4890  λ_max=1.6561\n",
      "[Adam | lr=0.1] Epoch 1341/4000: train_loss=0.0000  test_loss=32.4911  λ_max=1.6514\n",
      "[Adam | lr=0.1] Epoch 1342/4000: train_loss=0.0000  test_loss=32.4978  λ_max=1.6153\n",
      "[Adam | lr=0.1] Epoch 1343/4000: train_loss=0.0000  test_loss=32.5031  λ_max=1.5840\n",
      "[Adam | lr=0.1] Iter 21500: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 1344/4000: train_loss=0.0000  test_loss=32.5051  λ_max=1.6315\n",
      "[Adam | lr=0.1] Epoch 1345/4000: train_loss=0.0000  test_loss=32.5090  λ_max=1.6503\n",
      "[Adam | lr=0.1] Epoch 1346/4000: train_loss=0.0000  test_loss=32.5134  λ_max=1.6230\n",
      "[Adam | lr=0.1] Epoch 1347/4000: train_loss=0.0000  test_loss=32.5155  λ_max=1.6118\n",
      "[Adam | lr=0.1] Epoch 1348/4000: train_loss=0.0000  test_loss=32.5227  λ_max=1.6650\n",
      "[Adam | lr=0.1] Epoch 1349/4000: train_loss=0.0000  test_loss=32.5241  λ_max=1.6650\n",
      "[Adam | lr=0.1] Iter 21600: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 1350/4000: train_loss=0.0000  test_loss=32.5284  λ_max=1.5580\n",
      "[Adam | lr=0.1] Epoch 1351/4000: train_loss=0.0000  test_loss=32.5377  λ_max=1.6712\n",
      "[Adam | lr=0.1] Epoch 1352/4000: train_loss=0.0000  test_loss=32.5406  λ_max=1.5732\n",
      "[Adam | lr=0.1] Epoch 1353/4000: train_loss=0.0000  test_loss=32.5454  λ_max=1.6315\n",
      "[Adam | lr=0.1] Epoch 1354/4000: train_loss=0.0000  test_loss=32.5502  λ_max=1.6223\n",
      "[Adam | lr=0.1] Epoch 1355/4000: train_loss=0.0000  test_loss=32.5597  λ_max=1.6410\n",
      "[Adam | lr=0.1] Epoch 1356/4000: train_loss=0.0000  test_loss=32.5656  λ_max=1.6635\n",
      "[Adam | lr=0.1] Iter 21700: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 1357/4000: train_loss=0.0000  test_loss=32.5711  λ_max=1.5840\n",
      "[Adam | lr=0.1] Epoch 1358/4000: train_loss=0.0000  test_loss=32.5783  λ_max=1.6303\n",
      "[Adam | lr=0.1] Epoch 1359/4000: train_loss=0.0000  test_loss=32.5842  λ_max=1.6764\n",
      "[Adam | lr=0.1] Epoch 1360/4000: train_loss=0.0000  test_loss=32.5910  λ_max=1.6137\n",
      "[Adam | lr=0.1] Epoch 1361/4000: train_loss=0.0000  test_loss=32.5986  λ_max=1.6284\n",
      "[Adam | lr=0.1] Epoch 1362/4000: train_loss=0.0000  test_loss=32.6044  λ_max=1.6653\n",
      "[Adam | lr=0.1] Iter 21800: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 1363/4000: train_loss=0.0000  test_loss=32.6101  λ_max=1.5931\n",
      "[Adam | lr=0.1] Epoch 1364/4000: train_loss=0.0000  test_loss=32.6214  λ_max=1.6134\n",
      "[Adam | lr=0.1] Epoch 1365/4000: train_loss=0.0000  test_loss=32.6286  λ_max=1.6607\n",
      "[Adam | lr=0.1] Epoch 1366/4000: train_loss=0.0000  test_loss=32.6340  λ_max=1.5934\n",
      "[Adam | lr=0.1] Epoch 1367/4000: train_loss=0.0000  test_loss=32.6453  λ_max=1.5178\n",
      "[Adam | lr=0.1] Epoch 1368/4000: train_loss=0.0000  test_loss=32.6547  λ_max=1.6011\n",
      "[Adam | lr=0.1] Iter 21900: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 1369/4000: train_loss=0.0000  test_loss=32.6660  λ_max=1.5678\n",
      "[Adam | lr=0.1] Epoch 1370/4000: train_loss=0.0000  test_loss=32.6725  λ_max=1.5971\n",
      "[Adam | lr=0.1] Epoch 1371/4000: train_loss=0.0000  test_loss=32.6859  λ_max=1.6477\n",
      "[Adam | lr=0.1] Epoch 1372/4000: train_loss=0.0000  test_loss=32.6911  λ_max=1.6139\n",
      "[Adam | lr=0.1] Epoch 1373/4000: train_loss=0.0000  test_loss=32.7034  λ_max=1.5363\n",
      "[Adam | lr=0.1] Epoch 1374/4000: train_loss=0.0000  test_loss=32.7168  λ_max=1.6010\n",
      "[Adam | lr=0.1] Iter 22000: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 1375/4000: train_loss=0.0000  test_loss=32.7243  λ_max=1.6716\n",
      "[Adam | lr=0.1] Epoch 1376/4000: train_loss=0.0000  test_loss=32.7324  λ_max=1.6639\n",
      "[Adam | lr=0.1] Epoch 1377/4000: train_loss=0.0000  test_loss=32.7426  λ_max=1.6380\n",
      "[Adam | lr=0.1] Epoch 1378/4000: train_loss=0.0000  test_loss=32.7593  λ_max=1.7111\n",
      "[Adam | lr=0.1] Epoch 1379/4000: train_loss=0.0000  test_loss=32.7697  λ_max=1.6505\n",
      "[Adam | lr=0.1] Epoch 1380/4000: train_loss=0.0000  test_loss=32.7831  λ_max=1.6200\n",
      "[Adam | lr=0.1] Epoch 1381/4000: train_loss=0.0000  test_loss=32.7944  λ_max=1.6043\n",
      "[Adam | lr=0.1] Iter 22100: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 1382/4000: train_loss=0.0000  test_loss=32.8077  λ_max=1.5536\n",
      "[Adam | lr=0.1] Epoch 1383/4000: train_loss=0.0000  test_loss=32.8196  λ_max=1.6272\n",
      "[Adam | lr=0.1] Epoch 1384/4000: train_loss=0.0000  test_loss=32.8336  λ_max=1.6140\n",
      "[Adam | lr=0.1] Epoch 1385/4000: train_loss=0.0000  test_loss=32.8436  λ_max=1.6472\n",
      "[Adam | lr=0.1] Epoch 1386/4000: train_loss=0.0000  test_loss=32.8620  λ_max=1.7041\n",
      "[Adam | lr=0.1] Epoch 1387/4000: train_loss=0.0000  test_loss=32.8719  λ_max=1.6185\n",
      "[Adam | lr=0.1] Iter 22200: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 1388/4000: train_loss=0.0000  test_loss=32.8886  λ_max=1.6155\n",
      "[Adam | lr=0.1] Epoch 1389/4000: train_loss=0.0000  test_loss=32.9105  λ_max=1.6585\n",
      "[Adam | lr=0.1] Epoch 1390/4000: train_loss=0.0000  test_loss=32.9172  λ_max=1.6752\n",
      "[Adam | lr=0.1] Epoch 1391/4000: train_loss=0.0000  test_loss=32.9386  λ_max=1.5988\n",
      "[Adam | lr=0.1] Epoch 1392/4000: train_loss=0.0000  test_loss=32.9488  λ_max=1.6465\n",
      "[Adam | lr=0.1] Epoch 1393/4000: train_loss=0.0000  test_loss=32.9641  λ_max=1.6373\n",
      "[Adam | lr=0.1] Iter 22300: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 1394/4000: train_loss=0.0000  test_loss=32.9832  λ_max=1.6989\n",
      "[Adam | lr=0.1] Epoch 1395/4000: train_loss=0.0000  test_loss=33.0032  λ_max=1.6830\n",
      "[Adam | lr=0.1] Epoch 1396/4000: train_loss=0.0000  test_loss=33.0162  λ_max=1.7668\n",
      "[Adam | lr=0.1] Epoch 1397/4000: train_loss=0.0000  test_loss=33.0350  λ_max=1.7292\n",
      "[Adam | lr=0.1] Epoch 1398/4000: train_loss=0.0000  test_loss=33.0538  λ_max=1.7014\n",
      "[Adam | lr=0.1] Epoch 1399/4000: train_loss=0.0000  test_loss=33.0676  λ_max=1.6523\n",
      "[Adam | lr=0.1] Iter 22400: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 1400/4000: train_loss=0.0000  test_loss=33.0914  λ_max=1.6831\n",
      "[Adam | lr=0.1] Epoch 1401/4000: train_loss=0.0000  test_loss=33.1067  λ_max=1.6207\n",
      "[Adam | lr=0.1] Epoch 1402/4000: train_loss=0.0000  test_loss=33.1282  λ_max=1.7841\n",
      "[Adam | lr=0.1] Epoch 1403/4000: train_loss=0.0000  test_loss=33.1419  λ_max=1.7834\n",
      "[Adam | lr=0.1] Epoch 1404/4000: train_loss=0.0000  test_loss=33.1681  λ_max=1.7498\n",
      "[Adam | lr=0.1] Epoch 1405/4000: train_loss=0.0000  test_loss=33.1848  λ_max=1.6474\n",
      "[Adam | lr=0.1] Epoch 1406/4000: train_loss=0.0000  test_loss=33.2037  λ_max=1.8159\n",
      "[Adam | lr=0.1] Iter 22500: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 1407/4000: train_loss=0.0000  test_loss=33.2279  λ_max=1.7029\n",
      "[Adam | lr=0.1] Epoch 1408/4000: train_loss=0.0000  test_loss=33.2495  λ_max=1.7518\n",
      "[Adam | lr=0.1] Epoch 1409/4000: train_loss=0.0000  test_loss=33.2661  λ_max=1.8330\n",
      "[Adam | lr=0.1] Epoch 1410/4000: train_loss=0.0000  test_loss=33.2914  λ_max=1.8400\n",
      "[Adam | lr=0.1] Epoch 1411/4000: train_loss=0.0000  test_loss=33.3128  λ_max=1.8004\n",
      "[Adam | lr=0.1] Epoch 1412/4000: train_loss=0.0000  test_loss=33.3344  λ_max=1.8559\n",
      "[Adam | lr=0.1] Iter 22600: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 1413/4000: train_loss=0.0000  test_loss=33.3570  λ_max=1.7454\n",
      "[Adam | lr=0.1] Epoch 1414/4000: train_loss=0.0000  test_loss=33.3806  λ_max=1.8610\n",
      "[Adam | lr=0.1] Epoch 1415/4000: train_loss=0.0000  test_loss=33.3950  λ_max=1.7196\n",
      "[Adam | lr=0.1] Epoch 1416/4000: train_loss=0.0000  test_loss=33.4258  λ_max=1.7371\n",
      "[Adam | lr=0.1] Epoch 1417/4000: train_loss=0.0000  test_loss=33.4476  λ_max=1.7930\n",
      "[Adam | lr=0.1] Epoch 1418/4000: train_loss=0.0000  test_loss=33.4750  λ_max=1.8260\n",
      "[Adam | lr=0.1] Iter 22700: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 1419/4000: train_loss=0.0000  test_loss=33.4933  λ_max=1.8576\n",
      "[Adam | lr=0.1] Epoch 1420/4000: train_loss=0.0000  test_loss=33.5182  λ_max=1.9183\n",
      "[Adam | lr=0.1] Epoch 1421/4000: train_loss=0.0000  test_loss=33.5414  λ_max=1.6308\n",
      "[Adam | lr=0.1] Epoch 1422/4000: train_loss=0.0000  test_loss=33.5730  λ_max=1.6929\n",
      "[Adam | lr=0.1] Epoch 1423/4000: train_loss=0.0000  test_loss=33.5903  λ_max=1.8819\n",
      "[Adam | lr=0.1] Epoch 1424/4000: train_loss=0.0000  test_loss=33.6235  λ_max=1.9324\n",
      "[Adam | lr=0.1] Iter 22800: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 1425/4000: train_loss=0.0000  test_loss=33.6512  λ_max=1.8526\n",
      "[Adam | lr=0.1] Epoch 1426/4000: train_loss=0.0000  test_loss=33.6709  λ_max=1.7359\n",
      "[Adam | lr=0.1] Epoch 1427/4000: train_loss=0.0000  test_loss=33.7011  λ_max=1.9575\n",
      "[Adam | lr=0.1] Epoch 1428/4000: train_loss=0.0000  test_loss=33.7231  λ_max=1.9218\n",
      "[Adam | lr=0.1] Epoch 1429/4000: train_loss=0.0000  test_loss=33.7481  λ_max=1.9007\n",
      "[Adam | lr=0.1] Epoch 1430/4000: train_loss=0.0000  test_loss=33.7801  λ_max=1.7135\n",
      "[Adam | lr=0.1] Epoch 1431/4000: train_loss=0.0000  test_loss=33.8081  λ_max=1.8969\n",
      "[Adam | lr=0.1] Iter 22900: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 1432/4000: train_loss=0.0000  test_loss=33.8358  λ_max=1.9852\n",
      "[Adam | lr=0.1] Epoch 1433/4000: train_loss=0.0000  test_loss=33.8597  λ_max=1.9576\n",
      "[Adam | lr=0.1] Epoch 1434/4000: train_loss=0.0000  test_loss=33.8902  λ_max=2.0291\n",
      "[Adam | lr=0.1] Epoch 1435/4000: train_loss=0.0000  test_loss=33.9178  λ_max=1.8882\n",
      "[Adam | lr=0.1] Epoch 1436/4000: train_loss=0.0000  test_loss=33.9464  λ_max=2.0390\n",
      "[Adam | lr=0.1] Epoch 1437/4000: train_loss=0.0000  test_loss=33.9746  λ_max=1.9307\n",
      "[Adam | lr=0.1] Iter 23000: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 1438/4000: train_loss=0.0000  test_loss=34.0038  λ_max=2.0571\n",
      "[Adam | lr=0.1] Epoch 1439/4000: train_loss=0.0000  test_loss=34.0324  λ_max=2.0715\n",
      "[Adam | lr=0.1] Epoch 1440/4000: train_loss=0.0000  test_loss=34.0675  λ_max=2.0350\n",
      "[Adam | lr=0.1] Epoch 1441/4000: train_loss=0.0000  test_loss=34.0881  λ_max=2.0851\n",
      "[Adam | lr=0.1] Epoch 1442/4000: train_loss=0.0000  test_loss=34.1202  λ_max=1.9266\n",
      "[Adam | lr=0.1] Epoch 1443/4000: train_loss=0.0000  test_loss=34.1525  λ_max=1.8503\n",
      "[Adam | lr=0.1] Iter 23100: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 1444/4000: train_loss=0.0000  test_loss=34.1811  λ_max=2.0830\n",
      "[Adam | lr=0.1] Epoch 1445/4000: train_loss=0.0000  test_loss=34.2130  λ_max=2.0955\n",
      "[Adam | lr=0.1] Epoch 1446/4000: train_loss=0.0000  test_loss=34.2383  λ_max=2.0319\n",
      "[Adam | lr=0.1] Epoch 1447/4000: train_loss=0.0000  test_loss=34.2687  λ_max=2.1171\n",
      "[Adam | lr=0.1] Epoch 1448/4000: train_loss=0.0000  test_loss=34.2974  λ_max=2.0113\n",
      "[Adam | lr=0.1] Epoch 1449/4000: train_loss=0.0000  test_loss=34.3346  λ_max=1.9249\n",
      "[Adam | lr=0.1] Iter 23200: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 1450/4000: train_loss=0.0000  test_loss=34.3620  λ_max=2.1093\n",
      "[Adam | lr=0.1] Epoch 1451/4000: train_loss=0.0000  test_loss=34.3972  λ_max=2.1470\n",
      "[Adam | lr=0.1] Epoch 1452/4000: train_loss=0.0000  test_loss=34.4211  λ_max=2.1655\n",
      "[Adam | lr=0.1] Epoch 1453/4000: train_loss=0.0000  test_loss=34.4569  λ_max=2.1752\n",
      "[Adam | lr=0.1] Epoch 1454/4000: train_loss=0.0000  test_loss=34.4849  λ_max=2.0095\n",
      "[Adam | lr=0.1] Epoch 1455/4000: train_loss=0.0000  test_loss=34.5192  λ_max=2.2013\n",
      "[Adam | lr=0.1] Epoch 1456/4000: train_loss=0.0000  test_loss=34.5463  λ_max=2.2066\n",
      "[Adam | lr=0.1] Iter 23300: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 1457/4000: train_loss=0.0000  test_loss=34.5790  λ_max=2.1146\n",
      "[Adam | lr=0.1] Epoch 1458/4000: train_loss=0.0000  test_loss=34.6141  λ_max=2.2180\n",
      "[Adam | lr=0.1] Epoch 1459/4000: train_loss=0.0000  test_loss=34.6418  λ_max=2.0592\n",
      "[Adam | lr=0.1] Epoch 1460/4000: train_loss=0.0000  test_loss=34.6722  λ_max=2.2182\n",
      "[Adam | lr=0.1] Epoch 1461/4000: train_loss=0.0000  test_loss=34.7035  λ_max=2.2241\n",
      "[Adam | lr=0.1] Epoch 1462/4000: train_loss=0.0000  test_loss=34.7345  λ_max=2.2422\n",
      "[Adam | lr=0.1] Iter 23400: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 1463/4000: train_loss=0.0000  test_loss=34.7716  λ_max=2.1892\n",
      "[Adam | lr=0.1] Epoch 1464/4000: train_loss=0.0000  test_loss=34.8108  λ_max=2.2346\n",
      "[Adam | lr=0.1] Epoch 1465/4000: train_loss=0.0000  test_loss=34.8276  λ_max=2.0929\n",
      "[Adam | lr=0.1] Epoch 1466/4000: train_loss=0.0000  test_loss=34.8600  λ_max=2.1790\n",
      "[Adam | lr=0.1] Epoch 1467/4000: train_loss=0.0000  test_loss=34.8989  λ_max=2.2158\n",
      "[Adam | lr=0.1] Epoch 1468/4000: train_loss=0.0000  test_loss=34.9221  λ_max=2.2048\n",
      "[Adam | lr=0.1] Iter 23500: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 1469/4000: train_loss=0.0000  test_loss=34.9624  λ_max=2.2574\n",
      "[Adam | lr=0.1] Epoch 1470/4000: train_loss=0.0000  test_loss=34.9891  λ_max=1.9146\n",
      "[Adam | lr=0.1] Epoch 1471/4000: train_loss=0.0000  test_loss=35.0240  λ_max=2.2536\n",
      "[Adam | lr=0.1] Epoch 1472/4000: train_loss=0.0000  test_loss=35.0510  λ_max=2.1175\n",
      "[Adam | lr=0.1] Epoch 1473/4000: train_loss=0.0000  test_loss=35.0878  λ_max=2.2437\n",
      "[Adam | lr=0.1] Epoch 1474/4000: train_loss=0.0000  test_loss=35.1161  λ_max=1.8647\n",
      "[Adam | lr=0.1] Iter 23600: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 1475/4000: train_loss=0.0000  test_loss=35.1539  λ_max=2.2529\n",
      "[Adam | lr=0.1] Epoch 1476/4000: train_loss=0.0000  test_loss=35.1832  λ_max=2.2551\n",
      "[Adam | lr=0.1] Epoch 1477/4000: train_loss=0.0000  test_loss=35.2170  λ_max=2.1590\n",
      "[Adam | lr=0.1] Epoch 1478/4000: train_loss=0.0000  test_loss=35.2527  λ_max=1.8880\n",
      "[Adam | lr=0.1] Epoch 1479/4000: train_loss=0.0000  test_loss=35.2802  λ_max=2.2635\n",
      "[Adam | lr=0.1] Epoch 1480/4000: train_loss=0.0000  test_loss=35.3110  λ_max=2.1827\n",
      "[Adam | lr=0.1] Epoch 1481/4000: train_loss=0.0000  test_loss=35.3412  λ_max=1.9931\n",
      "[Adam | lr=0.1] Iter 23700: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 1482/4000: train_loss=0.0000  test_loss=35.3779  λ_max=2.1773\n",
      "[Adam | lr=0.1] Epoch 1483/4000: train_loss=0.0000  test_loss=35.4082  λ_max=2.2837\n",
      "[Adam | lr=0.1] Epoch 1484/4000: train_loss=0.0000  test_loss=35.4347  λ_max=2.1605\n",
      "[Adam | lr=0.1] Epoch 1485/4000: train_loss=0.0000  test_loss=35.4778  λ_max=2.2918\n",
      "[Adam | lr=0.1] Epoch 1486/4000: train_loss=0.0000  test_loss=35.5011  λ_max=2.2967\n",
      "[Adam | lr=0.1] Epoch 1487/4000: train_loss=0.0000  test_loss=35.5388  λ_max=2.0113\n",
      "[Adam | lr=0.1] Iter 23800: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 1488/4000: train_loss=0.0000  test_loss=35.5707  λ_max=2.2030\n",
      "[Adam | lr=0.1] Epoch 1489/4000: train_loss=0.0000  test_loss=35.5977  λ_max=2.2781\n",
      "[Adam | lr=0.1] Epoch 1490/4000: train_loss=0.0000  test_loss=35.6399  λ_max=1.8335\n",
      "[Adam | lr=0.1] Epoch 1491/4000: train_loss=0.0000  test_loss=35.6669  λ_max=1.9939\n",
      "[Adam | lr=0.1] Epoch 1492/4000: train_loss=0.0000  test_loss=35.6988  λ_max=2.0942\n",
      "[Adam | lr=0.1] Epoch 1493/4000: train_loss=0.0000  test_loss=35.7397  λ_max=2.2208\n",
      "[Adam | lr=0.1] Iter 23900: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 1494/4000: train_loss=0.0000  test_loss=35.7554  λ_max=2.2021\n",
      "[Adam | lr=0.1] Epoch 1495/4000: train_loss=0.0000  test_loss=35.8076  λ_max=2.1853\n",
      "[Adam | lr=0.1] Epoch 1496/4000: train_loss=0.0000  test_loss=35.8171  λ_max=2.2844\n",
      "[Adam | lr=0.1] Epoch 1497/4000: train_loss=0.0000  test_loss=35.8664  λ_max=2.2995\n",
      "[Adam | lr=0.1] Epoch 1498/4000: train_loss=0.0000  test_loss=35.8942  λ_max=2.1563\n",
      "[Adam | lr=0.1] Epoch 1499/4000: train_loss=0.0000  test_loss=35.9235  λ_max=2.0350\n",
      "[Adam | lr=0.1] Iter 24000: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 1500/4000: train_loss=0.0000  test_loss=35.9604  λ_max=2.2267\n",
      "[Adam | lr=0.1] Epoch 1501/4000: train_loss=0.0000  test_loss=35.9945  λ_max=2.2445\n",
      "[Adam | lr=0.1] Epoch 1502/4000: train_loss=0.0000  test_loss=36.0346  λ_max=2.1360\n",
      "[Adam | lr=0.1] Epoch 1503/4000: train_loss=0.0000  test_loss=36.0612  λ_max=2.1311\n",
      "[Adam | lr=0.1] Epoch 1504/4000: train_loss=0.0000  test_loss=36.0932  λ_max=2.2039\n",
      "[Adam | lr=0.1] Epoch 1505/4000: train_loss=0.0000  test_loss=36.1329  λ_max=2.0309\n",
      "[Adam | lr=0.1] Epoch 1506/4000: train_loss=0.0000  test_loss=36.1681  λ_max=2.1562\n",
      "[Adam | lr=0.1] Iter 24100: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 1507/4000: train_loss=0.0000  test_loss=36.1997  λ_max=2.2635\n",
      "[Adam | lr=0.1] Epoch 1508/4000: train_loss=0.0000  test_loss=36.2424  λ_max=2.0545\n",
      "[Adam | lr=0.1] Epoch 1509/4000: train_loss=0.0000  test_loss=36.2715  λ_max=2.2017\n",
      "[Adam | lr=0.1] Epoch 1510/4000: train_loss=0.0000  test_loss=36.3076  λ_max=2.1382\n",
      "[Adam | lr=0.1] Epoch 1511/4000: train_loss=0.0000  test_loss=36.3490  λ_max=2.1222\n",
      "[Adam | lr=0.1] Epoch 1512/4000: train_loss=0.0000  test_loss=36.3895  λ_max=2.0446\n",
      "[Adam | lr=0.1] Iter 24200: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 1513/4000: train_loss=0.0000  test_loss=36.4293  λ_max=2.2276\n",
      "[Adam | lr=0.1] Epoch 1514/4000: train_loss=0.0000  test_loss=36.4593  λ_max=2.2486\n",
      "[Adam | lr=0.1] Epoch 1515/4000: train_loss=0.0000  test_loss=36.5008  λ_max=2.1599\n",
      "[Adam | lr=0.1] Epoch 1516/4000: train_loss=0.0000  test_loss=36.5246  λ_max=2.1949\n",
      "[Adam | lr=0.1] Epoch 1517/4000: train_loss=0.0000  test_loss=36.5668  λ_max=2.2745\n",
      "[Adam | lr=0.1] Epoch 1518/4000: train_loss=0.0000  test_loss=36.6200  λ_max=2.1849\n",
      "[Adam | lr=0.1] Iter 24300: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 1519/4000: train_loss=0.0000  test_loss=36.6400  λ_max=2.3133\n",
      "[Adam | lr=0.1] Epoch 1520/4000: train_loss=0.0000  test_loss=36.6951  λ_max=2.2235\n",
      "[Adam | lr=0.1] Epoch 1521/4000: train_loss=0.0000  test_loss=36.7179  λ_max=2.2273\n",
      "[Adam | lr=0.1] Epoch 1522/4000: train_loss=0.0000  test_loss=36.7602  λ_max=2.2326\n",
      "[Adam | lr=0.1] Epoch 1523/4000: train_loss=0.0000  test_loss=36.8042  λ_max=2.1256\n",
      "[Adam | lr=0.1] Epoch 1524/4000: train_loss=0.0000  test_loss=36.8496  λ_max=2.1975\n",
      "[Adam | lr=0.1] Iter 24400: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 1525/4000: train_loss=0.0000  test_loss=36.8833  λ_max=2.2409\n",
      "[Adam | lr=0.1] Epoch 1526/4000: train_loss=0.0000  test_loss=36.9267  λ_max=2.2594\n",
      "[Adam | lr=0.1] Epoch 1527/4000: train_loss=0.0000  test_loss=36.9625  λ_max=2.1244\n",
      "[Adam | lr=0.1] Epoch 1528/4000: train_loss=0.0000  test_loss=37.0067  λ_max=2.2082\n",
      "[Adam | lr=0.1] Epoch 1529/4000: train_loss=0.0000  test_loss=37.0442  λ_max=2.2492\n",
      "[Adam | lr=0.1] Epoch 1530/4000: train_loss=0.0000  test_loss=37.0733  λ_max=2.2446\n",
      "[Adam | lr=0.1] Epoch 1531/4000: train_loss=0.0000  test_loss=37.1224  λ_max=2.3550\n",
      "[Adam | lr=0.1] Iter 24500: loss=0.0000\n",
      "[Adam | lr=0.1] Epoch 1532/4000: train_loss=0.0000  test_loss=37.1613  λ_max=2.1201\n",
      "[Adam | lr=0.1] Epoch 1533/4000: train_loss=33.5632  test_loss=150.2040  λ_max=5.6055\n",
      "[Adam | lr=0.1] Epoch 1534/4000: train_loss=124.3018  test_loss=79.9417  λ_max=60.1632\n",
      "[Adam | lr=0.1] Epoch 1535/4000: train_loss=62.2756  test_loss=37.0479  λ_max=140.5475\n",
      "[Adam | lr=0.1] Epoch 1536/4000: train_loss=36.6074  test_loss=49.3117  λ_max=55.4352\n",
      "[Adam | lr=0.1] Epoch 1537/4000: train_loss=26.8307  test_loss=23.1836  λ_max=147.2497\n",
      "[Adam | lr=0.1] Iter 24600: loss=16.6856\n",
      "[Adam | lr=0.1] Epoch 1538/4000: train_loss=17.2781  test_loss=12.4018  λ_max=221.5347\n",
      "[Adam | lr=0.1] Epoch 1539/4000: train_loss=14.1515  test_loss=13.6651  λ_max=279.7372\n",
      "[Adam | lr=0.1] Epoch 1540/4000: train_loss=13.1767  test_loss=8.0164  λ_max=308.3403\n",
      "[Adam | lr=0.1] Epoch 1541/4000: train_loss=11.2299  test_loss=10.4096  λ_max=217.9702\n",
      "[Adam | lr=0.1] Epoch 1542/4000: train_loss=8.9756  test_loss=8.9087  λ_max=203.9596\n",
      "[Adam | lr=0.1] Epoch 1543/4000: train_loss=8.0043  test_loss=7.5787  λ_max=212.3420\n",
      "[Adam | lr=0.1] Iter 24700: loss=5.5411\n",
      "[Adam | lr=0.1] Epoch 1544/4000: train_loss=7.1005  test_loss=6.9049  λ_max=177.9405\n",
      "[Adam | lr=0.1] Epoch 1545/4000: train_loss=6.1681  test_loss=4.9953  λ_max=236.3394\n",
      "[Adam | lr=0.1] Epoch 1546/4000: train_loss=5.6201  test_loss=4.6117  λ_max=293.6547\n",
      "[Adam | lr=0.1] Epoch 1547/4000: train_loss=5.1861  test_loss=4.1048  λ_max=332.4183\n",
      "[Adam | lr=0.1] Epoch 1548/4000: train_loss=4.7287  test_loss=4.2891  λ_max=296.5311\n",
      "[Adam | lr=0.1] Epoch 1549/4000: train_loss=4.2819  test_loss=3.8600  λ_max=229.5444\n",
      "[Adam | lr=0.1] Iter 24800: loss=3.3340\n",
      "[Adam | lr=0.1] Epoch 1550/4000: train_loss=3.8275  test_loss=4.5157  λ_max=220.2044\n",
      "[Adam | lr=0.1] Epoch 1551/4000: train_loss=4.4555  test_loss=7.9782  λ_max=163.5968\n",
      "[Adam | lr=0.1] Epoch 1552/4000: train_loss=4.8256  test_loss=3.9579  λ_max=209.8184\n",
      "[Adam | lr=0.1] Epoch 1553/4000: train_loss=3.6330  test_loss=2.9387  λ_max=276.3841\n",
      "[Adam | lr=0.1] Epoch 1554/4000: train_loss=3.6471  test_loss=2.9998  λ_max=363.9716\n",
      "[Adam | lr=0.1] Epoch 1555/4000: train_loss=3.7647  test_loss=3.6733  λ_max=218.3273\n",
      "[Adam | lr=0.1] Epoch 1556/4000: train_loss=3.4974  test_loss=3.7265  λ_max=213.8330\n",
      "[Adam | lr=0.1] Iter 24900: loss=3.3670\n",
      "[Adam | lr=0.1] Epoch 1557/4000: train_loss=3.2673  test_loss=3.2403  λ_max=202.0233\n",
      "[Adam | lr=0.1] Epoch 1558/4000: train_loss=3.1640  test_loss=2.9794  λ_max=234.7078\n",
      "[Adam | lr=0.1] Epoch 1559/4000: train_loss=3.1484  test_loss=3.2874  λ_max=278.3146\n",
      "[Adam | lr=0.1] Epoch 1560/4000: train_loss=3.0125  test_loss=2.9017  λ_max=248.2955\n",
      "[Adam | lr=0.1] Epoch 1561/4000: train_loss=2.9164  test_loss=3.2591  λ_max=198.4608\n",
      "[Adam | lr=0.1] Epoch 1562/4000: train_loss=2.8283  test_loss=2.6875  λ_max=249.5844\n",
      "[Adam | lr=0.1] Iter 25000: loss=2.5599\n",
      "[Adam | lr=0.1] Epoch 1563/4000: train_loss=2.8820  test_loss=2.6112  λ_max=239.3300\n",
      "[Adam | lr=0.1] Epoch 1564/4000: train_loss=2.8666  test_loss=2.6461  λ_max=220.6364\n",
      "[Adam | lr=0.1] Epoch 1565/4000: train_loss=2.8180  test_loss=2.8308  λ_max=192.6022\n",
      "[Adam | lr=0.1] Epoch 1566/4000: train_loss=2.5992  test_loss=2.3230  λ_max=270.7484\n",
      "[Adam | lr=0.1] Epoch 1567/4000: train_loss=2.3486  test_loss=2.3970  λ_max=260.1562\n",
      "[Adam | lr=0.1] Epoch 1568/4000: train_loss=2.3390  test_loss=2.3508  λ_max=253.8216\n",
      "[Adam | lr=0.1] Iter 25100: loss=2.3209\n",
      "[Adam | lr=0.1] Epoch 1569/4000: train_loss=2.3562  test_loss=2.3493  λ_max=248.2048\n",
      "[Adam | lr=0.1] Epoch 1570/4000: train_loss=2.3842  test_loss=2.3656  λ_max=225.3032\n",
      "[Adam | lr=0.1] Epoch 1571/4000: train_loss=2.3558  test_loss=2.2298  λ_max=243.8507\n",
      "[Adam | lr=0.1] Epoch 1572/4000: train_loss=2.3422  test_loss=2.3169  λ_max=209.6670\n",
      "[Adam | lr=0.1] Epoch 1573/4000: train_loss=2.3246  test_loss=2.3254  λ_max=275.3150\n",
      "[Adam | lr=0.1] Epoch 1574/4000: train_loss=2.3365  test_loss=2.4938  λ_max=220.3586\n",
      "[Adam | lr=0.1] Iter 25200: loss=2.4020\n",
      "[Adam | lr=0.1] Epoch 1575/4000: train_loss=2.4381  test_loss=2.4062  λ_max=225.7025\n",
      "[Adam | lr=0.1] Epoch 1576/4000: train_loss=2.3487  test_loss=2.3182  λ_max=235.6577\n",
      "[Adam | lr=0.1] Epoch 1577/4000: train_loss=2.2991  test_loss=2.2614  λ_max=197.6996\n",
      "[Adam | lr=0.1] Epoch 1578/4000: train_loss=2.2496  test_loss=2.3012  λ_max=264.0064\n",
      "[Adam | lr=0.1] Epoch 1579/4000: train_loss=2.3339  test_loss=2.3630  λ_max=230.1787\n",
      "[Adam | lr=0.1] Epoch 1580/4000: train_loss=2.3070  test_loss=2.4502  λ_max=170.3470\n",
      "[Adam | lr=0.1] Epoch 1581/4000: train_loss=2.3658  test_loss=2.3300  λ_max=247.7887\n",
      "[Adam | lr=0.1] Iter 25300: loss=2.2398\n",
      "[Adam | lr=0.1] Epoch 1582/4000: train_loss=2.2723  test_loss=2.3804  λ_max=194.3430\n",
      "[Adam | lr=0.1] Epoch 1583/4000: train_loss=2.2921  test_loss=2.4611  λ_max=212.5797\n",
      "[Adam | lr=0.1] Epoch 1584/4000: train_loss=2.3237  test_loss=2.3372  λ_max=205.6911\n",
      "[Adam | lr=0.1] Epoch 1585/4000: train_loss=2.2393  test_loss=2.3058  λ_max=205.7322\n",
      "[Adam | lr=0.1] Epoch 1586/4000: train_loss=2.2170  test_loss=2.2533  λ_max=243.4233\n",
      "[Adam | lr=0.1] Epoch 1587/4000: train_loss=2.1979  test_loss=2.2153  λ_max=237.9971\n",
      "[Adam | lr=0.1] Iter 25400: loss=2.2593\n",
      "[Adam | lr=0.1] Epoch 1588/4000: train_loss=2.2275  test_loss=2.3028  λ_max=189.7782\n",
      "[Adam | lr=0.1] Epoch 1589/4000: train_loss=2.2263  test_loss=2.2455  λ_max=231.1604\n",
      "[Adam | lr=0.1] Epoch 1590/4000: train_loss=2.2190  test_loss=2.2134  λ_max=226.7252\n",
      "[Adam | lr=0.1] Epoch 1591/4000: train_loss=2.2341  test_loss=2.4170  λ_max=196.9881\n",
      "[Adam | lr=0.1] Epoch 1592/4000: train_loss=2.3047  test_loss=2.2960  λ_max=219.2501\n",
      "[Adam | lr=0.1] Epoch 1593/4000: train_loss=2.2367  test_loss=2.2222  λ_max=226.7862\n",
      "[Adam | lr=0.1] Iter 25500: loss=2.2218\n",
      "[Adam | lr=0.1] Epoch 1594/4000: train_loss=2.2178  test_loss=2.3979  λ_max=169.4816\n",
      "[Adam | lr=0.1] Epoch 1595/4000: train_loss=2.2916  test_loss=2.3331  λ_max=239.3250\n",
      "[Adam | lr=0.1] Epoch 1596/4000: train_loss=2.2824  test_loss=2.2494  λ_max=204.2041\n",
      "[Adam | lr=0.1] Epoch 1597/4000: train_loss=2.2142  test_loss=2.2167  λ_max=221.0520\n",
      "[Adam | lr=0.1] Epoch 1598/4000: train_loss=2.2046  test_loss=2.2628  λ_max=192.3973\n",
      "[Adam | lr=0.1] Epoch 1599/4000: train_loss=2.2330  test_loss=2.4089  λ_max=186.9155\n",
      "[Adam | lr=0.1] Iter 25600: loss=2.2607\n",
      "[Adam | lr=0.1] Epoch 1600/4000: train_loss=2.2620  test_loss=2.2678  λ_max=192.2767\n",
      "[Adam | lr=0.1] Epoch 1601/4000: train_loss=2.2444  test_loss=2.3673  λ_max=202.8609\n",
      "[Adam | lr=0.1] Epoch 1602/4000: train_loss=2.2215  test_loss=2.2300  λ_max=215.6888\n",
      "[Adam | lr=0.1] Epoch 1603/4000: train_loss=2.2206  test_loss=2.2486  λ_max=228.4971\n",
      "[Adam | lr=0.1] Epoch 1604/4000: train_loss=2.1989  test_loss=2.2080  λ_max=215.0280\n",
      "[Adam | lr=0.1] Epoch 1605/4000: train_loss=2.2147  test_loss=2.3525  λ_max=224.5445\n",
      "[Adam | lr=0.1] Epoch 1606/4000: train_loss=2.2474  test_loss=2.2818  λ_max=204.9866\n",
      "[Adam | lr=0.1] Iter 25700: loss=2.2561\n",
      "[Adam | lr=0.1] Epoch 1607/4000: train_loss=2.2458  test_loss=2.4313  λ_max=197.8581\n",
      "[Adam | lr=0.1] Epoch 1608/4000: train_loss=2.2673  test_loss=2.3118  λ_max=174.1608\n",
      "[Adam | lr=0.1] Epoch 1609/4000: train_loss=2.2064  test_loss=2.2652  λ_max=173.1067\n",
      "[Adam | lr=0.1] Epoch 1610/4000: train_loss=2.2603  test_loss=2.2895  λ_max=221.9210\n",
      "[Adam | lr=0.1] Epoch 1611/4000: train_loss=2.2251  test_loss=2.2487  λ_max=179.4858\n",
      "[Adam | lr=0.1] Epoch 1612/4000: train_loss=2.1686  test_loss=2.2497  λ_max=207.5886\n",
      "[Adam | lr=0.1] Iter 25800: loss=2.1586\n",
      "[Adam | lr=0.1] Epoch 1613/4000: train_loss=2.1709  test_loss=2.3081  λ_max=201.2756\n",
      "[Adam | lr=0.1] Epoch 1614/4000: train_loss=2.2013  test_loss=2.2206  λ_max=204.1553\n",
      "[Adam | lr=0.1] Epoch 1615/4000: train_loss=2.1678  test_loss=2.2222  λ_max=198.1360\n",
      "[Adam | lr=0.1] Epoch 1616/4000: train_loss=2.1787  test_loss=2.2837  λ_max=192.1822\n",
      "[Adam | lr=0.1] Epoch 1617/4000: train_loss=2.1967  test_loss=2.2989  λ_max=194.3376\n",
      "[Adam | lr=0.1] Epoch 1618/4000: train_loss=2.2657  test_loss=2.3787  λ_max=182.7015\n",
      "[Adam | lr=0.1] Iter 25900: loss=2.2793\n",
      "[Adam | lr=0.1] Epoch 1619/4000: train_loss=2.2871  test_loss=2.3379  λ_max=186.7753\n",
      "[Adam | lr=0.1] Epoch 1620/4000: train_loss=2.2052  test_loss=2.2830  λ_max=196.4381\n",
      "[Adam | lr=0.1] Epoch 1621/4000: train_loss=2.1796  test_loss=2.3119  λ_max=158.6837\n",
      "[Adam | lr=0.1] Epoch 1622/4000: train_loss=2.2358  test_loss=2.2485  λ_max=179.4152\n",
      "[Adam | lr=0.1] Epoch 1623/4000: train_loss=2.2077  test_loss=2.3320  λ_max=141.0863\n",
      "[Adam | lr=0.1] Epoch 1624/4000: train_loss=2.2801  test_loss=2.3157  λ_max=159.1608\n",
      "[Adam | lr=0.1] Iter 26000: loss=2.1337\n",
      "[Adam | lr=0.1] Epoch 1625/4000: train_loss=2.2647  test_loss=2.3059  λ_max=195.7513\n",
      "[Adam | lr=0.1] Epoch 1626/4000: train_loss=2.1779  test_loss=2.3376  λ_max=133.4605\n",
      "[Adam | lr=0.1] Epoch 1627/4000: train_loss=2.1954  test_loss=2.3048  λ_max=150.6712\n",
      "[Adam | lr=0.1] Epoch 1628/4000: train_loss=2.1814  test_loss=2.2461  λ_max=190.5870\n",
      "[Adam | lr=0.1] Epoch 1629/4000: train_loss=2.1714  test_loss=2.2281  λ_max=174.6075\n",
      "[Adam | lr=0.1] Epoch 1630/4000: train_loss=2.1439  test_loss=2.2626  λ_max=165.8018\n",
      "[Adam | lr=0.1] Epoch 1631/4000: train_loss=2.1545  test_loss=2.2277  λ_max=175.3184\n",
      "[Adam | lr=0.1] Iter 26100: loss=2.1469\n",
      "[Adam | lr=0.1] Epoch 1632/4000: train_loss=2.1339  test_loss=2.2086  λ_max=185.3211\n",
      "[Adam | lr=0.1] Epoch 1633/4000: train_loss=2.1417  test_loss=2.2243  λ_max=174.3354\n",
      "[Adam | lr=0.1] Epoch 1634/4000: train_loss=2.1507  test_loss=2.2172  λ_max=171.4294\n",
      "[Adam | lr=0.1] Epoch 1635/4000: train_loss=2.1363  test_loss=2.2272  λ_max=166.0633\n",
      "[Adam | lr=0.1] Epoch 1636/4000: train_loss=2.1334  test_loss=2.2142  λ_max=177.6065\n",
      "[Adam | lr=0.1] Epoch 1637/4000: train_loss=2.1245  test_loss=2.2370  λ_max=156.8027\n",
      "[Adam | lr=0.1] Iter 26200: loss=2.1372\n",
      "[Adam | lr=0.1] Epoch 1638/4000: train_loss=2.1339  test_loss=2.2222  λ_max=191.3360\n",
      "[Adam | lr=0.1] Epoch 1639/4000: train_loss=2.1214  test_loss=2.2190  λ_max=180.8883\n",
      "[Adam | lr=0.1] Epoch 1640/4000: train_loss=2.1213  test_loss=2.2379  λ_max=138.2625\n",
      "[Adam | lr=0.1] Epoch 1641/4000: train_loss=2.1324  test_loss=2.2153  λ_max=176.8461\n",
      "[Adam | lr=0.1] Epoch 1642/4000: train_loss=2.1353  test_loss=2.2420  λ_max=177.5631\n",
      "[Adam | lr=0.1] Epoch 1643/4000: train_loss=2.1285  test_loss=2.2345  λ_max=160.7849\n",
      "[Adam | lr=0.1] Iter 26300: loss=2.2212\n",
      "[Adam | lr=0.1] Epoch 1644/4000: train_loss=2.1945  test_loss=2.3770  λ_max=130.5605\n",
      "[Adam | lr=0.1] Epoch 1645/4000: train_loss=2.2144  test_loss=2.2917  λ_max=164.5772\n",
      "[Adam | lr=0.1] Epoch 1646/4000: train_loss=2.2265  test_loss=2.2664  λ_max=179.3358\n",
      "[Adam | lr=0.1] Epoch 1647/4000: train_loss=2.2072  test_loss=2.2523  λ_max=185.2122\n",
      "[Adam | lr=0.1] Epoch 1648/4000: train_loss=2.1368  test_loss=2.2202  λ_max=161.5388\n",
      "[Adam | lr=0.1] Epoch 1649/4000: train_loss=2.1221  test_loss=2.2161  λ_max=165.2272\n",
      "[Adam | lr=0.1] Iter 26400: loss=2.1100\n",
      "[Adam | lr=0.1] Epoch 1650/4000: train_loss=2.1162  test_loss=2.2348  λ_max=176.2187\n",
      "[Adam | lr=0.1] Epoch 1651/4000: train_loss=2.1484  test_loss=2.2442  λ_max=167.8882\n",
      "[Adam | lr=0.1] Epoch 1652/4000: train_loss=2.1218  test_loss=2.2383  λ_max=149.5675\n",
      "[Adam | lr=0.1] Epoch 1653/4000: train_loss=2.1180  test_loss=2.2288  λ_max=174.8873\n",
      "[Adam | lr=0.1] Epoch 1654/4000: train_loss=2.1090  test_loss=2.2275  λ_max=158.4447\n",
      "[Adam | lr=0.1] Epoch 1655/4000: train_loss=2.1156  test_loss=2.2292  λ_max=162.7607\n",
      "[Adam | lr=0.1] Epoch 1656/4000: train_loss=2.1166  test_loss=2.2353  λ_max=156.2768\n",
      "[Adam | lr=0.1] Iter 26500: loss=2.1102\n",
      "[Adam | lr=0.1] Epoch 1657/4000: train_loss=2.1028  test_loss=2.2174  λ_max=172.4916\n",
      "[Adam | lr=0.1] Epoch 1658/4000: train_loss=2.1062  test_loss=2.2413  λ_max=125.2451\n",
      "[Adam | lr=0.1] Epoch 1659/4000: train_loss=2.1249  test_loss=2.2727  λ_max=148.2112\n",
      "[Adam | lr=0.1] Epoch 1660/4000: train_loss=2.1413  test_loss=2.2251  λ_max=169.6858\n",
      "[Adam | lr=0.1] Epoch 1661/4000: train_loss=2.1176  test_loss=2.2207  λ_max=159.0584\n",
      "[Adam | lr=0.1] Epoch 1662/4000: train_loss=2.1283  test_loss=2.2747  λ_max=141.5945\n",
      "[Adam | lr=0.1] Iter 26600: loss=2.1271\n",
      "[Adam | lr=0.1] Epoch 1663/4000: train_loss=2.1370  test_loss=2.2712  λ_max=159.2472\n",
      "[Adam | lr=0.1] Epoch 1664/4000: train_loss=2.2353  test_loss=2.5173  λ_max=142.1841\n",
      "[Adam | lr=0.1] Epoch 1665/4000: train_loss=2.3457  test_loss=2.3233  λ_max=146.8365\n",
      "[Adam | lr=0.1] Epoch 1666/4000: train_loss=2.1666  test_loss=2.2524  λ_max=140.6812\n",
      "[Adam | lr=0.1] Epoch 1667/4000: train_loss=2.1747  test_loss=2.2594  λ_max=140.5936\n",
      "[Adam | lr=0.1] Epoch 1668/4000: train_loss=2.1269  test_loss=2.2528  λ_max=135.5658\n",
      "[Adam | lr=0.1] Iter 26700: loss=2.1041\n",
      "[Adam | lr=0.1] Epoch 1669/4000: train_loss=2.1227  test_loss=2.2167  λ_max=144.5269\n",
      "[Adam | lr=0.1] Epoch 1670/4000: train_loss=2.1132  test_loss=2.2481  λ_max=138.2218\n",
      "[Adam | lr=0.1] Epoch 1671/4000: train_loss=2.1065  test_loss=2.2320  λ_max=159.4823\n",
      "[Adam | lr=0.1] Epoch 1672/4000: train_loss=2.1458  test_loss=2.3627  λ_max=147.0833\n",
      "[Adam | lr=0.1] Epoch 1673/4000: train_loss=2.2570  test_loss=2.3773  λ_max=129.6805\n",
      "[Adam | lr=0.1] Epoch 1674/4000: train_loss=2.2223  test_loss=2.2356  λ_max=140.6971\n",
      "[Adam | lr=0.1] Iter 26800: loss=2.1779\n",
      "[Adam | lr=0.1] Epoch 1675/4000: train_loss=2.1646  test_loss=2.3461  λ_max=138.7484\n",
      "[Adam | lr=0.1] Epoch 1676/4000: train_loss=2.1592  test_loss=2.3341  λ_max=118.2546\n",
      "[Adam | lr=0.1] Epoch 1677/4000: train_loss=2.1370  test_loss=2.2617  λ_max=137.7933\n",
      "[Adam | lr=0.1] Epoch 1678/4000: train_loss=2.1306  test_loss=2.2378  λ_max=127.3334\n",
      "[Adam | lr=0.1] Epoch 1679/4000: train_loss=2.1077  test_loss=2.2403  λ_max=130.9206\n",
      "[Adam | lr=0.1] Epoch 1680/4000: train_loss=2.1129  test_loss=2.2510  λ_max=129.9769\n",
      "[Adam | lr=0.1] Epoch 1681/4000: train_loss=2.0994  test_loss=2.2446  λ_max=130.6466\n",
      "[Adam | lr=0.1] Iter 26900: loss=2.0900\n",
      "[Adam | lr=0.1] Epoch 1682/4000: train_loss=2.1476  test_loss=2.2717  λ_max=107.2131\n",
      "[Adam | lr=0.1] Epoch 1683/4000: train_loss=2.1288  test_loss=2.2714  λ_max=116.7713\n",
      "[Adam | lr=0.1] Epoch 1684/4000: train_loss=2.0975  test_loss=2.2298  λ_max=113.7374\n",
      "[Adam | lr=0.1] Epoch 1685/4000: train_loss=2.0848  test_loss=2.2176  λ_max=127.9069\n",
      "[Adam | lr=0.1] Epoch 1686/4000: train_loss=2.0821  test_loss=2.2446  λ_max=117.3881\n",
      "[Adam | lr=0.1] Epoch 1687/4000: train_loss=2.0968  test_loss=2.2561  λ_max=122.6750\n",
      "[Adam | lr=0.1] Iter 27000: loss=2.1122\n",
      "[Adam | lr=0.1] Epoch 1688/4000: train_loss=2.1139  test_loss=2.2703  λ_max=117.7710\n",
      "[Adam | lr=0.1] Epoch 1689/4000: train_loss=2.0951  test_loss=2.2300  λ_max=129.6277\n",
      "[Adam | lr=0.1] Epoch 1690/4000: train_loss=2.0824  test_loss=2.2319  λ_max=117.4873\n",
      "[Adam | lr=0.1] Epoch 1691/4000: train_loss=2.0770  test_loss=2.2257  λ_max=123.1535\n",
      "[Adam | lr=0.1] Epoch 1692/4000: train_loss=2.0786  test_loss=2.2245  λ_max=120.0250\n",
      "[Adam | lr=0.1] Epoch 1693/4000: train_loss=2.0808  test_loss=2.2243  λ_max=126.3708\n",
      "[Adam | lr=0.1] Iter 27100: loss=2.0732\n",
      "[Adam | lr=0.1] Epoch 1694/4000: train_loss=2.0785  test_loss=2.2243  λ_max=129.6228\n",
      "[Adam | lr=0.1] Epoch 1695/4000: train_loss=2.0812  test_loss=2.2215  λ_max=127.1104\n",
      "[Adam | lr=0.1] Epoch 1696/4000: train_loss=2.0784  test_loss=2.2214  λ_max=117.7678\n",
      "[Adam | lr=0.1] Epoch 1697/4000: train_loss=2.0803  test_loss=2.2363  λ_max=123.2775\n",
      "[Adam | lr=0.1] Epoch 1698/4000: train_loss=2.0764  test_loss=2.2305  λ_max=115.0110\n",
      "[Adam | lr=0.1] Epoch 1699/4000: train_loss=2.0755  test_loss=2.2283  λ_max=122.2235\n",
      "[Adam | lr=0.1] Iter 27200: loss=2.1024\n",
      "[Adam | lr=0.1] Epoch 1700/4000: train_loss=2.0730  test_loss=2.2232  λ_max=124.1441\n",
      "[Adam | lr=0.1] Epoch 1701/4000: train_loss=2.0664  test_loss=2.2227  λ_max=131.4319\n",
      "[Adam | lr=0.1] Epoch 1702/4000: train_loss=2.0695  test_loss=2.2302  λ_max=118.9947\n",
      "[Adam | lr=0.1] Epoch 1703/4000: train_loss=2.0651  test_loss=2.2276  λ_max=120.3866\n",
      "[Adam | lr=0.1] Epoch 1704/4000: train_loss=2.0661  test_loss=2.2401  λ_max=122.3456\n",
      "[Adam | lr=0.1] Epoch 1705/4000: train_loss=2.0709  test_loss=2.2345  λ_max=113.7902\n",
      "[Adam | lr=0.1] Epoch 1706/4000: train_loss=2.0839  test_loss=2.2600  λ_max=119.1481\n",
      "[Adam | lr=0.1] Iter 27300: loss=2.0695\n",
      "[Adam | lr=0.1] Epoch 1707/4000: train_loss=2.1011  test_loss=2.2458  λ_max=123.0232\n",
      "[Adam | lr=0.1] Epoch 1708/4000: train_loss=2.0927  test_loss=2.2452  λ_max=117.9790\n",
      "[Adam | lr=0.1] Epoch 1709/4000: train_loss=2.0814  test_loss=2.2800  λ_max=105.8287\n",
      "[Adam | lr=0.1] Epoch 1710/4000: train_loss=2.0763  test_loss=2.2624  λ_max=107.9203\n",
      "[Adam | lr=0.1] Epoch 1711/4000: train_loss=2.0854  test_loss=2.2383  λ_max=112.7383\n",
      "[Adam | lr=0.1] Epoch 1712/4000: train_loss=2.0754  test_loss=2.2788  λ_max=116.8610\n",
      "[Adam | lr=0.1] Iter 27400: loss=2.0805\n",
      "[Adam | lr=0.1] Epoch 1713/4000: train_loss=2.0895  test_loss=2.2815  λ_max=126.9844\n",
      "[Adam | lr=0.1] Epoch 1714/4000: train_loss=2.1179  test_loss=2.3472  λ_max=83.6468\n",
      "[Adam | lr=0.1] Epoch 1715/4000: train_loss=2.1180  test_loss=2.3244  λ_max=94.1770\n",
      "[Adam | lr=0.1] Epoch 1716/4000: train_loss=2.0937  test_loss=2.2498  λ_max=107.2274\n",
      "[Adam | lr=0.1] Epoch 1717/4000: train_loss=2.0743  test_loss=2.2574  λ_max=106.7285\n",
      "[Adam | lr=0.1] Epoch 1718/4000: train_loss=2.0837  test_loss=2.3074  λ_max=80.9506\n",
      "[Adam | lr=0.1] Iter 27500: loss=2.0872\n",
      "[Adam | lr=0.1] Epoch 1719/4000: train_loss=2.0861  test_loss=2.2658  λ_max=93.8856\n",
      "[Adam | lr=0.1] Epoch 1720/4000: train_loss=2.0612  test_loss=2.2352  λ_max=101.1602\n",
      "[Adam | lr=0.1] Epoch 1721/4000: train_loss=2.0467  test_loss=2.2359  λ_max=99.8082\n",
      "[Adam | lr=0.1] Epoch 1722/4000: train_loss=2.0425  test_loss=2.2328  λ_max=102.7545\n",
      "[Adam | lr=0.1] Epoch 1723/4000: train_loss=2.0493  test_loss=2.2638  λ_max=98.9877\n",
      "[Adam | lr=0.1] Epoch 1724/4000: train_loss=2.0562  test_loss=2.2548  λ_max=95.3786\n",
      "[Adam | lr=0.1] Iter 27600: loss=2.0407\n",
      "[Adam | lr=0.1] Epoch 1725/4000: train_loss=2.0445  test_loss=2.2405  λ_max=101.9347\n",
      "[Adam | lr=0.1] Epoch 1726/4000: train_loss=2.0385  test_loss=2.2509  λ_max=94.5166\n",
      "[Adam | lr=0.1] Epoch 1727/4000: train_loss=2.0421  test_loss=2.2665  λ_max=107.4043\n",
      "[Adam | lr=0.1] Epoch 1728/4000: train_loss=2.0499  test_loss=2.2483  λ_max=103.3717\n",
      "[Adam | lr=0.1] Epoch 1729/4000: train_loss=2.0469  test_loss=2.2505  λ_max=101.9870\n",
      "[Adam | lr=0.1] Epoch 1730/4000: train_loss=2.0343  test_loss=2.2393  λ_max=90.3076\n",
      "[Adam | lr=0.1] Epoch 1731/4000: train_loss=2.0326  test_loss=2.2490  λ_max=99.0150\n",
      "[Adam | lr=0.1] Iter 27700: loss=2.0200\n",
      "[Adam | lr=0.1] Epoch 1732/4000: train_loss=2.0353  test_loss=2.2423  λ_max=98.2477\n",
      "[Adam | lr=0.1] Epoch 1733/4000: train_loss=2.0496  test_loss=2.2498  λ_max=99.4016\n",
      "[Adam | lr=0.1] Epoch 1734/4000: train_loss=2.0363  test_loss=2.2845  λ_max=91.4687\n",
      "[Adam | lr=0.1] Epoch 1735/4000: train_loss=2.0417  test_loss=2.2614  λ_max=98.9828\n",
      "[Adam | lr=0.1] Epoch 1736/4000: train_loss=2.0354  test_loss=2.2576  λ_max=96.8639\n",
      "[Adam | lr=0.1] Epoch 1737/4000: train_loss=2.0517  test_loss=2.3136  λ_max=78.8087\n",
      "[Adam | lr=0.1] Iter 27800: loss=2.0591\n",
      "[Adam | lr=0.1] Epoch 1738/4000: train_loss=2.0752  test_loss=2.2707  λ_max=71.2718\n",
      "[Adam | lr=0.1] Epoch 1739/4000: train_loss=2.0474  test_loss=2.2603  λ_max=90.9981\n",
      "[Adam | lr=0.1] Epoch 1740/4000: train_loss=2.0311  test_loss=2.2594  λ_max=89.0446\n",
      "[Adam | lr=0.1] Epoch 1741/4000: train_loss=2.0456  test_loss=2.3842  λ_max=81.1770\n",
      "[Adam | lr=0.1] Epoch 1742/4000: train_loss=2.0599  test_loss=2.2638  λ_max=89.8632\n",
      "[Adam | lr=0.1] Epoch 1743/4000: train_loss=2.0286  test_loss=2.2624  λ_max=83.1747\n",
      "[Adam | lr=0.1] Iter 27900: loss=1.9995\n",
      "[Adam | lr=0.1] Epoch 1744/4000: train_loss=2.0226  test_loss=2.2683  λ_max=60.6733\n",
      "[Adam | lr=0.1] Epoch 1745/4000: train_loss=2.0208  test_loss=2.2869  λ_max=89.2466\n",
      "[Adam | lr=0.1] Epoch 1746/4000: train_loss=2.0302  test_loss=2.2597  λ_max=67.8648\n",
      "[Adam | lr=0.1] Epoch 1747/4000: train_loss=2.0259  test_loss=2.2778  λ_max=83.4980\n",
      "[Adam | lr=0.1] Epoch 1748/4000: train_loss=2.0160  test_loss=2.2680  λ_max=89.5809\n",
      "[Adam | lr=0.1] Epoch 1749/4000: train_loss=2.0207  test_loss=2.2821  λ_max=85.7661\n",
      "[Adam | lr=0.1] Iter 28000: loss=2.0287\n",
      "[Adam | lr=0.1] Epoch 1750/4000: train_loss=2.0253  test_loss=2.2769  λ_max=92.9049\n",
      "[Adam | lr=0.1] Epoch 1751/4000: train_loss=2.0166  test_loss=2.2715  λ_max=91.1314\n",
      "[Adam | lr=0.1] Epoch 1752/4000: train_loss=2.0165  test_loss=2.2543  λ_max=87.8775\n",
      "[Adam | lr=0.1] Epoch 1753/4000: train_loss=2.0135  test_loss=2.2883  λ_max=93.7174\n",
      "[Adam | lr=0.1] Epoch 1754/4000: train_loss=2.0450  test_loss=2.2798  λ_max=82.6491\n",
      "[Adam | lr=0.1] Epoch 1755/4000: train_loss=2.0226  test_loss=2.2958  λ_max=90.5688\n",
      "[Adam | lr=0.1] Epoch 1756/4000: train_loss=2.0182  test_loss=2.3001  λ_max=79.2264\n",
      "[Adam | lr=0.1] Iter 28100: loss=2.0131\n",
      "[Adam | lr=0.1] Epoch 1757/4000: train_loss=2.0271  test_loss=2.2780  λ_max=85.3949\n",
      "[Adam | lr=0.1] Epoch 1758/4000: train_loss=2.0182  test_loss=2.3004  λ_max=84.9283\n",
      "[Adam | lr=0.1] Epoch 1759/4000: train_loss=2.0068  test_loss=2.2710  λ_max=86.2310\n",
      "[Adam | lr=0.1] Epoch 1760/4000: train_loss=2.0525  test_loss=2.2777  λ_max=84.8204\n",
      "[Adam | lr=0.1] Epoch 1761/4000: train_loss=2.0145  test_loss=2.2608  λ_max=82.1616\n",
      "[Adam | lr=0.1] Epoch 1762/4000: train_loss=2.0058  test_loss=2.2754  λ_max=90.3216\n",
      "[Adam | lr=0.1] Iter 28200: loss=2.0331\n",
      "[Adam | lr=0.1] Epoch 1763/4000: train_loss=2.0195  test_loss=2.2757  λ_max=75.4169\n",
      "[Adam | lr=0.1] Epoch 1764/4000: train_loss=2.0049  test_loss=2.2698  λ_max=83.4697\n",
      "[Adam | lr=0.1] Epoch 1765/4000: train_loss=2.0251  test_loss=2.2940  λ_max=66.1878\n",
      "[Adam | lr=0.1] Epoch 1766/4000: train_loss=2.0492  test_loss=2.3057  λ_max=82.9908\n",
      "[Adam | lr=0.1] Epoch 1767/4000: train_loss=2.0060  test_loss=2.2765  λ_max=79.1531\n",
      "[Adam | lr=0.1] Epoch 1768/4000: train_loss=1.9972  test_loss=2.2716  λ_max=64.0339\n",
      "[Adam | lr=0.1] Iter 28300: loss=2.0228\n",
      "[Adam | lr=0.1] Epoch 1769/4000: train_loss=2.0044  test_loss=2.2799  λ_max=68.0050\n",
      "[Adam | lr=0.1] Epoch 1770/4000: train_loss=1.9993  test_loss=2.2797  λ_max=74.8589\n",
      "[Adam | lr=0.1] Epoch 1771/4000: train_loss=1.9968  test_loss=2.2847  λ_max=74.1473\n",
      "[Adam | lr=0.1] Epoch 1772/4000: train_loss=1.9900  test_loss=2.2804  λ_max=79.5572\n",
      "[Adam | lr=0.1] Epoch 1773/4000: train_loss=1.9906  test_loss=2.2671  λ_max=70.7639\n",
      "[Adam | lr=0.1] Epoch 1774/4000: train_loss=1.9924  test_loss=2.2725  λ_max=72.2873\n",
      "[Adam | lr=0.1] Iter 28400: loss=1.9832\n",
      "[Adam | lr=0.1] Epoch 1775/4000: train_loss=1.9884  test_loss=2.2704  λ_max=77.1748\n",
      "[Adam | lr=0.1] Epoch 1776/4000: train_loss=1.9903  test_loss=2.2915  λ_max=69.1209\n",
      "[Adam | lr=0.1] Epoch 1777/4000: train_loss=2.0017  test_loss=2.2859  λ_max=60.4979\n",
      "[Adam | lr=0.1] Epoch 1778/4000: train_loss=2.0463  test_loss=2.3486  λ_max=67.1904\n",
      "[Adam | lr=0.1] Epoch 1779/4000: train_loss=2.0148  test_loss=2.2873  λ_max=67.1018\n",
      "[Adam | lr=0.1] Epoch 1780/4000: train_loss=1.9861  test_loss=2.2947  λ_max=62.4226\n",
      "[Adam | lr=0.1] Epoch 1781/4000: train_loss=1.9883  test_loss=2.2895  λ_max=65.9724\n",
      "[Adam | lr=0.1] Iter 28500: loss=1.9991\n",
      "[Adam | lr=0.1] Epoch 1782/4000: train_loss=1.9857  test_loss=2.2810  λ_max=60.6218\n",
      "[Adam | lr=0.1] Epoch 1783/4000: train_loss=1.9784  test_loss=2.2804  λ_max=68.6322\n",
      "[Adam | lr=0.1] Epoch 1784/4000: train_loss=1.9723  test_loss=2.2892  λ_max=72.2638\n",
      "[Adam | lr=0.1] Epoch 1785/4000: train_loss=1.9752  test_loss=2.3011  λ_max=62.0065\n",
      "[Adam | lr=0.1] Epoch 1786/4000: train_loss=1.9726  test_loss=2.3053  λ_max=63.7350\n",
      "[Adam | lr=0.1] Epoch 1787/4000: train_loss=1.9739  test_loss=2.2934  λ_max=61.1504\n",
      "[Adam | lr=0.1] Iter 28600: loss=1.9983\n",
      "[Adam | lr=0.1] Epoch 1788/4000: train_loss=1.9777  test_loss=2.2929  λ_max=62.4479\n",
      "[Adam | lr=0.1] Epoch 1789/4000: train_loss=1.9796  test_loss=2.2929  λ_max=59.5745\n",
      "[Adam | lr=0.1] Epoch 1790/4000: train_loss=1.9697  test_loss=2.2959  λ_max=64.2214\n",
      "[Adam | lr=0.1] Epoch 1791/4000: train_loss=1.9767  test_loss=2.2827  λ_max=68.8640\n",
      "[Adam | lr=0.1] Epoch 1792/4000: train_loss=1.9796  test_loss=2.2994  λ_max=64.5035\n",
      "[Adam | lr=0.1] Epoch 1793/4000: train_loss=1.9619  test_loss=2.2951  λ_max=62.3551\n",
      "[Adam | lr=0.1] Iter 28700: loss=1.9500\n",
      "[Adam | lr=0.1] Epoch 1794/4000: train_loss=1.9574  test_loss=2.2897  λ_max=70.1015\n",
      "[Adam | lr=0.1] Epoch 1795/4000: train_loss=1.9541  test_loss=2.3037  λ_max=65.2017\n",
      "[Adam | lr=0.1] Epoch 1796/4000: train_loss=1.9455  test_loss=2.3044  λ_max=71.2961\n",
      "[Adam | lr=0.1] Epoch 1797/4000: train_loss=1.9605  test_loss=2.3208  λ_max=70.3549\n",
      "[Adam | lr=0.1] Epoch 1798/4000: train_loss=1.9522  test_loss=2.3000  λ_max=64.6476\n",
      "[Adam | lr=0.1] Epoch 1799/4000: train_loss=1.9589  test_loss=2.3050  λ_max=67.2676\n",
      "[Adam | lr=0.1] Iter 28800: loss=1.9694\n",
      "[Adam | lr=0.1] Epoch 1800/4000: train_loss=1.9650  test_loss=2.3091  λ_max=64.9774\n",
      "[Adam | lr=0.1] Epoch 1801/4000: train_loss=1.9511  test_loss=2.2952  λ_max=65.7289\n",
      "[Adam | lr=0.1] Epoch 1802/4000: train_loss=1.9490  test_loss=2.3010  λ_max=67.6491\n",
      "[Adam | lr=0.1] Epoch 1803/4000: train_loss=1.9500  test_loss=2.3307  λ_max=72.9133\n",
      "[Adam | lr=0.1] Epoch 1804/4000: train_loss=1.9458  test_loss=2.3099  λ_max=70.7062\n",
      "[Adam | lr=0.1] Epoch 1805/4000: train_loss=1.9480  test_loss=2.3197  λ_max=72.5559\n",
      "[Adam | lr=0.1] Epoch 1806/4000: train_loss=1.9455  test_loss=2.3021  λ_max=75.3823\n",
      "[Adam | lr=0.1] Iter 28900: loss=1.9521\n",
      "[Adam | lr=0.1] Epoch 1807/4000: train_loss=1.9401  test_loss=2.3280  λ_max=76.9837\n",
      "[Adam | lr=0.1] Epoch 1808/4000: train_loss=1.9519  test_loss=2.3252  λ_max=69.7065\n",
      "[Adam | lr=0.1] Epoch 1809/4000: train_loss=1.9699  test_loss=2.3646  λ_max=65.1188\n",
      "[Adam | lr=0.1] Epoch 1810/4000: train_loss=1.9858  test_loss=2.3238  λ_max=68.0779\n",
      "[Adam | lr=0.1] Epoch 1811/4000: train_loss=1.9448  test_loss=2.3434  λ_max=70.0550\n",
      "[Adam | lr=0.1] Epoch 1812/4000: train_loss=1.9448  test_loss=2.3099  λ_max=64.9526\n",
      "[Adam | lr=0.1] Iter 29000: loss=1.9320\n",
      "[Adam | lr=0.1] Epoch 1813/4000: train_loss=1.9353  test_loss=2.3223  λ_max=71.6469\n",
      "[Adam | lr=0.1] Epoch 1814/4000: train_loss=1.9382  test_loss=2.3374  λ_max=66.1233\n",
      "[Adam | lr=0.1] Epoch 1815/4000: train_loss=1.9355  test_loss=2.3266  λ_max=63.2373\n",
      "[Adam | lr=0.1] Epoch 1816/4000: train_loss=1.9284  test_loss=2.3245  λ_max=65.6870\n",
      "[Adam | lr=0.1] Epoch 1817/4000: train_loss=1.9294  test_loss=2.3146  λ_max=65.8761\n",
      "[Adam | lr=0.1] Epoch 1818/4000: train_loss=1.9287  test_loss=2.3362  λ_max=62.1283\n",
      "[Adam | lr=0.1] Iter 29100: loss=1.9402\n",
      "[Adam | lr=0.1] Epoch 1819/4000: train_loss=1.9312  test_loss=2.3248  λ_max=63.3056\n",
      "[Adam | lr=0.1] Epoch 1820/4000: train_loss=1.9244  test_loss=2.3184  λ_max=59.6023\n",
      "[Adam | lr=0.1] Epoch 1821/4000: train_loss=1.9259  test_loss=2.3191  λ_max=66.0318\n",
      "[Adam | lr=0.1] Epoch 1822/4000: train_loss=1.9250  test_loss=2.3214  λ_max=65.8743\n",
      "[Adam | lr=0.1] Epoch 1823/4000: train_loss=1.9248  test_loss=2.3292  λ_max=63.4976\n",
      "[Adam | lr=0.1] Epoch 1824/4000: train_loss=1.9221  test_loss=2.3281  λ_max=62.4090\n",
      "[Adam | lr=0.1] Iter 29200: loss=1.9095\n",
      "[Adam | lr=0.1] Epoch 1825/4000: train_loss=1.9242  test_loss=2.3179  λ_max=63.6868\n",
      "[Adam | lr=0.1] Epoch 1826/4000: train_loss=1.9323  test_loss=2.3498  λ_max=65.8907\n",
      "[Adam | lr=0.1] Epoch 1827/4000: train_loss=1.9408  test_loss=2.3367  λ_max=62.4568\n",
      "[Adam | lr=0.1] Epoch 1828/4000: train_loss=1.9294  test_loss=2.3268  λ_max=62.9086\n",
      "[Adam | lr=0.1] Epoch 1829/4000: train_loss=1.9209  test_loss=2.3264  λ_max=62.4625\n",
      "[Adam | lr=0.1] Epoch 1830/4000: train_loss=1.9193  test_loss=2.3266  λ_max=62.5448\n",
      "[Adam | lr=0.1] Epoch 1831/4000: train_loss=1.9203  test_loss=2.3327  λ_max=57.8936\n",
      "[Adam | lr=0.1] Iter 29300: loss=1.9224\n",
      "[Adam | lr=0.1] Epoch 1832/4000: train_loss=1.9404  test_loss=2.4111  λ_max=54.6525\n",
      "[Adam | lr=0.1] Epoch 1833/4000: train_loss=1.9400  test_loss=2.3398  λ_max=60.8891\n",
      "[Adam | lr=0.1] Epoch 1834/4000: train_loss=1.9215  test_loss=2.3372  λ_max=51.4721\n",
      "[Adam | lr=0.1] Epoch 1835/4000: train_loss=1.9151  test_loss=2.3294  λ_max=56.7593\n",
      "[Adam | lr=0.1] Epoch 1836/4000: train_loss=1.9156  test_loss=2.3398  λ_max=55.6715\n",
      "[Adam | lr=0.1] Epoch 1837/4000: train_loss=1.9164  test_loss=2.3280  λ_max=52.4095\n",
      "[Adam | lr=0.1] Iter 29400: loss=1.8928\n",
      "[Adam | lr=0.1] Epoch 1838/4000: train_loss=1.9148  test_loss=2.3252  λ_max=53.7189\n",
      "[Adam | lr=0.1] Epoch 1839/4000: train_loss=1.9093  test_loss=2.3368  λ_max=55.2993\n",
      "[Adam | lr=0.1] Epoch 1840/4000: train_loss=1.9130  test_loss=2.3431  λ_max=54.5974\n",
      "[Adam | lr=0.1] Epoch 1841/4000: train_loss=1.9192  test_loss=2.3418  λ_max=57.4742\n",
      "[Adam | lr=0.1] Epoch 1842/4000: train_loss=1.9099  test_loss=2.3517  λ_max=56.3749\n",
      "[Adam | lr=0.1] Epoch 1843/4000: train_loss=1.9093  test_loss=2.3468  λ_max=58.2045\n",
      "[Adam | lr=0.1] Iter 29500: loss=1.9316\n",
      "[Adam | lr=0.1] Epoch 1844/4000: train_loss=1.9212  test_loss=2.3617  λ_max=52.9061\n",
      "[Adam | lr=0.1] Epoch 1845/4000: train_loss=1.9123  test_loss=2.3604  λ_max=52.4589\n",
      "[Adam | lr=0.1] Epoch 1846/4000: train_loss=1.9114  test_loss=2.3467  λ_max=57.8840\n",
      "[Adam | lr=0.1] Epoch 1847/4000: train_loss=1.9239  test_loss=2.3598  λ_max=52.9894\n",
      "[Adam | lr=0.1] Epoch 1848/4000: train_loss=1.9125  test_loss=2.3682  λ_max=53.6875\n",
      "[Adam | lr=0.1] Epoch 1849/4000: train_loss=1.9093  test_loss=2.3487  λ_max=53.6632\n",
      "[Adam | lr=0.1] Iter 29600: loss=1.9176\n",
      "[Adam | lr=0.1] Epoch 1850/4000: train_loss=1.9012  test_loss=2.3455  λ_max=52.1454\n",
      "[Adam | lr=0.1] Epoch 1851/4000: train_loss=1.8989  test_loss=2.3444  λ_max=56.7448\n",
      "[Adam | lr=0.1] Epoch 1852/4000: train_loss=1.9017  test_loss=2.3527  λ_max=57.1412\n",
      "[Adam | lr=0.1] Epoch 1853/4000: train_loss=1.9020  test_loss=2.3596  λ_max=49.0664\n",
      "[Adam | lr=0.1] Epoch 1854/4000: train_loss=1.9021  test_loss=2.3571  λ_max=55.2262\n",
      "[Adam | lr=0.1] Epoch 1855/4000: train_loss=1.9047  test_loss=2.3697  λ_max=57.0066\n",
      "[Adam | lr=0.1] Epoch 1856/4000: train_loss=1.9020  test_loss=2.3540  λ_max=54.2058\n",
      "[Adam | lr=0.1] Iter 29700: loss=1.8872\n",
      "[Adam | lr=0.1] Epoch 1857/4000: train_loss=1.9019  test_loss=2.3711  λ_max=51.0009\n",
      "[Adam | lr=0.1] Epoch 1858/4000: train_loss=1.9003  test_loss=2.3671  λ_max=56.7951\n",
      "[Adam | lr=0.1] Epoch 1859/4000: train_loss=1.8937  test_loss=2.3594  λ_max=47.1349\n",
      "[Adam | lr=0.1] Epoch 1860/4000: train_loss=1.8977  test_loss=2.3592  λ_max=52.4544\n",
      "[Adam | lr=0.1] Epoch 1861/4000: train_loss=1.8927  test_loss=2.3621  λ_max=52.9429\n",
      "[Adam | lr=0.1] Epoch 1862/4000: train_loss=1.8976  test_loss=2.3706  λ_max=47.3047\n",
      "[Adam | lr=0.1] Iter 29800: loss=1.9050\n",
      "[Adam | lr=0.1] Epoch 1863/4000: train_loss=1.8990  test_loss=2.3764  λ_max=55.3816\n",
      "[Adam | lr=0.1] Epoch 1864/4000: train_loss=1.8961  test_loss=2.3711  λ_max=57.1660\n",
      "[Adam | lr=0.1] Epoch 1865/4000: train_loss=1.8899  test_loss=2.3679  λ_max=62.2685\n",
      "[Adam | lr=0.1] Epoch 1866/4000: train_loss=1.8927  test_loss=2.3702  λ_max=62.5470\n",
      "[Adam | lr=0.1] Epoch 1867/4000: train_loss=1.8864  test_loss=2.3762  λ_max=65.9658\n",
      "[Adam | lr=0.1] Epoch 1868/4000: train_loss=1.8878  test_loss=2.3892  λ_max=67.6972\n",
      "[Adam | lr=0.1] Iter 29900: loss=1.9281\n",
      "[Adam | lr=0.1] Epoch 1869/4000: train_loss=1.9103  test_loss=2.4129  λ_max=59.9683\n",
      "[Adam | lr=0.1] Epoch 1870/4000: train_loss=1.8970  test_loss=2.3814  λ_max=56.3720\n",
      "[Adam | lr=0.1] Epoch 1871/4000: train_loss=1.8874  test_loss=2.3759  λ_max=59.9172\n",
      "[Adam | lr=0.1] Epoch 1872/4000: train_loss=1.8799  test_loss=2.3793  λ_max=64.3750\n",
      "[Adam | lr=0.1] Epoch 1873/4000: train_loss=1.8856  test_loss=2.3800  λ_max=67.7824\n",
      "[Adam | lr=0.1] Epoch 1874/4000: train_loss=1.8863  test_loss=2.3871  λ_max=73.2044\n",
      "[Adam | lr=0.1] Iter 30000: loss=1.8918\n",
      "[Adam | lr=0.1] Epoch 1875/4000: train_loss=1.8879  test_loss=2.4195  λ_max=67.6257\n",
      "[Adam | lr=0.1] Epoch 1876/4000: train_loss=1.8830  test_loss=2.3904  λ_max=71.0190\n",
      "[Adam | lr=0.1] Epoch 1877/4000: train_loss=1.8732  test_loss=2.3945  λ_max=77.4243\n",
      "[Adam | lr=0.1] Epoch 1878/4000: train_loss=1.8810  test_loss=2.3990  λ_max=73.8360\n",
      "[Adam | lr=0.1] Epoch 1879/4000: train_loss=1.8798  test_loss=2.4229  λ_max=73.2813\n",
      "[Adam | lr=0.1] Epoch 1880/4000: train_loss=1.8807  test_loss=2.3960  λ_max=67.0414\n",
      "[Adam | lr=0.1] Epoch 1881/4000: train_loss=1.8701  test_loss=2.4316  λ_max=65.4857\n",
      "[Adam | lr=0.1] Iter 30100: loss=1.8944\n",
      "[Adam | lr=0.1] Epoch 1882/4000: train_loss=1.8755  test_loss=2.4035  λ_max=67.9148\n",
      "[Adam | lr=0.1] Epoch 1883/4000: train_loss=1.8680  test_loss=2.4051  λ_max=70.3864\n",
      "[Adam | lr=0.1] Epoch 1884/4000: train_loss=1.8785  test_loss=2.4246  λ_max=62.1444\n",
      "[Adam | lr=0.1] Epoch 1885/4000: train_loss=1.8720  test_loss=2.4113  λ_max=62.0250\n",
      "[Adam | lr=0.1] Epoch 1886/4000: train_loss=1.8664  test_loss=2.4159  λ_max=63.3272\n",
      "[Adam | lr=0.1] Epoch 1887/4000: train_loss=1.8609  test_loss=2.4115  λ_max=61.5435\n",
      "[Adam | lr=0.1] Iter 30200: loss=1.8659\n",
      "[Adam | lr=0.1] Epoch 1888/4000: train_loss=1.8618  test_loss=2.4182  λ_max=65.6067\n",
      "[Adam | lr=0.1] Epoch 1889/4000: train_loss=1.8575  test_loss=2.4200  λ_max=64.5690\n",
      "[Adam | lr=0.1] Epoch 1890/4000: train_loss=1.8589  test_loss=2.4175  λ_max=64.6214\n",
      "[Adam | lr=0.1] Epoch 1891/4000: train_loss=1.8554  test_loss=2.4292  λ_max=63.0456\n",
      "[Adam | lr=0.1] Epoch 1892/4000: train_loss=1.8647  test_loss=2.4178  λ_max=67.1101\n",
      "[Adam | lr=0.1] Epoch 1893/4000: train_loss=1.8595  test_loss=2.4262  λ_max=65.4105\n",
      "[Adam | lr=0.1] Iter 30300: loss=1.8447\n",
      "[Adam | lr=0.1] Epoch 1894/4000: train_loss=1.8558  test_loss=2.4171  λ_max=65.4209\n",
      "[Adam | lr=0.1] Epoch 1895/4000: train_loss=1.8522  test_loss=2.4175  λ_max=63.6297\n",
      "[Adam | lr=0.1] Epoch 1896/4000: train_loss=1.8494  test_loss=2.4391  λ_max=66.4723\n",
      "[Adam | lr=0.1] Epoch 1897/4000: train_loss=1.8485  test_loss=2.4394  λ_max=70.1124\n",
      "[Adam | lr=0.1] Epoch 1898/4000: train_loss=1.8563  test_loss=2.4384  λ_max=66.4274\n",
      "[Adam | lr=0.1] Epoch 1899/4000: train_loss=1.8523  test_loss=2.4416  λ_max=60.9748\n",
      "[Adam | lr=0.1] Iter 30400: loss=1.8717\n",
      "[Adam | lr=0.1] Epoch 1900/4000: train_loss=1.8489  test_loss=2.4413  λ_max=62.4777\n",
      "[Adam | lr=0.1] Epoch 1901/4000: train_loss=1.8503  test_loss=2.4544  λ_max=63.1805\n",
      "[Adam | lr=0.1] Epoch 1902/4000: train_loss=1.8415  test_loss=2.4516  λ_max=67.0003\n",
      "[Adam | lr=0.1] Epoch 1903/4000: train_loss=1.8346  test_loss=2.4586  λ_max=73.3531\n",
      "[Adam | lr=0.1] Epoch 1904/4000: train_loss=1.8379  test_loss=2.4561  λ_max=45.6713\n",
      "[Adam | lr=0.1] Epoch 1905/4000: train_loss=1.8261  test_loss=2.4622  λ_max=60.0474\n",
      "[Adam | lr=0.1] Epoch 1906/4000: train_loss=1.8260  test_loss=2.4565  λ_max=63.9551\n",
      "[Adam | lr=0.1] Iter 30500: loss=1.8103\n",
      "[Adam | lr=0.1] Epoch 1907/4000: train_loss=1.8222  test_loss=2.4601  λ_max=66.3596\n",
      "[Adam | lr=0.1] Epoch 1908/4000: train_loss=1.8153  test_loss=2.4670  λ_max=64.6202\n",
      "[Adam | lr=0.1] Epoch 1909/4000: train_loss=1.8111  test_loss=2.4732  λ_max=74.4962\n",
      "[Adam | lr=0.1] Epoch 1910/4000: train_loss=1.8124  test_loss=2.4707  λ_max=76.8609\n",
      "[Adam | lr=0.1] Epoch 1911/4000: train_loss=1.8105  test_loss=2.4689  λ_max=77.6889\n",
      "[Adam | lr=0.1] Epoch 1912/4000: train_loss=1.8070  test_loss=2.4733  λ_max=78.9841\n",
      "[Adam | lr=0.1] Iter 30600: loss=1.8249\n",
      "[Adam | lr=0.1] Epoch 1913/4000: train_loss=1.8026  test_loss=2.4815  λ_max=76.3200\n",
      "[Adam | lr=0.1] Epoch 1914/4000: train_loss=1.8058  test_loss=2.4940  λ_max=71.4309\n",
      "[Adam | lr=0.1] Epoch 1915/4000: train_loss=1.8027  test_loss=2.4898  λ_max=70.5293\n",
      "[Adam | lr=0.1] Epoch 1916/4000: train_loss=1.7995  test_loss=2.5072  λ_max=67.0500\n",
      "[Adam | lr=0.1] Epoch 1917/4000: train_loss=1.8064  test_loss=2.5087  λ_max=68.1180\n",
      "[Adam | lr=0.1] Epoch 1918/4000: train_loss=1.8022  test_loss=2.4984  λ_max=71.1581\n",
      "[Adam | lr=0.1] Iter 30700: loss=1.7809\n",
      "[Adam | lr=0.1] Epoch 1919/4000: train_loss=1.7880  test_loss=2.4919  λ_max=67.2700\n",
      "[Adam | lr=0.1] Epoch 1920/4000: train_loss=1.7832  test_loss=2.5000  λ_max=66.7316\n",
      "[Adam | lr=0.1] Epoch 1921/4000: train_loss=1.7736  test_loss=2.5087  λ_max=67.5834\n",
      "[Adam | lr=0.1] Epoch 1922/4000: train_loss=1.7745  test_loss=2.5182  λ_max=67.9411\n",
      "[Adam | lr=0.1] Epoch 1923/4000: train_loss=1.7766  test_loss=2.5466  λ_max=67.4980\n",
      "[Adam | lr=0.1] Epoch 1924/4000: train_loss=1.7729  test_loss=2.5248  λ_max=65.9640\n",
      "[Adam | lr=0.1] Iter 30800: loss=1.7918\n",
      "[Adam | lr=0.1] Epoch 1925/4000: train_loss=1.7721  test_loss=2.5590  λ_max=58.6900\n",
      "[Adam | lr=0.1] Epoch 1926/4000: train_loss=1.7711  test_loss=2.5264  λ_max=58.5116\n",
      "[Adam | lr=0.1] Epoch 1927/4000: train_loss=1.7643  test_loss=2.5282  λ_max=53.6201\n",
      "[Adam | lr=0.1] Epoch 1928/4000: train_loss=1.7628  test_loss=2.5368  λ_max=58.9705\n",
      "[Adam | lr=0.1] Epoch 1929/4000: train_loss=1.7638  test_loss=2.5424  λ_max=48.5380\n",
      "[Adam | lr=0.1] Epoch 1930/4000: train_loss=1.7597  test_loss=2.5341  λ_max=60.1227\n",
      "[Adam | lr=0.1] Epoch 1931/4000: train_loss=1.7581  test_loss=2.5487  λ_max=59.1972\n",
      "[Adam | lr=0.1] Iter 30900: loss=1.7597\n",
      "[Adam | lr=0.1] Epoch 1932/4000: train_loss=1.7531  test_loss=2.5541  λ_max=58.0023\n",
      "[Adam | lr=0.1] Epoch 1933/4000: train_loss=1.7577  test_loss=2.5542  λ_max=54.7335\n",
      "[Adam | lr=0.1] Epoch 1934/4000: train_loss=1.7547  test_loss=2.5621  λ_max=57.4307\n",
      "[Adam | lr=0.1] Epoch 1935/4000: train_loss=1.7574  test_loss=2.5635  λ_max=54.9028\n",
      "[Adam | lr=0.1] Epoch 1936/4000: train_loss=1.7528  test_loss=2.5573  λ_max=55.6748\n",
      "[Adam | lr=0.1] Epoch 1937/4000: train_loss=1.7530  test_loss=2.5616  λ_max=49.2050\n",
      "[Adam | lr=0.1] Iter 31000: loss=1.7360\n",
      "[Adam | lr=0.1] Epoch 1938/4000: train_loss=1.7549  test_loss=2.5761  λ_max=53.6518\n",
      "[Adam | lr=0.1] Epoch 1939/4000: train_loss=1.7452  test_loss=2.5622  λ_max=54.2168\n",
      "[Adam | lr=0.1] Epoch 1940/4000: train_loss=1.7411  test_loss=2.5576  λ_max=54.2133\n",
      "[Adam | lr=0.1] Epoch 1941/4000: train_loss=1.7497  test_loss=2.5655  λ_max=55.0841\n",
      "[Adam | lr=0.1] Epoch 1942/4000: train_loss=1.7448  test_loss=2.5803  λ_max=54.7267\n",
      "[Adam | lr=0.1] Epoch 1943/4000: train_loss=1.7406  test_loss=2.5642  λ_max=48.7720\n",
      "[Adam | lr=0.1] Iter 31100: loss=1.7544\n",
      "[Adam | lr=0.1] Epoch 1944/4000: train_loss=1.7404  test_loss=2.5829  λ_max=52.4572\n",
      "[Adam | lr=0.1] Epoch 1945/4000: train_loss=1.7395  test_loss=2.5871  λ_max=51.8445\n",
      "[Adam | lr=0.1] Epoch 1946/4000: train_loss=1.7388  test_loss=2.5906  λ_max=48.5529\n",
      "[Adam | lr=0.1] Epoch 1947/4000: train_loss=1.7360  test_loss=2.5872  λ_max=49.7883\n",
      "[Adam | lr=0.1] Epoch 1948/4000: train_loss=1.7322  test_loss=2.5826  λ_max=55.3739\n",
      "[Adam | lr=0.1] Epoch 1949/4000: train_loss=1.7312  test_loss=2.5889  λ_max=55.2994\n",
      "[Adam | lr=0.1] Iter 31200: loss=1.7473\n",
      "[Adam | lr=0.1] Epoch 1950/4000: train_loss=1.7247  test_loss=2.5799  λ_max=53.4856\n",
      "[Adam | lr=0.1] Epoch 1951/4000: train_loss=1.7323  test_loss=2.5960  λ_max=54.2623\n",
      "[Adam | lr=0.1] Epoch 1952/4000: train_loss=1.7315  test_loss=2.5955  λ_max=45.2694\n",
      "[Adam | lr=0.1] Epoch 1953/4000: train_loss=1.7256  test_loss=2.6149  λ_max=46.2171\n",
      "[Adam | lr=0.1] Epoch 1954/4000: train_loss=1.7340  test_loss=2.6092  λ_max=56.8062\n",
      "[Adam | lr=0.1] Epoch 1955/4000: train_loss=1.7396  test_loss=2.6241  λ_max=56.5725\n",
      "[Adam | lr=0.1] Epoch 1956/4000: train_loss=1.7297  test_loss=2.6189  λ_max=54.8455\n",
      "[Adam | lr=0.1] Iter 31300: loss=1.6897\n",
      "[Adam | lr=0.1] Epoch 1957/4000: train_loss=1.7213  test_loss=2.6347  λ_max=55.9895\n",
      "[Adam | lr=0.1] Epoch 1958/4000: train_loss=1.7208  test_loss=2.6077  λ_max=56.0798\n",
      "[Adam | lr=0.1] Epoch 1959/4000: train_loss=1.7131  test_loss=2.6351  λ_max=47.8885\n",
      "[Adam | lr=0.1] Epoch 1960/4000: train_loss=1.7176  test_loss=2.6459  λ_max=53.9613\n",
      "[Adam | lr=0.1] Epoch 1961/4000: train_loss=1.7194  test_loss=2.6367  λ_max=56.2427\n",
      "[Adam | lr=0.1] Epoch 1962/4000: train_loss=1.7148  test_loss=2.6435  λ_max=51.3332\n",
      "[Adam | lr=0.1] Iter 31400: loss=1.7142\n",
      "[Adam | lr=0.1] Epoch 1963/4000: train_loss=1.7177  test_loss=2.6751  λ_max=55.6453\n",
      "[Adam | lr=0.1] Epoch 1964/4000: train_loss=1.7135  test_loss=2.6400  λ_max=56.7399\n",
      "[Adam | lr=0.1] Epoch 1965/4000: train_loss=1.7101  test_loss=2.6265  λ_max=56.1850\n",
      "[Adam | lr=0.1] Epoch 1966/4000: train_loss=1.6964  test_loss=2.6413  λ_max=58.3682\n",
      "[Adam | lr=0.1] Epoch 1967/4000: train_loss=1.6969  test_loss=2.6666  λ_max=68.3247\n",
      "[Adam | lr=0.1] Epoch 1968/4000: train_loss=1.6928  test_loss=2.6443  λ_max=74.0303\n",
      "[Adam | lr=0.1] Iter 31500: loss=1.6867\n",
      "[Adam | lr=0.1] Epoch 1969/4000: train_loss=1.6929  test_loss=2.6715  λ_max=54.3685\n",
      "[Adam | lr=0.1] Epoch 1970/4000: train_loss=1.6906  test_loss=2.6737  λ_max=65.3254\n",
      "[Adam | lr=0.1] Epoch 1971/4000: train_loss=1.6854  test_loss=2.6726  λ_max=74.0635\n",
      "[Adam | lr=0.1] Epoch 1972/4000: train_loss=1.6825  test_loss=2.6766  λ_max=79.9018\n",
      "[Adam | lr=0.1] Epoch 1973/4000: train_loss=1.6829  test_loss=2.7210  λ_max=67.7583\n",
      "[Adam | lr=0.1] Epoch 1974/4000: train_loss=1.6806  test_loss=2.7024  λ_max=63.2121\n",
      "[Adam | lr=0.1] Iter 31600: loss=1.6835\n",
      "[Adam | lr=0.1] Epoch 1975/4000: train_loss=1.6723  test_loss=2.6895  λ_max=52.7133\n",
      "[Adam | lr=0.1] Epoch 1976/4000: train_loss=1.6702  test_loss=2.7162  λ_max=64.3703\n",
      "[Adam | lr=0.1] Epoch 1977/4000: train_loss=1.6809  test_loss=2.7585  λ_max=71.0832\n",
      "[Adam | lr=0.1] Epoch 1978/4000: train_loss=1.6707  test_loss=2.7071  λ_max=73.7938\n",
      "[Adam | lr=0.1] Epoch 1979/4000: train_loss=1.6631  test_loss=2.7319  λ_max=81.3713\n",
      "[Adam | lr=0.1] Epoch 1980/4000: train_loss=1.6711  test_loss=2.7289  λ_max=63.3595\n",
      "[Adam | lr=0.1] Epoch 1981/4000: train_loss=1.6600  test_loss=2.7200  λ_max=60.7752\n",
      "[Adam | lr=0.1] Iter 31700: loss=1.6357\n",
      "[Adam | lr=0.1] Epoch 1982/4000: train_loss=1.6555  test_loss=2.7314  λ_max=61.3904\n",
      "[Adam | lr=0.1] Epoch 1983/4000: train_loss=1.6536  test_loss=2.7288  λ_max=52.8852\n",
      "[Adam | lr=0.1] Epoch 1984/4000: train_loss=1.6534  test_loss=2.7508  λ_max=64.9704\n",
      "[Adam | lr=0.1] Epoch 1985/4000: train_loss=1.6517  test_loss=2.7470  λ_max=70.7862\n",
      "[Adam | lr=0.1] Epoch 1986/4000: train_loss=1.6586  test_loss=2.7604  λ_max=67.0665\n",
      "[Adam | lr=0.1] Epoch 1987/4000: train_loss=1.6513  test_loss=2.7424  λ_max=59.7088\n",
      "[Adam | lr=0.1] Iter 31800: loss=1.6343\n",
      "[Adam | lr=0.1] Epoch 1988/4000: train_loss=1.6459  test_loss=2.7566  λ_max=67.1657\n",
      "[Adam | lr=0.1] Epoch 1989/4000: train_loss=1.6385  test_loss=2.7716  λ_max=71.8199\n",
      "[Adam | lr=0.1] Epoch 1990/4000: train_loss=1.6452  test_loss=2.7654  λ_max=63.3960\n",
      "[Adam | lr=0.1] Epoch 1991/4000: train_loss=1.6387  test_loss=2.7523  λ_max=71.5666\n",
      "[Adam | lr=0.1] Epoch 1992/4000: train_loss=1.6320  test_loss=2.7825  λ_max=68.6446\n",
      "[Adam | lr=0.1] Epoch 1993/4000: train_loss=1.6325  test_loss=2.8019  λ_max=74.4019\n",
      "[Adam | lr=0.1] Iter 31900: loss=1.6542\n",
      "[Adam | lr=0.1] Epoch 1994/4000: train_loss=1.6322  test_loss=2.7780  λ_max=75.1488\n",
      "[Adam | lr=0.1] Epoch 1995/4000: train_loss=1.6263  test_loss=2.7767  λ_max=72.1740\n",
      "[Adam | lr=0.1] Epoch 1996/4000: train_loss=1.6212  test_loss=2.7936  λ_max=72.7394\n",
      "[Adam | lr=0.1] Epoch 1997/4000: train_loss=1.6175  test_loss=2.8144  λ_max=68.8958\n",
      "[Adam | lr=0.1] Epoch 1998/4000: train_loss=1.6192  test_loss=2.8205  λ_max=66.0325\n",
      "[Adam | lr=0.1] Epoch 1999/4000: train_loss=1.6088  test_loss=2.8197  λ_max=65.6015\n",
      "[Adam | lr=0.1] Iter 32000: loss=1.6464\n",
      "[Adam | lr=0.1] Epoch 2000/4000: train_loss=1.6064  test_loss=2.8268  λ_max=73.1507\n",
      "[Adam | lr=0.1] Epoch 2001/4000: train_loss=1.6024  test_loss=2.8042  λ_max=69.0338\n",
      "[Adam | lr=0.1] Epoch 2002/4000: train_loss=1.5923  test_loss=2.8417  λ_max=68.4463\n",
      "[Adam | lr=0.1] Epoch 2003/4000: train_loss=1.5959  test_loss=2.8492  λ_max=67.8439\n",
      "[Adam | lr=0.1] Epoch 2004/4000: train_loss=1.5939  test_loss=2.8519  λ_max=67.6828\n",
      "[Adam | lr=0.1] Epoch 2005/4000: train_loss=1.5949  test_loss=2.8434  λ_max=67.1048\n",
      "[Adam | lr=0.1] Epoch 2006/4000: train_loss=1.5846  test_loss=2.8352  λ_max=68.0556\n",
      "[Adam | lr=0.1] Iter 32100: loss=1.5372\n",
      "[Adam | lr=0.1] Epoch 2007/4000: train_loss=1.5804  test_loss=2.8850  λ_max=53.9060\n",
      "[Adam | lr=0.1] Epoch 2008/4000: train_loss=1.5848  test_loss=2.8696  λ_max=63.3302\n",
      "[Adam | lr=0.1] Epoch 2009/4000: train_loss=1.5713  test_loss=2.8605  λ_max=62.3238\n",
      "[Adam | lr=0.1] Epoch 2010/4000: train_loss=1.5666  test_loss=2.8853  λ_max=66.7331\n",
      "[Adam | lr=0.1] Epoch 2011/4000: train_loss=1.5655  test_loss=2.9096  λ_max=69.6867\n",
      "[Adam | lr=0.1] Epoch 2012/4000: train_loss=1.5634  test_loss=2.8957  λ_max=70.0177\n",
      "[Adam | lr=0.1] Iter 32200: loss=1.5886\n",
      "[Adam | lr=0.1] Epoch 2013/4000: train_loss=1.5600  test_loss=2.9048  λ_max=69.8958\n",
      "[Adam | lr=0.1] Epoch 2014/4000: train_loss=1.5554  test_loss=2.9058  λ_max=64.3988\n",
      "[Adam | lr=0.1] Epoch 2015/4000: train_loss=1.5495  test_loss=2.9074  λ_max=70.8687\n",
      "[Adam | lr=0.1] Epoch 2016/4000: train_loss=1.5475  test_loss=2.9234  λ_max=74.7021\n",
      "[Adam | lr=0.1] Epoch 2017/4000: train_loss=1.5462  test_loss=2.9535  λ_max=76.8151\n",
      "[Adam | lr=0.1] Epoch 2018/4000: train_loss=1.5370  test_loss=2.9521  λ_max=80.4971\n",
      "[Adam | lr=0.1] Iter 32300: loss=1.5500\n",
      "[Adam | lr=0.1] Epoch 2019/4000: train_loss=1.5350  test_loss=2.9568  λ_max=76.5316\n",
      "[Adam | lr=0.1] Epoch 2020/4000: train_loss=1.5288  test_loss=2.9513  λ_max=59.1614\n",
      "[Adam | lr=0.1] Epoch 2021/4000: train_loss=1.5289  test_loss=2.9711  λ_max=63.2001\n",
      "[Adam | lr=0.1] Epoch 2022/4000: train_loss=1.5165  test_loss=2.9631  λ_max=64.0686\n",
      "[Adam | lr=0.1] Epoch 2023/4000: train_loss=1.5109  test_loss=2.9854  λ_max=59.8711\n",
      "[Adam | lr=0.1] Epoch 2024/4000: train_loss=1.5051  test_loss=3.0008  λ_max=64.5182\n",
      "[Adam | lr=0.1] Iter 32400: loss=1.5165\n",
      "[Adam | lr=0.1] Epoch 2025/4000: train_loss=1.4994  test_loss=2.9762  λ_max=67.1853\n",
      "[Adam | lr=0.1] Epoch 2026/4000: train_loss=1.4921  test_loss=3.0284  λ_max=62.6029\n",
      "[Adam | lr=0.1] Epoch 2027/4000: train_loss=1.4884  test_loss=3.0046  λ_max=64.9239\n",
      "[Adam | lr=0.1] Epoch 2028/4000: train_loss=1.4836  test_loss=3.0394  λ_max=63.9528\n",
      "[Adam | lr=0.1] Epoch 2029/4000: train_loss=1.4877  test_loss=3.0832  λ_max=65.0088\n",
      "[Adam | lr=0.1] Epoch 2030/4000: train_loss=1.4859  test_loss=3.0755  λ_max=67.6497\n",
      "[Adam | lr=0.1] Epoch 2031/4000: train_loss=1.4700  test_loss=3.0638  λ_max=67.0679\n",
      "[Adam | lr=0.1] Iter 32500: loss=1.4567\n",
      "[Adam | lr=0.1] Epoch 2032/4000: train_loss=1.4572  test_loss=3.0613  λ_max=82.5488\n",
      "[Adam | lr=0.1] Epoch 2033/4000: train_loss=1.4567  test_loss=3.1179  λ_max=67.8121\n",
      "[Adam | lr=0.1] Epoch 2034/4000: train_loss=1.4513  test_loss=3.0756  λ_max=67.5427\n",
      "[Adam | lr=0.1] Epoch 2035/4000: train_loss=1.4448  test_loss=3.0969  λ_max=56.3663\n",
      "[Adam | lr=0.1] Epoch 2036/4000: train_loss=1.4483  test_loss=3.1306  λ_max=55.5268\n",
      "[Adam | lr=0.1] Epoch 2037/4000: train_loss=1.4450  test_loss=3.1381  λ_max=60.8282\n",
      "[Adam | lr=0.1] Iter 32600: loss=1.4336\n",
      "[Adam | lr=0.1] Epoch 2038/4000: train_loss=1.4384  test_loss=3.1222  λ_max=66.2864\n",
      "[Adam | lr=0.1] Epoch 2039/4000: train_loss=1.4327  test_loss=3.1822  λ_max=68.7002\n",
      "[Adam | lr=0.1] Epoch 2040/4000: train_loss=1.4318  test_loss=3.1650  λ_max=61.5213\n",
      "[Adam | lr=0.1] Epoch 2041/4000: train_loss=1.4204  test_loss=3.1740  λ_max=64.3891\n",
      "[Adam | lr=0.1] Epoch 2042/4000: train_loss=1.4152  test_loss=3.1963  λ_max=63.4097\n",
      "[Adam | lr=0.1] Epoch 2043/4000: train_loss=1.4184  test_loss=3.2072  λ_max=65.6742\n",
      "[Adam | lr=0.1] Iter 32700: loss=1.3851\n",
      "[Adam | lr=0.1] Epoch 2044/4000: train_loss=1.4094  test_loss=3.2233  λ_max=59.1812\n",
      "[Adam | lr=0.1] Epoch 2045/4000: train_loss=1.4030  test_loss=3.2129  λ_max=63.9020\n",
      "[Adam | lr=0.1] Epoch 2046/4000: train_loss=1.3963  test_loss=3.2350  λ_max=63.2310\n",
      "[Adam | lr=0.1] Epoch 2047/4000: train_loss=1.3919  test_loss=3.2508  λ_max=61.3613\n",
      "[Adam | lr=0.1] Epoch 2048/4000: train_loss=1.3921  test_loss=3.2460  λ_max=63.6770\n",
      "[Adam | lr=0.1] Epoch 2049/4000: train_loss=1.3869  test_loss=3.2882  λ_max=61.7366\n",
      "[Adam | lr=0.1] Iter 32800: loss=1.4539\n",
      "[Adam | lr=0.1] Epoch 2050/4000: train_loss=1.3908  test_loss=3.2690  λ_max=71.6880\n",
      "[Adam | lr=0.1] Epoch 2051/4000: train_loss=1.3832  test_loss=3.3077  λ_max=76.0381\n",
      "[Adam | lr=0.1] Epoch 2052/4000: train_loss=1.3731  test_loss=3.3038  λ_max=73.7439\n",
      "[Adam | lr=0.1] Epoch 2053/4000: train_loss=1.3648  test_loss=3.3203  λ_max=64.5300\n",
      "[Adam | lr=0.1] Epoch 2054/4000: train_loss=1.3583  test_loss=3.3660  λ_max=68.5545\n",
      "[Adam | lr=0.1] Epoch 2055/4000: train_loss=1.3516  test_loss=3.3424  λ_max=61.2989\n",
      "[Adam | lr=0.1] Epoch 2056/4000: train_loss=1.3531  test_loss=3.3863  λ_max=62.4834\n",
      "[Adam | lr=0.1] Iter 32900: loss=1.2568\n",
      "[Adam | lr=0.1] Epoch 2057/4000: train_loss=1.3457  test_loss=3.3750  λ_max=66.1432\n",
      "[Adam | lr=0.1] Epoch 2058/4000: train_loss=1.3473  test_loss=3.4152  λ_max=67.3149\n",
      "[Adam | lr=0.1] Epoch 2059/4000: train_loss=1.3352  test_loss=3.4065  λ_max=65.4266\n",
      "[Adam | lr=0.1] Epoch 2060/4000: train_loss=1.3317  test_loss=3.4211  λ_max=64.8614\n",
      "[Adam | lr=0.1] Epoch 2061/4000: train_loss=1.3223  test_loss=3.4453  λ_max=67.0931\n",
      "[Adam | lr=0.1] Epoch 2062/4000: train_loss=1.3209  test_loss=3.5023  λ_max=65.0245\n",
      "[Adam | lr=0.1] Iter 33000: loss=1.3320\n",
      "[Adam | lr=0.1] Epoch 2063/4000: train_loss=1.3157  test_loss=3.4814  λ_max=78.9163\n",
      "[Adam | lr=0.1] Epoch 2064/4000: train_loss=1.3150  test_loss=3.4745  λ_max=68.5318\n",
      "[Adam | lr=0.1] Epoch 2065/4000: train_loss=1.3026  test_loss=3.5157  λ_max=63.2612\n",
      "[Adam | lr=0.1] Epoch 2066/4000: train_loss=1.3051  test_loss=3.5436  λ_max=65.5288\n",
      "[Adam | lr=0.1] Epoch 2067/4000: train_loss=1.3040  test_loss=3.5787  λ_max=68.1567\n",
      "[Adam | lr=0.1] Epoch 2068/4000: train_loss=1.3055  test_loss=3.6054  λ_max=67.4869\n",
      "[Adam | lr=0.1] Iter 33100: loss=1.3120\n",
      "[Adam | lr=0.1] Epoch 2069/4000: train_loss=1.2934  test_loss=3.5483  λ_max=67.2623\n",
      "[Adam | lr=0.1] Epoch 2070/4000: train_loss=1.2776  test_loss=3.6161  λ_max=69.8672\n",
      "[Adam | lr=0.1] Epoch 2071/4000: train_loss=1.2728  test_loss=3.5954  λ_max=68.3189\n",
      "[Adam | lr=0.1] Epoch 2072/4000: train_loss=1.2687  test_loss=3.6821  λ_max=65.3724\n",
      "[Adam | lr=0.1] Epoch 2073/4000: train_loss=1.2673  test_loss=3.7073  λ_max=55.7847\n",
      "[Adam | lr=0.1] Epoch 2074/4000: train_loss=1.2615  test_loss=3.7020  λ_max=62.7930\n",
      "[Adam | lr=0.1] Iter 33200: loss=1.3163\n",
      "[Adam | lr=0.1] Epoch 2075/4000: train_loss=1.2585  test_loss=3.7325  λ_max=66.8586\n",
      "[Adam | lr=0.1] Epoch 2076/4000: train_loss=1.2555  test_loss=3.7444  λ_max=67.5590\n",
      "[Adam | lr=0.1] Epoch 2077/4000: train_loss=1.2489  test_loss=3.7484  λ_max=62.3371\n",
      "[Adam | lr=0.1] Epoch 2078/4000: train_loss=1.2403  test_loss=3.7866  λ_max=68.5658\n",
      "[Adam | lr=0.1] Epoch 2079/4000: train_loss=1.2355  test_loss=3.8063  λ_max=60.1191\n",
      "[Adam | lr=0.1] Epoch 2080/4000: train_loss=1.2323  test_loss=3.8408  λ_max=59.5115\n",
      "[Adam | lr=0.1] Epoch 2081/4000: train_loss=1.2238  test_loss=3.8216  λ_max=63.0098\n",
      "[Adam | lr=0.1] Iter 33300: loss=1.1882\n",
      "[Adam | lr=0.1] Epoch 2082/4000: train_loss=1.2163  test_loss=3.8506  λ_max=71.7789\n",
      "[Adam | lr=0.1] Epoch 2083/4000: train_loss=1.2305  test_loss=3.8860  λ_max=59.2835\n",
      "[Adam | lr=0.1] Epoch 2084/4000: train_loss=1.2276  test_loss=3.8908  λ_max=61.9168\n",
      "[Adam | lr=0.1] Epoch 2085/4000: train_loss=1.2113  test_loss=3.9193  λ_max=62.3890\n",
      "[Adam | lr=0.1] Epoch 2086/4000: train_loss=1.2014  test_loss=3.9544  λ_max=61.3113\n",
      "[Adam | lr=0.1] Epoch 2087/4000: train_loss=1.1999  test_loss=3.9902  λ_max=61.9396\n",
      "[Adam | lr=0.1] Iter 33400: loss=1.1682\n",
      "[Adam | lr=0.1] Epoch 2088/4000: train_loss=1.2010  test_loss=4.0088  λ_max=60.5263\n",
      "[Adam | lr=0.1] Epoch 2089/4000: train_loss=1.1913  test_loss=4.0345  λ_max=58.3973\n",
      "[Adam | lr=0.1] Epoch 2090/4000: train_loss=1.1855  test_loss=4.0240  λ_max=47.8397\n",
      "[Adam | lr=0.1] Epoch 2091/4000: train_loss=1.1802  test_loss=4.0618  λ_max=55.5616\n",
      "[Adam | lr=0.1] Epoch 2092/4000: train_loss=1.1695  test_loss=4.0556  λ_max=55.1560\n",
      "[Adam | lr=0.1] Epoch 2093/4000: train_loss=1.1601  test_loss=4.1370  λ_max=57.3982\n",
      "[Adam | lr=0.1] Iter 33500: loss=1.2218\n",
      "[Adam | lr=0.1] Epoch 2094/4000: train_loss=1.1555  test_loss=4.1523  λ_max=54.8255\n",
      "[Adam | lr=0.1] Epoch 2095/4000: train_loss=1.1525  test_loss=4.1697  λ_max=50.9899\n",
      "[Adam | lr=0.1] Epoch 2096/4000: train_loss=1.1491  test_loss=4.2042  λ_max=59.5984\n",
      "[Adam | lr=0.1] Epoch 2097/4000: train_loss=1.1440  test_loss=4.2613  λ_max=65.3463\n",
      "[Adam | lr=0.1] Epoch 2098/4000: train_loss=1.1457  test_loss=4.2526  λ_max=61.2120\n",
      "[Adam | lr=0.1] Epoch 2099/4000: train_loss=1.1391  test_loss=4.2636  λ_max=55.5792\n",
      "[Adam | lr=0.1] Iter 33600: loss=1.2102\n",
      "[Adam | lr=0.1] Epoch 2100/4000: train_loss=1.1299  test_loss=4.2879  λ_max=56.9054\n",
      "[Adam | lr=0.1] Epoch 2101/4000: train_loss=1.1223  test_loss=4.3434  λ_max=59.1021\n",
      "[Adam | lr=0.1] Epoch 2102/4000: train_loss=1.1192  test_loss=4.3655  λ_max=59.6415\n",
      "[Adam | lr=0.1] Epoch 2103/4000: train_loss=1.1137  test_loss=4.4111  λ_max=54.4159\n",
      "[Adam | lr=0.1] Epoch 2104/4000: train_loss=1.1119  test_loss=4.4415  λ_max=54.3299\n",
      "[Adam | lr=0.1] Epoch 2105/4000: train_loss=1.1016  test_loss=4.4257  λ_max=57.1670\n",
      "[Adam | lr=0.1] Epoch 2106/4000: train_loss=1.0930  test_loss=4.4953  λ_max=53.9634\n",
      "[Adam | lr=0.1] Iter 33700: loss=1.0624\n",
      "[Adam | lr=0.1] Epoch 2107/4000: train_loss=1.0859  test_loss=4.4837  λ_max=57.2374\n",
      "[Adam | lr=0.1] Epoch 2108/4000: train_loss=1.0843  test_loss=4.5865  λ_max=60.3192\n",
      "[Adam | lr=0.1] Epoch 2109/4000: train_loss=1.0762  test_loss=4.6287  λ_max=60.1588\n",
      "[Adam | lr=0.1] Epoch 2110/4000: train_loss=1.0753  test_loss=4.6366  λ_max=57.7295\n",
      "[Adam | lr=0.1] Epoch 2111/4000: train_loss=1.0755  test_loss=4.6583  λ_max=59.1387\n",
      "[Adam | lr=0.1] Epoch 2112/4000: train_loss=1.0692  test_loss=4.6710  λ_max=60.2566\n",
      "[Adam | lr=0.1] Iter 33800: loss=1.0620\n",
      "[Adam | lr=0.1] Epoch 2113/4000: train_loss=1.0619  test_loss=4.6953  λ_max=55.8709\n",
      "[Adam | lr=0.1] Epoch 2114/4000: train_loss=1.0600  test_loss=4.7397  λ_max=56.3569\n",
      "[Adam | lr=0.1] Epoch 2115/4000: train_loss=1.0448  test_loss=4.7721  λ_max=51.7079\n",
      "[Adam | lr=0.1] Epoch 2116/4000: train_loss=1.0444  test_loss=4.8117  λ_max=51.5589\n",
      "[Adam | lr=0.1] Epoch 2117/4000: train_loss=1.0431  test_loss=4.8363  λ_max=54.2752\n",
      "[Adam | lr=0.1] Epoch 2118/4000: train_loss=1.0420  test_loss=4.8808  λ_max=57.2008\n",
      "[Adam | lr=0.1] Iter 33900: loss=1.0897\n",
      "[Adam | lr=0.1] Epoch 2119/4000: train_loss=1.0337  test_loss=4.8767  λ_max=61.4846\n",
      "[Adam | lr=0.1] Epoch 2120/4000: train_loss=1.0239  test_loss=4.9316  λ_max=67.8087\n",
      "[Adam | lr=0.1] Epoch 2121/4000: train_loss=1.0224  test_loss=4.9608  λ_max=57.5628\n",
      "[Adam | lr=0.1] Epoch 2122/4000: train_loss=1.0251  test_loss=5.0312  λ_max=51.9083\n",
      "[Adam | lr=0.1] Epoch 2123/4000: train_loss=1.0128  test_loss=5.0413  λ_max=53.2831\n",
      "[Adam | lr=0.1] Epoch 2124/4000: train_loss=1.0128  test_loss=5.0115  λ_max=50.5468\n",
      "[Adam | lr=0.1] Iter 34000: loss=1.0777\n",
      "[Adam | lr=0.1] Epoch 2125/4000: train_loss=1.0033  test_loss=5.1216  λ_max=58.7611\n",
      "[Adam | lr=0.1] Epoch 2126/4000: train_loss=1.0032  test_loss=5.1039  λ_max=61.8090\n",
      "[Adam | lr=0.1] Epoch 2127/4000: train_loss=1.0052  test_loss=5.2019  λ_max=56.8418\n",
      "[Adam | lr=0.1] Epoch 2128/4000: train_loss=1.0027  test_loss=5.1773  λ_max=55.6082\n",
      "[Adam | lr=0.1] Epoch 2129/4000: train_loss=1.0071  test_loss=5.2897  λ_max=53.7678\n",
      "[Adam | lr=0.1] Epoch 2130/4000: train_loss=0.9923  test_loss=5.2240  λ_max=56.0761\n",
      "[Adam | lr=0.1] Epoch 2131/4000: train_loss=0.9795  test_loss=5.3152  λ_max=61.0907\n",
      "[Adam | lr=0.1] Iter 34100: loss=0.8973\n",
      "[Adam | lr=0.1] Epoch 2132/4000: train_loss=0.9744  test_loss=5.3537  λ_max=63.0424\n",
      "[Adam | lr=0.1] Epoch 2133/4000: train_loss=0.9684  test_loss=5.4076  λ_max=62.7433\n",
      "[Adam | lr=0.1] Epoch 2134/4000: train_loss=0.9686  test_loss=5.4525  λ_max=59.4540\n",
      "[Adam | lr=0.1] Epoch 2135/4000: train_loss=0.9569  test_loss=5.4606  λ_max=59.0104\n",
      "[Adam | lr=0.1] Epoch 2136/4000: train_loss=0.9429  test_loss=5.4631  λ_max=56.0998\n",
      "[Adam | lr=0.1] Epoch 2137/4000: train_loss=0.9591  test_loss=5.6115  λ_max=56.1519\n",
      "[Adam | lr=0.1] Iter 34200: loss=0.9918\n",
      "[Adam | lr=0.1] Epoch 2138/4000: train_loss=0.9581  test_loss=5.5620  λ_max=54.7297\n",
      "[Adam | lr=0.1] Epoch 2139/4000: train_loss=0.9557  test_loss=5.6020  λ_max=55.5644\n",
      "[Adam | lr=0.1] Epoch 2140/4000: train_loss=0.9437  test_loss=5.6263  λ_max=53.8190\n",
      "[Adam | lr=0.1] Epoch 2141/4000: train_loss=0.9422  test_loss=5.6442  λ_max=58.5859\n",
      "[Adam | lr=0.1] Epoch 2142/4000: train_loss=0.9359  test_loss=5.6547  λ_max=56.3618\n",
      "[Adam | lr=0.1] Epoch 2143/4000: train_loss=0.9262  test_loss=5.7527  λ_max=55.1725\n",
      "[Adam | lr=0.1] Iter 34300: loss=0.9742\n",
      "[Adam | lr=0.1] Epoch 2144/4000: train_loss=0.9229  test_loss=5.8051  λ_max=51.7385\n",
      "[Adam | lr=0.1] Epoch 2145/4000: train_loss=0.9228  test_loss=5.8284  λ_max=54.5327\n",
      "[Adam | lr=0.1] Epoch 2146/4000: train_loss=0.9115  test_loss=5.9269  λ_max=57.9511\n",
      "[Adam | lr=0.1] Epoch 2147/4000: train_loss=0.9166  test_loss=5.9725  λ_max=55.9565\n",
      "[Adam | lr=0.1] Epoch 2148/4000: train_loss=0.9137  test_loss=6.0058  λ_max=47.6527\n",
      "[Adam | lr=0.1] Epoch 2149/4000: train_loss=0.8996  test_loss=6.0200  λ_max=49.5364\n",
      "[Adam | lr=0.1] Iter 34400: loss=0.9890\n",
      "[Adam | lr=0.1] Epoch 2150/4000: train_loss=0.8910  test_loss=6.0876  λ_max=52.8968\n",
      "[Adam | lr=0.1] Epoch 2151/4000: train_loss=0.8874  test_loss=6.1795  λ_max=54.5912\n",
      "[Adam | lr=0.1] Epoch 2152/4000: train_loss=0.8914  test_loss=6.2007  λ_max=48.4396\n",
      "[Adam | lr=0.1] Epoch 2153/4000: train_loss=0.8853  test_loss=6.2748  λ_max=52.8677\n",
      "[Adam | lr=0.1] Epoch 2154/4000: train_loss=0.8814  test_loss=6.3225  λ_max=45.3953\n",
      "[Adam | lr=0.1] Epoch 2155/4000: train_loss=0.8836  test_loss=6.3497  λ_max=46.5501\n",
      "[Adam | lr=0.1] Epoch 2156/4000: train_loss=0.8835  test_loss=6.3650  λ_max=49.2196\n",
      "[Adam | lr=0.1] Iter 34500: loss=0.7645\n",
      "[Adam | lr=0.1] Epoch 2157/4000: train_loss=0.8844  test_loss=6.3579  λ_max=54.7991\n",
      "[Adam | lr=0.1] Epoch 2158/4000: train_loss=0.8828  test_loss=6.4418  λ_max=60.8928\n",
      "[Adam | lr=0.1] Epoch 2159/4000: train_loss=0.8744  test_loss=6.4565  λ_max=60.6645\n",
      "[Adam | lr=0.1] Epoch 2160/4000: train_loss=0.8741  test_loss=6.4687  λ_max=50.1172\n",
      "[Adam | lr=0.1] Epoch 2161/4000: train_loss=0.8618  test_loss=6.4445  λ_max=52.2836\n",
      "[Adam | lr=0.1] Epoch 2162/4000: train_loss=0.8543  test_loss=6.5486  λ_max=50.0378\n",
      "[Adam | lr=0.1] Iter 34600: loss=0.8352\n",
      "[Adam | lr=0.1] Epoch 2163/4000: train_loss=0.8514  test_loss=6.6448  λ_max=46.9134\n",
      "[Adam | lr=0.1] Epoch 2164/4000: train_loss=0.8509  test_loss=6.6854  λ_max=48.4401\n",
      "[Adam | lr=0.1] Epoch 2165/4000: train_loss=0.8465  test_loss=6.7194  λ_max=48.5037\n",
      "[Adam | lr=0.1] Epoch 2166/4000: train_loss=0.8451  test_loss=6.7570  λ_max=45.9327\n",
      "[Adam | lr=0.1] Epoch 2167/4000: train_loss=0.8487  test_loss=6.7865  λ_max=52.3700\n",
      "[Adam | lr=0.1] Epoch 2168/4000: train_loss=0.8544  test_loss=6.8268  λ_max=58.9006\n",
      "[Adam | lr=0.1] Iter 34700: loss=0.9141\n",
      "[Adam | lr=0.1] Epoch 2169/4000: train_loss=0.8388  test_loss=6.9101  λ_max=61.0567\n",
      "[Adam | lr=0.1] Epoch 2170/4000: train_loss=0.8320  test_loss=6.8742  λ_max=61.5634\n",
      "[Adam | lr=0.1] Epoch 2171/4000: train_loss=0.8292  test_loss=7.0048  λ_max=49.7435\n",
      "[Adam | lr=0.1] Epoch 2172/4000: train_loss=0.8258  test_loss=6.9945  λ_max=49.4292\n",
      "[Adam | lr=0.1] Epoch 2173/4000: train_loss=0.8240  test_loss=7.0710  λ_max=49.2261\n",
      "[Adam | lr=0.1] Epoch 2174/4000: train_loss=0.8206  test_loss=7.1127  λ_max=47.7915\n",
      "[Adam | lr=0.1] Iter 34800: loss=0.8294\n",
      "[Adam | lr=0.1] Epoch 2175/4000: train_loss=0.8129  test_loss=7.1240  λ_max=50.2948\n",
      "[Adam | lr=0.1] Epoch 2176/4000: train_loss=0.8038  test_loss=7.1472  λ_max=51.1785\n",
      "[Adam | lr=0.1] Epoch 2177/4000: train_loss=0.8051  test_loss=7.2969  λ_max=48.8876\n",
      "[Adam | lr=0.1] Epoch 2178/4000: train_loss=0.8015  test_loss=7.3613  λ_max=49.3183\n",
      "[Adam | lr=0.1] Epoch 2179/4000: train_loss=0.7997  test_loss=7.3924  λ_max=50.9578\n",
      "[Adam | lr=0.1] Epoch 2180/4000: train_loss=0.7959  test_loss=7.4555  λ_max=51.3377\n",
      "[Adam | lr=0.1] Epoch 2181/4000: train_loss=0.7933  test_loss=7.5278  λ_max=52.1129\n",
      "[Adam | lr=0.1] Iter 34900: loss=0.7502\n",
      "[Adam | lr=0.1] Epoch 2182/4000: train_loss=0.7913  test_loss=7.5737  λ_max=50.8395\n",
      "[Adam | lr=0.1] Epoch 2183/4000: train_loss=0.7880  test_loss=7.5032  λ_max=51.2799\n",
      "[Adam | lr=0.1] Epoch 2184/4000: train_loss=0.7906  test_loss=7.6332  λ_max=49.5463\n",
      "[Adam | lr=0.1] Epoch 2185/4000: train_loss=0.7867  test_loss=7.5827  λ_max=50.8279\n",
      "[Adam | lr=0.1] Epoch 2186/4000: train_loss=0.7772  test_loss=7.6997  λ_max=49.9822\n",
      "[Adam | lr=0.1] Epoch 2187/4000: train_loss=0.7707  test_loss=7.7327  λ_max=50.9642\n",
      "[Adam | lr=0.1] Iter 35000: loss=0.7307\n",
      "[Adam | lr=0.1] Epoch 2188/4000: train_loss=0.7720  test_loss=7.8507  λ_max=47.6540\n",
      "[Adam | lr=0.1] Epoch 2189/4000: train_loss=0.7720  test_loss=7.8654  λ_max=47.9032\n",
      "[Adam | lr=0.1] Epoch 2190/4000: train_loss=0.7779  test_loss=7.9487  λ_max=46.5733\n",
      "[Adam | lr=0.1] Epoch 2191/4000: train_loss=0.7714  test_loss=7.9766  λ_max=48.8569\n",
      "[Adam | lr=0.1] Epoch 2192/4000: train_loss=0.7688  test_loss=8.0318  λ_max=41.6479\n",
      "[Adam | lr=0.1] Epoch 2193/4000: train_loss=0.7630  test_loss=8.0425  λ_max=46.2482\n",
      "[Adam | lr=0.1] Iter 35100: loss=0.7396\n",
      "[Adam | lr=0.1] Epoch 2194/4000: train_loss=0.7621  test_loss=8.2025  λ_max=46.0814\n",
      "[Adam | lr=0.1] Epoch 2195/4000: train_loss=0.7538  test_loss=8.0772  λ_max=42.6216\n",
      "[Adam | lr=0.1] Epoch 2196/4000: train_loss=0.7435  test_loss=8.1572  λ_max=47.4641\n",
      "[Adam | lr=0.1] Epoch 2197/4000: train_loss=0.7327  test_loss=8.1917  λ_max=48.7778\n",
      "[Adam | lr=0.1] Epoch 2198/4000: train_loss=0.7429  test_loss=8.4088  λ_max=47.1893\n",
      "[Adam | lr=0.1] Epoch 2199/4000: train_loss=0.7461  test_loss=8.4436  λ_max=46.1727\n",
      "[Adam | lr=0.1] Iter 35200: loss=0.7400\n",
      "[Adam | lr=0.1] Epoch 2200/4000: train_loss=0.7450  test_loss=8.3995  λ_max=50.6238\n",
      "[Adam | lr=0.1] Epoch 2201/4000: train_loss=0.7424  test_loss=8.4709  λ_max=53.6248\n",
      "[Adam | lr=0.1] Epoch 2202/4000: train_loss=0.7484  test_loss=8.4873  λ_max=54.7176\n",
      "[Adam | lr=0.1] Epoch 2203/4000: train_loss=0.7387  test_loss=8.5428  λ_max=54.1714\n",
      "[Adam | lr=0.1] Epoch 2204/4000: train_loss=0.7337  test_loss=8.5450  λ_max=54.4667\n",
      "[Adam | lr=0.1] Epoch 2205/4000: train_loss=0.7236  test_loss=8.6632  λ_max=51.2371\n",
      "[Adam | lr=0.1] Epoch 2206/4000: train_loss=0.7126  test_loss=8.7109  λ_max=39.2164\n",
      "[Adam | lr=0.1] Iter 35300: loss=0.6670\n",
      "[Adam | lr=0.1] Epoch 2207/4000: train_loss=0.7105  test_loss=8.7601  λ_max=44.0357\n",
      "[Adam | lr=0.1] Epoch 2208/4000: train_loss=0.7139  test_loss=8.8225  λ_max=45.5936\n",
      "[Adam | lr=0.1] Epoch 2209/4000: train_loss=0.7175  test_loss=8.9064  λ_max=50.4153\n",
      "[Adam | lr=0.1] Epoch 2210/4000: train_loss=0.7124  test_loss=8.9853  λ_max=48.2657\n",
      "[Adam | lr=0.1] Epoch 2211/4000: train_loss=0.7049  test_loss=9.0014  λ_max=49.4771\n",
      "[Adam | lr=0.1] Epoch 2212/4000: train_loss=0.7029  test_loss=9.1048  λ_max=51.2705\n",
      "[Adam | lr=0.1] Iter 35400: loss=0.7453\n",
      "[Adam | lr=0.1] Epoch 2213/4000: train_loss=0.7071  test_loss=9.1310  λ_max=47.9404\n",
      "[Adam | lr=0.1] Epoch 2214/4000: train_loss=0.7020  test_loss=9.2083  λ_max=45.2238\n",
      "[Adam | lr=0.1] Epoch 2215/4000: train_loss=0.6975  test_loss=9.2468  λ_max=43.7410\n",
      "[Adam | lr=0.1] Epoch 2216/4000: train_loss=0.6913  test_loss=9.2732  λ_max=45.0084\n",
      "[Adam | lr=0.1] Epoch 2217/4000: train_loss=0.6835  test_loss=9.3672  λ_max=43.0783\n",
      "[Adam | lr=0.1] Epoch 2218/4000: train_loss=0.6800  test_loss=9.4635  λ_max=44.0455\n",
      "[Adam | lr=0.1] Iter 35500: loss=0.7182\n",
      "[Adam | lr=0.1] Epoch 2219/4000: train_loss=0.6769  test_loss=9.5395  λ_max=40.9530\n",
      "[Adam | lr=0.1] Epoch 2220/4000: train_loss=0.6791  test_loss=9.7316  λ_max=45.9906\n",
      "[Adam | lr=0.1] Epoch 2221/4000: train_loss=0.6749  test_loss=9.6459  λ_max=52.5347\n",
      "[Adam | lr=0.1] Epoch 2222/4000: train_loss=0.6709  test_loss=9.7027  λ_max=51.5432\n",
      "[Adam | lr=0.1] Epoch 2223/4000: train_loss=0.6630  test_loss=9.7395  λ_max=46.6542\n",
      "[Adam | lr=0.1] Epoch 2224/4000: train_loss=0.6703  test_loss=9.8736  λ_max=45.5620\n",
      "[Adam | lr=0.1] Iter 35600: loss=0.7445\n",
      "[Adam | lr=0.1] Epoch 2225/4000: train_loss=0.6683  test_loss=10.0070  λ_max=44.2285\n",
      "[Adam | lr=0.1] Epoch 2226/4000: train_loss=0.6761  test_loss=9.9274  λ_max=47.7704\n",
      "[Adam | lr=0.1] Epoch 2227/4000: train_loss=0.6704  test_loss=9.8968  λ_max=50.0229\n",
      "[Adam | lr=0.1] Epoch 2228/4000: train_loss=0.6509  test_loss=9.9593  λ_max=49.8498\n",
      "[Adam | lr=0.1] Epoch 2229/4000: train_loss=0.6379  test_loss=10.0405  λ_max=48.8484\n",
      "[Adam | lr=0.1] Epoch 2230/4000: train_loss=0.6380  test_loss=10.1760  λ_max=50.3648\n",
      "[Adam | lr=0.1] Epoch 2231/4000: train_loss=0.6322  test_loss=10.2664  λ_max=46.9604\n",
      "[Adam | lr=0.1] Iter 35700: loss=0.5342\n",
      "[Adam | lr=0.1] Epoch 2232/4000: train_loss=0.6231  test_loss=10.3379  λ_max=48.1228\n",
      "[Adam | lr=0.1] Epoch 2233/4000: train_loss=0.6229  test_loss=10.4516  λ_max=46.8621\n",
      "[Adam | lr=0.1] Epoch 2234/4000: train_loss=0.6246  test_loss=10.5122  λ_max=42.2007\n",
      "[Adam | lr=0.1] Epoch 2235/4000: train_loss=0.6278  test_loss=10.7137  λ_max=43.4198\n",
      "[Adam | lr=0.1] Epoch 2236/4000: train_loss=0.6321  test_loss=10.5908  λ_max=42.2605\n",
      "[Adam | lr=0.1] Epoch 2237/4000: train_loss=0.6417  test_loss=10.7085  λ_max=43.7290\n",
      "[Adam | lr=0.1] Iter 35800: loss=0.5477\n",
      "[Adam | lr=0.1] Epoch 2238/4000: train_loss=0.6273  test_loss=10.6869  λ_max=44.1610\n",
      "[Adam | lr=0.1] Epoch 2239/4000: train_loss=0.6241  test_loss=10.7536  λ_max=47.6671\n",
      "[Adam | lr=0.1] Epoch 2240/4000: train_loss=0.6271  test_loss=10.8128  λ_max=47.9903\n",
      "[Adam | lr=0.1] Epoch 2241/4000: train_loss=0.6374  test_loss=10.8668  λ_max=44.9981\n",
      "[Adam | lr=0.1] Epoch 2242/4000: train_loss=0.6385  test_loss=11.0732  λ_max=46.4062\n",
      "[Adam | lr=0.1] Epoch 2243/4000: train_loss=0.6360  test_loss=11.0521  λ_max=44.3375\n",
      "[Adam | lr=0.1] Iter 35900: loss=0.6805\n",
      "[Adam | lr=0.1] Epoch 2244/4000: train_loss=0.6462  test_loss=11.0776  λ_max=40.2532\n",
      "[Adam | lr=0.1] Epoch 2245/4000: train_loss=0.6414  test_loss=11.0204  λ_max=46.4580\n",
      "[Adam | lr=0.1] Epoch 2246/4000: train_loss=0.6302  test_loss=11.1201  λ_max=45.1917\n",
      "[Adam | lr=0.1] Epoch 2247/4000: train_loss=0.6143  test_loss=11.0417  λ_max=44.8638\n",
      "[Adam | lr=0.1] Epoch 2248/4000: train_loss=0.5997  test_loss=11.1934  λ_max=48.5538\n",
      "[Adam | lr=0.1] Epoch 2249/4000: train_loss=0.6000  test_loss=11.4063  λ_max=39.7301\n",
      "[Adam | lr=0.1] Iter 36000: loss=0.5963\n",
      "[Adam | lr=0.1] Epoch 2250/4000: train_loss=0.5847  test_loss=11.4247  λ_max=41.0663\n",
      "[Adam | lr=0.1] Epoch 2251/4000: train_loss=0.5825  test_loss=11.5079  λ_max=46.2758\n",
      "[Adam | lr=0.1] Epoch 2252/4000: train_loss=0.5858  test_loss=11.6942  λ_max=45.5777\n",
      "[Adam | lr=0.1] Epoch 2253/4000: train_loss=0.5837  test_loss=11.8041  λ_max=40.9687\n",
      "[Adam | lr=0.1] Epoch 2254/4000: train_loss=0.5918  test_loss=11.9168  λ_max=41.5720\n",
      "[Adam | lr=0.1] Epoch 2255/4000: train_loss=0.5932  test_loss=11.9292  λ_max=42.2117\n",
      "[Adam | lr=0.1] Epoch 2256/4000: train_loss=0.5922  test_loss=11.8397  λ_max=42.1372\n",
      "[Adam | lr=0.1] Iter 36100: loss=0.5175\n",
      "[Adam | lr=0.1] Epoch 2257/4000: train_loss=0.5876  test_loss=11.8892  λ_max=43.1409\n",
      "[Adam | lr=0.1] Epoch 2258/4000: train_loss=0.5892  test_loss=11.9694  λ_max=43.8242\n",
      "[Adam | lr=0.1] Epoch 2259/4000: train_loss=0.5875  test_loss=12.0623  λ_max=46.6523\n",
      "[Adam | lr=0.1] Epoch 2260/4000: train_loss=0.5662  test_loss=12.0381  λ_max=42.4531\n",
      "[Adam | lr=0.1] Epoch 2261/4000: train_loss=0.5581  test_loss=12.1337  λ_max=39.3343\n",
      "[Adam | lr=0.1] Epoch 2262/4000: train_loss=0.5532  test_loss=12.3083  λ_max=41.7311\n",
      "[Adam | lr=0.1] Iter 36200: loss=0.5451\n",
      "[Adam | lr=0.1] Epoch 2263/4000: train_loss=0.5510  test_loss=12.4246  λ_max=41.4061\n",
      "[Adam | lr=0.1] Epoch 2264/4000: train_loss=0.5555  test_loss=12.5371  λ_max=41.0978\n",
      "[Adam | lr=0.1] Epoch 2265/4000: train_loss=0.5541  test_loss=12.5983  λ_max=41.0967\n",
      "[Adam | lr=0.1] Epoch 2266/4000: train_loss=0.5454  test_loss=12.5991  λ_max=41.2784\n",
      "[Adam | lr=0.1] Epoch 2267/4000: train_loss=0.5590  test_loss=12.7925  λ_max=39.6342\n",
      "[Adam | lr=0.1] Epoch 2268/4000: train_loss=0.5518  test_loss=12.7874  λ_max=39.5497\n",
      "[Adam | lr=0.1] Iter 36300: loss=0.6305\n",
      "[Adam | lr=0.1] Epoch 2269/4000: train_loss=0.5567  test_loss=12.8528  λ_max=39.3544\n",
      "[Adam | lr=0.1] Epoch 2270/4000: train_loss=0.5557  test_loss=12.9466  λ_max=37.8898\n",
      "[Adam | lr=0.1] Epoch 2271/4000: train_loss=0.5477  test_loss=13.0101  λ_max=39.4641\n",
      "[Adam | lr=0.1] Epoch 2272/4000: train_loss=0.5457  test_loss=13.1509  λ_max=37.2183\n",
      "[Adam | lr=0.1] Epoch 2273/4000: train_loss=0.5499  test_loss=13.0888  λ_max=40.0739\n",
      "[Adam | lr=0.1] Epoch 2274/4000: train_loss=0.5541  test_loss=13.1984  λ_max=39.2663\n",
      "[Adam | lr=0.1] Iter 36400: loss=0.6423\n",
      "[Adam | lr=0.1] Epoch 2275/4000: train_loss=0.5540  test_loss=13.3282  λ_max=38.7441\n",
      "[Adam | lr=0.1] Epoch 2276/4000: train_loss=0.5395  test_loss=13.2386  λ_max=33.7012\n",
      "[Adam | lr=0.1] Epoch 2277/4000: train_loss=0.5318  test_loss=13.2444  λ_max=37.7297\n",
      "[Adam | lr=0.1] Epoch 2278/4000: train_loss=0.5295  test_loss=13.4012  λ_max=38.0681\n",
      "[Adam | lr=0.1] Epoch 2279/4000: train_loss=0.5330  test_loss=13.5117  λ_max=37.8486\n",
      "[Adam | lr=0.1] Epoch 2280/4000: train_loss=0.5189  test_loss=13.5948  λ_max=40.6423\n",
      "[Adam | lr=0.1] Epoch 2281/4000: train_loss=0.5031  test_loss=13.7577  λ_max=40.1746\n",
      "[Adam | lr=0.1] Iter 36500: loss=0.4488\n",
      "[Adam | lr=0.1] Epoch 2282/4000: train_loss=0.4968  test_loss=13.8564  λ_max=39.5366\n",
      "[Adam | lr=0.1] Epoch 2283/4000: train_loss=0.4946  test_loss=14.1174  λ_max=36.3638\n",
      "[Adam | lr=0.1] Epoch 2284/4000: train_loss=0.4899  test_loss=14.2779  λ_max=34.9800\n",
      "[Adam | lr=0.1] Epoch 2285/4000: train_loss=0.4932  test_loss=14.3310  λ_max=37.9223\n",
      "[Adam | lr=0.1] Epoch 2286/4000: train_loss=0.5015  test_loss=14.5587  λ_max=31.6795\n",
      "[Adam | lr=0.1] Epoch 2287/4000: train_loss=0.5018  test_loss=14.4680  λ_max=39.6654\n",
      "[Adam | lr=0.1] Iter 36600: loss=0.4778\n",
      "[Adam | lr=0.1] Epoch 2288/4000: train_loss=0.5066  test_loss=14.5428  λ_max=39.0545\n",
      "[Adam | lr=0.1] Epoch 2289/4000: train_loss=0.4980  test_loss=14.5967  λ_max=40.1394\n",
      "[Adam | lr=0.1] Epoch 2290/4000: train_loss=0.4934  test_loss=14.6254  λ_max=40.8428\n",
      "[Adam | lr=0.1] Epoch 2291/4000: train_loss=0.4863  test_loss=14.7723  λ_max=40.4210\n",
      "[Adam | lr=0.1] Epoch 2292/4000: train_loss=0.4837  test_loss=14.9076  λ_max=32.0318\n",
      "[Adam | lr=0.1] Epoch 2293/4000: train_loss=0.4883  test_loss=15.0032  λ_max=30.8656\n",
      "[Adam | lr=0.1] Iter 36700: loss=0.5123\n",
      "[Adam | lr=0.1] Epoch 2294/4000: train_loss=0.4848  test_loss=15.1170  λ_max=38.4637\n",
      "[Adam | lr=0.1] Epoch 2295/4000: train_loss=0.4823  test_loss=15.2984  λ_max=38.2972\n",
      "[Adam | lr=0.1] Epoch 2296/4000: train_loss=0.4804  test_loss=15.3449  λ_max=37.1874\n",
      "[Adam | lr=0.1] Epoch 2297/4000: train_loss=0.4927  test_loss=15.4819  λ_max=34.4767\n",
      "[Adam | lr=0.1] Epoch 2298/4000: train_loss=0.4856  test_loss=15.4174  λ_max=35.3721\n",
      "[Adam | lr=0.1] Epoch 2299/4000: train_loss=0.4788  test_loss=15.4961  λ_max=32.0868\n",
      "[Adam | lr=0.1] Iter 36800: loss=0.5399\n",
      "[Adam | lr=0.1] Epoch 2300/4000: train_loss=0.4838  test_loss=15.6743  λ_max=30.8873\n",
      "[Adam | lr=0.1] Epoch 2301/4000: train_loss=0.4909  test_loss=15.8467  λ_max=32.3524\n",
      "[Adam | lr=0.1] Epoch 2302/4000: train_loss=0.4803  test_loss=15.7817  λ_max=34.9521\n",
      "[Adam | lr=0.1] Epoch 2303/4000: train_loss=0.4618  test_loss=15.9055  λ_max=36.6822\n",
      "[Adam | lr=0.1] Epoch 2304/4000: train_loss=0.4661  test_loss=16.1229  λ_max=36.2351\n",
      "[Adam | lr=0.1] Epoch 2305/4000: train_loss=0.4757  test_loss=16.1862  λ_max=36.8330\n",
      "[Adam | lr=0.1] Epoch 2306/4000: train_loss=0.4782  test_loss=16.2130  λ_max=41.5907\n",
      "[Adam | lr=0.1] Iter 36900: loss=0.4499\n",
      "[Adam | lr=0.1] Epoch 2307/4000: train_loss=0.4702  test_loss=16.4505  λ_max=36.1612\n",
      "[Adam | lr=0.1] Epoch 2308/4000: train_loss=0.4774  test_loss=16.4506  λ_max=35.7405\n",
      "[Adam | lr=0.1] Epoch 2309/4000: train_loss=0.4841  test_loss=16.6773  λ_max=37.3851\n",
      "[Adam | lr=0.1] Epoch 2310/4000: train_loss=0.4737  test_loss=16.5731  λ_max=35.9861\n",
      "[Adam | lr=0.1] Epoch 2311/4000: train_loss=0.4608  test_loss=16.5103  λ_max=36.6924\n",
      "[Adam | lr=0.1] Epoch 2312/4000: train_loss=0.4554  test_loss=16.7306  λ_max=37.2771\n",
      "[Adam | lr=0.1] Iter 37000: loss=0.4609\n",
      "[Adam | lr=0.1] Epoch 2313/4000: train_loss=0.4460  test_loss=16.7443  λ_max=35.6450\n",
      "[Adam | lr=0.1] Epoch 2314/4000: train_loss=0.4405  test_loss=16.9504  λ_max=40.7333\n",
      "[Adam | lr=0.1] Epoch 2315/4000: train_loss=0.4402  test_loss=17.1277  λ_max=41.8510\n",
      "[Adam | lr=0.1] Epoch 2316/4000: train_loss=0.4446  test_loss=17.4308  λ_max=34.0311\n",
      "[Adam | lr=0.1] Epoch 2317/4000: train_loss=0.4346  test_loss=17.3818  λ_max=37.1308\n",
      "[Adam | lr=0.1] Epoch 2318/4000: train_loss=0.4288  test_loss=17.4418  λ_max=30.5912\n",
      "[Adam | lr=0.1] Iter 37100: loss=0.4471\n",
      "[Adam | lr=0.1] Epoch 2319/4000: train_loss=0.4275  test_loss=17.6374  λ_max=33.4963\n",
      "[Adam | lr=0.1] Epoch 2320/4000: train_loss=0.4294  test_loss=17.7708  λ_max=32.9580\n",
      "[Adam | lr=0.1] Epoch 2321/4000: train_loss=0.4293  test_loss=17.9128  λ_max=32.5738\n",
      "[Adam | lr=0.1] Epoch 2322/4000: train_loss=0.4268  test_loss=17.8289  λ_max=31.9289\n",
      "[Adam | lr=0.1] Epoch 2323/4000: train_loss=0.4235  test_loss=18.0039  λ_max=34.2397\n",
      "[Adam | lr=0.1] Epoch 2324/4000: train_loss=0.4159  test_loss=18.0746  λ_max=34.4868\n",
      "[Adam | lr=0.1] Iter 37200: loss=0.4810\n",
      "[Adam | lr=0.1] Epoch 2325/4000: train_loss=0.4197  test_loss=18.2708  λ_max=34.2049\n",
      "[Adam | lr=0.1] Epoch 2326/4000: train_loss=0.4168  test_loss=18.3934  λ_max=33.2589\n",
      "[Adam | lr=0.1] Epoch 2327/4000: train_loss=0.4094  test_loss=18.4498  λ_max=33.8525\n",
      "[Adam | lr=0.1] Epoch 2328/4000: train_loss=0.4085  test_loss=18.5258  λ_max=34.8029\n",
      "[Adam | lr=0.1] Epoch 2329/4000: train_loss=0.4052  test_loss=18.7425  λ_max=31.9322\n",
      "[Adam | lr=0.1] Epoch 2330/4000: train_loss=0.4089  test_loss=18.8742  λ_max=33.9137\n",
      "[Adam | lr=0.1] Epoch 2331/4000: train_loss=0.4120  test_loss=19.0361  λ_max=36.0764\n",
      "[Adam | lr=0.1] Iter 37300: loss=0.3910\n",
      "[Adam | lr=0.1] Epoch 2332/4000: train_loss=0.4177  test_loss=18.9350  λ_max=34.4632\n",
      "[Adam | lr=0.1] Epoch 2333/4000: train_loss=0.4249  test_loss=19.2212  λ_max=35.2399\n",
      "[Adam | lr=0.1] Epoch 2334/4000: train_loss=0.4370  test_loss=19.2798  λ_max=32.7098\n",
      "[Adam | lr=0.1] Epoch 2335/4000: train_loss=0.4389  test_loss=19.1456  λ_max=31.8275\n",
      "[Adam | lr=0.1] Epoch 2336/4000: train_loss=0.4267  test_loss=19.0893  λ_max=32.2461\n",
      "[Adam | lr=0.1] Epoch 2337/4000: train_loss=0.4120  test_loss=19.3786  λ_max=32.0113\n",
      "[Adam | lr=0.1] Iter 37400: loss=0.3416\n",
      "[Adam | lr=0.1] Epoch 2338/4000: train_loss=0.4053  test_loss=19.5270  λ_max=33.6542\n",
      "[Adam | lr=0.1] Epoch 2339/4000: train_loss=0.3773  test_loss=19.4951  λ_max=41.6328\n",
      "[Adam | lr=0.1] Epoch 2340/4000: train_loss=0.3641  test_loss=19.8901  λ_max=40.5212\n",
      "[Adam | lr=0.1] Epoch 2341/4000: train_loss=0.3657  test_loss=20.1031  λ_max=31.6948\n",
      "[Adam | lr=0.1] Epoch 2342/4000: train_loss=0.3776  test_loss=20.3423  λ_max=39.1712\n",
      "[Adam | lr=0.1] Epoch 2343/4000: train_loss=0.3814  test_loss=20.2972  λ_max=39.0160\n",
      "[Adam | lr=0.1] Iter 37500: loss=0.3828\n",
      "[Adam | lr=0.1] Epoch 2344/4000: train_loss=0.3804  test_loss=20.5424  λ_max=36.2611\n",
      "[Adam | lr=0.1] Epoch 2345/4000: train_loss=0.3705  test_loss=20.6935  λ_max=32.7924\n",
      "[Adam | lr=0.1] Epoch 2346/4000: train_loss=0.3755  test_loss=20.9108  λ_max=31.8519\n",
      "[Adam | lr=0.1] Epoch 2347/4000: train_loss=0.3682  test_loss=20.7905  λ_max=32.3347\n",
      "[Adam | lr=0.1] Epoch 2348/4000: train_loss=0.3686  test_loss=21.0222  λ_max=30.2106\n",
      "[Adam | lr=0.1] Epoch 2349/4000: train_loss=0.3764  test_loss=20.9208  λ_max=31.6468\n",
      "[Adam | lr=0.1] Iter 37600: loss=0.5003\n",
      "[Adam | lr=0.1] Epoch 2350/4000: train_loss=0.3789  test_loss=21.1844  λ_max=31.3671\n",
      "[Adam | lr=0.1] Epoch 2351/4000: train_loss=0.3761  test_loss=21.4341  λ_max=31.9246\n",
      "[Adam | lr=0.1] Epoch 2352/4000: train_loss=0.3768  test_loss=21.2813  λ_max=33.5030\n",
      "[Adam | lr=0.1] Epoch 2353/4000: train_loss=0.3861  test_loss=21.3639  λ_max=33.2035\n",
      "[Adam | lr=0.1] Epoch 2354/4000: train_loss=0.3918  test_loss=21.4407  λ_max=35.0211\n",
      "[Adam | lr=0.1] Epoch 2355/4000: train_loss=0.3775  test_loss=21.4557  λ_max=34.2937\n",
      "[Adam | lr=0.1] Epoch 2356/4000: train_loss=0.3577  test_loss=21.7130  λ_max=34.7817\n",
      "[Adam | lr=0.1] Iter 37700: loss=0.3018\n",
      "[Adam | lr=0.1] Epoch 2357/4000: train_loss=0.3453  test_loss=21.7832  λ_max=32.4378\n",
      "[Adam | lr=0.1] Epoch 2358/4000: train_loss=0.3390  test_loss=22.1627  λ_max=31.8830\n",
      "[Adam | lr=0.1] Epoch 2359/4000: train_loss=0.3322  test_loss=22.5293  λ_max=27.6791\n",
      "[Adam | lr=0.1] Epoch 2360/4000: train_loss=0.3279  test_loss=22.5141  λ_max=29.6258\n",
      "[Adam | lr=0.1] Epoch 2361/4000: train_loss=0.3353  test_loss=22.6682  λ_max=30.7730\n",
      "[Adam | lr=0.1] Epoch 2362/4000: train_loss=0.3330  test_loss=23.1914  λ_max=29.1206\n",
      "[Adam | lr=0.1] Iter 37800: loss=0.3092\n",
      "[Adam | lr=0.1] Epoch 2363/4000: train_loss=0.3422  test_loss=23.1390  λ_max=29.9945\n",
      "[Adam | lr=0.1] Epoch 2364/4000: train_loss=0.3559  test_loss=23.3495  λ_max=31.6957\n",
      "[Adam | lr=0.1] Epoch 2365/4000: train_loss=0.3569  test_loss=23.2734  λ_max=34.7940\n",
      "[Adam | lr=0.1] Epoch 2366/4000: train_loss=0.3611  test_loss=23.3177  λ_max=33.1361\n",
      "[Adam | lr=0.1] Epoch 2367/4000: train_loss=0.3532  test_loss=23.5692  λ_max=33.3388\n",
      "[Adam | lr=0.1] Epoch 2368/4000: train_loss=0.3547  test_loss=23.7046  λ_max=30.3683\n",
      "[Adam | lr=0.1] Iter 37900: loss=0.3708\n",
      "[Adam | lr=0.1] Epoch 2369/4000: train_loss=0.3517  test_loss=23.6718  λ_max=32.9448\n",
      "[Adam | lr=0.1] Epoch 2370/4000: train_loss=0.3558  test_loss=23.6976  λ_max=31.0707\n",
      "[Adam | lr=0.1] Epoch 2371/4000: train_loss=0.3612  test_loss=23.8573  λ_max=32.8243\n",
      "[Adam | lr=0.1] Epoch 2372/4000: train_loss=0.3485  test_loss=23.8467  λ_max=31.2764\n",
      "[Adam | lr=0.1] Epoch 2373/4000: train_loss=0.3432  test_loss=24.1670  λ_max=29.8766\n",
      "[Adam | lr=0.1] Epoch 2374/4000: train_loss=0.3578  test_loss=24.3245  λ_max=31.9447\n",
      "[Adam | lr=0.1] Iter 38000: loss=0.4477\n",
      "[Adam | lr=0.1] Epoch 2375/4000: train_loss=0.3730  test_loss=24.4484  λ_max=34.1625\n",
      "[Adam | lr=0.1] Epoch 2376/4000: train_loss=0.3709  test_loss=24.6337  λ_max=35.1997\n",
      "[Adam | lr=0.1] Epoch 2377/4000: train_loss=0.3657  test_loss=24.5698  λ_max=35.4334\n",
      "[Adam | lr=0.1] Epoch 2378/4000: train_loss=0.3472  test_loss=24.6125  λ_max=33.5239\n",
      "[Adam | lr=0.1] Epoch 2379/4000: train_loss=0.3308  test_loss=24.9232  λ_max=33.8681\n",
      "[Adam | lr=0.1] Epoch 2380/4000: train_loss=0.3383  test_loss=24.8985  λ_max=28.5162\n",
      "[Adam | lr=0.1] Epoch 2381/4000: train_loss=0.3353  test_loss=25.1227  λ_max=33.9165\n",
      "[Adam | lr=0.1] Iter 38100: loss=0.2878\n",
      "[Adam | lr=0.1] Epoch 2382/4000: train_loss=0.3323  test_loss=25.3321  λ_max=29.4042\n",
      "[Adam | lr=0.1] Epoch 2383/4000: train_loss=0.3181  test_loss=25.6686  λ_max=28.9946\n",
      "[Adam | lr=0.1] Epoch 2384/4000: train_loss=0.3160  test_loss=25.7467  λ_max=31.1423\n",
      "[Adam | lr=0.1] Epoch 2385/4000: train_loss=0.3123  test_loss=25.8462  λ_max=29.7439\n",
      "[Adam | lr=0.1] Epoch 2386/4000: train_loss=0.3059  test_loss=26.0730  λ_max=28.4800\n",
      "[Adam | lr=0.1] Epoch 2387/4000: train_loss=0.3074  test_loss=26.3553  λ_max=29.3169\n",
      "[Adam | lr=0.1] Iter 38200: loss=0.3123\n",
      "[Adam | lr=0.1] Epoch 2388/4000: train_loss=0.3100  test_loss=26.6226  λ_max=30.6294\n",
      "[Adam | lr=0.1] Epoch 2389/4000: train_loss=0.3285  test_loss=26.6557  λ_max=27.7663\n",
      "[Adam | lr=0.1] Epoch 2390/4000: train_loss=0.3234  test_loss=26.9615  λ_max=26.2207\n",
      "[Adam | lr=0.1] Epoch 2391/4000: train_loss=0.3281  test_loss=27.0757  λ_max=29.4861\n",
      "[Adam | lr=0.1] Epoch 2392/4000: train_loss=0.3300  test_loss=27.2317  λ_max=27.0818\n",
      "[Adam | lr=0.1] Epoch 2393/4000: train_loss=0.3347  test_loss=27.2540  λ_max=25.9193\n",
      "[Adam | lr=0.1] Iter 38300: loss=0.3983\n",
      "[Adam | lr=0.1] Epoch 2394/4000: train_loss=0.3451  test_loss=27.0769  λ_max=27.8421\n",
      "[Adam | lr=0.1] Epoch 2395/4000: train_loss=0.3247  test_loss=27.1728  λ_max=24.6933\n",
      "[Adam | lr=0.1] Epoch 2396/4000: train_loss=0.3215  test_loss=27.3535  λ_max=28.5976\n",
      "[Adam | lr=0.1] Epoch 2397/4000: train_loss=0.3217  test_loss=27.5562  λ_max=28.9671\n",
      "[Adam | lr=0.1] Epoch 2398/4000: train_loss=0.3063  test_loss=27.5163  λ_max=29.9691\n",
      "[Adam | lr=0.1] Epoch 2399/4000: train_loss=0.2883  test_loss=27.9296  λ_max=29.8073\n",
      "[Adam | lr=0.1] Iter 38400: loss=0.3019\n",
      "[Adam | lr=0.1] Epoch 2400/4000: train_loss=0.2803  test_loss=28.0118  λ_max=27.8978\n",
      "[Adam | lr=0.1] Epoch 2401/4000: train_loss=0.2759  test_loss=28.2631  λ_max=26.8793\n",
      "[Adam | lr=0.1] Epoch 2402/4000: train_loss=0.2685  test_loss=28.5612  λ_max=26.2724\n",
      "[Adam | lr=0.1] Epoch 2403/4000: train_loss=0.2801  test_loss=28.8356  λ_max=25.5740\n",
      "[Adam | lr=0.1] Epoch 2404/4000: train_loss=0.2982  test_loss=28.9921  λ_max=22.9515\n",
      "[Adam | lr=0.1] Epoch 2405/4000: train_loss=0.3065  test_loss=29.2689  λ_max=27.6170\n",
      "[Adam | lr=0.1] Epoch 2406/4000: train_loss=0.3064  test_loss=29.5662  λ_max=27.5052\n",
      "[Adam | lr=0.1] Iter 38500: loss=0.2830\n",
      "[Adam | lr=0.1] Epoch 2407/4000: train_loss=0.3155  test_loss=29.5504  λ_max=27.1286\n",
      "[Adam | lr=0.1] Epoch 2408/4000: train_loss=0.3211  test_loss=29.6063  λ_max=26.9205\n",
      "[Adam | lr=0.1] Epoch 2409/4000: train_loss=0.3268  test_loss=29.2159  λ_max=28.2549\n",
      "[Adam | lr=0.1] Epoch 2410/4000: train_loss=0.3201  test_loss=29.4929  λ_max=29.4105\n",
      "[Adam | lr=0.1] Epoch 2411/4000: train_loss=0.3174  test_loss=29.6096  λ_max=27.7133\n",
      "[Adam | lr=0.1] Epoch 2412/4000: train_loss=0.3069  test_loss=29.6992  λ_max=28.9696\n",
      "[Adam | lr=0.1] Iter 38600: loss=0.2926\n",
      "[Adam | lr=0.1] Epoch 2413/4000: train_loss=0.2996  test_loss=29.6680  λ_max=28.6126\n",
      "[Adam | lr=0.1] Epoch 2414/4000: train_loss=0.2851  test_loss=29.9572  λ_max=28.1774\n",
      "[Adam | lr=0.1] Epoch 2415/4000: train_loss=0.2703  test_loss=29.9222  λ_max=25.8493\n",
      "[Adam | lr=0.1] Epoch 2416/4000: train_loss=0.2695  test_loss=30.6531  λ_max=28.1138\n",
      "[Adam | lr=0.1] Epoch 2417/4000: train_loss=0.2657  test_loss=30.6274  λ_max=26.4962\n",
      "[Adam | lr=0.1] Epoch 2418/4000: train_loss=0.2691  test_loss=31.0986  λ_max=27.2081\n",
      "[Adam | lr=0.1] Iter 38700: loss=0.2860\n",
      "[Adam | lr=0.1] Epoch 2419/4000: train_loss=0.2710  test_loss=31.1233  λ_max=29.6578\n",
      "[Adam | lr=0.1] Epoch 2420/4000: train_loss=0.2739  test_loss=31.3220  λ_max=30.3459\n",
      "[Adam | lr=0.1] Epoch 2421/4000: train_loss=0.2563  test_loss=31.5218  λ_max=32.2559\n",
      "[Adam | lr=0.1] Epoch 2422/4000: train_loss=0.2457  test_loss=31.6765  λ_max=33.9194\n",
      "[Adam | lr=0.1] Epoch 2423/4000: train_loss=0.2523  test_loss=32.1603  λ_max=32.4112\n",
      "[Adam | lr=0.1] Epoch 2424/4000: train_loss=0.2570  test_loss=32.1659  λ_max=27.2309\n",
      "[Adam | lr=0.1] Iter 38800: loss=0.3713\n",
      "[Adam | lr=0.1] Epoch 2425/4000: train_loss=0.2689  test_loss=32.5259  λ_max=32.0710\n",
      "[Adam | lr=0.1] Epoch 2426/4000: train_loss=0.2788  test_loss=32.5447  λ_max=28.6953\n",
      "[Adam | lr=0.1] Epoch 2427/4000: train_loss=0.2841  test_loss=32.7601  λ_max=26.2666\n",
      "[Adam | lr=0.1] Epoch 2428/4000: train_loss=0.2835  test_loss=32.8596  λ_max=27.6833\n",
      "[Adam | lr=0.1] Epoch 2429/4000: train_loss=0.2990  test_loss=32.9483  λ_max=27.2949\n",
      "[Adam | lr=0.1] Epoch 2430/4000: train_loss=0.3019  test_loss=32.8291  λ_max=27.8592\n",
      "[Adam | lr=0.1] Epoch 2431/4000: train_loss=0.2853  test_loss=32.7718  λ_max=30.8973\n",
      "[Adam | lr=0.1] Iter 38900: loss=0.2529\n",
      "[Adam | lr=0.1] Epoch 2432/4000: train_loss=0.2833  test_loss=32.6162  λ_max=32.4259\n",
      "[Adam | lr=0.1] Epoch 2433/4000: train_loss=0.2736  test_loss=33.2442  λ_max=32.5191\n",
      "[Adam | lr=0.1] Epoch 2434/4000: train_loss=0.2708  test_loss=33.3535  λ_max=26.6416\n",
      "[Adam | lr=0.1] Epoch 2435/4000: train_loss=0.2650  test_loss=33.2407  λ_max=25.7491\n",
      "[Adam | lr=0.1] Epoch 2436/4000: train_loss=0.2528  test_loss=33.5488  λ_max=25.7447\n",
      "[Adam | lr=0.1] Epoch 2437/4000: train_loss=0.2364  test_loss=33.8220  λ_max=29.1391\n",
      "[Adam | lr=0.1] Iter 39000: loss=0.2266\n",
      "[Adam | lr=0.1] Epoch 2438/4000: train_loss=0.2490  test_loss=34.1062  λ_max=25.6697\n",
      "[Adam | lr=0.1] Epoch 2439/4000: train_loss=0.2578  test_loss=34.2412  λ_max=30.4719\n",
      "[Adam | lr=0.1] Epoch 2440/4000: train_loss=0.2603  test_loss=34.4266  λ_max=29.9016\n",
      "[Adam | lr=0.1] Epoch 2441/4000: train_loss=0.2799  test_loss=35.0575  λ_max=25.7442\n",
      "[Adam | lr=0.1] Epoch 2442/4000: train_loss=0.2930  test_loss=35.0565  λ_max=27.0645\n",
      "[Adam | lr=0.1] Epoch 2443/4000: train_loss=0.2796  test_loss=34.9208  λ_max=27.6120\n",
      "[Adam | lr=0.1] Iter 39100: loss=0.2841\n",
      "[Adam | lr=0.1] Epoch 2444/4000: train_loss=0.2720  test_loss=34.9308  λ_max=31.2622\n",
      "[Adam | lr=0.1] Epoch 2445/4000: train_loss=0.2678  test_loss=34.9772  λ_max=29.3295\n",
      "[Adam | lr=0.1] Epoch 2446/4000: train_loss=0.2738  test_loss=35.5386  λ_max=31.1701\n",
      "[Adam | lr=0.1] Epoch 2447/4000: train_loss=0.2683  test_loss=35.8858  λ_max=29.7551\n",
      "[Adam | lr=0.1] Epoch 2448/4000: train_loss=0.2682  test_loss=35.9598  λ_max=30.2093\n",
      "[Adam | lr=0.1] Epoch 2449/4000: train_loss=0.2748  test_loss=36.2812  λ_max=26.9657\n",
      "[Adam | lr=0.1] Iter 39200: loss=0.3188\n",
      "[Adam | lr=0.1] Epoch 2450/4000: train_loss=0.2731  test_loss=35.9562  λ_max=28.3548\n",
      "[Adam | lr=0.1] Epoch 2451/4000: train_loss=0.2649  test_loss=36.3075  λ_max=23.8345\n",
      "[Adam | lr=0.1] Epoch 2452/4000: train_loss=0.2568  test_loss=36.6695  λ_max=24.6103\n",
      "[Adam | lr=0.1] Epoch 2453/4000: train_loss=0.2596  test_loss=36.9731  λ_max=22.3975\n",
      "[Adam | lr=0.1] Epoch 2454/4000: train_loss=0.2513  test_loss=36.9456  λ_max=21.8991\n",
      "[Adam | lr=0.1] Epoch 2455/4000: train_loss=0.2591  test_loss=37.1480  λ_max=22.2880\n",
      "[Adam | lr=0.1] Epoch 2456/4000: train_loss=0.2648  test_loss=37.1682  λ_max=22.3211\n",
      "[Adam | lr=0.1] Iter 39300: loss=0.2083\n",
      "[Adam | lr=0.1] Epoch 2457/4000: train_loss=0.2604  test_loss=37.3835  λ_max=24.8625\n",
      "[Adam | lr=0.1] Epoch 2458/4000: train_loss=0.2688  test_loss=37.6207  λ_max=22.4612\n",
      "[Adam | lr=0.1] Epoch 2459/4000: train_loss=0.2821  test_loss=37.7478  λ_max=24.7106\n",
      "[Adam | lr=0.1] Epoch 2460/4000: train_loss=0.2919  test_loss=37.6440  λ_max=23.6631\n",
      "[Adam | lr=0.1] Epoch 2461/4000: train_loss=0.2982  test_loss=37.7150  λ_max=25.6082\n",
      "[Adam | lr=0.1] Epoch 2462/4000: train_loss=0.2886  test_loss=37.7984  λ_max=26.0973\n",
      "[Adam | lr=0.1] Iter 39400: loss=0.2669\n",
      "[Adam | lr=0.1] Epoch 2463/4000: train_loss=0.2865  test_loss=38.0591  λ_max=24.9598\n",
      "[Adam | lr=0.1] Epoch 2464/4000: train_loss=0.2796  test_loss=38.1226  λ_max=27.9113\n",
      "[Adam | lr=0.1] Epoch 2465/4000: train_loss=0.2753  test_loss=38.3741  λ_max=29.4420\n",
      "[Adam | lr=0.1] Epoch 2466/4000: train_loss=0.2784  test_loss=38.3670  λ_max=28.8344\n",
      "[Adam | lr=0.1] Epoch 2467/4000: train_loss=0.2801  test_loss=38.3555  λ_max=28.2851\n",
      "[Adam | lr=0.1] Epoch 2468/4000: train_loss=0.2922  test_loss=38.8177  λ_max=27.9694\n",
      "[Adam | lr=0.1] Iter 39500: loss=0.3487\n",
      "[Adam | lr=0.1] Epoch 2469/4000: train_loss=0.2905  test_loss=39.3816  λ_max=32.1996\n",
      "[Adam | lr=0.1] Epoch 2470/4000: train_loss=0.2811  test_loss=39.2000  λ_max=32.4365\n",
      "[Adam | lr=0.1] Epoch 2471/4000: train_loss=0.2721  test_loss=39.1548  λ_max=32.8760\n",
      "[Adam | lr=0.1] Epoch 2472/4000: train_loss=0.2685  test_loss=39.3708  λ_max=24.0546\n",
      "[Adam | lr=0.1] Epoch 2473/4000: train_loss=0.2640  test_loss=39.5975  λ_max=23.0503\n",
      "[Adam | lr=0.1] Epoch 2474/4000: train_loss=0.2562  test_loss=39.5450  λ_max=21.9424\n",
      "[Adam | lr=0.1] Iter 39600: loss=0.3292\n",
      "[Adam | lr=0.1] Epoch 2475/4000: train_loss=0.2487  test_loss=39.8326  λ_max=23.2272\n",
      "[Adam | lr=0.1] Epoch 2476/4000: train_loss=0.2387  test_loss=40.1459  λ_max=27.3646\n",
      "[Adam | lr=0.1] Epoch 2477/4000: train_loss=0.2440  test_loss=40.5091  λ_max=20.7461\n",
      "[Adam | lr=0.1] Epoch 2478/4000: train_loss=0.2283  test_loss=40.3153  λ_max=24.5405\n",
      "[Adam | lr=0.1] Epoch 2479/4000: train_loss=0.2193  test_loss=40.9033  λ_max=23.5580\n",
      "[Adam | lr=0.1] Epoch 2480/4000: train_loss=0.2091  test_loss=40.9508  λ_max=21.0727\n",
      "[Adam | lr=0.1] Epoch 2481/4000: train_loss=0.1978  test_loss=41.4369  λ_max=23.7971\n",
      "[Adam | lr=0.1] Iter 39700: loss=0.1711\n",
      "[Adam | lr=0.1] Epoch 2482/4000: train_loss=0.1993  test_loss=41.3580  λ_max=22.2384\n",
      "[Adam | lr=0.1] Epoch 2483/4000: train_loss=0.2109  test_loss=42.0568  λ_max=23.4802\n",
      "[Adam | lr=0.1] Epoch 2484/4000: train_loss=0.2101  test_loss=42.2614  λ_max=22.9256\n",
      "[Adam | lr=0.1] Epoch 2485/4000: train_loss=0.2058  test_loss=42.2249  λ_max=22.0763\n",
      "[Adam | lr=0.1] Epoch 2486/4000: train_loss=0.2043  test_loss=43.0861  λ_max=24.1061\n",
      "[Adam | lr=0.1] Epoch 2487/4000: train_loss=0.2027  test_loss=42.7759  λ_max=24.7503\n",
      "[Adam | lr=0.1] Iter 39800: loss=0.2503\n",
      "[Adam | lr=0.1] Epoch 2488/4000: train_loss=0.2299  test_loss=43.5396  λ_max=20.9461\n",
      "[Adam | lr=0.1] Epoch 2489/4000: train_loss=0.2399  test_loss=43.5760  λ_max=21.2500\n",
      "[Adam | lr=0.1] Epoch 2490/4000: train_loss=0.2534  test_loss=43.5323  λ_max=23.0334\n",
      "[Adam | lr=0.1] Epoch 2491/4000: train_loss=0.2595  test_loss=43.7552  λ_max=21.1535\n",
      "[Adam | lr=0.1] Epoch 2492/4000: train_loss=0.2623  test_loss=43.6790  λ_max=21.1643\n",
      "[Adam | lr=0.1] Epoch 2493/4000: train_loss=0.2666  test_loss=43.5204  λ_max=26.1740\n",
      "[Adam | lr=0.1] Iter 39900: loss=0.2871\n",
      "[Adam | lr=0.1] Epoch 2494/4000: train_loss=0.2778  test_loss=43.8185  λ_max=26.8036\n",
      "[Adam | lr=0.1] Epoch 2495/4000: train_loss=0.2680  test_loss=43.8730  λ_max=27.4669\n",
      "[Adam | lr=0.1] Epoch 2496/4000: train_loss=0.2696  test_loss=44.0569  λ_max=31.6969\n",
      "[Adam | lr=0.1] Epoch 2497/4000: train_loss=0.2574  test_loss=44.0644  λ_max=31.0630\n",
      "[Adam | lr=0.1] Epoch 2498/4000: train_loss=0.2462  test_loss=44.1459  λ_max=31.8546\n",
      "[Adam | lr=0.1] Epoch 2499/4000: train_loss=0.2467  test_loss=44.3547  λ_max=24.7906\n",
      "[Adam | lr=0.1] Iter 40000: loss=0.2865\n",
      "[Adam | lr=0.1] Epoch 2500/4000: train_loss=0.2503  test_loss=44.7229  λ_max=25.5495\n",
      "[Adam | lr=0.1] Epoch 2501/4000: train_loss=0.2490  test_loss=44.4347  λ_max=29.7178\n",
      "[Adam | lr=0.1] Epoch 2502/4000: train_loss=0.2419  test_loss=44.8515  λ_max=29.5605\n",
      "[Adam | lr=0.1] Epoch 2503/4000: train_loss=0.2363  test_loss=44.7879  λ_max=30.8524\n",
      "[Adam | lr=0.1] Epoch 2504/4000: train_loss=0.2497  test_loss=45.5701  λ_max=26.2351\n",
      "[Adam | lr=0.1] Epoch 2505/4000: train_loss=0.2542  test_loss=45.5574  λ_max=22.0426\n",
      "[Adam | lr=0.1] Epoch 2506/4000: train_loss=0.2512  test_loss=45.4662  λ_max=20.8030\n",
      "[Adam | lr=0.1] Iter 40100: loss=0.2125\n",
      "[Adam | lr=0.1] Epoch 2507/4000: train_loss=0.2651  test_loss=45.8080  λ_max=20.3019\n",
      "[Adam | lr=0.1] Epoch 2508/4000: train_loss=0.2703  test_loss=45.6181  λ_max=22.1686\n",
      "[Adam | lr=0.1] Epoch 2509/4000: train_loss=0.2547  test_loss=46.5066  λ_max=21.9206\n",
      "[Adam | lr=0.1] Epoch 2510/4000: train_loss=0.2450  test_loss=46.1695  λ_max=21.3642\n",
      "[Adam | lr=0.1] Epoch 2511/4000: train_loss=0.2454  test_loss=46.5635  λ_max=20.4089\n",
      "[Adam | lr=0.1] Epoch 2512/4000: train_loss=0.2469  test_loss=46.2903  λ_max=23.0205\n",
      "[Adam | lr=0.1] Iter 40200: loss=0.2409\n",
      "[Adam | lr=0.1] Epoch 2513/4000: train_loss=0.2388  test_loss=46.6019  λ_max=24.4672\n",
      "[Adam | lr=0.1] Epoch 2514/4000: train_loss=0.2472  test_loss=46.9423  λ_max=25.4937\n",
      "[Adam | lr=0.1] Epoch 2515/4000: train_loss=0.2360  test_loss=47.7440  λ_max=25.6636\n",
      "[Adam | lr=0.1] Epoch 2516/4000: train_loss=0.2265  test_loss=47.4731  λ_max=25.2607\n",
      "[Adam | lr=0.1] Epoch 2517/4000: train_loss=0.2203  test_loss=48.0427  λ_max=26.3973\n",
      "[Adam | lr=0.1] Epoch 2518/4000: train_loss=0.2072  test_loss=47.8710  λ_max=25.0082\n",
      "[Adam | lr=0.1] Iter 40300: loss=0.2179\n",
      "[Adam | lr=0.1] Epoch 2519/4000: train_loss=0.2052  test_loss=48.5671  λ_max=24.9840\n",
      "[Adam | lr=0.1] Epoch 2520/4000: train_loss=0.2222  test_loss=48.7614  λ_max=22.4789\n",
      "[Adam | lr=0.1] Epoch 2521/4000: train_loss=0.2298  test_loss=49.1806  λ_max=22.6803\n",
      "[Adam | lr=0.1] Epoch 2522/4000: train_loss=0.2316  test_loss=49.6245  λ_max=24.9251\n",
      "[Adam | lr=0.1] Epoch 2523/4000: train_loss=0.2270  test_loss=49.1673  λ_max=27.6941\n",
      "[Adam | lr=0.1] Epoch 2524/4000: train_loss=0.2360  test_loss=49.3777  λ_max=26.5346\n",
      "[Adam | lr=0.1] Iter 40400: loss=0.3477\n",
      "[Adam | lr=0.1] Epoch 2525/4000: train_loss=0.2577  test_loss=49.3448  λ_max=25.1769\n",
      "[Adam | lr=0.1] Epoch 2526/4000: train_loss=0.2685  test_loss=50.2952  λ_max=21.7843\n",
      "[Adam | lr=0.1] Epoch 2527/4000: train_loss=0.2806  test_loss=49.8465  λ_max=21.3966\n",
      "[Adam | lr=0.1] Epoch 2528/4000: train_loss=0.2787  test_loss=49.9861  λ_max=24.3156\n",
      "[Adam | lr=0.1] Epoch 2529/4000: train_loss=0.2727  test_loss=50.3889  λ_max=26.5365\n",
      "[Adam | lr=0.1] Epoch 2530/4000: train_loss=0.2670  test_loss=50.3864  λ_max=25.5892\n",
      "[Adam | lr=0.1] Epoch 2531/4000: train_loss=0.2465  test_loss=50.2460  λ_max=30.5386\n",
      "[Adam | lr=0.1] Iter 40500: loss=0.2032\n",
      "[Adam | lr=0.1] Epoch 2532/4000: train_loss=0.2520  test_loss=50.7686  λ_max=33.1076\n",
      "[Adam | lr=0.1] Epoch 2533/4000: train_loss=0.2604  test_loss=50.7593  λ_max=29.4264\n",
      "[Adam | lr=0.1] Epoch 2534/4000: train_loss=0.2671  test_loss=51.2412  λ_max=29.9766\n",
      "[Adam | lr=0.1] Epoch 2535/4000: train_loss=0.2754  test_loss=51.6961  λ_max=28.8539\n",
      "[Adam | lr=0.1] Epoch 2536/4000: train_loss=0.2645  test_loss=51.1192  λ_max=25.2492\n",
      "[Adam | lr=0.1] Epoch 2537/4000: train_loss=0.2647  test_loss=51.5738  λ_max=22.8578\n",
      "[Adam | lr=0.1] Iter 40600: loss=0.2545\n",
      "[Adam | lr=0.1] Epoch 2538/4000: train_loss=0.2554  test_loss=52.2434  λ_max=25.7604\n",
      "[Adam | lr=0.1] Epoch 2539/4000: train_loss=0.2530  test_loss=52.2074  λ_max=25.5459\n",
      "[Adam | lr=0.1] Epoch 2540/4000: train_loss=0.2329  test_loss=52.6349  λ_max=28.7430\n",
      "[Adam | lr=0.1] Epoch 2541/4000: train_loss=0.2255  test_loss=52.9762  λ_max=27.4748\n",
      "[Adam | lr=0.1] Epoch 2542/4000: train_loss=0.2056  test_loss=52.6145  λ_max=28.4321\n",
      "[Adam | lr=0.1] Epoch 2543/4000: train_loss=0.2042  test_loss=53.1942  λ_max=25.5824\n",
      "[Adam | lr=0.1] Iter 40700: loss=0.2114\n",
      "[Adam | lr=0.1] Epoch 2544/4000: train_loss=0.2136  test_loss=53.3245  λ_max=23.5454\n",
      "[Adam | lr=0.1] Epoch 2545/4000: train_loss=0.2189  test_loss=54.3150  λ_max=23.8645\n",
      "[Adam | lr=0.1] Epoch 2546/4000: train_loss=0.2386  test_loss=53.7184  λ_max=23.7556\n",
      "[Adam | lr=0.1] Epoch 2547/4000: train_loss=0.2356  test_loss=54.4082  λ_max=26.2803\n",
      "[Adam | lr=0.1] Epoch 2548/4000: train_loss=0.2287  test_loss=54.6021  λ_max=25.8804\n",
      "[Adam | lr=0.1] Epoch 2549/4000: train_loss=0.2285  test_loss=54.6591  λ_max=28.6530\n",
      "[Adam | lr=0.1] Iter 40800: loss=0.2804\n",
      "[Adam | lr=0.1] Epoch 2550/4000: train_loss=0.2275  test_loss=55.0143  λ_max=27.8805\n",
      "[Adam | lr=0.1] Epoch 2551/4000: train_loss=0.2264  test_loss=55.3972  λ_max=29.7723\n",
      "[Adam | lr=0.1] Epoch 2552/4000: train_loss=0.2431  test_loss=55.5473  λ_max=25.9129\n",
      "[Adam | lr=0.1] Epoch 2553/4000: train_loss=0.2401  test_loss=55.7817  λ_max=24.2557\n",
      "[Adam | lr=0.1] Epoch 2554/4000: train_loss=0.2246  test_loss=55.2299  λ_max=25.6129\n",
      "[Adam | lr=0.1] Epoch 2555/4000: train_loss=0.2091  test_loss=56.0977  λ_max=24.5391\n",
      "[Adam | lr=0.1] Epoch 2556/4000: train_loss=0.2173  test_loss=56.1569  λ_max=22.8768\n",
      "[Adam | lr=0.1] Iter 40900: loss=0.2021\n",
      "[Adam | lr=0.1] Epoch 2557/4000: train_loss=0.2127  test_loss=56.3684  λ_max=24.9723\n",
      "[Adam | lr=0.1] Epoch 2558/4000: train_loss=0.2153  test_loss=56.3653  λ_max=24.4305\n",
      "[Adam | lr=0.1] Epoch 2559/4000: train_loss=0.2151  test_loss=56.6211  λ_max=24.0118\n",
      "[Adam | lr=0.1] Epoch 2560/4000: train_loss=0.2071  test_loss=56.7513  λ_max=24.5410\n",
      "[Adam | lr=0.1] Epoch 2561/4000: train_loss=0.2134  test_loss=56.7406  λ_max=23.0933\n",
      "[Adam | lr=0.1] Epoch 2562/4000: train_loss=0.2149  test_loss=57.0978  λ_max=24.2183\n",
      "[Adam | lr=0.1] Iter 41000: loss=0.2101\n",
      "[Adam | lr=0.1] Epoch 2563/4000: train_loss=0.2190  test_loss=57.5819  λ_max=23.6349\n",
      "[Adam | lr=0.1] Epoch 2564/4000: train_loss=0.2115  test_loss=57.9442  λ_max=22.9625\n",
      "[Adam | lr=0.1] Epoch 2565/4000: train_loss=0.2077  test_loss=57.8704  λ_max=26.9122\n",
      "[Adam | lr=0.1] Epoch 2566/4000: train_loss=0.2120  test_loss=58.6123  λ_max=27.7851\n",
      "[Adam | lr=0.1] Epoch 2567/4000: train_loss=0.2320  test_loss=58.8824  λ_max=28.3605\n",
      "[Adam | lr=0.1] Epoch 2568/4000: train_loss=0.2446  test_loss=58.6363  λ_max=26.2187\n",
      "[Adam | lr=0.1] Iter 41100: loss=0.2538\n",
      "[Adam | lr=0.1] Epoch 2569/4000: train_loss=0.2423  test_loss=59.0286  λ_max=24.6662\n",
      "[Adam | lr=0.1] Epoch 2570/4000: train_loss=0.2422  test_loss=59.2582  λ_max=24.2955\n",
      "[Adam | lr=0.1] Epoch 2571/4000: train_loss=0.2441  test_loss=59.5262  λ_max=23.1363\n",
      "[Adam | lr=0.1] Epoch 2572/4000: train_loss=0.2484  test_loss=59.0616  λ_max=26.4414\n",
      "[Adam | lr=0.1] Epoch 2573/4000: train_loss=0.2622  test_loss=59.4585  λ_max=24.1595\n",
      "[Adam | lr=0.1] Epoch 2574/4000: train_loss=0.2690  test_loss=59.8314  λ_max=24.5287\n",
      "[Adam | lr=0.1] Iter 41200: loss=0.3414\n",
      "[Adam | lr=0.1] Epoch 2575/4000: train_loss=0.2598  test_loss=59.6377  λ_max=26.6528\n",
      "[Adam | lr=0.1] Epoch 2576/4000: train_loss=0.2755  test_loss=59.4815  λ_max=28.3965\n",
      "[Adam | lr=0.1] Epoch 2577/4000: train_loss=0.2741  test_loss=59.8092  λ_max=26.1588\n",
      "[Adam | lr=0.1] Epoch 2578/4000: train_loss=0.2554  test_loss=59.9988  λ_max=26.9460\n",
      "[Adam | lr=0.1] Epoch 2579/4000: train_loss=0.2453  test_loss=60.1273  λ_max=25.9623\n",
      "[Adam | lr=0.1] Epoch 2580/4000: train_loss=0.2414  test_loss=60.6096  λ_max=26.4421\n",
      "[Adam | lr=0.1] Epoch 2581/4000: train_loss=0.2274  test_loss=60.8007  λ_max=25.7312\n",
      "[Adam | lr=0.1] Iter 41300: loss=0.1822\n",
      "[Adam | lr=0.1] Epoch 2582/4000: train_loss=0.2090  test_loss=61.0436  λ_max=24.2105\n",
      "[Adam | lr=0.1] Epoch 2583/4000: train_loss=0.2116  test_loss=61.2095  λ_max=24.4991\n",
      "[Adam | lr=0.1] Epoch 2584/4000: train_loss=0.2020  test_loss=61.7847  λ_max=23.0743\n",
      "[Adam | lr=0.1] Epoch 2585/4000: train_loss=0.1899  test_loss=62.0428  λ_max=24.0869\n",
      "[Adam | lr=0.1] Epoch 2586/4000: train_loss=0.1899  test_loss=62.5281  λ_max=23.5021\n",
      "[Adam | lr=0.1] Epoch 2587/4000: train_loss=0.1894  test_loss=63.0202  λ_max=21.6639\n",
      "[Adam | lr=0.1] Iter 41400: loss=0.1782\n",
      "[Adam | lr=0.1] Epoch 2588/4000: train_loss=0.1816  test_loss=63.7844  λ_max=26.0536\n",
      "[Adam | lr=0.1] Epoch 2589/4000: train_loss=0.1855  test_loss=63.5015  λ_max=21.0410\n",
      "[Adam | lr=0.1] Epoch 2590/4000: train_loss=0.1809  test_loss=63.6729  λ_max=21.6535\n",
      "[Adam | lr=0.1] Epoch 2591/4000: train_loss=0.1796  test_loss=64.3842  λ_max=19.9863\n",
      "[Adam | lr=0.1] Epoch 2592/4000: train_loss=0.1870  test_loss=64.2404  λ_max=19.6540\n",
      "[Adam | lr=0.1] Epoch 2593/4000: train_loss=0.1774  test_loss=64.7299  λ_max=21.1441\n",
      "[Adam | lr=0.1] Iter 41500: loss=0.2128\n",
      "[Adam | lr=0.1] Epoch 2594/4000: train_loss=0.1750  test_loss=64.5463  λ_max=21.3652\n",
      "[Adam | lr=0.1] Epoch 2595/4000: train_loss=0.1971  test_loss=65.5286  λ_max=17.9513\n",
      "[Adam | lr=0.1] Epoch 2596/4000: train_loss=0.2071  test_loss=65.5701  λ_max=19.4127\n",
      "[Adam | lr=0.1] Epoch 2597/4000: train_loss=0.2313  test_loss=65.8322  λ_max=21.0638\n",
      "[Adam | lr=0.1] Epoch 2598/4000: train_loss=0.2424  test_loss=66.0842  λ_max=23.3219\n",
      "[Adam | lr=0.1] Epoch 2599/4000: train_loss=0.2738  test_loss=65.8412  λ_max=26.1089\n",
      "[Adam | lr=0.1] Iter 41600: loss=0.4401\n",
      "[Adam | lr=0.1] Epoch 2600/4000: train_loss=0.3128  test_loss=66.1662  λ_max=27.4255\n",
      "[Adam | lr=0.1] Epoch 2601/4000: train_loss=0.3169  test_loss=65.9143  λ_max=32.1038\n",
      "[Adam | lr=0.1] Epoch 2602/4000: train_loss=0.3350  test_loss=65.5031  λ_max=31.6339\n",
      "[Adam | lr=0.1] Epoch 2603/4000: train_loss=0.3143  test_loss=65.9352  λ_max=29.9924\n",
      "[Adam | lr=0.1] Epoch 2604/4000: train_loss=0.3053  test_loss=65.4706  λ_max=30.0137\n",
      "[Adam | lr=0.1] Epoch 2605/4000: train_loss=0.3015  test_loss=65.4129  λ_max=28.6700\n",
      "[Adam | lr=0.1] Epoch 2606/4000: train_loss=0.2928  test_loss=65.6347  λ_max=26.1503\n",
      "[Adam | lr=0.1] Iter 41700: loss=0.2194\n",
      "[Adam | lr=0.1] Epoch 2607/4000: train_loss=0.2724  test_loss=65.4048  λ_max=28.6911\n",
      "[Adam | lr=0.1] Epoch 2608/4000: train_loss=0.2725  test_loss=66.5445  λ_max=31.4343\n",
      "[Adam | lr=0.1] Epoch 2609/4000: train_loss=0.2623  test_loss=66.0436  λ_max=32.5461\n",
      "[Adam | lr=0.1] Epoch 2610/4000: train_loss=0.2456  test_loss=66.9640  λ_max=31.7865\n",
      "[Adam | lr=0.1] Epoch 2611/4000: train_loss=0.2353  test_loss=66.2123  λ_max=30.2702\n",
      "[Adam | lr=0.1] Epoch 2612/4000: train_loss=0.2278  test_loss=67.1524  λ_max=25.5442\n",
      "[Adam | lr=0.1] Iter 41800: loss=0.1993\n",
      "[Adam | lr=0.1] Epoch 2613/4000: train_loss=0.2231  test_loss=67.4253  λ_max=25.8569\n",
      "[Adam | lr=0.1] Epoch 2614/4000: train_loss=0.2066  test_loss=67.7273  λ_max=25.9022\n",
      "[Adam | lr=0.1] Epoch 2615/4000: train_loss=0.1844  test_loss=68.3753  λ_max=25.2471\n",
      "[Adam | lr=0.1] Epoch 2616/4000: train_loss=0.1710  test_loss=68.7176  λ_max=22.8327\n",
      "[Adam | lr=0.1] Epoch 2617/4000: train_loss=0.1553  test_loss=69.2131  λ_max=23.2214\n",
      "[Adam | lr=0.1] Epoch 2618/4000: train_loss=0.1447  test_loss=69.1449  λ_max=23.9698\n",
      "[Adam | lr=0.1] Iter 41900: loss=0.1574\n",
      "[Adam | lr=0.1] Epoch 2619/4000: train_loss=0.1446  test_loss=69.3842  λ_max=22.7527\n",
      "[Adam | lr=0.1] Epoch 2620/4000: train_loss=0.1456  test_loss=69.8173  λ_max=24.2630\n",
      "[Adam | lr=0.1] Epoch 2621/4000: train_loss=0.1538  test_loss=71.1183  λ_max=24.1069\n",
      "[Adam | lr=0.1] Epoch 2622/4000: train_loss=0.1540  test_loss=70.9421  λ_max=21.0508\n",
      "[Adam | lr=0.1] Epoch 2623/4000: train_loss=0.1597  test_loss=71.4606  λ_max=23.2672\n",
      "[Adam | lr=0.1] Epoch 2624/4000: train_loss=0.1737  test_loss=72.0371  λ_max=21.7938\n",
      "[Adam | lr=0.1] Iter 42000: loss=0.1982\n",
      "[Adam | lr=0.1] Epoch 2625/4000: train_loss=0.1786  test_loss=72.4084  λ_max=22.0283\n",
      "[Adam | lr=0.1] Epoch 2626/4000: train_loss=0.1926  test_loss=72.3589  λ_max=22.8038\n",
      "[Adam | lr=0.1] Epoch 2627/4000: train_loss=0.2078  test_loss=72.9245  λ_max=22.3632\n",
      "[Adam | lr=0.1] Epoch 2628/4000: train_loss=0.2182  test_loss=72.9889  λ_max=20.8643\n",
      "[Adam | lr=0.1] Epoch 2629/4000: train_loss=0.2335  test_loss=73.8515  λ_max=20.7846\n",
      "[Adam | lr=0.1] Epoch 2630/4000: train_loss=0.2577  test_loss=73.7095  λ_max=22.3552\n",
      "[Adam | lr=0.1] Epoch 2631/4000: train_loss=0.2835  test_loss=73.0666  λ_max=21.8140\n",
      "[Adam | lr=0.1] Iter 42100: loss=0.2358\n",
      "[Adam | lr=0.1] Epoch 2632/4000: train_loss=0.2955  test_loss=73.6187  λ_max=22.6493\n",
      "[Adam | lr=0.1] Epoch 2633/4000: train_loss=0.3123  test_loss=73.4186  λ_max=25.2496\n",
      "[Adam | lr=0.1] Epoch 2634/4000: train_loss=0.3185  test_loss=73.0997  λ_max=28.0462\n",
      "[Adam | lr=0.1] Epoch 2635/4000: train_loss=0.3219  test_loss=73.7650  λ_max=30.2653\n",
      "[Adam | lr=0.1] Epoch 2636/4000: train_loss=0.3238  test_loss=73.6109  λ_max=27.6038\n",
      "[Adam | lr=0.1] Epoch 2637/4000: train_loss=0.3048  test_loss=72.6153  λ_max=28.8747\n",
      "[Adam | lr=0.1] Iter 42200: loss=0.2703\n",
      "[Adam | lr=0.1] Epoch 2638/4000: train_loss=0.2749  test_loss=73.2215  λ_max=28.6482\n",
      "[Adam | lr=0.1] Epoch 2639/4000: train_loss=0.2618  test_loss=73.4399  λ_max=32.3667\n",
      "[Adam | lr=0.1] Epoch 2640/4000: train_loss=0.2531  test_loss=72.8594  λ_max=29.8090\n",
      "[Adam | lr=0.1] Epoch 2641/4000: train_loss=0.2257  test_loss=73.6336  λ_max=30.7929\n",
      "[Adam | lr=0.1] Epoch 2642/4000: train_loss=0.2201  test_loss=74.2736  λ_max=28.1334\n",
      "[Adam | lr=0.1] Epoch 2643/4000: train_loss=0.2266  test_loss=74.5270  λ_max=27.4084\n",
      "[Adam | lr=0.1] Iter 42300: loss=0.2376\n",
      "[Adam | lr=0.1] Epoch 2644/4000: train_loss=0.2237  test_loss=74.9736  λ_max=28.0371\n",
      "[Adam | lr=0.1] Epoch 2645/4000: train_loss=0.2254  test_loss=74.7445  λ_max=30.6468\n",
      "[Adam | lr=0.1] Epoch 2646/4000: train_loss=0.2127  test_loss=75.0124  λ_max=26.0049\n",
      "[Adam | lr=0.1] Epoch 2647/4000: train_loss=0.1804  test_loss=75.1894  λ_max=25.9898\n",
      "[Adam | lr=0.1] Epoch 2648/4000: train_loss=0.1779  test_loss=75.9520  λ_max=26.1617\n",
      "[Adam | lr=0.1] Epoch 2649/4000: train_loss=0.1730  test_loss=76.5826  λ_max=25.4979\n",
      "[Adam | lr=0.1] Iter 42400: loss=0.2044\n",
      "[Adam | lr=0.1] Epoch 2650/4000: train_loss=0.1841  test_loss=77.3704  λ_max=24.1639\n",
      "[Adam | lr=0.1] Epoch 2651/4000: train_loss=0.1832  test_loss=77.6406  λ_max=25.8616\n",
      "[Adam | lr=0.1] Epoch 2652/4000: train_loss=0.1762  test_loss=77.5278  λ_max=20.9463\n",
      "[Adam | lr=0.1] Epoch 2653/4000: train_loss=0.1765  test_loss=78.0215  λ_max=23.4443\n",
      "[Adam | lr=0.1] Epoch 2654/4000: train_loss=0.1697  test_loss=78.0551  λ_max=21.0969\n",
      "[Adam | lr=0.1] Epoch 2655/4000: train_loss=0.1784  test_loss=78.3483  λ_max=21.8910\n",
      "[Adam | lr=0.1] Epoch 2656/4000: train_loss=0.1784  test_loss=79.2158  λ_max=21.1707\n",
      "[Adam | lr=0.1] Iter 42500: loss=0.1793\n",
      "[Adam | lr=0.1] Epoch 2657/4000: train_loss=0.1834  test_loss=79.5402  λ_max=21.2874\n",
      "[Adam | lr=0.1] Epoch 2658/4000: train_loss=0.1885  test_loss=79.2095  λ_max=18.6315\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Sudoku solver + Hessian-sharpness experiment.\n",
    "Runs for multiple optimizers (SGD, Adam, Muon) × multiple learning rates.\n",
    "Saves losses, sharpness values, and plots.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from datasets import load_dataset\n",
    "import pickle\n",
    "\n",
    "# ============================================================\n",
    "# Try to import Muon optimizer\n",
    "# ============================================================\n",
    "try:\n",
    "    from muon import MuonWithAuxAdam\n",
    "    MUON_AVAILABLE = True\n",
    "except ImportError:\n",
    "    MUON_AVAILABLE = False\n",
    "    print(\"Skipping Muon runs.\\n\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Dataset wrapper\n",
    "# ============================================================\n",
    "class SudokuHFDataset(Dataset):\n",
    "    def __init__(self, split=\"train\", max_size=None):\n",
    "        ds = load_dataset(\"sapientinc/sudoku-extreme\", split=split)\n",
    "        if max_size is not None:\n",
    "            ds = ds.select(range(min(max_size, len(ds))))\n",
    "        self.ds = ds\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        puzzle_str = self.ds[idx][\"question\"].replace(\".\", \"0\")\n",
    "        sol_str    = self.ds[idx][\"answer\"]\n",
    "\n",
    "        puzzle = np.array([int(c) for c in puzzle_str], dtype=np.int64)\n",
    "        sol    = np.array([int(c) for c in sol_str],    dtype=np.int64)\n",
    "\n",
    "        x = np.zeros((81, 10), dtype=np.float32)\n",
    "        for i, v in enumerate(puzzle):\n",
    "            x[i, v] = 1.0\n",
    "\n",
    "        x = x.reshape(810)\n",
    "        y = sol - 1\n",
    "        return x, y\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Model\n",
    "# ============================================================\n",
    "class SudokuNet(nn.Module):\n",
    "    def __init__(self, hidden_dim=512):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(810, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.LayerNorm(hidden_dim),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.LayerNorm(hidden_dim),\n",
    "            nn.Linear(hidden_dim, 729),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.net(x)\n",
    "        return out.view(-1, 81, 9)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Hessian sharpness (λ_max)\n",
    "# ============================================================\n",
    "def hessian_largest_eigval(model, loss_fn, x, y, device=\"cpu\", num_iters=10):\n",
    "    \"\"\"\n",
    "    Implementation of Hessian λ_max using power iteration.\n",
    "\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    x, y = x.to(device), y.to(device)\n",
    "\n",
    "    def grad_vec():\n",
    "        out = model(x)\n",
    "        loss = loss_fn(out.view(-1, 9), y.view(-1))\n",
    "        grads = torch.autograd.grad(loss, model.parameters(), create_graph=True)\n",
    "        return torch.cat([g.reshape(-1) for g in grads])\n",
    "\n",
    "    # Initial vector\n",
    "    v = torch.randn_like(grad_vec())\n",
    "    v /= (v.norm() + 1e-12)\n",
    "\n",
    "    # Power iteration\n",
    "    for _ in range(num_iters):\n",
    "        g  = grad_vec()\n",
    "        Hv = torch.autograd.grad(\n",
    "            g, model.parameters(), grad_outputs=v,\n",
    "            retain_graph=True, create_graph=True\n",
    "        )\n",
    "        Hv_vec = torch.cat([h.reshape(-1) for h in Hv])\n",
    "        v = Hv_vec / (Hv_vec.norm() + 1e-12)\n",
    "\n",
    "    # Rayleigh quotient\n",
    "    g  = grad_vec()\n",
    "    Hv = torch.autograd.grad(g, model.parameters(), grad_outputs=v)\n",
    "    Hv_vec = torch.cat([h.reshape(-1) for h in Hv])\n",
    "    return torch.dot(v, Hv_vec).item()\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Training loop for a single optimizer + lr\n",
    "# ============================================================\n",
    "def run_training(\n",
    "    optimizer_name,\n",
    "    model_constructor,\n",
    "    optimizer_constructor,\n",
    "    lr,\n",
    "    device,\n",
    "    epochs,\n",
    "    batch_size,\n",
    "    hidden_dim,\n",
    "    num_train,\n",
    "    num_test,\n",
    "    print_every,\n",
    "):\n",
    "    train_ds = SudokuHFDataset(\"train\", max_size=num_train)\n",
    "    test_ds  = SudokuHFDataset(\"test\",  max_size=num_test)\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "    test_loader  = DataLoader(test_ds,  batch_size=batch_size)\n",
    "\n",
    "    model    = model_constructor(hidden_dim=hidden_dim).to(device)\n",
    "    loss_fn  = nn.CrossEntropyLoss()\n",
    "    optimizer = optimizer_constructor(model.parameters(), lr=lr)\n",
    "\n",
    "    train_losses   = []\n",
    "    test_losses    = []\n",
    "    sharpness_vals = []\n",
    "\n",
    "    iteration = 0\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "\n",
    "        for x, y in train_loader:\n",
    "            iteration += 1\n",
    "            x, y = x.to(device), y.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            out  = model(x)\n",
    "            loss = loss_fn(out.view(-1, 9), y.view(-1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            if iteration % print_every == 0:\n",
    "                print(f\"[{optimizer_name} | lr={lr:.4g}] Iter {iteration}: loss={loss.item():.4f}\")\n",
    "\n",
    "        avg_train_loss = total_loss / len(train_loader)\n",
    "        train_losses.append(avg_train_loss)\n",
    "\n",
    "        # --- test loss ---\n",
    "        model.eval()\n",
    "        test_x, test_y = next(iter(test_loader))\n",
    "        test_x, test_y = test_x.to(device), test_y.to(device)\n",
    "        with torch.no_grad():\n",
    "            out_val   = model(test_x)\n",
    "            test_loss = loss_fn(out_val.view(-1, 9), test_y.view(-1)).item()\n",
    "        test_losses.append(test_loss)\n",
    "\n",
    "        # --- sharpness ---\n",
    "        eigval = hessian_largest_eigval(model, loss_fn, test_x, test_y, device=device)\n",
    "        sharpness_vals.append(eigval)\n",
    "\n",
    "        print(f\"[{optimizer_name} | lr={lr:.4g}] Epoch {epoch}/{epochs}: \"\n",
    "              f\"train_loss={avg_train_loss:.4f}  test_loss={test_loss:.4f}  λ_max={eigval:.4f}\")\n",
    "\n",
    "    return {\n",
    "        \"train_losses\":   train_losses,\n",
    "        \"test_losses\":    test_losses,\n",
    "        \"sharpness_vals\": sharpness_vals,\n",
    "    }\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Full experiment sweep across optimizers and LRs\n",
    "# ============================================================\n",
    "def main_sweep(\n",
    "    *,\n",
    "    device,\n",
    "    epochs,\n",
    "    batch_size,\n",
    "    hidden_dim,\n",
    "    num_train,\n",
    "    num_test,\n",
    "    print_every,\n",
    "    lrs,\n",
    "    seed=0,\n",
    "):\n",
    "    # ----------------------------\n",
    "    # Set random seed for reproducibility\n",
    "    # ----------------------------\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    os.makedirs(\"results\", exist_ok=True)\n",
    "    results_all = {}\n",
    "\n",
    "    # --- optimizer constructors ---\n",
    "    optimizers = {\n",
    "        \"SGD\":  lambda params, lr: optim.SGD(params, lr=lr),\n",
    "        \"Adam\": lambda params, lr: optim.Adam(params, lr=lr),\n",
    "    }\n",
    "\n",
    "    if MUON_AVAILABLE:\n",
    "        def make_muon(params, lr):\n",
    "            hidden_weights = [p for p in params if p.ndim >= 2]\n",
    "            other_params   = [p for p in params if p.ndim < 2]\n",
    "            param_groups = [\n",
    "                {\"params\": hidden_weights, \"use_muon\": True, \"lr\": lr},\n",
    "                {\"params\": other_params,   \"use_muon\": False, \"lr\": lr / 10.0},\n",
    "            ]\n",
    "            return MuonWithAuxAdam(param_groups)\n",
    "        optimizers[\"Muon\"] = make_muon\n",
    "\n",
    "    # ----------------------------\n",
    "    # Run sweeps\n",
    "    # ----------------------------\n",
    "    for opt_name, opt_fn in optimizers.items():\n",
    "        results_all[opt_name] = {}\n",
    "        plt.figure(figsize=(10, 6))\n",
    "\n",
    "        for lr in lrs:\n",
    "            print(f\"\\n### Running {opt_name} with lr={lr:.4g}\")\n",
    "\n",
    "            result = run_training(\n",
    "                optimizer_name       = opt_name,\n",
    "                model_constructor    = SudokuNet,\n",
    "                optimizer_constructor=lambda p, lr=lr: opt_fn(p, lr),\n",
    "                lr=lr,\n",
    "                device=device,\n",
    "                epochs=epochs,\n",
    "                batch_size=batch_size,\n",
    "                hidden_dim=hidden_dim,\n",
    "                num_train=num_train,\n",
    "                num_test=num_test,\n",
    "                print_every=print_every,\n",
    "            )\n",
    "\n",
    "            results_all[opt_name][lr] = result\n",
    "\n",
    "            # Save raw data\n",
    "            fname = f\"results/{opt_name}_lr{lr:.4g}.npz\"\n",
    "            np.savez(\n",
    "                fname,\n",
    "                train_losses=np.array(result[\"train_losses\"]),\n",
    "                test_losses=np.array(result[\"test_losses\"]),\n",
    "                sharpness_vals=np.array(result[\"sharpness_vals\"]),\n",
    "            )\n",
    "            print(f\"Saved data → {fname}\")\n",
    "\n",
    "            # Individual sharpness plot\n",
    "            plt_ind = plt.figure(figsize=(8, 4))\n",
    "            plt.plot(range(1, len(result[\"sharpness_vals\"]) + 1),\n",
    "                     result[\"sharpness_vals\"], marker='o')\n",
    "            plt.title(f\"{opt_name} – lr={lr:.4g} – Hessian Sharpness\")\n",
    "            plt.xlabel(\"Epoch\")\n",
    "            plt.ylabel(\"λₘₐₓ\")\n",
    "            plt.grid(True)\n",
    "            plt.tight_layout()\n",
    "            plot_fname = f\"results/{opt_name}_lr{lr:.4g}_sharpness.png\"\n",
    "            plt.savefig(plot_fname)\n",
    "            plt.close(plt_ind)\n",
    "            print(f\"Saved plot → {plot_fname}\")\n",
    "\n",
    "            # Add to combined plot\n",
    "            plt.plot(range(1, len(result[\"sharpness_vals\"]) + 1),\n",
    "                     result[\"sharpness_vals\"],\n",
    "                     lw=2, label=f\"lr={lr:g}\")\n",
    "\n",
    "        # Combined optimizer-specific plot\n",
    "        plt.title(f\"Hessian Sharpness vs Epochs – {opt_name}\")\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"λₘₐₓ\")\n",
    "        plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        combined_path = f\"results/{opt_name}_combined_sharpness.png\"\n",
    "        plt.savefig(combined_path)\n",
    "        plt.close()\n",
    "        print(f\"Saved combined plot → {combined_path}\")\n",
    "\n",
    "    # Save everything\n",
    "    with open(\"results/all_results.pkl\", \"wb\") as f:\n",
    "        pickle.dump(results_all, f)\n",
    "\n",
    "    print(\"Saved full results dictionary to results/all_results.pkl\")\n",
    "\n",
    "    return results_all\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Entry point\n",
    "# ============================================================\n",
    "if __name__ == \"__main__\":\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    sweep_results = main_sweep(\n",
    "        device=device,\n",
    "        epochs=4000,\n",
    "        batch_size=128,\n",
    "        hidden_dim=512,\n",
    "        num_train=2000,\n",
    "        num_test=500,\n",
    "        print_every=100,\n",
    "        lrs=[1e-1, 5e-2, 1e-2, 1e-3],\n",
    "        seed=42,   \n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6636717-f796-46f0-80d6-e2422211b756",
   "metadata": {},
   "source": [
    "# Fixed Muon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7973d59f-35b7-4ae9-a443-67706314d536",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Patched torch.distributed for single-process Muon execution.\n",
      "Using device: cpu\n",
      "\n",
      "🔹 Running Muon with lr=0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (/home/aradilla/.cache/huggingface/datasets/sapientinc___csv/sapientinc--sudoku-extreme-798989c95bd556dd/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n",
      "Found cached dataset csv (/home/aradilla/.cache/huggingface/datasets/sapientinc___csv/sapientinc--sudoku-extreme-798989c95bd556dd/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Muon | lr=0.1] Epoch 1/4000: train_loss=2.2032  test_loss=2.1538  λ_max=2.5824\n",
      "[Muon | lr=0.1] Epoch 2/4000: train_loss=1.7708  test_loss=2.1370  λ_max=3.6472\n",
      "[Muon | lr=0.1] Epoch 3/4000: train_loss=1.2221  test_loss=2.4876  λ_max=2.7793\n",
      "[Muon | lr=0.1] Epoch 4/4000: train_loss=0.7887  test_loss=2.9310  λ_max=2.1912\n",
      "[Muon | lr=0.1] Epoch 5/4000: train_loss=0.4929  test_loss=3.4553  λ_max=1.9937\n",
      "[Muon | lr=0.1] Epoch 6/4000: train_loss=0.3360  test_loss=4.0215  λ_max=1.7545\n",
      "[Muon | lr=0.1] Iter 100: loss=0.1611\n",
      "[Muon | lr=0.1] Epoch 7/4000: train_loss=0.2691  test_loss=4.4746  λ_max=1.7505\n",
      "[Muon | lr=0.1] Epoch 8/4000: train_loss=0.2324  test_loss=4.8543  λ_max=1.5398\n",
      "[Muon | lr=0.1] Epoch 9/4000: train_loss=0.2046  test_loss=5.1592  λ_max=1.5972\n",
      "[Muon | lr=0.1] Epoch 10/4000: train_loss=0.1849  test_loss=5.5142  λ_max=1.4183\n",
      "[Muon | lr=0.1] Epoch 11/4000: train_loss=0.1675  test_loss=5.7637  λ_max=1.3610\n",
      "[Muon | lr=0.1] Epoch 12/4000: train_loss=0.1515  test_loss=6.0106  λ_max=1.3108\n",
      "[Muon | lr=0.1] Iter 200: loss=0.1321\n",
      "[Muon | lr=0.1] Epoch 13/4000: train_loss=0.1411  test_loss=6.2108  λ_max=1.2770\n",
      "[Muon | lr=0.1] Epoch 14/4000: train_loss=0.1260  test_loss=6.4364  λ_max=1.2255\n",
      "[Muon | lr=0.1] Epoch 15/4000: train_loss=0.1162  test_loss=6.6068  λ_max=1.2333\n",
      "[Muon | lr=0.1] Epoch 16/4000: train_loss=0.1061  test_loss=6.8062  λ_max=1.1927\n",
      "[Muon | lr=0.1] Epoch 17/4000: train_loss=0.1016  test_loss=7.0288  λ_max=1.1526\n",
      "[Muon | lr=0.1] Epoch 18/4000: train_loss=0.0938  test_loss=7.2510  λ_max=1.1630\n",
      "[Muon | lr=0.1] Iter 300: loss=0.1183\n",
      "[Muon | lr=0.1] Epoch 19/4000: train_loss=0.0904  test_loss=7.4459  λ_max=1.1104\n",
      "[Muon | lr=0.1] Epoch 20/4000: train_loss=0.0823  test_loss=7.5656  λ_max=1.1468\n",
      "[Muon | lr=0.1] Epoch 21/4000: train_loss=0.0784  test_loss=7.7571  λ_max=1.0458\n",
      "[Muon | lr=0.1] Epoch 22/4000: train_loss=0.0749  test_loss=7.8685  λ_max=1.0862\n",
      "[Muon | lr=0.1] Epoch 23/4000: train_loss=0.0724  test_loss=8.0438  λ_max=1.0677\n",
      "[Muon | lr=0.1] Epoch 24/4000: train_loss=0.0694  test_loss=8.1625  λ_max=0.9982\n",
      "[Muon | lr=0.1] Iter 400: loss=0.1073\n",
      "[Muon | lr=0.1] Epoch 25/4000: train_loss=0.0645  test_loss=8.3334  λ_max=1.0739\n",
      "[Muon | lr=0.1] Epoch 26/4000: train_loss=0.0642  test_loss=8.4812  λ_max=0.9826\n",
      "[Muon | lr=0.1] Epoch 27/4000: train_loss=0.0618  test_loss=8.6196  λ_max=0.9972\n",
      "[Muon | lr=0.1] Epoch 28/4000: train_loss=0.0605  test_loss=8.8226  λ_max=1.0123\n",
      "[Muon | lr=0.1] Epoch 29/4000: train_loss=0.0579  test_loss=8.9209  λ_max=0.9914\n",
      "[Muon | lr=0.1] Epoch 30/4000: train_loss=0.0556  test_loss=9.0858  λ_max=0.9756\n",
      "[Muon | lr=0.1] Epoch 31/4000: train_loss=0.0547  test_loss=9.1806  λ_max=0.9964\n",
      "[Muon | lr=0.1] Iter 500: loss=0.0338\n",
      "[Muon | lr=0.1] Epoch 32/4000: train_loss=0.0518  test_loss=9.3546  λ_max=1.0230\n",
      "[Muon | lr=0.1] Epoch 33/4000: train_loss=0.0504  test_loss=9.5433  λ_max=0.9747\n",
      "[Muon | lr=0.1] Epoch 34/4000: train_loss=0.0490  test_loss=9.7085  λ_max=0.9407\n",
      "[Muon | lr=0.1] Epoch 35/4000: train_loss=0.0477  test_loss=9.8580  λ_max=0.9564\n",
      "[Muon | lr=0.1] Epoch 36/4000: train_loss=0.0453  test_loss=10.0475  λ_max=0.9099\n",
      "[Muon | lr=0.1] Epoch 37/4000: train_loss=0.0440  test_loss=10.1480  λ_max=0.9376\n",
      "[Muon | lr=0.1] Iter 600: loss=0.0407\n",
      "[Muon | lr=0.1] Epoch 38/4000: train_loss=0.0440  test_loss=10.2490  λ_max=0.9238\n",
      "[Muon | lr=0.1] Epoch 39/4000: train_loss=0.0425  test_loss=10.3412  λ_max=0.9865\n",
      "[Muon | lr=0.1] Epoch 40/4000: train_loss=0.0395  test_loss=10.4596  λ_max=0.9181\n",
      "[Muon | lr=0.1] Epoch 41/4000: train_loss=0.0404  test_loss=10.5857  λ_max=0.8751\n",
      "[Muon | lr=0.1] Epoch 42/4000: train_loss=0.0397  test_loss=10.6449  λ_max=0.9456\n",
      "[Muon | lr=0.1] Epoch 43/4000: train_loss=0.0389  test_loss=10.7249  λ_max=0.9676\n",
      "[Muon | lr=0.1] Iter 700: loss=0.0486\n",
      "[Muon | lr=0.1] Epoch 44/4000: train_loss=0.0366  test_loss=10.8523  λ_max=0.9025\n",
      "[Muon | lr=0.1] Epoch 45/4000: train_loss=0.0360  test_loss=11.0178  λ_max=0.8996\n",
      "[Muon | lr=0.1] Epoch 46/4000: train_loss=0.0359  test_loss=11.0820  λ_max=0.8996\n",
      "[Muon | lr=0.1] Epoch 47/4000: train_loss=0.0354  test_loss=11.1602  λ_max=0.9791\n",
      "[Muon | lr=0.1] Epoch 48/4000: train_loss=0.0346  test_loss=11.3581  λ_max=0.9304\n",
      "[Muon | lr=0.1] Epoch 49/4000: train_loss=0.0328  test_loss=11.4263  λ_max=0.9459\n",
      "[Muon | lr=0.1] Iter 800: loss=0.0672\n",
      "[Muon | lr=0.1] Epoch 50/4000: train_loss=0.0353  test_loss=11.6363  λ_max=0.9397\n",
      "[Muon | lr=0.1] Epoch 51/4000: train_loss=0.0320  test_loss=11.6651  λ_max=0.8923\n",
      "[Muon | lr=0.1] Epoch 52/4000: train_loss=0.0324  test_loss=11.7408  λ_max=0.9157\n",
      "[Muon | lr=0.1] Epoch 53/4000: train_loss=0.0308  test_loss=11.8548  λ_max=0.9295\n",
      "[Muon | lr=0.1] Epoch 54/4000: train_loss=0.0309  test_loss=11.9359  λ_max=0.9376\n",
      "[Muon | lr=0.1] Epoch 55/4000: train_loss=0.0299  test_loss=12.1168  λ_max=0.9326\n",
      "[Muon | lr=0.1] Epoch 56/4000: train_loss=0.0295  test_loss=12.1418  λ_max=0.9255\n",
      "[Muon | lr=0.1] Iter 900: loss=0.0157\n",
      "[Muon | lr=0.1] Epoch 57/4000: train_loss=0.0294  test_loss=12.2813  λ_max=0.8956\n",
      "[Muon | lr=0.1] Epoch 58/4000: train_loss=0.0290  test_loss=12.3820  λ_max=0.9399\n",
      "[Muon | lr=0.1] Epoch 59/4000: train_loss=0.0275  test_loss=12.4546  λ_max=0.9271\n",
      "[Muon | lr=0.1] Epoch 60/4000: train_loss=0.0282  test_loss=12.5349  λ_max=0.8824\n",
      "[Muon | lr=0.1] Epoch 61/4000: train_loss=0.0281  test_loss=12.5906  λ_max=0.9137\n",
      "[Muon | lr=0.1] Epoch 62/4000: train_loss=0.0268  test_loss=12.6802  λ_max=0.9131\n",
      "[Muon | lr=0.1] Iter 1000: loss=0.0258\n",
      "[Muon | lr=0.1] Epoch 63/4000: train_loss=0.0276  test_loss=12.7408  λ_max=0.9106\n",
      "[Muon | lr=0.1] Epoch 64/4000: train_loss=0.0259  test_loss=12.8695  λ_max=0.8852\n",
      "[Muon | lr=0.1] Epoch 65/4000: train_loss=0.0256  test_loss=12.8888  λ_max=0.8693\n",
      "[Muon | lr=0.1] Epoch 66/4000: train_loss=0.0262  test_loss=12.9586  λ_max=0.9537\n",
      "[Muon | lr=0.1] Epoch 67/4000: train_loss=0.0241  test_loss=13.0790  λ_max=0.8968\n",
      "[Muon | lr=0.1] Epoch 68/4000: train_loss=0.0251  test_loss=13.2294  λ_max=0.8915\n",
      "[Muon | lr=0.1] Iter 1100: loss=0.0300\n",
      "[Muon | lr=0.1] Epoch 69/4000: train_loss=0.0256  test_loss=13.2756  λ_max=0.9119\n",
      "[Muon | lr=0.1] Epoch 70/4000: train_loss=0.0246  test_loss=13.3596  λ_max=0.9207\n",
      "[Muon | lr=0.1] Epoch 71/4000: train_loss=0.0241  test_loss=13.4550  λ_max=0.9068\n",
      "[Muon | lr=0.1] Epoch 72/4000: train_loss=0.0238  test_loss=13.5470  λ_max=0.9506\n",
      "[Muon | lr=0.1] Epoch 73/4000: train_loss=0.0234  test_loss=13.6710  λ_max=0.8964\n",
      "[Muon | lr=0.1] Epoch 74/4000: train_loss=0.0239  test_loss=13.7618  λ_max=0.9092\n",
      "[Muon | lr=0.1] Iter 1200: loss=0.0401\n",
      "[Muon | lr=0.1] Epoch 75/4000: train_loss=0.0228  test_loss=13.8138  λ_max=0.8467\n",
      "[Muon | lr=0.1] Epoch 76/4000: train_loss=0.0231  test_loss=13.9107  λ_max=0.9348\n",
      "[Muon | lr=0.1] Epoch 77/4000: train_loss=0.0215  test_loss=13.9895  λ_max=0.9241\n",
      "[Muon | lr=0.1] Epoch 78/4000: train_loss=0.0223  test_loss=14.0311  λ_max=0.9561\n",
      "[Muon | lr=0.1] Epoch 79/4000: train_loss=0.0218  test_loss=14.1164  λ_max=0.9263\n",
      "[Muon | lr=0.1] Epoch 80/4000: train_loss=0.0222  test_loss=14.2179  λ_max=0.8844\n",
      "[Muon | lr=0.1] Epoch 81/4000: train_loss=0.0208  test_loss=14.3597  λ_max=0.8808\n",
      "[Muon | lr=0.1] Iter 1300: loss=0.0143\n",
      "[Muon | lr=0.1] Epoch 82/4000: train_loss=0.0201  test_loss=14.4112  λ_max=0.9283\n",
      "[Muon | lr=0.1] Epoch 83/4000: train_loss=0.0210  test_loss=14.4600  λ_max=0.9853\n",
      "[Muon | lr=0.1] Epoch 84/4000: train_loss=0.0205  test_loss=14.5830  λ_max=0.8876\n",
      "[Muon | lr=0.1] Epoch 85/4000: train_loss=0.0213  test_loss=14.6809  λ_max=0.9219\n",
      "[Muon | lr=0.1] Epoch 86/4000: train_loss=0.0202  test_loss=14.8198  λ_max=0.8489\n",
      "[Muon | lr=0.1] Epoch 87/4000: train_loss=0.0199  test_loss=14.8939  λ_max=0.9274\n",
      "[Muon | lr=0.1] Iter 1400: loss=0.0235\n",
      "[Muon | lr=0.1] Epoch 88/4000: train_loss=0.0194  test_loss=15.0290  λ_max=0.9209\n",
      "[Muon | lr=0.1] Epoch 89/4000: train_loss=0.0208  test_loss=15.0563  λ_max=0.8713\n",
      "[Muon | lr=0.1] Epoch 90/4000: train_loss=0.0190  test_loss=15.1181  λ_max=0.8913\n",
      "[Muon | lr=0.1] Epoch 91/4000: train_loss=0.0202  test_loss=15.1545  λ_max=0.9002\n",
      "[Muon | lr=0.1] Epoch 92/4000: train_loss=0.0187  test_loss=15.2157  λ_max=0.9191\n",
      "[Muon | lr=0.1] Epoch 93/4000: train_loss=0.0202  test_loss=15.3283  λ_max=0.9146\n",
      "[Muon | lr=0.1] Iter 1500: loss=0.0252\n",
      "[Muon | lr=0.1] Epoch 94/4000: train_loss=0.0188  test_loss=15.3594  λ_max=0.8890\n",
      "[Muon | lr=0.1] Epoch 95/4000: train_loss=0.0189  test_loss=15.4743  λ_max=0.8917\n",
      "[Muon | lr=0.1] Epoch 96/4000: train_loss=0.0184  test_loss=15.5057  λ_max=0.9043\n",
      "[Muon | lr=0.1] Epoch 97/4000: train_loss=0.0184  test_loss=15.5682  λ_max=0.8966\n",
      "[Muon | lr=0.1] Epoch 98/4000: train_loss=0.0184  test_loss=15.6955  λ_max=0.9156\n",
      "[Muon | lr=0.1] Epoch 99/4000: train_loss=0.0176  test_loss=15.7022  λ_max=0.9603\n",
      "[Muon | lr=0.1] Iter 1600: loss=0.0314\n",
      "[Muon | lr=0.1] Epoch 100/4000: train_loss=0.0178  test_loss=15.8321  λ_max=0.9314\n",
      "[Muon | lr=0.1] Epoch 101/4000: train_loss=0.0173  test_loss=15.9828  λ_max=0.9351\n",
      "[Muon | lr=0.1] Epoch 102/4000: train_loss=0.0177  test_loss=16.1169  λ_max=0.9756\n",
      "[Muon | lr=0.1] Epoch 103/4000: train_loss=0.0175  test_loss=16.1131  λ_max=0.9740\n",
      "[Muon | lr=0.1] Epoch 104/4000: train_loss=0.0180  test_loss=16.1581  λ_max=0.9176\n",
      "[Muon | lr=0.1] Epoch 105/4000: train_loss=0.0178  test_loss=16.1897  λ_max=0.9382\n",
      "[Muon | lr=0.1] Epoch 106/4000: train_loss=0.0181  test_loss=16.2367  λ_max=0.9804\n",
      "[Muon | lr=0.1] Iter 1700: loss=0.0110\n",
      "[Muon | lr=0.1] Epoch 107/4000: train_loss=0.0172  test_loss=16.3454  λ_max=0.9239\n",
      "[Muon | lr=0.1] Epoch 108/4000: train_loss=0.0161  test_loss=16.4271  λ_max=0.9399\n",
      "[Muon | lr=0.1] Epoch 109/4000: train_loss=0.0162  test_loss=16.5427  λ_max=0.9910\n",
      "[Muon | lr=0.1] Epoch 110/4000: train_loss=0.0163  test_loss=16.5946  λ_max=0.9303\n",
      "[Muon | lr=0.1] Epoch 111/4000: train_loss=0.0163  test_loss=16.7038  λ_max=0.9367\n",
      "[Muon | lr=0.1] Epoch 112/4000: train_loss=0.0158  test_loss=16.6891  λ_max=0.9463\n",
      "[Muon | lr=0.1] Iter 1800: loss=0.0159\n",
      "[Muon | lr=0.1] Epoch 113/4000: train_loss=0.0166  test_loss=16.7995  λ_max=0.9790\n",
      "[Muon | lr=0.1] Epoch 114/4000: train_loss=0.0151  test_loss=16.8610  λ_max=1.0204\n",
      "[Muon | lr=0.1] Epoch 115/4000: train_loss=0.0168  test_loss=16.9720  λ_max=0.9712\n",
      "[Muon | lr=0.1] Epoch 116/4000: train_loss=0.0161  test_loss=17.0250  λ_max=0.9073\n",
      "[Muon | lr=0.1] Epoch 117/4000: train_loss=0.0158  test_loss=17.1063  λ_max=1.0509\n",
      "[Muon | lr=0.1] Epoch 118/4000: train_loss=0.0151  test_loss=17.1841  λ_max=0.9404\n",
      "[Muon | lr=0.1] Iter 1900: loss=0.0189\n",
      "[Muon | lr=0.1] Epoch 119/4000: train_loss=0.0154  test_loss=17.2634  λ_max=0.9838\n",
      "[Muon | lr=0.1] Epoch 120/4000: train_loss=0.0150  test_loss=17.3933  λ_max=0.9530\n",
      "[Muon | lr=0.1] Epoch 121/4000: train_loss=0.0156  test_loss=17.4949  λ_max=0.9449\n",
      "[Muon | lr=0.1] Epoch 122/4000: train_loss=0.0157  test_loss=17.5265  λ_max=0.9469\n",
      "[Muon | lr=0.1] Epoch 123/4000: train_loss=0.0161  test_loss=17.5211  λ_max=0.9938\n",
      "[Muon | lr=0.1] Epoch 124/4000: train_loss=0.0146  test_loss=17.5884  λ_max=0.9664\n",
      "[Muon | lr=0.1] Iter 2000: loss=0.0254\n",
      "[Muon | lr=0.1] Epoch 125/4000: train_loss=0.0146  test_loss=17.6448  λ_max=1.0081\n",
      "[Muon | lr=0.1] Epoch 126/4000: train_loss=0.0146  test_loss=17.8181  λ_max=1.0011\n",
      "[Muon | lr=0.1] Epoch 127/4000: train_loss=0.0144  test_loss=17.8732  λ_max=0.9955\n",
      "[Muon | lr=0.1] Epoch 128/4000: train_loss=0.0154  test_loss=17.7929  λ_max=1.0144\n",
      "[Muon | lr=0.1] Epoch 129/4000: train_loss=0.0146  test_loss=17.9187  λ_max=0.9792\n",
      "[Muon | lr=0.1] Epoch 130/4000: train_loss=0.0144  test_loss=17.9868  λ_max=1.0170\n",
      "[Muon | lr=0.1] Epoch 131/4000: train_loss=0.0148  test_loss=18.0597  λ_max=0.9950\n",
      "[Muon | lr=0.1] Iter 2100: loss=0.0117\n",
      "[Muon | lr=0.1] Epoch 132/4000: train_loss=0.0145  test_loss=18.1096  λ_max=0.9411\n",
      "[Muon | lr=0.1] Epoch 133/4000: train_loss=0.0149  test_loss=18.1942  λ_max=0.9972\n",
      "[Muon | lr=0.1] Epoch 134/4000: train_loss=0.0136  test_loss=18.2832  λ_max=1.0041\n",
      "[Muon | lr=0.1] Epoch 135/4000: train_loss=0.0138  test_loss=18.3944  λ_max=0.9972\n",
      "[Muon | lr=0.1] Epoch 136/4000: train_loss=0.0131  test_loss=18.5262  λ_max=1.0556\n",
      "[Muon | lr=0.1] Epoch 137/4000: train_loss=0.0136  test_loss=18.7214  λ_max=1.0284\n",
      "[Muon | lr=0.1] Iter 2200: loss=0.0132\n",
      "[Muon | lr=0.1] Epoch 138/4000: train_loss=0.0132  test_loss=18.8361  λ_max=0.9480\n",
      "[Muon | lr=0.1] Epoch 139/4000: train_loss=0.0133  test_loss=18.9148  λ_max=1.0237\n",
      "[Muon | lr=0.1] Epoch 140/4000: train_loss=0.0135  test_loss=19.0443  λ_max=0.9861\n",
      "[Muon | lr=0.1] Epoch 141/4000: train_loss=0.0142  test_loss=19.1300  λ_max=0.9406\n",
      "[Muon | lr=0.1] Epoch 142/4000: train_loss=0.0137  test_loss=19.2387  λ_max=1.0090\n",
      "[Muon | lr=0.1] Epoch 143/4000: train_loss=0.0128  test_loss=19.3162  λ_max=0.9581\n",
      "[Muon | lr=0.1] Iter 2300: loss=0.0128\n",
      "[Muon | lr=0.1] Epoch 144/4000: train_loss=0.0117  test_loss=19.3552  λ_max=1.0065\n",
      "[Muon | lr=0.1] Epoch 145/4000: train_loss=0.0133  test_loss=19.3722  λ_max=0.9997\n",
      "[Muon | lr=0.1] Epoch 146/4000: train_loss=0.0129  test_loss=19.3521  λ_max=1.0717\n",
      "[Muon | lr=0.1] Epoch 147/4000: train_loss=0.0133  test_loss=19.4347  λ_max=0.9697\n",
      "[Muon | lr=0.1] Epoch 148/4000: train_loss=0.0136  test_loss=19.5004  λ_max=0.9953\n",
      "[Muon | lr=0.1] Epoch 149/4000: train_loss=0.0133  test_loss=19.5563  λ_max=1.0172\n",
      "[Muon | lr=0.1] Iter 2400: loss=0.0188\n",
      "[Muon | lr=0.1] Epoch 150/4000: train_loss=0.0125  test_loss=19.6496  λ_max=1.0348\n",
      "[Muon | lr=0.1] Epoch 151/4000: train_loss=0.0120  test_loss=19.7247  λ_max=1.0336\n",
      "[Muon | lr=0.1] Epoch 152/4000: train_loss=0.0136  test_loss=19.7331  λ_max=1.0305\n",
      "[Muon | lr=0.1] Epoch 153/4000: train_loss=0.0129  test_loss=19.8540  λ_max=0.9508\n",
      "[Muon | lr=0.1] Epoch 154/4000: train_loss=0.0127  test_loss=19.9603  λ_max=0.9853\n",
      "[Muon | lr=0.1] Epoch 155/4000: train_loss=0.0123  test_loss=20.0674  λ_max=1.0039\n",
      "[Muon | lr=0.1] Epoch 156/4000: train_loss=0.0131  test_loss=20.1213  λ_max=1.0696\n",
      "[Muon | lr=0.1] Iter 2500: loss=0.0062\n",
      "[Muon | lr=0.1] Epoch 157/4000: train_loss=0.0129  test_loss=20.2915  λ_max=1.0346\n",
      "[Muon | lr=0.1] Epoch 158/4000: train_loss=0.0128  test_loss=20.3546  λ_max=1.0461\n",
      "[Muon | lr=0.1] Epoch 159/4000: train_loss=0.0128  test_loss=20.4331  λ_max=1.0015\n",
      "[Muon | lr=0.1] Epoch 160/4000: train_loss=0.0119  test_loss=20.4592  λ_max=1.0073\n",
      "[Muon | lr=0.1] Epoch 161/4000: train_loss=0.0125  test_loss=20.4842  λ_max=1.0679\n",
      "[Muon | lr=0.1] Epoch 162/4000: train_loss=0.0130  test_loss=20.5362  λ_max=1.0936\n",
      "[Muon | lr=0.1] Iter 2600: loss=0.0123\n",
      "[Muon | lr=0.1] Epoch 163/4000: train_loss=0.0120  test_loss=20.4989  λ_max=1.0664\n",
      "[Muon | lr=0.1] Epoch 164/4000: train_loss=0.0126  test_loss=20.5751  λ_max=1.0484\n",
      "[Muon | lr=0.1] Epoch 165/4000: train_loss=0.0121  test_loss=20.6499  λ_max=1.0123\n",
      "[Muon | lr=0.1] Epoch 166/4000: train_loss=0.0121  test_loss=20.7305  λ_max=1.0306\n",
      "[Muon | lr=0.1] Epoch 167/4000: train_loss=0.0131  test_loss=20.7959  λ_max=1.0222\n",
      "[Muon | lr=0.1] Epoch 168/4000: train_loss=0.0118  test_loss=20.8561  λ_max=1.1068\n",
      "[Muon | lr=0.1] Iter 2700: loss=0.0192\n",
      "[Muon | lr=0.1] Epoch 169/4000: train_loss=0.0123  test_loss=20.8542  λ_max=1.0305\n",
      "[Muon | lr=0.1] Epoch 170/4000: train_loss=0.0112  test_loss=20.9488  λ_max=1.0395\n",
      "[Muon | lr=0.1] Epoch 171/4000: train_loss=0.0120  test_loss=21.0137  λ_max=1.0577\n",
      "[Muon | lr=0.1] Epoch 172/4000: train_loss=0.0117  test_loss=21.1940  λ_max=0.9884\n",
      "[Muon | lr=0.1] Epoch 173/4000: train_loss=0.0120  test_loss=21.2792  λ_max=1.0337\n",
      "[Muon | lr=0.1] Epoch 174/4000: train_loss=0.0120  test_loss=21.4311  λ_max=1.0551\n",
      "[Muon | lr=0.1] Iter 2800: loss=0.0129\n",
      "[Muon | lr=0.1] Epoch 175/4000: train_loss=0.0118  test_loss=21.4796  λ_max=1.0297\n",
      "[Muon | lr=0.1] Epoch 176/4000: train_loss=0.0115  test_loss=21.5761  λ_max=0.9829\n",
      "[Muon | lr=0.1] Epoch 177/4000: train_loss=0.0114  test_loss=21.6154  λ_max=1.0265\n",
      "[Muon | lr=0.1] Epoch 178/4000: train_loss=0.0123  test_loss=21.6447  λ_max=1.0336\n",
      "[Muon | lr=0.1] Epoch 179/4000: train_loss=0.0114  test_loss=21.7133  λ_max=1.0425\n",
      "[Muon | lr=0.1] Epoch 180/4000: train_loss=0.0117  test_loss=21.8108  λ_max=1.0728\n",
      "[Muon | lr=0.1] Epoch 181/4000: train_loss=0.0111  test_loss=21.8213  λ_max=1.1105\n",
      "[Muon | lr=0.1] Iter 2900: loss=0.0082\n",
      "[Muon | lr=0.1] Epoch 182/4000: train_loss=0.0117  test_loss=21.9125  λ_max=1.0017\n",
      "[Muon | lr=0.1] Epoch 183/4000: train_loss=0.0117  test_loss=21.9571  λ_max=1.0897\n",
      "[Muon | lr=0.1] Epoch 184/4000: train_loss=0.0121  test_loss=21.9614  λ_max=1.0734\n",
      "[Muon | lr=0.1] Epoch 185/4000: train_loss=0.0118  test_loss=22.0610  λ_max=1.0340\n",
      "[Muon | lr=0.1] Epoch 186/4000: train_loss=0.0108  test_loss=22.2308  λ_max=1.0765\n",
      "[Muon | lr=0.1] Epoch 187/4000: train_loss=0.0107  test_loss=22.3504  λ_max=1.0932\n",
      "[Muon | lr=0.1] Iter 3000: loss=0.0127\n",
      "[Muon | lr=0.1] Epoch 188/4000: train_loss=0.0119  test_loss=22.4481  λ_max=1.0946\n",
      "[Muon | lr=0.1] Epoch 189/4000: train_loss=0.0107  test_loss=22.5191  λ_max=1.0900\n",
      "[Muon | lr=0.1] Epoch 190/4000: train_loss=0.0117  test_loss=22.5084  λ_max=1.1379\n",
      "[Muon | lr=0.1] Epoch 191/4000: train_loss=0.0115  test_loss=22.5938  λ_max=1.0696\n",
      "[Muon | lr=0.1] Epoch 192/4000: train_loss=0.0117  test_loss=22.6507  λ_max=1.0422\n",
      "[Muon | lr=0.1] Epoch 193/4000: train_loss=0.0114  test_loss=22.6689  λ_max=1.0578\n",
      "[Muon | lr=0.1] Iter 3100: loss=0.0121\n",
      "[Muon | lr=0.1] Epoch 194/4000: train_loss=0.0107  test_loss=22.8011  λ_max=1.1346\n",
      "[Muon | lr=0.1] Epoch 195/4000: train_loss=0.0110  test_loss=22.8104  λ_max=1.1033\n",
      "[Muon | lr=0.1] Epoch 196/4000: train_loss=0.0116  test_loss=22.8745  λ_max=1.0666\n",
      "[Muon | lr=0.1] Epoch 197/4000: train_loss=0.0114  test_loss=22.9355  λ_max=1.1540\n",
      "[Muon | lr=0.1] Epoch 198/4000: train_loss=0.0115  test_loss=22.9587  λ_max=1.1147\n",
      "[Muon | lr=0.1] Epoch 199/4000: train_loss=0.0100  test_loss=23.1082  λ_max=1.0575\n",
      "[Muon | lr=0.1] Iter 3200: loss=0.0165\n",
      "[Muon | lr=0.1] Epoch 200/4000: train_loss=0.0107  test_loss=23.1434  λ_max=1.1520\n",
      "[Muon | lr=0.1] Epoch 201/4000: train_loss=0.0110  test_loss=23.3428  λ_max=1.0645\n",
      "[Muon | lr=0.1] Epoch 202/4000: train_loss=0.0115  test_loss=23.3758  λ_max=1.1609\n",
      "[Muon | lr=0.1] Epoch 203/4000: train_loss=0.0105  test_loss=23.3989  λ_max=1.1036\n",
      "[Muon | lr=0.1] Epoch 204/4000: train_loss=0.0116  test_loss=23.5311  λ_max=1.0637\n",
      "[Muon | lr=0.1] Epoch 205/4000: train_loss=0.0109  test_loss=23.5027  λ_max=1.1053\n",
      "[Muon | lr=0.1] Epoch 206/4000: train_loss=0.0106  test_loss=23.5714  λ_max=1.1488\n",
      "[Muon | lr=0.1] Iter 3300: loss=0.0056\n",
      "[Muon | lr=0.1] Epoch 207/4000: train_loss=0.0106  test_loss=23.5842  λ_max=1.1233\n",
      "[Muon | lr=0.1] Epoch 208/4000: train_loss=0.0106  test_loss=23.7586  λ_max=1.0178\n",
      "[Muon | lr=0.1] Epoch 209/4000: train_loss=0.0106  test_loss=23.7952  λ_max=1.0958\n",
      "[Muon | lr=0.1] Epoch 210/4000: train_loss=0.0105  test_loss=23.8489  λ_max=1.1082\n",
      "[Muon | lr=0.1] Epoch 211/4000: train_loss=0.0104  test_loss=23.8470  λ_max=1.1064\n",
      "[Muon | lr=0.1] Epoch 212/4000: train_loss=0.0097  test_loss=23.9024  λ_max=1.1101\n",
      "[Muon | lr=0.1] Iter 3400: loss=0.0064\n",
      "[Muon | lr=0.1] Epoch 213/4000: train_loss=0.0104  test_loss=23.9850  λ_max=1.0617\n",
      "[Muon | lr=0.1] Epoch 214/4000: train_loss=0.0091  test_loss=24.0485  λ_max=1.1084\n",
      "[Muon | lr=0.1] Epoch 215/4000: train_loss=0.0108  test_loss=24.0666  λ_max=1.1378\n",
      "[Muon | lr=0.1] Epoch 216/4000: train_loss=0.0104  test_loss=24.2443  λ_max=1.1194\n",
      "[Muon | lr=0.1] Epoch 217/4000: train_loss=0.0112  test_loss=24.2447  λ_max=1.1411\n",
      "[Muon | lr=0.1] Epoch 218/4000: train_loss=0.0101  test_loss=24.3056  λ_max=1.1341\n",
      "[Muon | lr=0.1] Iter 3500: loss=0.0092\n",
      "[Muon | lr=0.1] Epoch 219/4000: train_loss=0.0100  test_loss=24.3890  λ_max=1.1366\n",
      "[Muon | lr=0.1] Epoch 220/4000: train_loss=0.0105  test_loss=24.5078  λ_max=1.1329\n",
      "[Muon | lr=0.1] Epoch 221/4000: train_loss=0.0097  test_loss=24.5349  λ_max=1.1530\n",
      "[Muon | lr=0.1] Epoch 222/4000: train_loss=0.0100  test_loss=24.5522  λ_max=1.0884\n",
      "[Muon | lr=0.1] Epoch 223/4000: train_loss=0.0107  test_loss=24.6729  λ_max=1.1383\n",
      "[Muon | lr=0.1] Epoch 224/4000: train_loss=0.0094  test_loss=24.7111  λ_max=1.1374\n",
      "[Muon | lr=0.1] Iter 3600: loss=0.0096\n",
      "[Muon | lr=0.1] Epoch 225/4000: train_loss=0.0096  test_loss=24.7997  λ_max=1.1638\n",
      "[Muon | lr=0.1] Epoch 226/4000: train_loss=0.0100  test_loss=24.7836  λ_max=1.1200\n",
      "[Muon | lr=0.1] Epoch 227/4000: train_loss=0.0096  test_loss=24.9212  λ_max=1.0871\n",
      "[Muon | lr=0.1] Epoch 228/4000: train_loss=0.0095  test_loss=24.9418  λ_max=1.1497\n",
      "[Muon | lr=0.1] Epoch 229/4000: train_loss=0.0088  test_loss=24.9637  λ_max=1.1064\n",
      "[Muon | lr=0.1] Epoch 230/4000: train_loss=0.0102  test_loss=25.0067  λ_max=1.1166\n",
      "[Muon | lr=0.1] Epoch 231/4000: train_loss=0.0095  test_loss=25.0614  λ_max=1.1425\n",
      "[Muon | lr=0.1] Iter 3700: loss=0.0062\n",
      "[Muon | lr=0.1] Epoch 232/4000: train_loss=0.0093  test_loss=25.1312  λ_max=1.0989\n",
      "[Muon | lr=0.1] Epoch 233/4000: train_loss=0.0108  test_loss=25.2232  λ_max=1.1340\n",
      "[Muon | lr=0.1] Epoch 234/4000: train_loss=0.0098  test_loss=25.2072  λ_max=1.1408\n",
      "[Muon | lr=0.1] Epoch 235/4000: train_loss=0.0097  test_loss=25.2867  λ_max=1.0980\n",
      "[Muon | lr=0.1] Epoch 236/4000: train_loss=0.0102  test_loss=25.2881  λ_max=1.1081\n",
      "[Muon | lr=0.1] Epoch 237/4000: train_loss=0.0097  test_loss=25.2598  λ_max=1.1556\n",
      "[Muon | lr=0.1] Iter 3800: loss=0.0106\n",
      "[Muon | lr=0.1] Epoch 238/4000: train_loss=0.0097  test_loss=25.3115  λ_max=1.2337\n",
      "[Muon | lr=0.1] Epoch 239/4000: train_loss=0.0102  test_loss=25.3243  λ_max=1.1323\n",
      "[Muon | lr=0.1] Epoch 240/4000: train_loss=0.0101  test_loss=25.4263  λ_max=1.1799\n",
      "[Muon | lr=0.1] Epoch 241/4000: train_loss=0.0097  test_loss=25.4829  λ_max=1.1372\n",
      "[Muon | lr=0.1] Epoch 242/4000: train_loss=0.0094  test_loss=25.6087  λ_max=1.1755\n",
      "[Muon | lr=0.1] Epoch 243/4000: train_loss=0.0097  test_loss=25.7552  λ_max=1.0883\n",
      "[Muon | lr=0.1] Iter 3900: loss=0.0143\n",
      "[Muon | lr=0.1] Epoch 244/4000: train_loss=0.0097  test_loss=25.8427  λ_max=1.0425\n",
      "[Muon | lr=0.1] Epoch 245/4000: train_loss=0.0104  test_loss=25.9735  λ_max=1.1462\n",
      "[Muon | lr=0.1] Epoch 246/4000: train_loss=0.0093  test_loss=26.0352  λ_max=1.1796\n",
      "[Muon | lr=0.1] Epoch 247/4000: train_loss=0.0092  test_loss=26.1162  λ_max=1.1578\n",
      "[Muon | lr=0.1] Epoch 248/4000: train_loss=0.0091  test_loss=26.2095  λ_max=1.1598\n",
      "[Muon | lr=0.1] Epoch 249/4000: train_loss=0.0097  test_loss=26.2843  λ_max=1.1617\n",
      "[Muon | lr=0.1] Iter 4000: loss=0.0155\n",
      "[Muon | lr=0.1] Epoch 250/4000: train_loss=0.0102  test_loss=26.3227  λ_max=1.1881\n",
      "[Muon | lr=0.1] Epoch 251/4000: train_loss=0.0094  test_loss=26.3506  λ_max=1.1510\n",
      "[Muon | lr=0.1] Epoch 252/4000: train_loss=0.0089  test_loss=26.4051  λ_max=1.1690\n",
      "[Muon | lr=0.1] Epoch 253/4000: train_loss=0.0100  test_loss=26.4735  λ_max=1.2298\n",
      "[Muon | lr=0.1] Epoch 254/4000: train_loss=0.0106  test_loss=26.5666  λ_max=1.1339\n",
      "[Muon | lr=0.1] Epoch 255/4000: train_loss=0.0096  test_loss=26.5882  λ_max=1.1418\n",
      "[Muon | lr=0.1] Epoch 256/4000: train_loss=0.0095  test_loss=26.6604  λ_max=1.0813\n",
      "[Muon | lr=0.1] Iter 4100: loss=0.0065\n",
      "[Muon | lr=0.1] Epoch 257/4000: train_loss=0.0096  test_loss=26.6561  λ_max=1.0840\n",
      "[Muon | lr=0.1] Epoch 258/4000: train_loss=0.0086  test_loss=26.7541  λ_max=1.1002\n",
      "[Muon | lr=0.1] Epoch 259/4000: train_loss=0.0093  test_loss=26.7749  λ_max=1.1641\n",
      "[Muon | lr=0.1] Epoch 260/4000: train_loss=0.0088  test_loss=26.8822  λ_max=1.1498\n",
      "[Muon | lr=0.1] Epoch 261/4000: train_loss=0.0083  test_loss=26.9683  λ_max=1.1990\n",
      "[Muon | lr=0.1] Epoch 262/4000: train_loss=0.0090  test_loss=26.9715  λ_max=1.1528\n",
      "[Muon | lr=0.1] Iter 4200: loss=0.0086\n",
      "[Muon | lr=0.1] Epoch 263/4000: train_loss=0.0092  test_loss=27.0518  λ_max=1.1005\n",
      "[Muon | lr=0.1] Epoch 264/4000: train_loss=0.0086  test_loss=26.9585  λ_max=1.1869\n",
      "[Muon | lr=0.1] Epoch 265/4000: train_loss=0.0096  test_loss=27.0033  λ_max=1.1605\n",
      "[Muon | lr=0.1] Epoch 266/4000: train_loss=0.0091  test_loss=27.0269  λ_max=1.1609\n",
      "[Muon | lr=0.1] Epoch 267/4000: train_loss=0.0087  test_loss=27.1364  λ_max=1.2024\n",
      "[Muon | lr=0.1] Epoch 268/4000: train_loss=0.0098  test_loss=27.3025  λ_max=1.1509\n",
      "[Muon | lr=0.1] Iter 4300: loss=0.0128\n",
      "[Muon | lr=0.1] Epoch 269/4000: train_loss=0.0088  test_loss=27.3280  λ_max=1.1771\n",
      "[Muon | lr=0.1] Epoch 270/4000: train_loss=0.0091  test_loss=27.3598  λ_max=1.1718\n",
      "[Muon | lr=0.1] Epoch 271/4000: train_loss=0.0092  test_loss=27.4425  λ_max=1.1436\n",
      "[Muon | lr=0.1] Epoch 272/4000: train_loss=0.0092  test_loss=27.4808  λ_max=1.1113\n",
      "[Muon | lr=0.1] Epoch 273/4000: train_loss=0.0091  test_loss=27.4764  λ_max=1.1219\n",
      "[Muon | lr=0.1] Epoch 274/4000: train_loss=0.0078  test_loss=27.5771  λ_max=1.1864\n",
      "[Muon | lr=0.1] Iter 4400: loss=0.0213\n",
      "[Muon | lr=0.1] Epoch 275/4000: train_loss=0.0090  test_loss=27.6410  λ_max=1.1290\n",
      "[Muon | lr=0.1] Epoch 276/4000: train_loss=0.0077  test_loss=27.5645  λ_max=1.2411\n",
      "[Muon | lr=0.1] Epoch 277/4000: train_loss=0.0098  test_loss=27.6961  λ_max=1.1490\n",
      "[Muon | lr=0.1] Epoch 278/4000: train_loss=0.0093  test_loss=27.7146  λ_max=1.1831\n",
      "[Muon | lr=0.1] Epoch 279/4000: train_loss=0.0089  test_loss=27.7962  λ_max=1.1969\n",
      "[Muon | lr=0.1] Epoch 280/4000: train_loss=0.0090  test_loss=27.8437  λ_max=1.1810\n",
      "[Muon | lr=0.1] Epoch 281/4000: train_loss=0.0090  test_loss=27.9763  λ_max=1.1527\n",
      "[Muon | lr=0.1] Iter 4500: loss=0.0055\n",
      "[Muon | lr=0.1] Epoch 282/4000: train_loss=0.0084  test_loss=27.9869  λ_max=1.2031\n",
      "[Muon | lr=0.1] Epoch 283/4000: train_loss=0.0087  test_loss=28.1230  λ_max=1.1896\n",
      "[Muon | lr=0.1] Epoch 284/4000: train_loss=0.0096  test_loss=28.0891  λ_max=1.2240\n",
      "[Muon | lr=0.1] Epoch 285/4000: train_loss=0.0096  test_loss=28.1913  λ_max=1.2258\n",
      "[Muon | lr=0.1] Epoch 286/4000: train_loss=0.0093  test_loss=28.2943  λ_max=1.1608\n",
      "[Muon | lr=0.1] Epoch 287/4000: train_loss=0.0087  test_loss=28.3714  λ_max=1.1613\n",
      "[Muon | lr=0.1] Iter 4600: loss=0.0086\n",
      "[Muon | lr=0.1] Epoch 288/4000: train_loss=0.0096  test_loss=28.4349  λ_max=1.1734\n",
      "[Muon | lr=0.1] Epoch 289/4000: train_loss=0.0094  test_loss=28.4932  λ_max=1.2529\n",
      "[Muon | lr=0.1] Epoch 290/4000: train_loss=0.0087  test_loss=28.5715  λ_max=1.3147\n",
      "[Muon | lr=0.1] Epoch 291/4000: train_loss=0.0086  test_loss=28.5480  λ_max=1.2444\n",
      "[Muon | lr=0.1] Epoch 292/4000: train_loss=0.0087  test_loss=28.5602  λ_max=1.2393\n",
      "[Muon | lr=0.1] Epoch 293/4000: train_loss=0.0076  test_loss=28.6085  λ_max=1.1969\n",
      "[Muon | lr=0.1] Iter 4700: loss=0.0138\n",
      "[Muon | lr=0.1] Epoch 294/4000: train_loss=0.0087  test_loss=28.6140  λ_max=1.3114\n",
      "[Muon | lr=0.1] Epoch 295/4000: train_loss=0.0089  test_loss=28.6838  λ_max=1.2466\n",
      "[Muon | lr=0.1] Epoch 296/4000: train_loss=0.0083  test_loss=28.6977  λ_max=1.3755\n",
      "[Muon | lr=0.1] Epoch 297/4000: train_loss=0.0085  test_loss=28.8879  λ_max=1.2162\n",
      "[Muon | lr=0.1] Epoch 298/4000: train_loss=0.0087  test_loss=28.9499  λ_max=1.2332\n",
      "[Muon | lr=0.1] Epoch 299/4000: train_loss=0.0084  test_loss=28.9184  λ_max=1.2522\n",
      "[Muon | lr=0.1] Iter 4800: loss=0.0173\n",
      "[Muon | lr=0.1] Epoch 300/4000: train_loss=0.0092  test_loss=29.0471  λ_max=1.2771\n",
      "[Muon | lr=0.1] Epoch 301/4000: train_loss=0.0076  test_loss=29.1743  λ_max=1.2331\n",
      "[Muon | lr=0.1] Epoch 302/4000: train_loss=0.0079  test_loss=29.2910  λ_max=1.1640\n",
      "[Muon | lr=0.1] Epoch 303/4000: train_loss=0.0081  test_loss=29.3528  λ_max=1.2373\n",
      "[Muon | lr=0.1] Epoch 304/4000: train_loss=0.0083  test_loss=29.3525  λ_max=1.2535\n",
      "[Muon | lr=0.1] Epoch 305/4000: train_loss=0.0084  test_loss=29.4247  λ_max=1.2783\n",
      "[Muon | lr=0.1] Epoch 306/4000: train_loss=0.0086  test_loss=29.4401  λ_max=1.2553\n",
      "[Muon | lr=0.1] Iter 4900: loss=0.0048\n",
      "[Muon | lr=0.1] Epoch 307/4000: train_loss=0.0087  test_loss=29.4854  λ_max=1.1849\n",
      "[Muon | lr=0.1] Epoch 308/4000: train_loss=0.0075  test_loss=29.6479  λ_max=1.1830\n",
      "[Muon | lr=0.1] Epoch 309/4000: train_loss=0.0079  test_loss=29.6822  λ_max=1.2176\n",
      "[Muon | lr=0.1] Epoch 310/4000: train_loss=0.0080  test_loss=29.8368  λ_max=1.3139\n",
      "[Muon | lr=0.1] Epoch 311/4000: train_loss=0.0088  test_loss=29.8742  λ_max=1.2308\n",
      "[Muon | lr=0.1] Epoch 312/4000: train_loss=0.0084  test_loss=29.9277  λ_max=1.2739\n",
      "[Muon | lr=0.1] Iter 5000: loss=0.0091\n",
      "[Muon | lr=0.1] Epoch 313/4000: train_loss=0.0090  test_loss=29.8952  λ_max=1.2066\n",
      "[Muon | lr=0.1] Epoch 314/4000: train_loss=0.0083  test_loss=29.9582  λ_max=1.2399\n",
      "[Muon | lr=0.1] Epoch 315/4000: train_loss=0.0082  test_loss=30.0504  λ_max=1.3733\n",
      "[Muon | lr=0.1] Epoch 316/4000: train_loss=0.0090  test_loss=30.1559  λ_max=1.2065\n",
      "[Muon | lr=0.1] Epoch 317/4000: train_loss=0.0080  test_loss=30.1347  λ_max=1.2821\n",
      "[Muon | lr=0.1] Epoch 318/4000: train_loss=0.0079  test_loss=30.1169  λ_max=1.2183\n",
      "[Muon | lr=0.1] Iter 5100: loss=0.0092\n",
      "[Muon | lr=0.1] Epoch 319/4000: train_loss=0.0080  test_loss=30.1117  λ_max=1.2492\n",
      "[Muon | lr=0.1] Epoch 320/4000: train_loss=0.0084  test_loss=30.1860  λ_max=1.2524\n",
      "[Muon | lr=0.1] Epoch 321/4000: train_loss=0.0086  test_loss=30.3004  λ_max=1.3160\n",
      "[Muon | lr=0.1] Epoch 322/4000: train_loss=0.0088  test_loss=30.3577  λ_max=1.3001\n",
      "[Muon | lr=0.1] Epoch 323/4000: train_loss=0.0076  test_loss=30.4022  λ_max=1.2810\n",
      "[Muon | lr=0.1] Epoch 324/4000: train_loss=0.0078  test_loss=30.4421  λ_max=1.2331\n",
      "[Muon | lr=0.1] Iter 5200: loss=0.0156\n",
      "[Muon | lr=0.1] Epoch 325/4000: train_loss=0.0091  test_loss=30.5374  λ_max=1.2443\n",
      "[Muon | lr=0.1] Epoch 326/4000: train_loss=0.0086  test_loss=30.6542  λ_max=1.2797\n",
      "[Muon | lr=0.1] Epoch 327/4000: train_loss=0.0083  test_loss=30.6587  λ_max=1.2913\n",
      "[Muon | lr=0.1] Epoch 328/4000: train_loss=0.0085  test_loss=30.6117  λ_max=1.4086\n",
      "[Muon | lr=0.1] Epoch 329/4000: train_loss=0.0080  test_loss=30.8197  λ_max=1.2586\n",
      "[Muon | lr=0.1] Epoch 330/4000: train_loss=0.0086  test_loss=30.8317  λ_max=1.2553\n",
      "[Muon | lr=0.1] Epoch 331/4000: train_loss=0.0081  test_loss=30.9027  λ_max=1.2614\n",
      "[Muon | lr=0.1] Iter 5300: loss=0.0047\n",
      "[Muon | lr=0.1] Epoch 332/4000: train_loss=0.0078  test_loss=30.9282  λ_max=1.3130\n",
      "[Muon | lr=0.1] Epoch 333/4000: train_loss=0.0086  test_loss=31.0221  λ_max=1.3181\n",
      "[Muon | lr=0.1] Epoch 334/4000: train_loss=0.0076  test_loss=31.0990  λ_max=1.3622\n",
      "[Muon | lr=0.1] Epoch 335/4000: train_loss=0.0088  test_loss=31.0470  λ_max=1.3347\n",
      "[Muon | lr=0.1] Epoch 336/4000: train_loss=0.0074  test_loss=31.0987  λ_max=1.2633\n",
      "[Muon | lr=0.1] Epoch 337/4000: train_loss=0.0079  test_loss=31.2548  λ_max=1.3344\n",
      "[Muon | lr=0.1] Iter 5400: loss=0.0092\n",
      "[Muon | lr=0.1] Epoch 338/4000: train_loss=0.0075  test_loss=31.2994  λ_max=1.3546\n",
      "[Muon | lr=0.1] Epoch 339/4000: train_loss=0.0075  test_loss=31.3845  λ_max=1.3722\n",
      "[Muon | lr=0.1] Epoch 340/4000: train_loss=0.0082  test_loss=31.5484  λ_max=1.3234\n",
      "[Muon | lr=0.1] Epoch 341/4000: train_loss=0.0074  test_loss=31.5531  λ_max=1.3749\n",
      "[Muon | lr=0.1] Epoch 342/4000: train_loss=0.0083  test_loss=31.6470  λ_max=1.3243\n",
      "[Muon | lr=0.1] Epoch 343/4000: train_loss=0.0080  test_loss=31.7411  λ_max=1.2862\n",
      "[Muon | lr=0.1] Iter 5500: loss=0.0076\n",
      "[Muon | lr=0.1] Epoch 344/4000: train_loss=0.0068  test_loss=31.7853  λ_max=1.3140\n",
      "[Muon | lr=0.1] Epoch 345/4000: train_loss=0.0077  test_loss=31.7871  λ_max=1.3059\n",
      "[Muon | lr=0.1] Epoch 346/4000: train_loss=0.0073  test_loss=31.8276  λ_max=1.3131\n",
      "[Muon | lr=0.1] Epoch 347/4000: train_loss=0.0073  test_loss=31.8769  λ_max=1.2175\n",
      "[Muon | lr=0.1] Epoch 348/4000: train_loss=0.0082  test_loss=31.8620  λ_max=1.3386\n",
      "[Muon | lr=0.1] Epoch 349/4000: train_loss=0.0079  test_loss=31.8714  λ_max=1.2772\n",
      "[Muon | lr=0.1] Iter 5600: loss=0.0114\n",
      "[Muon | lr=0.1] Epoch 350/4000: train_loss=0.0076  test_loss=32.0343  λ_max=1.2676\n",
      "[Muon | lr=0.1] Epoch 351/4000: train_loss=0.0082  test_loss=32.0265  λ_max=1.2785\n",
      "[Muon | lr=0.1] Epoch 352/4000: train_loss=0.0086  test_loss=32.0768  λ_max=1.3330\n",
      "[Muon | lr=0.1] Epoch 353/4000: train_loss=0.0079  test_loss=32.1657  λ_max=1.2957\n",
      "[Muon | lr=0.1] Epoch 354/4000: train_loss=0.0077  test_loss=32.2652  λ_max=1.3710\n",
      "[Muon | lr=0.1] Epoch 355/4000: train_loss=0.0079  test_loss=32.2915  λ_max=1.3981\n",
      "[Muon | lr=0.1] Epoch 356/4000: train_loss=0.0074  test_loss=32.3568  λ_max=1.3177\n",
      "[Muon | lr=0.1] Iter 5700: loss=0.0041\n",
      "[Muon | lr=0.1] Epoch 357/4000: train_loss=0.0079  test_loss=32.4437  λ_max=1.3389\n",
      "[Muon | lr=0.1] Epoch 358/4000: train_loss=0.0083  test_loss=32.5692  λ_max=1.3908\n",
      "[Muon | lr=0.1] Epoch 359/4000: train_loss=0.0075  test_loss=32.6042  λ_max=1.2961\n",
      "[Muon | lr=0.1] Epoch 360/4000: train_loss=0.0079  test_loss=32.6893  λ_max=1.3057\n",
      "[Muon | lr=0.1] Epoch 361/4000: train_loss=0.0073  test_loss=32.6987  λ_max=1.3726\n",
      "[Muon | lr=0.1] Epoch 362/4000: train_loss=0.0078  test_loss=32.7676  λ_max=1.3922\n",
      "[Muon | lr=0.1] Iter 5800: loss=0.0107\n",
      "[Muon | lr=0.1] Epoch 363/4000: train_loss=0.0089  test_loss=32.8117  λ_max=1.3533\n",
      "[Muon | lr=0.1] Epoch 364/4000: train_loss=0.0077  test_loss=32.8845  λ_max=1.3197\n",
      "[Muon | lr=0.1] Epoch 365/4000: train_loss=0.0076  test_loss=32.9539  λ_max=1.3985\n",
      "[Muon | lr=0.1] Epoch 366/4000: train_loss=0.0066  test_loss=33.0532  λ_max=1.3623\n",
      "[Muon | lr=0.1] Epoch 367/4000: train_loss=0.0074  test_loss=33.1255  λ_max=1.3194\n",
      "[Muon | lr=0.1] Epoch 368/4000: train_loss=0.0077  test_loss=33.0947  λ_max=1.3813\n",
      "[Muon | lr=0.1] Iter 5900: loss=0.0099\n",
      "[Muon | lr=0.1] Epoch 369/4000: train_loss=0.0073  test_loss=33.2555  λ_max=1.3388\n",
      "[Muon | lr=0.1] Epoch 370/4000: train_loss=0.0075  test_loss=33.3144  λ_max=1.3900\n",
      "[Muon | lr=0.1] Epoch 371/4000: train_loss=0.0083  test_loss=33.2604  λ_max=1.4058\n",
      "[Muon | lr=0.1] Epoch 372/4000: train_loss=0.0068  test_loss=33.3511  λ_max=1.3772\n",
      "[Muon | lr=0.1] Epoch 373/4000: train_loss=0.0076  test_loss=33.4853  λ_max=1.3439\n",
      "[Muon | lr=0.1] Epoch 374/4000: train_loss=0.0074  test_loss=33.4818  λ_max=1.3871\n",
      "[Muon | lr=0.1] Iter 6000: loss=0.0096\n",
      "[Muon | lr=0.1] Epoch 375/4000: train_loss=0.0080  test_loss=33.6884  λ_max=1.3049\n",
      "[Muon | lr=0.1] Epoch 376/4000: train_loss=0.0075  test_loss=33.6495  λ_max=1.2592\n",
      "[Muon | lr=0.1] Epoch 377/4000: train_loss=0.0073  test_loss=33.6377  λ_max=1.3486\n",
      "[Muon | lr=0.1] Epoch 378/4000: train_loss=0.0068  test_loss=33.7848  λ_max=1.4355\n",
      "[Muon | lr=0.1] Epoch 379/4000: train_loss=0.0081  test_loss=33.9035  λ_max=1.4040\n",
      "[Muon | lr=0.1] Epoch 380/4000: train_loss=0.0078  test_loss=33.9908  λ_max=1.3562\n",
      "[Muon | lr=0.1] Epoch 381/4000: train_loss=0.0075  test_loss=33.8985  λ_max=1.4256\n",
      "[Muon | lr=0.1] Iter 6100: loss=0.0066\n",
      "[Muon | lr=0.1] Epoch 382/4000: train_loss=0.0074  test_loss=34.0050  λ_max=1.3910\n",
      "[Muon | lr=0.1] Epoch 383/4000: train_loss=0.0065  test_loss=33.9612  λ_max=1.3482\n",
      "[Muon | lr=0.1] Epoch 384/4000: train_loss=0.0068  test_loss=33.9511  λ_max=1.4718\n",
      "[Muon | lr=0.1] Epoch 385/4000: train_loss=0.0068  test_loss=33.9830  λ_max=1.3460\n",
      "[Muon | lr=0.1] Epoch 386/4000: train_loss=0.0075  test_loss=34.1501  λ_max=1.3482\n",
      "[Muon | lr=0.1] Epoch 387/4000: train_loss=0.0072  test_loss=34.2595  λ_max=1.4893\n",
      "[Muon | lr=0.1] Iter 6200: loss=0.0083\n",
      "[Muon | lr=0.1] Epoch 388/4000: train_loss=0.0071  test_loss=34.2814  λ_max=1.3810\n",
      "[Muon | lr=0.1] Epoch 389/4000: train_loss=0.0076  test_loss=34.3841  λ_max=1.3560\n",
      "[Muon | lr=0.1] Epoch 390/4000: train_loss=0.0070  test_loss=34.4380  λ_max=1.4062\n",
      "[Muon | lr=0.1] Epoch 391/4000: train_loss=0.0071  test_loss=34.5628  λ_max=1.3879\n",
      "[Muon | lr=0.1] Epoch 392/4000: train_loss=0.0068  test_loss=34.6197  λ_max=1.4121\n",
      "[Muon | lr=0.1] Epoch 393/4000: train_loss=0.0077  test_loss=34.7761  λ_max=1.3918\n",
      "[Muon | lr=0.1] Iter 6300: loss=0.0129\n",
      "[Muon | lr=0.1] Epoch 394/4000: train_loss=0.0077  test_loss=34.9525  λ_max=1.3668\n",
      "[Muon | lr=0.1] Epoch 395/4000: train_loss=0.0079  test_loss=34.9045  λ_max=1.4259\n",
      "[Muon | lr=0.1] Epoch 396/4000: train_loss=0.0079  test_loss=35.0321  λ_max=1.3280\n",
      "[Muon | lr=0.1] Epoch 397/4000: train_loss=0.0074  test_loss=35.0302  λ_max=1.3589\n",
      "[Muon | lr=0.1] Epoch 398/4000: train_loss=0.0069  test_loss=35.1116  λ_max=1.2870\n",
      "[Muon | lr=0.1] Epoch 399/4000: train_loss=0.0076  test_loss=35.1604  λ_max=1.4128\n",
      "[Muon | lr=0.1] Iter 6400: loss=0.0107\n",
      "[Muon | lr=0.1] Epoch 400/4000: train_loss=0.0076  test_loss=35.2128  λ_max=1.4115\n",
      "[Muon | lr=0.1] Epoch 401/4000: train_loss=0.0075  test_loss=35.3412  λ_max=1.4770\n",
      "[Muon | lr=0.1] Epoch 402/4000: train_loss=0.0075  test_loss=35.4792  λ_max=1.3474\n",
      "[Muon | lr=0.1] Epoch 403/4000: train_loss=0.0079  test_loss=35.4850  λ_max=1.4302\n",
      "[Muon | lr=0.1] Epoch 404/4000: train_loss=0.0079  test_loss=35.5262  λ_max=1.3359\n",
      "[Muon | lr=0.1] Epoch 405/4000: train_loss=0.0074  test_loss=35.5795  λ_max=1.3252\n",
      "[Muon | lr=0.1] Epoch 406/4000: train_loss=0.0080  test_loss=35.6310  λ_max=1.4070\n",
      "[Muon | lr=0.1] Iter 6500: loss=0.0028\n",
      "[Muon | lr=0.1] Epoch 407/4000: train_loss=0.0073  test_loss=35.6281  λ_max=1.3688\n",
      "[Muon | lr=0.1] Epoch 408/4000: train_loss=0.0065  test_loss=35.6568  λ_max=1.4139\n",
      "[Muon | lr=0.1] Epoch 409/4000: train_loss=0.0074  test_loss=35.7669  λ_max=1.4260\n",
      "[Muon | lr=0.1] Epoch 410/4000: train_loss=0.0072  test_loss=35.7797  λ_max=1.4096\n",
      "[Muon | lr=0.1] Epoch 411/4000: train_loss=0.0066  test_loss=35.8753  λ_max=1.3532\n",
      "[Muon | lr=0.1] Epoch 412/4000: train_loss=0.0067  test_loss=35.9617  λ_max=1.4294\n",
      "[Muon | lr=0.1] Iter 6600: loss=0.0100\n",
      "[Muon | lr=0.1] Epoch 413/4000: train_loss=0.0071  test_loss=35.9417  λ_max=1.5240\n",
      "[Muon | lr=0.1] Epoch 414/4000: train_loss=0.0080  test_loss=35.9522  λ_max=1.4652\n",
      "[Muon | lr=0.1] Epoch 415/4000: train_loss=0.0064  test_loss=35.9547  λ_max=1.4636\n",
      "[Muon | lr=0.1] Epoch 416/4000: train_loss=0.0069  test_loss=36.1452  λ_max=1.3313\n",
      "[Muon | lr=0.1] Epoch 417/4000: train_loss=0.0073  test_loss=36.2189  λ_max=1.4406\n",
      "[Muon | lr=0.1] Epoch 418/4000: train_loss=0.0077  test_loss=36.2220  λ_max=1.4413\n",
      "[Muon | lr=0.1] Iter 6700: loss=0.0118\n",
      "[Muon | lr=0.1] Epoch 419/4000: train_loss=0.0071  test_loss=36.3617  λ_max=1.3947\n",
      "[Muon | lr=0.1] Epoch 420/4000: train_loss=0.0075  test_loss=36.4779  λ_max=1.3233\n",
      "[Muon | lr=0.1] Epoch 421/4000: train_loss=0.0067  test_loss=36.4762  λ_max=1.4999\n",
      "[Muon | lr=0.1] Epoch 422/4000: train_loss=0.0071  test_loss=36.6066  λ_max=1.4969\n",
      "[Muon | lr=0.1] Epoch 423/4000: train_loss=0.0074  test_loss=36.7950  λ_max=1.4745\n",
      "[Muon | lr=0.1] Epoch 424/4000: train_loss=0.0070  test_loss=36.7559  λ_max=1.3449\n",
      "[Muon | lr=0.1] Iter 6800: loss=0.0125\n",
      "[Muon | lr=0.1] Epoch 425/4000: train_loss=0.0073  test_loss=36.9254  λ_max=1.5480\n",
      "[Muon | lr=0.1] Epoch 426/4000: train_loss=0.0078  test_loss=36.9548  λ_max=1.5186\n",
      "[Muon | lr=0.1] Epoch 427/4000: train_loss=0.0070  test_loss=36.9127  λ_max=1.4402\n",
      "[Muon | lr=0.1] Epoch 428/4000: train_loss=0.0074  test_loss=36.9718  λ_max=1.3820\n",
      "[Muon | lr=0.1] Epoch 429/4000: train_loss=0.0072  test_loss=36.9514  λ_max=1.3823\n",
      "[Muon | lr=0.1] Epoch 430/4000: train_loss=0.0074  test_loss=36.9902  λ_max=1.3850\n",
      "[Muon | lr=0.1] Epoch 431/4000: train_loss=0.0074  test_loss=37.0565  λ_max=1.5389\n",
      "[Muon | lr=0.1] Iter 6900: loss=0.0025\n",
      "[Muon | lr=0.1] Epoch 432/4000: train_loss=0.0074  test_loss=37.1052  λ_max=1.4717\n",
      "[Muon | lr=0.1] Epoch 433/4000: train_loss=0.0068  test_loss=37.1217  λ_max=1.4775\n",
      "[Muon | lr=0.1] Epoch 434/4000: train_loss=0.0064  test_loss=37.2510  λ_max=1.4668\n",
      "[Muon | lr=0.1] Epoch 435/4000: train_loss=0.0073  test_loss=37.3484  λ_max=1.4960\n",
      "[Muon | lr=0.1] Epoch 436/4000: train_loss=0.0078  test_loss=37.3020  λ_max=1.4192\n",
      "[Muon | lr=0.1] Epoch 437/4000: train_loss=0.0059  test_loss=37.4785  λ_max=1.4412\n",
      "[Muon | lr=0.1] Iter 7000: loss=0.0063\n",
      "[Muon | lr=0.1] Epoch 438/4000: train_loss=0.0068  test_loss=37.6311  λ_max=1.4491\n",
      "[Muon | lr=0.1] Epoch 439/4000: train_loss=0.0072  test_loss=37.6293  λ_max=1.4531\n",
      "[Muon | lr=0.1] Epoch 440/4000: train_loss=0.0068  test_loss=37.7545  λ_max=1.4967\n",
      "[Muon | lr=0.1] Epoch 441/4000: train_loss=0.0075  test_loss=37.7402  λ_max=1.4576\n",
      "[Muon | lr=0.1] Epoch 442/4000: train_loss=0.0080  test_loss=37.9022  λ_max=1.5355\n",
      "[Muon | lr=0.1] Epoch 443/4000: train_loss=0.0079  test_loss=38.0084  λ_max=1.4018\n",
      "[Muon | lr=0.1] Iter 7100: loss=0.0096\n",
      "[Muon | lr=0.1] Epoch 444/4000: train_loss=0.0066  test_loss=37.9639  λ_max=1.5962\n",
      "[Muon | lr=0.1] Epoch 445/4000: train_loss=0.0069  test_loss=38.0685  λ_max=1.4924\n",
      "[Muon | lr=0.1] Epoch 446/4000: train_loss=0.0074  test_loss=37.9727  λ_max=1.4698\n",
      "[Muon | lr=0.1] Epoch 447/4000: train_loss=0.0071  test_loss=38.1712  λ_max=1.4992\n",
      "[Muon | lr=0.1] Epoch 448/4000: train_loss=0.0066  test_loss=38.2137  λ_max=1.4042\n",
      "[Muon | lr=0.1] Epoch 449/4000: train_loss=0.0070  test_loss=38.2884  λ_max=1.4604\n",
      "[Muon | lr=0.1] Iter 7200: loss=0.0107\n",
      "[Muon | lr=0.1] Epoch 450/4000: train_loss=0.0070  test_loss=38.2954  λ_max=1.5318\n",
      "[Muon | lr=0.1] Epoch 451/4000: train_loss=0.0070  test_loss=38.2539  λ_max=1.4389\n",
      "[Muon | lr=0.1] Epoch 452/4000: train_loss=0.0066  test_loss=38.3221  λ_max=1.4308\n",
      "[Muon | lr=0.1] Epoch 453/4000: train_loss=0.0065  test_loss=38.2873  λ_max=1.4884\n",
      "[Muon | lr=0.1] Epoch 454/4000: train_loss=0.0063  test_loss=38.4620  λ_max=1.4795\n",
      "[Muon | lr=0.1] Epoch 455/4000: train_loss=0.0070  test_loss=38.6239  λ_max=1.5176\n",
      "[Muon | lr=0.1] Epoch 456/4000: train_loss=0.0077  test_loss=38.6041  λ_max=1.5338\n",
      "[Muon | lr=0.1] Iter 7300: loss=0.0055\n",
      "[Muon | lr=0.1] Epoch 457/4000: train_loss=0.0064  test_loss=38.6529  λ_max=1.6273\n",
      "[Muon | lr=0.1] Epoch 458/4000: train_loss=0.0077  test_loss=38.6560  λ_max=1.4502\n",
      "[Muon | lr=0.1] Epoch 459/4000: train_loss=0.0068  test_loss=38.6944  λ_max=1.5419\n",
      "[Muon | lr=0.1] Epoch 460/4000: train_loss=0.0070  test_loss=38.6574  λ_max=1.6064\n",
      "[Muon | lr=0.1] Epoch 461/4000: train_loss=0.0066  test_loss=38.8126  λ_max=1.5098\n",
      "[Muon | lr=0.1] Epoch 462/4000: train_loss=0.0071  test_loss=38.8878  λ_max=1.5388\n",
      "[Muon | lr=0.1] Iter 7400: loss=0.0029\n",
      "[Muon | lr=0.1] Epoch 463/4000: train_loss=0.0066  test_loss=38.8932  λ_max=1.7805\n",
      "[Muon | lr=0.1] Epoch 464/4000: train_loss=0.0068  test_loss=38.9595  λ_max=1.7016\n",
      "[Muon | lr=0.1] Epoch 465/4000: train_loss=0.0073  test_loss=39.1207  λ_max=1.5293\n",
      "[Muon | lr=0.1] Epoch 466/4000: train_loss=0.0067  test_loss=39.1910  λ_max=1.5545\n",
      "[Muon | lr=0.1] Epoch 467/4000: train_loss=0.0075  test_loss=39.2266  λ_max=1.4464\n",
      "[Muon | lr=0.1] Epoch 468/4000: train_loss=0.0071  test_loss=39.2820  λ_max=1.5140\n",
      "[Muon | lr=0.1] Iter 7500: loss=0.0113\n",
      "[Muon | lr=0.1] Epoch 469/4000: train_loss=0.0079  test_loss=39.4376  λ_max=1.4838\n",
      "[Muon | lr=0.1] Epoch 470/4000: train_loss=0.0060  test_loss=39.6141  λ_max=1.4857\n",
      "[Muon | lr=0.1] Epoch 471/4000: train_loss=0.0065  test_loss=39.7653  λ_max=1.4654\n",
      "[Muon | lr=0.1] Epoch 472/4000: train_loss=0.0068  test_loss=39.7316  λ_max=1.5334\n",
      "[Muon | lr=0.1] Epoch 473/4000: train_loss=0.0068  test_loss=39.8038  λ_max=1.6073\n",
      "[Muon | lr=0.1] Epoch 474/4000: train_loss=0.0071  test_loss=39.7626  λ_max=1.4229\n",
      "[Muon | lr=0.1] Iter 7600: loss=0.0139\n",
      "[Muon | lr=0.1] Epoch 475/4000: train_loss=0.0076  test_loss=39.8298  λ_max=1.4424\n",
      "[Muon | lr=0.1] Epoch 476/4000: train_loss=0.0070  test_loss=39.9475  λ_max=1.5720\n",
      "[Muon | lr=0.1] Epoch 477/4000: train_loss=0.0060  test_loss=40.0023  λ_max=1.4364\n",
      "[Muon | lr=0.1] Epoch 478/4000: train_loss=0.0073  test_loss=40.0369  λ_max=1.4689\n",
      "[Muon | lr=0.1] Epoch 479/4000: train_loss=0.0075  test_loss=40.0984  λ_max=1.4008\n",
      "[Muon | lr=0.1] Epoch 480/4000: train_loss=0.0073  test_loss=40.0253  λ_max=1.4809\n",
      "[Muon | lr=0.1] Epoch 481/4000: train_loss=0.0065  test_loss=40.1723  λ_max=1.4704\n",
      "[Muon | lr=0.1] Iter 7700: loss=0.0039\n",
      "[Muon | lr=0.1] Epoch 482/4000: train_loss=0.0074  test_loss=40.1378  λ_max=1.4167\n",
      "[Muon | lr=0.1] Epoch 483/4000: train_loss=0.0068  test_loss=40.3428  λ_max=1.4892\n",
      "[Muon | lr=0.1] Epoch 484/4000: train_loss=0.0068  test_loss=40.4175  λ_max=1.5382\n",
      "[Muon | lr=0.1] Epoch 485/4000: train_loss=0.0081  test_loss=40.4865  λ_max=1.4825\n",
      "[Muon | lr=0.1] Epoch 486/4000: train_loss=0.0080  test_loss=40.5067  λ_max=1.5391\n",
      "[Muon | lr=0.1] Epoch 487/4000: train_loss=0.0069  test_loss=40.5938  λ_max=1.4508\n",
      "[Muon | lr=0.1] Iter 7800: loss=0.0064\n",
      "[Muon | lr=0.1] Epoch 488/4000: train_loss=0.0072  test_loss=40.7049  λ_max=1.6276\n",
      "[Muon | lr=0.1] Epoch 489/4000: train_loss=0.0071  test_loss=40.7936  λ_max=1.6039\n",
      "[Muon | lr=0.1] Epoch 490/4000: train_loss=0.0067  test_loss=40.8400  λ_max=1.4542\n",
      "[Muon | lr=0.1] Epoch 491/4000: train_loss=0.0066  test_loss=40.8480  λ_max=1.6049\n",
      "[Muon | lr=0.1] Epoch 492/4000: train_loss=0.0069  test_loss=40.9031  λ_max=1.4915\n",
      "[Muon | lr=0.1] Epoch 493/4000: train_loss=0.0072  test_loss=40.8603  λ_max=1.5705\n",
      "[Muon | lr=0.1] Iter 7900: loss=0.0088\n",
      "[Muon | lr=0.1] Epoch 494/4000: train_loss=0.0067  test_loss=40.9245  λ_max=1.5514\n",
      "[Muon | lr=0.1] Epoch 495/4000: train_loss=0.0065  test_loss=40.9403  λ_max=1.5395\n",
      "[Muon | lr=0.1] Epoch 496/4000: train_loss=0.0068  test_loss=40.9853  λ_max=1.5512\n",
      "[Muon | lr=0.1] Epoch 497/4000: train_loss=0.0074  test_loss=41.0949  λ_max=1.5993\n",
      "[Muon | lr=0.1] Epoch 498/4000: train_loss=0.0057  test_loss=41.1273  λ_max=1.5557\n",
      "[Muon | lr=0.1] Epoch 499/4000: train_loss=0.0066  test_loss=41.1516  λ_max=1.5253\n",
      "[Muon | lr=0.1] Iter 8000: loss=0.0122\n",
      "[Muon | lr=0.1] Epoch 500/4000: train_loss=0.0070  test_loss=41.2004  λ_max=1.4868\n",
      "[Muon | lr=0.1] Epoch 501/4000: train_loss=0.0066  test_loss=41.2488  λ_max=1.4581\n",
      "[Muon | lr=0.1] Epoch 502/4000: train_loss=0.0061  test_loss=41.3634  λ_max=1.5058\n",
      "[Muon | lr=0.1] Epoch 503/4000: train_loss=0.0067  test_loss=41.3910  λ_max=1.4894\n",
      "[Muon | lr=0.1] Epoch 504/4000: train_loss=0.0065  test_loss=41.4971  λ_max=1.5743\n",
      "[Muon | lr=0.1] Epoch 505/4000: train_loss=0.0073  test_loss=41.5387  λ_max=1.5565\n",
      "[Muon | lr=0.1] Epoch 506/4000: train_loss=0.0072  test_loss=41.6568  λ_max=1.5177\n",
      "[Muon | lr=0.1] Iter 8100: loss=0.0031\n",
      "[Muon | lr=0.1] Epoch 507/4000: train_loss=0.0063  test_loss=41.7404  λ_max=1.5306\n",
      "[Muon | lr=0.1] Epoch 508/4000: train_loss=0.0066  test_loss=41.8882  λ_max=1.5835\n",
      "[Muon | lr=0.1] Epoch 509/4000: train_loss=0.0068  test_loss=41.8938  λ_max=1.5426\n",
      "[Muon | lr=0.1] Epoch 510/4000: train_loss=0.0064  test_loss=42.0641  λ_max=1.6090\n",
      "[Muon | lr=0.1] Epoch 511/4000: train_loss=0.0066  test_loss=42.1061  λ_max=1.6650\n",
      "[Muon | lr=0.1] Epoch 512/4000: train_loss=0.0072  test_loss=42.1964  λ_max=1.5750\n",
      "[Muon | lr=0.1] Iter 8200: loss=0.0060\n",
      "[Muon | lr=0.1] Epoch 513/4000: train_loss=0.0059  test_loss=42.0940  λ_max=1.6379\n",
      "[Muon | lr=0.1] Epoch 514/4000: train_loss=0.0067  test_loss=41.9999  λ_max=1.5781\n",
      "[Muon | lr=0.1] Epoch 515/4000: train_loss=0.0067  test_loss=42.0523  λ_max=1.5905\n",
      "[Muon | lr=0.1] Epoch 516/4000: train_loss=0.0067  test_loss=42.0060  λ_max=1.6142\n",
      "[Muon | lr=0.1] Epoch 517/4000: train_loss=0.0072  test_loss=42.0809  λ_max=1.6415\n",
      "[Muon | lr=0.1] Epoch 518/4000: train_loss=0.0066  test_loss=42.1272  λ_max=1.5839\n",
      "[Muon | lr=0.1] Iter 8300: loss=0.0081\n",
      "[Muon | lr=0.1] Epoch 519/4000: train_loss=0.0070  test_loss=42.2050  λ_max=1.7170\n",
      "[Muon | lr=0.1] Epoch 520/4000: train_loss=0.0068  test_loss=42.2463  λ_max=1.6281\n",
      "[Muon | lr=0.1] Epoch 521/4000: train_loss=0.0066  test_loss=42.2163  λ_max=1.5701\n",
      "[Muon | lr=0.1] Epoch 522/4000: train_loss=0.0069  test_loss=42.3220  λ_max=1.7428\n",
      "[Muon | lr=0.1] Epoch 523/4000: train_loss=0.0059  test_loss=42.3561  λ_max=1.6098\n",
      "[Muon | lr=0.1] Epoch 524/4000: train_loss=0.0073  test_loss=42.3595  λ_max=1.5433\n",
      "[Muon | lr=0.1] Iter 8400: loss=0.0136\n",
      "[Muon | lr=0.1] Epoch 525/4000: train_loss=0.0071  test_loss=42.5489  λ_max=1.5936\n",
      "[Muon | lr=0.1] Epoch 526/4000: train_loss=0.0067  test_loss=42.5998  λ_max=1.5696\n",
      "[Muon | lr=0.1] Epoch 527/4000: train_loss=0.0066  test_loss=42.6601  λ_max=1.6350\n",
      "[Muon | lr=0.1] Epoch 528/4000: train_loss=0.0058  test_loss=42.7686  λ_max=1.6673\n",
      "[Muon | lr=0.1] Epoch 529/4000: train_loss=0.0057  test_loss=42.8749  λ_max=1.6290\n",
      "[Muon | lr=0.1] Epoch 530/4000: train_loss=0.0063  test_loss=42.9879  λ_max=1.5934\n",
      "[Muon | lr=0.1] Epoch 531/4000: train_loss=0.0066  test_loss=43.1314  λ_max=1.6059\n",
      "[Muon | lr=0.1] Iter 8500: loss=0.0021\n",
      "[Muon | lr=0.1] Epoch 532/4000: train_loss=0.0057  test_loss=43.2477  λ_max=1.6004\n",
      "[Muon | lr=0.1] Epoch 533/4000: train_loss=0.0072  test_loss=43.2154  λ_max=1.6465\n",
      "[Muon | lr=0.1] Epoch 534/4000: train_loss=0.0064  test_loss=43.2870  λ_max=1.5801\n",
      "[Muon | lr=0.1] Epoch 535/4000: train_loss=0.0064  test_loss=43.2189  λ_max=1.6103\n",
      "[Muon | lr=0.1] Epoch 536/4000: train_loss=0.0066  test_loss=43.2567  λ_max=1.5883\n",
      "[Muon | lr=0.1] Epoch 537/4000: train_loss=0.0059  test_loss=43.2657  λ_max=1.7416\n",
      "[Muon | lr=0.1] Iter 8600: loss=0.0045\n",
      "[Muon | lr=0.1] Epoch 538/4000: train_loss=0.0064  test_loss=43.4093  λ_max=1.5862\n",
      "[Muon | lr=0.1] Epoch 539/4000: train_loss=0.0071  test_loss=43.4482  λ_max=1.6316\n",
      "[Muon | lr=0.1] Epoch 540/4000: train_loss=0.0068  test_loss=43.6095  λ_max=1.6182\n",
      "[Muon | lr=0.1] Epoch 541/4000: train_loss=0.0067  test_loss=43.6746  λ_max=1.8071\n",
      "[Muon | lr=0.1] Epoch 542/4000: train_loss=0.0063  test_loss=43.5806  λ_max=1.5167\n",
      "[Muon | lr=0.1] Epoch 543/4000: train_loss=0.0067  test_loss=43.5089  λ_max=1.6173\n",
      "[Muon | lr=0.1] Iter 8700: loss=0.0056\n",
      "[Muon | lr=0.1] Epoch 544/4000: train_loss=0.0064  test_loss=43.6054  λ_max=1.6304\n",
      "[Muon | lr=0.1] Epoch 545/4000: train_loss=0.0061  test_loss=43.7136  λ_max=1.6424\n",
      "[Muon | lr=0.1] Epoch 546/4000: train_loss=0.0064  test_loss=43.8080  λ_max=1.7131\n",
      "[Muon | lr=0.1] Epoch 547/4000: train_loss=0.0065  test_loss=43.9083  λ_max=1.5353\n",
      "[Muon | lr=0.1] Epoch 548/4000: train_loss=0.0062  test_loss=43.9237  λ_max=1.6051\n",
      "[Muon | lr=0.1] Epoch 549/4000: train_loss=0.0067  test_loss=44.0177  λ_max=1.6317\n",
      "[Muon | lr=0.1] Iter 8800: loss=0.0116\n",
      "[Muon | lr=0.1] Epoch 550/4000: train_loss=0.0072  test_loss=44.1092  λ_max=1.6064\n",
      "[Muon | lr=0.1] Epoch 551/4000: train_loss=0.0066  test_loss=44.1513  λ_max=1.5354\n",
      "[Muon | lr=0.1] Epoch 552/4000: train_loss=0.0068  test_loss=44.2237  λ_max=1.6671\n",
      "[Muon | lr=0.1] Epoch 553/4000: train_loss=0.0060  test_loss=44.3013  λ_max=1.5946\n",
      "[Muon | lr=0.1] Epoch 554/4000: train_loss=0.0055  test_loss=44.4186  λ_max=1.6410\n",
      "[Muon | lr=0.1] Epoch 555/4000: train_loss=0.0065  test_loss=44.4453  λ_max=1.6363\n",
      "[Muon | lr=0.1] Epoch 556/4000: train_loss=0.0063  test_loss=44.4109  λ_max=1.6537\n",
      "[Muon | lr=0.1] Iter 8900: loss=0.0045\n",
      "[Muon | lr=0.1] Epoch 557/4000: train_loss=0.0068  test_loss=44.4397  λ_max=1.7580\n",
      "[Muon | lr=0.1] Epoch 558/4000: train_loss=0.0070  test_loss=44.5496  λ_max=1.6024\n",
      "[Muon | lr=0.1] Epoch 559/4000: train_loss=0.0055  test_loss=44.7259  λ_max=1.6446\n",
      "[Muon | lr=0.1] Epoch 560/4000: train_loss=0.0061  test_loss=44.8981  λ_max=1.6203\n",
      "[Muon | lr=0.1] Epoch 561/4000: train_loss=0.0067  test_loss=44.9020  λ_max=1.5010\n",
      "[Muon | lr=0.1] Epoch 562/4000: train_loss=0.0064  test_loss=44.8868  λ_max=1.6821\n",
      "[Muon | lr=0.1] Iter 9000: loss=0.0034\n",
      "[Muon | lr=0.1] Epoch 563/4000: train_loss=0.0062  test_loss=44.8821  λ_max=1.5650\n",
      "[Muon | lr=0.1] Epoch 564/4000: train_loss=0.0063  test_loss=45.0993  λ_max=1.5780\n",
      "[Muon | lr=0.1] Epoch 565/4000: train_loss=0.0063  test_loss=45.2010  λ_max=1.7176\n",
      "[Muon | lr=0.1] Epoch 566/4000: train_loss=0.0064  test_loss=45.1147  λ_max=1.6970\n",
      "[Muon | lr=0.1] Epoch 567/4000: train_loss=0.0070  test_loss=45.1545  λ_max=1.5964\n",
      "[Muon | lr=0.1] Epoch 568/4000: train_loss=0.0063  test_loss=45.2270  λ_max=1.5479\n",
      "[Muon | lr=0.1] Iter 9100: loss=0.0081\n",
      "[Muon | lr=0.1] Epoch 569/4000: train_loss=0.0070  test_loss=45.2642  λ_max=1.6587\n",
      "[Muon | lr=0.1] Epoch 570/4000: train_loss=0.0064  test_loss=45.1716  λ_max=1.6005\n",
      "[Muon | lr=0.1] Epoch 571/4000: train_loss=0.0072  test_loss=45.2658  λ_max=1.6433\n",
      "[Muon | lr=0.1] Epoch 572/4000: train_loss=0.0066  test_loss=45.2413  λ_max=1.6865\n",
      "[Muon | lr=0.1] Epoch 573/4000: train_loss=0.0067  test_loss=45.2645  λ_max=1.7344\n",
      "[Muon | lr=0.1] Epoch 574/4000: train_loss=0.0072  test_loss=45.2604  λ_max=1.7622\n",
      "[Muon | lr=0.1] Iter 9200: loss=0.0146\n",
      "[Muon | lr=0.1] Epoch 575/4000: train_loss=0.0062  test_loss=45.3126  λ_max=1.5665\n",
      "[Muon | lr=0.1] Epoch 576/4000: train_loss=0.0063  test_loss=45.2535  λ_max=1.6172\n",
      "[Muon | lr=0.1] Epoch 577/4000: train_loss=0.0074  test_loss=45.4663  λ_max=1.8171\n",
      "[Muon | lr=0.1] Epoch 578/4000: train_loss=0.0065  test_loss=45.5259  λ_max=1.7308\n",
      "[Muon | lr=0.1] Epoch 579/4000: train_loss=0.0066  test_loss=45.5631  λ_max=1.5472\n",
      "[Muon | lr=0.1] Epoch 580/4000: train_loss=0.0063  test_loss=45.7384  λ_max=1.6637\n",
      "[Muon | lr=0.1] Epoch 581/4000: train_loss=0.0061  test_loss=45.8583  λ_max=1.7191\n",
      "[Muon | lr=0.1] Iter 9300: loss=0.0062\n",
      "[Muon | lr=0.1] Epoch 582/4000: train_loss=0.0071  test_loss=45.8567  λ_max=1.7151\n",
      "[Muon | lr=0.1] Epoch 583/4000: train_loss=0.0069  test_loss=45.8322  λ_max=1.7039\n",
      "[Muon | lr=0.1] Epoch 584/4000: train_loss=0.0069  test_loss=45.9537  λ_max=1.6431\n",
      "[Muon | lr=0.1] Epoch 585/4000: train_loss=0.0066  test_loss=46.0608  λ_max=1.8036\n",
      "[Muon | lr=0.1] Epoch 586/4000: train_loss=0.0069  test_loss=46.1393  λ_max=1.7135\n",
      "[Muon | lr=0.1] Epoch 587/4000: train_loss=0.0057  test_loss=46.2134  λ_max=1.8221\n",
      "[Muon | lr=0.1] Iter 9400: loss=0.0060\n",
      "[Muon | lr=0.1] Epoch 588/4000: train_loss=0.0055  test_loss=46.1193  λ_max=1.6467\n",
      "[Muon | lr=0.1] Epoch 589/4000: train_loss=0.0066  test_loss=46.2898  λ_max=1.7527\n",
      "[Muon | lr=0.1] Epoch 590/4000: train_loss=0.0066  test_loss=46.2945  λ_max=1.8050\n",
      "[Muon | lr=0.1] Epoch 591/4000: train_loss=0.0074  test_loss=46.3994  λ_max=1.7669\n",
      "[Muon | lr=0.1] Epoch 592/4000: train_loss=0.0068  test_loss=46.4756  λ_max=1.6485\n",
      "[Muon | lr=0.1] Epoch 593/4000: train_loss=0.0072  test_loss=46.5052  λ_max=1.6680\n",
      "[Muon | lr=0.1] Iter 9500: loss=0.0139\n",
      "[Muon | lr=0.1] Epoch 594/4000: train_loss=0.0066  test_loss=46.5283  λ_max=1.7871\n",
      "[Muon | lr=0.1] Epoch 595/4000: train_loss=0.0060  test_loss=46.4087  λ_max=1.6694\n",
      "[Muon | lr=0.1] Epoch 596/4000: train_loss=0.0056  test_loss=46.4159  λ_max=1.7246\n",
      "[Muon | lr=0.1] Epoch 597/4000: train_loss=0.0063  test_loss=46.4190  λ_max=1.6575\n",
      "[Muon | lr=0.1] Epoch 598/4000: train_loss=0.0062  test_loss=46.4733  λ_max=1.7259\n",
      "[Muon | lr=0.1] Epoch 599/4000: train_loss=0.0061  test_loss=46.5554  λ_max=1.8424\n",
      "[Muon | lr=0.1] Iter 9600: loss=0.0051\n",
      "[Muon | lr=0.1] Epoch 600/4000: train_loss=0.0055  test_loss=46.5561  λ_max=1.6828\n",
      "[Muon | lr=0.1] Epoch 601/4000: train_loss=0.0059  test_loss=46.6637  λ_max=1.6940\n",
      "[Muon | lr=0.1] Epoch 602/4000: train_loss=0.0060  test_loss=46.8022  λ_max=1.8374\n",
      "[Muon | lr=0.1] Epoch 603/4000: train_loss=0.0060  test_loss=46.9110  λ_max=1.6325\n",
      "[Muon | lr=0.1] Epoch 604/4000: train_loss=0.0071  test_loss=46.9482  λ_max=1.7153\n",
      "[Muon | lr=0.1] Epoch 605/4000: train_loss=0.0064  test_loss=47.0872  λ_max=1.7521\n",
      "[Muon | lr=0.1] Epoch 606/4000: train_loss=0.0070  test_loss=47.1615  λ_max=1.7012\n",
      "[Muon | lr=0.1] Iter 9700: loss=0.0041\n",
      "[Muon | lr=0.1] Epoch 607/4000: train_loss=0.0065  test_loss=47.0654  λ_max=1.7047\n",
      "[Muon | lr=0.1] Epoch 608/4000: train_loss=0.0067  test_loss=46.9377  λ_max=1.6337\n",
      "[Muon | lr=0.1] Epoch 609/4000: train_loss=0.0062  test_loss=47.0207  λ_max=1.6128\n",
      "[Muon | lr=0.1] Epoch 610/4000: train_loss=0.0059  test_loss=47.1472  λ_max=1.7529\n",
      "[Muon | lr=0.1] Epoch 611/4000: train_loss=0.0064  test_loss=47.1841  λ_max=1.7145\n",
      "[Muon | lr=0.1] Epoch 612/4000: train_loss=0.0065  test_loss=47.2285  λ_max=1.7845\n",
      "[Muon | lr=0.1] Iter 9800: loss=0.0049\n",
      "[Muon | lr=0.1] Epoch 613/4000: train_loss=0.0051  test_loss=47.3297  λ_max=1.6350\n",
      "[Muon | lr=0.1] Epoch 614/4000: train_loss=0.0062  test_loss=47.5252  λ_max=1.7255\n",
      "[Muon | lr=0.1] Epoch 615/4000: train_loss=0.0060  test_loss=47.6709  λ_max=1.8514\n",
      "[Muon | lr=0.1] Epoch 616/4000: train_loss=0.0066  test_loss=47.6363  λ_max=1.7746\n",
      "[Muon | lr=0.1] Epoch 617/4000: train_loss=0.0063  test_loss=47.7686  λ_max=1.7439\n",
      "[Muon | lr=0.1] Epoch 618/4000: train_loss=0.0066  test_loss=47.8784  λ_max=1.7546\n",
      "[Muon | lr=0.1] Iter 9900: loss=0.0089\n",
      "[Muon | lr=0.1] Epoch 619/4000: train_loss=0.0062  test_loss=47.8563  λ_max=1.7748\n",
      "[Muon | lr=0.1] Epoch 620/4000: train_loss=0.0063  test_loss=47.9718  λ_max=1.7360\n",
      "[Muon | lr=0.1] Epoch 621/4000: train_loss=0.0062  test_loss=48.2360  λ_max=1.7172\n",
      "[Muon | lr=0.1] Epoch 622/4000: train_loss=0.0061  test_loss=48.3807  λ_max=1.8094\n",
      "[Muon | lr=0.1] Epoch 623/4000: train_loss=0.0066  test_loss=48.4204  λ_max=1.8769\n",
      "[Muon | lr=0.1] Epoch 624/4000: train_loss=0.0066  test_loss=48.4649  λ_max=1.7422\n",
      "[Muon | lr=0.1] Iter 10000: loss=0.0038\n",
      "[Muon | lr=0.1] Epoch 625/4000: train_loss=0.0062  test_loss=48.4983  λ_max=1.6942\n",
      "[Muon | lr=0.1] Epoch 626/4000: train_loss=0.0061  test_loss=48.5586  λ_max=1.7443\n",
      "[Muon | lr=0.1] Epoch 627/4000: train_loss=0.0061  test_loss=48.5749  λ_max=1.7109\n",
      "[Muon | lr=0.1] Epoch 628/4000: train_loss=0.0049  test_loss=48.6039  λ_max=1.9131\n",
      "[Muon | lr=0.1] Epoch 629/4000: train_loss=0.0067  test_loss=48.5514  λ_max=1.8991\n",
      "[Muon | lr=0.1] Epoch 630/4000: train_loss=0.0067  test_loss=48.7203  λ_max=1.7696\n",
      "[Muon | lr=0.1] Epoch 631/4000: train_loss=0.0054  test_loss=48.8453  λ_max=1.7155\n",
      "[Muon | lr=0.1] Iter 10100: loss=0.0056\n",
      "[Muon | lr=0.1] Epoch 632/4000: train_loss=0.0056  test_loss=48.9037  λ_max=1.6223\n",
      "[Muon | lr=0.1] Epoch 633/4000: train_loss=0.0066  test_loss=49.0112  λ_max=1.7350\n",
      "[Muon | lr=0.1] Epoch 634/4000: train_loss=0.0054  test_loss=49.0364  λ_max=1.8031\n",
      "[Muon | lr=0.1] Epoch 635/4000: train_loss=0.0060  test_loss=48.9466  λ_max=1.8416\n",
      "[Muon | lr=0.1] Epoch 636/4000: train_loss=0.0069  test_loss=49.0136  λ_max=1.8281\n",
      "[Muon | lr=0.1] Epoch 637/4000: train_loss=0.0058  test_loss=49.1361  λ_max=1.7750\n",
      "[Muon | lr=0.1] Iter 10200: loss=0.0023\n",
      "[Muon | lr=0.1] Epoch 638/4000: train_loss=0.0061  test_loss=49.1460  λ_max=1.7076\n",
      "[Muon | lr=0.1] Epoch 639/4000: train_loss=0.0060  test_loss=49.1785  λ_max=1.7268\n",
      "[Muon | lr=0.1] Epoch 640/4000: train_loss=0.0064  test_loss=49.1529  λ_max=1.7240\n",
      "[Muon | lr=0.1] Epoch 641/4000: train_loss=0.0062  test_loss=49.2523  λ_max=1.7385\n",
      "[Muon | lr=0.1] Epoch 642/4000: train_loss=0.0052  test_loss=49.2658  λ_max=1.9262\n",
      "[Muon | lr=0.1] Epoch 643/4000: train_loss=0.0059  test_loss=49.4241  λ_max=1.7109\n",
      "[Muon | lr=0.1] Iter 10300: loss=0.0058\n",
      "[Muon | lr=0.1] Epoch 644/4000: train_loss=0.0058  test_loss=49.4947  λ_max=1.6504\n",
      "[Muon | lr=0.1] Epoch 645/4000: train_loss=0.0060  test_loss=49.5207  λ_max=1.7904\n",
      "[Muon | lr=0.1] Epoch 646/4000: train_loss=0.0061  test_loss=49.6089  λ_max=1.8738\n",
      "[Muon | lr=0.1] Epoch 647/4000: train_loss=0.0057  test_loss=49.8217  λ_max=1.7306\n",
      "[Muon | lr=0.1] Epoch 648/4000: train_loss=0.0058  test_loss=49.9626  λ_max=1.7649\n",
      "[Muon | lr=0.1] Epoch 649/4000: train_loss=0.0060  test_loss=50.1478  λ_max=1.6625\n",
      "[Muon | lr=0.1] Iter 10400: loss=0.0124\n",
      "[Muon | lr=0.1] Epoch 650/4000: train_loss=0.0064  test_loss=50.1540  λ_max=1.9090\n",
      "[Muon | lr=0.1] Epoch 651/4000: train_loss=0.0066  test_loss=50.1835  λ_max=1.8098\n",
      "[Muon | lr=0.1] Epoch 652/4000: train_loss=0.0063  test_loss=50.3308  λ_max=1.9001\n",
      "[Muon | lr=0.1] Epoch 653/4000: train_loss=0.0058  test_loss=50.5862  λ_max=1.8119\n",
      "[Muon | lr=0.1] Epoch 654/4000: train_loss=0.0068  test_loss=50.6386  λ_max=1.7898\n",
      "[Muon | lr=0.1] Epoch 655/4000: train_loss=0.0057  test_loss=50.6989  λ_max=1.7729\n",
      "[Muon | lr=0.1] Epoch 656/4000: train_loss=0.0065  test_loss=50.7664  λ_max=1.8614\n",
      "[Muon | lr=0.1] Iter 10500: loss=0.0025\n",
      "[Muon | lr=0.1] Epoch 657/4000: train_loss=0.0055  test_loss=50.7688  λ_max=1.6290\n",
      "[Muon | lr=0.1] Epoch 658/4000: train_loss=0.0060  test_loss=50.7868  λ_max=1.7499\n",
      "[Muon | lr=0.1] Epoch 659/4000: train_loss=0.0056  test_loss=50.7822  λ_max=1.7897\n",
      "[Muon | lr=0.1] Epoch 660/4000: train_loss=0.0061  test_loss=51.0702  λ_max=1.8220\n",
      "[Muon | lr=0.1] Epoch 661/4000: train_loss=0.0061  test_loss=51.0530  λ_max=1.8222\n",
      "[Muon | lr=0.1] Epoch 662/4000: train_loss=0.0057  test_loss=51.0811  λ_max=1.8236\n",
      "[Muon | lr=0.1] Iter 10600: loss=0.0064\n",
      "[Muon | lr=0.1] Epoch 663/4000: train_loss=0.0072  test_loss=51.2312  λ_max=1.7773\n",
      "[Muon | lr=0.1] Epoch 664/4000: train_loss=0.0069  test_loss=51.4363  λ_max=1.9001\n",
      "[Muon | lr=0.1] Epoch 665/4000: train_loss=0.0062  test_loss=51.7507  λ_max=1.7845\n",
      "[Muon | lr=0.1] Epoch 666/4000: train_loss=0.0060  test_loss=51.8105  λ_max=1.7740\n",
      "[Muon | lr=0.1] Epoch 667/4000: train_loss=0.0063  test_loss=51.8639  λ_max=1.7180\n",
      "[Muon | lr=0.1] Epoch 668/4000: train_loss=0.0064  test_loss=51.8918  λ_max=1.8377\n",
      "[Muon | lr=0.1] Iter 10700: loss=0.0142\n",
      "[Muon | lr=0.1] Epoch 669/4000: train_loss=0.0063  test_loss=51.9212  λ_max=1.7148\n",
      "[Muon | lr=0.1] Epoch 670/4000: train_loss=0.0055  test_loss=52.0299  λ_max=1.8206\n",
      "[Muon | lr=0.1] Epoch 671/4000: train_loss=0.0057  test_loss=52.1261  λ_max=1.8226\n",
      "[Muon | lr=0.1] Epoch 672/4000: train_loss=0.0072  test_loss=52.1106  λ_max=1.7807\n",
      "[Muon | lr=0.1] Epoch 673/4000: train_loss=0.0070  test_loss=52.0555  λ_max=1.9483\n",
      "[Muon | lr=0.1] Epoch 674/4000: train_loss=0.0062  test_loss=52.0766  λ_max=1.8966\n",
      "[Muon | lr=0.1] Iter 10800: loss=0.0111\n",
      "[Muon | lr=0.1] Epoch 675/4000: train_loss=0.0061  test_loss=52.1007  λ_max=1.8045\n",
      "[Muon | lr=0.1] Epoch 676/4000: train_loss=0.0061  test_loss=52.1829  λ_max=1.8386\n",
      "[Muon | lr=0.1] Epoch 677/4000: train_loss=0.0057  test_loss=52.1807  λ_max=1.7969\n",
      "[Muon | lr=0.1] Epoch 678/4000: train_loss=0.0051  test_loss=52.1668  λ_max=1.8914\n",
      "[Muon | lr=0.1] Epoch 679/4000: train_loss=0.0066  test_loss=52.3675  λ_max=1.7408\n",
      "[Muon | lr=0.1] Epoch 680/4000: train_loss=0.0059  test_loss=52.5423  λ_max=1.6969\n",
      "[Muon | lr=0.1] Epoch 681/4000: train_loss=0.0056  test_loss=52.5522  λ_max=1.7450\n",
      "[Muon | lr=0.1] Iter 10900: loss=0.0044\n",
      "[Muon | lr=0.1] Epoch 682/4000: train_loss=0.0059  test_loss=52.5906  λ_max=1.8264\n",
      "[Muon | lr=0.1] Epoch 683/4000: train_loss=0.0065  test_loss=52.6114  λ_max=1.9689\n",
      "[Muon | lr=0.1] Epoch 684/4000: train_loss=0.0056  test_loss=52.6457  λ_max=2.0173\n",
      "[Muon | lr=0.1] Epoch 685/4000: train_loss=0.0066  test_loss=52.6887  λ_max=1.7446\n",
      "[Muon | lr=0.1] Epoch 686/4000: train_loss=0.0057  test_loss=52.6589  λ_max=1.8229\n",
      "[Muon | lr=0.1] Epoch 687/4000: train_loss=0.0053  test_loss=52.6989  λ_max=2.0302\n",
      "[Muon | lr=0.1] Iter 11000: loss=0.0056\n",
      "[Muon | lr=0.1] Epoch 688/4000: train_loss=0.0067  test_loss=52.7882  λ_max=2.0115\n",
      "[Muon | lr=0.1] Epoch 689/4000: train_loss=0.0069  test_loss=52.9350  λ_max=1.7346\n",
      "[Muon | lr=0.1] Epoch 690/4000: train_loss=0.0060  test_loss=53.0135  λ_max=1.8193\n",
      "[Muon | lr=0.1] Epoch 691/4000: train_loss=0.0060  test_loss=53.1496  λ_max=1.8230\n",
      "[Muon | lr=0.1] Epoch 692/4000: train_loss=0.0071  test_loss=53.2076  λ_max=1.8674\n",
      "[Muon | lr=0.1] Epoch 693/4000: train_loss=0.0067  test_loss=53.2951  λ_max=1.8796\n",
      "[Muon | lr=0.1] Iter 11100: loss=0.0075\n",
      "[Muon | lr=0.1] Epoch 694/4000: train_loss=0.0063  test_loss=53.3635  λ_max=1.8302\n",
      "[Muon | lr=0.1] Epoch 695/4000: train_loss=0.0061  test_loss=53.3544  λ_max=1.8016\n",
      "[Muon | lr=0.1] Epoch 696/4000: train_loss=0.0069  test_loss=53.3326  λ_max=1.8527\n",
      "[Muon | lr=0.1] Epoch 697/4000: train_loss=0.0061  test_loss=53.3302  λ_max=1.8629\n",
      "[Muon | lr=0.1] Epoch 698/4000: train_loss=0.0059  test_loss=53.4668  λ_max=1.7973\n",
      "[Muon | lr=0.1] Epoch 699/4000: train_loss=0.0055  test_loss=53.4803  λ_max=1.8978\n",
      "[Muon | lr=0.1] Iter 11200: loss=0.0165\n",
      "[Muon | lr=0.1] Epoch 700/4000: train_loss=0.0063  test_loss=53.5393  λ_max=1.7885\n",
      "[Muon | lr=0.1] Epoch 701/4000: train_loss=0.0067  test_loss=53.7496  λ_max=1.9797\n",
      "[Muon | lr=0.1] Epoch 702/4000: train_loss=0.0059  test_loss=53.8458  λ_max=2.0018\n",
      "[Muon | lr=0.1] Epoch 703/4000: train_loss=0.0060  test_loss=53.8557  λ_max=1.7704\n",
      "[Muon | lr=0.1] Epoch 704/4000: train_loss=0.0057  test_loss=54.0001  λ_max=1.9216\n",
      "[Muon | lr=0.1] Epoch 705/4000: train_loss=0.0064  test_loss=53.9763  λ_max=1.8193\n",
      "[Muon | lr=0.1] Epoch 706/4000: train_loss=0.0067  test_loss=54.0631  λ_max=1.8952\n",
      "[Muon | lr=0.1] Iter 11300: loss=0.0054\n",
      "[Muon | lr=0.1] Epoch 707/4000: train_loss=0.0066  test_loss=54.1086  λ_max=1.8132\n",
      "[Muon | lr=0.1] Epoch 708/4000: train_loss=0.0056  test_loss=53.9579  λ_max=1.8821\n",
      "[Muon | lr=0.1] Epoch 709/4000: train_loss=0.0062  test_loss=54.0300  λ_max=1.7568\n",
      "[Muon | lr=0.1] Epoch 710/4000: train_loss=0.0059  test_loss=54.0860  λ_max=1.8523\n",
      "[Muon | lr=0.1] Epoch 711/4000: train_loss=0.0054  test_loss=54.1274  λ_max=1.8157\n",
      "[Muon | lr=0.1] Epoch 712/4000: train_loss=0.0051  test_loss=54.3507  λ_max=1.8035\n",
      "[Muon | lr=0.1] Iter 11400: loss=0.0078\n",
      "[Muon | lr=0.1] Epoch 713/4000: train_loss=0.0059  test_loss=54.5497  λ_max=1.8569\n",
      "[Muon | lr=0.1] Epoch 714/4000: train_loss=0.0066  test_loss=54.5512  λ_max=1.8548\n",
      "[Muon | lr=0.1] Epoch 715/4000: train_loss=0.0062  test_loss=54.6586  λ_max=1.8634\n",
      "[Muon | lr=0.1] Epoch 716/4000: train_loss=0.0055  test_loss=54.6293  λ_max=1.8548\n",
      "[Muon | lr=0.1] Epoch 717/4000: train_loss=0.0065  test_loss=54.6133  λ_max=1.8471\n",
      "[Muon | lr=0.1] Epoch 718/4000: train_loss=0.0067  test_loss=54.5650  λ_max=1.9424\n",
      "[Muon | lr=0.1] Iter 11500: loss=0.0093\n",
      "[Muon | lr=0.1] Epoch 719/4000: train_loss=0.0059  test_loss=54.6821  λ_max=1.9459\n",
      "[Muon | lr=0.1] Epoch 720/4000: train_loss=0.0056  test_loss=54.6678  λ_max=1.8139\n",
      "[Muon | lr=0.1] Epoch 721/4000: train_loss=0.0060  test_loss=54.6922  λ_max=1.8543\n",
      "[Muon | lr=0.1] Epoch 722/4000: train_loss=0.0063  test_loss=54.7823  λ_max=1.8179\n",
      "[Muon | lr=0.1] Epoch 723/4000: train_loss=0.0057  test_loss=54.6974  λ_max=1.9921\n",
      "[Muon | lr=0.1] Epoch 724/4000: train_loss=0.0065  test_loss=54.6992  λ_max=1.8668\n",
      "[Muon | lr=0.1] Iter 11600: loss=0.0126\n",
      "[Muon | lr=0.1] Epoch 725/4000: train_loss=0.0069  test_loss=54.7597  λ_max=1.8664\n",
      "[Muon | lr=0.1] Epoch 726/4000: train_loss=0.0056  test_loss=54.7534  λ_max=2.0361\n",
      "[Muon | lr=0.1] Epoch 727/4000: train_loss=0.0070  test_loss=54.8740  λ_max=1.9520\n",
      "[Muon | lr=0.1] Epoch 728/4000: train_loss=0.0061  test_loss=54.9477  λ_max=2.0336\n",
      "[Muon | lr=0.1] Epoch 729/4000: train_loss=0.0065  test_loss=55.1005  λ_max=1.8007\n",
      "[Muon | lr=0.1] Epoch 730/4000: train_loss=0.0056  test_loss=55.0418  λ_max=1.7977\n",
      "[Muon | lr=0.1] Epoch 731/4000: train_loss=0.0059  test_loss=55.1490  λ_max=1.9930\n",
      "[Muon | lr=0.1] Iter 11700: loss=0.0026\n",
      "[Muon | lr=0.1] Epoch 732/4000: train_loss=0.0064  test_loss=55.3413  λ_max=1.8625\n",
      "[Muon | lr=0.1] Epoch 733/4000: train_loss=0.0058  test_loss=55.3169  λ_max=1.8422\n",
      "[Muon | lr=0.1] Epoch 734/4000: train_loss=0.0054  test_loss=55.3672  λ_max=1.8966\n",
      "[Muon | lr=0.1] Epoch 735/4000: train_loss=0.0066  test_loss=55.5282  λ_max=1.9196\n",
      "[Muon | lr=0.1] Epoch 736/4000: train_loss=0.0064  test_loss=55.5280  λ_max=1.7952\n",
      "[Muon | lr=0.1] Epoch 737/4000: train_loss=0.0060  test_loss=55.5754  λ_max=1.8889\n",
      "[Muon | lr=0.1] Iter 11800: loss=0.0039\n",
      "[Muon | lr=0.1] Epoch 738/4000: train_loss=0.0058  test_loss=55.4928  λ_max=1.9995\n",
      "[Muon | lr=0.1] Epoch 739/4000: train_loss=0.0063  test_loss=55.6237  λ_max=2.0012\n",
      "[Muon | lr=0.1] Epoch 740/4000: train_loss=0.0056  test_loss=55.6841  λ_max=1.9057\n",
      "[Muon | lr=0.1] Epoch 741/4000: train_loss=0.0055  test_loss=55.8333  λ_max=1.9540\n",
      "[Muon | lr=0.1] Epoch 742/4000: train_loss=0.0054  test_loss=55.9392  λ_max=1.9334\n",
      "[Muon | lr=0.1] Epoch 743/4000: train_loss=0.0053  test_loss=56.1095  λ_max=2.0015\n",
      "[Muon | lr=0.1] Iter 11900: loss=0.0102\n",
      "[Muon | lr=0.1] Epoch 744/4000: train_loss=0.0061  test_loss=56.2467  λ_max=1.9059\n",
      "[Muon | lr=0.1] Epoch 745/4000: train_loss=0.0058  test_loss=56.1732  λ_max=1.9860\n",
      "[Muon | lr=0.1] Epoch 746/4000: train_loss=0.0073  test_loss=56.1760  λ_max=1.9651\n",
      "[Muon | lr=0.1] Epoch 747/4000: train_loss=0.0064  test_loss=56.1915  λ_max=1.9510\n",
      "[Muon | lr=0.1] Epoch 748/4000: train_loss=0.0056  test_loss=56.2516  λ_max=1.8885\n",
      "[Muon | lr=0.1] Epoch 749/4000: train_loss=0.0052  test_loss=56.2960  λ_max=1.8568\n",
      "[Muon | lr=0.1] Iter 12000: loss=0.0085\n",
      "[Muon | lr=0.1] Epoch 750/4000: train_loss=0.0062  test_loss=56.2585  λ_max=1.9457\n",
      "[Muon | lr=0.1] Epoch 751/4000: train_loss=0.0052  test_loss=56.2755  λ_max=1.9880\n",
      "[Muon | lr=0.1] Epoch 752/4000: train_loss=0.0063  test_loss=56.2315  λ_max=1.7895\n",
      "[Muon | lr=0.1] Epoch 753/4000: train_loss=0.0062  test_loss=56.3394  λ_max=1.7766\n",
      "[Muon | lr=0.1] Epoch 754/4000: train_loss=0.0060  test_loss=56.4229  λ_max=1.8781\n",
      "[Muon | lr=0.1] Epoch 755/4000: train_loss=0.0058  test_loss=56.4143  λ_max=1.8594\n",
      "[Muon | lr=0.1] Epoch 756/4000: train_loss=0.0066  test_loss=56.4557  λ_max=1.9663\n",
      "[Muon | lr=0.1] Iter 12100: loss=0.0030\n",
      "[Muon | lr=0.1] Epoch 757/4000: train_loss=0.0059  test_loss=56.5988  λ_max=1.9462\n",
      "[Muon | lr=0.1] Epoch 758/4000: train_loss=0.0060  test_loss=56.5421  λ_max=1.8905\n",
      "[Muon | lr=0.1] Epoch 759/4000: train_loss=0.0062  test_loss=56.7296  λ_max=1.9229\n",
      "[Muon | lr=0.1] Epoch 760/4000: train_loss=0.0060  test_loss=56.7325  λ_max=1.8470\n",
      "[Muon | lr=0.1] Epoch 761/4000: train_loss=0.0055  test_loss=56.7435  λ_max=1.9698\n",
      "[Muon | lr=0.1] Epoch 762/4000: train_loss=0.0058  test_loss=56.8966  λ_max=1.9446\n",
      "[Muon | lr=0.1] Iter 12200: loss=0.0110\n",
      "[Muon | lr=0.1] Epoch 763/4000: train_loss=0.0054  test_loss=57.0382  λ_max=1.9257\n",
      "[Muon | lr=0.1] Epoch 764/4000: train_loss=0.0066  test_loss=57.1149  λ_max=1.9120\n",
      "[Muon | lr=0.1] Epoch 765/4000: train_loss=0.0060  test_loss=57.1889  λ_max=1.8902\n",
      "[Muon | lr=0.1] Epoch 766/4000: train_loss=0.0063  test_loss=57.1618  λ_max=1.9022\n",
      "[Muon | lr=0.1] Epoch 767/4000: train_loss=0.0057  test_loss=57.2290  λ_max=1.9366\n",
      "[Muon | lr=0.1] Epoch 768/4000: train_loss=0.0051  test_loss=57.3308  λ_max=2.0787\n",
      "[Muon | lr=0.1] Iter 12300: loss=0.0096\n",
      "[Muon | lr=0.1] Epoch 769/4000: train_loss=0.0059  test_loss=57.2600  λ_max=1.8526\n",
      "[Muon | lr=0.1] Epoch 770/4000: train_loss=0.0063  test_loss=57.4523  λ_max=1.9123\n",
      "[Muon | lr=0.1] Epoch 771/4000: train_loss=0.0057  test_loss=57.6445  λ_max=1.9322\n",
      "[Muon | lr=0.1] Epoch 772/4000: train_loss=0.0057  test_loss=57.7925  λ_max=1.9541\n",
      "[Muon | lr=0.1] Epoch 773/4000: train_loss=0.0058  test_loss=57.9139  λ_max=1.9504\n",
      "[Muon | lr=0.1] Epoch 774/4000: train_loss=0.0055  test_loss=57.9018  λ_max=1.9887\n",
      "[Muon | lr=0.1] Iter 12400: loss=0.0071\n",
      "[Muon | lr=0.1] Epoch 775/4000: train_loss=0.0061  test_loss=57.8035  λ_max=1.9682\n",
      "[Muon | lr=0.1] Epoch 776/4000: train_loss=0.0055  test_loss=58.0123  λ_max=2.0140\n",
      "[Muon | lr=0.1] Epoch 777/4000: train_loss=0.0048  test_loss=58.0032  λ_max=2.0679\n",
      "[Muon | lr=0.1] Epoch 778/4000: train_loss=0.0063  test_loss=58.0557  λ_max=2.0720\n",
      "[Muon | lr=0.1] Epoch 779/4000: train_loss=0.0054  test_loss=58.1497  λ_max=1.9772\n",
      "[Muon | lr=0.1] Epoch 780/4000: train_loss=0.0057  test_loss=58.2236  λ_max=2.0937\n",
      "[Muon | lr=0.1] Epoch 781/4000: train_loss=0.0063  test_loss=58.2735  λ_max=2.0052\n",
      "[Muon | lr=0.1] Iter 12500: loss=0.0027\n",
      "[Muon | lr=0.1] Epoch 782/4000: train_loss=0.0066  test_loss=58.3065  λ_max=1.9557\n",
      "[Muon | lr=0.1] Epoch 783/4000: train_loss=0.0063  test_loss=58.3561  λ_max=1.8660\n",
      "[Muon | lr=0.1] Epoch 784/4000: train_loss=0.0061  test_loss=58.4055  λ_max=2.0215\n",
      "[Muon | lr=0.1] Epoch 785/4000: train_loss=0.0060  test_loss=58.4924  λ_max=1.9496\n",
      "[Muon | lr=0.1] Epoch 786/4000: train_loss=0.0058  test_loss=58.4771  λ_max=2.0710\n",
      "[Muon | lr=0.1] Epoch 787/4000: train_loss=0.0057  test_loss=58.5455  λ_max=1.8726\n",
      "[Muon | lr=0.1] Iter 12600: loss=0.0077\n",
      "[Muon | lr=0.1] Epoch 788/4000: train_loss=0.0060  test_loss=58.3527  λ_max=2.0467\n",
      "[Muon | lr=0.1] Epoch 789/4000: train_loss=0.0056  test_loss=58.3942  λ_max=2.0781\n",
      "[Muon | lr=0.1] Epoch 790/4000: train_loss=0.0062  test_loss=58.3976  λ_max=2.0291\n",
      "[Muon | lr=0.1] Epoch 791/4000: train_loss=0.0052  test_loss=58.3960  λ_max=2.0784\n",
      "[Muon | lr=0.1] Epoch 792/4000: train_loss=0.0058  test_loss=58.4642  λ_max=2.0614\n",
      "[Muon | lr=0.1] Epoch 793/4000: train_loss=0.0064  test_loss=58.7735  λ_max=1.9344\n",
      "[Muon | lr=0.1] Iter 12700: loss=0.0072\n",
      "[Muon | lr=0.1] Epoch 794/4000: train_loss=0.0054  test_loss=58.9709  λ_max=1.9443\n",
      "[Muon | lr=0.1] Epoch 795/4000: train_loss=0.0053  test_loss=58.9027  λ_max=2.0073\n",
      "[Muon | lr=0.1] Epoch 796/4000: train_loss=0.0057  test_loss=59.1217  λ_max=2.0386\n",
      "[Muon | lr=0.1] Epoch 797/4000: train_loss=0.0066  test_loss=59.1815  λ_max=1.9283\n",
      "[Muon | lr=0.1] Epoch 798/4000: train_loss=0.0062  test_loss=59.2275  λ_max=1.9129\n",
      "[Muon | lr=0.1] Epoch 799/4000: train_loss=0.0059  test_loss=59.2244  λ_max=2.1943\n",
      "[Muon | lr=0.1] Iter 12800: loss=0.0101\n",
      "[Muon | lr=0.1] Epoch 800/4000: train_loss=0.0066  test_loss=59.1294  λ_max=1.9907\n",
      "[Muon | lr=0.1] Epoch 801/4000: train_loss=0.0060  test_loss=59.2068  λ_max=1.9869\n",
      "[Muon | lr=0.1] Epoch 802/4000: train_loss=0.0066  test_loss=59.2206  λ_max=1.9010\n",
      "[Muon | lr=0.1] Epoch 803/4000: train_loss=0.0059  test_loss=59.3669  λ_max=2.1053\n",
      "[Muon | lr=0.1] Epoch 804/4000: train_loss=0.0055  test_loss=59.3688  λ_max=2.0647\n",
      "[Muon | lr=0.1] Epoch 805/4000: train_loss=0.0054  test_loss=59.4392  λ_max=2.2202\n",
      "[Muon | lr=0.1] Epoch 806/4000: train_loss=0.0062  test_loss=59.4623  λ_max=2.0872\n",
      "[Muon | lr=0.1] Iter 12900: loss=0.0041\n",
      "[Muon | lr=0.1] Epoch 807/4000: train_loss=0.0054  test_loss=59.5187  λ_max=2.0447\n",
      "[Muon | lr=0.1] Epoch 808/4000: train_loss=0.0052  test_loss=59.6020  λ_max=2.0093\n",
      "[Muon | lr=0.1] Epoch 809/4000: train_loss=0.0059  test_loss=59.5930  λ_max=2.2183\n",
      "[Muon | lr=0.1] Epoch 810/4000: train_loss=0.0054  test_loss=59.7880  λ_max=2.0416\n",
      "[Muon | lr=0.1] Epoch 811/4000: train_loss=0.0056  test_loss=59.8776  λ_max=1.9484\n",
      "[Muon | lr=0.1] Epoch 812/4000: train_loss=0.0057  test_loss=60.0699  λ_max=2.0035\n",
      "[Muon | lr=0.1] Iter 13000: loss=0.0086\n",
      "[Muon | lr=0.1] Epoch 813/4000: train_loss=0.0067  test_loss=60.3294  λ_max=1.9042\n",
      "[Muon | lr=0.1] Epoch 814/4000: train_loss=0.0056  test_loss=60.1709  λ_max=1.9881\n",
      "[Muon | lr=0.1] Epoch 815/4000: train_loss=0.0050  test_loss=60.1082  λ_max=2.2247\n",
      "[Muon | lr=0.1] Epoch 816/4000: train_loss=0.0058  test_loss=60.1250  λ_max=1.9180\n",
      "[Muon | lr=0.1] Epoch 817/4000: train_loss=0.0067  test_loss=60.1077  λ_max=1.9813\n",
      "[Muon | lr=0.1] Epoch 818/4000: train_loss=0.0064  test_loss=60.1048  λ_max=2.0863\n",
      "[Muon | lr=0.1] Iter 13100: loss=0.0063\n",
      "[Muon | lr=0.1] Epoch 819/4000: train_loss=0.0058  test_loss=60.1558  λ_max=2.0837\n",
      "[Muon | lr=0.1] Epoch 820/4000: train_loss=0.0058  test_loss=60.1339  λ_max=1.9822\n",
      "[Muon | lr=0.1] Epoch 821/4000: train_loss=0.0056  test_loss=60.1749  λ_max=1.9339\n",
      "[Muon | lr=0.1] Epoch 822/4000: train_loss=0.0055  test_loss=60.3126  λ_max=1.8107\n",
      "[Muon | lr=0.1] Epoch 823/4000: train_loss=0.0059  test_loss=60.2702  λ_max=2.0168\n",
      "[Muon | lr=0.1] Epoch 824/4000: train_loss=0.0058  test_loss=60.2776  λ_max=1.9530\n",
      "[Muon | lr=0.1] Iter 13200: loss=0.0004\n",
      "[Muon | lr=0.1] Epoch 825/4000: train_loss=0.0047  test_loss=60.5159  λ_max=2.0332\n",
      "[Muon | lr=0.1] Epoch 826/4000: train_loss=0.0050  test_loss=60.6152  λ_max=2.1050\n",
      "[Muon | lr=0.1] Epoch 827/4000: train_loss=0.0061  test_loss=60.8008  λ_max=1.8874\n",
      "[Muon | lr=0.1] Epoch 828/4000: train_loss=0.0064  test_loss=60.9536  λ_max=2.1640\n",
      "[Muon | lr=0.1] Epoch 829/4000: train_loss=0.0053  test_loss=61.0612  λ_max=2.1246\n",
      "[Muon | lr=0.1] Epoch 830/4000: train_loss=0.0056  test_loss=61.0595  λ_max=2.2344\n",
      "[Muon | lr=0.1] Epoch 831/4000: train_loss=0.0066  test_loss=61.1896  λ_max=2.1113\n",
      "[Muon | lr=0.1] Iter 13300: loss=0.0038\n",
      "[Muon | lr=0.1] Epoch 832/4000: train_loss=0.0058  test_loss=61.1627  λ_max=1.9655\n",
      "[Muon | lr=0.1] Epoch 833/4000: train_loss=0.0050  test_loss=61.2619  λ_max=1.8361\n",
      "[Muon | lr=0.1] Epoch 834/4000: train_loss=0.0050  test_loss=61.4004  λ_max=2.1733\n",
      "[Muon | lr=0.1] Epoch 835/4000: train_loss=0.0056  test_loss=61.4048  λ_max=2.2183\n",
      "[Muon | lr=0.1] Epoch 836/4000: train_loss=0.0054  test_loss=61.3444  λ_max=2.0728\n",
      "[Muon | lr=0.1] Epoch 837/4000: train_loss=0.0062  test_loss=61.3856  λ_max=1.9710\n",
      "[Muon | lr=0.1] Iter 13400: loss=0.0083\n",
      "[Muon | lr=0.1] Epoch 838/4000: train_loss=0.0070  test_loss=61.3639  λ_max=2.0048\n",
      "[Muon | lr=0.1] Epoch 839/4000: train_loss=0.0060  test_loss=61.3729  λ_max=2.0322\n",
      "[Muon | lr=0.1] Epoch 840/4000: train_loss=0.0062  test_loss=61.5464  λ_max=2.1383\n",
      "[Muon | lr=0.1] Epoch 841/4000: train_loss=0.0055  test_loss=61.5610  λ_max=1.9840\n",
      "[Muon | lr=0.1] Epoch 842/4000: train_loss=0.0053  test_loss=61.6446  λ_max=2.1631\n",
      "[Muon | lr=0.1] Epoch 843/4000: train_loss=0.0057  test_loss=61.7352  λ_max=2.0208\n",
      "[Muon | lr=0.1] Iter 13500: loss=0.0068\n",
      "[Muon | lr=0.1] Epoch 844/4000: train_loss=0.0056  test_loss=61.8493  λ_max=2.0330\n",
      "[Muon | lr=0.1] Epoch 845/4000: train_loss=0.0054  test_loss=61.9201  λ_max=1.9375\n",
      "[Muon | lr=0.1] Epoch 846/4000: train_loss=0.0060  test_loss=61.9358  λ_max=2.4635\n",
      "[Muon | lr=0.1] Epoch 847/4000: train_loss=0.0053  test_loss=62.0029  λ_max=2.0821\n",
      "[Muon | lr=0.1] Epoch 848/4000: train_loss=0.0058  test_loss=62.1278  λ_max=2.1219\n",
      "[Muon | lr=0.1] Epoch 849/4000: train_loss=0.0066  test_loss=62.4078  λ_max=2.1339\n",
      "[Muon | lr=0.1] Iter 13600: loss=0.0107\n",
      "[Muon | lr=0.1] Epoch 850/4000: train_loss=0.0066  test_loss=62.4781  λ_max=2.2160\n",
      "[Muon | lr=0.1] Epoch 851/4000: train_loss=0.0062  test_loss=62.6108  λ_max=2.0261\n",
      "[Muon | lr=0.1] Epoch 852/4000: train_loss=0.0063  test_loss=62.8562  λ_max=2.1468\n",
      "[Muon | lr=0.1] Epoch 853/4000: train_loss=0.0051  test_loss=62.7568  λ_max=2.1104\n",
      "[Muon | lr=0.1] Epoch 854/4000: train_loss=0.0052  test_loss=62.5945  λ_max=2.1159\n",
      "[Muon | lr=0.1] Epoch 855/4000: train_loss=0.0061  test_loss=62.6339  λ_max=2.0269\n",
      "[Muon | lr=0.1] Epoch 856/4000: train_loss=0.0061  test_loss=62.6061  λ_max=1.8707\n",
      "[Muon | lr=0.1] Iter 13700: loss=0.0022\n",
      "[Muon | lr=0.1] Epoch 857/4000: train_loss=0.0054  test_loss=62.7228  λ_max=2.0631\n",
      "[Muon | lr=0.1] Epoch 858/4000: train_loss=0.0048  test_loss=62.7595  λ_max=2.0874\n",
      "[Muon | lr=0.1] Epoch 859/4000: train_loss=0.0056  test_loss=62.8924  λ_max=2.0747\n",
      "[Muon | lr=0.1] Epoch 860/4000: train_loss=0.0066  test_loss=62.8286  λ_max=2.2173\n",
      "[Muon | lr=0.1] Epoch 861/4000: train_loss=0.0052  test_loss=62.9781  λ_max=1.9973\n",
      "[Muon | lr=0.1] Epoch 862/4000: train_loss=0.0057  test_loss=63.0894  λ_max=1.9938\n",
      "[Muon | lr=0.1] Iter 13800: loss=0.0053\n",
      "[Muon | lr=0.1] Epoch 863/4000: train_loss=0.0060  test_loss=63.0581  λ_max=2.0841\n",
      "[Muon | lr=0.1] Epoch 864/4000: train_loss=0.0055  test_loss=63.0167  λ_max=1.9373\n",
      "[Muon | lr=0.1] Epoch 865/4000: train_loss=0.0056  test_loss=63.1490  λ_max=1.9306\n",
      "[Muon | lr=0.1] Epoch 866/4000: train_loss=0.0064  test_loss=63.1750  λ_max=2.0706\n",
      "[Muon | lr=0.1] Epoch 867/4000: train_loss=0.0056  test_loss=63.2340  λ_max=2.1347\n",
      "[Muon | lr=0.1] Epoch 868/4000: train_loss=0.0069  test_loss=63.3810  λ_max=2.0646\n",
      "[Muon | lr=0.1] Iter 13900: loss=0.0139\n",
      "[Muon | lr=0.1] Epoch 869/4000: train_loss=0.0061  test_loss=63.4056  λ_max=2.0073\n",
      "[Muon | lr=0.1] Epoch 870/4000: train_loss=0.0055  test_loss=63.5321  λ_max=2.0071\n",
      "[Muon | lr=0.1] Epoch 871/4000: train_loss=0.0064  test_loss=63.5142  λ_max=2.0955\n",
      "[Muon | lr=0.1] Epoch 872/4000: train_loss=0.0065  test_loss=63.6039  λ_max=2.0150\n",
      "[Muon | lr=0.1] Epoch 873/4000: train_loss=0.0068  test_loss=63.6555  λ_max=2.0752\n",
      "[Muon | lr=0.1] Epoch 874/4000: train_loss=0.0064  test_loss=63.6016  λ_max=2.3037\n",
      "[Muon | lr=0.1] Iter 14000: loss=0.0105\n",
      "[Muon | lr=0.1] Epoch 875/4000: train_loss=0.0051  test_loss=63.7933  λ_max=2.4263\n",
      "[Muon | lr=0.1] Epoch 876/4000: train_loss=0.0055  test_loss=63.8253  λ_max=2.2014\n",
      "[Muon | lr=0.1] Epoch 877/4000: train_loss=0.0052  test_loss=63.8206  λ_max=2.1013\n",
      "[Muon | lr=0.1] Epoch 878/4000: train_loss=0.0052  test_loss=63.9054  λ_max=2.0821\n",
      "[Muon | lr=0.1] Epoch 879/4000: train_loss=0.0059  test_loss=64.0472  λ_max=2.0117\n",
      "[Muon | lr=0.1] Epoch 880/4000: train_loss=0.0052  test_loss=64.0098  λ_max=2.2117\n",
      "[Muon | lr=0.1] Epoch 881/4000: train_loss=0.0059  test_loss=64.0860  λ_max=2.2730\n",
      "[Muon | lr=0.1] Iter 14100: loss=0.0034\n",
      "[Muon | lr=0.1] Epoch 882/4000: train_loss=0.0065  test_loss=64.0368  λ_max=2.0128\n",
      "[Muon | lr=0.1] Epoch 883/4000: train_loss=0.0056  test_loss=64.1500  λ_max=2.2488\n",
      "[Muon | lr=0.1] Epoch 884/4000: train_loss=0.0055  test_loss=64.2431  λ_max=2.1288\n",
      "[Muon | lr=0.1] Epoch 885/4000: train_loss=0.0065  test_loss=64.2517  λ_max=1.9417\n",
      "[Muon | lr=0.1] Epoch 886/4000: train_loss=0.0053  test_loss=64.2232  λ_max=2.2013\n",
      "[Muon | lr=0.1] Epoch 887/4000: train_loss=0.0056  test_loss=64.3549  λ_max=2.2168\n",
      "[Muon | lr=0.1] Iter 14200: loss=0.0077\n",
      "[Muon | lr=0.1] Epoch 888/4000: train_loss=0.0058  test_loss=64.4338  λ_max=1.9987\n",
      "[Muon | lr=0.1] Epoch 889/4000: train_loss=0.0059  test_loss=64.5367  λ_max=2.0897\n",
      "[Muon | lr=0.1] Epoch 890/4000: train_loss=0.0059  test_loss=64.6728  λ_max=2.0959\n",
      "[Muon | lr=0.1] Epoch 891/4000: train_loss=0.0066  test_loss=64.5976  λ_max=2.1336\n",
      "[Muon | lr=0.1] Epoch 892/4000: train_loss=0.0060  test_loss=64.6072  λ_max=2.2751\n",
      "[Muon | lr=0.1] Epoch 893/4000: train_loss=0.0061  test_loss=64.6519  λ_max=2.1219\n",
      "[Muon | lr=0.1] Iter 14300: loss=0.0066\n",
      "[Muon | lr=0.1] Epoch 894/4000: train_loss=0.0059  test_loss=64.6386  λ_max=2.0963\n",
      "[Muon | lr=0.1] Epoch 895/4000: train_loss=0.0048  test_loss=64.8361  λ_max=2.1640\n",
      "[Muon | lr=0.1] Epoch 896/4000: train_loss=0.0056  test_loss=64.8317  λ_max=2.2124\n",
      "[Muon | lr=0.1] Epoch 897/4000: train_loss=0.0059  test_loss=64.8850  λ_max=2.1668\n",
      "[Muon | lr=0.1] Epoch 898/4000: train_loss=0.0041  test_loss=65.0757  λ_max=2.1001\n",
      "[Muon | lr=0.1] Epoch 899/4000: train_loss=0.0053  test_loss=64.9574  λ_max=2.1631\n",
      "[Muon | lr=0.1] Iter 14400: loss=0.0031\n",
      "[Muon | lr=0.1] Epoch 900/4000: train_loss=0.0053  test_loss=64.9690  λ_max=2.0005\n",
      "[Muon | lr=0.1] Epoch 901/4000: train_loss=0.0057  test_loss=65.1635  λ_max=2.2558\n",
      "[Muon | lr=0.1] Epoch 902/4000: train_loss=0.0047  test_loss=65.3478  λ_max=2.0113\n",
      "[Muon | lr=0.1] Epoch 903/4000: train_loss=0.0055  test_loss=65.5447  λ_max=2.1230\n",
      "[Muon | lr=0.1] Epoch 904/4000: train_loss=0.0061  test_loss=65.7757  λ_max=2.1070\n",
      "[Muon | lr=0.1] Epoch 905/4000: train_loss=0.0066  test_loss=65.8787  λ_max=2.1734\n",
      "[Muon | lr=0.1] Epoch 906/4000: train_loss=0.0056  test_loss=65.8684  λ_max=2.3315\n",
      "[Muon | lr=0.1] Iter 14500: loss=0.0017\n",
      "[Muon | lr=0.1] Epoch 907/4000: train_loss=0.0048  test_loss=65.8718  λ_max=2.0599\n",
      "[Muon | lr=0.1] Epoch 908/4000: train_loss=0.0051  test_loss=65.8338  λ_max=2.1540\n",
      "[Muon | lr=0.1] Epoch 909/4000: train_loss=0.0056  test_loss=65.8489  λ_max=2.0112\n",
      "[Muon | lr=0.1] Epoch 910/4000: train_loss=0.0049  test_loss=65.8624  λ_max=2.3677\n",
      "[Muon | lr=0.1] Epoch 911/4000: train_loss=0.0059  test_loss=65.8443  λ_max=2.0945\n",
      "[Muon | lr=0.1] Epoch 912/4000: train_loss=0.0056  test_loss=66.0776  λ_max=2.2782\n",
      "[Muon | lr=0.1] Iter 14600: loss=0.0068\n",
      "[Muon | lr=0.1] Epoch 913/4000: train_loss=0.0063  test_loss=66.1543  λ_max=2.2396\n",
      "[Muon | lr=0.1] Epoch 914/4000: train_loss=0.0060  test_loss=66.0970  λ_max=2.1491\n",
      "[Muon | lr=0.1] Epoch 915/4000: train_loss=0.0057  test_loss=66.2901  λ_max=2.1772\n",
      "[Muon | lr=0.1] Epoch 916/4000: train_loss=0.0058  test_loss=66.3210  λ_max=2.1420\n",
      "[Muon | lr=0.1] Epoch 917/4000: train_loss=0.0057  test_loss=66.1514  λ_max=2.0899\n",
      "[Muon | lr=0.1] Epoch 918/4000: train_loss=0.0048  test_loss=66.1999  λ_max=2.3891\n",
      "[Muon | lr=0.1] Iter 14700: loss=0.0078\n",
      "[Muon | lr=0.1] Epoch 919/4000: train_loss=0.0060  test_loss=66.3670  λ_max=2.2110\n",
      "[Muon | lr=0.1] Epoch 920/4000: train_loss=0.0053  test_loss=66.4221  λ_max=2.2522\n",
      "[Muon | lr=0.1] Epoch 921/4000: train_loss=0.0053  test_loss=66.4507  λ_max=2.3820\n",
      "[Muon | lr=0.1] Epoch 922/4000: train_loss=0.0053  test_loss=66.5951  λ_max=2.1618\n",
      "[Muon | lr=0.1] Epoch 923/4000: train_loss=0.0062  test_loss=66.7311  λ_max=2.0017\n",
      "[Muon | lr=0.1] Epoch 924/4000: train_loss=0.0053  test_loss=66.6454  λ_max=2.2495\n",
      "[Muon | lr=0.1] Iter 14800: loss=0.0092\n",
      "[Muon | lr=0.1] Epoch 925/4000: train_loss=0.0055  test_loss=66.5966  λ_max=2.2599\n",
      "[Muon | lr=0.1] Epoch 926/4000: train_loss=0.0055  test_loss=66.5154  λ_max=2.1380\n",
      "[Muon | lr=0.1] Epoch 927/4000: train_loss=0.0059  test_loss=66.6014  λ_max=2.0964\n",
      "[Muon | lr=0.1] Epoch 928/4000: train_loss=0.0060  test_loss=66.6106  λ_max=2.2322\n",
      "[Muon | lr=0.1] Epoch 929/4000: train_loss=0.0055  test_loss=66.7388  λ_max=2.1841\n",
      "[Muon | lr=0.1] Epoch 930/4000: train_loss=0.0054  test_loss=66.7890  λ_max=2.1912\n",
      "[Muon | lr=0.1] Epoch 931/4000: train_loss=0.0058  test_loss=66.9364  λ_max=2.2639\n",
      "[Muon | lr=0.1] Iter 14900: loss=0.0022\n",
      "[Muon | lr=0.1] Epoch 932/4000: train_loss=0.0054  test_loss=67.0302  λ_max=2.0674\n",
      "[Muon | lr=0.1] Epoch 933/4000: train_loss=0.0043  test_loss=67.0549  λ_max=2.2119\n",
      "[Muon | lr=0.1] Epoch 934/4000: train_loss=0.0061  test_loss=67.1788  λ_max=2.1918\n",
      "[Muon | lr=0.1] Epoch 935/4000: train_loss=0.0061  test_loss=67.3534  λ_max=2.3170\n",
      "[Muon | lr=0.1] Epoch 936/4000: train_loss=0.0062  test_loss=67.3521  λ_max=2.1140\n",
      "[Muon | lr=0.1] Epoch 937/4000: train_loss=0.0049  test_loss=67.3382  λ_max=2.2405\n",
      "[Muon | lr=0.1] Iter 15000: loss=0.0074\n",
      "[Muon | lr=0.1] Epoch 938/4000: train_loss=0.0051  test_loss=67.4674  λ_max=2.1458\n",
      "[Muon | lr=0.1] Epoch 939/4000: train_loss=0.0054  test_loss=67.6499  λ_max=2.2702\n",
      "[Muon | lr=0.1] Epoch 940/4000: train_loss=0.0061  test_loss=67.6914  λ_max=2.0984\n",
      "[Muon | lr=0.1] Epoch 941/4000: train_loss=0.0052  test_loss=67.6078  λ_max=2.2352\n",
      "[Muon | lr=0.1] Epoch 942/4000: train_loss=0.0060  test_loss=67.7940  λ_max=2.0723\n",
      "[Muon | lr=0.1] Epoch 943/4000: train_loss=0.0056  test_loss=67.8948  λ_max=2.4152\n",
      "[Muon | lr=0.1] Iter 15100: loss=0.0092\n",
      "[Muon | lr=0.1] Epoch 944/4000: train_loss=0.0059  test_loss=67.8852  λ_max=2.2508\n",
      "[Muon | lr=0.1] Epoch 945/4000: train_loss=0.0054  test_loss=67.8898  λ_max=2.1314\n",
      "[Muon | lr=0.1] Epoch 946/4000: train_loss=0.0060  test_loss=67.9596  λ_max=2.0606\n",
      "[Muon | lr=0.1] Epoch 947/4000: train_loss=0.0058  test_loss=67.9988  λ_max=2.2631\n",
      "[Muon | lr=0.1] Epoch 948/4000: train_loss=0.0063  test_loss=68.2013  λ_max=2.0893\n",
      "[Muon | lr=0.1] Epoch 949/4000: train_loss=0.0053  test_loss=68.3757  λ_max=2.2060\n",
      "[Muon | lr=0.1] Iter 15200: loss=0.0075\n",
      "[Muon | lr=0.1] Epoch 950/4000: train_loss=0.0055  test_loss=68.4753  λ_max=2.2852\n",
      "[Muon | lr=0.1] Epoch 951/4000: train_loss=0.0057  test_loss=68.5103  λ_max=2.2037\n",
      "[Muon | lr=0.1] Epoch 952/4000: train_loss=0.0058  test_loss=68.6450  λ_max=2.1846\n",
      "[Muon | lr=0.1] Epoch 953/4000: train_loss=0.0054  test_loss=68.6475  λ_max=2.0826\n",
      "[Muon | lr=0.1] Epoch 954/4000: train_loss=0.0062  test_loss=68.7254  λ_max=2.1478\n",
      "[Muon | lr=0.1] Epoch 955/4000: train_loss=0.0051  test_loss=68.6936  λ_max=2.2048\n",
      "[Muon | lr=0.1] Epoch 956/4000: train_loss=0.0061  test_loss=68.9267  λ_max=2.1884\n",
      "[Muon | lr=0.1] Iter 15300: loss=0.0028\n",
      "[Muon | lr=0.1] Epoch 957/4000: train_loss=0.0047  test_loss=69.0817  λ_max=2.4815\n",
      "[Muon | lr=0.1] Epoch 958/4000: train_loss=0.0047  test_loss=69.0890  λ_max=2.2181\n",
      "[Muon | lr=0.1] Epoch 959/4000: train_loss=0.0058  test_loss=69.0352  λ_max=2.2844\n",
      "[Muon | lr=0.1] Epoch 960/4000: train_loss=0.0058  test_loss=69.1941  λ_max=2.2073\n",
      "[Muon | lr=0.1] Epoch 961/4000: train_loss=0.0056  test_loss=69.3007  λ_max=2.3976\n",
      "[Muon | lr=0.1] Epoch 962/4000: train_loss=0.0059  test_loss=69.2976  λ_max=2.2503\n",
      "[Muon | lr=0.1] Iter 15400: loss=0.0078\n",
      "[Muon | lr=0.1] Epoch 963/4000: train_loss=0.0064  test_loss=69.3647  λ_max=2.2682\n",
      "[Muon | lr=0.1] Epoch 964/4000: train_loss=0.0056  test_loss=69.4955  λ_max=2.0653\n",
      "[Muon | lr=0.1] Epoch 965/4000: train_loss=0.0054  test_loss=69.6535  λ_max=2.2383\n",
      "[Muon | lr=0.1] Epoch 966/4000: train_loss=0.0056  test_loss=69.5680  λ_max=2.2660\n",
      "[Muon | lr=0.1] Epoch 967/4000: train_loss=0.0060  test_loss=69.6180  λ_max=2.1769\n",
      "[Muon | lr=0.1] Epoch 968/4000: train_loss=0.0055  test_loss=69.6536  λ_max=2.2594\n",
      "[Muon | lr=0.1] Iter 15500: loss=0.0048\n",
      "[Muon | lr=0.1] Epoch 969/4000: train_loss=0.0054  test_loss=69.6315  λ_max=2.2462\n",
      "[Muon | lr=0.1] Epoch 970/4000: train_loss=0.0049  test_loss=69.7254  λ_max=2.3199\n",
      "[Muon | lr=0.1] Epoch 971/4000: train_loss=0.0058  test_loss=69.8499  λ_max=2.2148\n",
      "[Muon | lr=0.1] Epoch 972/4000: train_loss=0.0058  test_loss=69.9122  λ_max=2.1386\n",
      "[Muon | lr=0.1] Epoch 973/4000: train_loss=0.0053  test_loss=70.0035  λ_max=2.2315\n",
      "[Muon | lr=0.1] Epoch 974/4000: train_loss=0.0058  test_loss=70.0288  λ_max=2.2393\n",
      "[Muon | lr=0.1] Iter 15600: loss=0.0143\n",
      "[Muon | lr=0.1] Epoch 975/4000: train_loss=0.0057  test_loss=70.1999  λ_max=2.3624\n",
      "[Muon | lr=0.1] Epoch 976/4000: train_loss=0.0057  test_loss=70.3417  λ_max=2.1388\n",
      "[Muon | lr=0.1] Epoch 977/4000: train_loss=0.0049  test_loss=70.5066  λ_max=2.2040\n",
      "[Muon | lr=0.1] Epoch 978/4000: train_loss=0.0050  test_loss=70.5184  λ_max=2.3871\n",
      "[Muon | lr=0.1] Epoch 979/4000: train_loss=0.0061  test_loss=70.5195  λ_max=2.5861\n",
      "[Muon | lr=0.1] Epoch 980/4000: train_loss=0.0063  test_loss=70.5359  λ_max=2.1952\n",
      "[Muon | lr=0.1] Epoch 981/4000: train_loss=0.0059  test_loss=70.7082  λ_max=2.2085\n",
      "[Muon | lr=0.1] Iter 15700: loss=0.0034\n",
      "[Muon | lr=0.1] Epoch 982/4000: train_loss=0.0059  test_loss=70.7868  λ_max=2.1280\n",
      "[Muon | lr=0.1] Epoch 983/4000: train_loss=0.0052  test_loss=70.8105  λ_max=2.2514\n",
      "[Muon | lr=0.1] Epoch 984/4000: train_loss=0.0052  test_loss=71.0454  λ_max=2.2031\n",
      "[Muon | lr=0.1] Epoch 985/4000: train_loss=0.0053  test_loss=71.1886  λ_max=2.2173\n",
      "[Muon | lr=0.1] Epoch 986/4000: train_loss=0.0054  test_loss=71.1794  λ_max=2.2977\n",
      "[Muon | lr=0.1] Epoch 987/4000: train_loss=0.0050  test_loss=71.2661  λ_max=2.0914\n",
      "[Muon | lr=0.1] Iter 15800: loss=0.0072\n",
      "[Muon | lr=0.1] Epoch 988/4000: train_loss=0.0059  test_loss=71.4175  λ_max=2.5583\n",
      "[Muon | lr=0.1] Epoch 989/4000: train_loss=0.0053  test_loss=71.5372  λ_max=2.2603\n",
      "[Muon | lr=0.1] Epoch 990/4000: train_loss=0.0052  test_loss=71.5598  λ_max=2.1847\n",
      "[Muon | lr=0.1] Epoch 991/4000: train_loss=0.0058  test_loss=71.6393  λ_max=2.3533\n",
      "[Muon | lr=0.1] Epoch 992/4000: train_loss=0.0057  test_loss=71.5211  λ_max=2.2213\n",
      "[Muon | lr=0.1] Epoch 993/4000: train_loss=0.0066  test_loss=71.6654  λ_max=2.3030\n",
      "[Muon | lr=0.1] Iter 15900: loss=0.0083\n",
      "[Muon | lr=0.1] Epoch 994/4000: train_loss=0.0050  test_loss=71.6670  λ_max=2.0047\n",
      "[Muon | lr=0.1] Epoch 995/4000: train_loss=0.0061  test_loss=71.7243  λ_max=2.3738\n",
      "[Muon | lr=0.1] Epoch 996/4000: train_loss=0.0052  test_loss=71.6873  λ_max=2.4549\n",
      "[Muon | lr=0.1] Epoch 997/4000: train_loss=0.0055  test_loss=71.8692  λ_max=2.3065\n",
      "[Muon | lr=0.1] Epoch 998/4000: train_loss=0.0050  test_loss=71.8415  λ_max=2.4105\n",
      "[Muon | lr=0.1] Epoch 999/4000: train_loss=0.0056  test_loss=71.9588  λ_max=2.4322\n",
      "[Muon | lr=0.1] Iter 16000: loss=0.0107\n",
      "[Muon | lr=0.1] Epoch 1000/4000: train_loss=0.0058  test_loss=72.0287  λ_max=2.4166\n",
      "[Muon | lr=0.1] Epoch 1001/4000: train_loss=0.0050  test_loss=72.0513  λ_max=2.3718\n",
      "[Muon | lr=0.1] Epoch 1002/4000: train_loss=0.0049  test_loss=72.2111  λ_max=2.3755\n",
      "[Muon | lr=0.1] Epoch 1003/4000: train_loss=0.0068  test_loss=72.1269  λ_max=2.2551\n",
      "[Muon | lr=0.1] Epoch 1004/4000: train_loss=0.0058  test_loss=72.3886  λ_max=2.3976\n",
      "[Muon | lr=0.1] Epoch 1005/4000: train_loss=0.0058  test_loss=72.4622  λ_max=2.2850\n",
      "[Muon | lr=0.1] Epoch 1006/4000: train_loss=0.0063  test_loss=72.5625  λ_max=2.4546\n",
      "[Muon | lr=0.1] Iter 16100: loss=0.0041\n",
      "[Muon | lr=0.1] Epoch 1007/4000: train_loss=0.0064  test_loss=72.6062  λ_max=2.3165\n",
      "[Muon | lr=0.1] Epoch 1008/4000: train_loss=0.0052  test_loss=72.5423  λ_max=2.4003\n",
      "[Muon | lr=0.1] Epoch 1009/4000: train_loss=0.0051  test_loss=72.5152  λ_max=2.2753\n",
      "[Muon | lr=0.1] Epoch 1010/4000: train_loss=0.0066  test_loss=72.4500  λ_max=2.3728\n",
      "[Muon | lr=0.1] Epoch 1011/4000: train_loss=0.0061  test_loss=72.4098  λ_max=2.3652\n",
      "[Muon | lr=0.1] Epoch 1012/4000: train_loss=0.0052  test_loss=72.6377  λ_max=2.4411\n",
      "[Muon | lr=0.1] Iter 16200: loss=0.0059\n",
      "[Muon | lr=0.1] Epoch 1013/4000: train_loss=0.0054  test_loss=72.7649  λ_max=2.2348\n",
      "[Muon | lr=0.1] Epoch 1014/4000: train_loss=0.0053  test_loss=72.7707  λ_max=2.7393\n",
      "[Muon | lr=0.1] Epoch 1015/4000: train_loss=0.0054  test_loss=72.8552  λ_max=2.3425\n",
      "[Muon | lr=0.1] Epoch 1016/4000: train_loss=0.0058  test_loss=72.8636  λ_max=2.3333\n",
      "[Muon | lr=0.1] Epoch 1017/4000: train_loss=0.0054  test_loss=72.9586  λ_max=2.2064\n",
      "[Muon | lr=0.1] Epoch 1018/4000: train_loss=0.0046  test_loss=73.1337  λ_max=2.5256\n",
      "[Muon | lr=0.1] Iter 16300: loss=0.0086\n",
      "[Muon | lr=0.1] Epoch 1019/4000: train_loss=0.0053  test_loss=73.1117  λ_max=2.3068\n",
      "[Muon | lr=0.1] Epoch 1020/4000: train_loss=0.0060  test_loss=73.2343  λ_max=2.3859\n",
      "[Muon | lr=0.1] Epoch 1021/4000: train_loss=0.0057  test_loss=73.3369  λ_max=2.2936\n",
      "[Muon | lr=0.1] Epoch 1022/4000: train_loss=0.0060  test_loss=73.3556  λ_max=2.3664\n",
      "[Muon | lr=0.1] Epoch 1023/4000: train_loss=0.0057  test_loss=73.4563  λ_max=2.3268\n",
      "[Muon | lr=0.1] Epoch 1024/4000: train_loss=0.0061  test_loss=73.6163  λ_max=2.2373\n",
      "[Muon | lr=0.1] Iter 16400: loss=0.0128\n",
      "[Muon | lr=0.1] Epoch 1025/4000: train_loss=0.0060  test_loss=73.5597  λ_max=2.3908\n",
      "[Muon | lr=0.1] Epoch 1026/4000: train_loss=0.0046  test_loss=73.5582  λ_max=2.2784\n",
      "[Muon | lr=0.1] Epoch 1027/4000: train_loss=0.0052  test_loss=73.5904  λ_max=2.3083\n",
      "[Muon | lr=0.1] Epoch 1028/4000: train_loss=0.0057  test_loss=73.4595  λ_max=2.3243\n",
      "[Muon | lr=0.1] Epoch 1029/4000: train_loss=0.0060  test_loss=73.4470  λ_max=2.2994\n",
      "[Muon | lr=0.1] Epoch 1030/4000: train_loss=0.0045  test_loss=73.5701  λ_max=2.4175\n",
      "[Muon | lr=0.1] Epoch 1031/4000: train_loss=0.0061  test_loss=73.6864  λ_max=2.5378\n",
      "[Muon | lr=0.1] Iter 16500: loss=0.0012\n",
      "[Muon | lr=0.1] Epoch 1032/4000: train_loss=0.0052  test_loss=73.7920  λ_max=2.4110\n",
      "[Muon | lr=0.1] Epoch 1033/4000: train_loss=0.0050  test_loss=73.9309  λ_max=2.2967\n",
      "[Muon | lr=0.1] Epoch 1034/4000: train_loss=0.0050  test_loss=74.0822  λ_max=2.5362\n",
      "[Muon | lr=0.1] Epoch 1035/4000: train_loss=0.0048  test_loss=74.1350  λ_max=2.2353\n",
      "[Muon | lr=0.1] Epoch 1036/4000: train_loss=0.0047  test_loss=74.3209  λ_max=2.3313\n",
      "[Muon | lr=0.1] Epoch 1037/4000: train_loss=0.0048  test_loss=74.5101  λ_max=2.3721\n",
      "[Muon | lr=0.1] Iter 16600: loss=0.0062\n",
      "[Muon | lr=0.1] Epoch 1038/4000: train_loss=0.0050  test_loss=74.6413  λ_max=2.5018\n",
      "[Muon | lr=0.1] Epoch 1039/4000: train_loss=0.0042  test_loss=74.9014  λ_max=2.4376\n",
      "[Muon | lr=0.1] Epoch 1040/4000: train_loss=0.0050  test_loss=74.8997  λ_max=2.2244\n",
      "[Muon | lr=0.1] Epoch 1041/4000: train_loss=0.0055  test_loss=75.0268  λ_max=2.4462\n",
      "[Muon | lr=0.1] Epoch 1042/4000: train_loss=0.0055  test_loss=75.1466  λ_max=2.1478\n",
      "[Muon | lr=0.1] Epoch 1043/4000: train_loss=0.0055  test_loss=75.1749  λ_max=2.4181\n",
      "[Muon | lr=0.1] Iter 16700: loss=0.0091\n",
      "[Muon | lr=0.1] Epoch 1044/4000: train_loss=0.0054  test_loss=75.3292  λ_max=2.2430\n",
      "[Muon | lr=0.1] Epoch 1045/4000: train_loss=0.0045  test_loss=75.4084  λ_max=2.1875\n",
      "[Muon | lr=0.1] Epoch 1046/4000: train_loss=0.0050  test_loss=75.4856  λ_max=2.3318\n",
      "[Muon | lr=0.1] Epoch 1047/4000: train_loss=0.0049  test_loss=75.5282  λ_max=2.2264\n",
      "[Muon | lr=0.1] Epoch 1048/4000: train_loss=0.0054  test_loss=75.6012  λ_max=2.4108\n",
      "[Muon | lr=0.1] Epoch 1049/4000: train_loss=0.0056  test_loss=75.7352  λ_max=2.3153\n",
      "[Muon | lr=0.1] Iter 16800: loss=0.0058\n",
      "[Muon | lr=0.1] Epoch 1050/4000: train_loss=0.0045  test_loss=75.9348  λ_max=2.2303\n",
      "[Muon | lr=0.1] Epoch 1051/4000: train_loss=0.0049  test_loss=75.9032  λ_max=2.4770\n",
      "[Muon | lr=0.1] Epoch 1052/4000: train_loss=0.0045  test_loss=76.0670  λ_max=2.4886\n",
      "[Muon | lr=0.1] Epoch 1053/4000: train_loss=0.0058  test_loss=76.2763  λ_max=2.4172\n",
      "[Muon | lr=0.1] Epoch 1054/4000: train_loss=0.0059  test_loss=76.3331  λ_max=2.5118\n",
      "[Muon | lr=0.1] Epoch 1055/4000: train_loss=0.0058  test_loss=76.4337  λ_max=2.3036\n",
      "[Muon | lr=0.1] Epoch 1056/4000: train_loss=0.0053  test_loss=76.3348  λ_max=2.3802\n",
      "[Muon | lr=0.1] Iter 16900: loss=0.0043\n",
      "[Muon | lr=0.1] Epoch 1057/4000: train_loss=0.0054  test_loss=76.5049  λ_max=2.2998\n",
      "[Muon | lr=0.1] Epoch 1058/4000: train_loss=0.0054  test_loss=76.6521  λ_max=2.4188\n",
      "[Muon | lr=0.1] Epoch 1059/4000: train_loss=0.0049  test_loss=76.6088  λ_max=2.2128\n",
      "[Muon | lr=0.1] Epoch 1060/4000: train_loss=0.0060  test_loss=76.5119  λ_max=2.3045\n",
      "[Muon | lr=0.1] Epoch 1061/4000: train_loss=0.0054  test_loss=76.6469  λ_max=2.5218\n",
      "[Muon | lr=0.1] Epoch 1062/4000: train_loss=0.0060  test_loss=76.6248  λ_max=2.3364\n",
      "[Muon | lr=0.1] Iter 17000: loss=0.0049\n",
      "[Muon | lr=0.1] Epoch 1063/4000: train_loss=0.0050  test_loss=76.5906  λ_max=2.2911\n",
      "[Muon | lr=0.1] Epoch 1064/4000: train_loss=0.0050  test_loss=76.8048  λ_max=2.6220\n",
      "[Muon | lr=0.1] Epoch 1065/4000: train_loss=0.0052  test_loss=76.8012  λ_max=2.3544\n",
      "[Muon | lr=0.1] Epoch 1066/4000: train_loss=0.0051  test_loss=76.8381  λ_max=2.4731\n",
      "[Muon | lr=0.1] Epoch 1067/4000: train_loss=0.0059  test_loss=76.9702  λ_max=2.4531\n",
      "[Muon | lr=0.1] Epoch 1068/4000: train_loss=0.0052  test_loss=76.9192  λ_max=2.2989\n",
      "[Muon | lr=0.1] Iter 17100: loss=0.0052\n",
      "[Muon | lr=0.1] Epoch 1069/4000: train_loss=0.0055  test_loss=77.0310  λ_max=2.2500\n",
      "[Muon | lr=0.1] Epoch 1070/4000: train_loss=0.0046  test_loss=77.0062  λ_max=2.3039\n",
      "[Muon | lr=0.1] Epoch 1071/4000: train_loss=0.0049  test_loss=77.0573  λ_max=2.4200\n",
      "[Muon | lr=0.1] Epoch 1072/4000: train_loss=0.0051  test_loss=77.1874  λ_max=2.4799\n",
      "[Muon | lr=0.1] Epoch 1073/4000: train_loss=0.0060  test_loss=77.2129  λ_max=2.2765\n",
      "[Muon | lr=0.1] Epoch 1074/4000: train_loss=0.0049  test_loss=77.2431  λ_max=2.4588\n",
      "[Muon | lr=0.1] Iter 17200: loss=0.0105\n",
      "[Muon | lr=0.1] Epoch 1075/4000: train_loss=0.0057  test_loss=77.3547  λ_max=2.4108\n",
      "[Muon | lr=0.1] Epoch 1076/4000: train_loss=0.0055  test_loss=77.4711  λ_max=2.3802\n",
      "[Muon | lr=0.1] Epoch 1077/4000: train_loss=0.0062  test_loss=77.7075  λ_max=2.3936\n",
      "[Muon | lr=0.1] Epoch 1078/4000: train_loss=0.0045  test_loss=77.6310  λ_max=2.6102\n",
      "[Muon | lr=0.1] Epoch 1079/4000: train_loss=0.0060  test_loss=77.8361  λ_max=2.3705\n",
      "[Muon | lr=0.1] Epoch 1080/4000: train_loss=0.0052  test_loss=78.0783  λ_max=2.5058\n",
      "[Muon | lr=0.1] Epoch 1081/4000: train_loss=0.0059  test_loss=78.0991  λ_max=2.4674\n",
      "[Muon | lr=0.1] Iter 17300: loss=0.0045\n",
      "[Muon | lr=0.1] Epoch 1082/4000: train_loss=0.0057  test_loss=78.1525  λ_max=2.3966\n",
      "[Muon | lr=0.1] Epoch 1083/4000: train_loss=0.0042  test_loss=78.1099  λ_max=2.4032\n",
      "[Muon | lr=0.1] Epoch 1084/4000: train_loss=0.0052  test_loss=78.2290  λ_max=2.5862\n",
      "[Muon | lr=0.1] Epoch 1085/4000: train_loss=0.0047  test_loss=78.2499  λ_max=2.4890\n",
      "[Muon | lr=0.1] Epoch 1086/4000: train_loss=0.0054  test_loss=78.3674  λ_max=2.5240\n",
      "[Muon | lr=0.1] Epoch 1087/4000: train_loss=0.0053  test_loss=78.6077  λ_max=2.2704\n",
      "[Muon | lr=0.1] Iter 17400: loss=0.0045\n",
      "[Muon | lr=0.1] Epoch 1088/4000: train_loss=0.0055  test_loss=78.7448  λ_max=2.4403\n",
      "[Muon | lr=0.1] Epoch 1089/4000: train_loss=0.0049  test_loss=78.9984  λ_max=2.6145\n",
      "[Muon | lr=0.1] Epoch 1090/4000: train_loss=0.0050  test_loss=79.0466  λ_max=2.4905\n",
      "[Muon | lr=0.1] Epoch 1091/4000: train_loss=0.0057  test_loss=78.9274  λ_max=2.3394\n",
      "[Muon | lr=0.1] Epoch 1092/4000: train_loss=0.0062  test_loss=78.8916  λ_max=2.1913\n",
      "[Muon | lr=0.1] Epoch 1093/4000: train_loss=0.0058  test_loss=79.0199  λ_max=2.2703\n",
      "[Muon | lr=0.1] Iter 17500: loss=0.0073\n",
      "[Muon | lr=0.1] Epoch 1094/4000: train_loss=0.0061  test_loss=79.3209  λ_max=2.3151\n",
      "[Muon | lr=0.1] Epoch 1095/4000: train_loss=0.0056  test_loss=79.4383  λ_max=2.4975\n",
      "[Muon | lr=0.1] Epoch 1096/4000: train_loss=0.0053  test_loss=79.5413  λ_max=2.2643\n",
      "[Muon | lr=0.1] Epoch 1097/4000: train_loss=0.0059  test_loss=79.5433  λ_max=2.3261\n",
      "[Muon | lr=0.1] Epoch 1098/4000: train_loss=0.0039  test_loss=79.5496  λ_max=2.4846\n",
      "[Muon | lr=0.1] Epoch 1099/4000: train_loss=0.0044  test_loss=79.6355  λ_max=2.6091\n",
      "[Muon | lr=0.1] Iter 17600: loss=0.0070\n",
      "[Muon | lr=0.1] Epoch 1100/4000: train_loss=0.0049  test_loss=79.6555  λ_max=2.3557\n",
      "[Muon | lr=0.1] Epoch 1101/4000: train_loss=0.0060  test_loss=79.6473  λ_max=2.3818\n",
      "[Muon | lr=0.1] Epoch 1102/4000: train_loss=0.0062  test_loss=79.6473  λ_max=2.4751\n",
      "[Muon | lr=0.1] Epoch 1103/4000: train_loss=0.0047  test_loss=79.6375  λ_max=2.2577\n",
      "[Muon | lr=0.1] Epoch 1104/4000: train_loss=0.0053  test_loss=79.6948  λ_max=2.4358\n",
      "[Muon | lr=0.1] Epoch 1105/4000: train_loss=0.0060  test_loss=79.8318  λ_max=2.3327\n",
      "[Muon | lr=0.1] Epoch 1106/4000: train_loss=0.0056  test_loss=79.8293  λ_max=2.4851\n",
      "[Muon | lr=0.1] Iter 17700: loss=0.0043\n",
      "[Muon | lr=0.1] Epoch 1107/4000: train_loss=0.0052  test_loss=79.8894  λ_max=2.3138\n",
      "[Muon | lr=0.1] Epoch 1108/4000: train_loss=0.0054  test_loss=79.8379  λ_max=2.3125\n",
      "[Muon | lr=0.1] Epoch 1109/4000: train_loss=0.0047  test_loss=79.9725  λ_max=2.3650\n",
      "[Muon | lr=0.1] Epoch 1110/4000: train_loss=0.0053  test_loss=79.9324  λ_max=2.4470\n",
      "[Muon | lr=0.1] Epoch 1111/4000: train_loss=0.0063  test_loss=79.8337  λ_max=2.4973\n",
      "[Muon | lr=0.1] Epoch 1112/4000: train_loss=0.0055  test_loss=79.7409  λ_max=2.4485\n",
      "[Muon | lr=0.1] Iter 17800: loss=0.0082\n",
      "[Muon | lr=0.1] Epoch 1113/4000: train_loss=0.0056  test_loss=79.7850  λ_max=2.5651\n",
      "[Muon | lr=0.1] Epoch 1114/4000: train_loss=0.0051  test_loss=79.9765  λ_max=2.3587\n",
      "[Muon | lr=0.1] Epoch 1115/4000: train_loss=0.0055  test_loss=79.8214  λ_max=2.3851\n",
      "[Muon | lr=0.1] Epoch 1116/4000: train_loss=0.0048  test_loss=80.0152  λ_max=2.3621\n",
      "[Muon | lr=0.1] Epoch 1117/4000: train_loss=0.0052  test_loss=80.1913  λ_max=2.5478\n",
      "[Muon | lr=0.1] Epoch 1118/4000: train_loss=0.0047  test_loss=80.3611  λ_max=2.4140\n",
      "[Muon | lr=0.1] Iter 17900: loss=0.0102\n",
      "[Muon | lr=0.1] Epoch 1119/4000: train_loss=0.0059  test_loss=80.3794  λ_max=2.3139\n",
      "[Muon | lr=0.1] Epoch 1120/4000: train_loss=0.0056  test_loss=80.2287  λ_max=2.6580\n",
      "[Muon | lr=0.1] Epoch 1121/4000: train_loss=0.0060  test_loss=80.3889  λ_max=2.4273\n",
      "[Muon | lr=0.1] Epoch 1122/4000: train_loss=0.0056  test_loss=80.3424  λ_max=2.4115\n",
      "[Muon | lr=0.1] Epoch 1123/4000: train_loss=0.0051  test_loss=80.4797  λ_max=2.4209\n",
      "[Muon | lr=0.1] Epoch 1124/4000: train_loss=0.0047  test_loss=80.4901  λ_max=2.3777\n",
      "[Muon | lr=0.1] Iter 18000: loss=0.0072\n",
      "[Muon | lr=0.1] Epoch 1125/4000: train_loss=0.0053  test_loss=80.5391  λ_max=2.4301\n",
      "[Muon | lr=0.1] Epoch 1126/4000: train_loss=0.0061  test_loss=80.5784  λ_max=2.3166\n",
      "[Muon | lr=0.1] Epoch 1127/4000: train_loss=0.0052  test_loss=80.7375  λ_max=2.6459\n",
      "[Muon | lr=0.1] Epoch 1128/4000: train_loss=0.0054  test_loss=80.8321  λ_max=2.4868\n",
      "[Muon | lr=0.1] Epoch 1129/4000: train_loss=0.0061  test_loss=80.8110  λ_max=2.5306\n",
      "[Muon | lr=0.1] Epoch 1130/4000: train_loss=0.0061  test_loss=80.8103  λ_max=2.5445\n",
      "[Muon | lr=0.1] Epoch 1131/4000: train_loss=0.0055  test_loss=80.8387  λ_max=2.5120\n",
      "[Muon | lr=0.1] Iter 18100: loss=0.0023\n",
      "[Muon | lr=0.1] Epoch 1132/4000: train_loss=0.0046  test_loss=80.7626  λ_max=2.5399\n",
      "[Muon | lr=0.1] Epoch 1133/4000: train_loss=0.0047  test_loss=80.9060  λ_max=2.5168\n",
      "[Muon | lr=0.1] Epoch 1134/4000: train_loss=0.0058  test_loss=80.9751  λ_max=2.3880\n",
      "[Muon | lr=0.1] Epoch 1135/4000: train_loss=0.0051  test_loss=81.2155  λ_max=2.7982\n",
      "[Muon | lr=0.1] Epoch 1136/4000: train_loss=0.0048  test_loss=81.2935  λ_max=2.6594\n",
      "[Muon | lr=0.1] Epoch 1137/4000: train_loss=0.0060  test_loss=81.4903  λ_max=2.4375\n",
      "[Muon | lr=0.1] Iter 18200: loss=0.0051\n",
      "[Muon | lr=0.1] Epoch 1138/4000: train_loss=0.0060  test_loss=81.7891  λ_max=2.4506\n",
      "[Muon | lr=0.1] Epoch 1139/4000: train_loss=0.0062  test_loss=81.8774  λ_max=2.2864\n",
      "[Muon | lr=0.1] Epoch 1140/4000: train_loss=0.0059  test_loss=81.7653  λ_max=2.5021\n",
      "[Muon | lr=0.1] Epoch 1141/4000: train_loss=0.0041  test_loss=81.7120  λ_max=2.4465\n",
      "[Muon | lr=0.1] Epoch 1142/4000: train_loss=0.0053  test_loss=81.5069  λ_max=2.3498\n",
      "[Muon | lr=0.1] Epoch 1143/4000: train_loss=0.0050  test_loss=81.6830  λ_max=2.5697\n",
      "[Muon | lr=0.1] Iter 18300: loss=0.0055\n",
      "[Muon | lr=0.1] Epoch 1144/4000: train_loss=0.0049  test_loss=81.8537  λ_max=2.5980\n",
      "[Muon | lr=0.1] Epoch 1145/4000: train_loss=0.0050  test_loss=81.8670  λ_max=2.4055\n",
      "[Muon | lr=0.1] Epoch 1146/4000: train_loss=0.0049  test_loss=81.8733  λ_max=2.4435\n",
      "[Muon | lr=0.1] Epoch 1147/4000: train_loss=0.0056  test_loss=82.1190  λ_max=2.4104\n",
      "[Muon | lr=0.1] Epoch 1148/4000: train_loss=0.0050  test_loss=82.0472  λ_max=2.3689\n",
      "[Muon | lr=0.1] Epoch 1149/4000: train_loss=0.0068  test_loss=82.0143  λ_max=2.6644\n",
      "[Muon | lr=0.1] Iter 18400: loss=0.0043\n",
      "[Muon | lr=0.1] Epoch 1150/4000: train_loss=0.0045  test_loss=82.0590  λ_max=2.5093\n",
      "[Muon | lr=0.1] Epoch 1151/4000: train_loss=0.0051  test_loss=81.9936  λ_max=2.3007\n",
      "[Muon | lr=0.1] Epoch 1152/4000: train_loss=0.0057  test_loss=82.1528  λ_max=2.4344\n",
      "[Muon | lr=0.1] Epoch 1153/4000: train_loss=0.0050  test_loss=82.1649  λ_max=2.4328\n",
      "[Muon | lr=0.1] Epoch 1154/4000: train_loss=0.0063  test_loss=82.1418  λ_max=2.3574\n",
      "[Muon | lr=0.1] Epoch 1155/4000: train_loss=0.0060  test_loss=82.3067  λ_max=2.4302\n",
      "[Muon | lr=0.1] Epoch 1156/4000: train_loss=0.0057  test_loss=82.3389  λ_max=2.5046\n",
      "[Muon | lr=0.1] Iter 18500: loss=0.0034\n",
      "[Muon | lr=0.1] Epoch 1157/4000: train_loss=0.0066  test_loss=82.3015  λ_max=2.5141\n",
      "[Muon | lr=0.1] Epoch 1158/4000: train_loss=0.0051  test_loss=82.4096  λ_max=2.8092\n",
      "[Muon | lr=0.1] Epoch 1159/4000: train_loss=0.0049  test_loss=82.6308  λ_max=2.7778\n",
      "[Muon | lr=0.1] Epoch 1160/4000: train_loss=0.0057  test_loss=82.9062  λ_max=2.4389\n",
      "[Muon | lr=0.1] Epoch 1161/4000: train_loss=0.0050  test_loss=82.9745  λ_max=2.5108\n",
      "[Muon | lr=0.1] Epoch 1162/4000: train_loss=0.0056  test_loss=82.9034  λ_max=2.4369\n",
      "[Muon | lr=0.1] Iter 18600: loss=0.0033\n",
      "[Muon | lr=0.1] Epoch 1163/4000: train_loss=0.0047  test_loss=82.8563  λ_max=2.3980\n",
      "[Muon | lr=0.1] Epoch 1164/4000: train_loss=0.0054  test_loss=82.8828  λ_max=2.5061\n",
      "[Muon | lr=0.1] Epoch 1165/4000: train_loss=0.0057  test_loss=82.8893  λ_max=2.3764\n",
      "[Muon | lr=0.1] Epoch 1166/4000: train_loss=0.0062  test_loss=82.9136  λ_max=2.2555\n",
      "[Muon | lr=0.1] Epoch 1167/4000: train_loss=0.0055  test_loss=83.0887  λ_max=2.5115\n",
      "[Muon | lr=0.1] Epoch 1168/4000: train_loss=0.0065  test_loss=83.3096  λ_max=2.5020\n",
      "[Muon | lr=0.1] Iter 18700: loss=0.0079\n",
      "[Muon | lr=0.1] Epoch 1169/4000: train_loss=0.0063  test_loss=83.4672  λ_max=2.6977\n",
      "[Muon | lr=0.1] Epoch 1170/4000: train_loss=0.0047  test_loss=83.5657  λ_max=2.5421\n",
      "[Muon | lr=0.1] Epoch 1171/4000: train_loss=0.0044  test_loss=83.6009  λ_max=2.4337\n",
      "[Muon | lr=0.1] Epoch 1172/4000: train_loss=0.0052  test_loss=83.6581  λ_max=2.5618\n",
      "[Muon | lr=0.1] Epoch 1173/4000: train_loss=0.0058  test_loss=83.7450  λ_max=2.4836\n",
      "[Muon | lr=0.1] Epoch 1174/4000: train_loss=0.0049  test_loss=83.8922  λ_max=2.6224\n",
      "[Muon | lr=0.1] Iter 18800: loss=0.0097\n",
      "[Muon | lr=0.1] Epoch 1175/4000: train_loss=0.0057  test_loss=83.9332  λ_max=2.4811\n",
      "[Muon | lr=0.1] Epoch 1176/4000: train_loss=0.0061  test_loss=84.0428  λ_max=2.5092\n",
      "[Muon | lr=0.1] Epoch 1177/4000: train_loss=0.0050  test_loss=83.9806  λ_max=2.6324\n",
      "[Muon | lr=0.1] Epoch 1178/4000: train_loss=0.0047  test_loss=84.0987  λ_max=2.6883\n",
      "[Muon | lr=0.1] Epoch 1179/4000: train_loss=0.0048  test_loss=84.2162  λ_max=2.5246\n",
      "[Muon | lr=0.1] Epoch 1180/4000: train_loss=0.0051  test_loss=84.3011  λ_max=2.5787\n",
      "[Muon | lr=0.1] Epoch 1181/4000: train_loss=0.0070  test_loss=84.4072  λ_max=2.5498\n",
      "[Muon | lr=0.1] Iter 18900: loss=0.0008\n",
      "[Muon | lr=0.1] Epoch 1182/4000: train_loss=0.0058  test_loss=84.5568  λ_max=2.4688\n",
      "[Muon | lr=0.1] Epoch 1183/4000: train_loss=0.0054  test_loss=84.5060  λ_max=2.6002\n",
      "[Muon | lr=0.1] Epoch 1184/4000: train_loss=0.0050  test_loss=84.6662  λ_max=2.5450\n",
      "[Muon | lr=0.1] Epoch 1185/4000: train_loss=0.0047  test_loss=84.6695  λ_max=2.6133\n",
      "[Muon | lr=0.1] Epoch 1186/4000: train_loss=0.0048  test_loss=84.6813  λ_max=2.5799\n",
      "[Muon | lr=0.1] Epoch 1187/4000: train_loss=0.0057  test_loss=84.7699  λ_max=2.5127\n",
      "[Muon | lr=0.1] Iter 19000: loss=0.0048\n",
      "[Muon | lr=0.1] Epoch 1188/4000: train_loss=0.0059  test_loss=84.8935  λ_max=2.4647\n",
      "[Muon | lr=0.1] Epoch 1189/4000: train_loss=0.0054  test_loss=84.9366  λ_max=2.5826\n",
      "[Muon | lr=0.1] Epoch 1190/4000: train_loss=0.0052  test_loss=84.7790  λ_max=2.5653\n",
      "[Muon | lr=0.1] Epoch 1191/4000: train_loss=0.0053  test_loss=84.8263  λ_max=2.5397\n",
      "[Muon | lr=0.1] Epoch 1192/4000: train_loss=0.0048  test_loss=84.9029  λ_max=2.6242\n",
      "[Muon | lr=0.1] Epoch 1193/4000: train_loss=0.0055  test_loss=84.9644  λ_max=2.6513\n",
      "[Muon | lr=0.1] Iter 19100: loss=0.0112\n",
      "[Muon | lr=0.1] Epoch 1194/4000: train_loss=0.0055  test_loss=85.2431  λ_max=2.4724\n",
      "[Muon | lr=0.1] Epoch 1195/4000: train_loss=0.0057  test_loss=85.3345  λ_max=2.5366\n",
      "[Muon | lr=0.1] Epoch 1196/4000: train_loss=0.0054  test_loss=85.4543  λ_max=2.5560\n",
      "[Muon | lr=0.1] Epoch 1197/4000: train_loss=0.0049  test_loss=85.5943  λ_max=2.7202\n",
      "[Muon | lr=0.1] Epoch 1198/4000: train_loss=0.0055  test_loss=85.6212  λ_max=2.5973\n",
      "[Muon | lr=0.1] Epoch 1199/4000: train_loss=0.0049  test_loss=85.6746  λ_max=2.5119\n",
      "[Muon | lr=0.1] Iter 19200: loss=0.0143\n",
      "[Muon | lr=0.1] Epoch 1200/4000: train_loss=0.0057  test_loss=85.7152  λ_max=2.3718\n",
      "[Muon | lr=0.1] Epoch 1201/4000: train_loss=0.0050  test_loss=85.7408  λ_max=2.4574\n",
      "[Muon | lr=0.1] Epoch 1202/4000: train_loss=0.0056  test_loss=85.8599  λ_max=2.5174\n",
      "[Muon | lr=0.1] Epoch 1203/4000: train_loss=0.0045  test_loss=85.8995  λ_max=2.6593\n",
      "[Muon | lr=0.1] Epoch 1204/4000: train_loss=0.0052  test_loss=86.0936  λ_max=2.7464\n",
      "[Muon | lr=0.1] Epoch 1205/4000: train_loss=0.0048  test_loss=86.2492  λ_max=2.3338\n",
      "[Muon | lr=0.1] Epoch 1206/4000: train_loss=0.0059  test_loss=86.2750  λ_max=2.6315\n",
      "[Muon | lr=0.1] Iter 19300: loss=0.0040\n",
      "[Muon | lr=0.1] Epoch 1207/4000: train_loss=0.0052  test_loss=86.2110  λ_max=2.5830\n",
      "[Muon | lr=0.1] Epoch 1208/4000: train_loss=0.0052  test_loss=86.2542  λ_max=2.5821\n",
      "[Muon | lr=0.1] Epoch 1209/4000: train_loss=0.0053  test_loss=86.4332  λ_max=2.4866\n",
      "[Muon | lr=0.1] Epoch 1210/4000: train_loss=0.0041  test_loss=86.4804  λ_max=2.5342\n",
      "[Muon | lr=0.1] Epoch 1211/4000: train_loss=0.0043  test_loss=86.7423  λ_max=2.5910\n",
      "[Muon | lr=0.1] Epoch 1212/4000: train_loss=0.0051  test_loss=86.8333  λ_max=2.4519\n",
      "[Muon | lr=0.1] Iter 19400: loss=0.0069\n",
      "[Muon | lr=0.1] Epoch 1213/4000: train_loss=0.0063  test_loss=86.8974  λ_max=2.4726\n",
      "[Muon | lr=0.1] Epoch 1214/4000: train_loss=0.0061  test_loss=86.9408  λ_max=2.6414\n",
      "[Muon | lr=0.1] Epoch 1215/4000: train_loss=0.0061  test_loss=87.0006  λ_max=2.5660\n",
      "[Muon | lr=0.1] Epoch 1216/4000: train_loss=0.0042  test_loss=87.0957  λ_max=2.6592\n",
      "[Muon | lr=0.1] Epoch 1217/4000: train_loss=0.0056  test_loss=87.2863  λ_max=2.6832\n",
      "[Muon | lr=0.1] Epoch 1218/4000: train_loss=0.0057  test_loss=87.0687  λ_max=2.5264\n",
      "[Muon | lr=0.1] Iter 19500: loss=0.0122\n",
      "[Muon | lr=0.1] Epoch 1219/4000: train_loss=0.0058  test_loss=86.9649  λ_max=2.8327\n",
      "[Muon | lr=0.1] Epoch 1220/4000: train_loss=0.0052  test_loss=86.9722  λ_max=3.1581\n",
      "[Muon | lr=0.1] Epoch 1221/4000: train_loss=0.0049  test_loss=86.9775  λ_max=2.4105\n",
      "[Muon | lr=0.1] Epoch 1222/4000: train_loss=0.0044  test_loss=87.0845  λ_max=2.5429\n",
      "[Muon | lr=0.1] Epoch 1223/4000: train_loss=0.0059  test_loss=87.0528  λ_max=2.5095\n",
      "[Muon | lr=0.1] Epoch 1224/4000: train_loss=0.0055  test_loss=87.0544  λ_max=2.9355\n",
      "[Muon | lr=0.1] Iter 19600: loss=0.0113\n",
      "[Muon | lr=0.1] Epoch 1225/4000: train_loss=0.0056  test_loss=87.2440  λ_max=2.4671\n",
      "[Muon | lr=0.1] Epoch 1226/4000: train_loss=0.0058  test_loss=87.4191  λ_max=2.4871\n",
      "[Muon | lr=0.1] Epoch 1227/4000: train_loss=0.0048  test_loss=87.5520  λ_max=2.5537\n",
      "[Muon | lr=0.1] Epoch 1228/4000: train_loss=0.0051  test_loss=87.6533  λ_max=2.4970\n",
      "[Muon | lr=0.1] Epoch 1229/4000: train_loss=0.0056  test_loss=87.8919  λ_max=2.7858\n",
      "[Muon | lr=0.1] Epoch 1230/4000: train_loss=0.0053  test_loss=87.7240  λ_max=2.7989\n",
      "[Muon | lr=0.1] Epoch 1231/4000: train_loss=0.0047  test_loss=87.7800  λ_max=2.5889\n",
      "[Muon | lr=0.1] Iter 19700: loss=0.0019\n",
      "[Muon | lr=0.1] Epoch 1232/4000: train_loss=0.0061  test_loss=87.9078  λ_max=2.4260\n",
      "[Muon | lr=0.1] Epoch 1233/4000: train_loss=0.0058  test_loss=87.9104  λ_max=2.6859\n",
      "[Muon | lr=0.1] Epoch 1234/4000: train_loss=0.0055  test_loss=87.9537  λ_max=2.4562\n",
      "[Muon | lr=0.1] Epoch 1235/4000: train_loss=0.0070  test_loss=87.9954  λ_max=2.6422\n",
      "[Muon | lr=0.1] Epoch 1236/4000: train_loss=0.0049  test_loss=87.9943  λ_max=2.6634\n",
      "[Muon | lr=0.1] Epoch 1237/4000: train_loss=0.0063  test_loss=88.1202  λ_max=2.9613\n",
      "[Muon | lr=0.1] Iter 19800: loss=0.0028\n",
      "[Muon | lr=0.1] Epoch 1238/4000: train_loss=0.0046  test_loss=88.4036  λ_max=2.7233\n",
      "[Muon | lr=0.1] Epoch 1239/4000: train_loss=0.0051  test_loss=88.6247  λ_max=2.5726\n",
      "[Muon | lr=0.1] Epoch 1240/4000: train_loss=0.0054  test_loss=88.5650  λ_max=2.6183\n",
      "[Muon | lr=0.1] Epoch 1241/4000: train_loss=0.0053  test_loss=88.4200  λ_max=2.5847\n",
      "[Muon | lr=0.1] Epoch 1242/4000: train_loss=0.0050  test_loss=88.5327  λ_max=2.8372\n",
      "[Muon | lr=0.1] Epoch 1243/4000: train_loss=0.0052  test_loss=88.7423  λ_max=2.6526\n",
      "[Muon | lr=0.1] Iter 19900: loss=0.0090\n",
      "[Muon | lr=0.1] Epoch 1244/4000: train_loss=0.0055  test_loss=88.6795  λ_max=2.3809\n",
      "[Muon | lr=0.1] Epoch 1245/4000: train_loss=0.0054  test_loss=88.6979  λ_max=2.4097\n",
      "[Muon | lr=0.1] Epoch 1246/4000: train_loss=0.0048  test_loss=88.7863  λ_max=2.6849\n",
      "[Muon | lr=0.1] Epoch 1247/4000: train_loss=0.0051  test_loss=88.7324  λ_max=2.9098\n",
      "[Muon | lr=0.1] Epoch 1248/4000: train_loss=0.0047  test_loss=88.7052  λ_max=2.6048\n",
      "[Muon | lr=0.1] Epoch 1249/4000: train_loss=0.0051  test_loss=88.7350  λ_max=2.8330\n",
      "[Muon | lr=0.1] Iter 20000: loss=0.0115\n",
      "[Muon | lr=0.1] Epoch 1250/4000: train_loss=0.0056  test_loss=88.8231  λ_max=2.7240\n",
      "[Muon | lr=0.1] Epoch 1251/4000: train_loss=0.0050  test_loss=88.9500  λ_max=2.6048\n",
      "[Muon | lr=0.1] Epoch 1252/4000: train_loss=0.0053  test_loss=89.1543  λ_max=2.3800\n",
      "[Muon | lr=0.1] Epoch 1253/4000: train_loss=0.0060  test_loss=89.2397  λ_max=2.5590\n",
      "[Muon | lr=0.1] Epoch 1254/4000: train_loss=0.0053  test_loss=89.4162  λ_max=2.8785\n",
      "[Muon | lr=0.1] Epoch 1255/4000: train_loss=0.0061  test_loss=89.5777  λ_max=2.6732\n",
      "[Muon | lr=0.1] Epoch 1256/4000: train_loss=0.0061  test_loss=89.6580  λ_max=2.9526\n",
      "[Muon | lr=0.1] Iter 20100: loss=0.0019\n",
      "[Muon | lr=0.1] Epoch 1257/4000: train_loss=0.0045  test_loss=89.7084  λ_max=2.9487\n",
      "[Muon | lr=0.1] Epoch 1258/4000: train_loss=0.0053  test_loss=89.6481  λ_max=2.7640\n",
      "[Muon | lr=0.1] Epoch 1259/4000: train_loss=0.0051  test_loss=89.8053  λ_max=2.4223\n",
      "[Muon | lr=0.1] Epoch 1260/4000: train_loss=0.0050  test_loss=89.7943  λ_max=2.5120\n",
      "[Muon | lr=0.1] Epoch 1261/4000: train_loss=0.0043  test_loss=89.8374  λ_max=2.5502\n",
      "[Muon | lr=0.1] Epoch 1262/4000: train_loss=0.0063  test_loss=90.0212  λ_max=2.8440\n",
      "[Muon | lr=0.1] Iter 20200: loss=0.0024\n",
      "[Muon | lr=0.1] Epoch 1263/4000: train_loss=0.0058  test_loss=89.9485  λ_max=2.3394\n",
      "[Muon | lr=0.1] Epoch 1264/4000: train_loss=0.0049  test_loss=89.9814  λ_max=2.5573\n",
      "[Muon | lr=0.1] Epoch 1265/4000: train_loss=0.0060  test_loss=90.0388  λ_max=2.5975\n",
      "[Muon | lr=0.1] Epoch 1266/4000: train_loss=0.0056  test_loss=90.2041  λ_max=2.4995\n",
      "[Muon | lr=0.1] Epoch 1267/4000: train_loss=0.0061  test_loss=90.3503  λ_max=2.7249\n",
      "[Muon | lr=0.1] Epoch 1268/4000: train_loss=0.0047  test_loss=90.2936  λ_max=2.6400\n",
      "[Muon | lr=0.1] Iter 20300: loss=0.0132\n",
      "[Muon | lr=0.1] Epoch 1269/4000: train_loss=0.0048  test_loss=90.2025  λ_max=2.8152\n",
      "[Muon | lr=0.1] Epoch 1270/4000: train_loss=0.0045  test_loss=90.2657  λ_max=2.7564\n",
      "[Muon | lr=0.1] Epoch 1271/4000: train_loss=0.0049  test_loss=90.2423  λ_max=2.9993\n",
      "[Muon | lr=0.1] Epoch 1272/4000: train_loss=0.0057  test_loss=90.3937  λ_max=2.7810\n",
      "[Muon | lr=0.1] Epoch 1273/4000: train_loss=0.0054  test_loss=90.4860  λ_max=2.4831\n",
      "[Muon | lr=0.1] Epoch 1274/4000: train_loss=0.0056  test_loss=90.6437  λ_max=2.6586\n",
      "[Muon | lr=0.1] Iter 20400: loss=0.0150\n",
      "[Muon | lr=0.1] Epoch 1275/4000: train_loss=0.0056  test_loss=90.7597  λ_max=2.6314\n",
      "[Muon | lr=0.1] Epoch 1276/4000: train_loss=0.0049  test_loss=90.4998  λ_max=2.6081\n",
      "[Muon | lr=0.1] Epoch 1277/4000: train_loss=0.0058  test_loss=90.7274  λ_max=2.6841\n",
      "[Muon | lr=0.1] Epoch 1278/4000: train_loss=0.0054  test_loss=90.6297  λ_max=2.6845\n",
      "[Muon | lr=0.1] Epoch 1279/4000: train_loss=0.0059  test_loss=90.6659  λ_max=2.4552\n",
      "[Muon | lr=0.1] Epoch 1280/4000: train_loss=0.0050  test_loss=90.9396  λ_max=2.5862\n",
      "[Muon | lr=0.1] Epoch 1281/4000: train_loss=0.0054  test_loss=90.8512  λ_max=2.9384\n",
      "[Muon | lr=0.1] Iter 20500: loss=0.0019\n",
      "[Muon | lr=0.1] Epoch 1282/4000: train_loss=0.0050  test_loss=90.9462  λ_max=2.6721\n",
      "[Muon | lr=0.1] Epoch 1283/4000: train_loss=0.0048  test_loss=91.0663  λ_max=2.5970\n",
      "[Muon | lr=0.1] Epoch 1284/4000: train_loss=0.0050  test_loss=91.2772  λ_max=2.6224\n",
      "[Muon | lr=0.1] Epoch 1285/4000: train_loss=0.0048  test_loss=91.2814  λ_max=2.5410\n",
      "[Muon | lr=0.1] Epoch 1286/4000: train_loss=0.0055  test_loss=91.3476  λ_max=2.7458\n",
      "[Muon | lr=0.1] Epoch 1287/4000: train_loss=0.0049  test_loss=91.5190  λ_max=2.4975\n",
      "[Muon | lr=0.1] Iter 20600: loss=0.0054\n",
      "[Muon | lr=0.1] Epoch 1288/4000: train_loss=0.0053  test_loss=91.6028  λ_max=2.8833\n",
      "[Muon | lr=0.1] Epoch 1289/4000: train_loss=0.0052  test_loss=91.6861  λ_max=2.6735\n",
      "[Muon | lr=0.1] Epoch 1290/4000: train_loss=0.0057  test_loss=91.8911  λ_max=2.7094\n",
      "[Muon | lr=0.1] Epoch 1291/4000: train_loss=0.0054  test_loss=92.0429  λ_max=2.5983\n",
      "[Muon | lr=0.1] Epoch 1292/4000: train_loss=0.0048  test_loss=91.9412  λ_max=2.6667\n",
      "[Muon | lr=0.1] Epoch 1293/4000: train_loss=0.0048  test_loss=92.1227  λ_max=2.7311\n",
      "[Muon | lr=0.1] Iter 20700: loss=0.0051\n",
      "[Muon | lr=0.1] Epoch 1294/4000: train_loss=0.0040  test_loss=92.2560  λ_max=2.3797\n",
      "[Muon | lr=0.1] Epoch 1295/4000: train_loss=0.0071  test_loss=92.3584  λ_max=2.7630\n",
      "[Muon | lr=0.1] Epoch 1296/4000: train_loss=0.0050  test_loss=92.4349  λ_max=2.7607\n",
      "[Muon | lr=0.1] Epoch 1297/4000: train_loss=0.0048  test_loss=92.5062  λ_max=2.6637\n",
      "[Muon | lr=0.1] Epoch 1298/4000: train_loss=0.0048  test_loss=92.5441  λ_max=2.7754\n",
      "[Muon | lr=0.1] Epoch 1299/4000: train_loss=0.0058  test_loss=92.7396  λ_max=2.7677\n",
      "[Muon | lr=0.1] Iter 20800: loss=0.0113\n",
      "[Muon | lr=0.1] Epoch 1300/4000: train_loss=0.0042  test_loss=92.6380  λ_max=2.6144\n",
      "[Muon | lr=0.1] Epoch 1301/4000: train_loss=0.0060  test_loss=92.6626  λ_max=2.8057\n",
      "[Muon | lr=0.1] Epoch 1302/4000: train_loss=0.0056  test_loss=92.6458  λ_max=2.5065\n",
      "[Muon | lr=0.1] Epoch 1303/4000: train_loss=0.0055  test_loss=92.7523  λ_max=2.8321\n",
      "[Muon | lr=0.1] Epoch 1304/4000: train_loss=0.0058  test_loss=92.8100  λ_max=2.6886\n",
      "[Muon | lr=0.1] Epoch 1305/4000: train_loss=0.0056  test_loss=92.9153  λ_max=3.1907\n",
      "[Muon | lr=0.1] Epoch 1306/4000: train_loss=0.0055  test_loss=92.8780  λ_max=2.8581\n",
      "[Muon | lr=0.1] Iter 20900: loss=0.0048\n",
      "[Muon | lr=0.1] Epoch 1307/4000: train_loss=0.0049  test_loss=93.0847  λ_max=2.7966\n",
      "[Muon | lr=0.1] Epoch 1308/4000: train_loss=0.0056  test_loss=93.0852  λ_max=2.7378\n",
      "[Muon | lr=0.1] Epoch 1309/4000: train_loss=0.0042  test_loss=93.0131  λ_max=2.6533\n",
      "[Muon | lr=0.1] Epoch 1310/4000: train_loss=0.0048  test_loss=93.2840  λ_max=2.6140\n",
      "[Muon | lr=0.1] Epoch 1311/4000: train_loss=0.0056  test_loss=93.2872  λ_max=2.6176\n",
      "[Muon | lr=0.1] Epoch 1312/4000: train_loss=0.0048  test_loss=93.3164  λ_max=2.7825\n",
      "[Muon | lr=0.1] Iter 21000: loss=0.0084\n",
      "[Muon | lr=0.1] Epoch 1313/4000: train_loss=0.0052  test_loss=93.3686  λ_max=2.4983\n",
      "[Muon | lr=0.1] Epoch 1314/4000: train_loss=0.0054  test_loss=93.1415  λ_max=2.7705\n",
      "[Muon | lr=0.1] Epoch 1315/4000: train_loss=0.0062  test_loss=93.0346  λ_max=2.8058\n",
      "[Muon | lr=0.1] Epoch 1316/4000: train_loss=0.0057  test_loss=92.9397  λ_max=2.6929\n",
      "[Muon | lr=0.1] Epoch 1317/4000: train_loss=0.0041  test_loss=93.0107  λ_max=2.6381\n",
      "[Muon | lr=0.1] Epoch 1318/4000: train_loss=0.0055  test_loss=93.0797  λ_max=2.7616\n",
      "[Muon | lr=0.1] Iter 21100: loss=0.0078\n",
      "[Muon | lr=0.1] Epoch 1319/4000: train_loss=0.0049  test_loss=93.1584  λ_max=2.9099\n",
      "[Muon | lr=0.1] Epoch 1320/4000: train_loss=0.0059  test_loss=93.0848  λ_max=2.6740\n",
      "[Muon | lr=0.1] Epoch 1321/4000: train_loss=0.0051  test_loss=92.9606  λ_max=2.9038\n",
      "[Muon | lr=0.1] Epoch 1322/4000: train_loss=0.0054  test_loss=92.9787  λ_max=2.6130\n",
      "[Muon | lr=0.1] Epoch 1323/4000: train_loss=0.0059  test_loss=93.0221  λ_max=2.6036\n",
      "[Muon | lr=0.1] Epoch 1324/4000: train_loss=0.0056  test_loss=92.9165  λ_max=2.5327\n",
      "[Muon | lr=0.1] Iter 21200: loss=0.0089\n",
      "[Muon | lr=0.1] Epoch 1325/4000: train_loss=0.0051  test_loss=92.9636  λ_max=2.8294\n",
      "[Muon | lr=0.1] Epoch 1326/4000: train_loss=0.0054  test_loss=93.0206  λ_max=2.6788\n",
      "[Muon | lr=0.1] Epoch 1327/4000: train_loss=0.0049  test_loss=93.0611  λ_max=2.6234\n",
      "[Muon | lr=0.1] Epoch 1328/4000: train_loss=0.0055  test_loss=93.1381  λ_max=2.6582\n",
      "[Muon | lr=0.1] Epoch 1329/4000: train_loss=0.0055  test_loss=93.2145  λ_max=2.5527\n",
      "[Muon | lr=0.1] Epoch 1330/4000: train_loss=0.0054  test_loss=93.2163  λ_max=2.8953\n",
      "[Muon | lr=0.1] Epoch 1331/4000: train_loss=0.0057  test_loss=93.3804  λ_max=2.9333\n",
      "[Muon | lr=0.1] Iter 21300: loss=0.0013\n",
      "[Muon | lr=0.1] Epoch 1332/4000: train_loss=0.0053  test_loss=93.4086  λ_max=2.7383\n",
      "[Muon | lr=0.1] Epoch 1333/4000: train_loss=0.0050  test_loss=93.2501  λ_max=2.8963\n",
      "[Muon | lr=0.1] Epoch 1334/4000: train_loss=0.0048  test_loss=93.5304  λ_max=2.7483\n",
      "[Muon | lr=0.1] Epoch 1335/4000: train_loss=0.0046  test_loss=93.6771  λ_max=2.7643\n",
      "[Muon | lr=0.1] Epoch 1336/4000: train_loss=0.0050  test_loss=93.6811  λ_max=2.7490\n",
      "[Muon | lr=0.1] Epoch 1337/4000: train_loss=0.0052  test_loss=93.8771  λ_max=2.7658\n",
      "[Muon | lr=0.1] Iter 21400: loss=0.0082\n",
      "[Muon | lr=0.1] Epoch 1338/4000: train_loss=0.0051  test_loss=94.1533  λ_max=2.5431\n",
      "[Muon | lr=0.1] Epoch 1339/4000: train_loss=0.0052  test_loss=94.0924  λ_max=2.9690\n",
      "[Muon | lr=0.1] Epoch 1340/4000: train_loss=0.0053  test_loss=94.3070  λ_max=2.8691\n",
      "[Muon | lr=0.1] Epoch 1341/4000: train_loss=0.0047  test_loss=94.3543  λ_max=2.8192\n",
      "[Muon | lr=0.1] Epoch 1342/4000: train_loss=0.0053  test_loss=94.2510  λ_max=2.8103\n",
      "[Muon | lr=0.1] Epoch 1343/4000: train_loss=0.0052  test_loss=94.1803  λ_max=2.8329\n",
      "[Muon | lr=0.1] Iter 21500: loss=0.0107\n",
      "[Muon | lr=0.1] Epoch 1344/4000: train_loss=0.0057  test_loss=94.2903  λ_max=2.8015\n",
      "[Muon | lr=0.1] Epoch 1345/4000: train_loss=0.0049  test_loss=94.5651  λ_max=2.8751\n",
      "[Muon | lr=0.1] Epoch 1346/4000: train_loss=0.0062  test_loss=94.5554  λ_max=2.5988\n",
      "[Muon | lr=0.1] Epoch 1347/4000: train_loss=0.0051  test_loss=94.6755  λ_max=3.0156\n",
      "[Muon | lr=0.1] Epoch 1348/4000: train_loss=0.0058  test_loss=94.8083  λ_max=2.8506\n",
      "[Muon | lr=0.1] Epoch 1349/4000: train_loss=0.0051  test_loss=94.8171  λ_max=2.7719\n",
      "[Muon | lr=0.1] Iter 21600: loss=0.0115\n",
      "[Muon | lr=0.1] Epoch 1350/4000: train_loss=0.0044  test_loss=94.8823  λ_max=2.6122\n",
      "[Muon | lr=0.1] Epoch 1351/4000: train_loss=0.0050  test_loss=95.0956  λ_max=2.6434\n",
      "[Muon | lr=0.1] Epoch 1352/4000: train_loss=0.0057  test_loss=95.0672  λ_max=2.7731\n",
      "[Muon | lr=0.1] Epoch 1353/4000: train_loss=0.0061  test_loss=95.0352  λ_max=2.6504\n",
      "[Muon | lr=0.1] Epoch 1354/4000: train_loss=0.0057  test_loss=95.2334  λ_max=2.9578\n",
      "[Muon | lr=0.1] Epoch 1355/4000: train_loss=0.0061  test_loss=95.3310  λ_max=2.6493\n",
      "[Muon | lr=0.1] Epoch 1356/4000: train_loss=0.0056  test_loss=95.3753  λ_max=2.6493\n",
      "[Muon | lr=0.1] Iter 21700: loss=0.0019\n",
      "[Muon | lr=0.1] Epoch 1357/4000: train_loss=0.0048  test_loss=95.5050  λ_max=2.5152\n",
      "[Muon | lr=0.1] Epoch 1358/4000: train_loss=0.0054  test_loss=95.4603  λ_max=2.7235\n",
      "[Muon | lr=0.1] Epoch 1359/4000: train_loss=0.0054  test_loss=95.5239  λ_max=2.5917\n",
      "[Muon | lr=0.1] Epoch 1360/4000: train_loss=0.0052  test_loss=95.6590  λ_max=2.7488\n",
      "[Muon | lr=0.1] Epoch 1361/4000: train_loss=0.0050  test_loss=95.6223  λ_max=2.8889\n",
      "[Muon | lr=0.1] Epoch 1362/4000: train_loss=0.0047  test_loss=95.5430  λ_max=2.7293\n",
      "[Muon | lr=0.1] Iter 21800: loss=0.0034\n",
      "[Muon | lr=0.1] Epoch 1363/4000: train_loss=0.0047  test_loss=95.4803  λ_max=2.9120\n",
      "[Muon | lr=0.1] Epoch 1364/4000: train_loss=0.0053  test_loss=95.6309  λ_max=3.0052\n",
      "[Muon | lr=0.1] Epoch 1365/4000: train_loss=0.0039  test_loss=95.5633  λ_max=2.9349\n",
      "[Muon | lr=0.1] Epoch 1366/4000: train_loss=0.0061  test_loss=95.6409  λ_max=2.8180\n",
      "[Muon | lr=0.1] Epoch 1367/4000: train_loss=0.0061  test_loss=95.7251  λ_max=2.7901\n",
      "[Muon | lr=0.1] Epoch 1368/4000: train_loss=0.0056  test_loss=95.7376  λ_max=2.6548\n",
      "[Muon | lr=0.1] Iter 21900: loss=0.0083\n",
      "[Muon | lr=0.1] Epoch 1369/4000: train_loss=0.0064  test_loss=95.9659  λ_max=2.7574\n",
      "[Muon | lr=0.1] Epoch 1370/4000: train_loss=0.0055  test_loss=96.1276  λ_max=2.7210\n",
      "[Muon | lr=0.1] Epoch 1371/4000: train_loss=0.0053  test_loss=96.2391  λ_max=2.6187\n",
      "[Muon | lr=0.1] Epoch 1372/4000: train_loss=0.0045  test_loss=96.2384  λ_max=2.7078\n",
      "[Muon | lr=0.1] Epoch 1373/4000: train_loss=0.0055  test_loss=96.2156  λ_max=3.1244\n",
      "[Muon | lr=0.1] Epoch 1374/4000: train_loss=0.0053  test_loss=96.1521  λ_max=2.9206\n",
      "[Muon | lr=0.1] Iter 22000: loss=0.0158\n",
      "[Muon | lr=0.1] Epoch 1375/4000: train_loss=0.0061  test_loss=96.0999  λ_max=2.7415\n",
      "[Muon | lr=0.1] Epoch 1376/4000: train_loss=0.0054  test_loss=96.2643  λ_max=3.0259\n",
      "[Muon | lr=0.1] Epoch 1377/4000: train_loss=0.0048  test_loss=96.5210  λ_max=2.8731\n",
      "[Muon | lr=0.1] Epoch 1378/4000: train_loss=0.0051  test_loss=96.5239  λ_max=2.6730\n",
      "[Muon | lr=0.1] Epoch 1379/4000: train_loss=0.0054  test_loss=96.5423  λ_max=3.3198\n",
      "[Muon | lr=0.1] Epoch 1380/4000: train_loss=0.0054  test_loss=96.5361  λ_max=3.0842\n",
      "[Muon | lr=0.1] Epoch 1381/4000: train_loss=0.0039  test_loss=96.7105  λ_max=2.8531\n",
      "[Muon | lr=0.1] Iter 22100: loss=0.0038\n",
      "[Muon | lr=0.1] Epoch 1382/4000: train_loss=0.0055  test_loss=96.7150  λ_max=2.7451\n",
      "[Muon | lr=0.1] Epoch 1383/4000: train_loss=0.0052  test_loss=96.7362  λ_max=3.0984\n",
      "[Muon | lr=0.1] Epoch 1384/4000: train_loss=0.0062  test_loss=96.8981  λ_max=2.7750\n",
      "[Muon | lr=0.1] Epoch 1385/4000: train_loss=0.0045  test_loss=97.1133  λ_max=2.5962\n",
      "[Muon | lr=0.1] Epoch 1386/4000: train_loss=0.0049  test_loss=97.2682  λ_max=2.4806\n",
      "[Muon | lr=0.1] Epoch 1387/4000: train_loss=0.0052  test_loss=97.2336  λ_max=2.6764\n",
      "[Muon | lr=0.1] Iter 22200: loss=0.0052\n",
      "[Muon | lr=0.1] Epoch 1388/4000: train_loss=0.0047  test_loss=97.2121  λ_max=2.6288\n",
      "[Muon | lr=0.1] Epoch 1389/4000: train_loss=0.0044  test_loss=97.3884  λ_max=2.7891\n",
      "[Muon | lr=0.1] Epoch 1390/4000: train_loss=0.0050  test_loss=97.4599  λ_max=2.7383\n",
      "[Muon | lr=0.1] Epoch 1391/4000: train_loss=0.0049  test_loss=97.4543  λ_max=3.0346\n",
      "[Muon | lr=0.1] Epoch 1392/4000: train_loss=0.0046  test_loss=97.5223  λ_max=2.7235\n",
      "[Muon | lr=0.1] Epoch 1393/4000: train_loss=0.0046  test_loss=97.7506  λ_max=2.7553\n",
      "[Muon | lr=0.1] Iter 22300: loss=0.0069\n",
      "[Muon | lr=0.1] Epoch 1394/4000: train_loss=0.0047  test_loss=97.8295  λ_max=2.6680\n",
      "[Muon | lr=0.1] Epoch 1395/4000: train_loss=0.0056  test_loss=97.8069  λ_max=2.7635\n",
      "[Muon | lr=0.1] Epoch 1396/4000: train_loss=0.0052  test_loss=98.1083  λ_max=2.6595\n",
      "[Muon | lr=0.1] Epoch 1397/4000: train_loss=0.0053  test_loss=98.3214  λ_max=2.6364\n",
      "[Muon | lr=0.1] Epoch 1398/4000: train_loss=0.0050  test_loss=98.2769  λ_max=2.7497\n",
      "[Muon | lr=0.1] Epoch 1399/4000: train_loss=0.0055  test_loss=98.3114  λ_max=3.0047\n",
      "[Muon | lr=0.1] Iter 22400: loss=0.0035\n",
      "[Muon | lr=0.1] Epoch 1400/4000: train_loss=0.0048  test_loss=98.3460  λ_max=2.9871\n",
      "[Muon | lr=0.1] Epoch 1401/4000: train_loss=0.0046  test_loss=98.2395  λ_max=3.5571\n",
      "[Muon | lr=0.1] Epoch 1402/4000: train_loss=0.0059  test_loss=98.4251  λ_max=2.6703\n",
      "[Muon | lr=0.1] Epoch 1403/4000: train_loss=0.0051  test_loss=98.5949  λ_max=2.6726\n",
      "[Muon | lr=0.1] Epoch 1404/4000: train_loss=0.0052  test_loss=98.5823  λ_max=2.5510\n",
      "[Muon | lr=0.1] Epoch 1405/4000: train_loss=0.0058  test_loss=98.6729  λ_max=2.9920\n",
      "[Muon | lr=0.1] Epoch 1406/4000: train_loss=0.0043  test_loss=98.6712  λ_max=2.7929\n",
      "[Muon | lr=0.1] Iter 22500: loss=0.0039\n",
      "[Muon | lr=0.1] Epoch 1407/4000: train_loss=0.0053  test_loss=98.6608  λ_max=2.9339\n",
      "[Muon | lr=0.1] Epoch 1408/4000: train_loss=0.0046  test_loss=98.6912  λ_max=2.9340\n",
      "[Muon | lr=0.1] Epoch 1409/4000: train_loss=0.0047  test_loss=98.7381  λ_max=2.7082\n",
      "[Muon | lr=0.1] Epoch 1410/4000: train_loss=0.0059  test_loss=98.7290  λ_max=3.0556\n",
      "[Muon | lr=0.1] Epoch 1411/4000: train_loss=0.0057  test_loss=98.8252  λ_max=2.7846\n",
      "[Muon | lr=0.1] Epoch 1412/4000: train_loss=0.0049  test_loss=98.9026  λ_max=2.9455\n",
      "[Muon | lr=0.1] Iter 22600: loss=0.0046\n",
      "[Muon | lr=0.1] Epoch 1413/4000: train_loss=0.0048  test_loss=98.9307  λ_max=2.6446\n",
      "[Muon | lr=0.1] Epoch 1414/4000: train_loss=0.0055  test_loss=99.1504  λ_max=2.8088\n",
      "[Muon | lr=0.1] Epoch 1415/4000: train_loss=0.0045  test_loss=99.0984  λ_max=2.8062\n",
      "[Muon | lr=0.1] Epoch 1416/4000: train_loss=0.0048  test_loss=99.0444  λ_max=2.7417\n",
      "[Muon | lr=0.1] Epoch 1417/4000: train_loss=0.0060  test_loss=99.1245  λ_max=3.0712\n",
      "[Muon | lr=0.1] Epoch 1418/4000: train_loss=0.0051  test_loss=99.2379  λ_max=2.8892\n",
      "[Muon | lr=0.1] Iter 22700: loss=0.0048\n",
      "[Muon | lr=0.1] Epoch 1419/4000: train_loss=0.0046  test_loss=99.3614  λ_max=2.7727\n",
      "[Muon | lr=0.1] Epoch 1420/4000: train_loss=0.0054  test_loss=99.5478  λ_max=2.8092\n",
      "[Muon | lr=0.1] Epoch 1421/4000: train_loss=0.0046  test_loss=99.6800  λ_max=2.7888\n",
      "[Muon | lr=0.1] Epoch 1422/4000: train_loss=0.0055  test_loss=99.6055  λ_max=2.7636\n",
      "[Muon | lr=0.1] Epoch 1423/4000: train_loss=0.0045  test_loss=99.7365  λ_max=2.8038\n",
      "[Muon | lr=0.1] Epoch 1424/4000: train_loss=0.0044  test_loss=99.9058  λ_max=2.8996\n",
      "[Muon | lr=0.1] Iter 22800: loss=0.0097\n",
      "[Muon | lr=0.1] Epoch 1425/4000: train_loss=0.0057  test_loss=100.0491  λ_max=2.7019\n",
      "[Muon | lr=0.1] Epoch 1426/4000: train_loss=0.0052  test_loss=100.2670  λ_max=3.2075\n",
      "[Muon | lr=0.1] Epoch 1427/4000: train_loss=0.0050  test_loss=100.4645  λ_max=2.8137\n",
      "[Muon | lr=0.1] Epoch 1428/4000: train_loss=0.0042  test_loss=100.2274  λ_max=2.8069\n",
      "[Muon | lr=0.1] Epoch 1429/4000: train_loss=0.0048  test_loss=100.1581  λ_max=2.5737\n",
      "[Muon | lr=0.1] Epoch 1430/4000: train_loss=0.0052  test_loss=100.2624  λ_max=3.3127\n",
      "[Muon | lr=0.1] Epoch 1431/4000: train_loss=0.0053  test_loss=100.4988  λ_max=3.0123\n",
      "[Muon | lr=0.1] Iter 22900: loss=0.0013\n",
      "[Muon | lr=0.1] Epoch 1432/4000: train_loss=0.0052  test_loss=100.5170  λ_max=3.2379\n",
      "[Muon | lr=0.1] Epoch 1433/4000: train_loss=0.0053  test_loss=100.4925  λ_max=2.9011\n",
      "[Muon | lr=0.1] Epoch 1434/4000: train_loss=0.0052  test_loss=100.6078  λ_max=2.8794\n",
      "[Muon | lr=0.1] Epoch 1435/4000: train_loss=0.0053  test_loss=100.6284  λ_max=2.8214\n",
      "[Muon | lr=0.1] Epoch 1436/4000: train_loss=0.0053  test_loss=100.8624  λ_max=2.6820\n",
      "[Muon | lr=0.1] Epoch 1437/4000: train_loss=0.0057  test_loss=101.1420  λ_max=2.9560\n",
      "[Muon | lr=0.1] Iter 23000: loss=0.0039\n",
      "[Muon | lr=0.1] Epoch 1438/4000: train_loss=0.0048  test_loss=101.1878  λ_max=2.8284\n",
      "[Muon | lr=0.1] Epoch 1439/4000: train_loss=0.0051  test_loss=101.1512  λ_max=2.8079\n",
      "[Muon | lr=0.1] Epoch 1440/4000: train_loss=0.0058  test_loss=101.2312  λ_max=2.8255\n",
      "[Muon | lr=0.1] Epoch 1441/4000: train_loss=0.0052  test_loss=101.3734  λ_max=2.7054\n",
      "[Muon | lr=0.1] Epoch 1442/4000: train_loss=0.0051  test_loss=101.2884  λ_max=2.8958\n",
      "[Muon | lr=0.1] Epoch 1443/4000: train_loss=0.0053  test_loss=101.2347  λ_max=2.7910\n",
      "[Muon | lr=0.1] Iter 23100: loss=0.0071\n",
      "[Muon | lr=0.1] Epoch 1444/4000: train_loss=0.0050  test_loss=101.2013  λ_max=2.7116\n",
      "[Muon | lr=0.1] Epoch 1445/4000: train_loss=0.0052  test_loss=101.3148  λ_max=2.7389\n",
      "[Muon | lr=0.1] Epoch 1446/4000: train_loss=0.0052  test_loss=101.4510  λ_max=3.4297\n",
      "[Muon | lr=0.1] Epoch 1447/4000: train_loss=0.0058  test_loss=101.6537  λ_max=2.9829\n",
      "[Muon | lr=0.1] Epoch 1448/4000: train_loss=0.0050  test_loss=101.8466  λ_max=2.8709\n",
      "[Muon | lr=0.1] Epoch 1449/4000: train_loss=0.0049  test_loss=101.9525  λ_max=3.1083\n",
      "[Muon | lr=0.1] Iter 23200: loss=0.0103\n",
      "[Muon | lr=0.1] Epoch 1450/4000: train_loss=0.0051  test_loss=102.2210  λ_max=2.6607\n",
      "[Muon | lr=0.1] Epoch 1451/4000: train_loss=0.0051  test_loss=102.3652  λ_max=3.0377\n",
      "[Muon | lr=0.1] Epoch 1452/4000: train_loss=0.0064  test_loss=102.5445  λ_max=3.6470\n",
      "[Muon | lr=0.1] Epoch 1453/4000: train_loss=0.0067  test_loss=102.5239  λ_max=2.8643\n",
      "[Muon | lr=0.1] Epoch 1454/4000: train_loss=0.0050  test_loss=102.4159  λ_max=3.1410\n",
      "[Muon | lr=0.1] Epoch 1455/4000: train_loss=0.0052  test_loss=102.3744  λ_max=2.8100\n",
      "[Muon | lr=0.1] Epoch 1456/4000: train_loss=0.0045  test_loss=102.5600  λ_max=2.8787\n",
      "[Muon | lr=0.1] Iter 23300: loss=0.0039\n",
      "[Muon | lr=0.1] Epoch 1457/4000: train_loss=0.0049  test_loss=102.6325  λ_max=3.0027\n",
      "[Muon | lr=0.1] Epoch 1458/4000: train_loss=0.0061  test_loss=102.7217  λ_max=3.1050\n",
      "[Muon | lr=0.1] Epoch 1459/4000: train_loss=0.0053  test_loss=102.7721  λ_max=2.6320\n",
      "[Muon | lr=0.1] Epoch 1460/4000: train_loss=0.0051  test_loss=102.8223  λ_max=2.8784\n",
      "[Muon | lr=0.1] Epoch 1461/4000: train_loss=0.0047  test_loss=102.7194  λ_max=3.1001\n",
      "[Muon | lr=0.1] Epoch 1462/4000: train_loss=0.0048  test_loss=102.8642  λ_max=3.0252\n",
      "[Muon | lr=0.1] Iter 23400: loss=0.0052\n",
      "[Muon | lr=0.1] Epoch 1463/4000: train_loss=0.0053  test_loss=102.9306  λ_max=2.9864\n",
      "[Muon | lr=0.1] Epoch 1464/4000: train_loss=0.0053  test_loss=102.7893  λ_max=2.8369\n",
      "[Muon | lr=0.1] Epoch 1465/4000: train_loss=0.0048  test_loss=102.8255  λ_max=2.9113\n",
      "[Muon | lr=0.1] Epoch 1466/4000: train_loss=0.0044  test_loss=103.0123  λ_max=2.6856\n",
      "[Muon | lr=0.1] Epoch 1467/4000: train_loss=0.0052  test_loss=103.0594  λ_max=2.9549\n",
      "[Muon | lr=0.1] Epoch 1468/4000: train_loss=0.0043  test_loss=103.2679  λ_max=2.9460\n",
      "[Muon | lr=0.1] Iter 23500: loss=0.0024\n",
      "[Muon | lr=0.1] Epoch 1469/4000: train_loss=0.0045  test_loss=103.2308  λ_max=3.0956\n",
      "[Muon | lr=0.1] Epoch 1470/4000: train_loss=0.0059  test_loss=102.9770  λ_max=2.7079\n",
      "[Muon | lr=0.1] Epoch 1471/4000: train_loss=0.0049  test_loss=103.1550  λ_max=2.9022\n",
      "[Muon | lr=0.1] Epoch 1472/4000: train_loss=0.0049  test_loss=103.2043  λ_max=2.8318\n",
      "[Muon | lr=0.1] Epoch 1473/4000: train_loss=0.0049  test_loss=103.3201  λ_max=2.9083\n",
      "[Muon | lr=0.1] Epoch 1474/4000: train_loss=0.0053  test_loss=103.4749  λ_max=2.8481\n",
      "[Muon | lr=0.1] Iter 23600: loss=0.0045\n",
      "[Muon | lr=0.1] Epoch 1475/4000: train_loss=0.0046  test_loss=103.7230  λ_max=3.0478\n",
      "[Muon | lr=0.1] Epoch 1476/4000: train_loss=0.0039  test_loss=103.7096  λ_max=2.7868\n",
      "[Muon | lr=0.1] Epoch 1477/4000: train_loss=0.0056  test_loss=103.7683  λ_max=2.8525\n",
      "[Muon | lr=0.1] Epoch 1478/4000: train_loss=0.0051  test_loss=103.8915  λ_max=2.8684\n",
      "[Muon | lr=0.1] Epoch 1479/4000: train_loss=0.0042  test_loss=104.0385  λ_max=2.8359\n",
      "[Muon | lr=0.1] Epoch 1480/4000: train_loss=0.0049  test_loss=104.0957  λ_max=2.7965\n",
      "[Muon | lr=0.1] Epoch 1481/4000: train_loss=0.0051  test_loss=104.2691  λ_max=2.8141\n",
      "[Muon | lr=0.1] Iter 23700: loss=0.0015\n",
      "[Muon | lr=0.1] Epoch 1482/4000: train_loss=0.0040  test_loss=104.3478  λ_max=3.2445\n",
      "[Muon | lr=0.1] Epoch 1483/4000: train_loss=0.0041  test_loss=104.3371  λ_max=2.8262\n",
      "[Muon | lr=0.1] Epoch 1484/4000: train_loss=0.0049  test_loss=104.2982  λ_max=2.8817\n",
      "[Muon | lr=0.1] Epoch 1485/4000: train_loss=0.0059  test_loss=104.4191  λ_max=3.0363\n",
      "[Muon | lr=0.1] Epoch 1486/4000: train_loss=0.0053  test_loss=104.4469  λ_max=2.8649\n",
      "[Muon | lr=0.1] Epoch 1487/4000: train_loss=0.0048  test_loss=104.4425  λ_max=3.0282\n",
      "[Muon | lr=0.1] Iter 23800: loss=0.0062\n",
      "[Muon | lr=0.1] Epoch 1488/4000: train_loss=0.0050  test_loss=104.6432  λ_max=2.9404\n",
      "[Muon | lr=0.1] Epoch 1489/4000: train_loss=0.0056  test_loss=104.8046  λ_max=3.0260\n",
      "[Muon | lr=0.1] Epoch 1490/4000: train_loss=0.0054  test_loss=105.0763  λ_max=3.0092\n",
      "[Muon | lr=0.1] Epoch 1491/4000: train_loss=0.0054  test_loss=105.3289  λ_max=2.9826\n",
      "[Muon | lr=0.1] Epoch 1492/4000: train_loss=0.0045  test_loss=105.4157  λ_max=2.9922\n",
      "[Muon | lr=0.1] Epoch 1493/4000: train_loss=0.0047  test_loss=105.5303  λ_max=2.9242\n",
      "[Muon | lr=0.1] Iter 23900: loss=0.0094\n",
      "[Muon | lr=0.1] Epoch 1494/4000: train_loss=0.0041  test_loss=105.5059  λ_max=2.7762\n",
      "[Muon | lr=0.1] Epoch 1495/4000: train_loss=0.0042  test_loss=105.4465  λ_max=2.8611\n",
      "[Muon | lr=0.1] Epoch 1496/4000: train_loss=0.0049  test_loss=105.4472  λ_max=2.9588\n",
      "[Muon | lr=0.1] Epoch 1497/4000: train_loss=0.0047  test_loss=105.5176  λ_max=2.8458\n",
      "[Muon | lr=0.1] Epoch 1498/4000: train_loss=0.0060  test_loss=105.5977  λ_max=2.9023\n",
      "[Muon | lr=0.1] Epoch 1499/4000: train_loss=0.0053  test_loss=105.6682  λ_max=2.8357\n",
      "[Muon | lr=0.1] Iter 24000: loss=0.0050\n",
      "[Muon | lr=0.1] Epoch 1500/4000: train_loss=0.0055  test_loss=105.5784  λ_max=2.9563\n",
      "[Muon | lr=0.1] Epoch 1501/4000: train_loss=0.0039  test_loss=105.6052  λ_max=2.9586\n",
      "[Muon | lr=0.1] Epoch 1502/4000: train_loss=0.0047  test_loss=105.7122  λ_max=3.1045\n",
      "[Muon | lr=0.1] Epoch 1503/4000: train_loss=0.0043  test_loss=105.8549  λ_max=2.9805\n",
      "[Muon | lr=0.1] Epoch 1504/4000: train_loss=0.0047  test_loss=105.8233  λ_max=3.2184\n",
      "[Muon | lr=0.1] Epoch 1505/4000: train_loss=0.0052  test_loss=105.9587  λ_max=3.1339\n",
      "[Muon | lr=0.1] Epoch 1506/4000: train_loss=0.0046  test_loss=106.3275  λ_max=3.0846\n",
      "[Muon | lr=0.1] Iter 24100: loss=0.0071\n",
      "[Muon | lr=0.1] Epoch 1507/4000: train_loss=0.0051  test_loss=106.4389  λ_max=3.0238\n",
      "[Muon | lr=0.1] Epoch 1508/4000: train_loss=0.0049  test_loss=106.7155  λ_max=2.7473\n",
      "[Muon | lr=0.1] Epoch 1509/4000: train_loss=0.0046  test_loss=106.6970  λ_max=2.9620\n",
      "[Muon | lr=0.1] Epoch 1510/4000: train_loss=0.0044  test_loss=106.6715  λ_max=3.1976\n",
      "[Muon | lr=0.1] Epoch 1511/4000: train_loss=0.0057  test_loss=106.8186  λ_max=3.1050\n",
      "[Muon | lr=0.1] Epoch 1512/4000: train_loss=0.0058  test_loss=106.9708  λ_max=3.1987\n",
      "[Muon | lr=0.1] Iter 24200: loss=0.0017\n",
      "[Muon | lr=0.1] Epoch 1513/4000: train_loss=0.0051  test_loss=106.9104  λ_max=2.8664\n",
      "[Muon | lr=0.1] Epoch 1514/4000: train_loss=0.0049  test_loss=106.8593  λ_max=3.0493\n",
      "[Muon | lr=0.1] Epoch 1515/4000: train_loss=0.0049  test_loss=106.7931  λ_max=3.0452\n",
      "[Muon | lr=0.1] Epoch 1516/4000: train_loss=0.0052  test_loss=106.8801  λ_max=3.0620\n",
      "[Muon | lr=0.1] Epoch 1517/4000: train_loss=0.0060  test_loss=107.0021  λ_max=3.0459\n",
      "[Muon | lr=0.1] Epoch 1518/4000: train_loss=0.0062  test_loss=106.9594  λ_max=3.5787\n",
      "[Muon | lr=0.1] Iter 24300: loss=0.0035\n",
      "[Muon | lr=0.1] Epoch 1519/4000: train_loss=0.0041  test_loss=107.1145  λ_max=2.9940\n",
      "[Muon | lr=0.1] Epoch 1520/4000: train_loss=0.0050  test_loss=107.0505  λ_max=3.1074\n",
      "[Muon | lr=0.1] Epoch 1521/4000: train_loss=0.0055  test_loss=107.0188  λ_max=2.9923\n",
      "[Muon | lr=0.1] Epoch 1522/4000: train_loss=0.0037  test_loss=107.1345  λ_max=2.9500\n",
      "[Muon | lr=0.1] Epoch 1523/4000: train_loss=0.0062  test_loss=107.0590  λ_max=3.3333\n",
      "[Muon | lr=0.1] Epoch 1524/4000: train_loss=0.0056  test_loss=107.2215  λ_max=3.2029\n",
      "[Muon | lr=0.1] Iter 24400: loss=0.0054\n",
      "[Muon | lr=0.1] Epoch 1525/4000: train_loss=0.0045  test_loss=107.1872  λ_max=2.9685\n",
      "[Muon | lr=0.1] Epoch 1526/4000: train_loss=0.0051  test_loss=107.3522  λ_max=2.9085\n",
      "[Muon | lr=0.1] Epoch 1527/4000: train_loss=0.0048  test_loss=107.4899  λ_max=3.0635\n",
      "[Muon | lr=0.1] Epoch 1528/4000: train_loss=0.0061  test_loss=107.5147  λ_max=2.8900\n",
      "[Muon | lr=0.1] Epoch 1529/4000: train_loss=0.0046  test_loss=107.5372  λ_max=3.1078\n",
      "[Muon | lr=0.1] Epoch 1530/4000: train_loss=0.0046  test_loss=107.6433  λ_max=3.0059\n",
      "[Muon | lr=0.1] Epoch 1531/4000: train_loss=0.0048  test_loss=107.9108  λ_max=3.0007\n",
      "[Muon | lr=0.1] Iter 24500: loss=0.0011\n",
      "[Muon | lr=0.1] Epoch 1532/4000: train_loss=0.0047  test_loss=108.0883  λ_max=2.8604\n",
      "[Muon | lr=0.1] Epoch 1533/4000: train_loss=0.0041  test_loss=107.9728  λ_max=2.7811\n",
      "[Muon | lr=0.1] Epoch 1534/4000: train_loss=0.0050  test_loss=108.1038  λ_max=2.8537\n",
      "[Muon | lr=0.1] Epoch 1535/4000: train_loss=0.0043  test_loss=108.1410  λ_max=3.1866\n",
      "[Muon | lr=0.1] Epoch 1536/4000: train_loss=0.0044  test_loss=108.0863  λ_max=3.2904\n",
      "[Muon | lr=0.1] Epoch 1537/4000: train_loss=0.0046  test_loss=108.0324  λ_max=2.8279\n",
      "[Muon | lr=0.1] Iter 24600: loss=0.0054\n",
      "[Muon | lr=0.1] Epoch 1538/4000: train_loss=0.0047  test_loss=108.0606  λ_max=2.8546\n",
      "[Muon | lr=0.1] Epoch 1539/4000: train_loss=0.0054  test_loss=108.1658  λ_max=2.9019\n",
      "[Muon | lr=0.1] Epoch 1540/4000: train_loss=0.0040  test_loss=108.4602  λ_max=2.9459\n",
      "[Muon | lr=0.1] Epoch 1541/4000: train_loss=0.0037  test_loss=108.6651  λ_max=2.8226\n",
      "[Muon | lr=0.1] Epoch 1542/4000: train_loss=0.0053  test_loss=108.6318  λ_max=3.2714\n",
      "[Muon | lr=0.1] Epoch 1543/4000: train_loss=0.0055  test_loss=108.6847  λ_max=3.2208\n",
      "[Muon | lr=0.1] Iter 24700: loss=0.0075\n",
      "[Muon | lr=0.1] Epoch 1544/4000: train_loss=0.0048  test_loss=108.7719  λ_max=2.8231\n",
      "[Muon | lr=0.1] Epoch 1545/4000: train_loss=0.0042  test_loss=108.7832  λ_max=3.0908\n",
      "[Muon | lr=0.1] Epoch 1546/4000: train_loss=0.0045  test_loss=108.8206  λ_max=3.1353\n",
      "[Muon | lr=0.1] Epoch 1547/4000: train_loss=0.0052  test_loss=108.7592  λ_max=3.1576\n",
      "[Muon | lr=0.1] Epoch 1548/4000: train_loss=0.0066  test_loss=109.0343  λ_max=2.9033\n",
      "[Muon | lr=0.1] Epoch 1549/4000: train_loss=0.0068  test_loss=109.0984  λ_max=2.8829\n",
      "[Muon | lr=0.1] Iter 24800: loss=0.0131\n",
      "[Muon | lr=0.1] Epoch 1550/4000: train_loss=0.0052  test_loss=109.1719  λ_max=2.9739\n",
      "[Muon | lr=0.1] Epoch 1551/4000: train_loss=0.0040  test_loss=109.0775  λ_max=3.1879\n",
      "[Muon | lr=0.1] Epoch 1552/4000: train_loss=0.0053  test_loss=109.4115  λ_max=3.0668\n",
      "[Muon | lr=0.1] Epoch 1553/4000: train_loss=0.0058  test_loss=109.4539  λ_max=2.9655\n",
      "[Muon | lr=0.1] Epoch 1554/4000: train_loss=0.0049  test_loss=109.4315  λ_max=2.8505\n",
      "[Muon | lr=0.1] Epoch 1555/4000: train_loss=0.0050  test_loss=109.6147  λ_max=3.3120\n",
      "[Muon | lr=0.1] Epoch 1556/4000: train_loss=0.0057  test_loss=109.5083  λ_max=3.0746\n",
      "[Muon | lr=0.1] Iter 24900: loss=0.0014\n",
      "[Muon | lr=0.1] Epoch 1557/4000: train_loss=0.0056  test_loss=109.3711  λ_max=2.8278\n",
      "[Muon | lr=0.1] Epoch 1558/4000: train_loss=0.0040  test_loss=109.5124  λ_max=3.5075\n",
      "[Muon | lr=0.1] Epoch 1559/4000: train_loss=0.0050  test_loss=109.8335  λ_max=2.9452\n",
      "[Muon | lr=0.1] Epoch 1560/4000: train_loss=0.0054  test_loss=109.8832  λ_max=2.9475\n",
      "[Muon | lr=0.1] Epoch 1561/4000: train_loss=0.0055  test_loss=109.8882  λ_max=2.9514\n",
      "[Muon | lr=0.1] Epoch 1562/4000: train_loss=0.0054  test_loss=109.7852  λ_max=3.3962\n",
      "[Muon | lr=0.1] Iter 25000: loss=0.0026\n",
      "[Muon | lr=0.1] Epoch 1563/4000: train_loss=0.0048  test_loss=109.9367  λ_max=3.3034\n",
      "[Muon | lr=0.1] Epoch 1564/4000: train_loss=0.0055  test_loss=110.1086  λ_max=3.6334\n",
      "[Muon | lr=0.1] Epoch 1565/4000: train_loss=0.0046  test_loss=110.2174  λ_max=3.0308\n",
      "[Muon | lr=0.1] Epoch 1566/4000: train_loss=0.0055  test_loss=110.3394  λ_max=2.9134\n",
      "[Muon | lr=0.1] Epoch 1567/4000: train_loss=0.0048  test_loss=110.4512  λ_max=3.0516\n",
      "[Muon | lr=0.1] Epoch 1568/4000: train_loss=0.0052  test_loss=110.4466  λ_max=3.5287\n",
      "[Muon | lr=0.1] Iter 25100: loss=0.0032\n",
      "[Muon | lr=0.1] Epoch 1569/4000: train_loss=0.0045  test_loss=110.4308  λ_max=3.1621\n",
      "[Muon | lr=0.1] Epoch 1570/4000: train_loss=0.0043  test_loss=110.4835  λ_max=3.0525\n",
      "[Muon | lr=0.1] Epoch 1571/4000: train_loss=0.0048  test_loss=110.4203  λ_max=3.0506\n",
      "[Muon | lr=0.1] Epoch 1572/4000: train_loss=0.0045  test_loss=110.5180  λ_max=3.3475\n",
      "[Muon | lr=0.1] Epoch 1573/4000: train_loss=0.0058  test_loss=110.6919  λ_max=3.0304\n",
      "[Muon | lr=0.1] Epoch 1574/4000: train_loss=0.0054  test_loss=110.6996  λ_max=3.2730\n",
      "[Muon | lr=0.1] Iter 25200: loss=0.0093\n",
      "[Muon | lr=0.1] Epoch 1575/4000: train_loss=0.0056  test_loss=110.8671  λ_max=2.8647\n",
      "[Muon | lr=0.1] Epoch 1576/4000: train_loss=0.0051  test_loss=110.8310  λ_max=3.2108\n",
      "[Muon | lr=0.1] Epoch 1577/4000: train_loss=0.0051  test_loss=110.8050  λ_max=2.9460\n",
      "[Muon | lr=0.1] Epoch 1578/4000: train_loss=0.0058  test_loss=110.9069  λ_max=3.0302\n",
      "[Muon | lr=0.1] Epoch 1579/4000: train_loss=0.0052  test_loss=111.3012  λ_max=2.8188\n",
      "[Muon | lr=0.1] Epoch 1580/4000: train_loss=0.0047  test_loss=111.6038  λ_max=2.9557\n",
      "[Muon | lr=0.1] Epoch 1581/4000: train_loss=0.0048  test_loss=111.6212  λ_max=3.0356\n",
      "[Muon | lr=0.1] Iter 25300: loss=0.0053\n",
      "[Muon | lr=0.1] Epoch 1582/4000: train_loss=0.0047  test_loss=111.5383  λ_max=2.8751\n",
      "[Muon | lr=0.1] Epoch 1583/4000: train_loss=0.0050  test_loss=111.3993  λ_max=3.0274\n",
      "[Muon | lr=0.1] Epoch 1584/4000: train_loss=0.0044  test_loss=111.5842  λ_max=2.9639\n",
      "[Muon | lr=0.1] Epoch 1585/4000: train_loss=0.0047  test_loss=111.5291  λ_max=4.1003\n",
      "[Muon | lr=0.1] Epoch 1586/4000: train_loss=0.0041  test_loss=111.6037  λ_max=3.0593\n",
      "[Muon | lr=0.1] Epoch 1587/4000: train_loss=0.0041  test_loss=111.6678  λ_max=3.4030\n",
      "[Muon | lr=0.1] Iter 25400: loss=0.0109\n",
      "[Muon | lr=0.1] Epoch 1588/4000: train_loss=0.0062  test_loss=111.9550  λ_max=3.2634\n",
      "[Muon | lr=0.1] Epoch 1589/4000: train_loss=0.0047  test_loss=111.8715  λ_max=3.0730\n",
      "[Muon | lr=0.1] Epoch 1590/4000: train_loss=0.0051  test_loss=111.9630  λ_max=3.2384\n",
      "[Muon | lr=0.1] Epoch 1591/4000: train_loss=0.0044  test_loss=111.9442  λ_max=3.1386\n",
      "[Muon | lr=0.1] Epoch 1592/4000: train_loss=0.0047  test_loss=111.8945  λ_max=3.1739\n",
      "[Muon | lr=0.1] Epoch 1593/4000: train_loss=0.0047  test_loss=112.1156  λ_max=3.1479\n",
      "[Muon | lr=0.1] Iter 25500: loss=0.0045\n",
      "[Muon | lr=0.1] Epoch 1594/4000: train_loss=0.0057  test_loss=112.1509  λ_max=3.1858\n",
      "[Muon | lr=0.1] Epoch 1595/4000: train_loss=0.0046  test_loss=112.2924  λ_max=3.2420\n",
      "[Muon | lr=0.1] Epoch 1596/4000: train_loss=0.0056  test_loss=112.3343  λ_max=3.2897\n",
      "[Muon | lr=0.1] Epoch 1597/4000: train_loss=0.0043  test_loss=112.1549  λ_max=3.2782\n",
      "[Muon | lr=0.1] Epoch 1598/4000: train_loss=0.0041  test_loss=112.1736  λ_max=3.0997\n",
      "[Muon | lr=0.1] Epoch 1599/4000: train_loss=0.0048  test_loss=112.1412  λ_max=3.0686\n",
      "[Muon | lr=0.1] Iter 25600: loss=0.0065\n",
      "[Muon | lr=0.1] Epoch 1600/4000: train_loss=0.0044  test_loss=112.1095  λ_max=3.2267\n",
      "[Muon | lr=0.1] Epoch 1601/4000: train_loss=0.0039  test_loss=112.3817  λ_max=2.8734\n",
      "[Muon | lr=0.1] Epoch 1602/4000: train_loss=0.0052  test_loss=112.4763  λ_max=3.0775\n",
      "[Muon | lr=0.1] Epoch 1603/4000: train_loss=0.0054  test_loss=112.6258  λ_max=2.9787\n",
      "[Muon | lr=0.1] Epoch 1604/4000: train_loss=0.0053  test_loss=112.7707  λ_max=2.9425\n",
      "[Muon | lr=0.1] Epoch 1605/4000: train_loss=0.0044  test_loss=112.9681  λ_max=2.9847\n",
      "[Muon | lr=0.1] Epoch 1606/4000: train_loss=0.0051  test_loss=113.1750  λ_max=3.2139\n",
      "[Muon | lr=0.1] Iter 25700: loss=0.0018\n",
      "[Muon | lr=0.1] Epoch 1607/4000: train_loss=0.0041  test_loss=113.4071  λ_max=2.8940\n",
      "[Muon | lr=0.1] Epoch 1608/4000: train_loss=0.0052  test_loss=113.2859  λ_max=2.6918\n",
      "[Muon | lr=0.1] Epoch 1609/4000: train_loss=0.0054  test_loss=113.3288  λ_max=3.0844\n",
      "[Muon | lr=0.1] Epoch 1610/4000: train_loss=0.0047  test_loss=113.4848  λ_max=2.9444\n",
      "[Muon | lr=0.1] Epoch 1611/4000: train_loss=0.0040  test_loss=113.6702  λ_max=3.0263\n",
      "[Muon | lr=0.1] Epoch 1612/4000: train_loss=0.0047  test_loss=113.7839  λ_max=3.4083\n",
      "[Muon | lr=0.1] Iter 25800: loss=0.0023\n",
      "[Muon | lr=0.1] Epoch 1613/4000: train_loss=0.0049  test_loss=113.8569  λ_max=3.1280\n",
      "[Muon | lr=0.1] Epoch 1614/4000: train_loss=0.0046  test_loss=113.9749  λ_max=3.2192\n",
      "[Muon | lr=0.1] Epoch 1615/4000: train_loss=0.0052  test_loss=114.0408  λ_max=2.9836\n",
      "[Muon | lr=0.1] Epoch 1616/4000: train_loss=0.0052  test_loss=113.9833  λ_max=3.3824\n",
      "[Muon | lr=0.1] Epoch 1617/4000: train_loss=0.0040  test_loss=113.9733  λ_max=3.3262\n",
      "[Muon | lr=0.1] Epoch 1618/4000: train_loss=0.0052  test_loss=114.0524  λ_max=3.0371\n",
      "[Muon | lr=0.1] Iter 25900: loss=0.0063\n",
      "[Muon | lr=0.1] Epoch 1619/4000: train_loss=0.0055  test_loss=114.3663  λ_max=2.9439\n",
      "[Muon | lr=0.1] Epoch 1620/4000: train_loss=0.0047  test_loss=114.5361  λ_max=3.1785\n",
      "[Muon | lr=0.1] Epoch 1621/4000: train_loss=0.0056  test_loss=114.5905  λ_max=3.4024\n",
      "[Muon | lr=0.1] Epoch 1622/4000: train_loss=0.0057  test_loss=114.6827  λ_max=3.2564\n",
      "[Muon | lr=0.1] Epoch 1623/4000: train_loss=0.0039  test_loss=114.8692  λ_max=3.0806\n",
      "[Muon | lr=0.1] Epoch 1624/4000: train_loss=0.0058  test_loss=114.9027  λ_max=3.1243\n",
      "[Muon | lr=0.1] Iter 26000: loss=0.0216\n",
      "[Muon | lr=0.1] Epoch 1625/4000: train_loss=0.0058  test_loss=115.1402  λ_max=3.2865\n",
      "[Muon | lr=0.1] Epoch 1626/4000: train_loss=0.0059  test_loss=115.2944  λ_max=3.2388\n",
      "[Muon | lr=0.1] Epoch 1627/4000: train_loss=0.0043  test_loss=115.4489  λ_max=2.9837\n",
      "[Muon | lr=0.1] Epoch 1628/4000: train_loss=0.0044  test_loss=115.5092  λ_max=3.1093\n",
      "[Muon | lr=0.1] Epoch 1629/4000: train_loss=0.0050  test_loss=115.4966  λ_max=3.0748\n",
      "[Muon | lr=0.1] Epoch 1630/4000: train_loss=0.0052  test_loss=115.5085  λ_max=3.2659\n",
      "[Muon | lr=0.1] Epoch 1631/4000: train_loss=0.0060  test_loss=115.6568  λ_max=2.9481\n",
      "[Muon | lr=0.1] Iter 26100: loss=0.0025\n",
      "[Muon | lr=0.1] Epoch 1632/4000: train_loss=0.0050  test_loss=115.5756  λ_max=3.6243\n",
      "[Muon | lr=0.1] Epoch 1633/4000: train_loss=0.0045  test_loss=115.6549  λ_max=3.2056\n",
      "[Muon | lr=0.1] Epoch 1634/4000: train_loss=0.0037  test_loss=115.5339  λ_max=2.8803\n",
      "[Muon | lr=0.1] Epoch 1635/4000: train_loss=0.0048  test_loss=115.7314  λ_max=3.1079\n",
      "[Muon | lr=0.1] Epoch 1636/4000: train_loss=0.0047  test_loss=115.6538  λ_max=3.3237\n",
      "[Muon | lr=0.1] Epoch 1637/4000: train_loss=0.0046  test_loss=115.7756  λ_max=2.8498\n",
      "[Muon | lr=0.1] Iter 26200: loss=0.0046\n",
      "[Muon | lr=0.1] Epoch 1638/4000: train_loss=0.0039  test_loss=115.9157  λ_max=3.5388\n",
      "[Muon | lr=0.1] Epoch 1639/4000: train_loss=0.0055  test_loss=115.9628  λ_max=3.1027\n",
      "[Muon | lr=0.1] Epoch 1640/4000: train_loss=0.0052  test_loss=116.0591  λ_max=3.2718\n",
      "[Muon | lr=0.1] Epoch 1641/4000: train_loss=0.0039  test_loss=116.1121  λ_max=2.9809\n",
      "[Muon | lr=0.1] Epoch 1642/4000: train_loss=0.0042  test_loss=115.9100  λ_max=2.9251\n",
      "[Muon | lr=0.1] Epoch 1643/4000: train_loss=0.0052  test_loss=115.8104  λ_max=3.2707\n",
      "[Muon | lr=0.1] Iter 26300: loss=0.0052\n",
      "[Muon | lr=0.1] Epoch 1644/4000: train_loss=0.0052  test_loss=116.0317  λ_max=3.4222\n",
      "[Muon | lr=0.1] Epoch 1645/4000: train_loss=0.0058  test_loss=116.2858  λ_max=3.3265\n",
      "[Muon | lr=0.1] Epoch 1646/4000: train_loss=0.0051  test_loss=116.3403  λ_max=3.2635\n",
      "[Muon | lr=0.1] Epoch 1647/4000: train_loss=0.0042  test_loss=116.6806  λ_max=3.2762\n",
      "[Muon | lr=0.1] Epoch 1648/4000: train_loss=0.0053  test_loss=116.8069  λ_max=3.1508\n",
      "[Muon | lr=0.1] Epoch 1649/4000: train_loss=0.0043  test_loss=117.0527  λ_max=3.1693\n",
      "[Muon | lr=0.1] Iter 26400: loss=0.0014\n",
      "[Muon | lr=0.1] Epoch 1650/4000: train_loss=0.0049  test_loss=117.2178  λ_max=3.0589\n",
      "[Muon | lr=0.1] Epoch 1651/4000: train_loss=0.0037  test_loss=117.3798  λ_max=3.0324\n",
      "[Muon | lr=0.1] Epoch 1652/4000: train_loss=0.0044  test_loss=117.4076  λ_max=3.1182\n",
      "[Muon | lr=0.1] Epoch 1653/4000: train_loss=0.0045  test_loss=117.2920  λ_max=3.0314\n",
      "[Muon | lr=0.1] Epoch 1654/4000: train_loss=0.0048  test_loss=117.5056  λ_max=3.1219\n",
      "[Muon | lr=0.1] Epoch 1655/4000: train_loss=0.0045  test_loss=117.6489  λ_max=3.1339\n",
      "[Muon | lr=0.1] Epoch 1656/4000: train_loss=0.0052  test_loss=117.6504  λ_max=3.1537\n",
      "[Muon | lr=0.1] Iter 26500: loss=0.0003\n",
      "[Muon | lr=0.1] Epoch 1657/4000: train_loss=0.0046  test_loss=117.8247  λ_max=3.0936\n",
      "[Muon | lr=0.1] Epoch 1658/4000: train_loss=0.0046  test_loss=118.0610  λ_max=3.1176\n",
      "[Muon | lr=0.1] Epoch 1659/4000: train_loss=0.0052  test_loss=118.2151  λ_max=3.2979\n",
      "[Muon | lr=0.1] Epoch 1660/4000: train_loss=0.0048  test_loss=118.3841  λ_max=3.0366\n",
      "[Muon | lr=0.1] Epoch 1661/4000: train_loss=0.0046  test_loss=118.4309  λ_max=2.9433\n",
      "[Muon | lr=0.1] Epoch 1662/4000: train_loss=0.0051  test_loss=118.5719  λ_max=3.0297\n",
      "[Muon | lr=0.1] Iter 26600: loss=0.0047\n",
      "[Muon | lr=0.1] Epoch 1663/4000: train_loss=0.0055  test_loss=118.6178  λ_max=3.0366\n",
      "[Muon | lr=0.1] Epoch 1664/4000: train_loss=0.0055  test_loss=118.7352  λ_max=3.1093\n",
      "[Muon | lr=0.1] Epoch 1665/4000: train_loss=0.0052  test_loss=118.8632  λ_max=3.3709\n",
      "[Muon | lr=0.1] Epoch 1666/4000: train_loss=0.0040  test_loss=119.0716  λ_max=3.2396\n",
      "[Muon | lr=0.1] Epoch 1667/4000: train_loss=0.0045  test_loss=119.1841  λ_max=2.8916\n",
      "[Muon | lr=0.1] Epoch 1668/4000: train_loss=0.0040  test_loss=119.2641  λ_max=3.1424\n",
      "[Muon | lr=0.1] Iter 26700: loss=0.0048\n",
      "[Muon | lr=0.1] Epoch 1669/4000: train_loss=0.0047  test_loss=119.3736  λ_max=3.3876\n",
      "[Muon | lr=0.1] Epoch 1670/4000: train_loss=0.0046  test_loss=119.3535  λ_max=3.1303\n",
      "[Muon | lr=0.1] Epoch 1671/4000: train_loss=0.0052  test_loss=119.1677  λ_max=3.5350\n",
      "[Muon | lr=0.1] Epoch 1672/4000: train_loss=0.0048  test_loss=119.2352  λ_max=3.3401\n",
      "[Muon | lr=0.1] Epoch 1673/4000: train_loss=0.0041  test_loss=119.3725  λ_max=3.1003\n",
      "[Muon | lr=0.1] Epoch 1674/4000: train_loss=0.0055  test_loss=119.2832  λ_max=3.6512\n",
      "[Muon | lr=0.1] Iter 26800: loss=0.0077\n",
      "[Muon | lr=0.1] Epoch 1675/4000: train_loss=0.0060  test_loss=119.5025  λ_max=3.0952\n",
      "[Muon | lr=0.1] Epoch 1676/4000: train_loss=0.0046  test_loss=119.6321  λ_max=3.2208\n",
      "[Muon | lr=0.1] Epoch 1677/4000: train_loss=0.0049  test_loss=119.7037  λ_max=3.6138\n",
      "[Muon | lr=0.1] Epoch 1678/4000: train_loss=0.0053  test_loss=119.9326  λ_max=2.8861\n",
      "[Muon | lr=0.1] Epoch 1679/4000: train_loss=0.0063  test_loss=120.0173  λ_max=3.3130\n",
      "[Muon | lr=0.1] Epoch 1680/4000: train_loss=0.0050  test_loss=120.0955  λ_max=3.0921\n",
      "[Muon | lr=0.1] Epoch 1681/4000: train_loss=0.0052  test_loss=120.3297  λ_max=3.0622\n",
      "[Muon | lr=0.1] Iter 26900: loss=0.0031\n",
      "[Muon | lr=0.1] Epoch 1682/4000: train_loss=0.0056  test_loss=120.2010  λ_max=3.0684\n",
      "[Muon | lr=0.1] Epoch 1683/4000: train_loss=0.0058  test_loss=120.1780  λ_max=3.3767\n",
      "[Muon | lr=0.1] Epoch 1684/4000: train_loss=0.0055  test_loss=120.2608  λ_max=3.3140\n",
      "[Muon | lr=0.1] Epoch 1685/4000: train_loss=0.0038  test_loss=120.5728  λ_max=3.1152\n",
      "[Muon | lr=0.1] Epoch 1686/4000: train_loss=0.0046  test_loss=120.6521  λ_max=2.9601\n",
      "[Muon | lr=0.1] Epoch 1687/4000: train_loss=0.0052  test_loss=120.7731  λ_max=3.0386\n",
      "[Muon | lr=0.1] Iter 27000: loss=0.0041\n",
      "[Muon | lr=0.1] Epoch 1688/4000: train_loss=0.0048  test_loss=120.9245  λ_max=3.1103\n",
      "[Muon | lr=0.1] Epoch 1689/4000: train_loss=0.0038  test_loss=121.1295  λ_max=3.3395\n",
      "[Muon | lr=0.1] Epoch 1690/4000: train_loss=0.0042  test_loss=121.2318  λ_max=3.8336\n",
      "[Muon | lr=0.1] Epoch 1691/4000: train_loss=0.0052  test_loss=121.2304  λ_max=3.2825\n",
      "[Muon | lr=0.1] Epoch 1692/4000: train_loss=0.0044  test_loss=121.1399  λ_max=3.1231\n",
      "[Muon | lr=0.1] Epoch 1693/4000: train_loss=0.0057  test_loss=121.2011  λ_max=3.2848\n",
      "[Muon | lr=0.1] Iter 27100: loss=0.0093\n",
      "[Muon | lr=0.1] Epoch 1694/4000: train_loss=0.0053  test_loss=121.0368  λ_max=3.2806\n",
      "[Muon | lr=0.1] Epoch 1695/4000: train_loss=0.0053  test_loss=121.0446  λ_max=3.3574\n",
      "[Muon | lr=0.1] Epoch 1696/4000: train_loss=0.0042  test_loss=121.1721  λ_max=3.4286\n",
      "[Muon | lr=0.1] Epoch 1697/4000: train_loss=0.0046  test_loss=121.0383  λ_max=3.6133\n",
      "[Muon | lr=0.1] Epoch 1698/4000: train_loss=0.0053  test_loss=121.0916  λ_max=3.0937\n",
      "[Muon | lr=0.1] Epoch 1699/4000: train_loss=0.0048  test_loss=121.2806  λ_max=3.5604\n",
      "[Muon | lr=0.1] Iter 27200: loss=0.0048\n",
      "[Muon | lr=0.1] Epoch 1700/4000: train_loss=0.0047  test_loss=121.2222  λ_max=3.1630\n",
      "[Muon | lr=0.1] Epoch 1701/4000: train_loss=0.0057  test_loss=121.2277  λ_max=2.8293\n",
      "[Muon | lr=0.1] Epoch 1702/4000: train_loss=0.0044  test_loss=121.3147  λ_max=3.0906\n",
      "[Muon | lr=0.1] Epoch 1703/4000: train_loss=0.0049  test_loss=121.4361  λ_max=3.7653\n",
      "[Muon | lr=0.1] Epoch 1704/4000: train_loss=0.0052  test_loss=121.7222  λ_max=3.2028\n",
      "[Muon | lr=0.1] Epoch 1705/4000: train_loss=0.0042  test_loss=121.7305  λ_max=3.1584\n",
      "[Muon | lr=0.1] Epoch 1706/4000: train_loss=0.0044  test_loss=121.7283  λ_max=3.0947\n",
      "[Muon | lr=0.1] Iter 27300: loss=0.0037\n",
      "[Muon | lr=0.1] Epoch 1707/4000: train_loss=0.0046  test_loss=121.9436  λ_max=3.7927\n",
      "[Muon | lr=0.1] Epoch 1708/4000: train_loss=0.0060  test_loss=122.0171  λ_max=3.1309\n",
      "[Muon | lr=0.1] Epoch 1709/4000: train_loss=0.0057  test_loss=121.9383  λ_max=3.3062\n",
      "[Muon | lr=0.1] Epoch 1710/4000: train_loss=0.0044  test_loss=121.9901  λ_max=3.3509\n",
      "[Muon | lr=0.1] Epoch 1711/4000: train_loss=0.0050  test_loss=122.0293  λ_max=3.2944\n",
      "[Muon | lr=0.1] Epoch 1712/4000: train_loss=0.0060  test_loss=122.0282  λ_max=3.2846\n",
      "[Muon | lr=0.1] Iter 27400: loss=0.0043\n",
      "[Muon | lr=0.1] Epoch 1713/4000: train_loss=0.0042  test_loss=122.3058  λ_max=3.2486\n",
      "[Muon | lr=0.1] Epoch 1714/4000: train_loss=0.0045  test_loss=122.4216  λ_max=3.4687\n",
      "[Muon | lr=0.1] Epoch 1715/4000: train_loss=0.0053  test_loss=122.4084  λ_max=2.9725\n",
      "[Muon | lr=0.1] Epoch 1716/4000: train_loss=0.0050  test_loss=122.5417  λ_max=3.2619\n",
      "[Muon | lr=0.1] Epoch 1717/4000: train_loss=0.0050  test_loss=122.6463  λ_max=3.2399\n",
      "[Muon | lr=0.1] Epoch 1718/4000: train_loss=0.0054  test_loss=122.7507  λ_max=3.0926\n",
      "[Muon | lr=0.1] Iter 27500: loss=0.0060\n",
      "[Muon | lr=0.1] Epoch 1719/4000: train_loss=0.0051  test_loss=122.9941  λ_max=3.2853\n",
      "[Muon | lr=0.1] Epoch 1720/4000: train_loss=0.0055  test_loss=123.1534  λ_max=3.0558\n",
      "[Muon | lr=0.1] Epoch 1721/4000: train_loss=0.0050  test_loss=123.3121  λ_max=3.3397\n",
      "[Muon | lr=0.1] Epoch 1722/4000: train_loss=0.0045  test_loss=123.6501  λ_max=3.2525\n",
      "[Muon | lr=0.1] Epoch 1723/4000: train_loss=0.0061  test_loss=123.6920  λ_max=3.1752\n",
      "[Muon | lr=0.1] Epoch 1724/4000: train_loss=0.0050  test_loss=123.5998  λ_max=3.1964\n",
      "[Muon | lr=0.1] Iter 27600: loss=0.0061\n",
      "[Muon | lr=0.1] Epoch 1725/4000: train_loss=0.0046  test_loss=123.5325  λ_max=3.1454\n",
      "[Muon | lr=0.1] Epoch 1726/4000: train_loss=0.0047  test_loss=123.3793  λ_max=3.1749\n",
      "[Muon | lr=0.1] Epoch 1727/4000: train_loss=0.0039  test_loss=123.4874  λ_max=3.0716\n",
      "[Muon | lr=0.1] Epoch 1728/4000: train_loss=0.0055  test_loss=123.2666  λ_max=3.7596\n",
      "[Muon | lr=0.1] Epoch 1729/4000: train_loss=0.0060  test_loss=123.3155  λ_max=3.2333\n",
      "[Muon | lr=0.1] Epoch 1730/4000: train_loss=0.0055  test_loss=123.2105  λ_max=3.4641\n",
      "[Muon | lr=0.1] Epoch 1731/4000: train_loss=0.0049  test_loss=123.1302  λ_max=3.2430\n",
      "[Muon | lr=0.1] Iter 27700: loss=0.0027\n",
      "[Muon | lr=0.1] Epoch 1732/4000: train_loss=0.0054  test_loss=123.3566  λ_max=3.3685\n",
      "[Muon | lr=0.1] Epoch 1733/4000: train_loss=0.0045  test_loss=123.8164  λ_max=3.2503\n",
      "[Muon | lr=0.1] Epoch 1734/4000: train_loss=0.0049  test_loss=123.7953  λ_max=3.3486\n",
      "[Muon | lr=0.1] Epoch 1735/4000: train_loss=0.0053  test_loss=124.1203  λ_max=3.1964\n",
      "[Muon | lr=0.1] Epoch 1736/4000: train_loss=0.0049  test_loss=124.1627  λ_max=2.8870\n",
      "[Muon | lr=0.1] Epoch 1737/4000: train_loss=0.0047  test_loss=124.2629  λ_max=3.4418\n",
      "[Muon | lr=0.1] Iter 27800: loss=0.0076\n",
      "[Muon | lr=0.1] Epoch 1738/4000: train_loss=0.0057  test_loss=124.1602  λ_max=4.0262\n",
      "[Muon | lr=0.1] Epoch 1739/4000: train_loss=0.0050  test_loss=124.3430  λ_max=3.9551\n",
      "[Muon | lr=0.1] Epoch 1740/4000: train_loss=0.0047  test_loss=124.2701  λ_max=3.0763\n",
      "[Muon | lr=0.1] Epoch 1741/4000: train_loss=0.0044  test_loss=124.1594  λ_max=3.3808\n",
      "[Muon | lr=0.1] Epoch 1742/4000: train_loss=0.0049  test_loss=124.2451  λ_max=3.0936\n",
      "[Muon | lr=0.1] Epoch 1743/4000: train_loss=0.0052  test_loss=124.3186  λ_max=3.2500\n",
      "[Muon | lr=0.1] Iter 27900: loss=0.0034\n",
      "[Muon | lr=0.1] Epoch 1744/4000: train_loss=0.0050  test_loss=124.3006  λ_max=3.2791\n",
      "[Muon | lr=0.1] Epoch 1745/4000: train_loss=0.0054  test_loss=124.4047  λ_max=3.1718\n",
      "[Muon | lr=0.1] Epoch 1746/4000: train_loss=0.0040  test_loss=124.4944  λ_max=3.3883\n",
      "[Muon | lr=0.1] Epoch 1747/4000: train_loss=0.0042  test_loss=124.4685  λ_max=3.0400\n",
      "[Muon | lr=0.1] Epoch 1748/4000: train_loss=0.0050  test_loss=124.3942  λ_max=3.1882\n",
      "[Muon | lr=0.1] Epoch 1749/4000: train_loss=0.0046  test_loss=124.3702  λ_max=2.8795\n",
      "[Muon | lr=0.1] Iter 28000: loss=0.0112\n",
      "[Muon | lr=0.1] Epoch 1750/4000: train_loss=0.0064  test_loss=124.2403  λ_max=3.3948\n",
      "[Muon | lr=0.1] Epoch 1751/4000: train_loss=0.0057  test_loss=124.2050  λ_max=3.2477\n",
      "[Muon | lr=0.1] Epoch 1752/4000: train_loss=0.0054  test_loss=124.3425  λ_max=3.2460\n",
      "[Muon | lr=0.1] Epoch 1753/4000: train_loss=0.0048  test_loss=124.5354  λ_max=3.5077\n",
      "[Muon | lr=0.1] Epoch 1754/4000: train_loss=0.0055  test_loss=124.5184  λ_max=3.2794\n",
      "[Muon | lr=0.1] Epoch 1755/4000: train_loss=0.0045  test_loss=124.5659  λ_max=3.3477\n",
      "[Muon | lr=0.1] Epoch 1756/4000: train_loss=0.0059  test_loss=124.6293  λ_max=3.5499\n",
      "[Muon | lr=0.1] Iter 28100: loss=0.0007\n",
      "[Muon | lr=0.1] Epoch 1757/4000: train_loss=0.0056  test_loss=124.7114  λ_max=3.6603\n",
      "[Muon | lr=0.1] Epoch 1758/4000: train_loss=0.0044  test_loss=124.6944  λ_max=3.2322\n",
      "[Muon | lr=0.1] Epoch 1759/4000: train_loss=0.0049  test_loss=124.8288  λ_max=3.3076\n",
      "[Muon | lr=0.1] Epoch 1760/4000: train_loss=0.0043  test_loss=124.8064  λ_max=3.2292\n",
      "[Muon | lr=0.1] Epoch 1761/4000: train_loss=0.0050  test_loss=124.8465  λ_max=3.3069\n",
      "[Muon | lr=0.1] Epoch 1762/4000: train_loss=0.0040  test_loss=124.8952  λ_max=3.1018\n",
      "[Muon | lr=0.1] Iter 28200: loss=0.0049\n",
      "[Muon | lr=0.1] Epoch 1763/4000: train_loss=0.0044  test_loss=124.9254  λ_max=3.6511\n",
      "[Muon | lr=0.1] Epoch 1764/4000: train_loss=0.0044  test_loss=125.1755  λ_max=3.2645\n",
      "[Muon | lr=0.1] Epoch 1765/4000: train_loss=0.0040  test_loss=125.1585  λ_max=3.3980\n",
      "[Muon | lr=0.1] Epoch 1766/4000: train_loss=0.0046  test_loss=125.2801  λ_max=3.3054\n",
      "[Muon | lr=0.1] Epoch 1767/4000: train_loss=0.0051  test_loss=125.3681  λ_max=2.9940\n",
      "[Muon | lr=0.1] Epoch 1768/4000: train_loss=0.0052  test_loss=125.2864  λ_max=3.4778\n",
      "[Muon | lr=0.1] Iter 28300: loss=0.0128\n",
      "[Muon | lr=0.1] Epoch 1769/4000: train_loss=0.0054  test_loss=125.0761  λ_max=3.0713\n",
      "[Muon | lr=0.1] Epoch 1770/4000: train_loss=0.0047  test_loss=125.2293  λ_max=3.0534\n",
      "[Muon | lr=0.1] Epoch 1771/4000: train_loss=0.0047  test_loss=125.3061  λ_max=3.1511\n",
      "[Muon | lr=0.1] Epoch 1772/4000: train_loss=0.0050  test_loss=125.2081  λ_max=3.0710\n",
      "[Muon | lr=0.1] Epoch 1773/4000: train_loss=0.0050  test_loss=125.5610  λ_max=3.2319\n",
      "[Muon | lr=0.1] Epoch 1774/4000: train_loss=0.0058  test_loss=125.6026  λ_max=3.5746\n",
      "[Muon | lr=0.1] Iter 28400: loss=0.0055\n",
      "[Muon | lr=0.1] Epoch 1775/4000: train_loss=0.0043  test_loss=125.7108  λ_max=3.1974\n",
      "[Muon | lr=0.1] Epoch 1776/4000: train_loss=0.0052  test_loss=125.9296  λ_max=3.4902\n",
      "[Muon | lr=0.1] Epoch 1777/4000: train_loss=0.0044  test_loss=126.3124  λ_max=3.1514\n",
      "[Muon | lr=0.1] Epoch 1778/4000: train_loss=0.0048  test_loss=126.6201  λ_max=3.3165\n",
      "[Muon | lr=0.1] Epoch 1779/4000: train_loss=0.0051  test_loss=126.7017  λ_max=3.1693\n",
      "[Muon | lr=0.1] Epoch 1780/4000: train_loss=0.0049  test_loss=126.7999  λ_max=3.5069\n",
      "[Muon | lr=0.1] Epoch 1781/4000: train_loss=0.0039  test_loss=126.8534  λ_max=3.2081\n",
      "[Muon | lr=0.1] Iter 28500: loss=0.0021\n",
      "[Muon | lr=0.1] Epoch 1782/4000: train_loss=0.0055  test_loss=126.8143  λ_max=3.3896\n",
      "[Muon | lr=0.1] Epoch 1783/4000: train_loss=0.0067  test_loss=126.7280  λ_max=3.0827\n",
      "[Muon | lr=0.1] Epoch 1784/4000: train_loss=0.0053  test_loss=126.9075  λ_max=3.5128\n",
      "[Muon | lr=0.1] Epoch 1785/4000: train_loss=0.0047  test_loss=126.7053  λ_max=3.3474\n",
      "[Muon | lr=0.1] Epoch 1786/4000: train_loss=0.0048  test_loss=126.7762  λ_max=3.1798\n",
      "[Muon | lr=0.1] Epoch 1787/4000: train_loss=0.0050  test_loss=126.9514  λ_max=3.2347\n",
      "[Muon | lr=0.1] Iter 28600: loss=0.0040\n",
      "[Muon | lr=0.1] Epoch 1788/4000: train_loss=0.0052  test_loss=126.8192  λ_max=3.4057\n",
      "[Muon | lr=0.1] Epoch 1789/4000: train_loss=0.0045  test_loss=126.8361  λ_max=3.0605\n",
      "[Muon | lr=0.1] Epoch 1790/4000: train_loss=0.0051  test_loss=126.8125  λ_max=3.2815\n",
      "[Muon | lr=0.1] Epoch 1791/4000: train_loss=0.0050  test_loss=126.8514  λ_max=3.3792\n",
      "[Muon | lr=0.1] Epoch 1792/4000: train_loss=0.0053  test_loss=126.9155  λ_max=3.3297\n",
      "[Muon | lr=0.1] Epoch 1793/4000: train_loss=0.0056  test_loss=126.9702  λ_max=3.4227\n",
      "[Muon | lr=0.1] Iter 28700: loss=0.0150\n",
      "[Muon | lr=0.1] Epoch 1794/4000: train_loss=0.0048  test_loss=127.1532  λ_max=3.4841\n",
      "[Muon | lr=0.1] Epoch 1795/4000: train_loss=0.0047  test_loss=127.1649  λ_max=3.3437\n",
      "[Muon | lr=0.1] Epoch 1796/4000: train_loss=0.0051  test_loss=127.2009  λ_max=3.3419\n",
      "[Muon | lr=0.1] Epoch 1797/4000: train_loss=0.0053  test_loss=127.1401  λ_max=3.4894\n",
      "[Muon | lr=0.1] Epoch 1798/4000: train_loss=0.0060  test_loss=127.2468  λ_max=3.7413\n",
      "[Muon | lr=0.1] Epoch 1799/4000: train_loss=0.0052  test_loss=127.4174  λ_max=3.6395\n",
      "[Muon | lr=0.1] Iter 28800: loss=0.0058\n",
      "[Muon | lr=0.1] Epoch 1800/4000: train_loss=0.0044  test_loss=127.7868  λ_max=3.1945\n",
      "[Muon | lr=0.1] Epoch 1801/4000: train_loss=0.0051  test_loss=127.7704  λ_max=3.3242\n",
      "[Muon | lr=0.1] Epoch 1802/4000: train_loss=0.0041  test_loss=127.9285  λ_max=3.3075\n",
      "[Muon | lr=0.1] Epoch 1803/4000: train_loss=0.0054  test_loss=127.9114  λ_max=3.4817\n",
      "[Muon | lr=0.1] Epoch 1804/4000: train_loss=0.0046  test_loss=127.8224  λ_max=3.1769\n",
      "[Muon | lr=0.1] Epoch 1805/4000: train_loss=0.0044  test_loss=127.8865  λ_max=3.2945\n",
      "[Muon | lr=0.1] Epoch 1806/4000: train_loss=0.0052  test_loss=128.0259  λ_max=3.4512\n",
      "[Muon | lr=0.1] Iter 28900: loss=0.0015\n",
      "[Muon | lr=0.1] Epoch 1807/4000: train_loss=0.0044  test_loss=128.1843  λ_max=3.2471\n",
      "[Muon | lr=0.1] Epoch 1808/4000: train_loss=0.0049  test_loss=128.1310  λ_max=3.4567\n",
      "[Muon | lr=0.1] Epoch 1809/4000: train_loss=0.0049  test_loss=128.0947  λ_max=3.2718\n",
      "[Muon | lr=0.1] Epoch 1810/4000: train_loss=0.0045  test_loss=127.9785  λ_max=3.5348\n",
      "[Muon | lr=0.1] Epoch 1811/4000: train_loss=0.0041  test_loss=127.8650  λ_max=3.2857\n",
      "[Muon | lr=0.1] Epoch 1812/4000: train_loss=0.0042  test_loss=127.6914  λ_max=3.3522\n",
      "[Muon | lr=0.1] Iter 29000: loss=0.0068\n",
      "[Muon | lr=0.1] Epoch 1813/4000: train_loss=0.0043  test_loss=127.9667  λ_max=3.5127\n",
      "[Muon | lr=0.1] Epoch 1814/4000: train_loss=0.0056  test_loss=128.3428  λ_max=3.3207\n",
      "[Muon | lr=0.1] Epoch 1815/4000: train_loss=0.0049  test_loss=128.3496  λ_max=3.2181\n",
      "[Muon | lr=0.1] Epoch 1816/4000: train_loss=0.0043  test_loss=128.3485  λ_max=3.2030\n",
      "[Muon | lr=0.1] Epoch 1817/4000: train_loss=0.0050  test_loss=128.0603  λ_max=3.5699\n",
      "[Muon | lr=0.1] Epoch 1818/4000: train_loss=0.0050  test_loss=127.9911  λ_max=3.3951\n",
      "[Muon | lr=0.1] Iter 29100: loss=0.0030\n",
      "[Muon | lr=0.1] Epoch 1819/4000: train_loss=0.0039  test_loss=127.9907  λ_max=3.4886\n",
      "[Muon | lr=0.1] Epoch 1820/4000: train_loss=0.0055  test_loss=128.2271  λ_max=3.7671\n",
      "[Muon | lr=0.1] Epoch 1821/4000: train_loss=0.0051  test_loss=128.5556  λ_max=3.3767\n",
      "[Muon | lr=0.1] Epoch 1822/4000: train_loss=0.0050  test_loss=128.9296  λ_max=3.7103\n",
      "[Muon | lr=0.1] Epoch 1823/4000: train_loss=0.0055  test_loss=129.2222  λ_max=3.4548\n",
      "[Muon | lr=0.1] Epoch 1824/4000: train_loss=0.0051  test_loss=129.1537  λ_max=3.5122\n",
      "[Muon | lr=0.1] Iter 29200: loss=0.0041\n",
      "[Muon | lr=0.1] Epoch 1825/4000: train_loss=0.0056  test_loss=129.0928  λ_max=3.3240\n",
      "[Muon | lr=0.1] Epoch 1826/4000: train_loss=0.0050  test_loss=129.2059  λ_max=3.2569\n",
      "[Muon | lr=0.1] Epoch 1827/4000: train_loss=0.0044  test_loss=129.3994  λ_max=3.3469\n",
      "[Muon | lr=0.1] Epoch 1828/4000: train_loss=0.0041  test_loss=129.6284  λ_max=3.3915\n",
      "[Muon | lr=0.1] Epoch 1829/4000: train_loss=0.0050  test_loss=129.6373  λ_max=3.4990\n",
      "[Muon | lr=0.1] Epoch 1830/4000: train_loss=0.0049  test_loss=129.8321  λ_max=3.4068\n",
      "[Muon | lr=0.1] Epoch 1831/4000: train_loss=0.0052  test_loss=130.0448  λ_max=3.8385\n",
      "[Muon | lr=0.1] Iter 29300: loss=0.0010\n",
      "[Muon | lr=0.1] Epoch 1832/4000: train_loss=0.0053  test_loss=130.2027  λ_max=3.3155\n",
      "[Muon | lr=0.1] Epoch 1833/4000: train_loss=0.0053  test_loss=130.0465  λ_max=3.6722\n",
      "[Muon | lr=0.1] Epoch 1834/4000: train_loss=0.0047  test_loss=129.9926  λ_max=3.2739\n",
      "[Muon | lr=0.1] Epoch 1835/4000: train_loss=0.0045  test_loss=129.9580  λ_max=3.1045\n",
      "[Muon | lr=0.1] Epoch 1836/4000: train_loss=0.0044  test_loss=130.2620  λ_max=3.5090\n",
      "[Muon | lr=0.1] Epoch 1837/4000: train_loss=0.0052  test_loss=130.0605  λ_max=2.9162\n",
      "[Muon | lr=0.1] Iter 29400: loss=0.0018\n",
      "[Muon | lr=0.1] Epoch 1838/4000: train_loss=0.0048  test_loss=130.0746  λ_max=3.0520\n",
      "[Muon | lr=0.1] Epoch 1839/4000: train_loss=0.0052  test_loss=130.3626  λ_max=3.0337\n",
      "[Muon | lr=0.1] Epoch 1840/4000: train_loss=0.0039  test_loss=130.5461  λ_max=3.5311\n",
      "[Muon | lr=0.1] Epoch 1841/4000: train_loss=0.0042  test_loss=130.5661  λ_max=3.2608\n",
      "[Muon | lr=0.1] Epoch 1842/4000: train_loss=0.0056  test_loss=130.5061  λ_max=3.1874\n",
      "[Muon | lr=0.1] Epoch 1843/4000: train_loss=0.0050  test_loss=130.5151  λ_max=3.9993\n",
      "[Muon | lr=0.1] Iter 29500: loss=0.0059\n",
      "[Muon | lr=0.1] Epoch 1844/4000: train_loss=0.0055  test_loss=130.6024  λ_max=3.1119\n",
      "[Muon | lr=0.1] Epoch 1845/4000: train_loss=0.0051  test_loss=130.4375  λ_max=3.4882\n",
      "[Muon | lr=0.1] Epoch 1846/4000: train_loss=0.0060  test_loss=130.3854  λ_max=3.2847\n",
      "[Muon | lr=0.1] Epoch 1847/4000: train_loss=0.0042  test_loss=130.3434  λ_max=3.4218\n",
      "[Muon | lr=0.1] Epoch 1848/4000: train_loss=0.0040  test_loss=130.3844  λ_max=3.1309\n",
      "[Muon | lr=0.1] Epoch 1849/4000: train_loss=0.0044  test_loss=130.3844  λ_max=3.0781\n",
      "[Muon | lr=0.1] Iter 29600: loss=0.0064\n",
      "[Muon | lr=0.1] Epoch 1850/4000: train_loss=0.0056  test_loss=130.4325  λ_max=3.4344\n",
      "[Muon | lr=0.1] Epoch 1851/4000: train_loss=0.0041  test_loss=130.5065  λ_max=3.5080\n",
      "[Muon | lr=0.1] Epoch 1852/4000: train_loss=0.0047  test_loss=130.6076  λ_max=3.4987\n",
      "[Muon | lr=0.1] Epoch 1853/4000: train_loss=0.0051  test_loss=130.8295  λ_max=3.3106\n",
      "[Muon | lr=0.1] Epoch 1854/4000: train_loss=0.0051  test_loss=130.9173  λ_max=3.3274\n",
      "[Muon | lr=0.1] Epoch 1855/4000: train_loss=0.0051  test_loss=130.9067  λ_max=3.4483\n",
      "[Muon | lr=0.1] Epoch 1856/4000: train_loss=0.0038  test_loss=131.0621  λ_max=3.4291\n",
      "[Muon | lr=0.1] Iter 29700: loss=0.0014\n",
      "[Muon | lr=0.1] Epoch 1857/4000: train_loss=0.0043  test_loss=131.0733  λ_max=3.3426\n",
      "[Muon | lr=0.1] Epoch 1858/4000: train_loss=0.0038  test_loss=131.3566  λ_max=3.1362\n",
      "[Muon | lr=0.1] Epoch 1859/4000: train_loss=0.0054  test_loss=131.5825  λ_max=3.5025\n",
      "[Muon | lr=0.1] Epoch 1860/4000: train_loss=0.0052  test_loss=131.5316  λ_max=3.3285\n",
      "[Muon | lr=0.1] Epoch 1861/4000: train_loss=0.0041  test_loss=131.5769  λ_max=3.4890\n",
      "[Muon | lr=0.1] Epoch 1862/4000: train_loss=0.0054  test_loss=131.7768  λ_max=3.3293\n",
      "[Muon | lr=0.1] Iter 29800: loss=0.0034\n",
      "[Muon | lr=0.1] Epoch 1863/4000: train_loss=0.0061  test_loss=131.7076  λ_max=3.5538\n",
      "[Muon | lr=0.1] Epoch 1864/4000: train_loss=0.0045  test_loss=131.8161  λ_max=3.2728\n",
      "[Muon | lr=0.1] Epoch 1865/4000: train_loss=0.0049  test_loss=132.1094  λ_max=3.3283\n",
      "[Muon | lr=0.1] Epoch 1866/4000: train_loss=0.0049  test_loss=132.3008  λ_max=3.4092\n",
      "[Muon | lr=0.1] Epoch 1867/4000: train_loss=0.0039  test_loss=132.5033  λ_max=3.4517\n",
      "[Muon | lr=0.1] Epoch 1868/4000: train_loss=0.0046  test_loss=132.6004  λ_max=3.3468\n",
      "[Muon | lr=0.1] Iter 29900: loss=0.0036\n",
      "[Muon | lr=0.1] Epoch 1869/4000: train_loss=0.0041  test_loss=132.7384  λ_max=3.3575\n",
      "[Muon | lr=0.1] Epoch 1870/4000: train_loss=0.0053  test_loss=132.7929  λ_max=3.4230\n",
      "[Muon | lr=0.1] Epoch 1871/4000: train_loss=0.0051  test_loss=132.9746  λ_max=3.6349\n",
      "[Muon | lr=0.1] Epoch 1872/4000: train_loss=0.0060  test_loss=133.0939  λ_max=3.4082\n",
      "[Muon | lr=0.1] Epoch 1873/4000: train_loss=0.0050  test_loss=133.1431  λ_max=3.4220\n",
      "[Muon | lr=0.1] Epoch 1874/4000: train_loss=0.0051  test_loss=133.3360  λ_max=3.4068\n",
      "[Muon | lr=0.1] Iter 30000: loss=0.0098\n",
      "[Muon | lr=0.1] Epoch 1875/4000: train_loss=0.0049  test_loss=133.4417  λ_max=3.2833\n",
      "[Muon | lr=0.1] Epoch 1876/4000: train_loss=0.0037  test_loss=133.4053  λ_max=3.3963\n",
      "[Muon | lr=0.1] Epoch 1877/4000: train_loss=0.0056  test_loss=133.5436  λ_max=3.2817\n",
      "[Muon | lr=0.1] Epoch 1878/4000: train_loss=0.0060  test_loss=133.4735  λ_max=3.4729\n",
      "[Muon | lr=0.1] Epoch 1879/4000: train_loss=0.0057  test_loss=133.5849  λ_max=3.3370\n",
      "[Muon | lr=0.1] Epoch 1880/4000: train_loss=0.0041  test_loss=133.4766  λ_max=3.3739\n",
      "[Muon | lr=0.1] Epoch 1881/4000: train_loss=0.0058  test_loss=133.5068  λ_max=3.2144\n",
      "[Muon | lr=0.1] Iter 30100: loss=0.0042\n",
      "[Muon | lr=0.1] Epoch 1882/4000: train_loss=0.0049  test_loss=133.8703  λ_max=3.6221\n",
      "[Muon | lr=0.1] Epoch 1883/4000: train_loss=0.0042  test_loss=133.9293  λ_max=3.5042\n",
      "[Muon | lr=0.1] Epoch 1884/4000: train_loss=0.0046  test_loss=133.8156  λ_max=3.6586\n",
      "[Muon | lr=0.1] Epoch 1885/4000: train_loss=0.0041  test_loss=133.9956  λ_max=3.5860\n",
      "[Muon | lr=0.1] Epoch 1886/4000: train_loss=0.0054  test_loss=134.0705  λ_max=3.5373\n",
      "[Muon | lr=0.1] Epoch 1887/4000: train_loss=0.0065  test_loss=133.9153  λ_max=3.3964\n",
      "[Muon | lr=0.1] Iter 30200: loss=0.0016\n",
      "[Muon | lr=0.1] Epoch 1888/4000: train_loss=0.0046  test_loss=133.9281  λ_max=3.2410\n",
      "[Muon | lr=0.1] Epoch 1889/4000: train_loss=0.0047  test_loss=133.7608  λ_max=3.5801\n",
      "[Muon | lr=0.1] Epoch 1890/4000: train_loss=0.0041  test_loss=133.5902  λ_max=3.6870\n",
      "[Muon | lr=0.1] Epoch 1891/4000: train_loss=0.0059  test_loss=133.6151  λ_max=3.4707\n",
      "[Muon | lr=0.1] Epoch 1892/4000: train_loss=0.0046  test_loss=133.7549  λ_max=3.1239\n",
      "[Muon | lr=0.1] Epoch 1893/4000: train_loss=0.0053  test_loss=133.8850  λ_max=3.3462\n",
      "[Muon | lr=0.1] Iter 30300: loss=0.0078\n",
      "[Muon | lr=0.1] Epoch 1894/4000: train_loss=0.0051  test_loss=134.1121  λ_max=3.4145\n",
      "[Muon | lr=0.1] Epoch 1895/4000: train_loss=0.0053  test_loss=134.3251  λ_max=3.2830\n",
      "[Muon | lr=0.1] Epoch 1896/4000: train_loss=0.0053  test_loss=134.4435  λ_max=4.1557\n",
      "[Muon | lr=0.1] Epoch 1897/4000: train_loss=0.0046  test_loss=134.4474  λ_max=3.4148\n",
      "[Muon | lr=0.1] Epoch 1898/4000: train_loss=0.0047  test_loss=134.5587  λ_max=4.1085\n",
      "[Muon | lr=0.1] Epoch 1899/4000: train_loss=0.0048  test_loss=134.7094  λ_max=3.5335\n",
      "[Muon | lr=0.1] Iter 30400: loss=0.0096\n",
      "[Muon | lr=0.1] Epoch 1900/4000: train_loss=0.0047  test_loss=134.7726  λ_max=3.5581\n",
      "[Muon | lr=0.1] Epoch 1901/4000: train_loss=0.0054  test_loss=134.6600  λ_max=3.4078\n",
      "[Muon | lr=0.1] Epoch 1902/4000: train_loss=0.0052  test_loss=134.7793  λ_max=3.1492\n",
      "[Muon | lr=0.1] Epoch 1903/4000: train_loss=0.0043  test_loss=135.0318  λ_max=3.1478\n",
      "[Muon | lr=0.1] Epoch 1904/4000: train_loss=0.0050  test_loss=135.0585  λ_max=3.2916\n",
      "[Muon | lr=0.1] Epoch 1905/4000: train_loss=0.0046  test_loss=135.1859  λ_max=3.7206\n",
      "[Muon | lr=0.1] Epoch 1906/4000: train_loss=0.0050  test_loss=135.1615  λ_max=3.5418\n",
      "[Muon | lr=0.1] Iter 30500: loss=0.0040\n",
      "[Muon | lr=0.1] Epoch 1907/4000: train_loss=0.0051  test_loss=135.1772  λ_max=3.6635\n",
      "[Muon | lr=0.1] Epoch 1908/4000: train_loss=0.0042  test_loss=135.3678  λ_max=3.7244\n",
      "[Muon | lr=0.1] Epoch 1909/4000: train_loss=0.0050  test_loss=135.3319  λ_max=3.4692\n",
      "[Muon | lr=0.1] Epoch 1910/4000: train_loss=0.0047  test_loss=135.4281  λ_max=3.5177\n",
      "[Muon | lr=0.1] Epoch 1911/4000: train_loss=0.0043  test_loss=135.5448  λ_max=3.8793\n",
      "[Muon | lr=0.1] Epoch 1912/4000: train_loss=0.0049  test_loss=135.4935  λ_max=3.7770\n",
      "[Muon | lr=0.1] Iter 30600: loss=0.0026\n",
      "[Muon | lr=0.1] Epoch 1913/4000: train_loss=0.0048  test_loss=135.4691  λ_max=3.2419\n",
      "[Muon | lr=0.1] Epoch 1914/4000: train_loss=0.0057  test_loss=135.5672  λ_max=3.3546\n",
      "[Muon | lr=0.1] Epoch 1915/4000: train_loss=0.0049  test_loss=135.5125  λ_max=3.6132\n",
      "[Muon | lr=0.1] Epoch 1916/4000: train_loss=0.0052  test_loss=135.5514  λ_max=3.6199\n",
      "[Muon | lr=0.1] Epoch 1917/4000: train_loss=0.0058  test_loss=135.5319  λ_max=3.9379\n",
      "[Muon | lr=0.1] Epoch 1918/4000: train_loss=0.0054  test_loss=135.5192  λ_max=3.4940\n",
      "[Muon | lr=0.1] Iter 30700: loss=0.0098\n",
      "[Muon | lr=0.1] Epoch 1919/4000: train_loss=0.0058  test_loss=135.6575  λ_max=3.9303\n",
      "[Muon | lr=0.1] Epoch 1920/4000: train_loss=0.0044  test_loss=135.6675  λ_max=3.7789\n",
      "[Muon | lr=0.1] Epoch 1921/4000: train_loss=0.0047  test_loss=135.6979  λ_max=3.6979\n",
      "[Muon | lr=0.1] Epoch 1922/4000: train_loss=0.0050  test_loss=135.8098  λ_max=3.2677\n",
      "[Muon | lr=0.1] Epoch 1923/4000: train_loss=0.0053  test_loss=135.8906  λ_max=3.4846\n",
      "[Muon | lr=0.1] Epoch 1924/4000: train_loss=0.0043  test_loss=136.0668  λ_max=3.5618\n",
      "[Muon | lr=0.1] Iter 30800: loss=0.0132\n",
      "[Muon | lr=0.1] Epoch 1925/4000: train_loss=0.0065  test_loss=136.1316  λ_max=3.4692\n",
      "[Muon | lr=0.1] Epoch 1926/4000: train_loss=0.0043  test_loss=136.3189  λ_max=3.5885\n",
      "[Muon | lr=0.1] Epoch 1927/4000: train_loss=0.0055  test_loss=136.7339  λ_max=3.1625\n",
      "[Muon | lr=0.1] Epoch 1928/4000: train_loss=0.0042  test_loss=137.0458  λ_max=3.3601\n",
      "[Muon | lr=0.1] Epoch 1929/4000: train_loss=0.0046  test_loss=136.9878  λ_max=3.7535\n",
      "[Muon | lr=0.1] Epoch 1930/4000: train_loss=0.0065  test_loss=137.0254  λ_max=3.4424\n",
      "[Muon | lr=0.1] Epoch 1931/4000: train_loss=0.0051  test_loss=136.8056  λ_max=3.3802\n",
      "[Muon | lr=0.1] Iter 30900: loss=0.0028\n",
      "[Muon | lr=0.1] Epoch 1932/4000: train_loss=0.0051  test_loss=136.8518  λ_max=3.4068\n",
      "[Muon | lr=0.1] Epoch 1933/4000: train_loss=0.0045  test_loss=136.8638  λ_max=3.6521\n",
      "[Muon | lr=0.1] Epoch 1934/4000: train_loss=0.0042  test_loss=136.9145  λ_max=3.7019\n",
      "[Muon | lr=0.1] Epoch 1935/4000: train_loss=0.0045  test_loss=137.0716  λ_max=3.4219\n",
      "[Muon | lr=0.1] Epoch 1936/4000: train_loss=0.0042  test_loss=137.3989  λ_max=3.5011\n",
      "[Muon | lr=0.1] Epoch 1937/4000: train_loss=0.0057  test_loss=137.4695  λ_max=3.4923\n",
      "[Muon | lr=0.1] Iter 31000: loss=0.0010\n",
      "[Muon | lr=0.1] Epoch 1938/4000: train_loss=0.0049  test_loss=137.4443  λ_max=4.0471\n",
      "[Muon | lr=0.1] Epoch 1939/4000: train_loss=0.0058  test_loss=137.6861  λ_max=3.3607\n",
      "[Muon | lr=0.1] Epoch 1940/4000: train_loss=0.0062  test_loss=137.8510  λ_max=3.7776\n",
      "[Muon | lr=0.1] Epoch 1941/4000: train_loss=0.0047  test_loss=137.7793  λ_max=3.4580\n",
      "[Muon | lr=0.1] Epoch 1942/4000: train_loss=0.0051  test_loss=137.9408  λ_max=3.2299\n",
      "[Muon | lr=0.1] Epoch 1943/4000: train_loss=0.0040  test_loss=137.9566  λ_max=3.6279\n",
      "[Muon | lr=0.1] Iter 31100: loss=0.0044\n",
      "[Muon | lr=0.1] Epoch 1944/4000: train_loss=0.0045  test_loss=138.0442  λ_max=3.4020\n",
      "[Muon | lr=0.1] Epoch 1945/4000: train_loss=0.0043  test_loss=138.1089  λ_max=3.6382\n",
      "[Muon | lr=0.1] Epoch 1946/4000: train_loss=0.0053  test_loss=138.4046  λ_max=4.2203\n",
      "[Muon | lr=0.1] Epoch 1947/4000: train_loss=0.0051  test_loss=138.3112  λ_max=3.5817\n",
      "[Muon | lr=0.1] Epoch 1948/4000: train_loss=0.0051  test_loss=138.1929  λ_max=3.3844\n",
      "[Muon | lr=0.1] Epoch 1949/4000: train_loss=0.0054  test_loss=138.0856  λ_max=3.6008\n",
      "[Muon | lr=0.1] Iter 31200: loss=0.0033\n",
      "[Muon | lr=0.1] Epoch 1950/4000: train_loss=0.0051  test_loss=138.0986  λ_max=3.5880\n",
      "[Muon | lr=0.1] Epoch 1951/4000: train_loss=0.0054  test_loss=138.1421  λ_max=4.1483\n",
      "[Muon | lr=0.1] Epoch 1952/4000: train_loss=0.0057  test_loss=138.2425  λ_max=3.8701\n",
      "[Muon | lr=0.1] Epoch 1953/4000: train_loss=0.0036  test_loss=138.1514  λ_max=4.1357\n",
      "[Muon | lr=0.1] Epoch 1954/4000: train_loss=0.0046  test_loss=138.3217  λ_max=3.5375\n",
      "[Muon | lr=0.1] Epoch 1955/4000: train_loss=0.0054  test_loss=138.5751  λ_max=3.4054\n",
      "[Muon | lr=0.1] Epoch 1956/4000: train_loss=0.0054  test_loss=138.6428  λ_max=3.5249\n",
      "[Muon | lr=0.1] Iter 31300: loss=0.0012\n",
      "[Muon | lr=0.1] Epoch 1957/4000: train_loss=0.0044  test_loss=138.6884  λ_max=3.5040\n",
      "[Muon | lr=0.1] Epoch 1958/4000: train_loss=0.0057  test_loss=138.7803  λ_max=3.3231\n",
      "[Muon | lr=0.1] Epoch 1959/4000: train_loss=0.0052  test_loss=138.7418  λ_max=3.2353\n",
      "[Muon | lr=0.1] Epoch 1960/4000: train_loss=0.0048  test_loss=138.7469  λ_max=3.4223\n",
      "[Muon | lr=0.1] Epoch 1961/4000: train_loss=0.0044  test_loss=138.6561  λ_max=3.2194\n",
      "[Muon | lr=0.1] Epoch 1962/4000: train_loss=0.0056  test_loss=138.5366  λ_max=4.0368\n",
      "[Muon | lr=0.1] Iter 31400: loss=0.0036\n",
      "[Muon | lr=0.1] Epoch 1963/4000: train_loss=0.0052  test_loss=138.8076  λ_max=3.3404\n",
      "[Muon | lr=0.1] Epoch 1964/4000: train_loss=0.0052  test_loss=138.8057  λ_max=3.9586\n",
      "[Muon | lr=0.1] Epoch 1965/4000: train_loss=0.0045  test_loss=138.8557  λ_max=3.7828\n",
      "[Muon | lr=0.1] Epoch 1966/4000: train_loss=0.0057  test_loss=138.9509  λ_max=3.5136\n",
      "[Muon | lr=0.1] Epoch 1967/4000: train_loss=0.0044  test_loss=139.4220  λ_max=3.3904\n",
      "[Muon | lr=0.1] Epoch 1968/4000: train_loss=0.0040  test_loss=139.4338  λ_max=3.4318\n",
      "[Muon | lr=0.1] Iter 31500: loss=0.0060\n",
      "[Muon | lr=0.1] Epoch 1969/4000: train_loss=0.0055  test_loss=139.4407  λ_max=3.6660\n",
      "[Muon | lr=0.1] Epoch 1970/4000: train_loss=0.0054  test_loss=139.4922  λ_max=3.4911\n",
      "[Muon | lr=0.1] Epoch 1971/4000: train_loss=0.0051  test_loss=139.7746  λ_max=3.6905\n",
      "[Muon | lr=0.1] Epoch 1972/4000: train_loss=0.0044  test_loss=139.9078  λ_max=3.3846\n",
      "[Muon | lr=0.1] Epoch 1973/4000: train_loss=0.0041  test_loss=139.8876  λ_max=3.6846\n",
      "[Muon | lr=0.1] Epoch 1974/4000: train_loss=0.0041  test_loss=140.1219  λ_max=3.3512\n",
      "[Muon | lr=0.1] Iter 31600: loss=0.0035\n",
      "[Muon | lr=0.1] Epoch 1975/4000: train_loss=0.0044  test_loss=140.2562  λ_max=4.0287\n",
      "[Muon | lr=0.1] Epoch 1976/4000: train_loss=0.0047  test_loss=140.1104  λ_max=3.2112\n",
      "[Muon | lr=0.1] Epoch 1977/4000: train_loss=0.0048  test_loss=140.2183  λ_max=3.5787\n",
      "[Muon | lr=0.1] Epoch 1978/4000: train_loss=0.0041  test_loss=140.5504  λ_max=3.4826\n",
      "[Muon | lr=0.1] Epoch 1979/4000: train_loss=0.0060  test_loss=140.8137  λ_max=3.7698\n",
      "[Muon | lr=0.1] Epoch 1980/4000: train_loss=0.0057  test_loss=140.7929  λ_max=3.6158\n",
      "[Muon | lr=0.1] Epoch 1981/4000: train_loss=0.0051  test_loss=140.8417  λ_max=3.6010\n",
      "[Muon | lr=0.1] Iter 31700: loss=0.0041\n",
      "[Muon | lr=0.1] Epoch 1982/4000: train_loss=0.0041  test_loss=140.9065  λ_max=3.5093\n",
      "[Muon | lr=0.1] Epoch 1983/4000: train_loss=0.0057  test_loss=141.0040  λ_max=3.7506\n",
      "[Muon | lr=0.1] Epoch 1984/4000: train_loss=0.0048  test_loss=141.1632  λ_max=3.9747\n",
      "[Muon | lr=0.1] Epoch 1985/4000: train_loss=0.0045  test_loss=141.4782  λ_max=3.6113\n",
      "[Muon | lr=0.1] Epoch 1986/4000: train_loss=0.0053  test_loss=141.5262  λ_max=3.3971\n",
      "[Muon | lr=0.1] Epoch 1987/4000: train_loss=0.0053  test_loss=141.3421  λ_max=3.3903\n",
      "[Muon | lr=0.1] Iter 31800: loss=0.0017\n",
      "[Muon | lr=0.1] Epoch 1988/4000: train_loss=0.0041  test_loss=141.6515  λ_max=3.9290\n",
      "[Muon | lr=0.1] Epoch 1989/4000: train_loss=0.0047  test_loss=141.7965  λ_max=3.2005\n",
      "[Muon | lr=0.1] Epoch 1990/4000: train_loss=0.0048  test_loss=141.9471  λ_max=3.2795\n",
      "[Muon | lr=0.1] Epoch 1991/4000: train_loss=0.0052  test_loss=142.0201  λ_max=4.1051\n",
      "[Muon | lr=0.1] Epoch 1992/4000: train_loss=0.0050  test_loss=141.9500  λ_max=3.7384\n",
      "[Muon | lr=0.1] Epoch 1993/4000: train_loss=0.0045  test_loss=141.7919  λ_max=3.9190\n",
      "[Muon | lr=0.1] Iter 31900: loss=0.0043\n",
      "[Muon | lr=0.1] Epoch 1994/4000: train_loss=0.0046  test_loss=141.7053  λ_max=3.3909\n",
      "[Muon | lr=0.1] Epoch 1995/4000: train_loss=0.0057  test_loss=141.5533  λ_max=3.8004\n",
      "[Muon | lr=0.1] Epoch 1996/4000: train_loss=0.0046  test_loss=141.5374  λ_max=3.6048\n",
      "[Muon | lr=0.1] Epoch 1997/4000: train_loss=0.0048  test_loss=141.5796  λ_max=3.7168\n",
      "[Muon | lr=0.1] Epoch 1998/4000: train_loss=0.0055  test_loss=141.8655  λ_max=3.3261\n",
      "[Muon | lr=0.1] Epoch 1999/4000: train_loss=0.0042  test_loss=142.1582  λ_max=3.7516\n",
      "[Muon | lr=0.1] Iter 32000: loss=0.0104\n",
      "[Muon | lr=0.1] Epoch 2000/4000: train_loss=0.0050  test_loss=142.1904  λ_max=3.5053\n",
      "[Muon | lr=0.1] Epoch 2001/4000: train_loss=0.0048  test_loss=142.3071  λ_max=3.6228\n",
      "[Muon | lr=0.1] Epoch 2002/4000: train_loss=0.0052  test_loss=142.4600  λ_max=3.1987\n",
      "[Muon | lr=0.1] Epoch 2003/4000: train_loss=0.0057  test_loss=142.6883  λ_max=3.6104\n",
      "[Muon | lr=0.1] Epoch 2004/4000: train_loss=0.0049  test_loss=142.5484  λ_max=3.8157\n",
      "[Muon | lr=0.1] Epoch 2005/4000: train_loss=0.0035  test_loss=142.4257  λ_max=3.4058\n",
      "[Muon | lr=0.1] Epoch 2006/4000: train_loss=0.0045  test_loss=142.5828  λ_max=3.9010\n",
      "[Muon | lr=0.1] Iter 32100: loss=0.0033\n",
      "[Muon | lr=0.1] Epoch 2007/4000: train_loss=0.0050  test_loss=142.7150  λ_max=3.4228\n",
      "[Muon | lr=0.1] Epoch 2008/4000: train_loss=0.0051  test_loss=142.7439  λ_max=3.5086\n",
      "[Muon | lr=0.1] Epoch 2009/4000: train_loss=0.0031  test_loss=142.8816  λ_max=4.1526\n",
      "[Muon | lr=0.1] Epoch 2010/4000: train_loss=0.0049  test_loss=142.7332  λ_max=3.7330\n",
      "[Muon | lr=0.1] Epoch 2011/4000: train_loss=0.0043  test_loss=143.0452  λ_max=3.4479\n",
      "[Muon | lr=0.1] Epoch 2012/4000: train_loss=0.0049  test_loss=142.9677  λ_max=3.7270\n",
      "[Muon | lr=0.1] Iter 32200: loss=0.0048\n",
      "[Muon | lr=0.1] Epoch 2013/4000: train_loss=0.0047  test_loss=142.8026  λ_max=3.6675\n",
      "[Muon | lr=0.1] Epoch 2014/4000: train_loss=0.0045  test_loss=142.9071  λ_max=4.0271\n",
      "[Muon | lr=0.1] Epoch 2015/4000: train_loss=0.0042  test_loss=143.1952  λ_max=3.4326\n",
      "[Muon | lr=0.1] Epoch 2016/4000: train_loss=0.0056  test_loss=143.3472  λ_max=3.3689\n",
      "[Muon | lr=0.1] Epoch 2017/4000: train_loss=0.0062  test_loss=143.4139  λ_max=3.7336\n",
      "[Muon | lr=0.1] Epoch 2018/4000: train_loss=0.0046  test_loss=143.3533  λ_max=3.4819\n",
      "[Muon | lr=0.1] Iter 32300: loss=0.0042\n",
      "[Muon | lr=0.1] Epoch 2019/4000: train_loss=0.0046  test_loss=143.2554  λ_max=3.1733\n",
      "[Muon | lr=0.1] Epoch 2020/4000: train_loss=0.0040  test_loss=143.1756  λ_max=3.5555\n",
      "[Muon | lr=0.1] Epoch 2021/4000: train_loss=0.0048  test_loss=143.2116  λ_max=3.6451\n",
      "[Muon | lr=0.1] Epoch 2022/4000: train_loss=0.0057  test_loss=143.2466  λ_max=3.6857\n",
      "[Muon | lr=0.1] Epoch 2023/4000: train_loss=0.0063  test_loss=143.4497  λ_max=3.6683\n",
      "[Muon | lr=0.1] Epoch 2024/4000: train_loss=0.0048  test_loss=143.6244  λ_max=3.5856\n",
      "[Muon | lr=0.1] Iter 32400: loss=0.0112\n",
      "[Muon | lr=0.1] Epoch 2025/4000: train_loss=0.0055  test_loss=143.8055  λ_max=3.4854\n",
      "[Muon | lr=0.1] Epoch 2026/4000: train_loss=0.0044  test_loss=143.8319  λ_max=4.0957\n",
      "[Muon | lr=0.1] Epoch 2027/4000: train_loss=0.0040  test_loss=143.6928  λ_max=3.8244\n",
      "[Muon | lr=0.1] Epoch 2028/4000: train_loss=0.0052  test_loss=143.6505  λ_max=4.0895\n",
      "[Muon | lr=0.1] Epoch 2029/4000: train_loss=0.0047  test_loss=143.5474  λ_max=3.8137\n",
      "[Muon | lr=0.1] Epoch 2030/4000: train_loss=0.0052  test_loss=143.4445  λ_max=3.5409\n",
      "[Muon | lr=0.1] Epoch 2031/4000: train_loss=0.0046  test_loss=143.6631  λ_max=3.3274\n",
      "[Muon | lr=0.1] Iter 32500: loss=0.0059\n",
      "[Muon | lr=0.1] Epoch 2032/4000: train_loss=0.0043  test_loss=143.8680  λ_max=4.2370\n",
      "[Muon | lr=0.1] Epoch 2033/4000: train_loss=0.0055  test_loss=143.5875  λ_max=3.6874\n",
      "[Muon | lr=0.1] Epoch 2034/4000: train_loss=0.0051  test_loss=143.6204  λ_max=3.4614\n",
      "[Muon | lr=0.1] Epoch 2035/4000: train_loss=0.0044  test_loss=143.5613  λ_max=3.3836\n",
      "[Muon | lr=0.1] Epoch 2036/4000: train_loss=0.0046  test_loss=143.6968  λ_max=4.1391\n",
      "[Muon | lr=0.1] Epoch 2037/4000: train_loss=0.0048  test_loss=143.7663  λ_max=3.6678\n",
      "[Muon | lr=0.1] Iter 32600: loss=0.0041\n",
      "[Muon | lr=0.1] Epoch 2038/4000: train_loss=0.0046  test_loss=144.1174  λ_max=3.6122\n",
      "[Muon | lr=0.1] Epoch 2039/4000: train_loss=0.0040  test_loss=144.4556  λ_max=3.6741\n",
      "[Muon | lr=0.1] Epoch 2040/4000: train_loss=0.0041  test_loss=144.5826  λ_max=3.8261\n",
      "[Muon | lr=0.1] Epoch 2041/4000: train_loss=0.0056  test_loss=144.4401  λ_max=3.6571\n",
      "[Muon | lr=0.1] Epoch 2042/4000: train_loss=0.0049  test_loss=144.2547  λ_max=3.6726\n",
      "[Muon | lr=0.1] Epoch 2043/4000: train_loss=0.0051  test_loss=144.2047  λ_max=3.5963\n",
      "[Muon | lr=0.1] Iter 32700: loss=0.0040\n",
      "[Muon | lr=0.1] Epoch 2044/4000: train_loss=0.0053  test_loss=144.3213  λ_max=3.4610\n",
      "[Muon | lr=0.1] Epoch 2045/4000: train_loss=0.0040  test_loss=144.6841  λ_max=3.6664\n",
      "[Muon | lr=0.1] Epoch 2046/4000: train_loss=0.0045  test_loss=144.6036  λ_max=3.4828\n",
      "[Muon | lr=0.1] Epoch 2047/4000: train_loss=0.0045  test_loss=144.6077  λ_max=3.9966\n",
      "[Muon | lr=0.1] Epoch 2048/4000: train_loss=0.0045  test_loss=144.7764  λ_max=3.6198\n",
      "[Muon | lr=0.1] Epoch 2049/4000: train_loss=0.0056  test_loss=144.9767  λ_max=3.9108\n",
      "[Muon | lr=0.1] Iter 32800: loss=0.0057\n",
      "[Muon | lr=0.1] Epoch 2050/4000: train_loss=0.0039  test_loss=145.0558  λ_max=3.9264\n",
      "[Muon | lr=0.1] Epoch 2051/4000: train_loss=0.0041  test_loss=145.2058  λ_max=3.8433\n",
      "[Muon | lr=0.1] Epoch 2052/4000: train_loss=0.0045  test_loss=145.3638  λ_max=3.6473\n",
      "[Muon | lr=0.1] Epoch 2053/4000: train_loss=0.0047  test_loss=145.5745  λ_max=4.3247\n",
      "[Muon | lr=0.1] Epoch 2054/4000: train_loss=0.0049  test_loss=145.6185  λ_max=3.9527\n",
      "[Muon | lr=0.1] Epoch 2055/4000: train_loss=0.0049  test_loss=145.4720  λ_max=3.7707\n",
      "[Muon | lr=0.1] Epoch 2056/4000: train_loss=0.0033  test_loss=145.6259  λ_max=3.6807\n",
      "[Muon | lr=0.1] Iter 32900: loss=0.0035\n",
      "[Muon | lr=0.1] Epoch 2057/4000: train_loss=0.0046  test_loss=145.5793  λ_max=3.5347\n",
      "[Muon | lr=0.1] Epoch 2058/4000: train_loss=0.0039  test_loss=145.6074  λ_max=3.4125\n",
      "[Muon | lr=0.1] Epoch 2059/4000: train_loss=0.0047  test_loss=145.5448  λ_max=4.0770\n",
      "[Muon | lr=0.1] Epoch 2060/4000: train_loss=0.0054  test_loss=145.8032  λ_max=3.4795\n",
      "[Muon | lr=0.1] Epoch 2061/4000: train_loss=0.0049  test_loss=145.8749  λ_max=3.6525\n",
      "[Muon | lr=0.1] Epoch 2062/4000: train_loss=0.0042  test_loss=145.8841  λ_max=4.5924\n",
      "[Muon | lr=0.1] Iter 33000: loss=0.0041\n",
      "[Muon | lr=0.1] Epoch 2063/4000: train_loss=0.0055  test_loss=145.8224  λ_max=3.9318\n",
      "[Muon | lr=0.1] Epoch 2064/4000: train_loss=0.0051  test_loss=145.6861  λ_max=3.9408\n",
      "[Muon | lr=0.1] Epoch 2065/4000: train_loss=0.0044  test_loss=145.9766  λ_max=3.9621\n",
      "[Muon | lr=0.1] Epoch 2066/4000: train_loss=0.0048  test_loss=146.1594  λ_max=3.6014\n",
      "[Muon | lr=0.1] Epoch 2067/4000: train_loss=0.0047  test_loss=146.3690  λ_max=3.1191\n",
      "[Muon | lr=0.1] Epoch 2068/4000: train_loss=0.0047  test_loss=146.4986  λ_max=3.6777\n",
      "[Muon | lr=0.1] Iter 33100: loss=0.0078\n",
      "[Muon | lr=0.1] Epoch 2069/4000: train_loss=0.0047  test_loss=146.5079  λ_max=3.8271\n",
      "[Muon | lr=0.1] Epoch 2070/4000: train_loss=0.0050  test_loss=146.4946  λ_max=3.6996\n",
      "[Muon | lr=0.1] Epoch 2071/4000: train_loss=0.0053  test_loss=146.5788  λ_max=3.7186\n",
      "[Muon | lr=0.1] Epoch 2072/4000: train_loss=0.0054  test_loss=146.5058  λ_max=3.7581\n",
      "[Muon | lr=0.1] Epoch 2073/4000: train_loss=0.0044  test_loss=146.5707  λ_max=3.8459\n",
      "[Muon | lr=0.1] Epoch 2074/4000: train_loss=0.0053  test_loss=146.6485  λ_max=4.1387\n",
      "[Muon | lr=0.1] Iter 33200: loss=0.0075\n",
      "[Muon | lr=0.1] Epoch 2075/4000: train_loss=0.0039  test_loss=146.5543  λ_max=3.4655\n",
      "[Muon | lr=0.1] Epoch 2076/4000: train_loss=0.0042  test_loss=146.6539  λ_max=3.7924\n",
      "[Muon | lr=0.1] Epoch 2077/4000: train_loss=0.0049  test_loss=146.3222  λ_max=3.4107\n",
      "[Muon | lr=0.1] Epoch 2078/4000: train_loss=0.0052  test_loss=146.1000  λ_max=3.7305\n",
      "[Muon | lr=0.1] Epoch 2079/4000: train_loss=0.0042  test_loss=146.2882  λ_max=4.3136\n",
      "[Muon | lr=0.1] Epoch 2080/4000: train_loss=0.0046  test_loss=146.6535  λ_max=3.8227\n",
      "[Muon | lr=0.1] Epoch 2081/4000: train_loss=0.0039  test_loss=146.6848  λ_max=3.5569\n",
      "[Muon | lr=0.1] Iter 33300: loss=0.0038\n",
      "[Muon | lr=0.1] Epoch 2082/4000: train_loss=0.0042  test_loss=146.8663  λ_max=4.2914\n",
      "[Muon | lr=0.1] Epoch 2083/4000: train_loss=0.0047  test_loss=146.8388  λ_max=3.2893\n",
      "[Muon | lr=0.1] Epoch 2084/4000: train_loss=0.0044  test_loss=147.0191  λ_max=3.7678\n",
      "[Muon | lr=0.1] Epoch 2085/4000: train_loss=0.0052  test_loss=147.1562  λ_max=3.5865\n",
      "[Muon | lr=0.1] Epoch 2086/4000: train_loss=0.0041  test_loss=147.3509  λ_max=3.5036\n",
      "[Muon | lr=0.1] Epoch 2087/4000: train_loss=0.0062  test_loss=147.4652  λ_max=3.6497\n",
      "[Muon | lr=0.1] Iter 33400: loss=0.0014\n",
      "[Muon | lr=0.1] Epoch 2088/4000: train_loss=0.0053  test_loss=147.7041  λ_max=4.3151\n",
      "[Muon | lr=0.1] Epoch 2089/4000: train_loss=0.0037  test_loss=147.8662  λ_max=3.6329\n",
      "[Muon | lr=0.1] Epoch 2090/4000: train_loss=0.0044  test_loss=148.0551  λ_max=4.5233\n",
      "[Muon | lr=0.1] Epoch 2091/4000: train_loss=0.0046  test_loss=148.1161  λ_max=3.4518\n",
      "[Muon | lr=0.1] Epoch 2092/4000: train_loss=0.0046  test_loss=148.5413  λ_max=3.7935\n",
      "[Muon | lr=0.1] Epoch 2093/4000: train_loss=0.0050  test_loss=148.6717  λ_max=4.0194\n",
      "[Muon | lr=0.1] Iter 33500: loss=0.0076\n",
      "[Muon | lr=0.1] Epoch 2094/4000: train_loss=0.0049  test_loss=148.8237  λ_max=3.8481\n",
      "[Muon | lr=0.1] Epoch 2095/4000: train_loss=0.0056  test_loss=148.7859  λ_max=3.5944\n",
      "[Muon | lr=0.1] Epoch 2096/4000: train_loss=0.0044  test_loss=148.9541  λ_max=3.7341\n",
      "[Muon | lr=0.1] Epoch 2097/4000: train_loss=0.0037  test_loss=149.0801  λ_max=3.7403\n",
      "[Muon | lr=0.1] Epoch 2098/4000: train_loss=0.0037  test_loss=149.1039  λ_max=3.5373\n",
      "[Muon | lr=0.1] Epoch 2099/4000: train_loss=0.0043  test_loss=149.1270  λ_max=3.7420\n",
      "[Muon | lr=0.1] Iter 33600: loss=0.0067\n",
      "[Muon | lr=0.1] Epoch 2100/4000: train_loss=0.0053  test_loss=149.0634  λ_max=3.6877\n",
      "[Muon | lr=0.1] Epoch 2101/4000: train_loss=0.0047  test_loss=149.3177  λ_max=3.8368\n",
      "[Muon | lr=0.1] Epoch 2102/4000: train_loss=0.0042  test_loss=149.4903  λ_max=3.4558\n",
      "[Muon | lr=0.1] Epoch 2103/4000: train_loss=0.0046  test_loss=149.4380  λ_max=4.0675\n",
      "[Muon | lr=0.1] Epoch 2104/4000: train_loss=0.0040  test_loss=149.3749  λ_max=3.9992\n",
      "[Muon | lr=0.1] Epoch 2105/4000: train_loss=0.0042  test_loss=149.5242  λ_max=3.7373\n",
      "[Muon | lr=0.1] Epoch 2106/4000: train_loss=0.0042  test_loss=149.7027  λ_max=3.8657\n",
      "[Muon | lr=0.1] Iter 33700: loss=0.0025\n",
      "[Muon | lr=0.1] Epoch 2107/4000: train_loss=0.0048  test_loss=149.6088  λ_max=3.8218\n",
      "[Muon | lr=0.1] Epoch 2108/4000: train_loss=0.0050  test_loss=149.6942  λ_max=3.7459\n",
      "[Muon | lr=0.1] Epoch 2109/4000: train_loss=0.0044  test_loss=149.7515  λ_max=3.6373\n",
      "[Muon | lr=0.1] Epoch 2110/4000: train_loss=0.0046  test_loss=149.6210  λ_max=3.7991\n",
      "[Muon | lr=0.1] Epoch 2111/4000: train_loss=0.0042  test_loss=149.4905  λ_max=3.6850\n",
      "[Muon | lr=0.1] Epoch 2112/4000: train_loss=0.0043  test_loss=149.4905  λ_max=3.6212\n",
      "[Muon | lr=0.1] Iter 33800: loss=0.0035\n",
      "[Muon | lr=0.1] Epoch 2113/4000: train_loss=0.0048  test_loss=149.5495  λ_max=3.5215\n",
      "[Muon | lr=0.1] Epoch 2114/4000: train_loss=0.0044  test_loss=149.5725  λ_max=3.8956\n",
      "[Muon | lr=0.1] Epoch 2115/4000: train_loss=0.0061  test_loss=149.6217  λ_max=3.7769\n",
      "[Muon | lr=0.1] Epoch 2116/4000: train_loss=0.0042  test_loss=149.8899  λ_max=3.5906\n",
      "[Muon | lr=0.1] Epoch 2117/4000: train_loss=0.0060  test_loss=149.6898  λ_max=3.7032\n",
      "[Muon | lr=0.1] Epoch 2118/4000: train_loss=0.0042  test_loss=150.0603  λ_max=3.8631\n",
      "[Muon | lr=0.1] Iter 33900: loss=0.0054\n",
      "[Muon | lr=0.1] Epoch 2119/4000: train_loss=0.0059  test_loss=150.3297  λ_max=3.5820\n",
      "[Muon | lr=0.1] Epoch 2120/4000: train_loss=0.0047  test_loss=150.4332  λ_max=4.1756\n",
      "[Muon | lr=0.1] Epoch 2121/4000: train_loss=0.0043  test_loss=150.6191  λ_max=3.8642\n",
      "[Muon | lr=0.1] Epoch 2122/4000: train_loss=0.0046  test_loss=150.8146  λ_max=3.9416\n",
      "[Muon | lr=0.1] Epoch 2123/4000: train_loss=0.0054  test_loss=150.8865  λ_max=4.2191\n",
      "[Muon | lr=0.1] Epoch 2124/4000: train_loss=0.0049  test_loss=150.9592  λ_max=3.8736\n",
      "[Muon | lr=0.1] Iter 34000: loss=0.0034\n",
      "[Muon | lr=0.1] Epoch 2125/4000: train_loss=0.0030  test_loss=151.1498  λ_max=3.4187\n",
      "[Muon | lr=0.1] Epoch 2126/4000: train_loss=0.0043  test_loss=151.3372  λ_max=3.2148\n",
      "[Muon | lr=0.1] Epoch 2127/4000: train_loss=0.0040  test_loss=151.4731  λ_max=3.8212\n",
      "[Muon | lr=0.1] Epoch 2128/4000: train_loss=0.0048  test_loss=151.7075  λ_max=3.6899\n",
      "[Muon | lr=0.1] Epoch 2129/4000: train_loss=0.0041  test_loss=151.5615  λ_max=3.8809\n",
      "[Muon | lr=0.1] Epoch 2130/4000: train_loss=0.0041  test_loss=151.8177  λ_max=3.8898\n",
      "[Muon | lr=0.1] Epoch 2131/4000: train_loss=0.0049  test_loss=151.9830  λ_max=3.8956\n",
      "[Muon | lr=0.1] Iter 34100: loss=0.0029\n",
      "[Muon | lr=0.1] Epoch 2132/4000: train_loss=0.0048  test_loss=152.0891  λ_max=3.5503\n",
      "[Muon | lr=0.1] Epoch 2133/4000: train_loss=0.0048  test_loss=152.2147  λ_max=4.2021\n",
      "[Muon | lr=0.1] Epoch 2134/4000: train_loss=0.0041  test_loss=152.3091  λ_max=3.6901\n",
      "[Muon | lr=0.1] Epoch 2135/4000: train_loss=0.0051  test_loss=152.2853  λ_max=3.8629\n",
      "[Muon | lr=0.1] Epoch 2136/4000: train_loss=0.0044  test_loss=152.4153  λ_max=3.6788\n",
      "[Muon | lr=0.1] Epoch 2137/4000: train_loss=0.0038  test_loss=152.4051  λ_max=3.7129\n",
      "[Muon | lr=0.1] Iter 34200: loss=0.0039\n",
      "[Muon | lr=0.1] Epoch 2138/4000: train_loss=0.0044  test_loss=152.4003  λ_max=3.6780\n",
      "[Muon | lr=0.1] Epoch 2139/4000: train_loss=0.0049  test_loss=152.3737  λ_max=3.6532\n",
      "[Muon | lr=0.1] Epoch 2140/4000: train_loss=0.0056  test_loss=152.2412  λ_max=3.9505\n",
      "[Muon | lr=0.1] Epoch 2141/4000: train_loss=0.0041  test_loss=152.2128  λ_max=4.3440\n",
      "[Muon | lr=0.1] Epoch 2142/4000: train_loss=0.0048  test_loss=152.4282  λ_max=3.9233\n",
      "[Muon | lr=0.1] Epoch 2143/4000: train_loss=0.0044  test_loss=152.7734  λ_max=4.1525\n",
      "[Muon | lr=0.1] Iter 34300: loss=0.0072\n",
      "[Muon | lr=0.1] Epoch 2144/4000: train_loss=0.0034  test_loss=153.0001  λ_max=3.6689\n",
      "[Muon | lr=0.1] Epoch 2145/4000: train_loss=0.0053  test_loss=153.1176  λ_max=3.7808\n",
      "[Muon | lr=0.1] Epoch 2146/4000: train_loss=0.0049  test_loss=153.0460  λ_max=4.0946\n",
      "[Muon | lr=0.1] Epoch 2147/4000: train_loss=0.0055  test_loss=153.3051  λ_max=4.0460\n",
      "[Muon | lr=0.1] Epoch 2148/4000: train_loss=0.0044  test_loss=153.4518  λ_max=3.8253\n",
      "[Muon | lr=0.1] Epoch 2149/4000: train_loss=0.0040  test_loss=153.5107  λ_max=4.1507\n",
      "[Muon | lr=0.1] Iter 34400: loss=0.0058\n",
      "[Muon | lr=0.1] Epoch 2150/4000: train_loss=0.0044  test_loss=153.6165  λ_max=3.7856\n",
      "[Muon | lr=0.1] Epoch 2151/4000: train_loss=0.0038  test_loss=153.5694  λ_max=3.4904\n",
      "[Muon | lr=0.1] Epoch 2152/4000: train_loss=0.0044  test_loss=153.8147  λ_max=3.4856\n",
      "[Muon | lr=0.1] Epoch 2153/4000: train_loss=0.0055  test_loss=154.0890  λ_max=3.9190\n",
      "[Muon | lr=0.1] Epoch 2154/4000: train_loss=0.0043  test_loss=154.1464  λ_max=3.8311\n",
      "[Muon | lr=0.1] Epoch 2155/4000: train_loss=0.0038  test_loss=154.1735  λ_max=4.1122\n",
      "[Muon | lr=0.1] Epoch 2156/4000: train_loss=0.0039  test_loss=154.3159  λ_max=3.8178\n",
      "[Muon | lr=0.1] Iter 34500: loss=0.0039\n",
      "[Muon | lr=0.1] Epoch 2157/4000: train_loss=0.0039  test_loss=154.5227  λ_max=3.7195\n",
      "[Muon | lr=0.1] Epoch 2158/4000: train_loss=0.0043  test_loss=154.8054  λ_max=3.4043\n",
      "[Muon | lr=0.1] Epoch 2159/4000: train_loss=0.0048  test_loss=154.9571  λ_max=3.5782\n",
      "[Muon | lr=0.1] Epoch 2160/4000: train_loss=0.0041  test_loss=154.9632  λ_max=3.7840\n",
      "[Muon | lr=0.1] Epoch 2161/4000: train_loss=0.0057  test_loss=155.0559  λ_max=3.9689\n",
      "[Muon | lr=0.1] Epoch 2162/4000: train_loss=0.0044  test_loss=155.3013  λ_max=3.7880\n",
      "[Muon | lr=0.1] Iter 34600: loss=0.0039\n",
      "[Muon | lr=0.1] Epoch 2163/4000: train_loss=0.0047  test_loss=155.4375  λ_max=3.6023\n",
      "[Muon | lr=0.1] Epoch 2164/4000: train_loss=0.0045  test_loss=155.5910  λ_max=3.9654\n",
      "[Muon | lr=0.1] Epoch 2165/4000: train_loss=0.0045  test_loss=155.5378  λ_max=3.7590\n",
      "[Muon | lr=0.1] Epoch 2166/4000: train_loss=0.0057  test_loss=155.3759  λ_max=4.1442\n",
      "[Muon | lr=0.1] Epoch 2167/4000: train_loss=0.0037  test_loss=155.5533  λ_max=4.1991\n",
      "[Muon | lr=0.1] Epoch 2168/4000: train_loss=0.0058  test_loss=155.8260  λ_max=3.9403\n",
      "[Muon | lr=0.1] Iter 34700: loss=0.0074\n",
      "[Muon | lr=0.1] Epoch 2169/4000: train_loss=0.0042  test_loss=156.0114  λ_max=3.6575\n",
      "[Muon | lr=0.1] Epoch 2170/4000: train_loss=0.0055  test_loss=155.9346  λ_max=4.0214\n",
      "[Muon | lr=0.1] Epoch 2171/4000: train_loss=0.0052  test_loss=155.6352  λ_max=3.7311\n",
      "[Muon | lr=0.1] Epoch 2172/4000: train_loss=0.0056  test_loss=155.5181  λ_max=3.7342\n",
      "[Muon | lr=0.1] Epoch 2173/4000: train_loss=0.0057  test_loss=155.6838  λ_max=3.7347\n",
      "[Muon | lr=0.1] Epoch 2174/4000: train_loss=0.0040  test_loss=155.6493  λ_max=4.0833\n",
      "[Muon | lr=0.1] Iter 34800: loss=0.0061\n",
      "[Muon | lr=0.1] Epoch 2175/4000: train_loss=0.0042  test_loss=155.4728  λ_max=3.8414\n",
      "[Muon | lr=0.1] Epoch 2176/4000: train_loss=0.0036  test_loss=155.6288  λ_max=3.9561\n",
      "[Muon | lr=0.1] Epoch 2177/4000: train_loss=0.0058  test_loss=155.5624  λ_max=4.0066\n",
      "[Muon | lr=0.1] Epoch 2178/4000: train_loss=0.0049  test_loss=155.4426  λ_max=3.8730\n",
      "[Muon | lr=0.1] Epoch 2179/4000: train_loss=0.0046  test_loss=155.4071  λ_max=4.0618\n",
      "[Muon | lr=0.1] Epoch 2180/4000: train_loss=0.0048  test_loss=155.3830  λ_max=3.8093\n",
      "[Muon | lr=0.1] Epoch 2181/4000: train_loss=0.0047  test_loss=155.2774  λ_max=3.8644\n",
      "[Muon | lr=0.1] Iter 34900: loss=0.0021\n",
      "[Muon | lr=0.1] Epoch 2182/4000: train_loss=0.0054  test_loss=155.4708  λ_max=4.2304\n",
      "[Muon | lr=0.1] Epoch 2183/4000: train_loss=0.0047  test_loss=155.6502  λ_max=3.5015\n",
      "[Muon | lr=0.1] Epoch 2184/4000: train_loss=0.0044  test_loss=155.7005  λ_max=4.2298\n",
      "[Muon | lr=0.1] Epoch 2185/4000: train_loss=0.0053  test_loss=155.6017  λ_max=3.7795\n",
      "[Muon | lr=0.1] Epoch 2186/4000: train_loss=0.0044  test_loss=155.6160  λ_max=3.5997\n",
      "[Muon | lr=0.1] Epoch 2187/4000: train_loss=0.0042  test_loss=155.6029  λ_max=3.6203\n",
      "[Muon | lr=0.1] Iter 35000: loss=0.0024\n",
      "[Muon | lr=0.1] Epoch 2188/4000: train_loss=0.0051  test_loss=155.9000  λ_max=3.7037\n",
      "[Muon | lr=0.1] Epoch 2189/4000: train_loss=0.0056  test_loss=156.1776  λ_max=3.8688\n",
      "[Muon | lr=0.1] Epoch 2190/4000: train_loss=0.0036  test_loss=156.1229  λ_max=3.5875\n",
      "[Muon | lr=0.1] Epoch 2191/4000: train_loss=0.0045  test_loss=156.3080  λ_max=3.9962\n",
      "[Muon | lr=0.1] Epoch 2192/4000: train_loss=0.0043  test_loss=156.4580  λ_max=3.8964\n",
      "[Muon | lr=0.1] Epoch 2193/4000: train_loss=0.0053  test_loss=156.5066  λ_max=3.7729\n",
      "[Muon | lr=0.1] Iter 35100: loss=0.0068\n",
      "[Muon | lr=0.1] Epoch 2194/4000: train_loss=0.0043  test_loss=156.4028  λ_max=3.9904\n",
      "[Muon | lr=0.1] Epoch 2195/4000: train_loss=0.0052  test_loss=156.3846  λ_max=3.8196\n",
      "[Muon | lr=0.1] Epoch 2196/4000: train_loss=0.0054  test_loss=156.2982  λ_max=3.8947\n",
      "[Muon | lr=0.1] Epoch 2197/4000: train_loss=0.0040  test_loss=156.2734  λ_max=3.9303\n",
      "[Muon | lr=0.1] Epoch 2198/4000: train_loss=0.0053  test_loss=156.3346  λ_max=3.9434\n",
      "[Muon | lr=0.1] Epoch 2199/4000: train_loss=0.0051  test_loss=156.3538  λ_max=3.9665\n",
      "[Muon | lr=0.1] Iter 35200: loss=0.0066\n",
      "[Muon | lr=0.1] Epoch 2200/4000: train_loss=0.0050  test_loss=156.5456  λ_max=3.9645\n",
      "[Muon | lr=0.1] Epoch 2201/4000: train_loss=0.0040  test_loss=156.5867  λ_max=4.0621\n",
      "[Muon | lr=0.1] Epoch 2202/4000: train_loss=0.0047  test_loss=156.6847  λ_max=3.9746\n",
      "[Muon | lr=0.1] Epoch 2203/4000: train_loss=0.0048  test_loss=156.7932  λ_max=3.7694\n",
      "[Muon | lr=0.1] Epoch 2204/4000: train_loss=0.0042  test_loss=156.7449  λ_max=4.0883\n",
      "[Muon | lr=0.1] Epoch 2205/4000: train_loss=0.0037  test_loss=156.7507  λ_max=3.5451\n",
      "[Muon | lr=0.1] Epoch 2206/4000: train_loss=0.0039  test_loss=156.9245  λ_max=4.1410\n",
      "[Muon | lr=0.1] Iter 35300: loss=0.0012\n",
      "[Muon | lr=0.1] Epoch 2207/4000: train_loss=0.0042  test_loss=157.3434  λ_max=3.8737\n",
      "[Muon | lr=0.1] Epoch 2208/4000: train_loss=0.0035  test_loss=157.5044  λ_max=3.6797\n",
      "[Muon | lr=0.1] Epoch 2209/4000: train_loss=0.0049  test_loss=157.4807  λ_max=3.8862\n",
      "[Muon | lr=0.1] Epoch 2210/4000: train_loss=0.0051  test_loss=157.7030  λ_max=3.8563\n",
      "[Muon | lr=0.1] Epoch 2211/4000: train_loss=0.0040  test_loss=158.2181  λ_max=3.9994\n",
      "[Muon | lr=0.1] Epoch 2212/4000: train_loss=0.0044  test_loss=158.1357  λ_max=3.9180\n",
      "[Muon | lr=0.1] Iter 35400: loss=0.0032\n",
      "[Muon | lr=0.1] Epoch 2213/4000: train_loss=0.0037  test_loss=158.2613  λ_max=4.1309\n",
      "[Muon | lr=0.1] Epoch 2214/4000: train_loss=0.0045  test_loss=158.3998  λ_max=3.6935\n",
      "[Muon | lr=0.1] Epoch 2215/4000: train_loss=0.0057  test_loss=158.4519  λ_max=3.8066\n",
      "[Muon | lr=0.1] Epoch 2216/4000: train_loss=0.0052  test_loss=158.6305  λ_max=4.0311\n",
      "[Muon | lr=0.1] Epoch 2217/4000: train_loss=0.0050  test_loss=158.9069  λ_max=3.6491\n",
      "[Muon | lr=0.1] Epoch 2218/4000: train_loss=0.0047  test_loss=158.9663  λ_max=3.5601\n",
      "[Muon | lr=0.1] Iter 35500: loss=0.0053\n",
      "[Muon | lr=0.1] Epoch 2219/4000: train_loss=0.0040  test_loss=159.0104  λ_max=3.9158\n",
      "[Muon | lr=0.1] Epoch 2220/4000: train_loss=0.0039  test_loss=159.0312  λ_max=3.7556\n",
      "[Muon | lr=0.1] Epoch 2221/4000: train_loss=0.0046  test_loss=158.9475  λ_max=3.8128\n",
      "[Muon | lr=0.1] Epoch 2222/4000: train_loss=0.0051  test_loss=158.8870  λ_max=3.8647\n",
      "[Muon | lr=0.1] Epoch 2223/4000: train_loss=0.0041  test_loss=158.8210  λ_max=3.8897\n",
      "[Muon | lr=0.1] Epoch 2224/4000: train_loss=0.0044  test_loss=158.9152  λ_max=3.7052\n",
      "[Muon | lr=0.1] Iter 35600: loss=0.0110\n",
      "[Muon | lr=0.1] Epoch 2225/4000: train_loss=0.0047  test_loss=159.3074  λ_max=3.9132\n",
      "[Muon | lr=0.1] Epoch 2226/4000: train_loss=0.0049  test_loss=159.6721  λ_max=3.7747\n",
      "[Muon | lr=0.1] Epoch 2227/4000: train_loss=0.0053  test_loss=159.7196  λ_max=3.7948\n",
      "[Muon | lr=0.1] Epoch 2228/4000: train_loss=0.0046  test_loss=159.9285  λ_max=3.4966\n",
      "[Muon | lr=0.1] Epoch 2229/4000: train_loss=0.0055  test_loss=159.9017  λ_max=3.6410\n",
      "[Muon | lr=0.1] Epoch 2230/4000: train_loss=0.0035  test_loss=159.8792  λ_max=3.7456\n",
      "[Muon | lr=0.1] Epoch 2231/4000: train_loss=0.0036  test_loss=160.0355  λ_max=3.8099\n",
      "[Muon | lr=0.1] Iter 35700: loss=0.0030\n",
      "[Muon | lr=0.1] Epoch 2232/4000: train_loss=0.0049  test_loss=160.0165  λ_max=3.7755\n",
      "[Muon | lr=0.1] Epoch 2233/4000: train_loss=0.0058  test_loss=160.1846  λ_max=3.7725\n",
      "[Muon | lr=0.1] Epoch 2234/4000: train_loss=0.0043  test_loss=160.3336  λ_max=4.2570\n",
      "[Muon | lr=0.1] Epoch 2235/4000: train_loss=0.0042  test_loss=160.2256  λ_max=3.9973\n",
      "[Muon | lr=0.1] Epoch 2236/4000: train_loss=0.0040  test_loss=160.2908  λ_max=4.2117\n",
      "[Muon | lr=0.1] Epoch 2237/4000: train_loss=0.0052  test_loss=160.3859  λ_max=4.2978\n",
      "[Muon | lr=0.1] Iter 35800: loss=0.0082\n",
      "[Muon | lr=0.1] Epoch 2238/4000: train_loss=0.0045  test_loss=160.3181  λ_max=3.8320\n",
      "[Muon | lr=0.1] Epoch 2239/4000: train_loss=0.0047  test_loss=160.4012  λ_max=3.8638\n",
      "[Muon | lr=0.1] Epoch 2240/4000: train_loss=0.0042  test_loss=160.6121  λ_max=4.3229\n",
      "[Muon | lr=0.1] Epoch 2241/4000: train_loss=0.0049  test_loss=160.7091  λ_max=4.3142\n",
      "[Muon | lr=0.1] Epoch 2242/4000: train_loss=0.0058  test_loss=160.7899  λ_max=3.7685\n",
      "[Muon | lr=0.1] Epoch 2243/4000: train_loss=0.0044  test_loss=160.8046  λ_max=4.1566\n",
      "[Muon | lr=0.1] Iter 35900: loss=0.0049\n",
      "[Muon | lr=0.1] Epoch 2244/4000: train_loss=0.0040  test_loss=160.8979  λ_max=3.6656\n",
      "[Muon | lr=0.1] Epoch 2245/4000: train_loss=0.0037  test_loss=161.0611  λ_max=3.6887\n",
      "[Muon | lr=0.1] Epoch 2246/4000: train_loss=0.0049  test_loss=161.0448  λ_max=3.7463\n",
      "[Muon | lr=0.1] Epoch 2247/4000: train_loss=0.0044  test_loss=161.0803  λ_max=3.9436\n",
      "[Muon | lr=0.1] Epoch 2248/4000: train_loss=0.0042  test_loss=161.1876  λ_max=4.4657\n",
      "[Muon | lr=0.1] Epoch 2249/4000: train_loss=0.0046  test_loss=161.0540  λ_max=3.6754\n",
      "[Muon | lr=0.1] Iter 36000: loss=0.0047\n",
      "[Muon | lr=0.1] Epoch 2250/4000: train_loss=0.0042  test_loss=161.1938  λ_max=3.6363\n",
      "[Muon | lr=0.1] Epoch 2251/4000: train_loss=0.0046  test_loss=161.4420  λ_max=3.9879\n",
      "[Muon | lr=0.1] Epoch 2252/4000: train_loss=0.0063  test_loss=161.5113  λ_max=3.6928\n",
      "[Muon | lr=0.1] Epoch 2253/4000: train_loss=0.0048  test_loss=161.5865  λ_max=3.9319\n",
      "[Muon | lr=0.1] Epoch 2254/4000: train_loss=0.0047  test_loss=161.5728  λ_max=4.0919\n",
      "[Muon | lr=0.1] Epoch 2255/4000: train_loss=0.0040  test_loss=161.6224  λ_max=4.2415\n",
      "[Muon | lr=0.1] Epoch 2256/4000: train_loss=0.0042  test_loss=161.6021  λ_max=3.6376\n",
      "[Muon | lr=0.1] Iter 36100: loss=0.0025\n",
      "[Muon | lr=0.1] Epoch 2257/4000: train_loss=0.0042  test_loss=161.9068  λ_max=3.9459\n",
      "[Muon | lr=0.1] Epoch 2258/4000: train_loss=0.0052  test_loss=162.1677  λ_max=3.8382\n",
      "[Muon | lr=0.1] Epoch 2259/4000: train_loss=0.0040  test_loss=162.1964  λ_max=3.9061\n",
      "[Muon | lr=0.1] Epoch 2260/4000: train_loss=0.0044  test_loss=162.1736  λ_max=4.2020\n",
      "[Muon | lr=0.1] Epoch 2261/4000: train_loss=0.0040  test_loss=162.2975  λ_max=4.1956\n",
      "[Muon | lr=0.1] Epoch 2262/4000: train_loss=0.0053  test_loss=162.1388  λ_max=3.8607\n",
      "[Muon | lr=0.1] Iter 36200: loss=0.0062\n",
      "[Muon | lr=0.1] Epoch 2263/4000: train_loss=0.0048  test_loss=162.2839  λ_max=4.0339\n",
      "[Muon | lr=0.1] Epoch 2264/4000: train_loss=0.0039  test_loss=162.3199  λ_max=3.8697\n",
      "[Muon | lr=0.1] Epoch 2265/4000: train_loss=0.0039  test_loss=162.4399  λ_max=4.0065\n",
      "[Muon | lr=0.1] Epoch 2266/4000: train_loss=0.0040  test_loss=162.1838  λ_max=3.7941\n",
      "[Muon | lr=0.1] Epoch 2267/4000: train_loss=0.0046  test_loss=161.9494  λ_max=3.7586\n",
      "[Muon | lr=0.1] Epoch 2268/4000: train_loss=0.0051  test_loss=161.6775  λ_max=3.8465\n",
      "[Muon | lr=0.1] Iter 36300: loss=0.0057\n",
      "[Muon | lr=0.1] Epoch 2269/4000: train_loss=0.0033  test_loss=162.0157  λ_max=3.5720\n",
      "[Muon | lr=0.1] Epoch 2270/4000: train_loss=0.0052  test_loss=162.2413  λ_max=3.8062\n",
      "[Muon | lr=0.1] Epoch 2271/4000: train_loss=0.0039  test_loss=162.2757  λ_max=3.8490\n",
      "[Muon | lr=0.1] Epoch 2272/4000: train_loss=0.0042  test_loss=162.2803  λ_max=4.0443\n",
      "[Muon | lr=0.1] Epoch 2273/4000: train_loss=0.0048  test_loss=162.2086  λ_max=3.9174\n",
      "[Muon | lr=0.1] Epoch 2274/4000: train_loss=0.0041  test_loss=162.0867  λ_max=4.3278\n",
      "[Muon | lr=0.1] Iter 36400: loss=0.0092\n",
      "[Muon | lr=0.1] Epoch 2275/4000: train_loss=0.0048  test_loss=162.2042  λ_max=3.7419\n",
      "[Muon | lr=0.1] Epoch 2276/4000: train_loss=0.0058  test_loss=162.2329  λ_max=4.0652\n",
      "[Muon | lr=0.1] Epoch 2277/4000: train_loss=0.0037  test_loss=162.1593  λ_max=3.8851\n",
      "[Muon | lr=0.1] Epoch 2278/4000: train_loss=0.0046  test_loss=162.1213  λ_max=3.7752\n",
      "[Muon | lr=0.1] Epoch 2279/4000: train_loss=0.0054  test_loss=162.5731  λ_max=4.0776\n",
      "[Muon | lr=0.1] Epoch 2280/4000: train_loss=0.0065  test_loss=162.7478  λ_max=3.9254\n",
      "[Muon | lr=0.1] Epoch 2281/4000: train_loss=0.0036  test_loss=162.8103  λ_max=4.0377\n",
      "[Muon | lr=0.1] Iter 36500: loss=0.0019\n",
      "[Muon | lr=0.1] Epoch 2282/4000: train_loss=0.0035  test_loss=162.8765  λ_max=4.1824\n",
      "[Muon | lr=0.1] Epoch 2283/4000: train_loss=0.0051  test_loss=163.0581  λ_max=4.2228\n",
      "[Muon | lr=0.1] Epoch 2284/4000: train_loss=0.0046  test_loss=163.2328  λ_max=4.2978\n",
      "[Muon | lr=0.1] Epoch 2285/4000: train_loss=0.0055  test_loss=163.3932  λ_max=4.2469\n",
      "[Muon | lr=0.1] Epoch 2286/4000: train_loss=0.0042  test_loss=163.3812  λ_max=4.0128\n",
      "[Muon | lr=0.1] Epoch 2287/4000: train_loss=0.0042  test_loss=163.7694  λ_max=3.8383\n",
      "[Muon | lr=0.1] Iter 36600: loss=0.0050\n",
      "[Muon | lr=0.1] Epoch 2288/4000: train_loss=0.0056  test_loss=163.5877  λ_max=4.1553\n",
      "[Muon | lr=0.1] Epoch 2289/4000: train_loss=0.0037  test_loss=163.6291  λ_max=4.2592\n",
      "[Muon | lr=0.1] Epoch 2290/4000: train_loss=0.0050  test_loss=163.7090  λ_max=3.8876\n",
      "[Muon | lr=0.1] Epoch 2291/4000: train_loss=0.0041  test_loss=163.8331  λ_max=4.0234\n",
      "[Muon | lr=0.1] Epoch 2292/4000: train_loss=0.0042  test_loss=163.9683  λ_max=4.2301\n",
      "[Muon | lr=0.1] Epoch 2293/4000: train_loss=0.0050  test_loss=164.2315  λ_max=4.0079\n",
      "[Muon | lr=0.1] Iter 36700: loss=0.0032\n",
      "[Muon | lr=0.1] Epoch 2294/4000: train_loss=0.0043  test_loss=164.3987  λ_max=3.9551\n",
      "[Muon | lr=0.1] Epoch 2295/4000: train_loss=0.0042  test_loss=164.6110  λ_max=4.2173\n",
      "[Muon | lr=0.1] Epoch 2296/4000: train_loss=0.0043  test_loss=164.8554  λ_max=3.9386\n",
      "[Muon | lr=0.1] Epoch 2297/4000: train_loss=0.0042  test_loss=165.2402  λ_max=3.8716\n",
      "[Muon | lr=0.1] Epoch 2298/4000: train_loss=0.0044  test_loss=165.1773  λ_max=3.8848\n",
      "[Muon | lr=0.1] Epoch 2299/4000: train_loss=0.0042  test_loss=165.1287  λ_max=4.0410\n",
      "[Muon | lr=0.1] Iter 36800: loss=0.0071\n",
      "[Muon | lr=0.1] Epoch 2300/4000: train_loss=0.0045  test_loss=164.9012  λ_max=4.0650\n",
      "[Muon | lr=0.1] Epoch 2301/4000: train_loss=0.0049  test_loss=164.9704  λ_max=3.7596\n",
      "[Muon | lr=0.1] Epoch 2302/4000: train_loss=0.0045  test_loss=165.0622  λ_max=4.0343\n",
      "[Muon | lr=0.1] Epoch 2303/4000: train_loss=0.0037  test_loss=165.1944  λ_max=3.9107\n",
      "[Muon | lr=0.1] Epoch 2304/4000: train_loss=0.0039  test_loss=165.5323  λ_max=4.0343\n",
      "[Muon | lr=0.1] Epoch 2305/4000: train_loss=0.0041  test_loss=165.5696  λ_max=3.8133\n",
      "[Muon | lr=0.1] Epoch 2306/4000: train_loss=0.0049  test_loss=165.6142  λ_max=4.3877\n",
      "[Muon | lr=0.1] Iter 36900: loss=0.0007\n",
      "[Muon | lr=0.1] Epoch 2307/4000: train_loss=0.0051  test_loss=165.6292  λ_max=4.2761\n",
      "[Muon | lr=0.1] Epoch 2308/4000: train_loss=0.0055  test_loss=165.8926  λ_max=3.9090\n",
      "[Muon | lr=0.1] Epoch 2309/4000: train_loss=0.0052  test_loss=166.1308  λ_max=3.8812\n",
      "[Muon | lr=0.1] Epoch 2310/4000: train_loss=0.0037  test_loss=166.2081  λ_max=4.0802\n",
      "[Muon | lr=0.1] Epoch 2311/4000: train_loss=0.0047  test_loss=166.4646  λ_max=3.6559\n",
      "[Muon | lr=0.1] Epoch 2312/4000: train_loss=0.0046  test_loss=166.4367  λ_max=4.2717\n",
      "[Muon | lr=0.1] Iter 37000: loss=0.0026\n",
      "[Muon | lr=0.1] Epoch 2313/4000: train_loss=0.0037  test_loss=166.5185  λ_max=3.8941\n",
      "[Muon | lr=0.1] Epoch 2314/4000: train_loss=0.0048  test_loss=166.5316  λ_max=4.8464\n",
      "[Muon | lr=0.1] Epoch 2315/4000: train_loss=0.0053  test_loss=166.3466  λ_max=4.0641\n",
      "[Muon | lr=0.1] Epoch 2316/4000: train_loss=0.0043  test_loss=166.2915  λ_max=4.0558\n",
      "[Muon | lr=0.1] Epoch 2317/4000: train_loss=0.0047  test_loss=166.6052  λ_max=4.3911\n",
      "[Muon | lr=0.1] Epoch 2318/4000: train_loss=0.0043  test_loss=166.8090  λ_max=3.9409\n",
      "[Muon | lr=0.1] Iter 37100: loss=0.0044\n",
      "[Muon | lr=0.1] Epoch 2319/4000: train_loss=0.0045  test_loss=166.8795  λ_max=3.7788\n",
      "[Muon | lr=0.1] Epoch 2320/4000: train_loss=0.0045  test_loss=167.1922  λ_max=4.3605\n",
      "[Muon | lr=0.1] Epoch 2321/4000: train_loss=0.0048  test_loss=167.1502  λ_max=4.5350\n",
      "[Muon | lr=0.1] Epoch 2322/4000: train_loss=0.0043  test_loss=167.1593  λ_max=3.7083\n",
      "[Muon | lr=0.1] Epoch 2323/4000: train_loss=0.0046  test_loss=167.2669  λ_max=4.2548\n",
      "[Muon | lr=0.1] Epoch 2324/4000: train_loss=0.0052  test_loss=167.3474  λ_max=4.3480\n",
      "[Muon | lr=0.1] Iter 37200: loss=0.0057\n",
      "[Muon | lr=0.1] Epoch 2325/4000: train_loss=0.0044  test_loss=167.3758  λ_max=4.4880\n",
      "[Muon | lr=0.1] Epoch 2326/4000: train_loss=0.0033  test_loss=167.5313  λ_max=4.1134\n",
      "[Muon | lr=0.1] Epoch 2327/4000: train_loss=0.0039  test_loss=167.6339  λ_max=4.0936\n",
      "[Muon | lr=0.1] Epoch 2328/4000: train_loss=0.0042  test_loss=167.5783  λ_max=3.9059\n",
      "[Muon | lr=0.1] Epoch 2329/4000: train_loss=0.0038  test_loss=167.9757  λ_max=4.2954\n",
      "[Muon | lr=0.1] Epoch 2330/4000: train_loss=0.0063  test_loss=168.1182  λ_max=4.3741\n",
      "[Muon | lr=0.1] Epoch 2331/4000: train_loss=0.0032  test_loss=168.3181  λ_max=4.1769\n",
      "[Muon | lr=0.1] Iter 37300: loss=0.0004\n",
      "[Muon | lr=0.1] Epoch 2332/4000: train_loss=0.0042  test_loss=168.5492  λ_max=4.5454\n",
      "[Muon | lr=0.1] Epoch 2333/4000: train_loss=0.0050  test_loss=168.7824  λ_max=3.8554\n",
      "[Muon | lr=0.1] Epoch 2334/4000: train_loss=0.0045  test_loss=168.5846  λ_max=4.1809\n",
      "[Muon | lr=0.1] Epoch 2335/4000: train_loss=0.0060  test_loss=168.7106  λ_max=4.3595\n",
      "[Muon | lr=0.1] Epoch 2336/4000: train_loss=0.0049  test_loss=168.9063  λ_max=3.8328\n",
      "[Muon | lr=0.1] Epoch 2337/4000: train_loss=0.0054  test_loss=168.5940  λ_max=3.8646\n",
      "[Muon | lr=0.1] Iter 37400: loss=0.0049\n",
      "[Muon | lr=0.1] Epoch 2338/4000: train_loss=0.0043  test_loss=168.6562  λ_max=3.9049\n",
      "[Muon | lr=0.1] Epoch 2339/4000: train_loss=0.0039  test_loss=168.8399  λ_max=4.2035\n",
      "[Muon | lr=0.1] Epoch 2340/4000: train_loss=0.0038  test_loss=168.7964  λ_max=3.8789\n",
      "[Muon | lr=0.1] Epoch 2341/4000: train_loss=0.0049  test_loss=168.6998  λ_max=4.0295\n",
      "[Muon | lr=0.1] Epoch 2342/4000: train_loss=0.0048  test_loss=168.9692  λ_max=3.8152\n",
      "[Muon | lr=0.1] Epoch 2343/4000: train_loss=0.0049  test_loss=168.8834  λ_max=3.8690\n",
      "[Muon | lr=0.1] Iter 37500: loss=0.0068\n",
      "[Muon | lr=0.1] Epoch 2344/4000: train_loss=0.0054  test_loss=168.6739  λ_max=4.1371\n",
      "[Muon | lr=0.1] Epoch 2345/4000: train_loss=0.0041  test_loss=168.8813  λ_max=4.1752\n",
      "[Muon | lr=0.1] Epoch 2346/4000: train_loss=0.0049  test_loss=168.8615  λ_max=3.6054\n",
      "[Muon | lr=0.1] Epoch 2347/4000: train_loss=0.0048  test_loss=168.8603  λ_max=4.1746\n",
      "[Muon | lr=0.1] Epoch 2348/4000: train_loss=0.0045  test_loss=169.0666  λ_max=4.1213\n",
      "[Muon | lr=0.1] Epoch 2349/4000: train_loss=0.0052  test_loss=169.2010  λ_max=4.0246\n",
      "[Muon | lr=0.1] Iter 37600: loss=0.0071\n",
      "[Muon | lr=0.1] Epoch 2350/4000: train_loss=0.0044  test_loss=169.3034  λ_max=4.3351\n",
      "[Muon | lr=0.1] Epoch 2351/4000: train_loss=0.0037  test_loss=169.3980  λ_max=4.1168\n",
      "[Muon | lr=0.1] Epoch 2352/4000: train_loss=0.0041  test_loss=169.1939  λ_max=4.6003\n",
      "[Muon | lr=0.1] Epoch 2353/4000: train_loss=0.0051  test_loss=169.2762  λ_max=3.9000\n",
      "[Muon | lr=0.1] Epoch 2354/4000: train_loss=0.0054  test_loss=169.4746  λ_max=3.9689\n",
      "[Muon | lr=0.1] Epoch 2355/4000: train_loss=0.0048  test_loss=169.6291  λ_max=3.5247\n",
      "[Muon | lr=0.1] Epoch 2356/4000: train_loss=0.0045  test_loss=169.7378  λ_max=4.0012\n",
      "[Muon | lr=0.1] Iter 37700: loss=0.0014\n",
      "[Muon | lr=0.1] Epoch 2357/4000: train_loss=0.0049  test_loss=170.0938  λ_max=3.8062\n",
      "[Muon | lr=0.1] Epoch 2358/4000: train_loss=0.0048  test_loss=170.3166  λ_max=3.8001\n",
      "[Muon | lr=0.1] Epoch 2359/4000: train_loss=0.0043  test_loss=170.5354  λ_max=4.0918\n",
      "[Muon | lr=0.1] Epoch 2360/4000: train_loss=0.0062  test_loss=170.6058  λ_max=4.1553\n",
      "[Muon | lr=0.1] Epoch 2361/4000: train_loss=0.0043  test_loss=170.4792  λ_max=3.8974\n",
      "[Muon | lr=0.1] Epoch 2362/4000: train_loss=0.0046  test_loss=170.4823  λ_max=4.1028\n",
      "[Muon | lr=0.1] Iter 37800: loss=0.0063\n",
      "[Muon | lr=0.1] Epoch 2363/4000: train_loss=0.0045  test_loss=170.8715  λ_max=4.1875\n",
      "[Muon | lr=0.1] Epoch 2364/4000: train_loss=0.0050  test_loss=171.3043  λ_max=3.7350\n",
      "[Muon | lr=0.1] Epoch 2365/4000: train_loss=0.0051  test_loss=171.4268  λ_max=3.8934\n",
      "[Muon | lr=0.1] Epoch 2366/4000: train_loss=0.0031  test_loss=171.4323  λ_max=4.2044\n",
      "[Muon | lr=0.1] Epoch 2367/4000: train_loss=0.0035  test_loss=171.4662  λ_max=3.7970\n",
      "[Muon | lr=0.1] Epoch 2368/4000: train_loss=0.0049  test_loss=171.4029  λ_max=3.9397\n",
      "[Muon | lr=0.1] Iter 37900: loss=0.0075\n",
      "[Muon | lr=0.1] Epoch 2369/4000: train_loss=0.0068  test_loss=171.4175  λ_max=4.4856\n",
      "[Muon | lr=0.1] Epoch 2370/4000: train_loss=0.0047  test_loss=171.3391  λ_max=4.3591\n",
      "[Muon | lr=0.1] Epoch 2371/4000: train_loss=0.0037  test_loss=171.2383  λ_max=4.3838\n",
      "[Muon | lr=0.1] Epoch 2372/4000: train_loss=0.0047  test_loss=171.2007  λ_max=4.1533\n",
      "[Muon | lr=0.1] Epoch 2373/4000: train_loss=0.0042  test_loss=171.0224  λ_max=3.8242\n",
      "[Muon | lr=0.1] Epoch 2374/4000: train_loss=0.0054  test_loss=171.0947  λ_max=4.2804\n",
      "[Muon | lr=0.1] Iter 38000: loss=0.0068\n",
      "[Muon | lr=0.1] Epoch 2375/4000: train_loss=0.0040  test_loss=171.0910  λ_max=4.1520\n",
      "[Muon | lr=0.1] Epoch 2376/4000: train_loss=0.0043  test_loss=171.0104  λ_max=3.9919\n",
      "[Muon | lr=0.1] Epoch 2377/4000: train_loss=0.0037  test_loss=171.4151  λ_max=3.8492\n",
      "[Muon | lr=0.1] Epoch 2378/4000: train_loss=0.0041  test_loss=171.4719  λ_max=3.7056\n",
      "[Muon | lr=0.1] Epoch 2379/4000: train_loss=0.0052  test_loss=171.4999  λ_max=4.0734\n",
      "[Muon | lr=0.1] Epoch 2380/4000: train_loss=0.0039  test_loss=171.7327  λ_max=4.0048\n",
      "[Muon | lr=0.1] Epoch 2381/4000: train_loss=0.0043  test_loss=171.5850  λ_max=3.9036\n",
      "[Muon | lr=0.1] Iter 38100: loss=0.0030\n",
      "[Muon | lr=0.1] Epoch 2382/4000: train_loss=0.0051  test_loss=171.6232  λ_max=3.7927\n",
      "[Muon | lr=0.1] Epoch 2383/4000: train_loss=0.0046  test_loss=171.8130  λ_max=3.9486\n",
      "[Muon | lr=0.1] Epoch 2384/4000: train_loss=0.0040  test_loss=171.9449  λ_max=4.1635\n",
      "[Muon | lr=0.1] Epoch 2385/4000: train_loss=0.0059  test_loss=172.4560  λ_max=4.1326\n",
      "[Muon | lr=0.1] Epoch 2386/4000: train_loss=0.0040  test_loss=172.6673  λ_max=3.6895\n",
      "[Muon | lr=0.1] Epoch 2387/4000: train_loss=0.0046  test_loss=172.7991  λ_max=4.5026\n",
      "[Muon | lr=0.1] Iter 38200: loss=0.0038\n",
      "[Muon | lr=0.1] Epoch 2388/4000: train_loss=0.0045  test_loss=172.7897  λ_max=4.5648\n",
      "[Muon | lr=0.1] Epoch 2389/4000: train_loss=0.0042  test_loss=172.7481  λ_max=4.4355\n",
      "[Muon | lr=0.1] Epoch 2390/4000: train_loss=0.0052  test_loss=172.8975  λ_max=4.1092\n",
      "[Muon | lr=0.1] Epoch 2391/4000: train_loss=0.0038  test_loss=173.1763  λ_max=4.4247\n",
      "[Muon | lr=0.1] Epoch 2392/4000: train_loss=0.0044  test_loss=173.3699  λ_max=4.2035\n",
      "[Muon | lr=0.1] Epoch 2393/4000: train_loss=0.0048  test_loss=173.3738  λ_max=3.8351\n",
      "[Muon | lr=0.1] Iter 38300: loss=0.0026\n",
      "[Muon | lr=0.1] Epoch 2394/4000: train_loss=0.0044  test_loss=173.5318  λ_max=4.0607\n",
      "[Muon | lr=0.1] Epoch 2395/4000: train_loss=0.0057  test_loss=173.3693  λ_max=3.9240\n",
      "[Muon | lr=0.1] Epoch 2396/4000: train_loss=0.0037  test_loss=173.1473  λ_max=3.9679\n",
      "[Muon | lr=0.1] Epoch 2397/4000: train_loss=0.0048  test_loss=173.1162  λ_max=4.0261\n",
      "[Muon | lr=0.1] Epoch 2398/4000: train_loss=0.0046  test_loss=173.2956  λ_max=4.2225\n",
      "[Muon | lr=0.1] Epoch 2399/4000: train_loss=0.0053  test_loss=173.0396  λ_max=4.8210\n",
      "[Muon | lr=0.1] Iter 38400: loss=0.0114\n",
      "[Muon | lr=0.1] Epoch 2400/4000: train_loss=0.0029  test_loss=173.0139  λ_max=4.1516\n",
      "[Muon | lr=0.1] Epoch 2401/4000: train_loss=0.0047  test_loss=173.1608  λ_max=4.9928\n",
      "[Muon | lr=0.1] Epoch 2402/4000: train_loss=0.0049  test_loss=173.1887  λ_max=4.3953\n",
      "[Muon | lr=0.1] Epoch 2403/4000: train_loss=0.0046  test_loss=173.2038  λ_max=4.6350\n",
      "[Muon | lr=0.1] Epoch 2404/4000: train_loss=0.0044  test_loss=173.1648  λ_max=4.2139\n",
      "[Muon | lr=0.1] Epoch 2405/4000: train_loss=0.0041  test_loss=172.6777  λ_max=4.0092\n",
      "[Muon | lr=0.1] Epoch 2406/4000: train_loss=0.0036  test_loss=172.4932  λ_max=4.5230\n",
      "[Muon | lr=0.1] Iter 38500: loss=0.0013\n",
      "[Muon | lr=0.1] Epoch 2407/4000: train_loss=0.0039  test_loss=172.4831  λ_max=3.8761\n",
      "[Muon | lr=0.1] Epoch 2408/4000: train_loss=0.0036  test_loss=172.6741  λ_max=4.1221\n",
      "[Muon | lr=0.1] Epoch 2409/4000: train_loss=0.0046  test_loss=172.8145  λ_max=4.0325\n",
      "[Muon | lr=0.1] Epoch 2410/4000: train_loss=0.0050  test_loss=172.9711  λ_max=4.3725\n",
      "[Muon | lr=0.1] Epoch 2411/4000: train_loss=0.0039  test_loss=173.0954  λ_max=4.1352\n",
      "[Muon | lr=0.1] Epoch 2412/4000: train_loss=0.0039  test_loss=173.4177  λ_max=4.3254\n",
      "[Muon | lr=0.1] Iter 38600: loss=0.0047\n",
      "[Muon | lr=0.1] Epoch 2413/4000: train_loss=0.0055  test_loss=173.3954  λ_max=4.0056\n",
      "[Muon | lr=0.1] Epoch 2414/4000: train_loss=0.0046  test_loss=173.2477  λ_max=4.3569\n",
      "[Muon | lr=0.1] Epoch 2415/4000: train_loss=0.0035  test_loss=173.3629  λ_max=4.9533\n",
      "[Muon | lr=0.1] Epoch 2416/4000: train_loss=0.0042  test_loss=173.1734  λ_max=4.0034\n",
      "[Muon | lr=0.1] Epoch 2417/4000: train_loss=0.0045  test_loss=173.2012  λ_max=4.3728\n",
      "[Muon | lr=0.1] Epoch 2418/4000: train_loss=0.0051  test_loss=173.4904  λ_max=4.1135\n",
      "[Muon | lr=0.1] Iter 38700: loss=0.0021\n",
      "[Muon | lr=0.1] Epoch 2419/4000: train_loss=0.0043  test_loss=173.4460  λ_max=4.3502\n",
      "[Muon | lr=0.1] Epoch 2420/4000: train_loss=0.0043  test_loss=173.1568  λ_max=5.1457\n",
      "[Muon | lr=0.1] Epoch 2421/4000: train_loss=0.0044  test_loss=173.3288  λ_max=4.3104\n",
      "[Muon | lr=0.1] Epoch 2422/4000: train_loss=0.0044  test_loss=173.3587  λ_max=4.0005\n",
      "[Muon | lr=0.1] Epoch 2423/4000: train_loss=0.0044  test_loss=173.3839  λ_max=3.8788\n",
      "[Muon | lr=0.1] Epoch 2424/4000: train_loss=0.0048  test_loss=173.4437  λ_max=4.2288\n",
      "[Muon | lr=0.1] Iter 38800: loss=0.0011\n",
      "[Muon | lr=0.1] Epoch 2425/4000: train_loss=0.0042  test_loss=173.6767  λ_max=4.6915\n",
      "[Muon | lr=0.1] Epoch 2426/4000: train_loss=0.0048  test_loss=173.8788  λ_max=4.1390\n",
      "[Muon | lr=0.1] Epoch 2427/4000: train_loss=0.0042  test_loss=173.8972  λ_max=4.9292\n",
      "[Muon | lr=0.1] Epoch 2428/4000: train_loss=0.0051  test_loss=174.0566  λ_max=4.3331\n",
      "[Muon | lr=0.1] Epoch 2429/4000: train_loss=0.0040  test_loss=173.8337  λ_max=3.9533\n",
      "[Muon | lr=0.1] Epoch 2430/4000: train_loss=0.0054  test_loss=173.9343  λ_max=3.8765\n",
      "[Muon | lr=0.1] Epoch 2431/4000: train_loss=0.0047  test_loss=174.0291  λ_max=3.8586\n",
      "[Muon | lr=0.1] Iter 38900: loss=0.0001\n",
      "[Muon | lr=0.1] Epoch 2432/4000: train_loss=0.0039  test_loss=174.2009  λ_max=4.1340\n",
      "[Muon | lr=0.1] Epoch 2433/4000: train_loss=0.0056  test_loss=174.4237  λ_max=4.0517\n",
      "[Muon | lr=0.1] Epoch 2434/4000: train_loss=0.0046  test_loss=174.3750  λ_max=4.3557\n",
      "[Muon | lr=0.1] Epoch 2435/4000: train_loss=0.0036  test_loss=174.1375  λ_max=4.9146\n",
      "[Muon | lr=0.1] Epoch 2436/4000: train_loss=0.0045  test_loss=174.1203  λ_max=4.0672\n",
      "[Muon | lr=0.1] Epoch 2437/4000: train_loss=0.0045  test_loss=174.1436  λ_max=3.8461\n",
      "[Muon | lr=0.1] Iter 39000: loss=0.0011\n",
      "[Muon | lr=0.1] Epoch 2438/4000: train_loss=0.0055  test_loss=174.1131  λ_max=4.5280\n",
      "[Muon | lr=0.1] Epoch 2439/4000: train_loss=0.0038  test_loss=174.1019  λ_max=3.8926\n",
      "[Muon | lr=0.1] Epoch 2440/4000: train_loss=0.0052  test_loss=174.2728  λ_max=4.2334\n",
      "[Muon | lr=0.1] Epoch 2441/4000: train_loss=0.0045  test_loss=174.3725  λ_max=4.7474\n",
      "[Muon | lr=0.1] Epoch 2442/4000: train_loss=0.0048  test_loss=174.3067  λ_max=4.2009\n",
      "[Muon | lr=0.1] Epoch 2443/4000: train_loss=0.0051  test_loss=174.4008  λ_max=4.2828\n",
      "[Muon | lr=0.1] Iter 39100: loss=0.0064\n",
      "[Muon | lr=0.1] Epoch 2444/4000: train_loss=0.0040  test_loss=174.6061  λ_max=4.2554\n",
      "[Muon | lr=0.1] Epoch 2445/4000: train_loss=0.0047  test_loss=174.8653  λ_max=4.0005\n",
      "[Muon | lr=0.1] Epoch 2446/4000: train_loss=0.0044  test_loss=174.9252  λ_max=3.8643\n",
      "[Muon | lr=0.1] Epoch 2447/4000: train_loss=0.0041  test_loss=175.0021  λ_max=4.0446\n",
      "[Muon | lr=0.1] Epoch 2448/4000: train_loss=0.0048  test_loss=174.8064  λ_max=4.1906\n",
      "[Muon | lr=0.1] Epoch 2449/4000: train_loss=0.0044  test_loss=174.6108  λ_max=4.0535\n",
      "[Muon | lr=0.1] Iter 39200: loss=0.0086\n",
      "[Muon | lr=0.1] Epoch 2450/4000: train_loss=0.0036  test_loss=174.5527  λ_max=4.1299\n",
      "[Muon | lr=0.1] Epoch 2451/4000: train_loss=0.0041  test_loss=174.7643  λ_max=4.1630\n",
      "[Muon | lr=0.1] Epoch 2452/4000: train_loss=0.0050  test_loss=174.6433  λ_max=4.5005\n",
      "[Muon | lr=0.1] Epoch 2453/4000: train_loss=0.0051  test_loss=174.5458  λ_max=4.0211\n",
      "[Muon | lr=0.1] Epoch 2454/4000: train_loss=0.0050  test_loss=174.7392  λ_max=4.4800\n",
      "[Muon | lr=0.1] Epoch 2455/4000: train_loss=0.0046  test_loss=174.9591  λ_max=4.0373\n",
      "[Muon | lr=0.1] Epoch 2456/4000: train_loss=0.0044  test_loss=174.9454  λ_max=4.1379\n",
      "[Muon | lr=0.1] Iter 39300: loss=0.0028\n",
      "[Muon | lr=0.1] Epoch 2457/4000: train_loss=0.0049  test_loss=175.0524  λ_max=4.0087\n",
      "[Muon | lr=0.1] Epoch 2458/4000: train_loss=0.0050  test_loss=175.3606  λ_max=4.0239\n",
      "[Muon | lr=0.1] Epoch 2459/4000: train_loss=0.0050  test_loss=175.3966  λ_max=4.1393\n",
      "[Muon | lr=0.1] Epoch 2460/4000: train_loss=0.0050  test_loss=175.4964  λ_max=4.1452\n",
      "[Muon | lr=0.1] Epoch 2461/4000: train_loss=0.0044  test_loss=175.5378  λ_max=4.1179\n",
      "[Muon | lr=0.1] Epoch 2462/4000: train_loss=0.0049  test_loss=175.6768  λ_max=4.4572\n",
      "[Muon | lr=0.1] Iter 39400: loss=0.0093\n",
      "[Muon | lr=0.1] Epoch 2463/4000: train_loss=0.0054  test_loss=176.0124  λ_max=4.2855\n",
      "[Muon | lr=0.1] Epoch 2464/4000: train_loss=0.0043  test_loss=175.8964  λ_max=4.3957\n",
      "[Muon | lr=0.1] Epoch 2465/4000: train_loss=0.0049  test_loss=175.7472  λ_max=4.4829\n",
      "[Muon | lr=0.1] Epoch 2466/4000: train_loss=0.0053  test_loss=175.8898  λ_max=4.4587\n",
      "[Muon | lr=0.1] Epoch 2467/4000: train_loss=0.0049  test_loss=176.0154  λ_max=4.2957\n",
      "[Muon | lr=0.1] Epoch 2468/4000: train_loss=0.0051  test_loss=176.5596  λ_max=4.1983\n",
      "[Muon | lr=0.1] Iter 39500: loss=0.0085\n",
      "[Muon | lr=0.1] Epoch 2469/4000: train_loss=0.0054  test_loss=176.7569  λ_max=4.4038\n",
      "[Muon | lr=0.1] Epoch 2470/4000: train_loss=0.0056  test_loss=176.8102  λ_max=4.6941\n",
      "[Muon | lr=0.1] Epoch 2471/4000: train_loss=0.0031  test_loss=176.9621  λ_max=4.0134\n",
      "[Muon | lr=0.1] Epoch 2472/4000: train_loss=0.0051  test_loss=177.0560  λ_max=4.1925\n",
      "[Muon | lr=0.1] Epoch 2473/4000: train_loss=0.0045  test_loss=177.3657  λ_max=3.9769\n",
      "[Muon | lr=0.1] Epoch 2474/4000: train_loss=0.0040  test_loss=177.1700  λ_max=3.9760\n",
      "[Muon | lr=0.1] Iter 39600: loss=0.0051\n",
      "[Muon | lr=0.1] Epoch 2475/4000: train_loss=0.0041  test_loss=177.1022  λ_max=4.5356\n",
      "[Muon | lr=0.1] Epoch 2476/4000: train_loss=0.0043  test_loss=177.0837  λ_max=4.2121\n",
      "[Muon | lr=0.1] Epoch 2477/4000: train_loss=0.0053  test_loss=177.1106  λ_max=5.1455\n",
      "[Muon | lr=0.1] Epoch 2478/4000: train_loss=0.0046  test_loss=177.0983  λ_max=4.0175\n",
      "[Muon | lr=0.1] Epoch 2479/4000: train_loss=0.0051  test_loss=177.2552  λ_max=4.0965\n",
      "[Muon | lr=0.1] Epoch 2480/4000: train_loss=0.0048  test_loss=177.3880  λ_max=4.3248\n",
      "[Muon | lr=0.1] Epoch 2481/4000: train_loss=0.0044  test_loss=177.8592  λ_max=4.2320\n",
      "[Muon | lr=0.1] Iter 39700: loss=0.0008\n",
      "[Muon | lr=0.1] Epoch 2482/4000: train_loss=0.0039  test_loss=178.2336  λ_max=4.2812\n",
      "[Muon | lr=0.1] Epoch 2483/4000: train_loss=0.0048  test_loss=177.9925  λ_max=4.3073\n",
      "[Muon | lr=0.1] Epoch 2484/4000: train_loss=0.0044  test_loss=178.0786  λ_max=4.7772\n",
      "[Muon | lr=0.1] Epoch 2485/4000: train_loss=0.0050  test_loss=177.8226  λ_max=4.5226\n",
      "[Muon | lr=0.1] Epoch 2486/4000: train_loss=0.0052  test_loss=177.8506  λ_max=3.7641\n",
      "[Muon | lr=0.1] Epoch 2487/4000: train_loss=0.0043  test_loss=178.0173  λ_max=4.1261\n",
      "[Muon | lr=0.1] Iter 39800: loss=0.0007\n",
      "[Muon | lr=0.1] Epoch 2488/4000: train_loss=0.0045  test_loss=178.1849  λ_max=4.3664\n",
      "[Muon | lr=0.1] Epoch 2489/4000: train_loss=0.0042  test_loss=178.2848  λ_max=4.0148\n",
      "[Muon | lr=0.1] Epoch 2490/4000: train_loss=0.0056  test_loss=178.3802  λ_max=4.5205\n",
      "[Muon | lr=0.1] Epoch 2491/4000: train_loss=0.0052  test_loss=178.6693  λ_max=4.6157\n",
      "[Muon | lr=0.1] Epoch 2492/4000: train_loss=0.0050  test_loss=178.5498  λ_max=4.0737\n",
      "[Muon | lr=0.1] Epoch 2493/4000: train_loss=0.0039  test_loss=178.6197  λ_max=4.5520\n",
      "[Muon | lr=0.1] Iter 39900: loss=0.0105\n",
      "[Muon | lr=0.1] Epoch 2494/4000: train_loss=0.0042  test_loss=178.6247  λ_max=4.2834\n",
      "[Muon | lr=0.1] Epoch 2495/4000: train_loss=0.0041  test_loss=178.6540  λ_max=4.5132\n",
      "[Muon | lr=0.1] Epoch 2496/4000: train_loss=0.0036  test_loss=178.8096  λ_max=4.4642\n",
      "[Muon | lr=0.1] Epoch 2497/4000: train_loss=0.0051  test_loss=178.6650  λ_max=4.4373\n",
      "[Muon | lr=0.1] Epoch 2498/4000: train_loss=0.0050  test_loss=178.5820  λ_max=4.3790\n",
      "[Muon | lr=0.1] Epoch 2499/4000: train_loss=0.0040  test_loss=178.3720  λ_max=4.0945\n",
      "[Muon | lr=0.1] Iter 40000: loss=0.0053\n",
      "[Muon | lr=0.1] Epoch 2500/4000: train_loss=0.0042  test_loss=178.2223  λ_max=4.0584\n",
      "[Muon | lr=0.1] Epoch 2501/4000: train_loss=0.0045  test_loss=177.9957  λ_max=4.2208\n",
      "[Muon | lr=0.1] Epoch 2502/4000: train_loss=0.0044  test_loss=178.1306  λ_max=4.1731\n",
      "[Muon | lr=0.1] Epoch 2503/4000: train_loss=0.0048  test_loss=178.3976  λ_max=4.3091\n",
      "[Muon | lr=0.1] Epoch 2504/4000: train_loss=0.0047  test_loss=178.4156  λ_max=4.5369\n",
      "[Muon | lr=0.1] Epoch 2505/4000: train_loss=0.0042  test_loss=178.3602  λ_max=4.2435\n",
      "[Muon | lr=0.1] Epoch 2506/4000: train_loss=0.0042  test_loss=178.1220  λ_max=3.9680\n",
      "[Muon | lr=0.1] Iter 40100: loss=0.0024\n",
      "[Muon | lr=0.1] Epoch 2507/4000: train_loss=0.0047  test_loss=178.1051  λ_max=4.7318\n",
      "[Muon | lr=0.1] Epoch 2508/4000: train_loss=0.0055  test_loss=178.1241  λ_max=4.2657\n",
      "[Muon | lr=0.1] Epoch 2509/4000: train_loss=0.0045  test_loss=178.6181  λ_max=4.4730\n",
      "[Muon | lr=0.1] Epoch 2510/4000: train_loss=0.0040  test_loss=179.0048  λ_max=4.6901\n",
      "[Muon | lr=0.1] Epoch 2511/4000: train_loss=0.0039  test_loss=179.1335  λ_max=4.5115\n",
      "[Muon | lr=0.1] Epoch 2512/4000: train_loss=0.0038  test_loss=179.3225  λ_max=4.6267\n",
      "[Muon | lr=0.1] Iter 40200: loss=0.0053\n",
      "[Muon | lr=0.1] Epoch 2513/4000: train_loss=0.0061  test_loss=179.4778  λ_max=4.9068\n",
      "[Muon | lr=0.1] Epoch 2514/4000: train_loss=0.0033  test_loss=179.6215  λ_max=4.1225\n",
      "[Muon | lr=0.1] Epoch 2515/4000: train_loss=0.0048  test_loss=179.7710  λ_max=4.7161\n",
      "[Muon | lr=0.1] Epoch 2516/4000: train_loss=0.0048  test_loss=179.8118  λ_max=4.1478\n",
      "[Muon | lr=0.1] Epoch 2517/4000: train_loss=0.0047  test_loss=179.8261  λ_max=4.7923\n",
      "[Muon | lr=0.1] Epoch 2518/4000: train_loss=0.0042  test_loss=179.8091  λ_max=4.3969\n",
      "[Muon | lr=0.1] Iter 40300: loss=0.0052\n",
      "[Muon | lr=0.1] Epoch 2519/4000: train_loss=0.0039  test_loss=179.8758  λ_max=4.0681\n",
      "[Muon | lr=0.1] Epoch 2520/4000: train_loss=0.0047  test_loss=179.9317  λ_max=3.9656\n",
      "[Muon | lr=0.1] Epoch 2521/4000: train_loss=0.0036  test_loss=179.7513  λ_max=4.1723\n",
      "[Muon | lr=0.1] Epoch 2522/4000: train_loss=0.0032  test_loss=179.6756  λ_max=4.2442\n",
      "[Muon | lr=0.1] Epoch 2523/4000: train_loss=0.0056  test_loss=179.8481  λ_max=4.2765\n",
      "[Muon | lr=0.1] Epoch 2524/4000: train_loss=0.0049  test_loss=180.1369  λ_max=3.9841\n",
      "[Muon | lr=0.1] Iter 40400: loss=0.0103\n",
      "[Muon | lr=0.1] Epoch 2525/4000: train_loss=0.0042  test_loss=180.3990  λ_max=5.1902\n",
      "[Muon | lr=0.1] Epoch 2526/4000: train_loss=0.0049  test_loss=180.8270  λ_max=4.1168\n",
      "[Muon | lr=0.1] Epoch 2527/4000: train_loss=0.0051  test_loss=180.8957  λ_max=4.1946\n",
      "[Muon | lr=0.1] Epoch 2528/4000: train_loss=0.0056  test_loss=180.7529  λ_max=4.5774\n",
      "[Muon | lr=0.1] Epoch 2529/4000: train_loss=0.0040  test_loss=180.6995  λ_max=4.8757\n",
      "[Muon | lr=0.1] Epoch 2530/4000: train_loss=0.0038  test_loss=180.5658  λ_max=4.3328\n",
      "[Muon | lr=0.1] Epoch 2531/4000: train_loss=0.0050  test_loss=180.5183  λ_max=4.2018\n",
      "[Muon | lr=0.1] Iter 40500: loss=0.0065\n",
      "[Muon | lr=0.1] Epoch 2532/4000: train_loss=0.0051  test_loss=180.5787  λ_max=4.5610\n",
      "[Muon | lr=0.1] Epoch 2533/4000: train_loss=0.0051  test_loss=180.7262  λ_max=4.3521\n",
      "[Muon | lr=0.1] Epoch 2534/4000: train_loss=0.0035  test_loss=181.0784  λ_max=4.0947\n",
      "[Muon | lr=0.1] Epoch 2535/4000: train_loss=0.0044  test_loss=181.2541  λ_max=4.1245\n",
      "[Muon | lr=0.1] Epoch 2536/4000: train_loss=0.0043  test_loss=181.6222  λ_max=4.7983\n",
      "[Muon | lr=0.1] Epoch 2537/4000: train_loss=0.0041  test_loss=181.9933  λ_max=4.2617\n",
      "[Muon | lr=0.1] Iter 40600: loss=0.0021\n",
      "[Muon | lr=0.1] Epoch 2538/4000: train_loss=0.0040  test_loss=181.8831  λ_max=4.2530\n",
      "[Muon | lr=0.1] Epoch 2539/4000: train_loss=0.0046  test_loss=182.0510  λ_max=3.8858\n",
      "[Muon | lr=0.1] Epoch 2540/4000: train_loss=0.0044  test_loss=182.1119  λ_max=4.5741\n",
      "[Muon | lr=0.1] Epoch 2541/4000: train_loss=0.0048  test_loss=182.3697  λ_max=4.1129\n",
      "[Muon | lr=0.1] Epoch 2542/4000: train_loss=0.0051  test_loss=182.5499  λ_max=4.0853\n",
      "[Muon | lr=0.1] Epoch 2543/4000: train_loss=0.0050  test_loss=182.5807  λ_max=4.1666\n",
      "[Muon | lr=0.1] Iter 40700: loss=0.0032\n",
      "[Muon | lr=0.1] Epoch 2544/4000: train_loss=0.0048  test_loss=182.7965  λ_max=4.0195\n",
      "[Muon | lr=0.1] Epoch 2545/4000: train_loss=0.0050  test_loss=182.8781  λ_max=4.2345\n",
      "[Muon | lr=0.1] Epoch 2546/4000: train_loss=0.0041  test_loss=182.8116  λ_max=3.8378\n",
      "[Muon | lr=0.1] Epoch 2547/4000: train_loss=0.0047  test_loss=182.6877  λ_max=4.3139\n",
      "[Muon | lr=0.1] Epoch 2548/4000: train_loss=0.0039  test_loss=182.7054  λ_max=4.1279\n",
      "[Muon | lr=0.1] Epoch 2549/4000: train_loss=0.0053  test_loss=182.8007  λ_max=3.9514\n",
      "[Muon | lr=0.1] Iter 40800: loss=0.0142\n",
      "[Muon | lr=0.1] Epoch 2550/4000: train_loss=0.0051  test_loss=182.8382  λ_max=4.2405\n",
      "[Muon | lr=0.1] Epoch 2551/4000: train_loss=0.0037  test_loss=182.5955  λ_max=4.4063\n",
      "[Muon | lr=0.1] Epoch 2552/4000: train_loss=0.0043  test_loss=182.7729  λ_max=4.1033\n",
      "[Muon | lr=0.1] Epoch 2553/4000: train_loss=0.0049  test_loss=183.0273  λ_max=4.3832\n",
      "[Muon | lr=0.1] Epoch 2554/4000: train_loss=0.0039  test_loss=183.0184  λ_max=4.1622\n",
      "[Muon | lr=0.1] Epoch 2555/4000: train_loss=0.0049  test_loss=183.2248  λ_max=4.1179\n",
      "[Muon | lr=0.1] Epoch 2556/4000: train_loss=0.0044  test_loss=183.6558  λ_max=4.3790\n",
      "[Muon | lr=0.1] Iter 40900: loss=0.0018\n",
      "[Muon | lr=0.1] Epoch 2557/4000: train_loss=0.0040  test_loss=183.6530  λ_max=4.6992\n",
      "[Muon | lr=0.1] Epoch 2558/4000: train_loss=0.0040  test_loss=183.5483  λ_max=4.2086\n",
      "[Muon | lr=0.1] Epoch 2559/4000: train_loss=0.0037  test_loss=183.7580  λ_max=4.2482\n",
      "[Muon | lr=0.1] Epoch 2560/4000: train_loss=0.0038  test_loss=183.8492  λ_max=4.3743\n",
      "[Muon | lr=0.1] Epoch 2561/4000: train_loss=0.0036  test_loss=184.1355  λ_max=4.0464\n",
      "[Muon | lr=0.1] Epoch 2562/4000: train_loss=0.0049  test_loss=184.2036  λ_max=4.3142\n",
      "[Muon | lr=0.1] Iter 41000: loss=0.0029\n",
      "[Muon | lr=0.1] Epoch 2563/4000: train_loss=0.0035  test_loss=184.1574  λ_max=4.4623\n",
      "[Muon | lr=0.1] Epoch 2564/4000: train_loss=0.0051  test_loss=184.2493  λ_max=4.2021\n",
      "[Muon | lr=0.1] Epoch 2565/4000: train_loss=0.0059  test_loss=184.5285  λ_max=4.5444\n",
      "[Muon | lr=0.1] Epoch 2566/4000: train_loss=0.0048  test_loss=184.6281  λ_max=4.0291\n",
      "[Muon | lr=0.1] Epoch 2567/4000: train_loss=0.0048  test_loss=184.3692  λ_max=4.0766\n",
      "[Muon | lr=0.1] Epoch 2568/4000: train_loss=0.0049  test_loss=184.5219  λ_max=4.5123\n",
      "[Muon | lr=0.1] Iter 41100: loss=0.0035\n",
      "[Muon | lr=0.1] Epoch 2569/4000: train_loss=0.0052  test_loss=184.8142  λ_max=4.7988\n",
      "[Muon | lr=0.1] Epoch 2570/4000: train_loss=0.0049  test_loss=184.7564  λ_max=4.5922\n",
      "[Muon | lr=0.1] Epoch 2571/4000: train_loss=0.0050  test_loss=185.0290  λ_max=4.6411\n",
      "[Muon | lr=0.1] Epoch 2572/4000: train_loss=0.0041  test_loss=185.1045  λ_max=4.4245\n",
      "[Muon | lr=0.1] Epoch 2573/4000: train_loss=0.0036  test_loss=185.3541  λ_max=4.4764\n",
      "[Muon | lr=0.1] Epoch 2574/4000: train_loss=0.0038  test_loss=185.6565  λ_max=4.3071\n",
      "[Muon | lr=0.1] Iter 41200: loss=0.0089\n",
      "[Muon | lr=0.1] Epoch 2575/4000: train_loss=0.0040  test_loss=186.1034  λ_max=4.5204\n",
      "[Muon | lr=0.1] Epoch 2576/4000: train_loss=0.0050  test_loss=186.1575  λ_max=4.5505\n",
      "[Muon | lr=0.1] Epoch 2577/4000: train_loss=0.0039  test_loss=186.1322  λ_max=4.1726\n",
      "[Muon | lr=0.1] Epoch 2578/4000: train_loss=0.0039  test_loss=186.0805  λ_max=4.1840\n",
      "[Muon | lr=0.1] Epoch 2579/4000: train_loss=0.0054  test_loss=186.1062  λ_max=3.9872\n",
      "[Muon | lr=0.1] Epoch 2580/4000: train_loss=0.0041  test_loss=186.3574  λ_max=4.0227\n",
      "[Muon | lr=0.1] Epoch 2581/4000: train_loss=0.0036  test_loss=186.3527  λ_max=4.7331\n",
      "[Muon | lr=0.1] Iter 41300: loss=0.0032\n",
      "[Muon | lr=0.1] Epoch 2582/4000: train_loss=0.0056  test_loss=186.6587  λ_max=4.3704\n",
      "[Muon | lr=0.1] Epoch 2583/4000: train_loss=0.0045  test_loss=186.3429  λ_max=4.4792\n",
      "[Muon | lr=0.1] Epoch 2584/4000: train_loss=0.0045  test_loss=186.3881  λ_max=4.1567\n",
      "[Muon | lr=0.1] Epoch 2585/4000: train_loss=0.0051  test_loss=186.9225  λ_max=4.6299\n",
      "[Muon | lr=0.1] Epoch 2586/4000: train_loss=0.0056  test_loss=187.0661  λ_max=4.6509\n",
      "[Muon | lr=0.1] Epoch 2587/4000: train_loss=0.0033  test_loss=187.0911  λ_max=5.0498\n",
      "[Muon | lr=0.1] Iter 41400: loss=0.0048\n",
      "[Muon | lr=0.1] Epoch 2588/4000: train_loss=0.0051  test_loss=187.0940  λ_max=4.4874\n",
      "[Muon | lr=0.1] Epoch 2589/4000: train_loss=0.0039  test_loss=186.8209  λ_max=4.2804\n",
      "[Muon | lr=0.1] Epoch 2590/4000: train_loss=0.0038  test_loss=187.0781  λ_max=4.3900\n",
      "[Muon | lr=0.1] Epoch 2591/4000: train_loss=0.0032  test_loss=187.0301  λ_max=4.2985\n",
      "[Muon | lr=0.1] Epoch 2592/4000: train_loss=0.0041  test_loss=187.3708  λ_max=4.2886\n",
      "[Muon | lr=0.1] Epoch 2593/4000: train_loss=0.0042  test_loss=187.3147  λ_max=4.6603\n",
      "[Muon | lr=0.1] Iter 41500: loss=0.0046\n",
      "[Muon | lr=0.1] Epoch 2594/4000: train_loss=0.0046  test_loss=187.3398  λ_max=4.3689\n",
      "[Muon | lr=0.1] Epoch 2595/4000: train_loss=0.0056  test_loss=187.5573  λ_max=4.6609\n",
      "[Muon | lr=0.1] Epoch 2596/4000: train_loss=0.0050  test_loss=187.8080  λ_max=4.6250\n",
      "[Muon | lr=0.1] Epoch 2597/4000: train_loss=0.0044  test_loss=187.9622  λ_max=4.9780\n",
      "[Muon | lr=0.1] Epoch 2598/4000: train_loss=0.0044  test_loss=188.1192  λ_max=4.3364\n",
      "[Muon | lr=0.1] Epoch 2599/4000: train_loss=0.0045  test_loss=187.8957  λ_max=4.4885\n",
      "[Muon | lr=0.1] Iter 41600: loss=0.0030\n",
      "[Muon | lr=0.1] Epoch 2600/4000: train_loss=0.0039  test_loss=187.8887  λ_max=4.3003\n",
      "[Muon | lr=0.1] Epoch 2601/4000: train_loss=0.0057  test_loss=188.0098  λ_max=4.6270\n",
      "[Muon | lr=0.1] Epoch 2602/4000: train_loss=0.0044  test_loss=188.0929  λ_max=4.7571\n",
      "[Muon | lr=0.1] Epoch 2603/4000: train_loss=0.0044  test_loss=187.8731  λ_max=4.3326\n",
      "[Muon | lr=0.1] Epoch 2604/4000: train_loss=0.0053  test_loss=187.8502  λ_max=4.5002\n",
      "[Muon | lr=0.1] Epoch 2605/4000: train_loss=0.0033  test_loss=188.1735  λ_max=4.4509\n",
      "[Muon | lr=0.1] Epoch 2606/4000: train_loss=0.0051  test_loss=188.2714  λ_max=4.3154\n",
      "[Muon | lr=0.1] Iter 41700: loss=0.0060\n",
      "[Muon | lr=0.1] Epoch 2607/4000: train_loss=0.0055  test_loss=188.2980  λ_max=4.6845\n",
      "[Muon | lr=0.1] Epoch 2608/4000: train_loss=0.0041  test_loss=188.5293  λ_max=4.6016\n",
      "[Muon | lr=0.1] Epoch 2609/4000: train_loss=0.0048  test_loss=188.5154  λ_max=4.7921\n",
      "[Muon | lr=0.1] Epoch 2610/4000: train_loss=0.0052  test_loss=188.4901  λ_max=4.4470\n",
      "[Muon | lr=0.1] Epoch 2611/4000: train_loss=0.0042  test_loss=188.4244  λ_max=4.0987\n",
      "[Muon | lr=0.1] Epoch 2612/4000: train_loss=0.0054  test_loss=188.8515  λ_max=4.8315\n",
      "[Muon | lr=0.1] Iter 41800: loss=0.0045\n",
      "[Muon | lr=0.1] Epoch 2613/4000: train_loss=0.0054  test_loss=189.0179  λ_max=4.1756\n",
      "[Muon | lr=0.1] Epoch 2614/4000: train_loss=0.0038  test_loss=189.0085  λ_max=4.7214\n",
      "[Muon | lr=0.1] Epoch 2615/4000: train_loss=0.0045  test_loss=189.1706  λ_max=4.8357\n",
      "[Muon | lr=0.1] Epoch 2616/4000: train_loss=0.0047  test_loss=189.2337  λ_max=4.5258\n",
      "[Muon | lr=0.1] Epoch 2617/4000: train_loss=0.0041  test_loss=189.2935  λ_max=4.4979\n",
      "[Muon | lr=0.1] Epoch 2618/4000: train_loss=0.0034  test_loss=189.4539  λ_max=4.2129\n",
      "[Muon | lr=0.1] Iter 41900: loss=0.0039\n",
      "[Muon | lr=0.1] Epoch 2619/4000: train_loss=0.0046  test_loss=189.3561  λ_max=4.5844\n",
      "[Muon | lr=0.1] Epoch 2620/4000: train_loss=0.0051  test_loss=189.6883  λ_max=4.1044\n",
      "[Muon | lr=0.1] Epoch 2621/4000: train_loss=0.0058  test_loss=190.0251  λ_max=4.7130\n",
      "[Muon | lr=0.1] Epoch 2622/4000: train_loss=0.0045  test_loss=189.8351  λ_max=4.6593\n",
      "[Muon | lr=0.1] Epoch 2623/4000: train_loss=0.0037  test_loss=189.8131  λ_max=4.6519\n",
      "[Muon | lr=0.1] Epoch 2624/4000: train_loss=0.0041  test_loss=189.8037  λ_max=4.2798\n",
      "[Muon | lr=0.1] Iter 42000: loss=0.0194\n",
      "[Muon | lr=0.1] Epoch 2625/4000: train_loss=0.0058  test_loss=189.3775  λ_max=4.4091\n",
      "[Muon | lr=0.1] Epoch 2626/4000: train_loss=0.0040  test_loss=189.0178  λ_max=4.0310\n",
      "[Muon | lr=0.1] Epoch 2627/4000: train_loss=0.0042  test_loss=188.7684  λ_max=4.0398\n",
      "[Muon | lr=0.1] Epoch 2628/4000: train_loss=0.0046  test_loss=188.7720  λ_max=4.2716\n",
      "[Muon | lr=0.1] Epoch 2629/4000: train_loss=0.0042  test_loss=188.5436  λ_max=4.1868\n",
      "[Muon | lr=0.1] Epoch 2630/4000: train_loss=0.0043  test_loss=188.7354  λ_max=4.5805\n",
      "[Muon | lr=0.1] Epoch 2631/4000: train_loss=0.0049  test_loss=189.1138  λ_max=4.0882\n",
      "[Muon | lr=0.1] Iter 42100: loss=0.0010\n",
      "[Muon | lr=0.1] Epoch 2632/4000: train_loss=0.0054  test_loss=189.1779  λ_max=4.5323\n",
      "[Muon | lr=0.1] Epoch 2633/4000: train_loss=0.0042  test_loss=189.2075  λ_max=4.7469\n",
      "[Muon | lr=0.1] Epoch 2634/4000: train_loss=0.0049  test_loss=189.0928  λ_max=4.4691\n",
      "[Muon | lr=0.1] Epoch 2635/4000: train_loss=0.0045  test_loss=189.1262  λ_max=4.2856\n",
      "[Muon | lr=0.1] Epoch 2636/4000: train_loss=0.0049  test_loss=189.2757  λ_max=5.1598\n",
      "[Muon | lr=0.1] Epoch 2637/4000: train_loss=0.0041  test_loss=189.4327  λ_max=4.0618\n",
      "[Muon | lr=0.1] Iter 42200: loss=0.0057\n",
      "[Muon | lr=0.1] Epoch 2638/4000: train_loss=0.0048  test_loss=189.5129  λ_max=4.3279\n",
      "[Muon | lr=0.1] Epoch 2639/4000: train_loss=0.0030  test_loss=189.7080  λ_max=4.1337\n",
      "[Muon | lr=0.1] Epoch 2640/4000: train_loss=0.0038  test_loss=190.0046  λ_max=4.3247\n",
      "[Muon | lr=0.1] Epoch 2641/4000: train_loss=0.0045  test_loss=189.7847  λ_max=4.1690\n",
      "[Muon | lr=0.1] Epoch 2642/4000: train_loss=0.0046  test_loss=189.6260  λ_max=4.1598\n",
      "[Muon | lr=0.1] Epoch 2643/4000: train_loss=0.0046  test_loss=189.6443  λ_max=4.3357\n",
      "[Muon | lr=0.1] Iter 42300: loss=0.0068\n",
      "[Muon | lr=0.1] Epoch 2644/4000: train_loss=0.0031  test_loss=189.7412  λ_max=4.0613\n",
      "[Muon | lr=0.1] Epoch 2645/4000: train_loss=0.0052  test_loss=189.7948  λ_max=4.4216\n",
      "[Muon | lr=0.1] Epoch 2646/4000: train_loss=0.0046  test_loss=189.9684  λ_max=4.1125\n",
      "[Muon | lr=0.1] Epoch 2647/4000: train_loss=0.0045  test_loss=190.2426  λ_max=4.5233\n",
      "[Muon | lr=0.1] Epoch 2648/4000: train_loss=0.0051  test_loss=190.3559  λ_max=4.3581\n",
      "[Muon | lr=0.1] Epoch 2649/4000: train_loss=0.0047  test_loss=190.4339  λ_max=4.5787\n",
      "[Muon | lr=0.1] Iter 42400: loss=0.0174\n",
      "[Muon | lr=0.1] Epoch 2650/4000: train_loss=0.0048  test_loss=190.5891  λ_max=4.4563\n",
      "[Muon | lr=0.1] Epoch 2651/4000: train_loss=0.0035  test_loss=190.9048  λ_max=4.1865\n",
      "[Muon | lr=0.1] Epoch 2652/4000: train_loss=0.0045  test_loss=190.8986  λ_max=4.5837\n",
      "[Muon | lr=0.1] Epoch 2653/4000: train_loss=0.0039  test_loss=190.6856  λ_max=4.7247\n",
      "[Muon | lr=0.1] Epoch 2654/4000: train_loss=0.0041  test_loss=190.5792  λ_max=4.0698\n",
      "[Muon | lr=0.1] Epoch 2655/4000: train_loss=0.0050  test_loss=190.8968  λ_max=4.8865\n",
      "[Muon | lr=0.1] Epoch 2656/4000: train_loss=0.0036  test_loss=190.9521  λ_max=4.2328\n",
      "[Muon | lr=0.1] Iter 42500: loss=0.0002\n",
      "[Muon | lr=0.1] Epoch 2657/4000: train_loss=0.0045  test_loss=191.0323  λ_max=4.2643\n",
      "[Muon | lr=0.1] Epoch 2658/4000: train_loss=0.0044  test_loss=190.8835  λ_max=4.1571\n",
      "[Muon | lr=0.1] Epoch 2659/4000: train_loss=0.0047  test_loss=190.8853  λ_max=4.0083\n",
      "[Muon | lr=0.1] Epoch 2660/4000: train_loss=0.0030  test_loss=190.8948  λ_max=4.3829\n",
      "[Muon | lr=0.1] Epoch 2661/4000: train_loss=0.0035  test_loss=190.8730  λ_max=4.8601\n",
      "[Muon | lr=0.1] Epoch 2662/4000: train_loss=0.0044  test_loss=190.7434  λ_max=4.6162\n",
      "[Muon | lr=0.1] Iter 42600: loss=0.0061\n",
      "[Muon | lr=0.1] Epoch 2663/4000: train_loss=0.0047  test_loss=190.5513  λ_max=4.4317\n",
      "[Muon | lr=0.1] Epoch 2664/4000: train_loss=0.0053  test_loss=190.8904  λ_max=4.7453\n",
      "[Muon | lr=0.1] Epoch 2665/4000: train_loss=0.0042  test_loss=191.2947  λ_max=4.0441\n",
      "[Muon | lr=0.1] Epoch 2666/4000: train_loss=0.0043  test_loss=191.2745  λ_max=4.6192\n",
      "[Muon | lr=0.1] Epoch 2667/4000: train_loss=0.0041  test_loss=191.2302  λ_max=4.7180\n",
      "[Muon | lr=0.1] Epoch 2668/4000: train_loss=0.0054  test_loss=191.2345  λ_max=4.3928\n",
      "[Muon | lr=0.1] Iter 42700: loss=0.0045\n",
      "[Muon | lr=0.1] Epoch 2669/4000: train_loss=0.0037  test_loss=190.9022  λ_max=4.2306\n",
      "[Muon | lr=0.1] Epoch 2670/4000: train_loss=0.0043  test_loss=190.9136  λ_max=4.0336\n",
      "[Muon | lr=0.1] Epoch 2671/4000: train_loss=0.0054  test_loss=191.0495  λ_max=4.4439\n",
      "[Muon | lr=0.1] Epoch 2672/4000: train_loss=0.0047  test_loss=191.2260  λ_max=4.4806\n",
      "[Muon | lr=0.1] Epoch 2673/4000: train_loss=0.0053  test_loss=191.4631  λ_max=4.4135\n",
      "[Muon | lr=0.1] Epoch 2674/4000: train_loss=0.0043  test_loss=191.5334  λ_max=4.7652\n",
      "[Muon | lr=0.1] Iter 42800: loss=0.0065\n",
      "[Muon | lr=0.1] Epoch 2675/4000: train_loss=0.0040  test_loss=191.5665  λ_max=4.3449\n",
      "[Muon | lr=0.1] Epoch 2676/4000: train_loss=0.0040  test_loss=191.7840  λ_max=4.2175\n",
      "[Muon | lr=0.1] Epoch 2677/4000: train_loss=0.0040  test_loss=191.9561  λ_max=4.2374\n",
      "[Muon | lr=0.1] Epoch 2678/4000: train_loss=0.0036  test_loss=191.9819  λ_max=4.3666\n",
      "[Muon | lr=0.1] Epoch 2679/4000: train_loss=0.0039  test_loss=192.1004  λ_max=4.3419\n",
      "[Muon | lr=0.1] Epoch 2680/4000: train_loss=0.0046  test_loss=192.1439  λ_max=4.6112\n",
      "[Muon | lr=0.1] Epoch 2681/4000: train_loss=0.0052  test_loss=192.2577  λ_max=4.3478\n",
      "[Muon | lr=0.1] Iter 42900: loss=0.0020\n",
      "[Muon | lr=0.1] Epoch 2682/4000: train_loss=0.0056  test_loss=192.2972  λ_max=4.9429\n",
      "[Muon | lr=0.1] Epoch 2683/4000: train_loss=0.0035  test_loss=192.3202  λ_max=4.0551\n",
      "[Muon | lr=0.1] Epoch 2684/4000: train_loss=0.0047  test_loss=192.4960  λ_max=4.6856\n",
      "[Muon | lr=0.1] Epoch 2685/4000: train_loss=0.0038  test_loss=192.9491  λ_max=4.4088\n",
      "[Muon | lr=0.1] Epoch 2686/4000: train_loss=0.0036  test_loss=193.0920  λ_max=4.5798\n",
      "[Muon | lr=0.1] Epoch 2687/4000: train_loss=0.0043  test_loss=193.3492  λ_max=4.7734\n",
      "[Muon | lr=0.1] Iter 43000: loss=0.0027\n",
      "[Muon | lr=0.1] Epoch 2688/4000: train_loss=0.0041  test_loss=193.2907  λ_max=4.3920\n",
      "[Muon | lr=0.1] Epoch 2689/4000: train_loss=0.0045  test_loss=193.2855  λ_max=5.2076\n",
      "[Muon | lr=0.1] Epoch 2690/4000: train_loss=0.0039  test_loss=193.5333  λ_max=4.3546\n",
      "[Muon | lr=0.1] Epoch 2691/4000: train_loss=0.0051  test_loss=193.9315  λ_max=3.9757\n",
      "[Muon | lr=0.1] Epoch 2692/4000: train_loss=0.0048  test_loss=193.9609  λ_max=4.8042\n",
      "[Muon | lr=0.1] Epoch 2693/4000: train_loss=0.0041  test_loss=194.0820  λ_max=4.7730\n",
      "[Muon | lr=0.1] Iter 43100: loss=0.0043\n",
      "[Muon | lr=0.1] Epoch 2694/4000: train_loss=0.0042  test_loss=194.1005  λ_max=4.7008\n",
      "[Muon | lr=0.1] Epoch 2695/4000: train_loss=0.0037  test_loss=194.0620  λ_max=4.2107\n",
      "[Muon | lr=0.1] Epoch 2696/4000: train_loss=0.0047  test_loss=194.1605  λ_max=4.0329\n",
      "[Muon | lr=0.1] Epoch 2697/4000: train_loss=0.0054  test_loss=194.2663  λ_max=4.1412\n",
      "[Muon | lr=0.1] Epoch 2698/4000: train_loss=0.0042  test_loss=194.2157  λ_max=4.0222\n",
      "[Muon | lr=0.1] Epoch 2699/4000: train_loss=0.0045  test_loss=194.4279  λ_max=4.1633\n",
      "[Muon | lr=0.1] Iter 43200: loss=0.0195\n",
      "[Muon | lr=0.1] Epoch 2700/4000: train_loss=0.0048  test_loss=194.4755  λ_max=4.3617\n",
      "[Muon | lr=0.1] Epoch 2701/4000: train_loss=0.0052  test_loss=194.4239  λ_max=4.3461\n",
      "[Muon | lr=0.1] Epoch 2702/4000: train_loss=0.0040  test_loss=194.3161  λ_max=4.2855\n",
      "[Muon | lr=0.1] Epoch 2703/4000: train_loss=0.0031  test_loss=194.5410  λ_max=4.6226\n",
      "[Muon | lr=0.1] Epoch 2704/4000: train_loss=0.0034  test_loss=194.6533  λ_max=4.3161\n",
      "[Muon | lr=0.1] Epoch 2705/4000: train_loss=0.0041  test_loss=194.4581  λ_max=4.6606\n",
      "[Muon | lr=0.1] Epoch 2706/4000: train_loss=0.0047  test_loss=194.2637  λ_max=5.0031\n",
      "[Muon | lr=0.1] Iter 43300: loss=0.0026\n",
      "[Muon | lr=0.1] Epoch 2707/4000: train_loss=0.0035  test_loss=194.2150  λ_max=4.2414\n",
      "[Muon | lr=0.1] Epoch 2708/4000: train_loss=0.0052  test_loss=194.2777  λ_max=4.5215\n",
      "[Muon | lr=0.1] Epoch 2709/4000: train_loss=0.0048  test_loss=194.5540  λ_max=4.3897\n",
      "[Muon | lr=0.1] Epoch 2710/4000: train_loss=0.0053  test_loss=194.6346  λ_max=4.3945\n",
      "[Muon | lr=0.1] Epoch 2711/4000: train_loss=0.0042  test_loss=194.5907  λ_max=4.6952\n",
      "[Muon | lr=0.1] Epoch 2712/4000: train_loss=0.0042  test_loss=194.8395  λ_max=4.8246\n",
      "[Muon | lr=0.1] Iter 43400: loss=0.0017\n",
      "[Muon | lr=0.1] Epoch 2713/4000: train_loss=0.0045  test_loss=194.8619  λ_max=5.1599\n",
      "[Muon | lr=0.1] Epoch 2714/4000: train_loss=0.0043  test_loss=195.0242  λ_max=4.6241\n",
      "[Muon | lr=0.1] Epoch 2715/4000: train_loss=0.0045  test_loss=195.2189  λ_max=4.4120\n",
      "[Muon | lr=0.1] Epoch 2716/4000: train_loss=0.0044  test_loss=195.4013  λ_max=5.3928\n",
      "[Muon | lr=0.1] Epoch 2717/4000: train_loss=0.0036  test_loss=195.5213  λ_max=4.8534\n",
      "[Muon | lr=0.1] Epoch 2718/4000: train_loss=0.0049  test_loss=195.5589  λ_max=4.4538\n",
      "[Muon | lr=0.1] Iter 43500: loss=0.0023\n",
      "[Muon | lr=0.1] Epoch 2719/4000: train_loss=0.0042  test_loss=195.6729  λ_max=4.9358\n",
      "[Muon | lr=0.1] Epoch 2720/4000: train_loss=0.0043  test_loss=195.6099  λ_max=4.5605\n",
      "[Muon | lr=0.1] Epoch 2721/4000: train_loss=0.0047  test_loss=195.6931  λ_max=4.6114\n",
      "[Muon | lr=0.1] Epoch 2722/4000: train_loss=0.0048  test_loss=195.8539  λ_max=4.8074\n",
      "[Muon | lr=0.1] Epoch 2723/4000: train_loss=0.0051  test_loss=196.0747  λ_max=4.1265\n",
      "[Muon | lr=0.1] Epoch 2724/4000: train_loss=0.0045  test_loss=196.0716  λ_max=4.4894\n",
      "[Muon | lr=0.1] Iter 43600: loss=0.0219\n",
      "[Muon | lr=0.1] Epoch 2725/4000: train_loss=0.0044  test_loss=196.4602  λ_max=4.3757\n",
      "[Muon | lr=0.1] Epoch 2726/4000: train_loss=0.0056  test_loss=196.4073  λ_max=4.4270\n",
      "[Muon | lr=0.1] Epoch 2727/4000: train_loss=0.0039  test_loss=196.5595  λ_max=5.2559\n",
      "[Muon | lr=0.1] Epoch 2728/4000: train_loss=0.0042  test_loss=197.0177  λ_max=4.8334\n",
      "[Muon | lr=0.1] Epoch 2729/4000: train_loss=0.0042  test_loss=196.9962  λ_max=4.8048\n",
      "[Muon | lr=0.1] Epoch 2730/4000: train_loss=0.0048  test_loss=197.0277  λ_max=5.0934\n",
      "[Muon | lr=0.1] Epoch 2731/4000: train_loss=0.0046  test_loss=197.0669  λ_max=4.4500\n",
      "[Muon | lr=0.1] Iter 43700: loss=0.0007\n",
      "[Muon | lr=0.1] Epoch 2732/4000: train_loss=0.0046  test_loss=197.1470  λ_max=4.3543\n",
      "[Muon | lr=0.1] Epoch 2733/4000: train_loss=0.0032  test_loss=197.4539  λ_max=4.2999\n",
      "[Muon | lr=0.1] Epoch 2734/4000: train_loss=0.0048  test_loss=197.4074  λ_max=4.4311\n",
      "[Muon | lr=0.1] Epoch 2735/4000: train_loss=0.0048  test_loss=197.5308  λ_max=4.6208\n",
      "[Muon | lr=0.1] Epoch 2736/4000: train_loss=0.0057  test_loss=197.6556  λ_max=4.7781\n",
      "[Muon | lr=0.1] Epoch 2737/4000: train_loss=0.0038  test_loss=197.5804  λ_max=5.0309\n",
      "[Muon | lr=0.1] Iter 43800: loss=0.0016\n",
      "[Muon | lr=0.1] Epoch 2738/4000: train_loss=0.0045  test_loss=197.4916  λ_max=4.3477\n",
      "[Muon | lr=0.1] Epoch 2739/4000: train_loss=0.0038  test_loss=197.5947  λ_max=4.2045\n",
      "[Muon | lr=0.1] Epoch 2740/4000: train_loss=0.0047  test_loss=197.7247  λ_max=4.9433\n",
      "[Muon | lr=0.1] Epoch 2741/4000: train_loss=0.0046  test_loss=198.0156  λ_max=4.4358\n",
      "[Muon | lr=0.1] Epoch 2742/4000: train_loss=0.0045  test_loss=198.1716  λ_max=4.9221\n",
      "[Muon | lr=0.1] Epoch 2743/4000: train_loss=0.0042  test_loss=198.3634  λ_max=4.7719\n",
      "[Muon | lr=0.1] Iter 43900: loss=0.0015\n",
      "[Muon | lr=0.1] Epoch 2744/4000: train_loss=0.0035  test_loss=198.3125  λ_max=4.1585\n",
      "[Muon | lr=0.1] Epoch 2745/4000: train_loss=0.0045  test_loss=198.5311  λ_max=4.4123\n",
      "[Muon | lr=0.1] Epoch 2746/4000: train_loss=0.0033  test_loss=198.7394  λ_max=4.7549\n",
      "[Muon | lr=0.1] Epoch 2747/4000: train_loss=0.0062  test_loss=198.8556  λ_max=4.6140\n",
      "[Muon | lr=0.1] Epoch 2748/4000: train_loss=0.0042  test_loss=198.9854  λ_max=4.2173\n",
      "[Muon | lr=0.1] Epoch 2749/4000: train_loss=0.0035  test_loss=198.9646  λ_max=4.6039\n",
      "[Muon | lr=0.1] Iter 44000: loss=0.0012\n",
      "[Muon | lr=0.1] Epoch 2750/4000: train_loss=0.0045  test_loss=199.0950  λ_max=4.1447\n",
      "[Muon | lr=0.1] Epoch 2751/4000: train_loss=0.0049  test_loss=199.3174  λ_max=4.7586\n",
      "[Muon | lr=0.1] Epoch 2752/4000: train_loss=0.0040  test_loss=199.4456  λ_max=4.5020\n",
      "[Muon | lr=0.1] Epoch 2753/4000: train_loss=0.0041  test_loss=199.4912  λ_max=4.6218\n",
      "[Muon | lr=0.1] Epoch 2754/4000: train_loss=0.0047  test_loss=199.5100  λ_max=4.6708\n",
      "[Muon | lr=0.1] Epoch 2755/4000: train_loss=0.0042  test_loss=199.4949  λ_max=4.4003\n",
      "[Muon | lr=0.1] Epoch 2756/4000: train_loss=0.0036  test_loss=199.8196  λ_max=4.7226\n",
      "[Muon | lr=0.1] Iter 44100: loss=0.0004\n",
      "[Muon | lr=0.1] Epoch 2757/4000: train_loss=0.0042  test_loss=199.8394  λ_max=5.0096\n",
      "[Muon | lr=0.1] Epoch 2758/4000: train_loss=0.0039  test_loss=199.7807  λ_max=4.4371\n",
      "[Muon | lr=0.1] Epoch 2759/4000: train_loss=0.0040  test_loss=199.6752  λ_max=4.6019\n",
      "[Muon | lr=0.1] Epoch 2760/4000: train_loss=0.0052  test_loss=199.5429  λ_max=4.4365\n",
      "[Muon | lr=0.1] Epoch 2761/4000: train_loss=0.0048  test_loss=199.6532  λ_max=4.4906\n",
      "[Muon | lr=0.1] Epoch 2762/4000: train_loss=0.0048  test_loss=199.8546  λ_max=4.3787\n",
      "[Muon | lr=0.1] Iter 44200: loss=0.0046\n",
      "[Muon | lr=0.1] Epoch 2763/4000: train_loss=0.0039  test_loss=199.8355  λ_max=5.0628\n",
      "[Muon | lr=0.1] Epoch 2764/4000: train_loss=0.0049  test_loss=200.0837  λ_max=4.2546\n",
      "[Muon | lr=0.1] Epoch 2765/4000: train_loss=0.0039  test_loss=200.4652  λ_max=4.7191\n",
      "[Muon | lr=0.1] Epoch 2766/4000: train_loss=0.0052  test_loss=200.8329  λ_max=4.7786\n",
      "[Muon | lr=0.1] Epoch 2767/4000: train_loss=0.0036  test_loss=200.9601  λ_max=4.4158\n",
      "[Muon | lr=0.1] Epoch 2768/4000: train_loss=0.0053  test_loss=201.0827  λ_max=4.5699\n",
      "[Muon | lr=0.1] Iter 44300: loss=0.0032\n",
      "[Muon | lr=0.1] Epoch 2769/4000: train_loss=0.0043  test_loss=201.0178  λ_max=5.2305\n",
      "[Muon | lr=0.1] Epoch 2770/4000: train_loss=0.0046  test_loss=200.9460  λ_max=4.2407\n",
      "[Muon | lr=0.1] Epoch 2771/4000: train_loss=0.0035  test_loss=200.7884  λ_max=5.2345\n",
      "[Muon | lr=0.1] Epoch 2772/4000: train_loss=0.0044  test_loss=200.8029  λ_max=4.4744\n",
      "[Muon | lr=0.1] Epoch 2773/4000: train_loss=0.0041  test_loss=200.7888  λ_max=4.5622\n",
      "[Muon | lr=0.1] Epoch 2774/4000: train_loss=0.0032  test_loss=200.9492  λ_max=5.3772\n",
      "[Muon | lr=0.1] Iter 44400: loss=0.0131\n",
      "[Muon | lr=0.1] Epoch 2775/4000: train_loss=0.0054  test_loss=201.0692  λ_max=4.1368\n",
      "[Muon | lr=0.1] Epoch 2776/4000: train_loss=0.0059  test_loss=201.4284  λ_max=4.4892\n",
      "[Muon | lr=0.1] Epoch 2777/4000: train_loss=0.0043  test_loss=201.9391  λ_max=4.8349\n",
      "[Muon | lr=0.1] Epoch 2778/4000: train_loss=0.0045  test_loss=202.1985  λ_max=4.3869\n",
      "[Muon | lr=0.1] Epoch 2779/4000: train_loss=0.0033  test_loss=202.3238  λ_max=4.3479\n",
      "[Muon | lr=0.1] Epoch 2780/4000: train_loss=0.0046  test_loss=202.3231  λ_max=4.5041\n",
      "[Muon | lr=0.1] Epoch 2781/4000: train_loss=0.0046  test_loss=202.5023  λ_max=4.3023\n",
      "[Muon | lr=0.1] Iter 44500: loss=0.0025\n",
      "[Muon | lr=0.1] Epoch 2782/4000: train_loss=0.0049  test_loss=202.4552  λ_max=4.6210\n",
      "[Muon | lr=0.1] Epoch 2783/4000: train_loss=0.0038  test_loss=202.5012  λ_max=4.5655\n",
      "[Muon | lr=0.1] Epoch 2784/4000: train_loss=0.0039  test_loss=202.5821  λ_max=4.3883\n",
      "[Muon | lr=0.1] Epoch 2785/4000: train_loss=0.0036  test_loss=202.8034  λ_max=4.0412\n",
      "[Muon | lr=0.1] Epoch 2786/4000: train_loss=0.0049  test_loss=202.7623  λ_max=4.7808\n",
      "[Muon | lr=0.1] Epoch 2787/4000: train_loss=0.0037  test_loss=202.9893  λ_max=4.4780\n",
      "[Muon | lr=0.1] Iter 44600: loss=0.0018\n",
      "[Muon | lr=0.1] Epoch 2788/4000: train_loss=0.0041  test_loss=203.0792  λ_max=4.5917\n",
      "[Muon | lr=0.1] Epoch 2789/4000: train_loss=0.0050  test_loss=202.8763  λ_max=4.4324\n",
      "[Muon | lr=0.1] Epoch 2790/4000: train_loss=0.0039  test_loss=202.8850  λ_max=4.2761\n",
      "[Muon | lr=0.1] Epoch 2791/4000: train_loss=0.0039  test_loss=203.1075  λ_max=4.4923\n",
      "[Muon | lr=0.1] Epoch 2792/4000: train_loss=0.0052  test_loss=203.0497  λ_max=4.4068\n",
      "[Muon | lr=0.1] Epoch 2793/4000: train_loss=0.0040  test_loss=203.1713  λ_max=4.6427\n",
      "[Muon | lr=0.1] Iter 44700: loss=0.0046\n",
      "[Muon | lr=0.1] Epoch 2794/4000: train_loss=0.0045  test_loss=203.2604  λ_max=4.6862\n",
      "[Muon | lr=0.1] Epoch 2795/4000: train_loss=0.0046  test_loss=203.3694  λ_max=5.0180\n",
      "[Muon | lr=0.1] Epoch 2796/4000: train_loss=0.0047  test_loss=203.3298  λ_max=4.7567\n",
      "[Muon | lr=0.1] Epoch 2797/4000: train_loss=0.0041  test_loss=203.3755  λ_max=4.9014\n",
      "[Muon | lr=0.1] Epoch 2798/4000: train_loss=0.0043  test_loss=203.7764  λ_max=4.4334\n",
      "[Muon | lr=0.1] Epoch 2799/4000: train_loss=0.0049  test_loss=204.0836  λ_max=4.8400\n",
      "[Muon | lr=0.1] Iter 44800: loss=0.0080\n",
      "[Muon | lr=0.1] Epoch 2800/4000: train_loss=0.0042  test_loss=204.1427  λ_max=4.4271\n",
      "[Muon | lr=0.1] Epoch 2801/4000: train_loss=0.0043  test_loss=204.1814  λ_max=4.9530\n",
      "[Muon | lr=0.1] Epoch 2802/4000: train_loss=0.0065  test_loss=204.1016  λ_max=4.0316\n",
      "[Muon | lr=0.1] Epoch 2803/4000: train_loss=0.0047  test_loss=203.8191  λ_max=4.6545\n",
      "[Muon | lr=0.1] Epoch 2804/4000: train_loss=0.0034  test_loss=203.8593  λ_max=4.7664\n",
      "[Muon | lr=0.1] Epoch 2805/4000: train_loss=0.0042  test_loss=204.1110  λ_max=4.8482\n",
      "[Muon | lr=0.1] Epoch 2806/4000: train_loss=0.0046  test_loss=204.0715  λ_max=4.6185\n",
      "[Muon | lr=0.1] Iter 44900: loss=0.0046\n",
      "[Muon | lr=0.1] Epoch 2807/4000: train_loss=0.0037  test_loss=204.3926  λ_max=4.6046\n",
      "[Muon | lr=0.1] Epoch 2808/4000: train_loss=0.0044  test_loss=204.4156  λ_max=5.6318\n",
      "[Muon | lr=0.1] Epoch 2809/4000: train_loss=0.0035  test_loss=204.4556  λ_max=3.9562\n",
      "[Muon | lr=0.1] Epoch 2810/4000: train_loss=0.0044  test_loss=204.4003  λ_max=4.5901\n",
      "[Muon | lr=0.1] Epoch 2811/4000: train_loss=0.0042  test_loss=204.6205  λ_max=5.0184\n",
      "[Muon | lr=0.1] Epoch 2812/4000: train_loss=0.0027  test_loss=204.7023  λ_max=4.6155\n",
      "[Muon | lr=0.1] Iter 45000: loss=0.0000\n",
      "[Muon | lr=0.1] Epoch 2813/4000: train_loss=0.0046  test_loss=204.6654  λ_max=4.2087\n",
      "[Muon | lr=0.1] Epoch 2814/4000: train_loss=0.0042  test_loss=204.5479  λ_max=5.2689\n",
      "[Muon | lr=0.1] Epoch 2815/4000: train_loss=0.0039  test_loss=204.4821  λ_max=4.3126\n",
      "[Muon | lr=0.1] Epoch 2816/4000: train_loss=0.0034  test_loss=204.4373  λ_max=5.1039\n",
      "[Muon | lr=0.1] Epoch 2817/4000: train_loss=0.0046  test_loss=204.5264  λ_max=4.6269\n",
      "[Muon | lr=0.1] Epoch 2818/4000: train_loss=0.0047  test_loss=204.8804  λ_max=5.0112\n",
      "[Muon | lr=0.1] Iter 45100: loss=0.0096\n",
      "[Muon | lr=0.1] Epoch 2819/4000: train_loss=0.0055  test_loss=205.2914  λ_max=4.4191\n",
      "[Muon | lr=0.1] Epoch 2820/4000: train_loss=0.0044  test_loss=205.1247  λ_max=4.8315\n",
      "[Muon | lr=0.1] Epoch 2821/4000: train_loss=0.0040  test_loss=205.1215  λ_max=4.7097\n",
      "[Muon | lr=0.1] Epoch 2822/4000: train_loss=0.0046  test_loss=205.1719  λ_max=4.8231\n",
      "[Muon | lr=0.1] Epoch 2823/4000: train_loss=0.0040  test_loss=205.3021  λ_max=4.2391\n",
      "[Muon | lr=0.1] Epoch 2824/4000: train_loss=0.0040  test_loss=205.1366  λ_max=4.3853\n",
      "[Muon | lr=0.1] Iter 45200: loss=0.0104\n",
      "[Muon | lr=0.1] Epoch 2825/4000: train_loss=0.0038  test_loss=205.2202  λ_max=4.3009\n",
      "[Muon | lr=0.1] Epoch 2826/4000: train_loss=0.0037  test_loss=205.3511  λ_max=4.3004\n",
      "[Muon | lr=0.1] Epoch 2827/4000: train_loss=0.0040  test_loss=204.9654  λ_max=4.5817\n",
      "[Muon | lr=0.1] Epoch 2828/4000: train_loss=0.0040  test_loss=205.0136  λ_max=4.9558\n",
      "[Muon | lr=0.1] Epoch 2829/4000: train_loss=0.0044  test_loss=205.0631  λ_max=4.7946\n",
      "[Muon | lr=0.1] Epoch 2830/4000: train_loss=0.0036  test_loss=205.1015  λ_max=4.6997\n",
      "[Muon | lr=0.1] Epoch 2831/4000: train_loss=0.0045  test_loss=205.4050  λ_max=4.6622\n",
      "[Muon | lr=0.1] Iter 45300: loss=0.0031\n",
      "[Muon | lr=0.1] Epoch 2832/4000: train_loss=0.0044  test_loss=205.0315  λ_max=5.2054\n",
      "[Muon | lr=0.1] Epoch 2833/4000: train_loss=0.0048  test_loss=204.7261  λ_max=4.1988\n",
      "[Muon | lr=0.1] Epoch 2834/4000: train_loss=0.0035  test_loss=205.0404  λ_max=4.7965\n",
      "[Muon | lr=0.1] Epoch 2835/4000: train_loss=0.0037  test_loss=204.9743  λ_max=4.8670\n",
      "[Muon | lr=0.1] Epoch 2836/4000: train_loss=0.0055  test_loss=204.9412  λ_max=4.9208\n",
      "[Muon | lr=0.1] Epoch 2837/4000: train_loss=0.0047  test_loss=204.9320  λ_max=4.6107\n",
      "[Muon | lr=0.1] Iter 45400: loss=0.0030\n",
      "[Muon | lr=0.1] Epoch 2838/4000: train_loss=0.0051  test_loss=204.7828  λ_max=4.5035\n",
      "[Muon | lr=0.1] Epoch 2839/4000: train_loss=0.0052  test_loss=205.1671  λ_max=4.4205\n",
      "[Muon | lr=0.1] Epoch 2840/4000: train_loss=0.0056  test_loss=205.4588  λ_max=5.1803\n",
      "[Muon | lr=0.1] Epoch 2841/4000: train_loss=0.0039  test_loss=205.5261  λ_max=4.1525\n",
      "[Muon | lr=0.1] Epoch 2842/4000: train_loss=0.0032  test_loss=205.6541  λ_max=4.6478\n",
      "[Muon | lr=0.1] Epoch 2843/4000: train_loss=0.0058  test_loss=205.6624  λ_max=4.7575\n",
      "[Muon | lr=0.1] Iter 45500: loss=0.0020\n",
      "[Muon | lr=0.1] Epoch 2844/4000: train_loss=0.0038  test_loss=205.7417  λ_max=5.0167\n",
      "[Muon | lr=0.1] Epoch 2845/4000: train_loss=0.0033  test_loss=205.8959  λ_max=5.0324\n",
      "[Muon | lr=0.1] Epoch 2846/4000: train_loss=0.0044  test_loss=205.8643  λ_max=4.2432\n",
      "[Muon | lr=0.1] Epoch 2847/4000: train_loss=0.0036  test_loss=206.0012  λ_max=4.3283\n",
      "[Muon | lr=0.1] Epoch 2848/4000: train_loss=0.0047  test_loss=205.7830  λ_max=4.5534\n",
      "[Muon | lr=0.1] Epoch 2849/4000: train_loss=0.0039  test_loss=205.8717  λ_max=4.9000\n",
      "[Muon | lr=0.1] Iter 45600: loss=0.0024\n",
      "[Muon | lr=0.1] Epoch 2850/4000: train_loss=0.0042  test_loss=205.8544  λ_max=4.3525\n",
      "[Muon | lr=0.1] Epoch 2851/4000: train_loss=0.0050  test_loss=205.6591  λ_max=4.4929\n",
      "[Muon | lr=0.1] Epoch 2852/4000: train_loss=0.0037  test_loss=205.5301  λ_max=4.8865\n",
      "[Muon | lr=0.1] Epoch 2853/4000: train_loss=0.0043  test_loss=205.3391  λ_max=5.1604\n",
      "[Muon | lr=0.1] Epoch 2854/4000: train_loss=0.0038  test_loss=205.1119  λ_max=4.4904\n",
      "[Muon | lr=0.1] Epoch 2855/4000: train_loss=0.0044  test_loss=205.1305  λ_max=4.5204\n",
      "[Muon | lr=0.1] Epoch 2856/4000: train_loss=0.0047  test_loss=205.0868  λ_max=5.1908\n",
      "[Muon | lr=0.1] Iter 45700: loss=0.0023\n",
      "[Muon | lr=0.1] Epoch 2857/4000: train_loss=0.0044  test_loss=205.1374  λ_max=4.9429\n",
      "[Muon | lr=0.1] Epoch 2858/4000: train_loss=0.0045  test_loss=205.2463  λ_max=5.8530\n",
      "[Muon | lr=0.1] Epoch 2859/4000: train_loss=0.0039  test_loss=205.1494  λ_max=4.6305\n",
      "[Muon | lr=0.1] Epoch 2860/4000: train_loss=0.0049  test_loss=205.0737  λ_max=4.5947\n",
      "[Muon | lr=0.1] Epoch 2861/4000: train_loss=0.0034  test_loss=205.1170  λ_max=5.1151\n",
      "[Muon | lr=0.1] Epoch 2862/4000: train_loss=0.0037  test_loss=205.3015  λ_max=4.4330\n",
      "[Muon | lr=0.1] Iter 45800: loss=0.0042\n",
      "[Muon | lr=0.1] Epoch 2863/4000: train_loss=0.0048  test_loss=205.4661  λ_max=4.8169\n",
      "[Muon | lr=0.1] Epoch 2864/4000: train_loss=0.0034  test_loss=205.6537  λ_max=4.9428\n",
      "[Muon | lr=0.1] Epoch 2865/4000: train_loss=0.0034  test_loss=205.4572  λ_max=4.7226\n",
      "[Muon | lr=0.1] Epoch 2866/4000: train_loss=0.0047  test_loss=205.5841  λ_max=4.6726\n",
      "[Muon | lr=0.1] Epoch 2867/4000: train_loss=0.0049  test_loss=205.7068  λ_max=4.6654\n",
      "[Muon | lr=0.1] Epoch 2868/4000: train_loss=0.0043  test_loss=205.7173  λ_max=4.4289\n",
      "[Muon | lr=0.1] Iter 45900: loss=0.0029\n",
      "[Muon | lr=0.1] Epoch 2869/4000: train_loss=0.0042  test_loss=206.0588  λ_max=4.7256\n",
      "[Muon | lr=0.1] Epoch 2870/4000: train_loss=0.0045  test_loss=206.2411  λ_max=4.3204\n",
      "[Muon | lr=0.1] Epoch 2871/4000: train_loss=0.0052  test_loss=206.2845  λ_max=4.6996\n",
      "[Muon | lr=0.1] Epoch 2872/4000: train_loss=0.0044  test_loss=206.3013  λ_max=4.8589\n",
      "[Muon | lr=0.1] Epoch 2873/4000: train_loss=0.0033  test_loss=206.4121  λ_max=4.7145\n",
      "[Muon | lr=0.1] Epoch 2874/4000: train_loss=0.0040  test_loss=206.5351  λ_max=4.8657\n",
      "[Muon | lr=0.1] Iter 46000: loss=0.0026\n",
      "[Muon | lr=0.1] Epoch 2875/4000: train_loss=0.0045  test_loss=206.7789  λ_max=5.7935\n",
      "[Muon | lr=0.1] Epoch 2876/4000: train_loss=0.0041  test_loss=206.8984  λ_max=5.0554\n",
      "[Muon | lr=0.1] Epoch 2877/4000: train_loss=0.0040  test_loss=206.8781  λ_max=4.5013\n",
      "[Muon | lr=0.1] Epoch 2878/4000: train_loss=0.0045  test_loss=206.8413  λ_max=4.6243\n",
      "[Muon | lr=0.1] Epoch 2879/4000: train_loss=0.0064  test_loss=207.1384  λ_max=4.6775\n",
      "[Muon | lr=0.1] Epoch 2880/4000: train_loss=0.0039  test_loss=207.0406  λ_max=5.0262\n",
      "[Muon | lr=0.1] Epoch 2881/4000: train_loss=0.0044  test_loss=206.9834  λ_max=5.0077\n",
      "[Muon | lr=0.1] Iter 46100: loss=0.0025\n",
      "[Muon | lr=0.1] Epoch 2882/4000: train_loss=0.0047  test_loss=207.0160  λ_max=4.1988\n",
      "[Muon | lr=0.1] Epoch 2883/4000: train_loss=0.0038  test_loss=207.4145  λ_max=4.7608\n",
      "[Muon | lr=0.1] Epoch 2884/4000: train_loss=0.0037  test_loss=207.5120  λ_max=5.2548\n",
      "[Muon | lr=0.1] Epoch 2885/4000: train_loss=0.0050  test_loss=207.4432  λ_max=5.8341\n",
      "[Muon | lr=0.1] Epoch 2886/4000: train_loss=0.0034  test_loss=207.5424  λ_max=4.7030\n",
      "[Muon | lr=0.1] Epoch 2887/4000: train_loss=0.0041  test_loss=207.8800  λ_max=4.7462\n",
      "[Muon | lr=0.1] Iter 46200: loss=0.0058\n",
      "[Muon | lr=0.1] Epoch 2888/4000: train_loss=0.0042  test_loss=208.0010  λ_max=4.8176\n",
      "[Muon | lr=0.1] Epoch 2889/4000: train_loss=0.0034  test_loss=208.0218  λ_max=4.5618\n",
      "[Muon | lr=0.1] Epoch 2890/4000: train_loss=0.0049  test_loss=208.2085  λ_max=4.6435\n",
      "[Muon | lr=0.1] Epoch 2891/4000: train_loss=0.0043  test_loss=208.3712  λ_max=4.9725\n",
      "[Muon | lr=0.1] Epoch 2892/4000: train_loss=0.0038  test_loss=208.3551  λ_max=4.3987\n",
      "[Muon | lr=0.1] Epoch 2893/4000: train_loss=0.0034  test_loss=208.3192  λ_max=5.3945\n",
      "[Muon | lr=0.1] Iter 46300: loss=0.0047\n",
      "[Muon | lr=0.1] Epoch 2894/4000: train_loss=0.0036  test_loss=208.1446  λ_max=4.6702\n",
      "[Muon | lr=0.1] Epoch 2895/4000: train_loss=0.0035  test_loss=208.1143  λ_max=5.1081\n",
      "[Muon | lr=0.1] Epoch 2896/4000: train_loss=0.0036  test_loss=208.2699  λ_max=4.8393\n",
      "[Muon | lr=0.1] Epoch 2897/4000: train_loss=0.0044  test_loss=208.3925  λ_max=5.1372\n",
      "[Muon | lr=0.1] Epoch 2898/4000: train_loss=0.0056  test_loss=208.4918  λ_max=4.8295\n",
      "[Muon | lr=0.1] Epoch 2899/4000: train_loss=0.0038  test_loss=208.7612  λ_max=4.7295\n",
      "[Muon | lr=0.1] Iter 46400: loss=0.0129\n",
      "[Muon | lr=0.1] Epoch 2900/4000: train_loss=0.0046  test_loss=208.7964  λ_max=4.7764\n",
      "[Muon | lr=0.1] Epoch 2901/4000: train_loss=0.0034  test_loss=208.9268  λ_max=5.2051\n",
      "[Muon | lr=0.1] Epoch 2902/4000: train_loss=0.0057  test_loss=209.2732  λ_max=4.9904\n",
      "[Muon | lr=0.1] Epoch 2903/4000: train_loss=0.0045  test_loss=209.4078  λ_max=4.9040\n",
      "[Muon | lr=0.1] Epoch 2904/4000: train_loss=0.0040  test_loss=209.2506  λ_max=4.7971\n",
      "[Muon | lr=0.1] Epoch 2905/4000: train_loss=0.0031  test_loss=209.1531  λ_max=4.5834\n",
      "[Muon | lr=0.1] Epoch 2906/4000: train_loss=0.0036  test_loss=209.3247  λ_max=4.6221\n",
      "[Muon | lr=0.1] Iter 46500: loss=0.0030\n",
      "[Muon | lr=0.1] Epoch 2907/4000: train_loss=0.0052  test_loss=209.4860  λ_max=4.8296\n",
      "[Muon | lr=0.1] Epoch 2908/4000: train_loss=0.0040  test_loss=209.7519  λ_max=4.4295\n",
      "[Muon | lr=0.1] Epoch 2909/4000: train_loss=0.0044  test_loss=209.7818  λ_max=4.4546\n",
      "[Muon | lr=0.1] Epoch 2910/4000: train_loss=0.0041  test_loss=210.1462  λ_max=4.8721\n",
      "[Muon | lr=0.1] Epoch 2911/4000: train_loss=0.0039  test_loss=210.1862  λ_max=4.4376\n",
      "[Muon | lr=0.1] Epoch 2912/4000: train_loss=0.0046  test_loss=210.1420  λ_max=4.7166\n",
      "[Muon | lr=0.1] Iter 46600: loss=0.0018\n",
      "[Muon | lr=0.1] Epoch 2913/4000: train_loss=0.0031  test_loss=210.1398  λ_max=4.6899\n",
      "[Muon | lr=0.1] Epoch 2914/4000: train_loss=0.0042  test_loss=210.2349  λ_max=4.8912\n",
      "[Muon | lr=0.1] Epoch 2915/4000: train_loss=0.0049  test_loss=210.5209  λ_max=5.1364\n",
      "[Muon | lr=0.1] Epoch 2916/4000: train_loss=0.0048  test_loss=210.7371  λ_max=4.4974\n",
      "[Muon | lr=0.1] Epoch 2917/4000: train_loss=0.0043  test_loss=211.0024  λ_max=4.9650\n",
      "[Muon | lr=0.1] Epoch 2918/4000: train_loss=0.0041  test_loss=211.1759  λ_max=5.0404\n",
      "[Muon | lr=0.1] Iter 46700: loss=0.0097\n",
      "[Muon | lr=0.1] Epoch 2919/4000: train_loss=0.0042  test_loss=211.1178  λ_max=4.8741\n",
      "[Muon | lr=0.1] Epoch 2920/4000: train_loss=0.0042  test_loss=211.2755  λ_max=4.5702\n",
      "[Muon | lr=0.1] Epoch 2921/4000: train_loss=0.0039  test_loss=211.4441  λ_max=4.7972\n",
      "[Muon | lr=0.1] Epoch 2922/4000: train_loss=0.0034  test_loss=211.4401  λ_max=5.1674\n",
      "[Muon | lr=0.1] Epoch 2923/4000: train_loss=0.0042  test_loss=211.6790  λ_max=4.7944\n",
      "[Muon | lr=0.1] Epoch 2924/4000: train_loss=0.0035  test_loss=211.8735  λ_max=4.9644\n",
      "[Muon | lr=0.1] Iter 46800: loss=0.0134\n",
      "[Muon | lr=0.1] Epoch 2925/4000: train_loss=0.0048  test_loss=211.9586  λ_max=4.6928\n",
      "[Muon | lr=0.1] Epoch 2926/4000: train_loss=0.0051  test_loss=212.0589  λ_max=4.8279\n",
      "[Muon | lr=0.1] Epoch 2927/4000: train_loss=0.0046  test_loss=212.0826  λ_max=4.8932\n",
      "[Muon | lr=0.1] Epoch 2928/4000: train_loss=0.0040  test_loss=212.2338  λ_max=4.9207\n",
      "[Muon | lr=0.1] Epoch 2929/4000: train_loss=0.0043  test_loss=212.3440  λ_max=4.4973\n",
      "[Muon | lr=0.1] Epoch 2930/4000: train_loss=0.0042  test_loss=211.9338  λ_max=5.0125\n",
      "[Muon | lr=0.1] Epoch 2931/4000: train_loss=0.0033  test_loss=211.8256  λ_max=5.0705\n",
      "[Muon | lr=0.1] Iter 46900: loss=0.0061\n",
      "[Muon | lr=0.1] Epoch 2932/4000: train_loss=0.0035  test_loss=211.9798  λ_max=5.4484\n",
      "[Muon | lr=0.1] Epoch 2933/4000: train_loss=0.0041  test_loss=212.2701  λ_max=4.3479\n",
      "[Muon | lr=0.1] Epoch 2934/4000: train_loss=0.0042  test_loss=212.4119  λ_max=4.7585\n",
      "[Muon | lr=0.1] Epoch 2935/4000: train_loss=0.0058  test_loss=212.3802  λ_max=4.7448\n",
      "[Muon | lr=0.1] Epoch 2936/4000: train_loss=0.0046  test_loss=212.6661  λ_max=4.9646\n",
      "[Muon | lr=0.1] Epoch 2937/4000: train_loss=0.0038  test_loss=212.5905  λ_max=4.7062\n",
      "[Muon | lr=0.1] Iter 47000: loss=0.0026\n",
      "[Muon | lr=0.1] Epoch 2938/4000: train_loss=0.0039  test_loss=212.4569  λ_max=4.9074\n",
      "[Muon | lr=0.1] Epoch 2939/4000: train_loss=0.0042  test_loss=212.4326  λ_max=4.6067\n",
      "[Muon | lr=0.1] Epoch 2940/4000: train_loss=0.0034  test_loss=212.6175  λ_max=4.7886\n",
      "[Muon | lr=0.1] Epoch 2941/4000: train_loss=0.0040  test_loss=212.7855  λ_max=4.8031\n",
      "[Muon | lr=0.1] Epoch 2942/4000: train_loss=0.0039  test_loss=212.9940  λ_max=4.5163\n",
      "[Muon | lr=0.1] Epoch 2943/4000: train_loss=0.0047  test_loss=213.3415  λ_max=4.7351\n",
      "[Muon | lr=0.1] Iter 47100: loss=0.0048\n",
      "[Muon | lr=0.1] Epoch 2944/4000: train_loss=0.0036  test_loss=213.3600  λ_max=4.8961\n",
      "[Muon | lr=0.1] Epoch 2945/4000: train_loss=0.0046  test_loss=213.5681  λ_max=4.7521\n",
      "[Muon | lr=0.1] Epoch 2946/4000: train_loss=0.0039  test_loss=213.7451  λ_max=4.9613\n",
      "[Muon | lr=0.1] Epoch 2947/4000: train_loss=0.0039  test_loss=213.7805  λ_max=4.8865\n",
      "[Muon | lr=0.1] Epoch 2948/4000: train_loss=0.0035  test_loss=214.1169  λ_max=4.8815\n",
      "[Muon | lr=0.1] Epoch 2949/4000: train_loss=0.0049  test_loss=214.3452  λ_max=4.6771\n",
      "[Muon | lr=0.1] Iter 47200: loss=0.0054\n",
      "[Muon | lr=0.1] Epoch 2950/4000: train_loss=0.0045  test_loss=214.4575  λ_max=5.1199\n",
      "[Muon | lr=0.1] Epoch 2951/4000: train_loss=0.0045  test_loss=214.6828  λ_max=4.7031\n",
      "[Muon | lr=0.1] Epoch 2952/4000: train_loss=0.0047  test_loss=214.6700  λ_max=4.9879\n",
      "[Muon | lr=0.1] Epoch 2953/4000: train_loss=0.0040  test_loss=214.5014  λ_max=5.0810\n",
      "[Muon | lr=0.1] Epoch 2954/4000: train_loss=0.0044  test_loss=214.5103  λ_max=4.9903\n",
      "[Muon | lr=0.1] Epoch 2955/4000: train_loss=0.0050  test_loss=214.8171  λ_max=4.9100\n",
      "[Muon | lr=0.1] Epoch 2956/4000: train_loss=0.0049  test_loss=215.1910  λ_max=4.6641\n",
      "[Muon | lr=0.1] Iter 47300: loss=0.0051\n",
      "[Muon | lr=0.1] Epoch 2957/4000: train_loss=0.0052  test_loss=215.3164  λ_max=4.7851\n",
      "[Muon | lr=0.1] Epoch 2958/4000: train_loss=0.0042  test_loss=215.3114  λ_max=5.5569\n",
      "[Muon | lr=0.1] Epoch 2959/4000: train_loss=0.0058  test_loss=215.3595  λ_max=5.0311\n",
      "[Muon | lr=0.1] Epoch 2960/4000: train_loss=0.0046  test_loss=215.7607  λ_max=4.6855\n",
      "[Muon | lr=0.1] Epoch 2961/4000: train_loss=0.0041  test_loss=215.7341  λ_max=4.5143\n",
      "[Muon | lr=0.1] Epoch 2962/4000: train_loss=0.0061  test_loss=215.5473  λ_max=4.7318\n",
      "[Muon | lr=0.1] Iter 47400: loss=0.0030\n",
      "[Muon | lr=0.1] Epoch 2963/4000: train_loss=0.0046  test_loss=215.4827  λ_max=4.6523\n",
      "[Muon | lr=0.1] Epoch 2964/4000: train_loss=0.0045  test_loss=215.4695  λ_max=4.3056\n",
      "[Muon | lr=0.1] Epoch 2965/4000: train_loss=0.0044  test_loss=215.6757  λ_max=4.6388\n",
      "[Muon | lr=0.1] Epoch 2966/4000: train_loss=0.0045  test_loss=215.7489  λ_max=4.8273\n",
      "[Muon | lr=0.1] Epoch 2967/4000: train_loss=0.0048  test_loss=215.8474  λ_max=4.4541\n",
      "[Muon | lr=0.1] Epoch 2968/4000: train_loss=0.0051  test_loss=215.7766  λ_max=4.5918\n",
      "[Muon | lr=0.1] Iter 47500: loss=0.0027\n",
      "[Muon | lr=0.1] Epoch 2969/4000: train_loss=0.0043  test_loss=215.8106  λ_max=4.9692\n",
      "[Muon | lr=0.1] Epoch 2970/4000: train_loss=0.0041  test_loss=215.6033  λ_max=5.1517\n",
      "[Muon | lr=0.1] Epoch 2971/4000: train_loss=0.0036  test_loss=215.6332  λ_max=5.0824\n",
      "[Muon | lr=0.1] Epoch 2972/4000: train_loss=0.0048  test_loss=215.7203  λ_max=4.6807\n",
      "[Muon | lr=0.1] Epoch 2973/4000: train_loss=0.0053  test_loss=215.4131  λ_max=4.5702\n",
      "[Muon | lr=0.1] Epoch 2974/4000: train_loss=0.0035  test_loss=215.5886  λ_max=4.7703\n",
      "[Muon | lr=0.1] Iter 47600: loss=0.0045\n",
      "[Muon | lr=0.1] Epoch 2975/4000: train_loss=0.0041  test_loss=215.7395  λ_max=4.9963\n",
      "[Muon | lr=0.1] Epoch 2976/4000: train_loss=0.0037  test_loss=215.9147  λ_max=4.9819\n",
      "[Muon | lr=0.1] Epoch 2977/4000: train_loss=0.0048  test_loss=216.0015  λ_max=5.0110\n",
      "[Muon | lr=0.1] Epoch 2978/4000: train_loss=0.0033  test_loss=216.2290  λ_max=4.9331\n",
      "[Muon | lr=0.1] Epoch 2979/4000: train_loss=0.0040  test_loss=216.5145  λ_max=4.7301\n",
      "[Muon | lr=0.1] Epoch 2980/4000: train_loss=0.0048  test_loss=216.5862  λ_max=5.2137\n",
      "[Muon | lr=0.1] Epoch 2981/4000: train_loss=0.0040  test_loss=216.5886  λ_max=4.4641\n",
      "[Muon | lr=0.1] Iter 47700: loss=0.0019\n",
      "[Muon | lr=0.1] Epoch 2982/4000: train_loss=0.0031  test_loss=216.6498  λ_max=5.0028\n",
      "[Muon | lr=0.1] Epoch 2983/4000: train_loss=0.0038  test_loss=216.7113  λ_max=4.5154\n",
      "[Muon | lr=0.1] Epoch 2984/4000: train_loss=0.0059  test_loss=216.7345  λ_max=4.7540\n",
      "[Muon | lr=0.1] Epoch 2985/4000: train_loss=0.0047  test_loss=216.9344  λ_max=4.9355\n",
      "[Muon | lr=0.1] Epoch 2986/4000: train_loss=0.0036  test_loss=217.4845  λ_max=5.1311\n",
      "[Muon | lr=0.1] Epoch 2987/4000: train_loss=0.0039  test_loss=217.7423  λ_max=4.6049\n",
      "[Muon | lr=0.1] Iter 47800: loss=0.0045\n",
      "[Muon | lr=0.1] Epoch 2988/4000: train_loss=0.0031  test_loss=217.6604  λ_max=4.2356\n",
      "[Muon | lr=0.1] Epoch 2989/4000: train_loss=0.0047  test_loss=217.6853  λ_max=4.6386\n",
      "[Muon | lr=0.1] Epoch 2990/4000: train_loss=0.0031  test_loss=217.9723  λ_max=6.0233\n",
      "[Muon | lr=0.1] Epoch 2991/4000: train_loss=0.0042  test_loss=218.1581  λ_max=4.5278\n",
      "[Muon | lr=0.1] Epoch 2992/4000: train_loss=0.0042  test_loss=218.2852  λ_max=5.2771\n",
      "[Muon | lr=0.1] Epoch 2993/4000: train_loss=0.0045  test_loss=218.5152  λ_max=5.3193\n",
      "[Muon | lr=0.1] Iter 47900: loss=0.0035\n",
      "[Muon | lr=0.1] Epoch 2994/4000: train_loss=0.0039  test_loss=218.4678  λ_max=4.8325\n",
      "[Muon | lr=0.1] Epoch 2995/4000: train_loss=0.0036  test_loss=218.7642  λ_max=5.7058\n",
      "[Muon | lr=0.1] Epoch 2996/4000: train_loss=0.0042  test_loss=218.8769  λ_max=5.6030\n",
      "[Muon | lr=0.1] Epoch 2997/4000: train_loss=0.0034  test_loss=218.9832  λ_max=4.6818\n",
      "[Muon | lr=0.1] Epoch 2998/4000: train_loss=0.0048  test_loss=219.2239  λ_max=5.0642\n",
      "[Muon | lr=0.1] Epoch 2999/4000: train_loss=0.0043  test_loss=219.3061  λ_max=5.5932\n",
      "[Muon | lr=0.1] Iter 48000: loss=0.0045\n",
      "[Muon | lr=0.1] Epoch 3000/4000: train_loss=0.0039  test_loss=219.5668  λ_max=4.7081\n",
      "[Muon | lr=0.1] Epoch 3001/4000: train_loss=0.0051  test_loss=219.7926  λ_max=4.6678\n",
      "[Muon | lr=0.1] Epoch 3002/4000: train_loss=0.0041  test_loss=219.8153  λ_max=5.4905\n",
      "[Muon | lr=0.1] Epoch 3003/4000: train_loss=0.0037  test_loss=219.8867  λ_max=4.5074\n",
      "[Muon | lr=0.1] Epoch 3004/4000: train_loss=0.0037  test_loss=219.8901  λ_max=4.8826\n",
      "[Muon | lr=0.1] Epoch 3005/4000: train_loss=0.0034  test_loss=219.9153  λ_max=5.1001\n",
      "[Muon | lr=0.1] Epoch 3006/4000: train_loss=0.0044  test_loss=220.1360  λ_max=5.6992\n",
      "[Muon | lr=0.1] Iter 48100: loss=0.0007\n",
      "[Muon | lr=0.1] Epoch 3007/4000: train_loss=0.0045  test_loss=220.0740  λ_max=4.8992\n",
      "[Muon | lr=0.1] Epoch 3008/4000: train_loss=0.0040  test_loss=220.2946  λ_max=4.8821\n",
      "[Muon | lr=0.1] Epoch 3009/4000: train_loss=0.0038  test_loss=220.6900  λ_max=5.0137\n",
      "[Muon | lr=0.1] Epoch 3010/4000: train_loss=0.0034  test_loss=220.6096  λ_max=4.8751\n",
      "[Muon | lr=0.1] Epoch 3011/4000: train_loss=0.0038  test_loss=220.4915  λ_max=4.7110\n",
      "[Muon | lr=0.1] Epoch 3012/4000: train_loss=0.0040  test_loss=220.7841  λ_max=4.9648\n",
      "[Muon | lr=0.1] Iter 48200: loss=0.0050\n",
      "[Muon | lr=0.1] Epoch 3013/4000: train_loss=0.0038  test_loss=221.0338  λ_max=5.1252\n",
      "[Muon | lr=0.1] Epoch 3014/4000: train_loss=0.0034  test_loss=221.1108  λ_max=5.4489\n",
      "[Muon | lr=0.1] Epoch 3015/4000: train_loss=0.0046  test_loss=221.1127  λ_max=4.7775\n",
      "[Muon | lr=0.1] Epoch 3016/4000: train_loss=0.0049  test_loss=221.0037  λ_max=4.9452\n",
      "[Muon | lr=0.1] Epoch 3017/4000: train_loss=0.0044  test_loss=221.0622  λ_max=5.2009\n",
      "[Muon | lr=0.1] Epoch 3018/4000: train_loss=0.0039  test_loss=221.4486  λ_max=5.2220\n",
      "[Muon | lr=0.1] Iter 48300: loss=0.0023\n",
      "[Muon | lr=0.1] Epoch 3019/4000: train_loss=0.0036  test_loss=221.1190  λ_max=5.0911\n",
      "[Muon | lr=0.1] Epoch 3020/4000: train_loss=0.0032  test_loss=221.2009  λ_max=4.6478\n",
      "[Muon | lr=0.1] Epoch 3021/4000: train_loss=0.0049  test_loss=221.6127  λ_max=6.1566\n",
      "[Muon | lr=0.1] Epoch 3022/4000: train_loss=0.0040  test_loss=221.6454  λ_max=4.9988\n",
      "[Muon | lr=0.1] Epoch 3023/4000: train_loss=0.0030  test_loss=221.8137  λ_max=4.7839\n",
      "[Muon | lr=0.1] Epoch 3024/4000: train_loss=0.0044  test_loss=221.9697  λ_max=4.7158\n",
      "[Muon | lr=0.1] Iter 48400: loss=0.0139\n",
      "[Muon | lr=0.1] Epoch 3025/4000: train_loss=0.0035  test_loss=221.8857  λ_max=5.1328\n",
      "[Muon | lr=0.1] Epoch 3026/4000: train_loss=0.0049  test_loss=221.8002  λ_max=4.6013\n",
      "[Muon | lr=0.1] Epoch 3027/4000: train_loss=0.0040  test_loss=221.5758  λ_max=4.6459\n",
      "[Muon | lr=0.1] Epoch 3028/4000: train_loss=0.0046  test_loss=221.4324  λ_max=4.5068\n",
      "[Muon | lr=0.1] Epoch 3029/4000: train_loss=0.0042  test_loss=221.6889  λ_max=4.8028\n",
      "[Muon | lr=0.1] Epoch 3030/4000: train_loss=0.0059  test_loss=221.9519  λ_max=4.7250\n",
      "[Muon | lr=0.1] Epoch 3031/4000: train_loss=0.0043  test_loss=221.8558  λ_max=4.6253\n",
      "[Muon | lr=0.1] Iter 48500: loss=0.0040\n",
      "[Muon | lr=0.1] Epoch 3032/4000: train_loss=0.0048  test_loss=222.0446  λ_max=5.7369\n",
      "[Muon | lr=0.1] Epoch 3033/4000: train_loss=0.0040  test_loss=222.3646  λ_max=4.7178\n",
      "[Muon | lr=0.1] Epoch 3034/4000: train_loss=0.0029  test_loss=222.2918  λ_max=5.1740\n",
      "[Muon | lr=0.1] Epoch 3035/4000: train_loss=0.0055  test_loss=222.2518  λ_max=4.8274\n",
      "[Muon | lr=0.1] Epoch 3036/4000: train_loss=0.0050  test_loss=221.9854  λ_max=5.4827\n",
      "[Muon | lr=0.1] Epoch 3037/4000: train_loss=0.0045  test_loss=221.7720  λ_max=4.6501\n",
      "[Muon | lr=0.1] Iter 48600: loss=0.0092\n",
      "[Muon | lr=0.1] Epoch 3038/4000: train_loss=0.0046  test_loss=222.1783  λ_max=4.8330\n",
      "[Muon | lr=0.1] Epoch 3039/4000: train_loss=0.0047  test_loss=222.4839  λ_max=5.4742\n",
      "[Muon | lr=0.1] Epoch 3040/4000: train_loss=0.0050  test_loss=222.5273  λ_max=4.7588\n",
      "[Muon | lr=0.1] Epoch 3041/4000: train_loss=0.0043  test_loss=222.5461  λ_max=4.8490\n",
      "[Muon | lr=0.1] Epoch 3042/4000: train_loss=0.0040  test_loss=222.5954  λ_max=4.8186\n",
      "[Muon | lr=0.1] Epoch 3043/4000: train_loss=0.0043  test_loss=222.6327  λ_max=5.7233\n",
      "[Muon | lr=0.1] Iter 48700: loss=0.0064\n",
      "[Muon | lr=0.1] Epoch 3044/4000: train_loss=0.0045  test_loss=222.6062  λ_max=4.8051\n",
      "[Muon | lr=0.1] Epoch 3045/4000: train_loss=0.0039  test_loss=222.5672  λ_max=4.9438\n",
      "[Muon | lr=0.1] Epoch 3046/4000: train_loss=0.0044  test_loss=222.2932  λ_max=5.1673\n",
      "[Muon | lr=0.1] Epoch 3047/4000: train_loss=0.0039  test_loss=222.3092  λ_max=4.6780\n",
      "[Muon | lr=0.1] Epoch 3048/4000: train_loss=0.0042  test_loss=222.4641  λ_max=4.6691\n",
      "[Muon | lr=0.1] Epoch 3049/4000: train_loss=0.0045  test_loss=222.7039  λ_max=5.1953\n",
      "[Muon | lr=0.1] Iter 48800: loss=0.0012\n",
      "[Muon | lr=0.1] Epoch 3050/4000: train_loss=0.0043  test_loss=222.7531  λ_max=4.5117\n",
      "[Muon | lr=0.1] Epoch 3051/4000: train_loss=0.0042  test_loss=222.9415  λ_max=4.5485\n",
      "[Muon | lr=0.1] Epoch 3052/4000: train_loss=0.0043  test_loss=222.9278  λ_max=4.6080\n",
      "[Muon | lr=0.1] Epoch 3053/4000: train_loss=0.0041  test_loss=222.8668  λ_max=5.0467\n",
      "[Muon | lr=0.1] Epoch 3054/4000: train_loss=0.0040  test_loss=223.0728  λ_max=4.4339\n",
      "[Muon | lr=0.1] Epoch 3055/4000: train_loss=0.0046  test_loss=223.0664  λ_max=4.6459\n",
      "[Muon | lr=0.1] Epoch 3056/4000: train_loss=0.0052  test_loss=223.3706  λ_max=5.1915\n",
      "[Muon | lr=0.1] Iter 48900: loss=0.0007\n",
      "[Muon | lr=0.1] Epoch 3057/4000: train_loss=0.0049  test_loss=223.5015  λ_max=4.9536\n",
      "[Muon | lr=0.1] Epoch 3058/4000: train_loss=0.0038  test_loss=224.0133  λ_max=5.3042\n",
      "[Muon | lr=0.1] Epoch 3059/4000: train_loss=0.0040  test_loss=223.9735  λ_max=5.0833\n",
      "[Muon | lr=0.1] Epoch 3060/4000: train_loss=0.0051  test_loss=224.1820  λ_max=4.6068\n",
      "[Muon | lr=0.1] Epoch 3061/4000: train_loss=0.0048  test_loss=224.3390  λ_max=5.1457\n",
      "[Muon | lr=0.1] Epoch 3062/4000: train_loss=0.0040  test_loss=224.2347  λ_max=4.9672\n",
      "[Muon | lr=0.1] Iter 49000: loss=0.0001\n",
      "[Muon | lr=0.1] Epoch 3063/4000: train_loss=0.0032  test_loss=224.3649  λ_max=5.2710\n",
      "[Muon | lr=0.1] Epoch 3064/4000: train_loss=0.0046  test_loss=224.5541  λ_max=4.5746\n",
      "[Muon | lr=0.1] Epoch 3065/4000: train_loss=0.0056  test_loss=224.5147  λ_max=5.1787\n",
      "[Muon | lr=0.1] Epoch 3066/4000: train_loss=0.0049  test_loss=224.4399  λ_max=5.1487\n",
      "[Muon | lr=0.1] Epoch 3067/4000: train_loss=0.0038  test_loss=224.6259  λ_max=4.4999\n",
      "[Muon | lr=0.1] Epoch 3068/4000: train_loss=0.0050  test_loss=224.5819  λ_max=5.2473\n",
      "[Muon | lr=0.1] Iter 49100: loss=0.0082\n",
      "[Muon | lr=0.1] Epoch 3069/4000: train_loss=0.0051  test_loss=224.6226  λ_max=4.8083\n",
      "[Muon | lr=0.1] Epoch 3070/4000: train_loss=0.0047  test_loss=224.9199  λ_max=4.9482\n",
      "[Muon | lr=0.1] Epoch 3071/4000: train_loss=0.0043  test_loss=225.0888  λ_max=4.7261\n",
      "[Muon | lr=0.1] Epoch 3072/4000: train_loss=0.0042  test_loss=225.1490  λ_max=5.3094\n",
      "[Muon | lr=0.1] Epoch 3073/4000: train_loss=0.0040  test_loss=225.3126  λ_max=4.8249\n",
      "[Muon | lr=0.1] Epoch 3074/4000: train_loss=0.0042  test_loss=225.4900  λ_max=5.1419\n",
      "[Muon | lr=0.1] Iter 49200: loss=0.0103\n",
      "[Muon | lr=0.1] Epoch 3075/4000: train_loss=0.0058  test_loss=225.6379  λ_max=4.9801\n",
      "[Muon | lr=0.1] Epoch 3076/4000: train_loss=0.0039  test_loss=225.3126  λ_max=5.5899\n",
      "[Muon | lr=0.1] Epoch 3077/4000: train_loss=0.0037  test_loss=225.2821  λ_max=5.3219\n",
      "[Muon | lr=0.1] Epoch 3078/4000: train_loss=0.0034  test_loss=225.2932  λ_max=4.8216\n",
      "[Muon | lr=0.1] Epoch 3079/4000: train_loss=0.0046  test_loss=225.5626  λ_max=5.7040\n",
      "[Muon | lr=0.1] Epoch 3080/4000: train_loss=0.0046  test_loss=225.6533  λ_max=5.0050\n",
      "[Muon | lr=0.1] Epoch 3081/4000: train_loss=0.0045  test_loss=225.6337  λ_max=5.1982\n",
      "[Muon | lr=0.1] Iter 49300: loss=0.0016\n",
      "[Muon | lr=0.1] Epoch 3082/4000: train_loss=0.0042  test_loss=225.7467  λ_max=4.6210\n",
      "[Muon | lr=0.1] Epoch 3083/4000: train_loss=0.0036  test_loss=225.6667  λ_max=5.0032\n",
      "[Muon | lr=0.1] Epoch 3084/4000: train_loss=0.0037  test_loss=225.7261  λ_max=5.2181\n",
      "[Muon | lr=0.1] Epoch 3085/4000: train_loss=0.0045  test_loss=225.8607  λ_max=5.0633\n",
      "[Muon | lr=0.1] Epoch 3086/4000: train_loss=0.0039  test_loss=225.8922  λ_max=4.9593\n",
      "[Muon | lr=0.1] Epoch 3087/4000: train_loss=0.0040  test_loss=225.9781  λ_max=5.0635\n",
      "[Muon | lr=0.1] Iter 49400: loss=0.0035\n",
      "[Muon | lr=0.1] Epoch 3088/4000: train_loss=0.0038  test_loss=226.1798  λ_max=5.0198\n",
      "[Muon | lr=0.1] Epoch 3089/4000: train_loss=0.0043  test_loss=226.3722  λ_max=6.0282\n",
      "[Muon | lr=0.1] Epoch 3090/4000: train_loss=0.0041  test_loss=226.4028  λ_max=4.8647\n",
      "[Muon | lr=0.1] Epoch 3091/4000: train_loss=0.0047  test_loss=226.5127  λ_max=5.7785\n",
      "[Muon | lr=0.1] Epoch 3092/4000: train_loss=0.0045  test_loss=226.5096  λ_max=5.0309\n",
      "[Muon | lr=0.1] Epoch 3093/4000: train_loss=0.0051  test_loss=226.4206  λ_max=4.9502\n",
      "[Muon | lr=0.1] Iter 49500: loss=0.0061\n",
      "[Muon | lr=0.1] Epoch 3094/4000: train_loss=0.0041  test_loss=226.5266  λ_max=4.6436\n",
      "[Muon | lr=0.1] Epoch 3095/4000: train_loss=0.0044  test_loss=226.7800  λ_max=5.5952\n",
      "[Muon | lr=0.1] Epoch 3096/4000: train_loss=0.0039  test_loss=226.7994  λ_max=4.9627\n",
      "[Muon | lr=0.1] Epoch 3097/4000: train_loss=0.0045  test_loss=226.7491  λ_max=5.1463\n",
      "[Muon | lr=0.1] Epoch 3098/4000: train_loss=0.0049  test_loss=226.7815  λ_max=5.1961\n",
      "[Muon | lr=0.1] Epoch 3099/4000: train_loss=0.0046  test_loss=226.8846  λ_max=5.2329\n",
      "[Muon | lr=0.1] Iter 49600: loss=0.0115\n",
      "[Muon | lr=0.1] Epoch 3100/4000: train_loss=0.0047  test_loss=227.1500  λ_max=4.7382\n",
      "[Muon | lr=0.1] Epoch 3101/4000: train_loss=0.0042  test_loss=227.0172  λ_max=5.1071\n",
      "[Muon | lr=0.1] Epoch 3102/4000: train_loss=0.0049  test_loss=227.0747  λ_max=5.2033\n",
      "[Muon | lr=0.1] Epoch 3103/4000: train_loss=0.0044  test_loss=227.3356  λ_max=4.8177\n",
      "[Muon | lr=0.1] Epoch 3104/4000: train_loss=0.0049  test_loss=227.5942  λ_max=5.0262\n",
      "[Muon | lr=0.1] Epoch 3105/4000: train_loss=0.0034  test_loss=227.7635  λ_max=5.6968\n",
      "[Muon | lr=0.1] Epoch 3106/4000: train_loss=0.0041  test_loss=227.8630  λ_max=4.7717\n",
      "[Muon | lr=0.1] Iter 49700: loss=0.0035\n",
      "[Muon | lr=0.1] Epoch 3107/4000: train_loss=0.0035  test_loss=227.6634  λ_max=5.0231\n",
      "[Muon | lr=0.1] Epoch 3108/4000: train_loss=0.0055  test_loss=227.6629  λ_max=4.9212\n",
      "[Muon | lr=0.1] Epoch 3109/4000: train_loss=0.0039  test_loss=227.7216  λ_max=5.2977\n",
      "[Muon | lr=0.1] Epoch 3110/4000: train_loss=0.0051  test_loss=227.7563  λ_max=5.3502\n",
      "[Muon | lr=0.1] Epoch 3111/4000: train_loss=0.0042  test_loss=227.7038  λ_max=4.7107\n",
      "[Muon | lr=0.1] Epoch 3112/4000: train_loss=0.0038  test_loss=227.8181  λ_max=5.7734\n",
      "[Muon | lr=0.1] Iter 49800: loss=0.0041\n",
      "[Muon | lr=0.1] Epoch 3113/4000: train_loss=0.0046  test_loss=227.9445  λ_max=5.2071\n",
      "[Muon | lr=0.1] Epoch 3114/4000: train_loss=0.0053  test_loss=228.2042  λ_max=5.1247\n",
      "[Muon | lr=0.1] Epoch 3115/4000: train_loss=0.0041  test_loss=228.4045  λ_max=5.1666\n",
      "[Muon | lr=0.1] Epoch 3116/4000: train_loss=0.0040  test_loss=228.2151  λ_max=5.1206\n",
      "[Muon | lr=0.1] Epoch 3117/4000: train_loss=0.0037  test_loss=228.1157  λ_max=4.9591\n",
      "[Muon | lr=0.1] Epoch 3118/4000: train_loss=0.0045  test_loss=228.1107  λ_max=4.9857\n",
      "[Muon | lr=0.1] Iter 49900: loss=0.0059\n",
      "[Muon | lr=0.1] Epoch 3119/4000: train_loss=0.0039  test_loss=228.4367  λ_max=4.7332\n",
      "[Muon | lr=0.1] Epoch 3120/4000: train_loss=0.0045  test_loss=228.6405  λ_max=5.7786\n",
      "[Muon | lr=0.1] Epoch 3121/4000: train_loss=0.0029  test_loss=229.0070  λ_max=5.6458\n",
      "[Muon | lr=0.1] Epoch 3122/4000: train_loss=0.0047  test_loss=228.7107  λ_max=4.8702\n",
      "[Muon | lr=0.1] Epoch 3123/4000: train_loss=0.0037  test_loss=228.8403  λ_max=4.9982\n",
      "[Muon | lr=0.1] Epoch 3124/4000: train_loss=0.0046  test_loss=229.1634  λ_max=5.2326\n",
      "[Muon | lr=0.1] Iter 50000: loss=0.0126\n",
      "[Muon | lr=0.1] Epoch 3125/4000: train_loss=0.0043  test_loss=229.0895  λ_max=5.2453\n",
      "[Muon | lr=0.1] Epoch 3126/4000: train_loss=0.0036  test_loss=228.9841  λ_max=5.3951\n",
      "[Muon | lr=0.1] Epoch 3127/4000: train_loss=0.0042  test_loss=229.2261  λ_max=4.8392\n",
      "[Muon | lr=0.1] Epoch 3128/4000: train_loss=0.0038  test_loss=229.4013  λ_max=4.6270\n",
      "[Muon | lr=0.1] Epoch 3129/4000: train_loss=0.0034  test_loss=229.3979  λ_max=4.8080\n",
      "[Muon | lr=0.1] Epoch 3130/4000: train_loss=0.0040  test_loss=229.4600  λ_max=5.1517\n",
      "[Muon | lr=0.1] Epoch 3131/4000: train_loss=0.0047  test_loss=229.7757  λ_max=5.1124\n",
      "[Muon | lr=0.1] Iter 50100: loss=0.0027\n",
      "[Muon | lr=0.1] Epoch 3132/4000: train_loss=0.0032  test_loss=229.8636  λ_max=5.3933\n",
      "[Muon | lr=0.1] Epoch 3133/4000: train_loss=0.0043  test_loss=230.1810  λ_max=4.9346\n",
      "[Muon | lr=0.1] Epoch 3134/4000: train_loss=0.0043  test_loss=230.5219  λ_max=4.9722\n",
      "[Muon | lr=0.1] Epoch 3135/4000: train_loss=0.0040  test_loss=230.3564  λ_max=5.5820\n",
      "[Muon | lr=0.1] Epoch 3136/4000: train_loss=0.0039  test_loss=230.2554  λ_max=5.2262\n",
      "[Muon | lr=0.1] Epoch 3137/4000: train_loss=0.0042  test_loss=230.3002  λ_max=5.0152\n",
      "[Muon | lr=0.1] Iter 50200: loss=0.0022\n",
      "[Muon | lr=0.1] Epoch 3138/4000: train_loss=0.0036  test_loss=230.3645  λ_max=5.4609\n",
      "[Muon | lr=0.1] Epoch 3139/4000: train_loss=0.0047  test_loss=230.4266  λ_max=4.8046\n",
      "[Muon | lr=0.1] Epoch 3140/4000: train_loss=0.0055  test_loss=230.5171  λ_max=5.6764\n",
      "[Muon | lr=0.1] Epoch 3141/4000: train_loss=0.0047  test_loss=230.7899  λ_max=5.1876\n",
      "[Muon | lr=0.1] Epoch 3142/4000: train_loss=0.0050  test_loss=230.9086  λ_max=5.1705\n",
      "[Muon | lr=0.1] Epoch 3143/4000: train_loss=0.0037  test_loss=230.9506  λ_max=5.0427\n",
      "[Muon | lr=0.1] Iter 50300: loss=0.0051\n",
      "[Muon | lr=0.1] Epoch 3144/4000: train_loss=0.0029  test_loss=230.8958  λ_max=5.1116\n",
      "[Muon | lr=0.1] Epoch 3145/4000: train_loss=0.0049  test_loss=231.2428  λ_max=5.2492\n",
      "[Muon | lr=0.1] Epoch 3146/4000: train_loss=0.0048  test_loss=231.3260  λ_max=5.2318\n",
      "[Muon | lr=0.1] Epoch 3147/4000: train_loss=0.0050  test_loss=231.0105  λ_max=5.0378\n",
      "[Muon | lr=0.1] Epoch 3148/4000: train_loss=0.0044  test_loss=230.8806  λ_max=4.9026\n",
      "[Muon | lr=0.1] Epoch 3149/4000: train_loss=0.0045  test_loss=231.0927  λ_max=5.0783\n",
      "[Muon | lr=0.1] Iter 50400: loss=0.0023\n",
      "[Muon | lr=0.1] Epoch 3150/4000: train_loss=0.0036  test_loss=231.4734  λ_max=5.6109\n",
      "[Muon | lr=0.1] Epoch 3151/4000: train_loss=0.0041  test_loss=231.7745  λ_max=4.7450\n",
      "[Muon | lr=0.1] Epoch 3152/4000: train_loss=0.0051  test_loss=232.0568  λ_max=5.4536\n",
      "[Muon | lr=0.1] Epoch 3153/4000: train_loss=0.0047  test_loss=232.2949  λ_max=5.0843\n",
      "[Muon | lr=0.1] Epoch 3154/4000: train_loss=0.0042  test_loss=232.3982  λ_max=5.1505\n",
      "[Muon | lr=0.1] Epoch 3155/4000: train_loss=0.0035  test_loss=232.6377  λ_max=4.7845\n",
      "[Muon | lr=0.1] Epoch 3156/4000: train_loss=0.0045  test_loss=233.0284  λ_max=5.3901\n",
      "[Muon | lr=0.1] Iter 50500: loss=0.0017\n",
      "[Muon | lr=0.1] Epoch 3157/4000: train_loss=0.0028  test_loss=232.9533  λ_max=4.7871\n",
      "[Muon | lr=0.1] Epoch 3158/4000: train_loss=0.0038  test_loss=232.9214  λ_max=4.9120\n",
      "[Muon | lr=0.1] Epoch 3159/4000: train_loss=0.0047  test_loss=233.0487  λ_max=5.1515\n",
      "[Muon | lr=0.1] Epoch 3160/4000: train_loss=0.0043  test_loss=233.0580  λ_max=5.0944\n",
      "[Muon | lr=0.1] Epoch 3161/4000: train_loss=0.0048  test_loss=233.2130  λ_max=5.5902\n",
      "[Muon | lr=0.1] Epoch 3162/4000: train_loss=0.0051  test_loss=233.2290  λ_max=5.3326\n",
      "[Muon | lr=0.1] Iter 50600: loss=0.0029\n",
      "[Muon | lr=0.1] Epoch 3163/4000: train_loss=0.0038  test_loss=233.1838  λ_max=5.0572\n",
      "[Muon | lr=0.1] Epoch 3164/4000: train_loss=0.0034  test_loss=233.3048  λ_max=5.5648\n",
      "[Muon | lr=0.1] Epoch 3165/4000: train_loss=0.0039  test_loss=233.6257  λ_max=5.6635\n",
      "[Muon | lr=0.1] Epoch 3166/4000: train_loss=0.0048  test_loss=233.6900  λ_max=4.9087\n",
      "[Muon | lr=0.1] Epoch 3167/4000: train_loss=0.0047  test_loss=233.2674  λ_max=5.3144\n",
      "[Muon | lr=0.1] Epoch 3168/4000: train_loss=0.0035  test_loss=232.8894  λ_max=4.6714\n",
      "[Muon | lr=0.1] Iter 50700: loss=0.0057\n",
      "[Muon | lr=0.1] Epoch 3169/4000: train_loss=0.0053  test_loss=232.9391  λ_max=5.1044\n",
      "[Muon | lr=0.1] Epoch 3170/4000: train_loss=0.0038  test_loss=232.8196  λ_max=4.9972\n",
      "[Muon | lr=0.1] Epoch 3171/4000: train_loss=0.0040  test_loss=233.2371  λ_max=5.1912\n",
      "[Muon | lr=0.1] Epoch 3172/4000: train_loss=0.0042  test_loss=233.5607  λ_max=5.6696\n",
      "[Muon | lr=0.1] Epoch 3173/4000: train_loss=0.0035  test_loss=233.7035  λ_max=5.1940\n",
      "[Muon | lr=0.1] Epoch 3174/4000: train_loss=0.0043  test_loss=233.6206  λ_max=4.9842\n",
      "[Muon | lr=0.1] Iter 50800: loss=0.0004\n",
      "[Muon | lr=0.1] Epoch 3175/4000: train_loss=0.0037  test_loss=234.0054  λ_max=4.9080\n",
      "[Muon | lr=0.1] Epoch 3176/4000: train_loss=0.0042  test_loss=234.0707  λ_max=5.1459\n",
      "[Muon | lr=0.1] Epoch 3177/4000: train_loss=0.0034  test_loss=234.2229  λ_max=4.8512\n",
      "[Muon | lr=0.1] Epoch 3178/4000: train_loss=0.0058  test_loss=234.3979  λ_max=5.2082\n",
      "[Muon | lr=0.1] Epoch 3179/4000: train_loss=0.0045  test_loss=234.5003  λ_max=4.8055\n",
      "[Muon | lr=0.1] Epoch 3180/4000: train_loss=0.0036  test_loss=234.7213  λ_max=5.5959\n",
      "[Muon | lr=0.1] Epoch 3181/4000: train_loss=0.0040  test_loss=234.5928  λ_max=4.8784\n",
      "[Muon | lr=0.1] Iter 50900: loss=0.0011\n",
      "[Muon | lr=0.1] Epoch 3182/4000: train_loss=0.0046  test_loss=234.4648  λ_max=4.9602\n",
      "[Muon | lr=0.1] Epoch 3183/4000: train_loss=0.0051  test_loss=234.2854  λ_max=5.0337\n",
      "[Muon | lr=0.1] Epoch 3184/4000: train_loss=0.0034  test_loss=234.4682  λ_max=5.0494\n",
      "[Muon | lr=0.1] Epoch 3185/4000: train_loss=0.0051  test_loss=234.4512  λ_max=5.1436\n",
      "[Muon | lr=0.1] Epoch 3186/4000: train_loss=0.0041  test_loss=234.5407  λ_max=5.1962\n",
      "[Muon | lr=0.1] Epoch 3187/4000: train_loss=0.0042  test_loss=234.6531  λ_max=5.1911\n",
      "[Muon | lr=0.1] Iter 51000: loss=0.0023\n",
      "[Muon | lr=0.1] Epoch 3188/4000: train_loss=0.0037  test_loss=234.6545  λ_max=4.8887\n",
      "[Muon | lr=0.1] Epoch 3189/4000: train_loss=0.0030  test_loss=234.6558  λ_max=5.0603\n",
      "[Muon | lr=0.1] Epoch 3190/4000: train_loss=0.0041  test_loss=234.7477  λ_max=4.7675\n",
      "[Muon | lr=0.1] Epoch 3191/4000: train_loss=0.0043  test_loss=234.9213  λ_max=6.0070\n",
      "[Muon | lr=0.1] Epoch 3192/4000: train_loss=0.0035  test_loss=235.1279  λ_max=4.9343\n",
      "[Muon | lr=0.1] Epoch 3193/4000: train_loss=0.0038  test_loss=235.1510  λ_max=4.6771\n",
      "[Muon | lr=0.1] Iter 51100: loss=0.0094\n",
      "[Muon | lr=0.1] Epoch 3194/4000: train_loss=0.0055  test_loss=235.0800  λ_max=5.3544\n",
      "[Muon | lr=0.1] Epoch 3195/4000: train_loss=0.0039  test_loss=234.9942  λ_max=5.2442\n",
      "[Muon | lr=0.1] Epoch 3196/4000: train_loss=0.0045  test_loss=234.7861  λ_max=5.2253\n",
      "[Muon | lr=0.1] Epoch 3197/4000: train_loss=0.0035  test_loss=234.7161  λ_max=5.4966\n",
      "[Muon | lr=0.1] Epoch 3198/4000: train_loss=0.0048  test_loss=234.7773  λ_max=5.3328\n",
      "[Muon | lr=0.1] Epoch 3199/4000: train_loss=0.0041  test_loss=234.8484  λ_max=5.4182\n",
      "[Muon | lr=0.1] Iter 51200: loss=0.0143\n",
      "[Muon | lr=0.1] Epoch 3200/4000: train_loss=0.0043  test_loss=235.2186  λ_max=4.9167\n",
      "[Muon | lr=0.1] Epoch 3201/4000: train_loss=0.0050  test_loss=235.4767  λ_max=5.2479\n",
      "[Muon | lr=0.1] Epoch 3202/4000: train_loss=0.0044  test_loss=235.3567  λ_max=4.8521\n",
      "[Muon | lr=0.1] Epoch 3203/4000: train_loss=0.0045  test_loss=235.3067  λ_max=5.1746\n",
      "[Muon | lr=0.1] Epoch 3204/4000: train_loss=0.0034  test_loss=235.5378  λ_max=5.7972\n",
      "[Muon | lr=0.1] Epoch 3205/4000: train_loss=0.0043  test_loss=235.8275  λ_max=4.8372\n",
      "[Muon | lr=0.1] Epoch 3206/4000: train_loss=0.0036  test_loss=235.8637  λ_max=5.6234\n",
      "[Muon | lr=0.1] Iter 51300: loss=0.0007\n",
      "[Muon | lr=0.1] Epoch 3207/4000: train_loss=0.0039  test_loss=235.9348  λ_max=4.7507\n",
      "[Muon | lr=0.1] Epoch 3208/4000: train_loss=0.0047  test_loss=236.2281  λ_max=5.7403\n",
      "[Muon | lr=0.1] Epoch 3209/4000: train_loss=0.0042  test_loss=236.6027  λ_max=4.7996\n",
      "[Muon | lr=0.1] Epoch 3210/4000: train_loss=0.0040  test_loss=236.9001  λ_max=5.2931\n",
      "[Muon | lr=0.1] Epoch 3211/4000: train_loss=0.0031  test_loss=236.9593  λ_max=4.8773\n",
      "[Muon | lr=0.1] Epoch 3212/4000: train_loss=0.0035  test_loss=237.2908  λ_max=5.2177\n",
      "[Muon | lr=0.1] Iter 51400: loss=0.0019\n",
      "[Muon | lr=0.1] Epoch 3213/4000: train_loss=0.0050  test_loss=237.5738  λ_max=5.0593\n",
      "[Muon | lr=0.1] Epoch 3214/4000: train_loss=0.0050  test_loss=237.7361  λ_max=4.6854\n",
      "[Muon | lr=0.1] Epoch 3215/4000: train_loss=0.0045  test_loss=237.7735  λ_max=4.6753\n",
      "[Muon | lr=0.1] Epoch 3216/4000: train_loss=0.0041  test_loss=237.9080  λ_max=5.0853\n",
      "[Muon | lr=0.1] Epoch 3217/4000: train_loss=0.0044  test_loss=237.9999  λ_max=5.5014\n",
      "[Muon | lr=0.1] Epoch 3218/4000: train_loss=0.0055  test_loss=237.7637  λ_max=4.8196\n",
      "[Muon | lr=0.1] Iter 51500: loss=0.0037\n",
      "[Muon | lr=0.1] Epoch 3219/4000: train_loss=0.0047  test_loss=237.6223  λ_max=4.9429\n",
      "[Muon | lr=0.1] Epoch 3220/4000: train_loss=0.0042  test_loss=237.8342  λ_max=5.2641\n",
      "[Muon | lr=0.1] Epoch 3221/4000: train_loss=0.0051  test_loss=237.6005  λ_max=5.4024\n",
      "[Muon | lr=0.1] Epoch 3222/4000: train_loss=0.0039  test_loss=237.8049  λ_max=5.3183\n",
      "[Muon | lr=0.1] Epoch 3223/4000: train_loss=0.0037  test_loss=237.6874  λ_max=5.1140\n",
      "[Muon | lr=0.1] Epoch 3224/4000: train_loss=0.0045  test_loss=238.0222  λ_max=5.0772\n",
      "[Muon | lr=0.1] Iter 51600: loss=0.0097\n",
      "[Muon | lr=0.1] Epoch 3225/4000: train_loss=0.0042  test_loss=238.2185  λ_max=4.9285\n",
      "[Muon | lr=0.1] Epoch 3226/4000: train_loss=0.0035  test_loss=238.4757  λ_max=5.6333\n",
      "[Muon | lr=0.1] Epoch 3227/4000: train_loss=0.0046  test_loss=238.6633  λ_max=4.9885\n",
      "[Muon | lr=0.1] Epoch 3228/4000: train_loss=0.0029  test_loss=238.9388  λ_max=4.7364\n",
      "[Muon | lr=0.1] Epoch 3229/4000: train_loss=0.0052  test_loss=239.0594  λ_max=5.6128\n",
      "[Muon | lr=0.1] Epoch 3230/4000: train_loss=0.0043  test_loss=239.1378  λ_max=5.2540\n",
      "[Muon | lr=0.1] Epoch 3231/4000: train_loss=0.0045  test_loss=238.8713  λ_max=5.0990\n",
      "[Muon | lr=0.1] Iter 51700: loss=0.0004\n",
      "[Muon | lr=0.1] Epoch 3232/4000: train_loss=0.0035  test_loss=238.7471  λ_max=5.0396\n",
      "[Muon | lr=0.1] Epoch 3233/4000: train_loss=0.0044  test_loss=238.7681  λ_max=5.0511\n",
      "[Muon | lr=0.1] Epoch 3234/4000: train_loss=0.0053  test_loss=238.8081  λ_max=5.4047\n",
      "[Muon | lr=0.1] Epoch 3235/4000: train_loss=0.0053  test_loss=238.9042  λ_max=5.0630\n",
      "[Muon | lr=0.1] Epoch 3236/4000: train_loss=0.0034  test_loss=239.0097  λ_max=5.5223\n",
      "[Muon | lr=0.1] Epoch 3237/4000: train_loss=0.0024  test_loss=239.2837  λ_max=5.1302\n",
      "[Muon | lr=0.1] Iter 51800: loss=0.0013\n",
      "[Muon | lr=0.1] Epoch 3238/4000: train_loss=0.0037  test_loss=239.4807  λ_max=4.8434\n",
      "[Muon | lr=0.1] Epoch 3239/4000: train_loss=0.0056  test_loss=239.5244  λ_max=5.2553\n",
      "[Muon | lr=0.1] Epoch 3240/4000: train_loss=0.0028  test_loss=239.3030  λ_max=5.2328\n",
      "[Muon | lr=0.1] Epoch 3241/4000: train_loss=0.0041  test_loss=239.2672  λ_max=4.8170\n",
      "[Muon | lr=0.1] Epoch 3242/4000: train_loss=0.0036  test_loss=239.0504  λ_max=4.9158\n",
      "[Muon | lr=0.1] Epoch 3243/4000: train_loss=0.0044  test_loss=239.0144  λ_max=4.7700\n",
      "[Muon | lr=0.1] Iter 51900: loss=0.0035\n",
      "[Muon | lr=0.1] Epoch 3244/4000: train_loss=0.0045  test_loss=238.9899  λ_max=4.9676\n",
      "[Muon | lr=0.1] Epoch 3245/4000: train_loss=0.0053  test_loss=239.0101  λ_max=4.8883\n",
      "[Muon | lr=0.1] Epoch 3246/4000: train_loss=0.0037  test_loss=239.0721  λ_max=5.3173\n",
      "[Muon | lr=0.1] Epoch 3247/4000: train_loss=0.0042  test_loss=238.9110  λ_max=5.0108\n",
      "[Muon | lr=0.1] Epoch 3248/4000: train_loss=0.0033  test_loss=239.0909  λ_max=5.2558\n",
      "[Muon | lr=0.1] Epoch 3249/4000: train_loss=0.0034  test_loss=239.3358  λ_max=5.2806\n",
      "[Muon | lr=0.1] Iter 52000: loss=0.0125\n",
      "[Muon | lr=0.1] Epoch 3250/4000: train_loss=0.0047  test_loss=239.5979  λ_max=6.1786\n",
      "[Muon | lr=0.1] Epoch 3251/4000: train_loss=0.0035  test_loss=240.0594  λ_max=5.5025\n",
      "[Muon | lr=0.1] Epoch 3252/4000: train_loss=0.0043  test_loss=240.3164  λ_max=5.3485\n",
      "[Muon | lr=0.1] Epoch 3253/4000: train_loss=0.0043  test_loss=240.3718  λ_max=5.6068\n",
      "[Muon | lr=0.1] Epoch 3254/4000: train_loss=0.0046  test_loss=240.1483  λ_max=5.1449\n",
      "[Muon | lr=0.1] Epoch 3255/4000: train_loss=0.0040  test_loss=240.3296  λ_max=5.0034\n",
      "[Muon | lr=0.1] Epoch 3256/4000: train_loss=0.0034  test_loss=240.5224  λ_max=4.8228\n",
      "[Muon | lr=0.1] Iter 52100: loss=0.0011\n",
      "[Muon | lr=0.1] Epoch 3257/4000: train_loss=0.0058  test_loss=240.5276  λ_max=5.0666\n",
      "[Muon | lr=0.1] Epoch 3258/4000: train_loss=0.0045  test_loss=240.5263  λ_max=5.2787\n",
      "[Muon | lr=0.1] Epoch 3259/4000: train_loss=0.0042  test_loss=240.6723  λ_max=5.1475\n",
      "[Muon | lr=0.1] Epoch 3260/4000: train_loss=0.0042  test_loss=240.6103  λ_max=5.3267\n",
      "[Muon | lr=0.1] Epoch 3261/4000: train_loss=0.0045  test_loss=240.4624  λ_max=5.0010\n",
      "[Muon | lr=0.1] Epoch 3262/4000: train_loss=0.0045  test_loss=240.5217  λ_max=5.6952\n",
      "[Muon | lr=0.1] Iter 52200: loss=0.0060\n",
      "[Muon | lr=0.1] Epoch 3263/4000: train_loss=0.0045  test_loss=240.3667  λ_max=5.3710\n",
      "[Muon | lr=0.1] Epoch 3264/4000: train_loss=0.0040  test_loss=240.5834  λ_max=5.6831\n",
      "[Muon | lr=0.1] Epoch 3265/4000: train_loss=0.0036  test_loss=240.8723  λ_max=5.6755\n",
      "[Muon | lr=0.1] Epoch 3266/4000: train_loss=0.0032  test_loss=240.8374  λ_max=4.9764\n",
      "[Muon | lr=0.1] Epoch 3267/4000: train_loss=0.0036  test_loss=240.6920  λ_max=5.1343\n",
      "[Muon | lr=0.1] Epoch 3268/4000: train_loss=0.0052  test_loss=240.8608  λ_max=5.0614\n",
      "[Muon | lr=0.1] Iter 52300: loss=0.0046\n",
      "[Muon | lr=0.1] Epoch 3269/4000: train_loss=0.0033  test_loss=240.8967  λ_max=4.7801\n",
      "[Muon | lr=0.1] Epoch 3270/4000: train_loss=0.0045  test_loss=241.0010  λ_max=4.9484\n",
      "[Muon | lr=0.1] Epoch 3271/4000: train_loss=0.0033  test_loss=241.2477  λ_max=5.6344\n",
      "[Muon | lr=0.1] Epoch 3272/4000: train_loss=0.0042  test_loss=240.9879  λ_max=5.7136\n",
      "[Muon | lr=0.1] Epoch 3273/4000: train_loss=0.0037  test_loss=241.2013  λ_max=6.0451\n",
      "[Muon | lr=0.1] Epoch 3274/4000: train_loss=0.0039  test_loss=241.6647  λ_max=5.2457\n",
      "[Muon | lr=0.1] Iter 52400: loss=0.0110\n",
      "[Muon | lr=0.1] Epoch 3275/4000: train_loss=0.0048  test_loss=241.7440  λ_max=4.8229\n",
      "[Muon | lr=0.1] Epoch 3276/4000: train_loss=0.0039  test_loss=241.8837  λ_max=6.1056\n",
      "[Muon | lr=0.1] Epoch 3277/4000: train_loss=0.0048  test_loss=242.0436  λ_max=5.7384\n",
      "[Muon | lr=0.1] Epoch 3278/4000: train_loss=0.0040  test_loss=242.1371  λ_max=5.2296\n",
      "[Muon | lr=0.1] Epoch 3279/4000: train_loss=0.0038  test_loss=242.2549  λ_max=5.3795\n",
      "[Muon | lr=0.1] Epoch 3280/4000: train_loss=0.0030  test_loss=242.4568  λ_max=5.1051\n",
      "[Muon | lr=0.1] Epoch 3281/4000: train_loss=0.0046  test_loss=242.6357  λ_max=4.7336\n",
      "[Muon | lr=0.1] Iter 52500: loss=0.0003\n",
      "[Muon | lr=0.1] Epoch 3282/4000: train_loss=0.0039  test_loss=242.6366  λ_max=5.0731\n",
      "[Muon | lr=0.1] Epoch 3283/4000: train_loss=0.0040  test_loss=242.8036  λ_max=4.9982\n",
      "[Muon | lr=0.1] Epoch 3284/4000: train_loss=0.0035  test_loss=242.6126  λ_max=4.7646\n",
      "[Muon | lr=0.1] Epoch 3285/4000: train_loss=0.0041  test_loss=242.6324  λ_max=5.1968\n",
      "[Muon | lr=0.1] Epoch 3286/4000: train_loss=0.0041  test_loss=242.7815  λ_max=5.7012\n",
      "[Muon | lr=0.1] Epoch 3287/4000: train_loss=0.0030  test_loss=242.7071  λ_max=5.4423\n",
      "[Muon | lr=0.1] Iter 52600: loss=0.0055\n",
      "[Muon | lr=0.1] Epoch 3288/4000: train_loss=0.0032  test_loss=242.6129  λ_max=4.8877\n",
      "[Muon | lr=0.1] Epoch 3289/4000: train_loss=0.0039  test_loss=242.8356  λ_max=5.7099\n",
      "[Muon | lr=0.1] Epoch 3290/4000: train_loss=0.0039  test_loss=243.2594  λ_max=5.4481\n",
      "[Muon | lr=0.1] Epoch 3291/4000: train_loss=0.0042  test_loss=243.3633  λ_max=5.7961\n",
      "[Muon | lr=0.1] Epoch 3292/4000: train_loss=0.0048  test_loss=243.3538  λ_max=5.0484\n",
      "[Muon | lr=0.1] Epoch 3293/4000: train_loss=0.0038  test_loss=243.5505  λ_max=5.0706\n",
      "[Muon | lr=0.1] Iter 52700: loss=0.0023\n",
      "[Muon | lr=0.1] Epoch 3294/4000: train_loss=0.0028  test_loss=243.4139  λ_max=5.0455\n",
      "[Muon | lr=0.1] Epoch 3295/4000: train_loss=0.0042  test_loss=243.3538  λ_max=5.4047\n",
      "[Muon | lr=0.1] Epoch 3296/4000: train_loss=0.0041  test_loss=243.4292  λ_max=6.4687\n",
      "[Muon | lr=0.1] Epoch 3297/4000: train_loss=0.0035  test_loss=243.3241  λ_max=5.0948\n",
      "[Muon | lr=0.1] Epoch 3298/4000: train_loss=0.0038  test_loss=243.4824  λ_max=5.0098\n",
      "[Muon | lr=0.1] Epoch 3299/4000: train_loss=0.0045  test_loss=243.5629  λ_max=4.9853\n",
      "[Muon | lr=0.1] Iter 52800: loss=0.0053\n",
      "[Muon | lr=0.1] Epoch 3300/4000: train_loss=0.0042  test_loss=243.6971  λ_max=5.3650\n",
      "[Muon | lr=0.1] Epoch 3301/4000: train_loss=0.0052  test_loss=243.8417  λ_max=5.3851\n",
      "[Muon | lr=0.1] Epoch 3302/4000: train_loss=0.0036  test_loss=243.6383  λ_max=5.4006\n",
      "[Muon | lr=0.1] Epoch 3303/4000: train_loss=0.0029  test_loss=243.5632  λ_max=5.5064\n",
      "[Muon | lr=0.1] Epoch 3304/4000: train_loss=0.0044  test_loss=243.5408  λ_max=5.0561\n",
      "[Muon | lr=0.1] Epoch 3305/4000: train_loss=0.0035  test_loss=243.7260  λ_max=5.3474\n",
      "[Muon | lr=0.1] Epoch 3306/4000: train_loss=0.0049  test_loss=243.5797  λ_max=5.1997\n",
      "[Muon | lr=0.1] Iter 52900: loss=0.0000\n",
      "[Muon | lr=0.1] Epoch 3307/4000: train_loss=0.0041  test_loss=243.5179  λ_max=5.1116\n",
      "[Muon | lr=0.1] Epoch 3308/4000: train_loss=0.0039  test_loss=243.5408  λ_max=5.4041\n",
      "[Muon | lr=0.1] Epoch 3309/4000: train_loss=0.0049  test_loss=243.4356  λ_max=5.4185\n",
      "[Muon | lr=0.1] Epoch 3310/4000: train_loss=0.0031  test_loss=243.1115  λ_max=5.6237\n",
      "[Muon | lr=0.1] Epoch 3311/4000: train_loss=0.0038  test_loss=243.4214  λ_max=5.5226\n",
      "[Muon | lr=0.1] Epoch 3312/4000: train_loss=0.0044  test_loss=243.8802  λ_max=6.0824\n",
      "[Muon | lr=0.1] Iter 53000: loss=0.0024\n",
      "[Muon | lr=0.1] Epoch 3313/4000: train_loss=0.0035  test_loss=244.0472  λ_max=5.1547\n",
      "[Muon | lr=0.1] Epoch 3314/4000: train_loss=0.0039  test_loss=244.0867  λ_max=5.3315\n",
      "[Muon | lr=0.1] Epoch 3315/4000: train_loss=0.0040  test_loss=244.2494  λ_max=5.0299\n",
      "[Muon | lr=0.1] Epoch 3316/4000: train_loss=0.0036  test_loss=244.4305  λ_max=5.4406\n",
      "[Muon | lr=0.1] Epoch 3317/4000: train_loss=0.0048  test_loss=244.4105  λ_max=4.7887\n",
      "[Muon | lr=0.1] Epoch 3318/4000: train_loss=0.0045  test_loss=244.3706  λ_max=4.8804\n",
      "[Muon | lr=0.1] Iter 53100: loss=0.0036\n",
      "[Muon | lr=0.1] Epoch 3319/4000: train_loss=0.0033  test_loss=244.3981  λ_max=5.0626\n",
      "[Muon | lr=0.1] Epoch 3320/4000: train_loss=0.0033  test_loss=244.6498  λ_max=5.3445\n",
      "[Muon | lr=0.1] Epoch 3321/4000: train_loss=0.0042  test_loss=244.8092  λ_max=6.3585\n",
      "[Muon | lr=0.1] Epoch 3322/4000: train_loss=0.0054  test_loss=245.0031  λ_max=5.5543\n",
      "[Muon | lr=0.1] Epoch 3323/4000: train_loss=0.0052  test_loss=245.1423  λ_max=4.7587\n",
      "[Muon | lr=0.1] Epoch 3324/4000: train_loss=0.0051  test_loss=245.2012  λ_max=4.9795\n",
      "[Muon | lr=0.1] Iter 53200: loss=0.0154\n",
      "[Muon | lr=0.1] Epoch 3325/4000: train_loss=0.0055  test_loss=244.9632  λ_max=6.0574\n",
      "[Muon | lr=0.1] Epoch 3326/4000: train_loss=0.0041  test_loss=245.0476  λ_max=5.6845\n",
      "[Muon | lr=0.1] Epoch 3327/4000: train_loss=0.0050  test_loss=245.1990  λ_max=6.1518\n",
      "[Muon | lr=0.1] Epoch 3328/4000: train_loss=0.0044  test_loss=245.4857  λ_max=5.5049\n",
      "[Muon | lr=0.1] Epoch 3329/4000: train_loss=0.0041  test_loss=245.3936  λ_max=5.2615\n",
      "[Muon | lr=0.1] Epoch 3330/4000: train_loss=0.0029  test_loss=245.7023  λ_max=6.5422\n",
      "[Muon | lr=0.1] Epoch 3331/4000: train_loss=0.0040  test_loss=245.7757  λ_max=5.2609\n",
      "[Muon | lr=0.1] Iter 53300: loss=0.0028\n",
      "[Muon | lr=0.1] Epoch 3332/4000: train_loss=0.0036  test_loss=245.5316  λ_max=5.3282\n",
      "[Muon | lr=0.1] Epoch 3333/4000: train_loss=0.0044  test_loss=245.5310  λ_max=5.5250\n",
      "[Muon | lr=0.1] Epoch 3334/4000: train_loss=0.0057  test_loss=245.6506  λ_max=5.4271\n",
      "[Muon | lr=0.1] Epoch 3335/4000: train_loss=0.0041  test_loss=245.7173  λ_max=6.2884\n",
      "[Muon | lr=0.1] Epoch 3336/4000: train_loss=0.0040  test_loss=245.8138  λ_max=5.6679\n",
      "[Muon | lr=0.1] Epoch 3337/4000: train_loss=0.0042  test_loss=245.8246  λ_max=5.0784\n",
      "[Muon | lr=0.1] Iter 53400: loss=0.0044\n",
      "[Muon | lr=0.1] Epoch 3338/4000: train_loss=0.0031  test_loss=245.8066  λ_max=5.3033\n",
      "[Muon | lr=0.1] Epoch 3339/4000: train_loss=0.0043  test_loss=246.0888  λ_max=5.1602\n",
      "[Muon | lr=0.1] Epoch 3340/4000: train_loss=0.0047  test_loss=246.3648  λ_max=5.6684\n",
      "[Muon | lr=0.1] Epoch 3341/4000: train_loss=0.0055  test_loss=246.3763  λ_max=5.3693\n",
      "[Muon | lr=0.1] Epoch 3342/4000: train_loss=0.0028  test_loss=246.2606  λ_max=5.5390\n",
      "[Muon | lr=0.1] Epoch 3343/4000: train_loss=0.0039  test_loss=246.1422  λ_max=5.3964\n",
      "[Muon | lr=0.1] Iter 53500: loss=0.0113\n",
      "[Muon | lr=0.1] Epoch 3344/4000: train_loss=0.0053  test_loss=246.5278  λ_max=5.3275\n",
      "[Muon | lr=0.1] Epoch 3345/4000: train_loss=0.0034  test_loss=246.8900  λ_max=5.2448\n",
      "[Muon | lr=0.1] Epoch 3346/4000: train_loss=0.0046  test_loss=246.9123  λ_max=5.5048\n",
      "[Muon | lr=0.1] Epoch 3347/4000: train_loss=0.0043  test_loss=246.9915  λ_max=6.0688\n",
      "[Muon | lr=0.1] Epoch 3348/4000: train_loss=0.0048  test_loss=246.9413  λ_max=4.9119\n",
      "[Muon | lr=0.1] Epoch 3349/4000: train_loss=0.0039  test_loss=247.1385  λ_max=5.0563\n",
      "[Muon | lr=0.1] Iter 53600: loss=0.0007\n",
      "[Muon | lr=0.1] Epoch 3350/4000: train_loss=0.0027  test_loss=247.6878  λ_max=5.2034\n",
      "[Muon | lr=0.1] Epoch 3351/4000: train_loss=0.0026  test_loss=248.1335  λ_max=5.5198\n",
      "[Muon | lr=0.1] Epoch 3352/4000: train_loss=0.0041  test_loss=248.4680  λ_max=5.2465\n",
      "[Muon | lr=0.1] Epoch 3353/4000: train_loss=0.0035  test_loss=248.7065  λ_max=5.1615\n",
      "[Muon | lr=0.1] Epoch 3354/4000: train_loss=0.0056  test_loss=248.6226  λ_max=5.3283\n",
      "[Muon | lr=0.1] Epoch 3355/4000: train_loss=0.0034  test_loss=248.5705  λ_max=5.2371\n",
      "[Muon | lr=0.1] Epoch 3356/4000: train_loss=0.0044  test_loss=248.3100  λ_max=6.0643\n",
      "[Muon | lr=0.1] Iter 53700: loss=0.0025\n",
      "[Muon | lr=0.1] Epoch 3357/4000: train_loss=0.0043  test_loss=248.3341  λ_max=5.3767\n",
      "[Muon | lr=0.1] Epoch 3358/4000: train_loss=0.0043  test_loss=248.3690  λ_max=5.7533\n",
      "[Muon | lr=0.1] Epoch 3359/4000: train_loss=0.0051  test_loss=248.4293  λ_max=5.3236\n",
      "[Muon | lr=0.1] Epoch 3360/4000: train_loss=0.0044  test_loss=248.7810  λ_max=5.4424\n",
      "[Muon | lr=0.1] Epoch 3361/4000: train_loss=0.0040  test_loss=249.1060  λ_max=5.2604\n",
      "[Muon | lr=0.1] Epoch 3362/4000: train_loss=0.0040  test_loss=249.0839  λ_max=4.8843\n",
      "[Muon | lr=0.1] Iter 53800: loss=0.0024\n",
      "[Muon | lr=0.1] Epoch 3363/4000: train_loss=0.0035  test_loss=249.2482  λ_max=5.7296\n",
      "[Muon | lr=0.1] Epoch 3364/4000: train_loss=0.0041  test_loss=249.3182  λ_max=4.9777\n",
      "[Muon | lr=0.1] Epoch 3365/4000: train_loss=0.0054  test_loss=249.7467  λ_max=4.8138\n",
      "[Muon | lr=0.1] Epoch 3366/4000: train_loss=0.0044  test_loss=249.8905  λ_max=5.3353\n",
      "[Muon | lr=0.1] Epoch 3367/4000: train_loss=0.0040  test_loss=249.8748  λ_max=6.6093\n",
      "[Muon | lr=0.1] Epoch 3368/4000: train_loss=0.0042  test_loss=249.8858  λ_max=6.1392\n",
      "[Muon | lr=0.1] Iter 53900: loss=0.0112\n",
      "[Muon | lr=0.1] Epoch 3369/4000: train_loss=0.0039  test_loss=249.9336  λ_max=5.1319\n",
      "[Muon | lr=0.1] Epoch 3370/4000: train_loss=0.0044  test_loss=250.0386  λ_max=5.4832\n",
      "[Muon | lr=0.1] Epoch 3371/4000: train_loss=0.0031  test_loss=250.3793  λ_max=5.3822\n",
      "[Muon | lr=0.1] Epoch 3372/4000: train_loss=0.0045  test_loss=250.5680  λ_max=4.8925\n",
      "[Muon | lr=0.1] Epoch 3373/4000: train_loss=0.0048  test_loss=250.7951  λ_max=5.2234\n",
      "[Muon | lr=0.1] Epoch 3374/4000: train_loss=0.0039  test_loss=250.8197  λ_max=5.1579\n",
      "[Muon | lr=0.1] Iter 54000: loss=0.0014\n",
      "[Muon | lr=0.1] Epoch 3375/4000: train_loss=0.0046  test_loss=250.6282  λ_max=5.1586\n",
      "[Muon | lr=0.1] Epoch 3376/4000: train_loss=0.0044  test_loss=250.4757  λ_max=5.4891\n",
      "[Muon | lr=0.1] Epoch 3377/4000: train_loss=0.0048  test_loss=250.4146  λ_max=5.7640\n",
      "[Muon | lr=0.1] Epoch 3378/4000: train_loss=0.0036  test_loss=250.3035  λ_max=5.1036\n",
      "[Muon | lr=0.1] Epoch 3379/4000: train_loss=0.0037  test_loss=250.4691  λ_max=5.3522\n",
      "[Muon | lr=0.1] Epoch 3380/4000: train_loss=0.0031  test_loss=250.7296  λ_max=4.8920\n",
      "[Muon | lr=0.1] Epoch 3381/4000: train_loss=0.0038  test_loss=250.6583  λ_max=5.6708\n",
      "[Muon | lr=0.1] Iter 54100: loss=0.0014\n",
      "[Muon | lr=0.1] Epoch 3382/4000: train_loss=0.0042  test_loss=250.6115  λ_max=5.2086\n",
      "[Muon | lr=0.1] Epoch 3383/4000: train_loss=0.0037  test_loss=250.8074  λ_max=4.9467\n",
      "[Muon | lr=0.1] Epoch 3384/4000: train_loss=0.0043  test_loss=251.0429  λ_max=5.4521\n",
      "[Muon | lr=0.1] Epoch 3385/4000: train_loss=0.0041  test_loss=251.2579  λ_max=4.9409\n",
      "[Muon | lr=0.1] Epoch 3386/4000: train_loss=0.0034  test_loss=251.3793  λ_max=5.2796\n",
      "[Muon | lr=0.1] Epoch 3387/4000: train_loss=0.0041  test_loss=251.5689  λ_max=6.5327\n",
      "[Muon | lr=0.1] Iter 54200: loss=0.0028\n",
      "[Muon | lr=0.1] Epoch 3388/4000: train_loss=0.0034  test_loss=251.5166  λ_max=5.1868\n",
      "[Muon | lr=0.1] Epoch 3389/4000: train_loss=0.0040  test_loss=251.6939  λ_max=5.5703\n",
      "[Muon | lr=0.1] Epoch 3390/4000: train_loss=0.0049  test_loss=251.6644  λ_max=5.9864\n",
      "[Muon | lr=0.1] Epoch 3391/4000: train_loss=0.0047  test_loss=251.5143  λ_max=4.9777\n",
      "[Muon | lr=0.1] Epoch 3392/4000: train_loss=0.0047  test_loss=251.3875  λ_max=5.8097\n",
      "[Muon | lr=0.1] Epoch 3393/4000: train_loss=0.0031  test_loss=251.6005  λ_max=5.1971\n",
      "[Muon | lr=0.1] Iter 54300: loss=0.0099\n",
      "[Muon | lr=0.1] Epoch 3394/4000: train_loss=0.0049  test_loss=252.1115  λ_max=5.6733\n",
      "[Muon | lr=0.1] Epoch 3395/4000: train_loss=0.0036  test_loss=252.4122  λ_max=5.4799\n",
      "[Muon | lr=0.1] Epoch 3396/4000: train_loss=0.0035  test_loss=252.6106  λ_max=5.0115\n",
      "[Muon | lr=0.1] Epoch 3397/4000: train_loss=0.0045  test_loss=252.5720  λ_max=4.9497\n",
      "[Muon | lr=0.1] Epoch 3398/4000: train_loss=0.0035  test_loss=252.5321  λ_max=5.0096\n",
      "[Muon | lr=0.1] Epoch 3399/4000: train_loss=0.0043  test_loss=252.7363  λ_max=5.2312\n",
      "[Muon | lr=0.1] Iter 54400: loss=0.0079\n",
      "[Muon | lr=0.1] Epoch 3400/4000: train_loss=0.0037  test_loss=252.7276  λ_max=5.1300\n",
      "[Muon | lr=0.1] Epoch 3401/4000: train_loss=0.0045  test_loss=252.7769  λ_max=4.9618\n",
      "[Muon | lr=0.1] Epoch 3402/4000: train_loss=0.0049  test_loss=252.7169  λ_max=6.7688\n",
      "[Muon | lr=0.1] Epoch 3403/4000: train_loss=0.0036  test_loss=252.5327  λ_max=5.6207\n",
      "[Muon | lr=0.1] Epoch 3404/4000: train_loss=0.0041  test_loss=252.4675  λ_max=5.3966\n",
      "[Muon | lr=0.1] Epoch 3405/4000: train_loss=0.0035  test_loss=252.4963  λ_max=5.4165\n",
      "[Muon | lr=0.1] Epoch 3406/4000: train_loss=0.0031  test_loss=252.6759  λ_max=5.7585\n",
      "[Muon | lr=0.1] Iter 54500: loss=0.0040\n",
      "[Muon | lr=0.1] Epoch 3407/4000: train_loss=0.0033  test_loss=252.5878  λ_max=4.9603\n",
      "[Muon | lr=0.1] Epoch 3408/4000: train_loss=0.0041  test_loss=252.7122  λ_max=5.1721\n",
      "[Muon | lr=0.1] Epoch 3409/4000: train_loss=0.0045  test_loss=252.6799  λ_max=5.3542\n",
      "[Muon | lr=0.1] Epoch 3410/4000: train_loss=0.0029  test_loss=252.9010  λ_max=4.7371\n",
      "[Muon | lr=0.1] Epoch 3411/4000: train_loss=0.0044  test_loss=252.9589  λ_max=5.5037\n",
      "[Muon | lr=0.1] Epoch 3412/4000: train_loss=0.0044  test_loss=252.6713  λ_max=5.5622\n",
      "[Muon | lr=0.1] Iter 54600: loss=0.0010\n",
      "[Muon | lr=0.1] Epoch 3413/4000: train_loss=0.0035  test_loss=252.6378  λ_max=5.4310\n",
      "[Muon | lr=0.1] Epoch 3414/4000: train_loss=0.0051  test_loss=252.8674  λ_max=5.2353\n",
      "[Muon | lr=0.1] Epoch 3415/4000: train_loss=0.0038  test_loss=253.1439  λ_max=5.2493\n",
      "[Muon | lr=0.1] Epoch 3416/4000: train_loss=0.0029  test_loss=253.4504  λ_max=5.5289\n",
      "[Muon | lr=0.1] Epoch 3417/4000: train_loss=0.0043  test_loss=253.7788  λ_max=5.9924\n",
      "[Muon | lr=0.1] Epoch 3418/4000: train_loss=0.0045  test_loss=253.6847  λ_max=5.8115\n",
      "[Muon | lr=0.1] Iter 54700: loss=0.0029\n",
      "[Muon | lr=0.1] Epoch 3419/4000: train_loss=0.0038  test_loss=253.5393  λ_max=4.7295\n",
      "[Muon | lr=0.1] Epoch 3420/4000: train_loss=0.0041  test_loss=253.8381  λ_max=5.8166\n",
      "[Muon | lr=0.1] Epoch 3421/4000: train_loss=0.0041  test_loss=253.7279  λ_max=5.4339\n",
      "[Muon | lr=0.1] Epoch 3422/4000: train_loss=0.0029  test_loss=253.7212  λ_max=5.0184\n",
      "[Muon | lr=0.1] Epoch 3423/4000: train_loss=0.0047  test_loss=253.7116  λ_max=5.1040\n",
      "[Muon | lr=0.1] Epoch 3424/4000: train_loss=0.0045  test_loss=253.6327  λ_max=5.4365\n",
      "[Muon | lr=0.1] Iter 54800: loss=0.0079\n",
      "[Muon | lr=0.1] Epoch 3425/4000: train_loss=0.0053  test_loss=253.7677  λ_max=5.2026\n",
      "[Muon | lr=0.1] Epoch 3426/4000: train_loss=0.0039  test_loss=253.9828  λ_max=4.6760\n",
      "[Muon | lr=0.1] Epoch 3427/4000: train_loss=0.0041  test_loss=253.9547  λ_max=5.4457\n",
      "[Muon | lr=0.1] Epoch 3428/4000: train_loss=0.0050  test_loss=253.8416  λ_max=5.5321\n",
      "[Muon | lr=0.1] Epoch 3429/4000: train_loss=0.0031  test_loss=254.1300  λ_max=5.4437\n",
      "[Muon | lr=0.1] Epoch 3430/4000: train_loss=0.0036  test_loss=254.3278  λ_max=4.8546\n",
      "[Muon | lr=0.1] Epoch 3431/4000: train_loss=0.0052  test_loss=254.1156  λ_max=5.2761\n",
      "[Muon | lr=0.1] Iter 54900: loss=0.0043\n",
      "[Muon | lr=0.1] Epoch 3432/4000: train_loss=0.0045  test_loss=254.1701  λ_max=5.5650\n",
      "[Muon | lr=0.1] Epoch 3433/4000: train_loss=0.0056  test_loss=254.3610  λ_max=4.9955\n",
      "[Muon | lr=0.1] Epoch 3434/4000: train_loss=0.0044  test_loss=253.9061  λ_max=6.1331\n",
      "[Muon | lr=0.1] Epoch 3435/4000: train_loss=0.0038  test_loss=253.9638  λ_max=4.8530\n",
      "[Muon | lr=0.1] Epoch 3436/4000: train_loss=0.0037  test_loss=253.9658  λ_max=5.2084\n",
      "[Muon | lr=0.1] Epoch 3437/4000: train_loss=0.0039  test_loss=254.0035  λ_max=5.4426\n",
      "[Muon | lr=0.1] Iter 55000: loss=0.0106\n",
      "[Muon | lr=0.1] Epoch 3438/4000: train_loss=0.0043  test_loss=254.1086  λ_max=5.4072\n",
      "[Muon | lr=0.1] Epoch 3439/4000: train_loss=0.0034  test_loss=254.2738  λ_max=5.4587\n",
      "[Muon | lr=0.1] Epoch 3440/4000: train_loss=0.0037  test_loss=254.6138  λ_max=5.3905\n",
      "[Muon | lr=0.1] Epoch 3441/4000: train_loss=0.0040  test_loss=254.7484  λ_max=5.1911\n",
      "[Muon | lr=0.1] Epoch 3442/4000: train_loss=0.0044  test_loss=254.7739  λ_max=5.0830\n",
      "[Muon | lr=0.1] Epoch 3443/4000: train_loss=0.0042  test_loss=254.7662  λ_max=5.1252\n",
      "[Muon | lr=0.1] Iter 55100: loss=0.0068\n",
      "[Muon | lr=0.1] Epoch 3444/4000: train_loss=0.0025  test_loss=254.9077  λ_max=5.5358\n",
      "[Muon | lr=0.1] Epoch 3445/4000: train_loss=0.0042  test_loss=255.0362  λ_max=5.5289\n",
      "[Muon | lr=0.1] Epoch 3446/4000: train_loss=0.0054  test_loss=254.6245  λ_max=4.9132\n",
      "[Muon | lr=0.1] Epoch 3447/4000: train_loss=0.0050  test_loss=254.7215  λ_max=5.5095\n",
      "[Muon | lr=0.1] Epoch 3448/4000: train_loss=0.0036  test_loss=254.7794  λ_max=5.5395\n",
      "[Muon | lr=0.1] Epoch 3449/4000: train_loss=0.0042  test_loss=254.6061  λ_max=5.4064\n",
      "[Muon | lr=0.1] Iter 55200: loss=0.0036\n",
      "[Muon | lr=0.1] Epoch 3450/4000: train_loss=0.0033  test_loss=254.6400  λ_max=4.8732\n",
      "[Muon | lr=0.1] Epoch 3451/4000: train_loss=0.0037  test_loss=255.0567  λ_max=4.9488\n",
      "[Muon | lr=0.1] Epoch 3452/4000: train_loss=0.0044  test_loss=255.0011  λ_max=4.9211\n",
      "[Muon | lr=0.1] Epoch 3453/4000: train_loss=0.0037  test_loss=254.8750  λ_max=6.3199\n",
      "[Muon | lr=0.1] Epoch 3454/4000: train_loss=0.0032  test_loss=254.9184  λ_max=7.0222\n",
      "[Muon | lr=0.1] Epoch 3455/4000: train_loss=0.0042  test_loss=254.9790  λ_max=5.2885\n",
      "[Muon | lr=0.1] Epoch 3456/4000: train_loss=0.0039  test_loss=255.0136  λ_max=5.3338\n",
      "[Muon | lr=0.1] Iter 55300: loss=0.0004\n",
      "[Muon | lr=0.1] Epoch 3457/4000: train_loss=0.0036  test_loss=255.0153  λ_max=4.7703\n",
      "[Muon | lr=0.1] Epoch 3458/4000: train_loss=0.0043  test_loss=255.0679  λ_max=5.5982\n",
      "[Muon | lr=0.1] Epoch 3459/4000: train_loss=0.0035  test_loss=255.2660  λ_max=5.2339\n",
      "[Muon | lr=0.1] Epoch 3460/4000: train_loss=0.0046  test_loss=255.2083  λ_max=5.6449\n",
      "[Muon | lr=0.1] Epoch 3461/4000: train_loss=0.0037  test_loss=255.6438  λ_max=5.4416\n",
      "[Muon | lr=0.1] Epoch 3462/4000: train_loss=0.0052  test_loss=255.7335  λ_max=5.7713\n",
      "[Muon | lr=0.1] Iter 55400: loss=0.0013\n",
      "[Muon | lr=0.1] Epoch 3463/4000: train_loss=0.0040  test_loss=255.8035  λ_max=5.2082\n",
      "[Muon | lr=0.1] Epoch 3464/4000: train_loss=0.0053  test_loss=255.8964  λ_max=5.6820\n",
      "[Muon | lr=0.1] Epoch 3465/4000: train_loss=0.0042  test_loss=256.3686  λ_max=5.6315\n",
      "[Muon | lr=0.1] Epoch 3466/4000: train_loss=0.0040  test_loss=256.3540  λ_max=5.6558\n",
      "[Muon | lr=0.1] Epoch 3467/4000: train_loss=0.0035  test_loss=256.3053  λ_max=5.4071\n",
      "[Muon | lr=0.1] Epoch 3468/4000: train_loss=0.0042  test_loss=256.4248  λ_max=4.9301\n",
      "[Muon | lr=0.1] Iter 55500: loss=0.0049\n",
      "[Muon | lr=0.1] Epoch 3469/4000: train_loss=0.0040  test_loss=256.5378  λ_max=5.4260\n",
      "[Muon | lr=0.1] Epoch 3470/4000: train_loss=0.0040  test_loss=256.2253  λ_max=5.3852\n",
      "[Muon | lr=0.1] Epoch 3471/4000: train_loss=0.0034  test_loss=256.4186  λ_max=6.4380\n",
      "[Muon | lr=0.1] Epoch 3472/4000: train_loss=0.0040  test_loss=256.7139  λ_max=5.7344\n",
      "[Muon | lr=0.1] Epoch 3473/4000: train_loss=0.0045  test_loss=256.8088  λ_max=5.1851\n",
      "[Muon | lr=0.1] Epoch 3474/4000: train_loss=0.0041  test_loss=256.9821  λ_max=5.7218\n",
      "[Muon | lr=0.1] Iter 55600: loss=0.0017\n",
      "[Muon | lr=0.1] Epoch 3475/4000: train_loss=0.0036  test_loss=257.2035  λ_max=5.2929\n",
      "[Muon | lr=0.1] Epoch 3476/4000: train_loss=0.0043  test_loss=257.2660  λ_max=5.5288\n",
      "[Muon | lr=0.1] Epoch 3477/4000: train_loss=0.0037  test_loss=257.2355  λ_max=5.3168\n",
      "[Muon | lr=0.1] Epoch 3478/4000: train_loss=0.0048  test_loss=257.5614  λ_max=5.8649\n",
      "[Muon | lr=0.1] Epoch 3479/4000: train_loss=0.0042  test_loss=257.3400  λ_max=5.7301\n",
      "[Muon | lr=0.1] Epoch 3480/4000: train_loss=0.0036  test_loss=257.5738  λ_max=5.0863\n",
      "[Muon | lr=0.1] Epoch 3481/4000: train_loss=0.0046  test_loss=257.4514  λ_max=5.3815\n",
      "[Muon | lr=0.1] Iter 55700: loss=0.0009\n",
      "[Muon | lr=0.1] Epoch 3482/4000: train_loss=0.0046  test_loss=257.2009  λ_max=6.1308\n",
      "[Muon | lr=0.1] Epoch 3483/4000: train_loss=0.0041  test_loss=256.9820  λ_max=5.2895\n",
      "[Muon | lr=0.1] Epoch 3484/4000: train_loss=0.0037  test_loss=257.0291  λ_max=4.9838\n",
      "[Muon | lr=0.1] Epoch 3485/4000: train_loss=0.0027  test_loss=257.1122  λ_max=5.1043\n",
      "[Muon | lr=0.1] Epoch 3486/4000: train_loss=0.0036  test_loss=256.8906  λ_max=5.3781\n",
      "[Muon | lr=0.1] Epoch 3487/4000: train_loss=0.0051  test_loss=256.8510  λ_max=6.4191\n",
      "[Muon | lr=0.1] Iter 55800: loss=0.0047\n",
      "[Muon | lr=0.1] Epoch 3488/4000: train_loss=0.0050  test_loss=256.9322  λ_max=5.8421\n",
      "[Muon | lr=0.1] Epoch 3489/4000: train_loss=0.0041  test_loss=256.8064  λ_max=5.6459\n",
      "[Muon | lr=0.1] Epoch 3490/4000: train_loss=0.0037  test_loss=256.7764  λ_max=5.1991\n",
      "[Muon | lr=0.1] Epoch 3491/4000: train_loss=0.0041  test_loss=256.7379  λ_max=5.8735\n",
      "[Muon | lr=0.1] Epoch 3492/4000: train_loss=0.0047  test_loss=256.6412  λ_max=5.2503\n",
      "[Muon | lr=0.1] Epoch 3493/4000: train_loss=0.0036  test_loss=256.5437  λ_max=5.5987\n",
      "[Muon | lr=0.1] Iter 55900: loss=0.0069\n",
      "[Muon | lr=0.1] Epoch 3494/4000: train_loss=0.0038  test_loss=256.9351  λ_max=6.0886\n",
      "[Muon | lr=0.1] Epoch 3495/4000: train_loss=0.0045  test_loss=257.0367  λ_max=5.7733\n",
      "[Muon | lr=0.1] Epoch 3496/4000: train_loss=0.0030  test_loss=257.0244  λ_max=5.5595\n",
      "[Muon | lr=0.1] Epoch 3497/4000: train_loss=0.0043  test_loss=257.3686  λ_max=6.1219\n",
      "[Muon | lr=0.1] Epoch 3498/4000: train_loss=0.0037  test_loss=257.6487  λ_max=5.4026\n",
      "[Muon | lr=0.1] Epoch 3499/4000: train_loss=0.0037  test_loss=257.6271  λ_max=5.4202\n",
      "[Muon | lr=0.1] Iter 56000: loss=0.0165\n",
      "[Muon | lr=0.1] Epoch 3500/4000: train_loss=0.0037  test_loss=257.5791  λ_max=5.4944\n",
      "[Muon | lr=0.1] Epoch 3501/4000: train_loss=0.0033  test_loss=258.1915  λ_max=5.6681\n",
      "[Muon | lr=0.1] Epoch 3502/4000: train_loss=0.0053  test_loss=258.4092  λ_max=5.7870\n",
      "[Muon | lr=0.1] Epoch 3503/4000: train_loss=0.0042  test_loss=258.3470  λ_max=5.1717\n",
      "[Muon | lr=0.1] Epoch 3504/4000: train_loss=0.0041  test_loss=258.2368  λ_max=5.3853\n",
      "[Muon | lr=0.1] Epoch 3505/4000: train_loss=0.0032  test_loss=258.5101  λ_max=5.4757\n",
      "[Muon | lr=0.1] Epoch 3506/4000: train_loss=0.0038  test_loss=258.5078  λ_max=5.5905\n",
      "[Muon | lr=0.1] Iter 56100: loss=0.0046\n",
      "[Muon | lr=0.1] Epoch 3507/4000: train_loss=0.0045  test_loss=258.3311  λ_max=5.5999\n",
      "[Muon | lr=0.1] Epoch 3508/4000: train_loss=0.0037  test_loss=258.4734  λ_max=5.5448\n",
      "[Muon | lr=0.1] Epoch 3509/4000: train_loss=0.0037  test_loss=258.6607  λ_max=5.2836\n",
      "[Muon | lr=0.1] Epoch 3510/4000: train_loss=0.0046  test_loss=258.8941  λ_max=4.9658\n",
      "[Muon | lr=0.1] Epoch 3511/4000: train_loss=0.0042  test_loss=258.9940  λ_max=5.2775\n",
      "[Muon | lr=0.1] Epoch 3512/4000: train_loss=0.0043  test_loss=259.2596  λ_max=5.6168\n",
      "[Muon | lr=0.1] Iter 56200: loss=0.0043\n",
      "[Muon | lr=0.1] Epoch 3513/4000: train_loss=0.0045  test_loss=259.1263  λ_max=5.8329\n",
      "[Muon | lr=0.1] Epoch 3514/4000: train_loss=0.0037  test_loss=259.4578  λ_max=5.8455\n",
      "[Muon | lr=0.1] Epoch 3515/4000: train_loss=0.0031  test_loss=259.5836  λ_max=6.5343\n",
      "[Muon | lr=0.1] Epoch 3516/4000: train_loss=0.0036  test_loss=259.4788  λ_max=5.2404\n",
      "[Muon | lr=0.1] Epoch 3517/4000: train_loss=0.0046  test_loss=259.4068  λ_max=5.1952\n",
      "[Muon | lr=0.1] Epoch 3518/4000: train_loss=0.0046  test_loss=259.5609  λ_max=5.6609\n",
      "[Muon | lr=0.1] Iter 56300: loss=0.0124\n",
      "[Muon | lr=0.1] Epoch 3519/4000: train_loss=0.0034  test_loss=259.5283  λ_max=6.0254\n",
      "[Muon | lr=0.1] Epoch 3520/4000: train_loss=0.0038  test_loss=259.4514  λ_max=6.0183\n",
      "[Muon | lr=0.1] Epoch 3521/4000: train_loss=0.0042  test_loss=259.7955  λ_max=5.3825\n",
      "[Muon | lr=0.1] Epoch 3522/4000: train_loss=0.0042  test_loss=259.9450  λ_max=5.5930\n",
      "[Muon | lr=0.1] Epoch 3523/4000: train_loss=0.0041  test_loss=260.3199  λ_max=5.9647\n",
      "[Muon | lr=0.1] Epoch 3524/4000: train_loss=0.0036  test_loss=260.7712  λ_max=5.4055\n",
      "[Muon | lr=0.1] Iter 56400: loss=0.0005\n",
      "[Muon | lr=0.1] Epoch 3525/4000: train_loss=0.0043  test_loss=261.2885  λ_max=5.1657\n",
      "[Muon | lr=0.1] Epoch 3526/4000: train_loss=0.0050  test_loss=261.2480  λ_max=5.9697\n",
      "[Muon | lr=0.1] Epoch 3527/4000: train_loss=0.0042  test_loss=261.2692  λ_max=5.2949\n",
      "[Muon | lr=0.1] Epoch 3528/4000: train_loss=0.0040  test_loss=261.4510  λ_max=5.6901\n",
      "[Muon | lr=0.1] Epoch 3529/4000: train_loss=0.0048  test_loss=261.5784  λ_max=5.3728\n",
      "[Muon | lr=0.1] Epoch 3530/4000: train_loss=0.0043  test_loss=261.4497  λ_max=5.3100\n",
      "[Muon | lr=0.1] Epoch 3531/4000: train_loss=0.0031  test_loss=261.3204  λ_max=5.7372\n",
      "[Muon | lr=0.1] Iter 56500: loss=0.0002\n",
      "[Muon | lr=0.1] Epoch 3532/4000: train_loss=0.0036  test_loss=261.3890  λ_max=5.1149\n",
      "[Muon | lr=0.1] Epoch 3533/4000: train_loss=0.0041  test_loss=261.2101  λ_max=5.3880\n",
      "[Muon | lr=0.1] Epoch 3534/4000: train_loss=0.0046  test_loss=261.2557  λ_max=5.2469\n",
      "[Muon | lr=0.1] Epoch 3535/4000: train_loss=0.0046  test_loss=261.1650  λ_max=5.6785\n",
      "[Muon | lr=0.1] Epoch 3536/4000: train_loss=0.0032  test_loss=261.0951  λ_max=5.6772\n",
      "[Muon | lr=0.1] Epoch 3537/4000: train_loss=0.0038  test_loss=261.1697  λ_max=5.4474\n",
      "[Muon | lr=0.1] Iter 56600: loss=0.0042\n",
      "[Muon | lr=0.1] Epoch 3538/4000: train_loss=0.0039  test_loss=261.2056  λ_max=5.0182\n",
      "[Muon | lr=0.1] Epoch 3539/4000: train_loss=0.0044  test_loss=261.4138  λ_max=5.6021\n",
      "[Muon | lr=0.1] Epoch 3540/4000: train_loss=0.0032  test_loss=261.8843  λ_max=5.3907\n",
      "[Muon | lr=0.1] Epoch 3541/4000: train_loss=0.0038  test_loss=261.8358  λ_max=5.3362\n",
      "[Muon | lr=0.1] Epoch 3542/4000: train_loss=0.0050  test_loss=261.7519  λ_max=5.6550\n",
      "[Muon | lr=0.1] Epoch 3543/4000: train_loss=0.0044  test_loss=261.7741  λ_max=6.0289\n",
      "[Muon | lr=0.1] Iter 56700: loss=0.0047\n",
      "[Muon | lr=0.1] Epoch 3544/4000: train_loss=0.0053  test_loss=261.8307  λ_max=4.9696\n",
      "[Muon | lr=0.1] Epoch 3545/4000: train_loss=0.0040  test_loss=262.0786  λ_max=5.7340\n",
      "[Muon | lr=0.1] Epoch 3546/4000: train_loss=0.0050  test_loss=262.2821  λ_max=5.7800\n",
      "[Muon | lr=0.1] Epoch 3547/4000: train_loss=0.0032  test_loss=262.4250  λ_max=5.2995\n",
      "[Muon | lr=0.1] Epoch 3548/4000: train_loss=0.0034  test_loss=262.6107  λ_max=5.2678\n",
      "[Muon | lr=0.1] Epoch 3549/4000: train_loss=0.0054  test_loss=262.5160  λ_max=5.4898\n",
      "[Muon | lr=0.1] Iter 56800: loss=0.0123\n",
      "[Muon | lr=0.1] Epoch 3550/4000: train_loss=0.0037  test_loss=262.5569  λ_max=5.5948\n",
      "[Muon | lr=0.1] Epoch 3551/4000: train_loss=0.0040  test_loss=262.7375  λ_max=5.7682\n",
      "[Muon | lr=0.1] Epoch 3552/4000: train_loss=0.0035  test_loss=262.9799  λ_max=5.6438\n",
      "[Muon | lr=0.1] Epoch 3553/4000: train_loss=0.0043  test_loss=263.1676  λ_max=5.1957\n",
      "[Muon | lr=0.1] Epoch 3554/4000: train_loss=0.0041  test_loss=263.2628  λ_max=5.2459\n",
      "[Muon | lr=0.1] Epoch 3555/4000: train_loss=0.0037  test_loss=263.3850  λ_max=5.6696\n",
      "[Muon | lr=0.1] Epoch 3556/4000: train_loss=0.0033  test_loss=263.3364  λ_max=5.5893\n",
      "[Muon | lr=0.1] Iter 56900: loss=0.0007\n",
      "[Muon | lr=0.1] Epoch 3557/4000: train_loss=0.0044  test_loss=263.7852  λ_max=5.6725\n",
      "[Muon | lr=0.1] Epoch 3558/4000: train_loss=0.0039  test_loss=263.7740  λ_max=5.8469\n",
      "[Muon | lr=0.1] Epoch 3559/4000: train_loss=0.0030  test_loss=263.6920  λ_max=5.2697\n",
      "[Muon | lr=0.1] Epoch 3560/4000: train_loss=0.0039  test_loss=264.0125  λ_max=5.0778\n",
      "[Muon | lr=0.1] Epoch 3561/4000: train_loss=0.0035  test_loss=263.6970  λ_max=5.6462\n",
      "[Muon | lr=0.1] Epoch 3562/4000: train_loss=0.0048  test_loss=263.5968  λ_max=5.4105\n",
      "[Muon | lr=0.1] Iter 57000: loss=0.0041\n",
      "[Muon | lr=0.1] Epoch 3563/4000: train_loss=0.0028  test_loss=263.8107  λ_max=5.8617\n",
      "[Muon | lr=0.1] Epoch 3564/4000: train_loss=0.0040  test_loss=263.8589  λ_max=6.1102\n",
      "[Muon | lr=0.1] Epoch 3565/4000: train_loss=0.0035  test_loss=264.0872  λ_max=5.3885\n",
      "[Muon | lr=0.1] Epoch 3566/4000: train_loss=0.0046  test_loss=264.1157  λ_max=5.5312\n",
      "[Muon | lr=0.1] Epoch 3567/4000: train_loss=0.0042  test_loss=264.1288  λ_max=5.5484\n",
      "[Muon | lr=0.1] Epoch 3568/4000: train_loss=0.0044  test_loss=264.5482  λ_max=5.5862\n",
      "[Muon | lr=0.1] Iter 57100: loss=0.0154\n",
      "[Muon | lr=0.1] Epoch 3569/4000: train_loss=0.0041  test_loss=264.5834  λ_max=5.7133\n",
      "[Muon | lr=0.1] Epoch 3570/4000: train_loss=0.0041  test_loss=264.7235  λ_max=5.7391\n",
      "[Muon | lr=0.1] Epoch 3571/4000: train_loss=0.0023  test_loss=264.9063  λ_max=5.2664\n",
      "[Muon | lr=0.1] Epoch 3572/4000: train_loss=0.0031  test_loss=264.7076  λ_max=5.6570\n",
      "[Muon | lr=0.1] Epoch 3573/4000: train_loss=0.0036  test_loss=264.8220  λ_max=5.7130\n",
      "[Muon | lr=0.1] Epoch 3574/4000: train_loss=0.0041  test_loss=264.9130  λ_max=5.5090\n",
      "[Muon | lr=0.1] Iter 57200: loss=0.0000\n",
      "[Muon | lr=0.1] Epoch 3575/4000: train_loss=0.0033  test_loss=265.1180  λ_max=5.8824\n",
      "[Muon | lr=0.1] Epoch 3576/4000: train_loss=0.0033  test_loss=265.1775  λ_max=5.6646\n",
      "[Muon | lr=0.1] Epoch 3577/4000: train_loss=0.0037  test_loss=265.3664  λ_max=5.3885\n",
      "[Muon | lr=0.1] Epoch 3578/4000: train_loss=0.0039  test_loss=265.5327  λ_max=4.8762\n",
      "[Muon | lr=0.1] Epoch 3579/4000: train_loss=0.0039  test_loss=265.6273  λ_max=5.0809\n",
      "[Muon | lr=0.1] Epoch 3580/4000: train_loss=0.0040  test_loss=265.6509  λ_max=5.7777\n",
      "[Muon | lr=0.1] Epoch 3581/4000: train_loss=0.0035  test_loss=265.8151  λ_max=5.2872\n",
      "[Muon | lr=0.1] Iter 57300: loss=0.0025\n",
      "[Muon | lr=0.1] Epoch 3582/4000: train_loss=0.0036  test_loss=266.1395  λ_max=5.9741\n",
      "[Muon | lr=0.1] Epoch 3583/4000: train_loss=0.0027  test_loss=266.2587  λ_max=5.7698\n",
      "[Muon | lr=0.1] Epoch 3584/4000: train_loss=0.0040  test_loss=266.2863  λ_max=5.4814\n",
      "[Muon | lr=0.1] Epoch 3585/4000: train_loss=0.0052  test_loss=266.2090  λ_max=5.7035\n",
      "[Muon | lr=0.1] Epoch 3586/4000: train_loss=0.0042  test_loss=266.2660  λ_max=5.4534\n",
      "[Muon | lr=0.1] Epoch 3587/4000: train_loss=0.0031  test_loss=266.1148  λ_max=5.7578\n",
      "[Muon | lr=0.1] Iter 57400: loss=0.0023\n",
      "[Muon | lr=0.1] Epoch 3588/4000: train_loss=0.0031  test_loss=266.0990  λ_max=5.5097\n",
      "[Muon | lr=0.1] Epoch 3589/4000: train_loss=0.0052  test_loss=266.1762  λ_max=5.7509\n",
      "[Muon | lr=0.1] Epoch 3590/4000: train_loss=0.0058  test_loss=266.3322  λ_max=5.7277\n",
      "[Muon | lr=0.1] Epoch 3591/4000: train_loss=0.0040  test_loss=266.0996  λ_max=5.2528\n",
      "[Muon | lr=0.1] Epoch 3592/4000: train_loss=0.0032  test_loss=265.9147  λ_max=5.6307\n",
      "[Muon | lr=0.1] Epoch 3593/4000: train_loss=0.0047  test_loss=266.1184  λ_max=5.5358\n",
      "[Muon | lr=0.1] Iter 57500: loss=0.0071\n",
      "[Muon | lr=0.1] Epoch 3594/4000: train_loss=0.0047  test_loss=266.2240  λ_max=5.3334\n",
      "[Muon | lr=0.1] Epoch 3595/4000: train_loss=0.0041  test_loss=266.1353  λ_max=5.3702\n",
      "[Muon | lr=0.1] Epoch 3596/4000: train_loss=0.0040  test_loss=265.9698  λ_max=5.5774\n",
      "[Muon | lr=0.1] Epoch 3597/4000: train_loss=0.0037  test_loss=265.9643  λ_max=5.9379\n",
      "[Muon | lr=0.1] Epoch 3598/4000: train_loss=0.0035  test_loss=266.1501  λ_max=5.4731\n",
      "[Muon | lr=0.1] Epoch 3599/4000: train_loss=0.0057  test_loss=266.3008  λ_max=5.6994\n",
      "[Muon | lr=0.1] Iter 57600: loss=0.0084\n",
      "[Muon | lr=0.1] Epoch 3600/4000: train_loss=0.0032  test_loss=266.5420  λ_max=6.0392\n",
      "[Muon | lr=0.1] Epoch 3601/4000: train_loss=0.0027  test_loss=266.5547  λ_max=5.6742\n",
      "[Muon | lr=0.1] Epoch 3602/4000: train_loss=0.0042  test_loss=266.5590  λ_max=6.4572\n",
      "[Muon | lr=0.1] Epoch 3603/4000: train_loss=0.0036  test_loss=266.5974  λ_max=5.6871\n",
      "[Muon | lr=0.1] Epoch 3604/4000: train_loss=0.0050  test_loss=267.0986  λ_max=5.7338\n",
      "[Muon | lr=0.1] Epoch 3605/4000: train_loss=0.0041  test_loss=267.1000  λ_max=5.7847\n",
      "[Muon | lr=0.1] Epoch 3606/4000: train_loss=0.0030  test_loss=267.2846  λ_max=6.7622\n",
      "[Muon | lr=0.1] Iter 57700: loss=0.0027\n",
      "[Muon | lr=0.1] Epoch 3607/4000: train_loss=0.0047  test_loss=267.5485  λ_max=6.1732\n",
      "[Muon | lr=0.1] Epoch 3608/4000: train_loss=0.0036  test_loss=267.3331  λ_max=5.3625\n",
      "[Muon | lr=0.1] Epoch 3609/4000: train_loss=0.0051  test_loss=267.1684  λ_max=5.4884\n",
      "[Muon | lr=0.1] Epoch 3610/4000: train_loss=0.0039  test_loss=267.3713  λ_max=6.6081\n",
      "[Muon | lr=0.1] Epoch 3611/4000: train_loss=0.0050  test_loss=267.5369  λ_max=5.5835\n",
      "[Muon | lr=0.1] Epoch 3612/4000: train_loss=0.0039  test_loss=267.4852  λ_max=5.7387\n",
      "[Muon | lr=0.1] Iter 57800: loss=0.0032\n",
      "[Muon | lr=0.1] Epoch 3613/4000: train_loss=0.0036  test_loss=267.3716  λ_max=5.8457\n",
      "[Muon | lr=0.1] Epoch 3614/4000: train_loss=0.0047  test_loss=267.1684  λ_max=5.8603\n",
      "[Muon | lr=0.1] Epoch 3615/4000: train_loss=0.0043  test_loss=266.9055  λ_max=5.5462\n",
      "[Muon | lr=0.1] Epoch 3616/4000: train_loss=0.0046  test_loss=266.8577  λ_max=5.7057\n",
      "[Muon | lr=0.1] Epoch 3617/4000: train_loss=0.0034  test_loss=266.9878  λ_max=4.8824\n",
      "[Muon | lr=0.1] Epoch 3618/4000: train_loss=0.0042  test_loss=267.1986  λ_max=6.1353\n",
      "[Muon | lr=0.1] Iter 57900: loss=0.0078\n",
      "[Muon | lr=0.1] Epoch 3619/4000: train_loss=0.0045  test_loss=267.3818  λ_max=5.1781\n",
      "[Muon | lr=0.1] Epoch 3620/4000: train_loss=0.0041  test_loss=267.5668  λ_max=5.8469\n",
      "[Muon | lr=0.1] Epoch 3621/4000: train_loss=0.0044  test_loss=267.6921  λ_max=5.7408\n",
      "[Muon | lr=0.1] Epoch 3622/4000: train_loss=0.0041  test_loss=267.6415  λ_max=5.7968\n",
      "[Muon | lr=0.1] Epoch 3623/4000: train_loss=0.0030  test_loss=267.6619  λ_max=5.5158\n",
      "[Muon | lr=0.1] Epoch 3624/4000: train_loss=0.0034  test_loss=267.6958  λ_max=6.3695\n",
      "[Muon | lr=0.1] Iter 58000: loss=0.0018\n",
      "[Muon | lr=0.1] Epoch 3625/4000: train_loss=0.0043  test_loss=267.5866  λ_max=5.4810\n",
      "[Muon | lr=0.1] Epoch 3626/4000: train_loss=0.0062  test_loss=267.4354  λ_max=6.0881\n",
      "[Muon | lr=0.1] Epoch 3627/4000: train_loss=0.0036  test_loss=267.5948  λ_max=5.4503\n",
      "[Muon | lr=0.1] Epoch 3628/4000: train_loss=0.0039  test_loss=267.6348  λ_max=5.4902\n",
      "[Muon | lr=0.1] Epoch 3629/4000: train_loss=0.0031  test_loss=267.8741  λ_max=5.4399\n",
      "[Muon | lr=0.1] Epoch 3630/4000: train_loss=0.0036  test_loss=268.1252  λ_max=5.2467\n",
      "[Muon | lr=0.1] Epoch 3631/4000: train_loss=0.0030  test_loss=268.1766  λ_max=5.5992\n",
      "[Muon | lr=0.1] Iter 58100: loss=0.0018\n",
      "[Muon | lr=0.1] Epoch 3632/4000: train_loss=0.0033  test_loss=268.2831  λ_max=5.5168\n",
      "[Muon | lr=0.1] Epoch 3633/4000: train_loss=0.0031  test_loss=268.2304  λ_max=5.7402\n",
      "[Muon | lr=0.1] Epoch 3634/4000: train_loss=0.0047  test_loss=268.1361  λ_max=5.9002\n",
      "[Muon | lr=0.1] Epoch 3635/4000: train_loss=0.0034  test_loss=268.6259  λ_max=6.5129\n",
      "[Muon | lr=0.1] Epoch 3636/4000: train_loss=0.0037  test_loss=268.8599  λ_max=5.5661\n",
      "[Muon | lr=0.1] Epoch 3637/4000: train_loss=0.0035  test_loss=268.8236  λ_max=5.9036\n",
      "[Muon | lr=0.1] Iter 58200: loss=0.0026\n",
      "[Muon | lr=0.1] Epoch 3638/4000: train_loss=0.0036  test_loss=269.0587  λ_max=6.0916\n",
      "[Muon | lr=0.1] Epoch 3639/4000: train_loss=0.0037  test_loss=269.1174  λ_max=5.7526\n",
      "[Muon | lr=0.1] Epoch 3640/4000: train_loss=0.0036  test_loss=268.9822  λ_max=5.7017\n",
      "[Muon | lr=0.1] Epoch 3641/4000: train_loss=0.0063  test_loss=269.1188  λ_max=5.3983\n",
      "[Muon | lr=0.1] Epoch 3642/4000: train_loss=0.0037  test_loss=269.1527  λ_max=5.5352\n",
      "[Muon | lr=0.1] Epoch 3643/4000: train_loss=0.0039  test_loss=269.2304  λ_max=5.7184\n",
      "[Muon | lr=0.1] Iter 58300: loss=0.0018\n",
      "[Muon | lr=0.1] Epoch 3644/4000: train_loss=0.0035  test_loss=269.8752  λ_max=5.7597\n",
      "[Muon | lr=0.1] Epoch 3645/4000: train_loss=0.0047  test_loss=270.2773  λ_max=5.2981\n",
      "[Muon | lr=0.1] Epoch 3646/4000: train_loss=0.0032  test_loss=270.7025  λ_max=5.9263\n",
      "[Muon | lr=0.1] Epoch 3647/4000: train_loss=0.0036  test_loss=270.6026  λ_max=6.2304\n",
      "[Muon | lr=0.1] Epoch 3648/4000: train_loss=0.0036  test_loss=270.4048  λ_max=5.8999\n",
      "[Muon | lr=0.1] Epoch 3649/4000: train_loss=0.0026  test_loss=270.4118  λ_max=5.8978\n",
      "[Muon | lr=0.1] Iter 58400: loss=0.0018\n",
      "[Muon | lr=0.1] Epoch 3650/4000: train_loss=0.0046  test_loss=270.3285  λ_max=5.4262\n",
      "[Muon | lr=0.1] Epoch 3651/4000: train_loss=0.0041  test_loss=270.2905  λ_max=6.0950\n",
      "[Muon | lr=0.1] Epoch 3652/4000: train_loss=0.0040  test_loss=270.7068  λ_max=5.5610\n",
      "[Muon | lr=0.1] Epoch 3653/4000: train_loss=0.0028  test_loss=270.9814  λ_max=6.3195\n",
      "[Muon | lr=0.1] Epoch 3654/4000: train_loss=0.0039  test_loss=271.1750  λ_max=5.9830\n",
      "[Muon | lr=0.1] Epoch 3655/4000: train_loss=0.0033  test_loss=271.2507  λ_max=6.0271\n",
      "[Muon | lr=0.1] Epoch 3656/4000: train_loss=0.0033  test_loss=271.4900  λ_max=5.4180\n",
      "[Muon | lr=0.1] Iter 58500: loss=0.0032\n",
      "[Muon | lr=0.1] Epoch 3657/4000: train_loss=0.0051  test_loss=271.6522  λ_max=5.2259\n",
      "[Muon | lr=0.1] Epoch 3658/4000: train_loss=0.0035  test_loss=271.9218  λ_max=5.2022\n",
      "[Muon | lr=0.1] Epoch 3659/4000: train_loss=0.0034  test_loss=272.1619  λ_max=6.9974\n",
      "[Muon | lr=0.1] Epoch 3660/4000: train_loss=0.0033  test_loss=272.1623  λ_max=5.9537\n",
      "[Muon | lr=0.1] Epoch 3661/4000: train_loss=0.0035  test_loss=272.3177  λ_max=5.5485\n",
      "[Muon | lr=0.1] Epoch 3662/4000: train_loss=0.0038  test_loss=272.1057  λ_max=5.9966\n",
      "[Muon | lr=0.1] Iter 58600: loss=0.0067\n",
      "[Muon | lr=0.1] Epoch 3663/4000: train_loss=0.0045  test_loss=271.8365  λ_max=5.0655\n",
      "[Muon | lr=0.1] Epoch 3664/4000: train_loss=0.0043  test_loss=272.1178  λ_max=5.4612\n",
      "[Muon | lr=0.1] Epoch 3665/4000: train_loss=0.0038  test_loss=272.3283  λ_max=5.6252\n",
      "[Muon | lr=0.1] Epoch 3666/4000: train_loss=0.0035  test_loss=272.3018  λ_max=5.3567\n",
      "[Muon | lr=0.1] Epoch 3667/4000: train_loss=0.0048  test_loss=272.3486  λ_max=5.5003\n",
      "[Muon | lr=0.1] Epoch 3668/4000: train_loss=0.0043  test_loss=272.5508  λ_max=5.5723\n",
      "[Muon | lr=0.1] Iter 58700: loss=0.0026\n",
      "[Muon | lr=0.1] Epoch 3669/4000: train_loss=0.0029  test_loss=272.9645  λ_max=5.5563\n",
      "[Muon | lr=0.1] Epoch 3670/4000: train_loss=0.0043  test_loss=272.9072  λ_max=5.9107\n",
      "[Muon | lr=0.1] Epoch 3671/4000: train_loss=0.0033  test_loss=272.9294  λ_max=5.6780\n",
      "[Muon | lr=0.1] Epoch 3672/4000: train_loss=0.0031  test_loss=273.2137  λ_max=5.9733\n",
      "[Muon | lr=0.1] Epoch 3673/4000: train_loss=0.0036  test_loss=273.4305  λ_max=6.1250\n",
      "[Muon | lr=0.1] Epoch 3674/4000: train_loss=0.0024  test_loss=273.2947  λ_max=5.8725\n",
      "[Muon | lr=0.1] Iter 58800: loss=0.0210\n",
      "[Muon | lr=0.1] Epoch 3675/4000: train_loss=0.0047  test_loss=273.7150  λ_max=6.3558\n",
      "[Muon | lr=0.1] Epoch 3676/4000: train_loss=0.0043  test_loss=273.7184  λ_max=5.5650\n",
      "[Muon | lr=0.1] Epoch 3677/4000: train_loss=0.0041  test_loss=273.9497  λ_max=5.4259\n",
      "[Muon | lr=0.1] Epoch 3678/4000: train_loss=0.0043  test_loss=273.8234  λ_max=5.7115\n",
      "[Muon | lr=0.1] Epoch 3679/4000: train_loss=0.0038  test_loss=273.6625  λ_max=6.0917\n",
      "[Muon | lr=0.1] Epoch 3680/4000: train_loss=0.0032  test_loss=273.9776  λ_max=5.5285\n",
      "[Muon | lr=0.1] Epoch 3681/4000: train_loss=0.0035  test_loss=274.6742  λ_max=5.8857\n",
      "[Muon | lr=0.1] Iter 58900: loss=0.0050\n",
      "[Muon | lr=0.1] Epoch 3682/4000: train_loss=0.0054  test_loss=275.1429  λ_max=5.6373\n",
      "[Muon | lr=0.1] Epoch 3683/4000: train_loss=0.0040  test_loss=275.2868  λ_max=5.3085\n",
      "[Muon | lr=0.1] Epoch 3684/4000: train_loss=0.0033  test_loss=275.3383  λ_max=5.7566\n",
      "[Muon | lr=0.1] Epoch 3685/4000: train_loss=0.0035  test_loss=275.1527  λ_max=7.1202\n",
      "[Muon | lr=0.1] Epoch 3686/4000: train_loss=0.0032  test_loss=275.4509  λ_max=5.4265\n",
      "[Muon | lr=0.1] Epoch 3687/4000: train_loss=0.0042  test_loss=275.6877  λ_max=5.5785\n",
      "[Muon | lr=0.1] Iter 59000: loss=0.0027\n",
      "[Muon | lr=0.1] Epoch 3688/4000: train_loss=0.0035  test_loss=275.6298  λ_max=5.7286\n",
      "[Muon | lr=0.1] Epoch 3689/4000: train_loss=0.0048  test_loss=275.8644  λ_max=5.9494\n",
      "[Muon | lr=0.1] Epoch 3690/4000: train_loss=0.0030  test_loss=275.9574  λ_max=5.3070\n",
      "[Muon | lr=0.1] Epoch 3691/4000: train_loss=0.0033  test_loss=276.0850  λ_max=6.3328\n",
      "[Muon | lr=0.1] Epoch 3692/4000: train_loss=0.0042  test_loss=276.2674  λ_max=5.3517\n",
      "[Muon | lr=0.1] Epoch 3693/4000: train_loss=0.0047  test_loss=276.3395  λ_max=6.0643\n",
      "[Muon | lr=0.1] Iter 59100: loss=0.0062\n",
      "[Muon | lr=0.1] Epoch 3694/4000: train_loss=0.0037  test_loss=276.0461  λ_max=5.6219\n",
      "[Muon | lr=0.1] Epoch 3695/4000: train_loss=0.0031  test_loss=276.2698  λ_max=6.0633\n",
      "[Muon | lr=0.1] Epoch 3696/4000: train_loss=0.0045  test_loss=276.6243  λ_max=5.8052\n",
      "[Muon | lr=0.1] Epoch 3697/4000: train_loss=0.0053  test_loss=276.4691  λ_max=5.1995\n",
      "[Muon | lr=0.1] Epoch 3698/4000: train_loss=0.0047  test_loss=276.4051  λ_max=5.4456\n",
      "[Muon | lr=0.1] Epoch 3699/4000: train_loss=0.0041  test_loss=276.4315  λ_max=6.0676\n",
      "[Muon | lr=0.1] Iter 59200: loss=0.0060\n",
      "[Muon | lr=0.1] Epoch 3700/4000: train_loss=0.0035  test_loss=276.2209  λ_max=6.7194\n",
      "[Muon | lr=0.1] Epoch 3701/4000: train_loss=0.0049  test_loss=275.9205  λ_max=7.3593\n",
      "[Muon | lr=0.1] Epoch 3702/4000: train_loss=0.0041  test_loss=275.7180  λ_max=6.5390\n",
      "[Muon | lr=0.1] Epoch 3703/4000: train_loss=0.0046  test_loss=275.8658  λ_max=6.0654\n",
      "[Muon | lr=0.1] Epoch 3704/4000: train_loss=0.0046  test_loss=275.9355  λ_max=5.9040\n",
      "[Muon | lr=0.1] Epoch 3705/4000: train_loss=0.0039  test_loss=276.0570  λ_max=6.2141\n",
      "[Muon | lr=0.1] Epoch 3706/4000: train_loss=0.0038  test_loss=276.0361  λ_max=5.7264\n",
      "[Muon | lr=0.1] Iter 59300: loss=0.0010\n",
      "[Muon | lr=0.1] Epoch 3707/4000: train_loss=0.0052  test_loss=276.1006  λ_max=5.4911\n",
      "[Muon | lr=0.1] Epoch 3708/4000: train_loss=0.0036  test_loss=276.0564  λ_max=5.7077\n",
      "[Muon | lr=0.1] Epoch 3709/4000: train_loss=0.0031  test_loss=275.8302  λ_max=5.4371\n",
      "[Muon | lr=0.1] Epoch 3710/4000: train_loss=0.0051  test_loss=275.8114  λ_max=6.3452\n",
      "[Muon | lr=0.1] Epoch 3711/4000: train_loss=0.0041  test_loss=275.8588  λ_max=5.4047\n",
      "[Muon | lr=0.1] Epoch 3712/4000: train_loss=0.0031  test_loss=275.8404  λ_max=5.4099\n",
      "[Muon | lr=0.1] Iter 59400: loss=0.0000\n",
      "[Muon | lr=0.1] Epoch 3713/4000: train_loss=0.0039  test_loss=276.0533  λ_max=7.0761\n",
      "[Muon | lr=0.1] Epoch 3714/4000: train_loss=0.0030  test_loss=276.4366  λ_max=6.5221\n",
      "[Muon | lr=0.1] Epoch 3715/4000: train_loss=0.0046  test_loss=276.4539  λ_max=6.5170\n",
      "[Muon | lr=0.1] Epoch 3716/4000: train_loss=0.0046  test_loss=276.4551  λ_max=6.1394\n",
      "[Muon | lr=0.1] Epoch 3717/4000: train_loss=0.0033  test_loss=276.3865  λ_max=6.9984\n",
      "[Muon | lr=0.1] Epoch 3718/4000: train_loss=0.0037  test_loss=276.6109  λ_max=5.6133\n",
      "[Muon | lr=0.1] Iter 59500: loss=0.0059\n",
      "[Muon | lr=0.1] Epoch 3719/4000: train_loss=0.0034  test_loss=276.9359  λ_max=5.7507\n",
      "[Muon | lr=0.1] Epoch 3720/4000: train_loss=0.0034  test_loss=276.8997  λ_max=5.5639\n",
      "[Muon | lr=0.1] Epoch 3721/4000: train_loss=0.0034  test_loss=276.8960  λ_max=5.7873\n",
      "[Muon | lr=0.1] Epoch 3722/4000: train_loss=0.0044  test_loss=276.8747  λ_max=5.2923\n",
      "[Muon | lr=0.1] Epoch 3723/4000: train_loss=0.0055  test_loss=276.9100  λ_max=5.4512\n",
      "[Muon | lr=0.1] Epoch 3724/4000: train_loss=0.0039  test_loss=277.0314  λ_max=5.7735\n",
      "[Muon | lr=0.1] Iter 59600: loss=0.0086\n",
      "[Muon | lr=0.1] Epoch 3725/4000: train_loss=0.0032  test_loss=276.9473  λ_max=5.5780\n",
      "[Muon | lr=0.1] Epoch 3726/4000: train_loss=0.0040  test_loss=276.9688  λ_max=5.8154\n",
      "[Muon | lr=0.1] Epoch 3727/4000: train_loss=0.0037  test_loss=276.9115  λ_max=5.7771\n",
      "[Muon | lr=0.1] Epoch 3728/4000: train_loss=0.0033  test_loss=276.9903  λ_max=6.1324\n",
      "[Muon | lr=0.1] Epoch 3729/4000: train_loss=0.0046  test_loss=276.8752  λ_max=5.8390\n",
      "[Muon | lr=0.1] Epoch 3730/4000: train_loss=0.0049  test_loss=276.7606  λ_max=6.1288\n",
      "[Muon | lr=0.1] Epoch 3731/4000: train_loss=0.0035  test_loss=276.9308  λ_max=5.7850\n",
      "[Muon | lr=0.1] Iter 59700: loss=0.0000\n",
      "[Muon | lr=0.1] Epoch 3732/4000: train_loss=0.0042  test_loss=277.0215  λ_max=5.7656\n",
      "[Muon | lr=0.1] Epoch 3733/4000: train_loss=0.0036  test_loss=277.3743  λ_max=5.5142\n",
      "[Muon | lr=0.1] Epoch 3734/4000: train_loss=0.0036  test_loss=277.5508  λ_max=5.6325\n",
      "[Muon | lr=0.1] Epoch 3735/4000: train_loss=0.0041  test_loss=277.5876  λ_max=5.3108\n",
      "[Muon | lr=0.1] Epoch 3736/4000: train_loss=0.0033  test_loss=277.5676  λ_max=6.0808\n",
      "[Muon | lr=0.1] Epoch 3737/4000: train_loss=0.0034  test_loss=277.9292  λ_max=5.9667\n",
      "[Muon | lr=0.1] Iter 59800: loss=0.0046\n",
      "[Muon | lr=0.1] Epoch 3738/4000: train_loss=0.0033  test_loss=278.1516  λ_max=6.3593\n",
      "[Muon | lr=0.1] Epoch 3739/4000: train_loss=0.0040  test_loss=278.1380  λ_max=5.4796\n",
      "[Muon | lr=0.1] Epoch 3740/4000: train_loss=0.0043  test_loss=278.2856  λ_max=5.6912\n",
      "[Muon | lr=0.1] Epoch 3741/4000: train_loss=0.0048  test_loss=278.2723  λ_max=6.1651\n",
      "[Muon | lr=0.1] Epoch 3742/4000: train_loss=0.0057  test_loss=278.4741  λ_max=6.7109\n",
      "[Muon | lr=0.1] Epoch 3743/4000: train_loss=0.0043  test_loss=278.9239  λ_max=6.3078\n",
      "[Muon | lr=0.1] Iter 59900: loss=0.0095\n",
      "[Muon | lr=0.1] Epoch 3744/4000: train_loss=0.0036  test_loss=278.9005  λ_max=5.6252\n",
      "[Muon | lr=0.1] Epoch 3745/4000: train_loss=0.0044  test_loss=278.9666  λ_max=5.7161\n",
      "[Muon | lr=0.1] Epoch 3746/4000: train_loss=0.0036  test_loss=279.0201  λ_max=5.5749\n",
      "[Muon | lr=0.1] Epoch 3747/4000: train_loss=0.0039  test_loss=279.1783  λ_max=6.2173\n",
      "[Muon | lr=0.1] Epoch 3748/4000: train_loss=0.0036  test_loss=279.5467  λ_max=5.9531\n",
      "[Muon | lr=0.1] Epoch 3749/4000: train_loss=0.0041  test_loss=279.7299  λ_max=5.5535\n",
      "[Muon | lr=0.1] Iter 60000: loss=0.0060\n",
      "[Muon | lr=0.1] Epoch 3750/4000: train_loss=0.0035  test_loss=279.6374  λ_max=5.9002\n",
      "[Muon | lr=0.1] Epoch 3751/4000: train_loss=0.0050  test_loss=279.8755  λ_max=5.3311\n",
      "[Muon | lr=0.1] Epoch 3752/4000: train_loss=0.0029  test_loss=280.0206  λ_max=6.3283\n",
      "[Muon | lr=0.1] Epoch 3753/4000: train_loss=0.0030  test_loss=280.0250  λ_max=6.8493\n",
      "[Muon | lr=0.1] Epoch 3754/4000: train_loss=0.0041  test_loss=279.9674  λ_max=5.7802\n",
      "[Muon | lr=0.1] Epoch 3755/4000: train_loss=0.0034  test_loss=280.2146  λ_max=6.0802\n",
      "[Muon | lr=0.1] Epoch 3756/4000: train_loss=0.0042  test_loss=280.3248  λ_max=5.7162\n",
      "[Muon | lr=0.1] Iter 60100: loss=0.0005\n",
      "[Muon | lr=0.1] Epoch 3757/4000: train_loss=0.0030  test_loss=280.3887  λ_max=5.5809\n",
      "[Muon | lr=0.1] Epoch 3758/4000: train_loss=0.0032  test_loss=280.4132  λ_max=5.0593\n",
      "[Muon | lr=0.1] Epoch 3759/4000: train_loss=0.0034  test_loss=280.4498  λ_max=5.5129\n",
      "[Muon | lr=0.1] Epoch 3760/4000: train_loss=0.0032  test_loss=280.4481  λ_max=5.5281\n",
      "[Muon | lr=0.1] Epoch 3761/4000: train_loss=0.0044  test_loss=280.8737  λ_max=5.9815\n",
      "[Muon | lr=0.1] Epoch 3762/4000: train_loss=0.0026  test_loss=281.1843  λ_max=5.5754\n",
      "[Muon | lr=0.1] Iter 60200: loss=0.0029\n",
      "[Muon | lr=0.1] Epoch 3763/4000: train_loss=0.0048  test_loss=281.1970  λ_max=5.2935\n",
      "[Muon | lr=0.1] Epoch 3764/4000: train_loss=0.0040  test_loss=281.2306  λ_max=6.3457\n",
      "[Muon | lr=0.1] Epoch 3765/4000: train_loss=0.0035  test_loss=281.4247  λ_max=5.7784\n",
      "[Muon | lr=0.1] Epoch 3766/4000: train_loss=0.0037  test_loss=281.2470  λ_max=6.3858\n",
      "[Muon | lr=0.1] Epoch 3767/4000: train_loss=0.0034  test_loss=281.1616  λ_max=5.7276\n",
      "[Muon | lr=0.1] Epoch 3768/4000: train_loss=0.0043  test_loss=281.0208  λ_max=5.6815\n",
      "[Muon | lr=0.1] Iter 60300: loss=0.0052\n",
      "[Muon | lr=0.1] Epoch 3769/4000: train_loss=0.0040  test_loss=280.7601  λ_max=5.9234\n",
      "[Muon | lr=0.1] Epoch 3770/4000: train_loss=0.0034  test_loss=281.0238  λ_max=5.6690\n",
      "[Muon | lr=0.1] Epoch 3771/4000: train_loss=0.0032  test_loss=281.4960  λ_max=7.3259\n",
      "[Muon | lr=0.1] Epoch 3772/4000: train_loss=0.0044  test_loss=281.7438  λ_max=5.7482\n",
      "[Muon | lr=0.1] Epoch 3773/4000: train_loss=0.0038  test_loss=282.1601  λ_max=6.0596\n",
      "[Muon | lr=0.1] Epoch 3774/4000: train_loss=0.0049  test_loss=282.4021  λ_max=5.9498\n",
      "[Muon | lr=0.1] Iter 60400: loss=0.0044\n",
      "[Muon | lr=0.1] Epoch 3775/4000: train_loss=0.0045  test_loss=282.4503  λ_max=5.5083\n",
      "[Muon | lr=0.1] Epoch 3776/4000: train_loss=0.0041  test_loss=282.5450  λ_max=5.5742\n",
      "[Muon | lr=0.1] Epoch 3777/4000: train_loss=0.0040  test_loss=282.7944  λ_max=5.8116\n",
      "[Muon | lr=0.1] Epoch 3778/4000: train_loss=0.0036  test_loss=282.9373  λ_max=6.3475\n",
      "[Muon | lr=0.1] Epoch 3779/4000: train_loss=0.0044  test_loss=282.9558  λ_max=5.2351\n",
      "[Muon | lr=0.1] Epoch 3780/4000: train_loss=0.0041  test_loss=282.9212  λ_max=5.7512\n",
      "[Muon | lr=0.1] Epoch 3781/4000: train_loss=0.0027  test_loss=283.1805  λ_max=5.7588\n",
      "[Muon | lr=0.1] Iter 60500: loss=0.0009\n",
      "[Muon | lr=0.1] Epoch 3782/4000: train_loss=0.0039  test_loss=283.3511  λ_max=5.8279\n",
      "[Muon | lr=0.1] Epoch 3783/4000: train_loss=0.0037  test_loss=283.1366  λ_max=6.4477\n",
      "[Muon | lr=0.1] Epoch 3784/4000: train_loss=0.0049  test_loss=283.4260  λ_max=6.1069\n",
      "[Muon | lr=0.1] Epoch 3785/4000: train_loss=0.0048  test_loss=283.2607  λ_max=6.0994\n",
      "[Muon | lr=0.1] Epoch 3786/4000: train_loss=0.0039  test_loss=282.8565  λ_max=5.3544\n",
      "[Muon | lr=0.1] Epoch 3787/4000: train_loss=0.0032  test_loss=282.6661  λ_max=5.5852\n",
      "[Muon | lr=0.1] Iter 60600: loss=0.0045\n",
      "[Muon | lr=0.1] Epoch 3788/4000: train_loss=0.0032  test_loss=282.7305  λ_max=6.8352\n",
      "[Muon | lr=0.1] Epoch 3789/4000: train_loss=0.0030  test_loss=283.0241  λ_max=6.4691\n",
      "[Muon | lr=0.1] Epoch 3790/4000: train_loss=0.0040  test_loss=283.1387  λ_max=6.1053\n",
      "[Muon | lr=0.1] Epoch 3791/4000: train_loss=0.0038  test_loss=283.2851  λ_max=6.6057\n",
      "[Muon | lr=0.1] Epoch 3792/4000: train_loss=0.0044  test_loss=283.4987  λ_max=5.4716\n",
      "[Muon | lr=0.1] Epoch 3793/4000: train_loss=0.0036  test_loss=283.4924  λ_max=6.1287\n",
      "[Muon | lr=0.1] Iter 60700: loss=0.0000\n",
      "[Muon | lr=0.1] Epoch 3794/4000: train_loss=0.0031  test_loss=283.7506  λ_max=5.9444\n",
      "[Muon | lr=0.1] Epoch 3795/4000: train_loss=0.0047  test_loss=283.9495  λ_max=6.1562\n",
      "[Muon | lr=0.1] Epoch 3796/4000: train_loss=0.0035  test_loss=284.5779  λ_max=5.9381\n",
      "[Muon | lr=0.1] Epoch 3797/4000: train_loss=0.0045  test_loss=284.7357  λ_max=5.5861\n",
      "[Muon | lr=0.1] Epoch 3798/4000: train_loss=0.0040  test_loss=284.5454  λ_max=6.0950\n",
      "[Muon | lr=0.1] Epoch 3799/4000: train_loss=0.0033  test_loss=284.4512  λ_max=6.0386\n",
      "[Muon | lr=0.1] Iter 60800: loss=0.0019\n",
      "[Muon | lr=0.1] Epoch 3800/4000: train_loss=0.0051  test_loss=284.3704  λ_max=6.0875\n",
      "[Muon | lr=0.1] Epoch 3801/4000: train_loss=0.0035  test_loss=284.4155  λ_max=5.4421\n",
      "[Muon | lr=0.1] Epoch 3802/4000: train_loss=0.0039  test_loss=284.0549  λ_max=6.0923\n",
      "[Muon | lr=0.1] Epoch 3803/4000: train_loss=0.0040  test_loss=283.9496  λ_max=6.3781\n",
      "[Muon | lr=0.1] Epoch 3804/4000: train_loss=0.0038  test_loss=284.1032  λ_max=6.1823\n",
      "[Muon | lr=0.1] Epoch 3805/4000: train_loss=0.0055  test_loss=284.2682  λ_max=5.4197\n",
      "[Muon | lr=0.1] Epoch 3806/4000: train_loss=0.0046  test_loss=284.4303  λ_max=5.7091\n",
      "[Muon | lr=0.1] Iter 60900: loss=0.0025\n",
      "[Muon | lr=0.1] Epoch 3807/4000: train_loss=0.0030  test_loss=284.5100  λ_max=6.1405\n",
      "[Muon | lr=0.1] Epoch 3808/4000: train_loss=0.0041  test_loss=284.4057  λ_max=5.7244\n",
      "[Muon | lr=0.1] Epoch 3809/4000: train_loss=0.0041  test_loss=284.4411  λ_max=5.5802\n",
      "[Muon | lr=0.1] Epoch 3810/4000: train_loss=0.0042  test_loss=284.6384  λ_max=6.2371\n",
      "[Muon | lr=0.1] Epoch 3811/4000: train_loss=0.0033  test_loss=284.7087  λ_max=5.4213\n",
      "[Muon | lr=0.1] Epoch 3812/4000: train_loss=0.0048  test_loss=284.9902  λ_max=5.9805\n",
      "[Muon | lr=0.1] Iter 61000: loss=0.0039\n",
      "[Muon | lr=0.1] Epoch 3813/4000: train_loss=0.0029  test_loss=285.3481  λ_max=5.8618\n",
      "[Muon | lr=0.1] Epoch 3814/4000: train_loss=0.0039  test_loss=285.6209  λ_max=6.3349\n",
      "[Muon | lr=0.1] Epoch 3815/4000: train_loss=0.0033  test_loss=285.7632  λ_max=6.2816\n",
      "[Muon | lr=0.1] Epoch 3816/4000: train_loss=0.0036  test_loss=285.5983  λ_max=5.7076\n",
      "[Muon | lr=0.1] Epoch 3817/4000: train_loss=0.0035  test_loss=285.4879  λ_max=5.7489\n",
      "[Muon | lr=0.1] Epoch 3818/4000: train_loss=0.0048  test_loss=285.3803  λ_max=5.9849\n",
      "[Muon | lr=0.1] Iter 61100: loss=0.0037\n",
      "[Muon | lr=0.1] Epoch 3819/4000: train_loss=0.0049  test_loss=285.5779  λ_max=5.6245\n",
      "[Muon | lr=0.1] Epoch 3820/4000: train_loss=0.0047  test_loss=285.7870  λ_max=6.2209\n",
      "[Muon | lr=0.1] Epoch 3821/4000: train_loss=0.0040  test_loss=285.9680  λ_max=5.7245\n",
      "[Muon | lr=0.1] Epoch 3822/4000: train_loss=0.0028  test_loss=286.0240  λ_max=5.9296\n",
      "[Muon | lr=0.1] Epoch 3823/4000: train_loss=0.0029  test_loss=286.1867  λ_max=5.4257\n",
      "[Muon | lr=0.1] Epoch 3824/4000: train_loss=0.0032  test_loss=286.4871  λ_max=5.5849\n",
      "[Muon | lr=0.1] Iter 61200: loss=0.0179\n",
      "[Muon | lr=0.1] Epoch 3825/4000: train_loss=0.0052  test_loss=286.7365  λ_max=5.4559\n",
      "[Muon | lr=0.1] Epoch 3826/4000: train_loss=0.0026  test_loss=286.6796  λ_max=5.4069\n",
      "[Muon | lr=0.1] Epoch 3827/4000: train_loss=0.0045  test_loss=286.7851  λ_max=6.3035\n",
      "[Muon | lr=0.1] Epoch 3828/4000: train_loss=0.0036  test_loss=287.1323  λ_max=6.0317\n",
      "[Muon | lr=0.1] Epoch 3829/4000: train_loss=0.0046  test_loss=287.2504  λ_max=5.8949\n",
      "[Muon | lr=0.1] Epoch 3830/4000: train_loss=0.0035  test_loss=287.1718  λ_max=5.8476\n",
      "[Muon | lr=0.1] Epoch 3831/4000: train_loss=0.0036  test_loss=287.1723  λ_max=5.0640\n",
      "[Muon | lr=0.1] Iter 61300: loss=0.0005\n",
      "[Muon | lr=0.1] Epoch 3832/4000: train_loss=0.0035  test_loss=286.8910  λ_max=6.1442\n",
      "[Muon | lr=0.1] Epoch 3833/4000: train_loss=0.0045  test_loss=286.7182  λ_max=5.9863\n",
      "[Muon | lr=0.1] Epoch 3834/4000: train_loss=0.0042  test_loss=287.0261  λ_max=6.2929\n",
      "[Muon | lr=0.1] Epoch 3835/4000: train_loss=0.0038  test_loss=287.2355  λ_max=6.2299\n",
      "[Muon | lr=0.1] Epoch 3836/4000: train_loss=0.0040  test_loss=287.4463  λ_max=5.7671\n",
      "[Muon | lr=0.1] Epoch 3837/4000: train_loss=0.0042  test_loss=287.8419  λ_max=5.9828\n",
      "[Muon | lr=0.1] Iter 61400: loss=0.0075\n",
      "[Muon | lr=0.1] Epoch 3838/4000: train_loss=0.0050  test_loss=287.9641  λ_max=6.2937\n",
      "[Muon | lr=0.1] Epoch 3839/4000: train_loss=0.0037  test_loss=288.0702  λ_max=6.4158\n",
      "[Muon | lr=0.1] Epoch 3840/4000: train_loss=0.0039  test_loss=287.6983  λ_max=6.1925\n",
      "[Muon | lr=0.1] Epoch 3841/4000: train_loss=0.0032  test_loss=287.8350  λ_max=6.0566\n",
      "[Muon | lr=0.1] Epoch 3842/4000: train_loss=0.0045  test_loss=288.0842  λ_max=5.9731\n",
      "[Muon | lr=0.1] Epoch 3843/4000: train_loss=0.0026  test_loss=288.4149  λ_max=6.2157\n",
      "[Muon | lr=0.1] Iter 61500: loss=0.0042\n",
      "[Muon | lr=0.1] Epoch 3844/4000: train_loss=0.0057  test_loss=288.4805  λ_max=6.2995\n",
      "[Muon | lr=0.1] Epoch 3845/4000: train_loss=0.0041  test_loss=288.2432  λ_max=6.1571\n",
      "[Muon | lr=0.1] Epoch 3846/4000: train_loss=0.0045  test_loss=288.0933  λ_max=5.8744\n",
      "[Muon | lr=0.1] Epoch 3847/4000: train_loss=0.0037  test_loss=287.9917  λ_max=5.9075\n",
      "[Muon | lr=0.1] Epoch 3848/4000: train_loss=0.0050  test_loss=287.9188  λ_max=6.0138\n",
      "[Muon | lr=0.1] Epoch 3849/4000: train_loss=0.0053  test_loss=288.0554  λ_max=6.5383\n",
      "[Muon | lr=0.1] Iter 61600: loss=0.0002\n",
      "[Muon | lr=0.1] Epoch 3850/4000: train_loss=0.0037  test_loss=287.9099  λ_max=6.0100\n",
      "[Muon | lr=0.1] Epoch 3851/4000: train_loss=0.0026  test_loss=287.7870  λ_max=5.7600\n",
      "[Muon | lr=0.1] Epoch 3852/4000: train_loss=0.0030  test_loss=287.8992  λ_max=5.9342\n",
      "[Muon | lr=0.1] Epoch 3853/4000: train_loss=0.0039  test_loss=287.9957  λ_max=5.7016\n",
      "[Muon | lr=0.1] Epoch 3854/4000: train_loss=0.0032  test_loss=288.0864  λ_max=6.7508\n",
      "[Muon | lr=0.1] Epoch 3855/4000: train_loss=0.0035  test_loss=288.0254  λ_max=6.8140\n",
      "[Muon | lr=0.1] Epoch 3856/4000: train_loss=0.0043  test_loss=287.9495  λ_max=6.1038\n",
      "[Muon | lr=0.1] Iter 61700: loss=0.0016\n",
      "[Muon | lr=0.1] Epoch 3857/4000: train_loss=0.0024  test_loss=287.7997  λ_max=5.7857\n",
      "[Muon | lr=0.1] Epoch 3858/4000: train_loss=0.0043  test_loss=287.7809  λ_max=6.0189\n",
      "[Muon | lr=0.1] Epoch 3859/4000: train_loss=0.0043  test_loss=287.7145  λ_max=5.8731\n",
      "[Muon | lr=0.1] Epoch 3860/4000: train_loss=0.0030  test_loss=287.6094  λ_max=6.4345\n",
      "[Muon | lr=0.1] Epoch 3861/4000: train_loss=0.0044  test_loss=287.5874  λ_max=5.5413\n",
      "[Muon | lr=0.1] Epoch 3862/4000: train_loss=0.0037  test_loss=287.6995  λ_max=5.9951\n",
      "[Muon | lr=0.1] Iter 61800: loss=0.0016\n",
      "[Muon | lr=0.1] Epoch 3863/4000: train_loss=0.0026  test_loss=287.9685  λ_max=6.2584\n",
      "[Muon | lr=0.1] Epoch 3864/4000: train_loss=0.0037  test_loss=288.1310  λ_max=6.4713\n",
      "[Muon | lr=0.1] Epoch 3865/4000: train_loss=0.0043  test_loss=287.9658  λ_max=5.8628\n",
      "[Muon | lr=0.1] Epoch 3866/4000: train_loss=0.0047  test_loss=288.1688  λ_max=5.6438\n",
      "[Muon | lr=0.1] Epoch 3867/4000: train_loss=0.0040  test_loss=288.6394  λ_max=5.6691\n",
      "[Muon | lr=0.1] Epoch 3868/4000: train_loss=0.0040  test_loss=289.1972  λ_max=6.1623\n",
      "[Muon | lr=0.1] Iter 61900: loss=0.0105\n",
      "[Muon | lr=0.1] Epoch 3869/4000: train_loss=0.0047  test_loss=289.7991  λ_max=6.0381\n",
      "[Muon | lr=0.1] Epoch 3870/4000: train_loss=0.0043  test_loss=289.9992  λ_max=5.7000\n",
      "[Muon | lr=0.1] Epoch 3871/4000: train_loss=0.0042  test_loss=289.9251  λ_max=5.7146\n",
      "[Muon | lr=0.1] Epoch 3872/4000: train_loss=0.0033  test_loss=289.6037  λ_max=6.1502\n",
      "[Muon | lr=0.1] Epoch 3873/4000: train_loss=0.0044  test_loss=289.5315  λ_max=6.4412\n",
      "[Muon | lr=0.1] Epoch 3874/4000: train_loss=0.0030  test_loss=289.5198  λ_max=5.4638\n",
      "[Muon | lr=0.1] Iter 62000: loss=0.0142\n",
      "[Muon | lr=0.1] Epoch 3875/4000: train_loss=0.0039  test_loss=289.3538  λ_max=6.2622\n",
      "[Muon | lr=0.1] Epoch 3876/4000: train_loss=0.0037  test_loss=289.1634  λ_max=5.8849\n",
      "[Muon | lr=0.1] Epoch 3877/4000: train_loss=0.0051  test_loss=289.3763  λ_max=6.4174\n",
      "[Muon | lr=0.1] Epoch 3878/4000: train_loss=0.0052  test_loss=289.5269  λ_max=5.7666\n",
      "[Muon | lr=0.1] Epoch 3879/4000: train_loss=0.0043  test_loss=289.4246  λ_max=6.2948\n",
      "[Muon | lr=0.1] Epoch 3880/4000: train_loss=0.0038  test_loss=289.6284  λ_max=6.7356\n",
      "[Muon | lr=0.1] Epoch 3881/4000: train_loss=0.0041  test_loss=289.8405  λ_max=6.1031\n",
      "[Muon | lr=0.1] Iter 62100: loss=0.0016\n",
      "[Muon | lr=0.1] Epoch 3882/4000: train_loss=0.0047  test_loss=289.8626  λ_max=6.4319\n",
      "[Muon | lr=0.1] Epoch 3883/4000: train_loss=0.0031  test_loss=290.0084  λ_max=7.0855\n",
      "[Muon | lr=0.1] Epoch 3884/4000: train_loss=0.0039  test_loss=289.9959  λ_max=6.5900\n",
      "[Muon | lr=0.1] Epoch 3885/4000: train_loss=0.0051  test_loss=289.9056  λ_max=6.0778\n",
      "[Muon | lr=0.1] Epoch 3886/4000: train_loss=0.0046  test_loss=289.7403  λ_max=6.1434\n",
      "[Muon | lr=0.1] Epoch 3887/4000: train_loss=0.0031  test_loss=289.5327  λ_max=6.9362\n",
      "[Muon | lr=0.1] Iter 62200: loss=0.0008\n",
      "[Muon | lr=0.1] Epoch 3888/4000: train_loss=0.0026  test_loss=289.8557  λ_max=6.0093\n",
      "[Muon | lr=0.1] Epoch 3889/4000: train_loss=0.0038  test_loss=290.0703  λ_max=6.3566\n",
      "[Muon | lr=0.1] Epoch 3890/4000: train_loss=0.0040  test_loss=289.8506  λ_max=6.4974\n",
      "[Muon | lr=0.1] Epoch 3891/4000: train_loss=0.0034  test_loss=289.7804  λ_max=6.0392\n",
      "[Muon | lr=0.1] Epoch 3892/4000: train_loss=0.0031  test_loss=290.2223  λ_max=6.3010\n",
      "[Muon | lr=0.1] Epoch 3893/4000: train_loss=0.0043  test_loss=290.5662  λ_max=5.7806\n",
      "[Muon | lr=0.1] Iter 62300: loss=0.0093\n",
      "[Muon | lr=0.1] Epoch 3894/4000: train_loss=0.0059  test_loss=290.5001  λ_max=6.9251\n",
      "[Muon | lr=0.1] Epoch 3895/4000: train_loss=0.0030  test_loss=290.8232  λ_max=5.9562\n",
      "[Muon | lr=0.1] Epoch 3896/4000: train_loss=0.0035  test_loss=290.7653  λ_max=5.9520\n",
      "[Muon | lr=0.1] Epoch 3897/4000: train_loss=0.0027  test_loss=290.8726  λ_max=6.1859\n",
      "[Muon | lr=0.1] Epoch 3898/4000: train_loss=0.0035  test_loss=290.9988  λ_max=5.4322\n",
      "[Muon | lr=0.1] Epoch 3899/4000: train_loss=0.0038  test_loss=291.2865  λ_max=6.1561\n",
      "[Muon | lr=0.1] Iter 62400: loss=0.0050\n",
      "[Muon | lr=0.1] Epoch 3900/4000: train_loss=0.0036  test_loss=291.2523  λ_max=5.9422\n",
      "[Muon | lr=0.1] Epoch 3901/4000: train_loss=0.0039  test_loss=291.4094  λ_max=5.5812\n",
      "[Muon | lr=0.1] Epoch 3902/4000: train_loss=0.0030  test_loss=291.7542  λ_max=5.6506\n",
      "[Muon | lr=0.1] Epoch 3903/4000: train_loss=0.0061  test_loss=291.9276  λ_max=7.0185\n",
      "[Muon | lr=0.1] Epoch 3904/4000: train_loss=0.0044  test_loss=291.8573  λ_max=5.8160\n",
      "[Muon | lr=0.1] Epoch 3905/4000: train_loss=0.0042  test_loss=292.0256  λ_max=5.9569\n",
      "[Muon | lr=0.1] Epoch 3906/4000: train_loss=0.0033  test_loss=292.1620  λ_max=6.1751\n",
      "[Muon | lr=0.1] Iter 62500: loss=0.0012\n",
      "[Muon | lr=0.1] Epoch 3907/4000: train_loss=0.0028  test_loss=292.0606  λ_max=5.9183\n",
      "[Muon | lr=0.1] Epoch 3908/4000: train_loss=0.0040  test_loss=292.0609  λ_max=5.9893\n",
      "[Muon | lr=0.1] Epoch 3909/4000: train_loss=0.0041  test_loss=292.3235  λ_max=5.8291\n",
      "[Muon | lr=0.1] Epoch 3910/4000: train_loss=0.0037  test_loss=292.6222  λ_max=5.9200\n",
      "[Muon | lr=0.1] Epoch 3911/4000: train_loss=0.0022  test_loss=292.9492  λ_max=6.1082\n",
      "[Muon | lr=0.1] Epoch 3912/4000: train_loss=0.0031  test_loss=293.0620  λ_max=6.2525\n",
      "[Muon | lr=0.1] Iter 62600: loss=0.0015\n",
      "[Muon | lr=0.1] Epoch 3913/4000: train_loss=0.0035  test_loss=293.1330  λ_max=5.4585\n",
      "[Muon | lr=0.1] Epoch 3914/4000: train_loss=0.0036  test_loss=293.1476  λ_max=6.5813\n",
      "[Muon | lr=0.1] Epoch 3915/4000: train_loss=0.0035  test_loss=293.3647  λ_max=5.8951\n",
      "[Muon | lr=0.1] Epoch 3916/4000: train_loss=0.0046  test_loss=293.5218  λ_max=5.7417\n",
      "[Muon | lr=0.1] Epoch 3917/4000: train_loss=0.0028  test_loss=293.7542  λ_max=5.6983\n",
      "[Muon | lr=0.1] Epoch 3918/4000: train_loss=0.0035  test_loss=293.8684  λ_max=6.9634\n",
      "[Muon | lr=0.1] Iter 62700: loss=0.0010\n",
      "[Muon | lr=0.1] Epoch 3919/4000: train_loss=0.0027  test_loss=293.8594  λ_max=6.0714\n",
      "[Muon | lr=0.1] Epoch 3920/4000: train_loss=0.0054  test_loss=294.2207  λ_max=6.4733\n",
      "[Muon | lr=0.1] Epoch 3921/4000: train_loss=0.0035  test_loss=294.7132  λ_max=6.3369\n",
      "[Muon | lr=0.1] Epoch 3922/4000: train_loss=0.0044  test_loss=294.6859  λ_max=6.0137\n",
      "[Muon | lr=0.1] Epoch 3923/4000: train_loss=0.0033  test_loss=294.9375  λ_max=6.4209\n",
      "[Muon | lr=0.1] Epoch 3924/4000: train_loss=0.0044  test_loss=295.2872  λ_max=6.3262\n",
      "[Muon | lr=0.1] Iter 62800: loss=0.0038\n",
      "[Muon | lr=0.1] Epoch 3925/4000: train_loss=0.0024  test_loss=295.6911  λ_max=6.3080\n",
      "[Muon | lr=0.1] Epoch 3926/4000: train_loss=0.0047  test_loss=295.7202  λ_max=6.5314\n",
      "[Muon | lr=0.1] Epoch 3927/4000: train_loss=0.0048  test_loss=295.5294  λ_max=7.2189\n",
      "[Muon | lr=0.1] Epoch 3928/4000: train_loss=0.0032  test_loss=295.5874  λ_max=5.6575\n",
      "[Muon | lr=0.1] Epoch 3929/4000: train_loss=0.0035  test_loss=295.5372  λ_max=6.3199\n",
      "[Muon | lr=0.1] Epoch 3930/4000: train_loss=0.0033  test_loss=295.0935  λ_max=7.2473\n",
      "[Muon | lr=0.1] Epoch 3931/4000: train_loss=0.0027  test_loss=295.0139  λ_max=6.2251\n",
      "[Muon | lr=0.1] Iter 62900: loss=0.0006\n",
      "[Muon | lr=0.1] Epoch 3932/4000: train_loss=0.0047  test_loss=295.0456  λ_max=6.1312\n",
      "[Muon | lr=0.1] Epoch 3933/4000: train_loss=0.0039  test_loss=295.1730  λ_max=7.0313\n",
      "[Muon | lr=0.1] Epoch 3934/4000: train_loss=0.0045  test_loss=295.0650  λ_max=5.7766\n",
      "[Muon | lr=0.1] Epoch 3935/4000: train_loss=0.0040  test_loss=295.1077  λ_max=6.2979\n",
      "[Muon | lr=0.1] Epoch 3936/4000: train_loss=0.0035  test_loss=295.2050  λ_max=6.6000\n",
      "[Muon | lr=0.1] Epoch 3937/4000: train_loss=0.0042  test_loss=295.1848  λ_max=6.8130\n",
      "[Muon | lr=0.1] Iter 63000: loss=0.0024\n",
      "[Muon | lr=0.1] Epoch 3938/4000: train_loss=0.0033  test_loss=295.2014  λ_max=5.8724\n",
      "[Muon | lr=0.1] Epoch 3939/4000: train_loss=0.0044  test_loss=295.1539  λ_max=5.9945\n",
      "[Muon | lr=0.1] Epoch 3940/4000: train_loss=0.0032  test_loss=295.1530  λ_max=6.1882\n",
      "[Muon | lr=0.1] Epoch 3941/4000: train_loss=0.0042  test_loss=295.5323  λ_max=5.6853\n",
      "[Muon | lr=0.1] Epoch 3942/4000: train_loss=0.0046  test_loss=295.4231  λ_max=6.3296\n",
      "[Muon | lr=0.1] Epoch 3943/4000: train_loss=0.0028  test_loss=295.6830  λ_max=6.1907\n",
      "[Muon | lr=0.1] Iter 63100: loss=0.0009\n",
      "[Muon | lr=0.1] Epoch 3944/4000: train_loss=0.0027  test_loss=295.7830  λ_max=5.7162\n",
      "[Muon | lr=0.1] Epoch 3945/4000: train_loss=0.0038  test_loss=296.4055  λ_max=5.9280\n",
      "[Muon | lr=0.1] Epoch 3946/4000: train_loss=0.0046  test_loss=296.4860  λ_max=5.6418\n",
      "[Muon | lr=0.1] Epoch 3947/4000: train_loss=0.0041  test_loss=296.7973  λ_max=5.8183\n",
      "[Muon | lr=0.1] Epoch 3948/4000: train_loss=0.0046  test_loss=297.0126  λ_max=6.5054\n",
      "[Muon | lr=0.1] Epoch 3949/4000: train_loss=0.0040  test_loss=297.0367  λ_max=5.7589\n",
      "[Muon | lr=0.1] Iter 63200: loss=0.0000\n",
      "[Muon | lr=0.1] Epoch 3950/4000: train_loss=0.0041  test_loss=296.8396  λ_max=5.4174\n",
      "[Muon | lr=0.1] Epoch 3951/4000: train_loss=0.0041  test_loss=296.8401  λ_max=6.0825\n",
      "[Muon | lr=0.1] Epoch 3952/4000: train_loss=0.0050  test_loss=296.7502  λ_max=5.7669\n",
      "[Muon | lr=0.1] Epoch 3953/4000: train_loss=0.0027  test_loss=296.4906  λ_max=5.9591\n",
      "[Muon | lr=0.1] Epoch 3954/4000: train_loss=0.0032  test_loss=297.0116  λ_max=5.6535\n",
      "[Muon | lr=0.1] Epoch 3955/4000: train_loss=0.0034  test_loss=297.4422  λ_max=6.4502\n",
      "[Muon | lr=0.1] Epoch 3956/4000: train_loss=0.0045  test_loss=297.9288  λ_max=5.8548\n",
      "[Muon | lr=0.1] Iter 63300: loss=0.0029\n",
      "[Muon | lr=0.1] Epoch 3957/4000: train_loss=0.0034  test_loss=298.2393  λ_max=6.4087\n",
      "[Muon | lr=0.1] Epoch 3958/4000: train_loss=0.0036  test_loss=298.5749  λ_max=5.9146\n",
      "[Muon | lr=0.1] Epoch 3959/4000: train_loss=0.0038  test_loss=298.3735  λ_max=5.8065\n",
      "[Muon | lr=0.1] Epoch 3960/4000: train_loss=0.0038  test_loss=298.3568  λ_max=6.0370\n",
      "[Muon | lr=0.1] Epoch 3961/4000: train_loss=0.0047  test_loss=298.3202  λ_max=5.8001\n",
      "[Muon | lr=0.1] Epoch 3962/4000: train_loss=0.0037  test_loss=298.5024  λ_max=5.6442\n",
      "[Muon | lr=0.1] Iter 63400: loss=0.0083\n",
      "[Muon | lr=0.1] Epoch 3963/4000: train_loss=0.0045  test_loss=298.5663  λ_max=5.7827\n",
      "[Muon | lr=0.1] Epoch 3964/4000: train_loss=0.0038  test_loss=298.3266  λ_max=5.9326\n",
      "[Muon | lr=0.1] Epoch 3965/4000: train_loss=0.0040  test_loss=298.2093  λ_max=6.0938\n",
      "[Muon | lr=0.1] Epoch 3966/4000: train_loss=0.0033  test_loss=298.3249  λ_max=6.7639\n",
      "[Muon | lr=0.1] Epoch 3967/4000: train_loss=0.0036  test_loss=298.1622  λ_max=4.9843\n",
      "[Muon | lr=0.1] Epoch 3968/4000: train_loss=0.0044  test_loss=298.5434  λ_max=6.2989\n",
      "[Muon | lr=0.1] Iter 63500: loss=0.0040\n",
      "[Muon | lr=0.1] Epoch 3969/4000: train_loss=0.0040  test_loss=298.8734  λ_max=6.2122\n",
      "[Muon | lr=0.1] Epoch 3970/4000: train_loss=0.0024  test_loss=298.9267  λ_max=5.7658\n",
      "[Muon | lr=0.1] Epoch 3971/4000: train_loss=0.0029  test_loss=299.1636  λ_max=5.8780\n",
      "[Muon | lr=0.1] Epoch 3972/4000: train_loss=0.0052  test_loss=299.2074  λ_max=6.0415\n",
      "[Muon | lr=0.1] Epoch 3973/4000: train_loss=0.0034  test_loss=299.0243  λ_max=5.2001\n",
      "[Muon | lr=0.1] Epoch 3974/4000: train_loss=0.0045  test_loss=299.1393  λ_max=6.1626\n",
      "[Muon | lr=0.1] Iter 63600: loss=0.0096\n",
      "[Muon | lr=0.1] Epoch 3975/4000: train_loss=0.0042  test_loss=299.1387  λ_max=6.2597\n",
      "[Muon | lr=0.1] Epoch 3976/4000: train_loss=0.0029  test_loss=299.1691  λ_max=6.1818\n",
      "[Muon | lr=0.1] Epoch 3977/4000: train_loss=0.0040  test_loss=299.3406  λ_max=7.1697\n",
      "[Muon | lr=0.1] Epoch 3978/4000: train_loss=0.0043  test_loss=299.3892  λ_max=5.9893\n",
      "[Muon | lr=0.1] Epoch 3979/4000: train_loss=0.0038  test_loss=299.8047  λ_max=5.7154\n",
      "[Muon | lr=0.1] Epoch 3980/4000: train_loss=0.0032  test_loss=299.9262  λ_max=5.6177\n",
      "[Muon | lr=0.1] Epoch 3981/4000: train_loss=0.0032  test_loss=299.9353  λ_max=6.6752\n",
      "[Muon | lr=0.1] Iter 63700: loss=0.0000\n",
      "[Muon | lr=0.1] Epoch 3982/4000: train_loss=0.0029  test_loss=299.6031  λ_max=5.7609\n",
      "[Muon | lr=0.1] Epoch 3983/4000: train_loss=0.0046  test_loss=299.3087  λ_max=7.3544\n",
      "[Muon | lr=0.1] Epoch 3984/4000: train_loss=0.0039  test_loss=299.1779  λ_max=6.0612\n",
      "[Muon | lr=0.1] Epoch 3985/4000: train_loss=0.0044  test_loss=299.2104  λ_max=6.6642\n",
      "[Muon | lr=0.1] Epoch 3986/4000: train_loss=0.0036  test_loss=299.3609  λ_max=6.1652\n",
      "[Muon | lr=0.1] Epoch 3987/4000: train_loss=0.0029  test_loss=299.1994  λ_max=5.9549\n",
      "[Muon | lr=0.1] Iter 63800: loss=0.0003\n",
      "[Muon | lr=0.1] Epoch 3988/4000: train_loss=0.0039  test_loss=299.4082  λ_max=5.8701\n",
      "[Muon | lr=0.1] Epoch 3989/4000: train_loss=0.0033  test_loss=299.4133  λ_max=6.2773\n",
      "[Muon | lr=0.1] Epoch 3990/4000: train_loss=0.0037  test_loss=299.4947  λ_max=6.0063\n",
      "[Muon | lr=0.1] Epoch 3991/4000: train_loss=0.0038  test_loss=299.6500  λ_max=6.3900\n",
      "[Muon | lr=0.1] Epoch 3992/4000: train_loss=0.0021  test_loss=299.7469  λ_max=6.4068\n",
      "[Muon | lr=0.1] Epoch 3993/4000: train_loss=0.0052  test_loss=300.0784  λ_max=6.1999\n",
      "[Muon | lr=0.1] Iter 63900: loss=0.0100\n",
      "[Muon | lr=0.1] Epoch 3994/4000: train_loss=0.0047  test_loss=300.3073  λ_max=6.4236\n",
      "[Muon | lr=0.1] Epoch 3995/4000: train_loss=0.0037  test_loss=300.1934  λ_max=6.3167\n",
      "[Muon | lr=0.1] Epoch 3996/4000: train_loss=0.0025  test_loss=300.5316  λ_max=5.6762\n",
      "[Muon | lr=0.1] Epoch 3997/4000: train_loss=0.0042  test_loss=300.9094  λ_max=6.2250\n",
      "[Muon | lr=0.1] Epoch 3998/4000: train_loss=0.0046  test_loss=301.0755  λ_max=5.9571\n",
      "[Muon | lr=0.1] Epoch 3999/4000: train_loss=0.0040  test_loss=301.1270  λ_max=6.9671\n",
      "[Muon | lr=0.1] Iter 64000: loss=0.0182\n",
      "[Muon | lr=0.1] Epoch 4000/4000: train_loss=0.0042  test_loss=301.0007  λ_max=7.3760\n",
      "\n",
      "🔹 Running Muon with lr=0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (/home/aradilla/.cache/huggingface/datasets/sapientinc___csv/sapientinc--sudoku-extreme-798989c95bd556dd/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n",
      "Found cached dataset csv (/home/aradilla/.cache/huggingface/datasets/sapientinc___csv/sapientinc--sudoku-extreme-798989c95bd556dd/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Muon | lr=0.05] Epoch 1/4000: train_loss=2.2016  test_loss=2.1353  λ_max=3.5944\n",
      "[Muon | lr=0.05] Epoch 2/4000: train_loss=1.7603  test_loss=2.0753  λ_max=5.9981\n",
      "[Muon | lr=0.05] Epoch 3/4000: train_loss=1.2006  test_loss=2.2291  λ_max=5.1825\n",
      "[Muon | lr=0.05] Epoch 4/4000: train_loss=0.7662  test_loss=2.5824  λ_max=4.7450\n",
      "[Muon | lr=0.05] Epoch 5/4000: train_loss=0.4561  test_loss=2.9970  λ_max=4.4606\n",
      "[Muon | lr=0.05] Epoch 6/4000: train_loss=0.2847  test_loss=3.4673  λ_max=4.1925\n",
      "[Muon | lr=0.05] Iter 100: loss=0.1388\n",
      "[Muon | lr=0.05] Epoch 7/4000: train_loss=0.2020  test_loss=3.9263  λ_max=4.1691\n",
      "[Muon | lr=0.05] Epoch 8/4000: train_loss=0.1669  test_loss=4.3096  λ_max=4.0466\n",
      "[Muon | lr=0.05] Epoch 9/4000: train_loss=0.1437  test_loss=4.6475  λ_max=4.0439\n",
      "[Muon | lr=0.05] Epoch 10/4000: train_loss=0.1263  test_loss=4.9130  λ_max=4.0093\n",
      "[Muon | lr=0.05] Epoch 11/4000: train_loss=0.1142  test_loss=5.1660  λ_max=3.8040\n",
      "[Muon | lr=0.05] Epoch 12/4000: train_loss=0.1060  test_loss=5.4244  λ_max=3.4685\n",
      "[Muon | lr=0.05] Iter 200: loss=0.0797\n",
      "[Muon | lr=0.05] Epoch 13/4000: train_loss=0.0966  test_loss=5.6797  λ_max=3.3792\n",
      "[Muon | lr=0.05] Epoch 14/4000: train_loss=0.0902  test_loss=5.9007  λ_max=3.4094\n",
      "[Muon | lr=0.05] Epoch 15/4000: train_loss=0.0829  test_loss=6.1138  λ_max=3.2394\n",
      "[Muon | lr=0.05] Epoch 16/4000: train_loss=0.0770  test_loss=6.3288  λ_max=2.8960\n",
      "[Muon | lr=0.05] Epoch 17/4000: train_loss=0.0717  test_loss=6.5563  λ_max=2.9307\n",
      "[Muon | lr=0.05] Epoch 18/4000: train_loss=0.0680  test_loss=6.7225  λ_max=3.0469\n",
      "[Muon | lr=0.05] Iter 300: loss=0.0853\n",
      "[Muon | lr=0.05] Epoch 19/4000: train_loss=0.0620  test_loss=6.8971  λ_max=3.0458\n",
      "[Muon | lr=0.05] Epoch 20/4000: train_loss=0.0596  test_loss=7.0814  λ_max=2.7632\n",
      "[Muon | lr=0.05] Epoch 21/4000: train_loss=0.0568  test_loss=7.2615  λ_max=2.8041\n",
      "[Muon | lr=0.05] Epoch 22/4000: train_loss=0.0557  test_loss=7.4082  λ_max=2.8113\n",
      "[Muon | lr=0.05] Epoch 23/4000: train_loss=0.0504  test_loss=7.6186  λ_max=2.6090\n",
      "[Muon | lr=0.05] Epoch 24/4000: train_loss=0.0482  test_loss=7.7586  λ_max=2.7830\n",
      "[Muon | lr=0.05] Iter 400: loss=0.0877\n",
      "[Muon | lr=0.05] Epoch 25/4000: train_loss=0.0479  test_loss=7.8721  λ_max=2.6531\n",
      "[Muon | lr=0.05] Epoch 26/4000: train_loss=0.0461  test_loss=8.0899  λ_max=2.6116\n",
      "[Muon | lr=0.05] Epoch 27/4000: train_loss=0.0442  test_loss=8.2260  λ_max=2.4337\n",
      "[Muon | lr=0.05] Epoch 28/4000: train_loss=0.0425  test_loss=8.3604  λ_max=2.5948\n",
      "[Muon | lr=0.05] Epoch 29/4000: train_loss=0.0403  test_loss=8.4705  λ_max=2.4883\n",
      "[Muon | lr=0.05] Epoch 30/4000: train_loss=0.0411  test_loss=8.5701  λ_max=2.3336\n",
      "[Muon | lr=0.05] Epoch 31/4000: train_loss=0.0378  test_loss=8.6955  λ_max=2.4090\n",
      "[Muon | lr=0.05] Iter 500: loss=0.0228\n",
      "[Muon | lr=0.05] Epoch 32/4000: train_loss=0.0374  test_loss=8.8201  λ_max=2.5056\n",
      "[Muon | lr=0.05] Epoch 33/4000: train_loss=0.0364  test_loss=9.0157  λ_max=2.2858\n",
      "[Muon | lr=0.05] Epoch 34/4000: train_loss=0.0344  test_loss=9.1795  λ_max=2.4505\n",
      "[Muon | lr=0.05] Epoch 35/4000: train_loss=0.0341  test_loss=9.3515  λ_max=2.2709\n",
      "[Muon | lr=0.05] Epoch 36/4000: train_loss=0.0337  test_loss=9.4683  λ_max=2.2382\n",
      "[Muon | lr=0.05] Epoch 37/4000: train_loss=0.0326  test_loss=9.5856  λ_max=2.1337\n",
      "[Muon | lr=0.05] Iter 600: loss=0.0301\n",
      "[Muon | lr=0.05] Epoch 38/4000: train_loss=0.0313  test_loss=9.7635  λ_max=2.1861\n",
      "[Muon | lr=0.05] Epoch 39/4000: train_loss=0.0314  test_loss=9.8628  λ_max=2.3254\n",
      "[Muon | lr=0.05] Epoch 40/4000: train_loss=0.0305  test_loss=10.0002  λ_max=2.2737\n",
      "[Muon | lr=0.05] Epoch 41/4000: train_loss=0.0298  test_loss=10.1466  λ_max=2.1837\n",
      "[Muon | lr=0.05] Epoch 42/4000: train_loss=0.0283  test_loss=10.2948  λ_max=2.2307\n",
      "[Muon | lr=0.05] Epoch 43/4000: train_loss=0.0278  test_loss=10.4413  λ_max=2.2939\n",
      "[Muon | lr=0.05] Iter 700: loss=0.0321\n",
      "[Muon | lr=0.05] Epoch 44/4000: train_loss=0.0276  test_loss=10.5791  λ_max=2.0351\n",
      "[Muon | lr=0.05] Epoch 45/4000: train_loss=0.0272  test_loss=10.6455  λ_max=2.2301\n",
      "[Muon | lr=0.05] Epoch 46/4000: train_loss=0.0254  test_loss=10.7247  λ_max=2.1615\n",
      "[Muon | lr=0.05] Epoch 47/4000: train_loss=0.0261  test_loss=10.7953  λ_max=2.0556\n",
      "[Muon | lr=0.05] Epoch 48/4000: train_loss=0.0250  test_loss=10.8789  λ_max=2.0917\n",
      "[Muon | lr=0.05] Epoch 49/4000: train_loss=0.0252  test_loss=10.9487  λ_max=2.1470\n",
      "[Muon | lr=0.05] Iter 800: loss=0.0493\n",
      "[Muon | lr=0.05] Epoch 50/4000: train_loss=0.0248  test_loss=11.1184  λ_max=2.0490\n",
      "[Muon | lr=0.05] Epoch 51/4000: train_loss=0.0238  test_loss=11.2248  λ_max=2.0895\n",
      "[Muon | lr=0.05] Epoch 52/4000: train_loss=0.0240  test_loss=11.3579  λ_max=2.0086\n",
      "[Muon | lr=0.05] Epoch 53/4000: train_loss=0.0226  test_loss=11.4426  λ_max=2.0485\n",
      "[Muon | lr=0.05] Epoch 54/4000: train_loss=0.0220  test_loss=11.5033  λ_max=2.0630\n",
      "[Muon | lr=0.05] Epoch 55/4000: train_loss=0.0223  test_loss=11.6101  λ_max=1.9514\n",
      "[Muon | lr=0.05] Epoch 56/4000: train_loss=0.0214  test_loss=11.6920  λ_max=1.9086\n",
      "[Muon | lr=0.05] Iter 900: loss=0.0152\n",
      "[Muon | lr=0.05] Epoch 57/4000: train_loss=0.0221  test_loss=11.7560  λ_max=2.0117\n",
      "[Muon | lr=0.05] Epoch 58/4000: train_loss=0.0215  test_loss=11.8397  λ_max=2.1992\n",
      "[Muon | lr=0.05] Epoch 59/4000: train_loss=0.0215  test_loss=11.9478  λ_max=2.0029\n",
      "[Muon | lr=0.05] Epoch 60/4000: train_loss=0.0213  test_loss=12.0723  λ_max=2.0026\n",
      "[Muon | lr=0.05] Epoch 61/4000: train_loss=0.0209  test_loss=12.2335  λ_max=2.0410\n",
      "[Muon | lr=0.05] Epoch 62/4000: train_loss=0.0211  test_loss=12.3059  λ_max=2.0042\n",
      "[Muon | lr=0.05] Iter 1000: loss=0.0178\n",
      "[Muon | lr=0.05] Epoch 63/4000: train_loss=0.0207  test_loss=12.4056  λ_max=1.9791\n",
      "[Muon | lr=0.05] Epoch 64/4000: train_loss=0.0199  test_loss=12.5269  λ_max=2.0355\n",
      "[Muon | lr=0.05] Epoch 65/4000: train_loss=0.0196  test_loss=12.6158  λ_max=1.9323\n",
      "[Muon | lr=0.05] Epoch 66/4000: train_loss=0.0188  test_loss=12.6400  λ_max=1.8440\n",
      "[Muon | lr=0.05] Epoch 67/4000: train_loss=0.0186  test_loss=12.7051  λ_max=1.9469\n",
      "[Muon | lr=0.05] Epoch 68/4000: train_loss=0.0185  test_loss=12.8337  λ_max=1.9181\n",
      "[Muon | lr=0.05] Iter 1100: loss=0.0210\n",
      "[Muon | lr=0.05] Epoch 69/4000: train_loss=0.0181  test_loss=12.8967  λ_max=1.9420\n",
      "[Muon | lr=0.05] Epoch 70/4000: train_loss=0.0178  test_loss=13.0273  λ_max=1.7987\n",
      "[Muon | lr=0.05] Epoch 71/4000: train_loss=0.0179  test_loss=13.0482  λ_max=1.8942\n",
      "[Muon | lr=0.05] Epoch 72/4000: train_loss=0.0174  test_loss=13.1009  λ_max=1.7780\n",
      "[Muon | lr=0.05] Epoch 73/4000: train_loss=0.0163  test_loss=13.1099  λ_max=1.8904\n",
      "[Muon | lr=0.05] Epoch 74/4000: train_loss=0.0169  test_loss=13.2302  λ_max=1.9315\n",
      "[Muon | lr=0.05] Iter 1200: loss=0.0343\n",
      "[Muon | lr=0.05] Epoch 75/4000: train_loss=0.0177  test_loss=13.3333  λ_max=1.9047\n",
      "[Muon | lr=0.05] Epoch 76/4000: train_loss=0.0173  test_loss=13.3797  λ_max=1.8342\n",
      "[Muon | lr=0.05] Epoch 77/4000: train_loss=0.0163  test_loss=13.4738  λ_max=1.7756\n",
      "[Muon | lr=0.05] Epoch 78/4000: train_loss=0.0167  test_loss=13.6454  λ_max=1.7968\n",
      "[Muon | lr=0.05] Epoch 79/4000: train_loss=0.0156  test_loss=13.6990  λ_max=1.9014\n",
      "[Muon | lr=0.05] Epoch 80/4000: train_loss=0.0165  test_loss=13.8311  λ_max=1.7699\n",
      "[Muon | lr=0.05] Epoch 81/4000: train_loss=0.0163  test_loss=13.8942  λ_max=1.8943\n",
      "[Muon | lr=0.05] Iter 1300: loss=0.0076\n",
      "[Muon | lr=0.05] Epoch 82/4000: train_loss=0.0158  test_loss=13.9717  λ_max=1.7050\n",
      "[Muon | lr=0.05] Epoch 83/4000: train_loss=0.0152  test_loss=14.0305  λ_max=1.7407\n",
      "[Muon | lr=0.05] Epoch 84/4000: train_loss=0.0158  test_loss=14.1019  λ_max=1.7781\n",
      "[Muon | lr=0.05] Epoch 85/4000: train_loss=0.0161  test_loss=14.2289  λ_max=1.8417\n",
      "[Muon | lr=0.05] Epoch 86/4000: train_loss=0.0155  test_loss=14.3096  λ_max=1.7295\n",
      "[Muon | lr=0.05] Epoch 87/4000: train_loss=0.0149  test_loss=14.4431  λ_max=1.7343\n",
      "[Muon | lr=0.05] Iter 1400: loss=0.0138\n",
      "[Muon | lr=0.05] Epoch 88/4000: train_loss=0.0146  test_loss=14.5875  λ_max=1.7627\n",
      "[Muon | lr=0.05] Epoch 89/4000: train_loss=0.0145  test_loss=14.7180  λ_max=1.7636\n",
      "[Muon | lr=0.05] Epoch 90/4000: train_loss=0.0141  test_loss=14.7809  λ_max=1.7565\n",
      "[Muon | lr=0.05] Epoch 91/4000: train_loss=0.0144  test_loss=14.8519  λ_max=1.7141\n",
      "[Muon | lr=0.05] Epoch 92/4000: train_loss=0.0133  test_loss=14.9448  λ_max=1.7518\n",
      "[Muon | lr=0.05] Epoch 93/4000: train_loss=0.0139  test_loss=15.0146  λ_max=1.7140\n",
      "[Muon | lr=0.05] Iter 1500: loss=0.0165\n",
      "[Muon | lr=0.05] Epoch 94/4000: train_loss=0.0129  test_loss=15.1291  λ_max=1.7209\n",
      "[Muon | lr=0.05] Epoch 95/4000: train_loss=0.0142  test_loss=15.2239  λ_max=1.6645\n",
      "[Muon | lr=0.05] Epoch 96/4000: train_loss=0.0134  test_loss=15.2964  λ_max=1.7219\n",
      "[Muon | lr=0.05] Epoch 97/4000: train_loss=0.0131  test_loss=15.3430  λ_max=1.7030\n",
      "[Muon | lr=0.05] Epoch 98/4000: train_loss=0.0133  test_loss=15.4762  λ_max=1.7749\n",
      "[Muon | lr=0.05] Epoch 99/4000: train_loss=0.0132  test_loss=15.5553  λ_max=1.7949\n",
      "[Muon | lr=0.05] Iter 1600: loss=0.0201\n",
      "[Muon | lr=0.05] Epoch 100/4000: train_loss=0.0134  test_loss=15.6315  λ_max=1.7026\n",
      "[Muon | lr=0.05] Epoch 101/4000: train_loss=0.0137  test_loss=15.6322  λ_max=1.7296\n",
      "[Muon | lr=0.05] Epoch 102/4000: train_loss=0.0132  test_loss=15.6746  λ_max=1.5998\n",
      "[Muon | lr=0.05] Epoch 103/4000: train_loss=0.0127  test_loss=15.7452  λ_max=1.6482\n",
      "[Muon | lr=0.05] Epoch 104/4000: train_loss=0.0134  test_loss=15.8131  λ_max=1.7117\n",
      "[Muon | lr=0.05] Epoch 105/4000: train_loss=0.0129  test_loss=15.8691  λ_max=1.7733\n",
      "[Muon | lr=0.05] Epoch 106/4000: train_loss=0.0117  test_loss=15.9506  λ_max=1.7425\n",
      "[Muon | lr=0.05] Iter 1700: loss=0.0067\n",
      "[Muon | lr=0.05] Epoch 107/4000: train_loss=0.0121  test_loss=16.0273  λ_max=1.7491\n",
      "[Muon | lr=0.05] Epoch 108/4000: train_loss=0.0122  test_loss=16.1846  λ_max=1.6972\n",
      "[Muon | lr=0.05] Epoch 109/4000: train_loss=0.0120  test_loss=16.2667  λ_max=1.6553\n",
      "[Muon | lr=0.05] Epoch 110/4000: train_loss=0.0121  test_loss=16.3278  λ_max=1.6985\n",
      "[Muon | lr=0.05] Epoch 111/4000: train_loss=0.0115  test_loss=16.3363  λ_max=1.8215\n",
      "[Muon | lr=0.05] Epoch 112/4000: train_loss=0.0121  test_loss=16.3765  λ_max=1.7340\n",
      "[Muon | lr=0.05] Iter 1800: loss=0.0107\n",
      "[Muon | lr=0.05] Epoch 113/4000: train_loss=0.0121  test_loss=16.4381  λ_max=1.7417\n",
      "[Muon | lr=0.05] Epoch 114/4000: train_loss=0.0119  test_loss=16.5449  λ_max=1.6514\n",
      "[Muon | lr=0.05] Epoch 115/4000: train_loss=0.0113  test_loss=16.5749  λ_max=1.8063\n",
      "[Muon | lr=0.05] Epoch 116/4000: train_loss=0.0113  test_loss=16.6647  λ_max=1.7083\n",
      "[Muon | lr=0.05] Epoch 117/4000: train_loss=0.0116  test_loss=16.7239  λ_max=1.7412\n",
      "[Muon | lr=0.05] Epoch 118/4000: train_loss=0.0108  test_loss=16.8490  λ_max=1.6377\n",
      "[Muon | lr=0.05] Iter 1900: loss=0.0165\n",
      "[Muon | lr=0.05] Epoch 119/4000: train_loss=0.0117  test_loss=16.8871  λ_max=1.7526\n",
      "[Muon | lr=0.05] Epoch 120/4000: train_loss=0.0109  test_loss=17.0041  λ_max=1.6426\n",
      "[Muon | lr=0.05] Epoch 121/4000: train_loss=0.0114  test_loss=17.1262  λ_max=1.6704\n",
      "[Muon | lr=0.05] Epoch 122/4000: train_loss=0.0105  test_loss=17.1866  λ_max=1.6426\n",
      "[Muon | lr=0.05] Epoch 123/4000: train_loss=0.0103  test_loss=17.2187  λ_max=1.7348\n",
      "[Muon | lr=0.05] Epoch 124/4000: train_loss=0.0106  test_loss=17.3164  λ_max=1.5948\n",
      "[Muon | lr=0.05] Iter 2000: loss=0.0206\n",
      "[Muon | lr=0.05] Epoch 125/4000: train_loss=0.0107  test_loss=17.3436  λ_max=1.7297\n",
      "[Muon | lr=0.05] Epoch 126/4000: train_loss=0.0115  test_loss=17.3977  λ_max=1.6744\n",
      "[Muon | lr=0.05] Epoch 127/4000: train_loss=0.0103  test_loss=17.4862  λ_max=1.6454\n",
      "[Muon | lr=0.05] Epoch 128/4000: train_loss=0.0106  test_loss=17.5409  λ_max=1.6443\n",
      "[Muon | lr=0.05] Epoch 129/4000: train_loss=0.0107  test_loss=17.5890  λ_max=1.6506\n",
      "[Muon | lr=0.05] Epoch 130/4000: train_loss=0.0100  test_loss=17.6747  λ_max=1.6345\n",
      "[Muon | lr=0.05] Epoch 131/4000: train_loss=0.0106  test_loss=17.7145  λ_max=1.6517\n",
      "[Muon | lr=0.05] Iter 2100: loss=0.0048\n",
      "[Muon | lr=0.05] Epoch 132/4000: train_loss=0.0098  test_loss=17.8120  λ_max=1.7070\n",
      "[Muon | lr=0.05] Epoch 133/4000: train_loss=0.0104  test_loss=17.9295  λ_max=1.7613\n",
      "[Muon | lr=0.05] Epoch 134/4000: train_loss=0.0097  test_loss=18.0423  λ_max=1.6126\n",
      "[Muon | lr=0.05] Epoch 135/4000: train_loss=0.0103  test_loss=18.1277  λ_max=1.6155\n",
      "[Muon | lr=0.05] Epoch 136/4000: train_loss=0.0101  test_loss=18.2086  λ_max=1.6057\n",
      "[Muon | lr=0.05] Epoch 137/4000: train_loss=0.0102  test_loss=18.3167  λ_max=1.6182\n",
      "[Muon | lr=0.05] Iter 2200: loss=0.0087\n",
      "[Muon | lr=0.05] Epoch 138/4000: train_loss=0.0100  test_loss=18.3375  λ_max=1.5839\n",
      "[Muon | lr=0.05] Epoch 139/4000: train_loss=0.0103  test_loss=18.3589  λ_max=1.6299\n",
      "[Muon | lr=0.05] Epoch 140/4000: train_loss=0.0094  test_loss=18.4262  λ_max=1.6306\n",
      "[Muon | lr=0.05] Epoch 141/4000: train_loss=0.0099  test_loss=18.5083  λ_max=1.7102\n",
      "[Muon | lr=0.05] Epoch 142/4000: train_loss=0.0095  test_loss=18.4910  λ_max=1.6847\n",
      "[Muon | lr=0.05] Epoch 143/4000: train_loss=0.0095  test_loss=18.5744  λ_max=1.7261\n",
      "[Muon | lr=0.05] Iter 2300: loss=0.0127\n",
      "[Muon | lr=0.05] Epoch 144/4000: train_loss=0.0096  test_loss=18.6591  λ_max=1.5814\n",
      "[Muon | lr=0.05] Epoch 145/4000: train_loss=0.0093  test_loss=18.7522  λ_max=1.6490\n",
      "[Muon | lr=0.05] Epoch 146/4000: train_loss=0.0104  test_loss=18.7767  λ_max=1.5822\n",
      "[Muon | lr=0.05] Epoch 147/4000: train_loss=0.0099  test_loss=18.8620  λ_max=1.5598\n",
      "[Muon | lr=0.05] Epoch 148/4000: train_loss=0.0096  test_loss=18.9687  λ_max=1.6797\n",
      "[Muon | lr=0.05] Epoch 149/4000: train_loss=0.0093  test_loss=19.0149  λ_max=1.5478\n",
      "[Muon | lr=0.05] Iter 2400: loss=0.0182\n",
      "[Muon | lr=0.05] Epoch 150/4000: train_loss=0.0097  test_loss=19.0503  λ_max=1.6164\n",
      "[Muon | lr=0.05] Epoch 151/4000: train_loss=0.0091  test_loss=19.1109  λ_max=1.6004\n",
      "[Muon | lr=0.05] Epoch 152/4000: train_loss=0.0096  test_loss=19.1733  λ_max=1.6055\n",
      "[Muon | lr=0.05] Epoch 153/4000: train_loss=0.0087  test_loss=19.2542  λ_max=1.6174\n",
      "[Muon | lr=0.05] Epoch 154/4000: train_loss=0.0094  test_loss=19.3459  λ_max=1.6254\n",
      "[Muon | lr=0.05] Epoch 155/4000: train_loss=0.0097  test_loss=19.4276  λ_max=1.5937\n",
      "[Muon | lr=0.05] Epoch 156/4000: train_loss=0.0096  test_loss=19.5507  λ_max=1.4545\n",
      "[Muon | lr=0.05] Iter 2500: loss=0.0037\n",
      "[Muon | lr=0.05] Epoch 157/4000: train_loss=0.0089  test_loss=19.6278  λ_max=1.6127\n",
      "[Muon | lr=0.05] Epoch 158/4000: train_loss=0.0094  test_loss=19.7467  λ_max=1.6962\n",
      "[Muon | lr=0.05] Epoch 159/4000: train_loss=0.0088  test_loss=19.7570  λ_max=1.6373\n",
      "[Muon | lr=0.05] Epoch 160/4000: train_loss=0.0084  test_loss=19.8240  λ_max=1.6068\n",
      "[Muon | lr=0.05] Epoch 161/4000: train_loss=0.0090  test_loss=19.8470  λ_max=1.6635\n",
      "[Muon | lr=0.05] Epoch 162/4000: train_loss=0.0087  test_loss=19.8619  λ_max=1.5909\n",
      "[Muon | lr=0.05] Iter 2600: loss=0.0094\n",
      "[Muon | lr=0.05] Epoch 163/4000: train_loss=0.0085  test_loss=19.9106  λ_max=1.5757\n",
      "[Muon | lr=0.05] Epoch 164/4000: train_loss=0.0084  test_loss=19.9657  λ_max=1.6387\n",
      "[Muon | lr=0.05] Epoch 165/4000: train_loss=0.0085  test_loss=20.1293  λ_max=1.6449\n",
      "[Muon | lr=0.05] Epoch 166/4000: train_loss=0.0081  test_loss=20.1962  λ_max=1.6422\n",
      "[Muon | lr=0.05] Epoch 167/4000: train_loss=0.0086  test_loss=20.2868  λ_max=1.5560\n",
      "[Muon | lr=0.05] Epoch 168/4000: train_loss=0.0083  test_loss=20.4087  λ_max=1.6405\n",
      "[Muon | lr=0.05] Iter 2700: loss=0.0111\n",
      "[Muon | lr=0.05] Epoch 169/4000: train_loss=0.0085  test_loss=20.4914  λ_max=1.5955\n",
      "[Muon | lr=0.05] Epoch 170/4000: train_loss=0.0079  test_loss=20.5619  λ_max=1.5831\n",
      "[Muon | lr=0.05] Epoch 171/4000: train_loss=0.0086  test_loss=20.6557  λ_max=1.5961\n",
      "[Muon | lr=0.05] Epoch 172/4000: train_loss=0.0076  test_loss=20.7133  λ_max=1.6424\n",
      "[Muon | lr=0.05] Epoch 173/4000: train_loss=0.0082  test_loss=20.7404  λ_max=1.6068\n",
      "[Muon | lr=0.05] Epoch 174/4000: train_loss=0.0080  test_loss=20.8287  λ_max=1.5113\n",
      "[Muon | lr=0.05] Iter 2800: loss=0.0075\n",
      "[Muon | lr=0.05] Epoch 175/4000: train_loss=0.0083  test_loss=20.8837  λ_max=1.6400\n",
      "[Muon | lr=0.05] Epoch 176/4000: train_loss=0.0085  test_loss=20.9937  λ_max=1.5611\n",
      "[Muon | lr=0.05] Epoch 177/4000: train_loss=0.0081  test_loss=21.0860  λ_max=1.5109\n",
      "[Muon | lr=0.05] Epoch 178/4000: train_loss=0.0084  test_loss=21.1329  λ_max=1.6521\n",
      "[Muon | lr=0.05] Epoch 179/4000: train_loss=0.0075  test_loss=21.2550  λ_max=1.5653\n",
      "[Muon | lr=0.05] Epoch 180/4000: train_loss=0.0079  test_loss=21.3419  λ_max=1.5534\n",
      "[Muon | lr=0.05] Epoch 181/4000: train_loss=0.0082  test_loss=21.3878  λ_max=1.6629\n",
      "[Muon | lr=0.05] Iter 2900: loss=0.0035\n",
      "[Muon | lr=0.05] Epoch 182/4000: train_loss=0.0081  test_loss=21.4754  λ_max=1.5423\n",
      "[Muon | lr=0.05] Epoch 183/4000: train_loss=0.0084  test_loss=21.5670  λ_max=1.5080\n",
      "[Muon | lr=0.05] Epoch 184/4000: train_loss=0.0081  test_loss=21.6010  λ_max=1.6536\n",
      "[Muon | lr=0.05] Epoch 185/4000: train_loss=0.0073  test_loss=21.6056  λ_max=1.5126\n",
      "[Muon | lr=0.05] Epoch 186/4000: train_loss=0.0082  test_loss=21.5915  λ_max=1.5149\n",
      "[Muon | lr=0.05] Epoch 187/4000: train_loss=0.0073  test_loss=21.6626  λ_max=1.6091\n",
      "[Muon | lr=0.05] Iter 3000: loss=0.0063\n",
      "[Muon | lr=0.05] Epoch 188/4000: train_loss=0.0073  test_loss=21.6479  λ_max=1.6031\n",
      "[Muon | lr=0.05] Epoch 189/4000: train_loss=0.0071  test_loss=21.7109  λ_max=1.5249\n",
      "[Muon | lr=0.05] Epoch 190/4000: train_loss=0.0075  test_loss=21.7671  λ_max=1.5885\n",
      "[Muon | lr=0.05] Epoch 191/4000: train_loss=0.0074  test_loss=21.7957  λ_max=1.5619\n",
      "[Muon | lr=0.05] Epoch 192/4000: train_loss=0.0076  test_loss=21.8649  λ_max=1.5916\n",
      "[Muon | lr=0.05] Epoch 193/4000: train_loss=0.0072  test_loss=21.8902  λ_max=1.4917\n",
      "[Muon | lr=0.05] Iter 3100: loss=0.0117\n",
      "[Muon | lr=0.05] Epoch 194/4000: train_loss=0.0075  test_loss=21.9115  λ_max=1.5784\n",
      "[Muon | lr=0.05] Epoch 195/4000: train_loss=0.0077  test_loss=21.9482  λ_max=1.5894\n",
      "[Muon | lr=0.05] Epoch 196/4000: train_loss=0.0074  test_loss=22.0080  λ_max=1.5804\n",
      "[Muon | lr=0.05] Epoch 197/4000: train_loss=0.0071  test_loss=22.0118  λ_max=1.5822\n",
      "[Muon | lr=0.05] Epoch 198/4000: train_loss=0.0077  test_loss=22.0526  λ_max=1.4974\n",
      "[Muon | lr=0.05] Epoch 199/4000: train_loss=0.0070  test_loss=22.1305  λ_max=1.5554\n",
      "[Muon | lr=0.05] Iter 3200: loss=0.0130\n",
      "[Muon | lr=0.05] Epoch 200/4000: train_loss=0.0073  test_loss=22.2428  λ_max=1.5500\n",
      "[Muon | lr=0.05] Epoch 201/4000: train_loss=0.0068  test_loss=22.3027  λ_max=1.6615\n",
      "[Muon | lr=0.05] Epoch 202/4000: train_loss=0.0071  test_loss=22.3503  λ_max=1.5660\n",
      "[Muon | lr=0.05] Epoch 203/4000: train_loss=0.0070  test_loss=22.4277  λ_max=1.5573\n",
      "[Muon | lr=0.05] Epoch 204/4000: train_loss=0.0068  test_loss=22.5348  λ_max=1.5609\n",
      "[Muon | lr=0.05] Epoch 205/4000: train_loss=0.0072  test_loss=22.5515  λ_max=1.4801\n",
      "[Muon | lr=0.05] Epoch 206/4000: train_loss=0.0071  test_loss=22.5981  λ_max=1.5718\n",
      "[Muon | lr=0.05] Iter 3300: loss=0.0040\n",
      "[Muon | lr=0.05] Epoch 207/4000: train_loss=0.0070  test_loss=22.6621  λ_max=1.5461\n",
      "[Muon | lr=0.05] Epoch 208/4000: train_loss=0.0068  test_loss=22.7317  λ_max=1.4636\n",
      "[Muon | lr=0.05] Epoch 209/4000: train_loss=0.0071  test_loss=22.7189  λ_max=1.4740\n",
      "[Muon | lr=0.05] Epoch 210/4000: train_loss=0.0068  test_loss=22.7974  λ_max=1.5865\n",
      "[Muon | lr=0.05] Epoch 211/4000: train_loss=0.0069  test_loss=22.7776  λ_max=1.4993\n",
      "[Muon | lr=0.05] Epoch 212/4000: train_loss=0.0071  test_loss=22.7718  λ_max=1.4778\n",
      "[Muon | lr=0.05] Iter 3400: loss=0.0064\n",
      "[Muon | lr=0.05] Epoch 213/4000: train_loss=0.0072  test_loss=22.7436  λ_max=1.4963\n",
      "[Muon | lr=0.05] Epoch 214/4000: train_loss=0.0069  test_loss=22.7313  λ_max=1.5588\n",
      "[Muon | lr=0.05] Epoch 215/4000: train_loss=0.0073  test_loss=22.7223  λ_max=1.6148\n",
      "[Muon | lr=0.05] Epoch 216/4000: train_loss=0.0072  test_loss=22.7652  λ_max=1.5554\n",
      "[Muon | lr=0.05] Epoch 217/4000: train_loss=0.0062  test_loss=22.8053  λ_max=1.5932\n",
      "[Muon | lr=0.05] Epoch 218/4000: train_loss=0.0068  test_loss=22.8830  λ_max=1.5196\n",
      "[Muon | lr=0.05] Iter 3500: loss=0.0100\n",
      "[Muon | lr=0.05] Epoch 219/4000: train_loss=0.0071  test_loss=22.9305  λ_max=1.5659\n",
      "[Muon | lr=0.05] Epoch 220/4000: train_loss=0.0070  test_loss=22.9531  λ_max=1.5421\n",
      "[Muon | lr=0.05] Epoch 221/4000: train_loss=0.0064  test_loss=23.0385  λ_max=1.5326\n",
      "[Muon | lr=0.05] Epoch 222/4000: train_loss=0.0073  test_loss=23.1110  λ_max=1.5536\n",
      "[Muon | lr=0.05] Epoch 223/4000: train_loss=0.0063  test_loss=23.1838  λ_max=1.5410\n",
      "[Muon | lr=0.05] Epoch 224/4000: train_loss=0.0070  test_loss=23.2346  λ_max=1.4785\n",
      "[Muon | lr=0.05] Iter 3600: loss=0.0165\n",
      "[Muon | lr=0.05] Epoch 225/4000: train_loss=0.0073  test_loss=23.3600  λ_max=1.3813\n",
      "[Muon | lr=0.05] Epoch 226/4000: train_loss=0.0068  test_loss=23.4050  λ_max=1.5997\n",
      "[Muon | lr=0.05] Epoch 227/4000: train_loss=0.0066  test_loss=23.4840  λ_max=1.5943\n",
      "[Muon | lr=0.05] Epoch 228/4000: train_loss=0.0072  test_loss=23.5796  λ_max=1.4575\n",
      "[Muon | lr=0.05] Epoch 229/4000: train_loss=0.0065  test_loss=23.6338  λ_max=1.5245\n",
      "[Muon | lr=0.05] Epoch 230/4000: train_loss=0.0072  test_loss=23.6663  λ_max=1.5120\n",
      "[Muon | lr=0.05] Epoch 231/4000: train_loss=0.0061  test_loss=23.7802  λ_max=1.5073\n",
      "[Muon | lr=0.05] Iter 3700: loss=0.0026\n",
      "[Muon | lr=0.05] Epoch 232/4000: train_loss=0.0065  test_loss=23.8264  λ_max=1.5072\n",
      "[Muon | lr=0.05] Epoch 233/4000: train_loss=0.0069  test_loss=23.9439  λ_max=1.6102\n",
      "[Muon | lr=0.05] Epoch 234/4000: train_loss=0.0062  test_loss=23.9768  λ_max=1.5108\n",
      "[Muon | lr=0.05] Epoch 235/4000: train_loss=0.0062  test_loss=24.0136  λ_max=1.4951\n",
      "[Muon | lr=0.05] Epoch 236/4000: train_loss=0.0060  test_loss=23.9788  λ_max=1.4282\n",
      "[Muon | lr=0.05] Epoch 237/4000: train_loss=0.0062  test_loss=24.0351  λ_max=1.4957\n",
      "[Muon | lr=0.05] Iter 3800: loss=0.0064\n",
      "[Muon | lr=0.05] Epoch 238/4000: train_loss=0.0065  test_loss=24.0298  λ_max=1.5983\n",
      "[Muon | lr=0.05] Epoch 239/4000: train_loss=0.0064  test_loss=24.0633  λ_max=1.4732\n",
      "[Muon | lr=0.05] Epoch 240/4000: train_loss=0.0063  test_loss=24.1473  λ_max=1.5711\n",
      "[Muon | lr=0.05] Epoch 241/4000: train_loss=0.0063  test_loss=24.1706  λ_max=1.5483\n",
      "[Muon | lr=0.05] Epoch 242/4000: train_loss=0.0062  test_loss=24.2831  λ_max=1.4882\n",
      "[Muon | lr=0.05] Epoch 243/4000: train_loss=0.0059  test_loss=24.3462  λ_max=1.4463\n",
      "[Muon | lr=0.05] Iter 3900: loss=0.0082\n",
      "[Muon | lr=0.05] Epoch 244/4000: train_loss=0.0059  test_loss=24.4343  λ_max=1.4292\n",
      "[Muon | lr=0.05] Epoch 245/4000: train_loss=0.0058  test_loss=24.4748  λ_max=1.5762\n",
      "[Muon | lr=0.05] Epoch 246/4000: train_loss=0.0059  test_loss=24.4349  λ_max=1.5751\n",
      "[Muon | lr=0.05] Epoch 247/4000: train_loss=0.0064  test_loss=24.4122  λ_max=1.5356\n",
      "[Muon | lr=0.05] Epoch 248/4000: train_loss=0.0062  test_loss=24.4087  λ_max=1.4423\n",
      "[Muon | lr=0.05] Epoch 249/4000: train_loss=0.0052  test_loss=24.4539  λ_max=1.5539\n",
      "[Muon | lr=0.05] Iter 4000: loss=0.0139\n",
      "[Muon | lr=0.05] Epoch 250/4000: train_loss=0.0062  test_loss=24.5271  λ_max=1.5807\n",
      "[Muon | lr=0.05] Epoch 251/4000: train_loss=0.0059  test_loss=24.5585  λ_max=1.6501\n",
      "[Muon | lr=0.05] Epoch 252/4000: train_loss=0.0057  test_loss=24.5823  λ_max=1.5317\n",
      "[Muon | lr=0.05] Epoch 253/4000: train_loss=0.0055  test_loss=24.7013  λ_max=1.4737\n",
      "[Muon | lr=0.05] Epoch 254/4000: train_loss=0.0057  test_loss=24.7272  λ_max=1.5478\n",
      "[Muon | lr=0.05] Epoch 255/4000: train_loss=0.0056  test_loss=24.8125  λ_max=1.5174\n",
      "[Muon | lr=0.05] Epoch 256/4000: train_loss=0.0060  test_loss=24.8837  λ_max=1.4702\n",
      "[Muon | lr=0.05] Iter 4100: loss=0.0034\n",
      "[Muon | lr=0.05] Epoch 257/4000: train_loss=0.0063  test_loss=24.9665  λ_max=1.4979\n",
      "[Muon | lr=0.05] Epoch 258/4000: train_loss=0.0060  test_loss=24.9481  λ_max=1.4194\n",
      "[Muon | lr=0.05] Epoch 259/4000: train_loss=0.0055  test_loss=24.9741  λ_max=1.4972\n",
      "[Muon | lr=0.05] Epoch 260/4000: train_loss=0.0052  test_loss=25.0231  λ_max=1.4825\n",
      "[Muon | lr=0.05] Epoch 261/4000: train_loss=0.0061  test_loss=25.1070  λ_max=1.5181\n",
      "[Muon | lr=0.05] Epoch 262/4000: train_loss=0.0055  test_loss=25.1661  λ_max=1.5483\n",
      "[Muon | lr=0.05] Iter 4200: loss=0.0075\n",
      "[Muon | lr=0.05] Epoch 263/4000: train_loss=0.0055  test_loss=25.2352  λ_max=1.5175\n",
      "[Muon | lr=0.05] Epoch 264/4000: train_loss=0.0056  test_loss=25.2842  λ_max=1.5644\n",
      "[Muon | lr=0.05] Epoch 265/4000: train_loss=0.0058  test_loss=25.3797  λ_max=1.4945\n",
      "[Muon | lr=0.05] Epoch 266/4000: train_loss=0.0062  test_loss=25.4228  λ_max=1.4871\n",
      "[Muon | lr=0.05] Epoch 267/4000: train_loss=0.0055  test_loss=25.5018  λ_max=1.4902\n",
      "[Muon | lr=0.05] Epoch 268/4000: train_loss=0.0061  test_loss=25.6369  λ_max=1.5973\n",
      "[Muon | lr=0.05] Iter 4300: loss=0.0076\n",
      "[Muon | lr=0.05] Epoch 269/4000: train_loss=0.0051  test_loss=25.7432  λ_max=1.5416\n",
      "[Muon | lr=0.05] Epoch 270/4000: train_loss=0.0054  test_loss=25.8399  λ_max=1.4183\n",
      "[Muon | lr=0.05] Epoch 271/4000: train_loss=0.0057  test_loss=25.8918  λ_max=1.4890\n",
      "[Muon | lr=0.05] Epoch 272/4000: train_loss=0.0053  test_loss=25.9386  λ_max=1.4278\n",
      "[Muon | lr=0.05] Epoch 273/4000: train_loss=0.0054  test_loss=26.0239  λ_max=1.5959\n",
      "[Muon | lr=0.05] Epoch 274/4000: train_loss=0.0056  test_loss=26.0905  λ_max=1.4052\n",
      "[Muon | lr=0.05] Iter 4400: loss=0.0112\n",
      "[Muon | lr=0.05] Epoch 275/4000: train_loss=0.0063  test_loss=26.1672  λ_max=1.5504\n",
      "[Muon | lr=0.05] Epoch 276/4000: train_loss=0.0058  test_loss=26.2171  λ_max=1.4482\n",
      "[Muon | lr=0.05] Epoch 277/4000: train_loss=0.0050  test_loss=26.1740  λ_max=1.4501\n",
      "[Muon | lr=0.05] Epoch 278/4000: train_loss=0.0056  test_loss=26.2232  λ_max=1.4937\n",
      "[Muon | lr=0.05] Epoch 279/4000: train_loss=0.0053  test_loss=26.2728  λ_max=1.5394\n",
      "[Muon | lr=0.05] Epoch 280/4000: train_loss=0.0056  test_loss=26.3439  λ_max=1.3809\n",
      "[Muon | lr=0.05] Epoch 281/4000: train_loss=0.0056  test_loss=26.3609  λ_max=1.5428\n",
      "[Muon | lr=0.05] Iter 4500: loss=0.0024\n",
      "[Muon | lr=0.05] Epoch 282/4000: train_loss=0.0057  test_loss=26.3913  λ_max=1.4258\n",
      "[Muon | lr=0.05] Epoch 283/4000: train_loss=0.0056  test_loss=26.4638  λ_max=1.5027\n",
      "[Muon | lr=0.05] Epoch 284/4000: train_loss=0.0052  test_loss=26.4919  λ_max=1.4675\n",
      "[Muon | lr=0.05] Epoch 285/4000: train_loss=0.0051  test_loss=26.4809  λ_max=1.5125\n",
      "[Muon | lr=0.05] Epoch 286/4000: train_loss=0.0053  test_loss=26.4998  λ_max=1.4812\n",
      "[Muon | lr=0.05] Epoch 287/4000: train_loss=0.0054  test_loss=26.4631  λ_max=1.5315\n",
      "[Muon | lr=0.05] Iter 4600: loss=0.0053\n",
      "[Muon | lr=0.05] Epoch 288/4000: train_loss=0.0053  test_loss=26.5294  λ_max=1.4818\n",
      "[Muon | lr=0.05] Epoch 289/4000: train_loss=0.0056  test_loss=26.5766  λ_max=1.5725\n",
      "[Muon | lr=0.05] Epoch 290/4000: train_loss=0.0047  test_loss=26.6383  λ_max=1.5864\n",
      "[Muon | lr=0.05] Epoch 291/4000: train_loss=0.0050  test_loss=26.6463  λ_max=1.4786\n",
      "[Muon | lr=0.05] Epoch 292/4000: train_loss=0.0053  test_loss=26.6960  λ_max=1.4292\n",
      "[Muon | lr=0.05] Epoch 293/4000: train_loss=0.0054  test_loss=26.7363  λ_max=1.5961\n",
      "[Muon | lr=0.05] Iter 4700: loss=0.0077\n",
      "[Muon | lr=0.05] Epoch 294/4000: train_loss=0.0057  test_loss=26.7941  λ_max=1.6284\n",
      "[Muon | lr=0.05] Epoch 295/4000: train_loss=0.0048  test_loss=26.8139  λ_max=1.6190\n",
      "[Muon | lr=0.05] Epoch 296/4000: train_loss=0.0050  test_loss=26.9068  λ_max=1.5294\n",
      "[Muon | lr=0.05] Epoch 297/4000: train_loss=0.0048  test_loss=26.8996  λ_max=1.5217\n",
      "[Muon | lr=0.05] Epoch 298/4000: train_loss=0.0051  test_loss=26.9442  λ_max=1.6467\n",
      "[Muon | lr=0.05] Epoch 299/4000: train_loss=0.0053  test_loss=26.9623  λ_max=1.5832\n",
      "[Muon | lr=0.05] Iter 4800: loss=0.0070\n",
      "[Muon | lr=0.05] Epoch 300/4000: train_loss=0.0052  test_loss=26.9740  λ_max=1.5444\n",
      "[Muon | lr=0.05] Epoch 301/4000: train_loss=0.0048  test_loss=27.0035  λ_max=1.5798\n",
      "[Muon | lr=0.05] Epoch 302/4000: train_loss=0.0052  test_loss=27.0935  λ_max=1.5415\n",
      "[Muon | lr=0.05] Epoch 303/4000: train_loss=0.0051  test_loss=27.1111  λ_max=1.5925\n",
      "[Muon | lr=0.05] Epoch 304/4000: train_loss=0.0050  test_loss=27.1573  λ_max=1.5795\n",
      "[Muon | lr=0.05] Epoch 305/4000: train_loss=0.0045  test_loss=27.1792  λ_max=1.5858\n",
      "[Muon | lr=0.05] Epoch 306/4000: train_loss=0.0048  test_loss=27.1755  λ_max=1.5502\n",
      "[Muon | lr=0.05] Iter 4900: loss=0.0016\n",
      "[Muon | lr=0.05] Epoch 307/4000: train_loss=0.0053  test_loss=27.2639  λ_max=1.5440\n",
      "[Muon | lr=0.05] Epoch 308/4000: train_loss=0.0052  test_loss=27.3048  λ_max=1.5723\n",
      "[Muon | lr=0.05] Epoch 309/4000: train_loss=0.0050  test_loss=27.3685  λ_max=1.4620\n",
      "[Muon | lr=0.05] Epoch 310/4000: train_loss=0.0060  test_loss=27.3613  λ_max=1.5316\n",
      "[Muon | lr=0.05] Epoch 311/4000: train_loss=0.0051  test_loss=27.4695  λ_max=1.5849\n",
      "[Muon | lr=0.05] Epoch 312/4000: train_loss=0.0049  test_loss=27.5113  λ_max=1.5986\n",
      "[Muon | lr=0.05] Iter 5000: loss=0.0042\n",
      "[Muon | lr=0.05] Epoch 313/4000: train_loss=0.0048  test_loss=27.4790  λ_max=1.5197\n",
      "[Muon | lr=0.05] Epoch 314/4000: train_loss=0.0046  test_loss=27.4842  λ_max=1.4964\n",
      "[Muon | lr=0.05] Epoch 315/4000: train_loss=0.0054  test_loss=27.5079  λ_max=1.5198\n",
      "[Muon | lr=0.05] Epoch 316/4000: train_loss=0.0051  test_loss=27.5316  λ_max=1.5462\n",
      "[Muon | lr=0.05] Epoch 317/4000: train_loss=0.0046  test_loss=27.6449  λ_max=1.5401\n",
      "[Muon | lr=0.05] Epoch 318/4000: train_loss=0.0048  test_loss=27.7448  λ_max=1.5276\n",
      "[Muon | lr=0.05] Iter 5100: loss=0.0046\n",
      "[Muon | lr=0.05] Epoch 319/4000: train_loss=0.0045  test_loss=27.8060  λ_max=1.6161\n",
      "[Muon | lr=0.05] Epoch 320/4000: train_loss=0.0050  test_loss=27.8541  λ_max=1.5277\n",
      "[Muon | lr=0.05] Epoch 321/4000: train_loss=0.0049  test_loss=27.8900  λ_max=1.6092\n",
      "[Muon | lr=0.05] Epoch 322/4000: train_loss=0.0047  test_loss=27.9528  λ_max=1.5763\n",
      "[Muon | lr=0.05] Epoch 323/4000: train_loss=0.0049  test_loss=28.0089  λ_max=1.6352\n",
      "[Muon | lr=0.05] Epoch 324/4000: train_loss=0.0051  test_loss=28.0636  λ_max=1.5019\n",
      "[Muon | lr=0.05] Iter 5200: loss=0.0055\n",
      "[Muon | lr=0.05] Epoch 325/4000: train_loss=0.0047  test_loss=28.1064  λ_max=1.5588\n",
      "[Muon | lr=0.05] Epoch 326/4000: train_loss=0.0050  test_loss=28.1812  λ_max=1.5728\n",
      "[Muon | lr=0.05] Epoch 327/4000: train_loss=0.0047  test_loss=28.2262  λ_max=1.6055\n",
      "[Muon | lr=0.05] Epoch 328/4000: train_loss=0.0050  test_loss=28.2861  λ_max=1.5955\n",
      "[Muon | lr=0.05] Epoch 329/4000: train_loss=0.0047  test_loss=28.2931  λ_max=1.5036\n",
      "[Muon | lr=0.05] Epoch 330/4000: train_loss=0.0043  test_loss=28.3095  λ_max=1.6267\n",
      "[Muon | lr=0.05] Epoch 331/4000: train_loss=0.0044  test_loss=28.3704  λ_max=1.6271\n",
      "[Muon | lr=0.05] Iter 5300: loss=0.0022\n",
      "[Muon | lr=0.05] Epoch 332/4000: train_loss=0.0047  test_loss=28.4045  λ_max=1.4625\n",
      "[Muon | lr=0.05] Epoch 333/4000: train_loss=0.0044  test_loss=28.4566  λ_max=1.5742\n",
      "[Muon | lr=0.05] Epoch 334/4000: train_loss=0.0048  test_loss=28.4575  λ_max=1.5622\n",
      "[Muon | lr=0.05] Epoch 335/4000: train_loss=0.0050  test_loss=28.5136  λ_max=1.6121\n",
      "[Muon | lr=0.05] Epoch 336/4000: train_loss=0.0048  test_loss=28.5040  λ_max=1.5998\n",
      "[Muon | lr=0.05] Epoch 337/4000: train_loss=0.0044  test_loss=28.5828  λ_max=1.4860\n",
      "[Muon | lr=0.05] Iter 5400: loss=0.0023\n",
      "[Muon | lr=0.05] Epoch 338/4000: train_loss=0.0044  test_loss=28.5882  λ_max=1.5975\n",
      "[Muon | lr=0.05] Epoch 339/4000: train_loss=0.0043  test_loss=28.6568  λ_max=1.5378\n",
      "[Muon | lr=0.05] Epoch 340/4000: train_loss=0.0043  test_loss=28.7628  λ_max=1.6233\n",
      "[Muon | lr=0.05] Epoch 341/4000: train_loss=0.0045  test_loss=28.8084  λ_max=1.6295\n",
      "[Muon | lr=0.05] Epoch 342/4000: train_loss=0.0052  test_loss=28.9463  λ_max=1.5483\n",
      "[Muon | lr=0.05] Epoch 343/4000: train_loss=0.0044  test_loss=28.9617  λ_max=1.5448\n",
      "[Muon | lr=0.05] Iter 5500: loss=0.0084\n",
      "[Muon | lr=0.05] Epoch 344/4000: train_loss=0.0046  test_loss=28.9791  λ_max=1.4937\n",
      "[Muon | lr=0.05] Epoch 345/4000: train_loss=0.0051  test_loss=28.9925  λ_max=1.6287\n",
      "[Muon | lr=0.05] Epoch 346/4000: train_loss=0.0048  test_loss=29.0322  λ_max=1.6087\n",
      "[Muon | lr=0.05] Epoch 347/4000: train_loss=0.0043  test_loss=29.0458  λ_max=1.5441\n",
      "[Muon | lr=0.05] Epoch 348/4000: train_loss=0.0051  test_loss=29.0320  λ_max=1.5533\n",
      "[Muon | lr=0.05] Epoch 349/4000: train_loss=0.0048  test_loss=29.1156  λ_max=1.6434\n",
      "[Muon | lr=0.05] Iter 5600: loss=0.0092\n",
      "[Muon | lr=0.05] Epoch 350/4000: train_loss=0.0047  test_loss=29.1532  λ_max=1.5270\n",
      "[Muon | lr=0.05] Epoch 351/4000: train_loss=0.0046  test_loss=29.2044  λ_max=1.5778\n",
      "[Muon | lr=0.05] Epoch 352/4000: train_loss=0.0043  test_loss=29.1792  λ_max=1.5568\n",
      "[Muon | lr=0.05] Epoch 353/4000: train_loss=0.0041  test_loss=29.3240  λ_max=1.5601\n",
      "[Muon | lr=0.05] Epoch 354/4000: train_loss=0.0046  test_loss=29.3822  λ_max=1.5619\n",
      "[Muon | lr=0.05] Epoch 355/4000: train_loss=0.0046  test_loss=29.5275  λ_max=1.5779\n",
      "[Muon | lr=0.05] Epoch 356/4000: train_loss=0.0043  test_loss=29.5746  λ_max=1.5547\n",
      "[Muon | lr=0.05] Iter 5700: loss=0.0018\n",
      "[Muon | lr=0.05] Epoch 357/4000: train_loss=0.0041  test_loss=29.6288  λ_max=1.4710\n",
      "[Muon | lr=0.05] Epoch 358/4000: train_loss=0.0045  test_loss=29.7275  λ_max=1.5201\n",
      "[Muon | lr=0.05] Epoch 359/4000: train_loss=0.0044  test_loss=29.8365  λ_max=1.3940\n",
      "[Muon | lr=0.05] Epoch 360/4000: train_loss=0.0042  test_loss=29.9476  λ_max=1.5118\n",
      "[Muon | lr=0.05] Epoch 361/4000: train_loss=0.0044  test_loss=29.9676  λ_max=1.5164\n",
      "[Muon | lr=0.05] Epoch 362/4000: train_loss=0.0045  test_loss=30.0019  λ_max=1.5769\n",
      "[Muon | lr=0.05] Iter 5800: loss=0.0053\n",
      "[Muon | lr=0.05] Epoch 363/4000: train_loss=0.0046  test_loss=29.9701  λ_max=1.5591\n",
      "[Muon | lr=0.05] Epoch 364/4000: train_loss=0.0042  test_loss=30.0136  λ_max=1.5540\n",
      "[Muon | lr=0.05] Epoch 365/4000: train_loss=0.0040  test_loss=30.0112  λ_max=1.4753\n",
      "[Muon | lr=0.05] Epoch 366/4000: train_loss=0.0045  test_loss=29.9808  λ_max=1.5926\n",
      "[Muon | lr=0.05] Epoch 367/4000: train_loss=0.0045  test_loss=30.0671  λ_max=1.4160\n",
      "[Muon | lr=0.05] Epoch 368/4000: train_loss=0.0040  test_loss=30.0848  λ_max=1.5107\n",
      "[Muon | lr=0.05] Iter 5900: loss=0.0037\n",
      "[Muon | lr=0.05] Epoch 369/4000: train_loss=0.0040  test_loss=30.1561  λ_max=1.5686\n",
      "[Muon | lr=0.05] Epoch 370/4000: train_loss=0.0042  test_loss=30.2144  λ_max=1.5227\n",
      "[Muon | lr=0.05] Epoch 371/4000: train_loss=0.0048  test_loss=30.1855  λ_max=1.5554\n",
      "[Muon | lr=0.05] Epoch 372/4000: train_loss=0.0043  test_loss=30.1690  λ_max=1.4877\n",
      "[Muon | lr=0.05] Epoch 373/4000: train_loss=0.0046  test_loss=30.1958  λ_max=1.5714\n",
      "[Muon | lr=0.05] Epoch 374/4000: train_loss=0.0041  test_loss=30.2658  λ_max=1.5469\n",
      "[Muon | lr=0.05] Iter 6000: loss=0.0077\n",
      "[Muon | lr=0.05] Epoch 375/4000: train_loss=0.0039  test_loss=30.3418  λ_max=1.5191\n",
      "[Muon | lr=0.05] Epoch 376/4000: train_loss=0.0038  test_loss=30.3208  λ_max=1.5282\n",
      "[Muon | lr=0.05] Epoch 377/4000: train_loss=0.0038  test_loss=30.3571  λ_max=1.5494\n",
      "[Muon | lr=0.05] Epoch 378/4000: train_loss=0.0042  test_loss=30.4210  λ_max=1.5019\n",
      "[Muon | lr=0.05] Epoch 379/4000: train_loss=0.0041  test_loss=30.5214  λ_max=1.5158\n",
      "[Muon | lr=0.05] Epoch 380/4000: train_loss=0.0038  test_loss=30.6370  λ_max=1.4727\n",
      "[Muon | lr=0.05] Epoch 381/4000: train_loss=0.0038  test_loss=30.5970  λ_max=1.4962\n",
      "[Muon | lr=0.05] Iter 6100: loss=0.0011\n",
      "[Muon | lr=0.05] Epoch 382/4000: train_loss=0.0041  test_loss=30.5949  λ_max=1.5219\n",
      "[Muon | lr=0.05] Epoch 383/4000: train_loss=0.0042  test_loss=30.6916  λ_max=1.5317\n",
      "[Muon | lr=0.05] Epoch 384/4000: train_loss=0.0045  test_loss=30.7594  λ_max=1.6227\n",
      "[Muon | lr=0.05] Epoch 385/4000: train_loss=0.0040  test_loss=30.8108  λ_max=1.5412\n",
      "[Muon | lr=0.05] Epoch 386/4000: train_loss=0.0041  test_loss=30.8992  λ_max=1.4981\n",
      "[Muon | lr=0.05] Epoch 387/4000: train_loss=0.0036  test_loss=30.9589  λ_max=1.4564\n",
      "[Muon | lr=0.05] Iter 6200: loss=0.0045\n",
      "[Muon | lr=0.05] Epoch 388/4000: train_loss=0.0042  test_loss=31.0514  λ_max=1.5492\n",
      "[Muon | lr=0.05] Epoch 389/4000: train_loss=0.0033  test_loss=31.1331  λ_max=1.5533\n",
      "[Muon | lr=0.05] Epoch 390/4000: train_loss=0.0038  test_loss=31.2388  λ_max=1.4037\n",
      "[Muon | lr=0.05] Epoch 391/4000: train_loss=0.0044  test_loss=31.2550  λ_max=1.5657\n",
      "[Muon | lr=0.05] Epoch 392/4000: train_loss=0.0036  test_loss=31.2832  λ_max=1.4376\n",
      "[Muon | lr=0.05] Epoch 393/4000: train_loss=0.0045  test_loss=31.3155  λ_max=1.4851\n",
      "[Muon | lr=0.05] Iter 6300: loss=0.0057\n",
      "[Muon | lr=0.05] Epoch 394/4000: train_loss=0.0039  test_loss=31.4601  λ_max=1.5609\n",
      "[Muon | lr=0.05] Epoch 395/4000: train_loss=0.0048  test_loss=31.6260  λ_max=1.5700\n",
      "[Muon | lr=0.05] Epoch 396/4000: train_loss=0.0042  test_loss=31.6421  λ_max=1.4922\n",
      "[Muon | lr=0.05] Epoch 397/4000: train_loss=0.0043  test_loss=31.6097  λ_max=1.4763\n",
      "[Muon | lr=0.05] Epoch 398/4000: train_loss=0.0040  test_loss=31.5719  λ_max=1.5283\n",
      "[Muon | lr=0.05] Epoch 399/4000: train_loss=0.0038  test_loss=31.5886  λ_max=1.4334\n",
      "[Muon | lr=0.05] Iter 6400: loss=0.0059\n",
      "[Muon | lr=0.05] Epoch 400/4000: train_loss=0.0036  test_loss=31.6158  λ_max=1.5294\n",
      "[Muon | lr=0.05] Epoch 401/4000: train_loss=0.0037  test_loss=31.6148  λ_max=1.5224\n",
      "[Muon | lr=0.05] Epoch 402/4000: train_loss=0.0038  test_loss=31.6506  λ_max=1.4889\n",
      "[Muon | lr=0.05] Epoch 403/4000: train_loss=0.0037  test_loss=31.7026  λ_max=1.5067\n",
      "[Muon | lr=0.05] Epoch 404/4000: train_loss=0.0034  test_loss=31.7695  λ_max=1.6261\n",
      "[Muon | lr=0.05] Epoch 405/4000: train_loss=0.0041  test_loss=31.7839  λ_max=1.4970\n",
      "[Muon | lr=0.05] Epoch 406/4000: train_loss=0.0039  test_loss=31.8804  λ_max=1.5354\n",
      "[Muon | lr=0.05] Iter 6500: loss=0.0017\n",
      "[Muon | lr=0.05] Epoch 407/4000: train_loss=0.0039  test_loss=31.8793  λ_max=1.5669\n",
      "[Muon | lr=0.05] Epoch 408/4000: train_loss=0.0041  test_loss=31.9313  λ_max=1.5687\n",
      "[Muon | lr=0.05] Epoch 409/4000: train_loss=0.0034  test_loss=31.9392  λ_max=1.4794\n",
      "[Muon | lr=0.05] Epoch 410/4000: train_loss=0.0041  test_loss=31.9366  λ_max=1.5089\n",
      "[Muon | lr=0.05] Epoch 411/4000: train_loss=0.0039  test_loss=31.9513  λ_max=1.4888\n",
      "[Muon | lr=0.05] Epoch 412/4000: train_loss=0.0038  test_loss=31.9696  λ_max=1.4735\n",
      "[Muon | lr=0.05] Iter 6600: loss=0.0027\n",
      "[Muon | lr=0.05] Epoch 413/4000: train_loss=0.0043  test_loss=32.0568  λ_max=1.4473\n",
      "[Muon | lr=0.05] Epoch 414/4000: train_loss=0.0039  test_loss=32.0399  λ_max=1.5486\n",
      "[Muon | lr=0.05] Epoch 415/4000: train_loss=0.0038  test_loss=32.0864  λ_max=1.5661\n",
      "[Muon | lr=0.05] Epoch 416/4000: train_loss=0.0039  test_loss=32.1978  λ_max=1.4453\n",
      "[Muon | lr=0.05] Epoch 417/4000: train_loss=0.0038  test_loss=32.3116  λ_max=1.5774\n",
      "[Muon | lr=0.05] Epoch 418/4000: train_loss=0.0041  test_loss=32.3676  λ_max=1.4697\n",
      "[Muon | lr=0.05] Iter 6700: loss=0.0080\n",
      "[Muon | lr=0.05] Epoch 419/4000: train_loss=0.0041  test_loss=32.3668  λ_max=1.5136\n",
      "[Muon | lr=0.05] Epoch 420/4000: train_loss=0.0036  test_loss=32.4495  λ_max=1.4900\n",
      "[Muon | lr=0.05] Epoch 421/4000: train_loss=0.0042  test_loss=32.4723  λ_max=1.5207\n",
      "[Muon | lr=0.05] Epoch 422/4000: train_loss=0.0033  test_loss=32.5030  λ_max=1.5397\n",
      "[Muon | lr=0.05] Epoch 423/4000: train_loss=0.0039  test_loss=32.5347  λ_max=1.5504\n",
      "[Muon | lr=0.05] Epoch 424/4000: train_loss=0.0041  test_loss=32.5522  λ_max=1.5053\n",
      "[Muon | lr=0.05] Iter 6800: loss=0.0050\n",
      "[Muon | lr=0.05] Epoch 425/4000: train_loss=0.0032  test_loss=32.5240  λ_max=1.5760\n",
      "[Muon | lr=0.05] Epoch 426/4000: train_loss=0.0037  test_loss=32.5153  λ_max=1.5003\n",
      "[Muon | lr=0.05] Epoch 427/4000: train_loss=0.0041  test_loss=32.5340  λ_max=1.5542\n",
      "[Muon | lr=0.05] Epoch 428/4000: train_loss=0.0040  test_loss=32.5712  λ_max=1.4454\n",
      "[Muon | lr=0.05] Epoch 429/4000: train_loss=0.0038  test_loss=32.5701  λ_max=1.5411\n",
      "[Muon | lr=0.05] Epoch 430/4000: train_loss=0.0038  test_loss=32.5671  λ_max=1.4997\n",
      "[Muon | lr=0.05] Epoch 431/4000: train_loss=0.0036  test_loss=32.6120  λ_max=1.5624\n",
      "[Muon | lr=0.05] Iter 6900: loss=0.0015\n",
      "[Muon | lr=0.05] Epoch 432/4000: train_loss=0.0041  test_loss=32.7859  λ_max=1.5559\n",
      "[Muon | lr=0.05] Epoch 433/4000: train_loss=0.0034  test_loss=32.8142  λ_max=1.5039\n",
      "[Muon | lr=0.05] Epoch 434/4000: train_loss=0.0038  test_loss=32.8270  λ_max=1.6127\n",
      "[Muon | lr=0.05] Epoch 435/4000: train_loss=0.0033  test_loss=32.9270  λ_max=1.6094\n",
      "[Muon | lr=0.05] Epoch 436/4000: train_loss=0.0038  test_loss=33.0399  λ_max=1.5778\n",
      "[Muon | lr=0.05] Epoch 437/4000: train_loss=0.0035  test_loss=33.1310  λ_max=1.6353\n",
      "[Muon | lr=0.05] Iter 7000: loss=0.0026\n",
      "[Muon | lr=0.05] Epoch 438/4000: train_loss=0.0036  test_loss=33.2463  λ_max=1.5440\n",
      "[Muon | lr=0.05] Epoch 439/4000: train_loss=0.0033  test_loss=33.3702  λ_max=1.4910\n",
      "[Muon | lr=0.05] Epoch 440/4000: train_loss=0.0036  test_loss=33.4595  λ_max=1.5266\n",
      "[Muon | lr=0.05] Epoch 441/4000: train_loss=0.0035  test_loss=33.4812  λ_max=1.5219\n",
      "[Muon | lr=0.05] Epoch 442/4000: train_loss=0.0036  test_loss=33.5398  λ_max=1.6265\n",
      "[Muon | lr=0.05] Epoch 443/4000: train_loss=0.0030  test_loss=33.5657  λ_max=1.4983\n",
      "[Muon | lr=0.05] Iter 7100: loss=0.0056\n",
      "[Muon | lr=0.05] Epoch 444/4000: train_loss=0.0036  test_loss=33.6127  λ_max=1.7089\n",
      "[Muon | lr=0.05] Epoch 445/4000: train_loss=0.0037  test_loss=33.6749  λ_max=1.4329\n",
      "[Muon | lr=0.05] Epoch 446/4000: train_loss=0.0036  test_loss=33.6662  λ_max=1.5393\n",
      "[Muon | lr=0.05] Epoch 447/4000: train_loss=0.0037  test_loss=33.6458  λ_max=1.5048\n",
      "[Muon | lr=0.05] Epoch 448/4000: train_loss=0.0035  test_loss=33.6728  λ_max=1.5417\n",
      "[Muon | lr=0.05] Epoch 449/4000: train_loss=0.0035  test_loss=33.7067  λ_max=1.4644\n",
      "[Muon | lr=0.05] Iter 7200: loss=0.0058\n",
      "[Muon | lr=0.05] Epoch 450/4000: train_loss=0.0037  test_loss=33.7342  λ_max=1.5613\n",
      "[Muon | lr=0.05] Epoch 451/4000: train_loss=0.0031  test_loss=33.7813  λ_max=1.5159\n",
      "[Muon | lr=0.05] Epoch 452/4000: train_loss=0.0037  test_loss=33.7514  λ_max=1.5393\n",
      "[Muon | lr=0.05] Epoch 453/4000: train_loss=0.0037  test_loss=33.7768  λ_max=1.4901\n",
      "[Muon | lr=0.05] Epoch 454/4000: train_loss=0.0036  test_loss=33.8118  λ_max=1.5348\n",
      "[Muon | lr=0.05] Epoch 455/4000: train_loss=0.0035  test_loss=33.8692  λ_max=1.5003\n",
      "[Muon | lr=0.05] Epoch 456/4000: train_loss=0.0035  test_loss=33.9184  λ_max=1.5868\n",
      "[Muon | lr=0.05] Iter 7300: loss=0.0007\n",
      "[Muon | lr=0.05] Epoch 457/4000: train_loss=0.0034  test_loss=33.9362  λ_max=1.5419\n",
      "[Muon | lr=0.05] Epoch 458/4000: train_loss=0.0037  test_loss=34.0285  λ_max=1.5939\n",
      "[Muon | lr=0.05] Epoch 459/4000: train_loss=0.0040  test_loss=34.0326  λ_max=1.5594\n",
      "[Muon | lr=0.05] Epoch 460/4000: train_loss=0.0037  test_loss=34.0837  λ_max=1.5383\n",
      "[Muon | lr=0.05] Epoch 461/4000: train_loss=0.0036  test_loss=34.1573  λ_max=1.4983\n",
      "[Muon | lr=0.05] Epoch 462/4000: train_loss=0.0037  test_loss=34.1722  λ_max=1.5156\n",
      "[Muon | lr=0.05] Iter 7400: loss=0.0039\n",
      "[Muon | lr=0.05] Epoch 463/4000: train_loss=0.0031  test_loss=34.2007  λ_max=1.4890\n",
      "[Muon | lr=0.05] Epoch 464/4000: train_loss=0.0034  test_loss=34.2583  λ_max=1.4976\n",
      "[Muon | lr=0.05] Epoch 465/4000: train_loss=0.0037  test_loss=34.3270  λ_max=1.4750\n",
      "[Muon | lr=0.05] Epoch 466/4000: train_loss=0.0036  test_loss=34.3998  λ_max=1.5141\n",
      "[Muon | lr=0.05] Epoch 467/4000: train_loss=0.0036  test_loss=34.4478  λ_max=1.5704\n",
      "[Muon | lr=0.05] Epoch 468/4000: train_loss=0.0032  test_loss=34.5238  λ_max=1.5237\n",
      "[Muon | lr=0.05] Iter 7500: loss=0.0044\n",
      "[Muon | lr=0.05] Epoch 469/4000: train_loss=0.0032  test_loss=34.5851  λ_max=1.5777\n",
      "[Muon | lr=0.05] Epoch 470/4000: train_loss=0.0033  test_loss=34.6344  λ_max=1.5273\n",
      "[Muon | lr=0.05] Epoch 471/4000: train_loss=0.0037  test_loss=34.6683  λ_max=1.4957\n",
      "[Muon | lr=0.05] Epoch 472/4000: train_loss=0.0035  test_loss=34.7726  λ_max=1.4600\n",
      "[Muon | lr=0.05] Epoch 473/4000: train_loss=0.0036  test_loss=34.8020  λ_max=1.5408\n",
      "[Muon | lr=0.05] Epoch 474/4000: train_loss=0.0036  test_loss=34.7963  λ_max=1.4464\n",
      "[Muon | lr=0.05] Iter 7600: loss=0.0063\n",
      "[Muon | lr=0.05] Epoch 475/4000: train_loss=0.0032  test_loss=34.8682  λ_max=1.4749\n",
      "[Muon | lr=0.05] Epoch 476/4000: train_loss=0.0030  test_loss=34.8828  λ_max=1.4488\n",
      "[Muon | lr=0.05] Epoch 477/4000: train_loss=0.0038  test_loss=35.0004  λ_max=1.5513\n",
      "[Muon | lr=0.05] Epoch 478/4000: train_loss=0.0037  test_loss=35.0853  λ_max=1.5735\n",
      "[Muon | lr=0.05] Epoch 479/4000: train_loss=0.0037  test_loss=35.1164  λ_max=1.4989\n",
      "[Muon | lr=0.05] Epoch 480/4000: train_loss=0.0041  test_loss=35.1826  λ_max=1.5658\n",
      "[Muon | lr=0.05] Epoch 481/4000: train_loss=0.0030  test_loss=35.1794  λ_max=1.5059\n",
      "[Muon | lr=0.05] Iter 7700: loss=0.0012\n",
      "[Muon | lr=0.05] Epoch 482/4000: train_loss=0.0036  test_loss=35.1276  λ_max=1.5277\n",
      "[Muon | lr=0.05] Epoch 483/4000: train_loss=0.0035  test_loss=35.1295  λ_max=1.6939\n",
      "[Muon | lr=0.05] Epoch 484/4000: train_loss=0.0036  test_loss=35.0805  λ_max=1.4701\n",
      "[Muon | lr=0.05] Epoch 485/4000: train_loss=0.0033  test_loss=35.0930  λ_max=1.4809\n",
      "[Muon | lr=0.05] Epoch 486/4000: train_loss=0.0034  test_loss=35.1388  λ_max=1.5218\n",
      "[Muon | lr=0.05] Epoch 487/4000: train_loss=0.0028  test_loss=35.1308  λ_max=1.5763\n",
      "[Muon | lr=0.05] Iter 7800: loss=0.0041\n",
      "[Muon | lr=0.05] Epoch 488/4000: train_loss=0.0038  test_loss=35.1489  λ_max=1.5244\n",
      "[Muon | lr=0.05] Epoch 489/4000: train_loss=0.0032  test_loss=35.1798  λ_max=1.5587\n",
      "[Muon | lr=0.05] Epoch 490/4000: train_loss=0.0030  test_loss=35.1821  λ_max=1.4844\n",
      "[Muon | lr=0.05] Epoch 491/4000: train_loss=0.0031  test_loss=35.2261  λ_max=1.5737\n",
      "[Muon | lr=0.05] Epoch 492/4000: train_loss=0.0031  test_loss=35.2206  λ_max=1.5410\n",
      "[Muon | lr=0.05] Epoch 493/4000: train_loss=0.0033  test_loss=35.3296  λ_max=1.5685\n",
      "[Muon | lr=0.05] Iter 7900: loss=0.0033\n",
      "[Muon | lr=0.05] Epoch 494/4000: train_loss=0.0027  test_loss=35.4628  λ_max=1.4892\n",
      "[Muon | lr=0.05] Epoch 495/4000: train_loss=0.0035  test_loss=35.5309  λ_max=1.5716\n",
      "[Muon | lr=0.05] Epoch 496/4000: train_loss=0.0031  test_loss=35.5597  λ_max=1.5091\n",
      "[Muon | lr=0.05] Epoch 497/4000: train_loss=0.0033  test_loss=35.5530  λ_max=1.5422\n",
      "[Muon | lr=0.05] Epoch 498/4000: train_loss=0.0030  test_loss=35.5108  λ_max=1.5945\n",
      "[Muon | lr=0.05] Epoch 499/4000: train_loss=0.0037  test_loss=35.5758  λ_max=1.5505\n",
      "[Muon | lr=0.05] Iter 8000: loss=0.0083\n",
      "[Muon | lr=0.05] Epoch 500/4000: train_loss=0.0037  test_loss=35.6317  λ_max=1.5172\n",
      "[Muon | lr=0.05] Epoch 501/4000: train_loss=0.0035  test_loss=35.6877  λ_max=1.5513\n",
      "[Muon | lr=0.05] Epoch 502/4000: train_loss=0.0034  test_loss=35.7987  λ_max=1.6294\n",
      "[Muon | lr=0.05] Epoch 503/4000: train_loss=0.0035  test_loss=35.8732  λ_max=1.4992\n",
      "[Muon | lr=0.05] Epoch 504/4000: train_loss=0.0034  test_loss=35.8954  λ_max=1.6304\n",
      "[Muon | lr=0.05] Epoch 505/4000: train_loss=0.0035  test_loss=35.9294  λ_max=1.4970\n",
      "[Muon | lr=0.05] Epoch 506/4000: train_loss=0.0034  test_loss=35.9324  λ_max=1.6084\n",
      "[Muon | lr=0.05] Iter 8100: loss=0.0005\n",
      "[Muon | lr=0.05] Epoch 507/4000: train_loss=0.0031  test_loss=35.9486  λ_max=1.6395\n",
      "[Muon | lr=0.05] Epoch 508/4000: train_loss=0.0028  test_loss=36.0089  λ_max=1.4728\n",
      "[Muon | lr=0.05] Epoch 509/4000: train_loss=0.0031  test_loss=36.0350  λ_max=1.6364\n",
      "[Muon | lr=0.05] Epoch 510/4000: train_loss=0.0031  test_loss=36.0440  λ_max=1.5302\n",
      "[Muon | lr=0.05] Epoch 511/4000: train_loss=0.0029  test_loss=36.1006  λ_max=1.6190\n",
      "[Muon | lr=0.05] Epoch 512/4000: train_loss=0.0030  test_loss=36.1385  λ_max=1.4946\n",
      "[Muon | lr=0.05] Iter 8200: loss=0.0028\n",
      "[Muon | lr=0.05] Epoch 513/4000: train_loss=0.0033  test_loss=36.1465  λ_max=1.5243\n",
      "[Muon | lr=0.05] Epoch 514/4000: train_loss=0.0031  test_loss=36.2168  λ_max=1.5297\n",
      "[Muon | lr=0.05] Epoch 515/4000: train_loss=0.0032  test_loss=36.2204  λ_max=1.6525\n",
      "[Muon | lr=0.05] Epoch 516/4000: train_loss=0.0034  test_loss=36.3117  λ_max=1.6098\n",
      "[Muon | lr=0.05] Epoch 517/4000: train_loss=0.0033  test_loss=36.3885  λ_max=1.6399\n",
      "[Muon | lr=0.05] Epoch 518/4000: train_loss=0.0031  test_loss=36.4507  λ_max=1.5104\n",
      "[Muon | lr=0.05] Iter 8300: loss=0.0049\n",
      "[Muon | lr=0.05] Epoch 519/4000: train_loss=0.0033  test_loss=36.4255  λ_max=1.6030\n",
      "[Muon | lr=0.05] Epoch 520/4000: train_loss=0.0033  test_loss=36.4398  λ_max=1.5402\n",
      "[Muon | lr=0.05] Epoch 521/4000: train_loss=0.0029  test_loss=36.4451  λ_max=1.6576\n",
      "[Muon | lr=0.05] Epoch 522/4000: train_loss=0.0029  test_loss=36.5016  λ_max=1.6537\n",
      "[Muon | lr=0.05] Epoch 523/4000: train_loss=0.0033  test_loss=36.6023  λ_max=1.5347\n",
      "[Muon | lr=0.05] Epoch 524/4000: train_loss=0.0030  test_loss=36.5727  λ_max=1.5173\n",
      "[Muon | lr=0.05] Iter 8400: loss=0.0084\n",
      "[Muon | lr=0.05] Epoch 525/4000: train_loss=0.0034  test_loss=36.5327  λ_max=1.6453\n",
      "[Muon | lr=0.05] Epoch 526/4000: train_loss=0.0028  test_loss=36.4642  λ_max=1.5579\n",
      "[Muon | lr=0.05] Epoch 527/4000: train_loss=0.0033  test_loss=36.4197  λ_max=1.7199\n",
      "[Muon | lr=0.05] Epoch 528/4000: train_loss=0.0033  test_loss=36.4556  λ_max=1.7000\n",
      "[Muon | lr=0.05] Epoch 529/4000: train_loss=0.0030  test_loss=36.5858  λ_max=1.5382\n",
      "[Muon | lr=0.05] Epoch 530/4000: train_loss=0.0031  test_loss=36.6619  λ_max=1.6893\n",
      "[Muon | lr=0.05] Epoch 531/4000: train_loss=0.0030  test_loss=36.6472  λ_max=1.5336\n",
      "[Muon | lr=0.05] Iter 8500: loss=0.0012\n",
      "[Muon | lr=0.05] Epoch 532/4000: train_loss=0.0032  test_loss=36.7380  λ_max=1.5344\n",
      "[Muon | lr=0.05] Epoch 533/4000: train_loss=0.0030  test_loss=36.7647  λ_max=1.6169\n",
      "[Muon | lr=0.05] Epoch 534/4000: train_loss=0.0028  test_loss=36.8330  λ_max=1.5714\n",
      "[Muon | lr=0.05] Epoch 535/4000: train_loss=0.0031  test_loss=36.9581  λ_max=1.6024\n",
      "[Muon | lr=0.05] Epoch 536/4000: train_loss=0.0027  test_loss=37.0375  λ_max=1.5669\n",
      "[Muon | lr=0.05] Epoch 537/4000: train_loss=0.0035  test_loss=37.1181  λ_max=1.5659\n",
      "[Muon | lr=0.05] Iter 8600: loss=0.0018\n",
      "[Muon | lr=0.05] Epoch 538/4000: train_loss=0.0035  test_loss=37.1290  λ_max=1.4540\n",
      "[Muon | lr=0.05] Epoch 539/4000: train_loss=0.0033  test_loss=37.1404  λ_max=1.5412\n",
      "[Muon | lr=0.05] Epoch 540/4000: train_loss=0.0037  test_loss=37.2096  λ_max=1.5121\n",
      "[Muon | lr=0.05] Epoch 541/4000: train_loss=0.0034  test_loss=37.2494  λ_max=1.6206\n",
      "[Muon | lr=0.05] Epoch 542/4000: train_loss=0.0034  test_loss=37.2924  λ_max=1.5583\n",
      "[Muon | lr=0.05] Epoch 543/4000: train_loss=0.0028  test_loss=37.2719  λ_max=1.6397\n",
      "[Muon | lr=0.05] Iter 8700: loss=0.0071\n",
      "[Muon | lr=0.05] Epoch 544/4000: train_loss=0.0030  test_loss=37.2784  λ_max=1.5392\n",
      "[Muon | lr=0.05] Epoch 545/4000: train_loss=0.0030  test_loss=37.3002  λ_max=1.6788\n",
      "[Muon | lr=0.05] Epoch 546/4000: train_loss=0.0032  test_loss=37.3483  λ_max=1.6112\n",
      "[Muon | lr=0.05] Epoch 547/4000: train_loss=0.0030  test_loss=37.3816  λ_max=1.6286\n",
      "[Muon | lr=0.05] Epoch 548/4000: train_loss=0.0031  test_loss=37.4132  λ_max=1.5306\n",
      "[Muon | lr=0.05] Epoch 549/4000: train_loss=0.0026  test_loss=37.4504  λ_max=1.6328\n",
      "[Muon | lr=0.05] Iter 8800: loss=0.0058\n",
      "[Muon | lr=0.05] Epoch 550/4000: train_loss=0.0029  test_loss=37.5070  λ_max=1.5346\n",
      "[Muon | lr=0.05] Epoch 551/4000: train_loss=0.0036  test_loss=37.5234  λ_max=1.5314\n",
      "[Muon | lr=0.05] Epoch 552/4000: train_loss=0.0030  test_loss=37.5794  λ_max=1.5794\n",
      "[Muon | lr=0.05] Epoch 553/4000: train_loss=0.0030  test_loss=37.5022  λ_max=1.5277\n",
      "[Muon | lr=0.05] Epoch 554/4000: train_loss=0.0029  test_loss=37.5376  λ_max=1.5752\n",
      "[Muon | lr=0.05] Epoch 555/4000: train_loss=0.0031  test_loss=37.5876  λ_max=1.5860\n",
      "[Muon | lr=0.05] Epoch 556/4000: train_loss=0.0029  test_loss=37.6704  λ_max=1.5686\n",
      "[Muon | lr=0.05] Iter 8900: loss=0.0019\n",
      "[Muon | lr=0.05] Epoch 557/4000: train_loss=0.0036  test_loss=37.7422  λ_max=1.6437\n",
      "[Muon | lr=0.05] Epoch 558/4000: train_loss=0.0034  test_loss=37.7347  λ_max=1.5523\n",
      "[Muon | lr=0.05] Epoch 559/4000: train_loss=0.0035  test_loss=37.7398  λ_max=1.5385\n",
      "[Muon | lr=0.05] Epoch 560/4000: train_loss=0.0031  test_loss=37.7743  λ_max=1.5423\n",
      "[Muon | lr=0.05] Epoch 561/4000: train_loss=0.0028  test_loss=37.8139  λ_max=1.5879\n",
      "[Muon | lr=0.05] Epoch 562/4000: train_loss=0.0029  test_loss=37.8518  λ_max=1.5786\n",
      "[Muon | lr=0.05] Iter 9000: loss=0.0030\n",
      "[Muon | lr=0.05] Epoch 563/4000: train_loss=0.0033  test_loss=37.8648  λ_max=1.5696\n",
      "[Muon | lr=0.05] Epoch 564/4000: train_loss=0.0026  test_loss=37.8721  λ_max=1.6380\n",
      "[Muon | lr=0.05] Epoch 565/4000: train_loss=0.0028  test_loss=37.9395  λ_max=1.4334\n",
      "[Muon | lr=0.05] Epoch 566/4000: train_loss=0.0034  test_loss=37.9174  λ_max=1.5617\n",
      "[Muon | lr=0.05] Epoch 567/4000: train_loss=0.0032  test_loss=37.9181  λ_max=1.6212\n",
      "[Muon | lr=0.05] Epoch 568/4000: train_loss=0.0031  test_loss=37.9039  λ_max=1.6033\n",
      "[Muon | lr=0.05] Iter 9100: loss=0.0038\n",
      "[Muon | lr=0.05] Epoch 569/4000: train_loss=0.0033  test_loss=37.9308  λ_max=1.6336\n",
      "[Muon | lr=0.05] Epoch 570/4000: train_loss=0.0029  test_loss=37.9854  λ_max=1.5486\n",
      "[Muon | lr=0.05] Epoch 571/4000: train_loss=0.0030  test_loss=37.9731  λ_max=1.6161\n",
      "[Muon | lr=0.05] Epoch 572/4000: train_loss=0.0029  test_loss=37.9820  λ_max=1.6981\n",
      "[Muon | lr=0.05] Epoch 573/4000: train_loss=0.0027  test_loss=38.0098  λ_max=1.5733\n",
      "[Muon | lr=0.05] Epoch 574/4000: train_loss=0.0026  test_loss=38.0447  λ_max=1.6405\n",
      "[Muon | lr=0.05] Iter 9200: loss=0.0043\n",
      "[Muon | lr=0.05] Epoch 575/4000: train_loss=0.0028  test_loss=38.0810  λ_max=1.6712\n",
      "[Muon | lr=0.05] Epoch 576/4000: train_loss=0.0024  test_loss=38.1423  λ_max=1.4923\n",
      "[Muon | lr=0.05] Epoch 577/4000: train_loss=0.0027  test_loss=38.1074  λ_max=1.6419\n",
      "[Muon | lr=0.05] Epoch 578/4000: train_loss=0.0027  test_loss=38.1154  λ_max=1.6043\n",
      "[Muon | lr=0.05] Epoch 579/4000: train_loss=0.0028  test_loss=38.1765  λ_max=1.5706\n",
      "[Muon | lr=0.05] Epoch 580/4000: train_loss=0.0030  test_loss=38.2029  λ_max=1.5467\n",
      "[Muon | lr=0.05] Epoch 581/4000: train_loss=0.0026  test_loss=38.3324  λ_max=1.6223\n",
      "[Muon | lr=0.05] Iter 9300: loss=0.0009\n",
      "[Muon | lr=0.05] Epoch 582/4000: train_loss=0.0029  test_loss=38.4466  λ_max=1.6195\n",
      "[Muon | lr=0.05] Epoch 583/4000: train_loss=0.0028  test_loss=38.4807  λ_max=1.6179\n",
      "[Muon | lr=0.05] Epoch 584/4000: train_loss=0.0025  test_loss=38.5407  λ_max=1.5308\n",
      "[Muon | lr=0.05] Epoch 585/4000: train_loss=0.0027  test_loss=38.5955  λ_max=1.5618\n",
      "[Muon | lr=0.05] Epoch 586/4000: train_loss=0.0030  test_loss=38.5709  λ_max=1.6101\n",
      "[Muon | lr=0.05] Epoch 587/4000: train_loss=0.0032  test_loss=38.5692  λ_max=1.5670\n",
      "[Muon | lr=0.05] Iter 9400: loss=0.0025\n",
      "[Muon | lr=0.05] Epoch 588/4000: train_loss=0.0028  test_loss=38.5943  λ_max=1.5353\n",
      "[Muon | lr=0.05] Epoch 589/4000: train_loss=0.0027  test_loss=38.6302  λ_max=1.5891\n",
      "[Muon | lr=0.05] Epoch 590/4000: train_loss=0.0031  test_loss=38.6419  λ_max=1.5907\n",
      "[Muon | lr=0.05] Epoch 591/4000: train_loss=0.0027  test_loss=38.6261  λ_max=1.5754\n",
      "[Muon | lr=0.05] Epoch 592/4000: train_loss=0.0024  test_loss=38.7347  λ_max=1.5941\n",
      "[Muon | lr=0.05] Epoch 593/4000: train_loss=0.0028  test_loss=38.7427  λ_max=1.6146\n",
      "[Muon | lr=0.05] Iter 9500: loss=0.0076\n",
      "[Muon | lr=0.05] Epoch 594/4000: train_loss=0.0031  test_loss=38.8100  λ_max=1.5170\n",
      "[Muon | lr=0.05] Epoch 595/4000: train_loss=0.0035  test_loss=38.8393  λ_max=1.5624\n",
      "[Muon | lr=0.05] Epoch 596/4000: train_loss=0.0029  test_loss=38.8787  λ_max=1.5937\n",
      "[Muon | lr=0.05] Epoch 597/4000: train_loss=0.0027  test_loss=38.9438  λ_max=1.5561\n",
      "[Muon | lr=0.05] Epoch 598/4000: train_loss=0.0030  test_loss=39.0603  λ_max=1.6400\n",
      "[Muon | lr=0.05] Epoch 599/4000: train_loss=0.0029  test_loss=39.1340  λ_max=1.5818\n",
      "[Muon | lr=0.05] Iter 9600: loss=0.0079\n",
      "[Muon | lr=0.05] Epoch 600/4000: train_loss=0.0031  test_loss=39.1555  λ_max=1.5740\n",
      "[Muon | lr=0.05] Epoch 601/4000: train_loss=0.0030  test_loss=39.1347  λ_max=1.6020\n",
      "[Muon | lr=0.05] Epoch 602/4000: train_loss=0.0028  test_loss=39.1172  λ_max=1.6967\n",
      "[Muon | lr=0.05] Epoch 603/4000: train_loss=0.0028  test_loss=39.2295  λ_max=1.5349\n",
      "[Muon | lr=0.05] Epoch 604/4000: train_loss=0.0027  test_loss=39.3009  λ_max=1.4726\n",
      "[Muon | lr=0.05] Epoch 605/4000: train_loss=0.0027  test_loss=39.3645  λ_max=1.5983\n",
      "[Muon | lr=0.05] Epoch 606/4000: train_loss=0.0024  test_loss=39.4576  λ_max=1.5962\n",
      "[Muon | lr=0.05] Iter 9700: loss=0.0006\n",
      "[Muon | lr=0.05] Epoch 607/4000: train_loss=0.0027  test_loss=39.5612  λ_max=1.5187\n",
      "[Muon | lr=0.05] Epoch 608/4000: train_loss=0.0022  test_loss=39.6431  λ_max=1.5595\n",
      "[Muon | lr=0.05] Epoch 609/4000: train_loss=0.0029  test_loss=39.6983  λ_max=1.5158\n",
      "[Muon | lr=0.05] Epoch 610/4000: train_loss=0.0025  test_loss=39.6349  λ_max=1.5682\n",
      "[Muon | lr=0.05] Epoch 611/4000: train_loss=0.0027  test_loss=39.6721  λ_max=1.5835\n",
      "[Muon | lr=0.05] Epoch 612/4000: train_loss=0.0024  test_loss=39.7001  λ_max=1.5459\n",
      "[Muon | lr=0.05] Iter 9800: loss=0.0026\n",
      "[Muon | lr=0.05] Epoch 613/4000: train_loss=0.0024  test_loss=39.7924  λ_max=1.5222\n",
      "[Muon | lr=0.05] Epoch 614/4000: train_loss=0.0031  test_loss=39.8264  λ_max=1.5370\n",
      "[Muon | lr=0.05] Epoch 615/4000: train_loss=0.0028  test_loss=39.7777  λ_max=1.6018\n",
      "[Muon | lr=0.05] Epoch 616/4000: train_loss=0.0028  test_loss=39.7575  λ_max=1.6000\n",
      "[Muon | lr=0.05] Epoch 617/4000: train_loss=0.0024  test_loss=39.8133  λ_max=1.5723\n",
      "[Muon | lr=0.05] Epoch 618/4000: train_loss=0.0027  test_loss=39.8739  λ_max=1.5474\n",
      "[Muon | lr=0.05] Iter 9900: loss=0.0049\n",
      "[Muon | lr=0.05] Epoch 619/4000: train_loss=0.0029  test_loss=39.9294  λ_max=1.5754\n",
      "[Muon | lr=0.05] Epoch 620/4000: train_loss=0.0031  test_loss=39.9140  λ_max=1.5827\n",
      "[Muon | lr=0.05] Epoch 621/4000: train_loss=0.0027  test_loss=39.9617  λ_max=1.6045\n",
      "[Muon | lr=0.05] Epoch 622/4000: train_loss=0.0028  test_loss=40.0201  λ_max=1.6312\n",
      "[Muon | lr=0.05] Epoch 623/4000: train_loss=0.0028  test_loss=40.1276  λ_max=1.6656\n",
      "[Muon | lr=0.05] Epoch 624/4000: train_loss=0.0028  test_loss=40.0968  λ_max=1.5801\n",
      "[Muon | lr=0.05] Iter 10000: loss=0.0059\n",
      "[Muon | lr=0.05] Epoch 625/4000: train_loss=0.0030  test_loss=40.1383  λ_max=1.5643\n",
      "[Muon | lr=0.05] Epoch 626/4000: train_loss=0.0028  test_loss=40.1848  λ_max=1.5608\n",
      "[Muon | lr=0.05] Epoch 627/4000: train_loss=0.0033  test_loss=40.1979  λ_max=1.6730\n",
      "[Muon | lr=0.05] Epoch 628/4000: train_loss=0.0031  test_loss=40.2899  λ_max=1.5597\n",
      "[Muon | lr=0.05] Epoch 629/4000: train_loss=0.0027  test_loss=40.2878  λ_max=1.6879\n",
      "[Muon | lr=0.05] Epoch 630/4000: train_loss=0.0029  test_loss=40.3246  λ_max=1.4780\n",
      "[Muon | lr=0.05] Epoch 631/4000: train_loss=0.0024  test_loss=40.4104  λ_max=1.6487\n",
      "[Muon | lr=0.05] Iter 10100: loss=0.0006\n",
      "[Muon | lr=0.05] Epoch 632/4000: train_loss=0.0024  test_loss=40.4952  λ_max=1.6516\n",
      "[Muon | lr=0.05] Epoch 633/4000: train_loss=0.0027  test_loss=40.5227  λ_max=1.4864\n",
      "[Muon | lr=0.05] Epoch 634/4000: train_loss=0.0024  test_loss=40.5584  λ_max=1.6476\n",
      "[Muon | lr=0.05] Epoch 635/4000: train_loss=0.0030  test_loss=40.5769  λ_max=1.6772\n",
      "[Muon | lr=0.05] Epoch 636/4000: train_loss=0.0025  test_loss=40.5498  λ_max=1.5944\n",
      "[Muon | lr=0.05] Epoch 637/4000: train_loss=0.0029  test_loss=40.6050  λ_max=1.5847\n",
      "[Muon | lr=0.05] Iter 10200: loss=0.0018\n",
      "[Muon | lr=0.05] Epoch 638/4000: train_loss=0.0030  test_loss=40.6336  λ_max=1.6452\n",
      "[Muon | lr=0.05] Epoch 639/4000: train_loss=0.0026  test_loss=40.5983  λ_max=1.6250\n",
      "[Muon | lr=0.05] Epoch 640/4000: train_loss=0.0026  test_loss=40.6396  λ_max=1.8108\n",
      "[Muon | lr=0.05] Epoch 641/4000: train_loss=0.0027  test_loss=40.6309  λ_max=1.6275\n",
      "[Muon | lr=0.05] Epoch 642/4000: train_loss=0.0024  test_loss=40.6351  λ_max=1.6342\n",
      "[Muon | lr=0.05] Epoch 643/4000: train_loss=0.0029  test_loss=40.6985  λ_max=1.5192\n",
      "[Muon | lr=0.05] Iter 10300: loss=0.0038\n",
      "[Muon | lr=0.05] Epoch 644/4000: train_loss=0.0028  test_loss=40.7520  λ_max=1.6455\n",
      "[Muon | lr=0.05] Epoch 645/4000: train_loss=0.0023  test_loss=40.7554  λ_max=1.5716\n",
      "[Muon | lr=0.05] Epoch 646/4000: train_loss=0.0026  test_loss=40.7102  λ_max=1.5393\n",
      "[Muon | lr=0.05] Epoch 647/4000: train_loss=0.0029  test_loss=40.7265  λ_max=1.6664\n",
      "[Muon | lr=0.05] Epoch 648/4000: train_loss=0.0026  test_loss=40.7576  λ_max=1.6065\n",
      "[Muon | lr=0.05] Epoch 649/4000: train_loss=0.0030  test_loss=40.8165  λ_max=1.5921\n",
      "[Muon | lr=0.05] Iter 10400: loss=0.0084\n",
      "[Muon | lr=0.05] Epoch 650/4000: train_loss=0.0032  test_loss=40.8462  λ_max=1.6245\n",
      "[Muon | lr=0.05] Epoch 651/4000: train_loss=0.0024  test_loss=40.8972  λ_max=1.6419\n",
      "[Muon | lr=0.05] Epoch 652/4000: train_loss=0.0027  test_loss=40.9034  λ_max=1.5774\n",
      "[Muon | lr=0.05] Epoch 653/4000: train_loss=0.0027  test_loss=40.9035  λ_max=1.6681\n",
      "[Muon | lr=0.05] Epoch 654/4000: train_loss=0.0024  test_loss=40.8061  λ_max=1.6253\n",
      "[Muon | lr=0.05] Epoch 655/4000: train_loss=0.0027  test_loss=40.7089  λ_max=1.6787\n",
      "[Muon | lr=0.05] Epoch 656/4000: train_loss=0.0024  test_loss=40.7027  λ_max=1.5764\n",
      "[Muon | lr=0.05] Iter 10500: loss=0.0016\n",
      "[Muon | lr=0.05] Epoch 657/4000: train_loss=0.0025  test_loss=40.7112  λ_max=1.7114\n",
      "[Muon | lr=0.05] Epoch 658/4000: train_loss=0.0029  test_loss=40.7316  λ_max=1.5861\n",
      "[Muon | lr=0.05] Epoch 659/4000: train_loss=0.0025  test_loss=40.7353  λ_max=1.7349\n",
      "[Muon | lr=0.05] Epoch 660/4000: train_loss=0.0023  test_loss=40.7215  λ_max=1.5336\n",
      "[Muon | lr=0.05] Epoch 661/4000: train_loss=0.0027  test_loss=40.8160  λ_max=1.6180\n",
      "[Muon | lr=0.05] Epoch 662/4000: train_loss=0.0026  test_loss=40.8852  λ_max=1.6212\n",
      "[Muon | lr=0.05] Iter 10600: loss=0.0027\n",
      "[Muon | lr=0.05] Epoch 663/4000: train_loss=0.0024  test_loss=40.9144  λ_max=1.5878\n",
      "[Muon | lr=0.05] Epoch 664/4000: train_loss=0.0023  test_loss=41.0237  λ_max=1.5832\n",
      "[Muon | lr=0.05] Epoch 665/4000: train_loss=0.0020  test_loss=41.0960  λ_max=1.6329\n",
      "[Muon | lr=0.05] Epoch 666/4000: train_loss=0.0025  test_loss=41.0882  λ_max=1.5845\n",
      "[Muon | lr=0.05] Epoch 667/4000: train_loss=0.0029  test_loss=41.1590  λ_max=1.7162\n",
      "[Muon | lr=0.05] Epoch 668/4000: train_loss=0.0027  test_loss=41.1678  λ_max=1.5724\n",
      "[Muon | lr=0.05] Iter 10700: loss=0.0042\n",
      "[Muon | lr=0.05] Epoch 669/4000: train_loss=0.0030  test_loss=41.2110  λ_max=1.5204\n",
      "[Muon | lr=0.05] Epoch 670/4000: train_loss=0.0023  test_loss=41.2204  λ_max=1.6855\n",
      "[Muon | lr=0.05] Epoch 671/4000: train_loss=0.0020  test_loss=41.2979  λ_max=1.7093\n",
      "[Muon | lr=0.05] Epoch 672/4000: train_loss=0.0027  test_loss=41.2875  λ_max=1.5369\n",
      "[Muon | lr=0.05] Epoch 673/4000: train_loss=0.0031  test_loss=41.3677  λ_max=1.6719\n",
      "[Muon | lr=0.05] Epoch 674/4000: train_loss=0.0023  test_loss=41.4204  λ_max=1.7356\n",
      "[Muon | lr=0.05] Iter 10800: loss=0.0077\n",
      "[Muon | lr=0.05] Epoch 675/4000: train_loss=0.0023  test_loss=41.4917  λ_max=1.6140\n",
      "[Muon | lr=0.05] Epoch 676/4000: train_loss=0.0026  test_loss=41.5771  λ_max=1.7036\n",
      "[Muon | lr=0.05] Epoch 677/4000: train_loss=0.0026  test_loss=41.6681  λ_max=1.6411\n",
      "[Muon | lr=0.05] Epoch 678/4000: train_loss=0.0025  test_loss=41.7341  λ_max=1.6480\n",
      "[Muon | lr=0.05] Epoch 679/4000: train_loss=0.0025  test_loss=41.7039  λ_max=1.5998\n",
      "[Muon | lr=0.05] Epoch 680/4000: train_loss=0.0025  test_loss=41.7869  λ_max=1.6201\n",
      "[Muon | lr=0.05] Epoch 681/4000: train_loss=0.0028  test_loss=41.8121  λ_max=1.5720\n",
      "[Muon | lr=0.05] Iter 10900: loss=0.0014\n",
      "[Muon | lr=0.05] Epoch 682/4000: train_loss=0.0024  test_loss=41.8273  λ_max=1.5264\n",
      "[Muon | lr=0.05] Epoch 683/4000: train_loss=0.0022  test_loss=41.9186  λ_max=1.6310\n",
      "[Muon | lr=0.05] Epoch 684/4000: train_loss=0.0024  test_loss=41.9522  λ_max=1.5933\n",
      "[Muon | lr=0.05] Epoch 685/4000: train_loss=0.0026  test_loss=41.9683  λ_max=1.6431\n",
      "[Muon | lr=0.05] Epoch 686/4000: train_loss=0.0027  test_loss=41.9984  λ_max=1.6401\n",
      "[Muon | lr=0.05] Epoch 687/4000: train_loss=0.0027  test_loss=41.9981  λ_max=1.6126\n",
      "[Muon | lr=0.05] Iter 11000: loss=0.0019\n",
      "[Muon | lr=0.05] Epoch 688/4000: train_loss=0.0024  test_loss=42.0618  λ_max=1.6129\n",
      "[Muon | lr=0.05] Epoch 689/4000: train_loss=0.0024  test_loss=42.1022  λ_max=1.5641\n",
      "[Muon | lr=0.05] Epoch 690/4000: train_loss=0.0023  test_loss=42.2182  λ_max=1.6163\n",
      "[Muon | lr=0.05] Epoch 691/4000: train_loss=0.0025  test_loss=42.3034  λ_max=1.6148\n",
      "[Muon | lr=0.05] Epoch 692/4000: train_loss=0.0028  test_loss=42.3003  λ_max=1.5744\n",
      "[Muon | lr=0.05] Epoch 693/4000: train_loss=0.0025  test_loss=42.3021  λ_max=1.6178\n",
      "[Muon | lr=0.05] Iter 11100: loss=0.0058\n",
      "[Muon | lr=0.05] Epoch 694/4000: train_loss=0.0025  test_loss=42.2984  λ_max=1.6236\n",
      "[Muon | lr=0.05] Epoch 695/4000: train_loss=0.0024  test_loss=42.3200  λ_max=1.5736\n",
      "[Muon | lr=0.05] Epoch 696/4000: train_loss=0.0026  test_loss=42.3657  λ_max=1.7211\n",
      "[Muon | lr=0.05] Epoch 697/4000: train_loss=0.0026  test_loss=42.4044  λ_max=1.7166\n",
      "[Muon | lr=0.05] Epoch 698/4000: train_loss=0.0026  test_loss=42.4233  λ_max=1.5850\n",
      "[Muon | lr=0.05] Epoch 699/4000: train_loss=0.0023  test_loss=42.4259  λ_max=1.6151\n",
      "[Muon | lr=0.05] Iter 11200: loss=0.0054\n",
      "[Muon | lr=0.05] Epoch 700/4000: train_loss=0.0025  test_loss=42.4519  λ_max=1.6198\n",
      "[Muon | lr=0.05] Epoch 701/4000: train_loss=0.0022  test_loss=42.5232  λ_max=1.4883\n",
      "[Muon | lr=0.05] Epoch 702/4000: train_loss=0.0024  test_loss=42.5307  λ_max=1.5988\n",
      "[Muon | lr=0.05] Epoch 703/4000: train_loss=0.0026  test_loss=42.5568  λ_max=1.5509\n",
      "[Muon | lr=0.05] Epoch 704/4000: train_loss=0.0023  test_loss=42.5839  λ_max=1.6688\n",
      "[Muon | lr=0.05] Epoch 705/4000: train_loss=0.0026  test_loss=42.6524  λ_max=1.7622\n",
      "[Muon | lr=0.05] Epoch 706/4000: train_loss=0.0023  test_loss=42.7428  λ_max=1.5644\n",
      "[Muon | lr=0.05] Iter 11300: loss=0.0007\n",
      "[Muon | lr=0.05] Epoch 707/4000: train_loss=0.0027  test_loss=42.7662  λ_max=1.6580\n",
      "[Muon | lr=0.05] Epoch 708/4000: train_loss=0.0022  test_loss=42.7734  λ_max=1.6510\n",
      "[Muon | lr=0.05] Epoch 709/4000: train_loss=0.0025  test_loss=42.8824  λ_max=1.4704\n",
      "[Muon | lr=0.05] Epoch 710/4000: train_loss=0.0024  test_loss=42.9207  λ_max=1.6366\n",
      "[Muon | lr=0.05] Epoch 711/4000: train_loss=0.0021  test_loss=42.8596  λ_max=1.6318\n",
      "[Muon | lr=0.05] Epoch 712/4000: train_loss=0.0022  test_loss=42.9026  λ_max=1.6057\n",
      "[Muon | lr=0.05] Iter 11400: loss=0.0014\n",
      "[Muon | lr=0.05] Epoch 713/4000: train_loss=0.0029  test_loss=42.9544  λ_max=1.5910\n",
      "[Muon | lr=0.05] Epoch 714/4000: train_loss=0.0021  test_loss=42.9259  λ_max=1.6740\n",
      "[Muon | lr=0.05] Epoch 715/4000: train_loss=0.0024  test_loss=42.9285  λ_max=1.6458\n",
      "[Muon | lr=0.05] Epoch 716/4000: train_loss=0.0022  test_loss=42.9280  λ_max=1.6130\n",
      "[Muon | lr=0.05] Epoch 717/4000: train_loss=0.0023  test_loss=42.9283  λ_max=1.6255\n",
      "[Muon | lr=0.05] Epoch 718/4000: train_loss=0.0022  test_loss=42.9527  λ_max=1.7328\n",
      "[Muon | lr=0.05] Iter 11500: loss=0.0015\n",
      "[Muon | lr=0.05] Epoch 719/4000: train_loss=0.0025  test_loss=43.0097  λ_max=1.6140\n",
      "[Muon | lr=0.05] Epoch 720/4000: train_loss=0.0024  test_loss=43.0118  λ_max=1.6234\n",
      "[Muon | lr=0.05] Epoch 721/4000: train_loss=0.0026  test_loss=43.0498  λ_max=1.6614\n",
      "[Muon | lr=0.05] Epoch 722/4000: train_loss=0.0023  test_loss=43.0581  λ_max=1.7135\n",
      "[Muon | lr=0.05] Epoch 723/4000: train_loss=0.0021  test_loss=43.0682  λ_max=1.6537\n",
      "[Muon | lr=0.05] Epoch 724/4000: train_loss=0.0019  test_loss=43.0874  λ_max=1.6893\n",
      "[Muon | lr=0.05] Iter 11600: loss=0.0033\n",
      "[Muon | lr=0.05] Epoch 725/4000: train_loss=0.0024  test_loss=43.1610  λ_max=1.5275\n",
      "[Muon | lr=0.05] Epoch 726/4000: train_loss=0.0020  test_loss=43.2205  λ_max=1.5276\n",
      "[Muon | lr=0.05] Epoch 727/4000: train_loss=0.0027  test_loss=43.2882  λ_max=1.6774\n",
      "[Muon | lr=0.05] Epoch 728/4000: train_loss=0.0021  test_loss=43.3071  λ_max=1.6346\n",
      "[Muon | lr=0.05] Epoch 729/4000: train_loss=0.0025  test_loss=43.4313  λ_max=1.5161\n",
      "[Muon | lr=0.05] Epoch 730/4000: train_loss=0.0023  test_loss=43.5612  λ_max=1.6625\n",
      "[Muon | lr=0.05] Epoch 731/4000: train_loss=0.0024  test_loss=43.6238  λ_max=1.6187\n",
      "[Muon | lr=0.05] Iter 11700: loss=0.0008\n",
      "[Muon | lr=0.05] Epoch 732/4000: train_loss=0.0026  test_loss=43.6115  λ_max=1.6811\n",
      "[Muon | lr=0.05] Epoch 733/4000: train_loss=0.0026  test_loss=43.6153  λ_max=1.6874\n",
      "[Muon | lr=0.05] Epoch 734/4000: train_loss=0.0024  test_loss=43.6192  λ_max=1.7171\n",
      "[Muon | lr=0.05] Epoch 735/4000: train_loss=0.0022  test_loss=43.6443  λ_max=1.6245\n",
      "[Muon | lr=0.05] Epoch 736/4000: train_loss=0.0023  test_loss=43.6589  λ_max=1.7158\n",
      "[Muon | lr=0.05] Epoch 737/4000: train_loss=0.0023  test_loss=43.7321  λ_max=1.6857\n",
      "[Muon | lr=0.05] Iter 11800: loss=0.0011\n",
      "[Muon | lr=0.05] Epoch 738/4000: train_loss=0.0024  test_loss=43.7806  λ_max=1.6360\n",
      "[Muon | lr=0.05] Epoch 739/4000: train_loss=0.0023  test_loss=43.7383  λ_max=1.7589\n",
      "[Muon | lr=0.05] Epoch 740/4000: train_loss=0.0018  test_loss=43.8250  λ_max=1.7125\n",
      "[Muon | lr=0.05] Epoch 741/4000: train_loss=0.0020  test_loss=43.8831  λ_max=1.7258\n",
      "[Muon | lr=0.05] Epoch 742/4000: train_loss=0.0026  test_loss=43.9191  λ_max=1.7041\n",
      "[Muon | lr=0.05] Epoch 743/4000: train_loss=0.0026  test_loss=43.9988  λ_max=1.5741\n",
      "[Muon | lr=0.05] Iter 11900: loss=0.0034\n",
      "[Muon | lr=0.05] Epoch 744/4000: train_loss=0.0022  test_loss=44.0726  λ_max=1.6010\n",
      "[Muon | lr=0.05] Epoch 745/4000: train_loss=0.0025  test_loss=44.0551  λ_max=1.5977\n",
      "[Muon | lr=0.05] Epoch 746/4000: train_loss=0.0026  test_loss=44.1033  λ_max=1.5878\n",
      "[Muon | lr=0.05] Epoch 747/4000: train_loss=0.0022  test_loss=44.1391  λ_max=1.6370\n",
      "[Muon | lr=0.05] Epoch 748/4000: train_loss=0.0025  test_loss=44.1782  λ_max=1.7062\n",
      "[Muon | lr=0.05] Epoch 749/4000: train_loss=0.0024  test_loss=44.2187  λ_max=1.7261\n",
      "[Muon | lr=0.05] Iter 12000: loss=0.0047\n",
      "[Muon | lr=0.05] Epoch 750/4000: train_loss=0.0021  test_loss=44.2322  λ_max=1.6751\n",
      "[Muon | lr=0.05] Epoch 751/4000: train_loss=0.0024  test_loss=44.2190  λ_max=1.5879\n",
      "[Muon | lr=0.05] Epoch 752/4000: train_loss=0.0018  test_loss=44.2335  λ_max=1.6514\n",
      "[Muon | lr=0.05] Epoch 753/4000: train_loss=0.0025  test_loss=44.2684  λ_max=1.6751\n",
      "[Muon | lr=0.05] Epoch 754/4000: train_loss=0.0023  test_loss=44.2800  λ_max=1.6065\n",
      "[Muon | lr=0.05] Epoch 755/4000: train_loss=0.0022  test_loss=44.3527  λ_max=1.5764\n",
      "[Muon | lr=0.05] Epoch 756/4000: train_loss=0.0023  test_loss=44.3604  λ_max=1.6711\n",
      "[Muon | lr=0.05] Iter 12100: loss=0.0012\n",
      "[Muon | lr=0.05] Epoch 757/4000: train_loss=0.0021  test_loss=44.3636  λ_max=1.6696\n",
      "[Muon | lr=0.05] Epoch 758/4000: train_loss=0.0022  test_loss=44.3708  λ_max=1.5596\n",
      "[Muon | lr=0.05] Epoch 759/4000: train_loss=0.0018  test_loss=44.4641  λ_max=1.6761\n",
      "[Muon | lr=0.05] Epoch 760/4000: train_loss=0.0022  test_loss=44.5094  λ_max=1.6241\n",
      "[Muon | lr=0.05] Epoch 761/4000: train_loss=0.0021  test_loss=44.5258  λ_max=1.5744\n",
      "[Muon | lr=0.05] Epoch 762/4000: train_loss=0.0024  test_loss=44.4461  λ_max=1.6792\n",
      "[Muon | lr=0.05] Iter 12200: loss=0.0009\n",
      "[Muon | lr=0.05] Epoch 763/4000: train_loss=0.0022  test_loss=44.4601  λ_max=1.6529\n",
      "[Muon | lr=0.05] Epoch 764/4000: train_loss=0.0023  test_loss=44.5556  λ_max=1.6197\n",
      "[Muon | lr=0.05] Epoch 765/4000: train_loss=0.0022  test_loss=44.5772  λ_max=1.5937\n",
      "[Muon | lr=0.05] Epoch 766/4000: train_loss=0.0022  test_loss=44.6659  λ_max=1.7134\n",
      "[Muon | lr=0.05] Epoch 767/4000: train_loss=0.0023  test_loss=44.7290  λ_max=1.6900\n",
      "[Muon | lr=0.05] Epoch 768/4000: train_loss=0.0022  test_loss=44.7812  λ_max=1.6715\n",
      "[Muon | lr=0.05] Iter 12300: loss=0.0073\n",
      "[Muon | lr=0.05] Epoch 769/4000: train_loss=0.0024  test_loss=44.8068  λ_max=1.5401\n",
      "[Muon | lr=0.05] Epoch 770/4000: train_loss=0.0023  test_loss=44.8233  λ_max=1.6170\n",
      "[Muon | lr=0.05] Epoch 771/4000: train_loss=0.0026  test_loss=44.8230  λ_max=1.5735\n",
      "[Muon | lr=0.05] Epoch 772/4000: train_loss=0.0025  test_loss=44.9158  λ_max=1.5457\n",
      "[Muon | lr=0.05] Epoch 773/4000: train_loss=0.0026  test_loss=44.9533  λ_max=1.6230\n",
      "[Muon | lr=0.05] Epoch 774/4000: train_loss=0.0025  test_loss=44.9700  λ_max=1.6460\n",
      "[Muon | lr=0.05] Iter 12400: loss=0.0032\n",
      "[Muon | lr=0.05] Epoch 775/4000: train_loss=0.0019  test_loss=44.9955  λ_max=1.5974\n",
      "[Muon | lr=0.05] Epoch 776/4000: train_loss=0.0024  test_loss=44.9843  λ_max=1.6692\n",
      "[Muon | lr=0.05] Epoch 777/4000: train_loss=0.0022  test_loss=44.9732  λ_max=1.6392\n",
      "[Muon | lr=0.05] Epoch 778/4000: train_loss=0.0023  test_loss=45.0358  λ_max=1.5435\n",
      "[Muon | lr=0.05] Epoch 779/4000: train_loss=0.0022  test_loss=45.0257  λ_max=1.7682\n",
      "[Muon | lr=0.05] Epoch 780/4000: train_loss=0.0022  test_loss=45.0944  λ_max=1.7804\n",
      "[Muon | lr=0.05] Epoch 781/4000: train_loss=0.0025  test_loss=45.2417  λ_max=1.6704\n",
      "[Muon | lr=0.05] Iter 12500: loss=0.0009\n",
      "[Muon | lr=0.05] Epoch 782/4000: train_loss=0.0024  test_loss=45.2819  λ_max=1.6793\n",
      "[Muon | lr=0.05] Epoch 783/4000: train_loss=0.0020  test_loss=45.3078  λ_max=1.6561\n",
      "[Muon | lr=0.05] Epoch 784/4000: train_loss=0.0025  test_loss=45.3744  λ_max=1.6790\n",
      "[Muon | lr=0.05] Epoch 785/4000: train_loss=0.0023  test_loss=45.4504  λ_max=1.6700\n",
      "[Muon | lr=0.05] Epoch 786/4000: train_loss=0.0019  test_loss=45.4711  λ_max=1.7325\n",
      "[Muon | lr=0.05] Epoch 787/4000: train_loss=0.0020  test_loss=45.4869  λ_max=1.6326\n",
      "[Muon | lr=0.05] Iter 12600: loss=0.0016\n",
      "[Muon | lr=0.05] Epoch 788/4000: train_loss=0.0021  test_loss=45.5224  λ_max=1.7461\n",
      "[Muon | lr=0.05] Epoch 789/4000: train_loss=0.0028  test_loss=45.5506  λ_max=1.7245\n",
      "[Muon | lr=0.05] Epoch 790/4000: train_loss=0.0024  test_loss=45.5895  λ_max=1.6684\n",
      "[Muon | lr=0.05] Epoch 791/4000: train_loss=0.0024  test_loss=45.6262  λ_max=1.6269\n",
      "[Muon | lr=0.05] Epoch 792/4000: train_loss=0.0018  test_loss=45.6356  λ_max=1.7245\n",
      "[Muon | lr=0.05] Epoch 793/4000: train_loss=0.0025  test_loss=45.7253  λ_max=1.5765\n",
      "[Muon | lr=0.05] Iter 12700: loss=0.0033\n",
      "[Muon | lr=0.05] Epoch 794/4000: train_loss=0.0023  test_loss=45.7805  λ_max=1.5993\n",
      "[Muon | lr=0.05] Epoch 795/4000: train_loss=0.0024  test_loss=45.7715  λ_max=1.6986\n",
      "[Muon | lr=0.05] Epoch 796/4000: train_loss=0.0024  test_loss=45.7939  λ_max=1.7383\n",
      "[Muon | lr=0.05] Epoch 797/4000: train_loss=0.0021  test_loss=45.8260  λ_max=1.7549\n",
      "[Muon | lr=0.05] Epoch 798/4000: train_loss=0.0020  test_loss=45.8525  λ_max=1.6646\n",
      "[Muon | lr=0.05] Epoch 799/4000: train_loss=0.0019  test_loss=45.8164  λ_max=1.7958\n",
      "[Muon | lr=0.05] Iter 12800: loss=0.0040\n",
      "[Muon | lr=0.05] Epoch 800/4000: train_loss=0.0022  test_loss=45.8757  λ_max=1.6351\n",
      "[Muon | lr=0.05] Epoch 801/4000: train_loss=0.0021  test_loss=45.9174  λ_max=1.7484\n",
      "[Muon | lr=0.05] Epoch 802/4000: train_loss=0.0024  test_loss=45.9398  λ_max=1.7270\n",
      "[Muon | lr=0.05] Epoch 803/4000: train_loss=0.0020  test_loss=46.0018  λ_max=1.7654\n",
      "[Muon | lr=0.05] Epoch 804/4000: train_loss=0.0023  test_loss=45.9853  λ_max=1.7077\n",
      "[Muon | lr=0.05] Epoch 805/4000: train_loss=0.0023  test_loss=45.9917  λ_max=1.7309\n",
      "[Muon | lr=0.05] Epoch 806/4000: train_loss=0.0022  test_loss=46.0060  λ_max=1.6563\n",
      "[Muon | lr=0.05] Iter 12900: loss=0.0008\n",
      "[Muon | lr=0.05] Epoch 807/4000: train_loss=0.0019  test_loss=46.0128  λ_max=1.6838\n",
      "[Muon | lr=0.05] Epoch 808/4000: train_loss=0.0024  test_loss=45.9647  λ_max=1.6892\n",
      "[Muon | lr=0.05] Epoch 809/4000: train_loss=0.0023  test_loss=46.0852  λ_max=1.6792\n",
      "[Muon | lr=0.05] Epoch 810/4000: train_loss=0.0021  test_loss=46.1398  λ_max=1.7007\n",
      "[Muon | lr=0.05] Epoch 811/4000: train_loss=0.0021  test_loss=46.1765  λ_max=1.6263\n",
      "[Muon | lr=0.05] Epoch 812/4000: train_loss=0.0020  test_loss=46.3167  λ_max=1.6345\n",
      "[Muon | lr=0.05] Iter 13000: loss=0.0010\n",
      "[Muon | lr=0.05] Epoch 813/4000: train_loss=0.0023  test_loss=46.3280  λ_max=1.7214\n",
      "[Muon | lr=0.05] Epoch 814/4000: train_loss=0.0024  test_loss=46.3910  λ_max=1.6373\n",
      "[Muon | lr=0.05] Epoch 815/4000: train_loss=0.0021  test_loss=46.4354  λ_max=1.7413\n",
      "[Muon | lr=0.05] Epoch 816/4000: train_loss=0.0025  test_loss=46.4667  λ_max=1.6531\n",
      "[Muon | lr=0.05] Epoch 817/4000: train_loss=0.0018  test_loss=46.5406  λ_max=1.6438\n",
      "[Muon | lr=0.05] Epoch 818/4000: train_loss=0.0020  test_loss=46.5451  λ_max=1.7442\n",
      "[Muon | lr=0.05] Iter 13100: loss=0.0027\n",
      "[Muon | lr=0.05] Epoch 819/4000: train_loss=0.0021  test_loss=46.6433  λ_max=1.5969\n",
      "[Muon | lr=0.05] Epoch 820/4000: train_loss=0.0019  test_loss=46.6515  λ_max=1.7143\n",
      "[Muon | lr=0.05] Epoch 821/4000: train_loss=0.0026  test_loss=46.7039  λ_max=1.7101\n",
      "[Muon | lr=0.05] Epoch 822/4000: train_loss=0.0020  test_loss=46.7975  λ_max=1.6394\n",
      "[Muon | lr=0.05] Epoch 823/4000: train_loss=0.0023  test_loss=46.8201  λ_max=1.6450\n",
      "[Muon | lr=0.05] Epoch 824/4000: train_loss=0.0022  test_loss=46.8701  λ_max=1.7146\n",
      "[Muon | lr=0.05] Iter 13200: loss=0.0048\n",
      "[Muon | lr=0.05] Epoch 825/4000: train_loss=0.0020  test_loss=46.8697  λ_max=1.6832\n",
      "[Muon | lr=0.05] Epoch 826/4000: train_loss=0.0019  test_loss=46.8327  λ_max=1.7537\n",
      "[Muon | lr=0.05] Epoch 827/4000: train_loss=0.0019  test_loss=46.8673  λ_max=1.6126\n",
      "[Muon | lr=0.05] Epoch 828/4000: train_loss=0.0022  test_loss=46.8729  λ_max=1.7727\n",
      "[Muon | lr=0.05] Epoch 829/4000: train_loss=0.0019  test_loss=46.8674  λ_max=1.7658\n",
      "[Muon | lr=0.05] Epoch 830/4000: train_loss=0.0020  test_loss=46.8817  λ_max=1.6804\n",
      "[Muon | lr=0.05] Epoch 831/4000: train_loss=0.0025  test_loss=46.8918  λ_max=1.8142\n",
      "[Muon | lr=0.05] Iter 13300: loss=0.0008\n",
      "[Muon | lr=0.05] Epoch 832/4000: train_loss=0.0020  test_loss=47.0390  λ_max=1.7147\n",
      "[Muon | lr=0.05] Epoch 833/4000: train_loss=0.0019  test_loss=47.1560  λ_max=1.5862\n",
      "[Muon | lr=0.05] Epoch 834/4000: train_loss=0.0025  test_loss=47.2512  λ_max=1.7324\n",
      "[Muon | lr=0.05] Epoch 835/4000: train_loss=0.0022  test_loss=47.3171  λ_max=1.7123\n",
      "[Muon | lr=0.05] Epoch 836/4000: train_loss=0.0019  test_loss=47.3768  λ_max=1.7944\n",
      "[Muon | lr=0.05] Epoch 837/4000: train_loss=0.0024  test_loss=47.3907  λ_max=1.7027\n",
      "[Muon | lr=0.05] Iter 13400: loss=0.0015\n",
      "[Muon | lr=0.05] Epoch 838/4000: train_loss=0.0020  test_loss=47.3738  λ_max=1.6944\n",
      "[Muon | lr=0.05] Epoch 839/4000: train_loss=0.0021  test_loss=47.3802  λ_max=1.7086\n",
      "[Muon | lr=0.05] Epoch 840/4000: train_loss=0.0021  test_loss=47.4503  λ_max=1.7933\n",
      "[Muon | lr=0.05] Epoch 841/4000: train_loss=0.0022  test_loss=47.5127  λ_max=1.7825\n",
      "[Muon | lr=0.05] Epoch 842/4000: train_loss=0.0022  test_loss=47.5020  λ_max=1.6728\n",
      "[Muon | lr=0.05] Epoch 843/4000: train_loss=0.0022  test_loss=47.5221  λ_max=1.7335\n",
      "[Muon | lr=0.05] Iter 13500: loss=0.0026\n",
      "[Muon | lr=0.05] Epoch 844/4000: train_loss=0.0020  test_loss=47.5711  λ_max=1.6033\n",
      "[Muon | lr=0.05] Epoch 845/4000: train_loss=0.0019  test_loss=47.5946  λ_max=1.7528\n",
      "[Muon | lr=0.05] Epoch 846/4000: train_loss=0.0017  test_loss=47.5855  λ_max=1.7241\n",
      "[Muon | lr=0.05] Epoch 847/4000: train_loss=0.0021  test_loss=47.5210  λ_max=1.7921\n",
      "[Muon | lr=0.05] Epoch 848/4000: train_loss=0.0019  test_loss=47.5490  λ_max=1.6881\n",
      "[Muon | lr=0.05] Epoch 849/4000: train_loss=0.0022  test_loss=47.6126  λ_max=1.7214\n",
      "[Muon | lr=0.05] Iter 13600: loss=0.0039\n",
      "[Muon | lr=0.05] Epoch 850/4000: train_loss=0.0018  test_loss=47.6233  λ_max=1.7155\n",
      "[Muon | lr=0.05] Epoch 851/4000: train_loss=0.0021  test_loss=47.6662  λ_max=1.7115\n",
      "[Muon | lr=0.05] Epoch 852/4000: train_loss=0.0019  test_loss=47.7228  λ_max=1.7853\n",
      "[Muon | lr=0.05] Epoch 853/4000: train_loss=0.0019  test_loss=47.7813  λ_max=1.5562\n",
      "[Muon | lr=0.05] Epoch 854/4000: train_loss=0.0020  test_loss=47.8005  λ_max=1.6044\n",
      "[Muon | lr=0.05] Epoch 855/4000: train_loss=0.0022  test_loss=47.8432  λ_max=1.7563\n",
      "[Muon | lr=0.05] Epoch 856/4000: train_loss=0.0020  test_loss=47.8567  λ_max=1.7592\n",
      "[Muon | lr=0.05] Iter 13700: loss=0.0008\n",
      "[Muon | lr=0.05] Epoch 857/4000: train_loss=0.0020  test_loss=47.9299  λ_max=1.6830\n",
      "[Muon | lr=0.05] Epoch 858/4000: train_loss=0.0020  test_loss=47.9601  λ_max=1.6179\n",
      "[Muon | lr=0.05] Epoch 859/4000: train_loss=0.0024  test_loss=47.9360  λ_max=1.6748\n",
      "[Muon | lr=0.05] Epoch 860/4000: train_loss=0.0019  test_loss=47.9627  λ_max=1.6496\n",
      "[Muon | lr=0.05] Epoch 861/4000: train_loss=0.0019  test_loss=47.9611  λ_max=1.6724\n",
      "[Muon | lr=0.05] Epoch 862/4000: train_loss=0.0018  test_loss=47.9362  λ_max=1.6779\n",
      "[Muon | lr=0.05] Iter 13800: loss=0.0022\n",
      "[Muon | lr=0.05] Epoch 863/4000: train_loss=0.0018  test_loss=47.9499  λ_max=1.7682\n",
      "[Muon | lr=0.05] Epoch 864/4000: train_loss=0.0022  test_loss=47.9084  λ_max=1.6993\n",
      "[Muon | lr=0.05] Epoch 865/4000: train_loss=0.0019  test_loss=47.8860  λ_max=1.7585\n",
      "[Muon | lr=0.05] Epoch 866/4000: train_loss=0.0016  test_loss=47.9235  λ_max=1.7383\n",
      "[Muon | lr=0.05] Epoch 867/4000: train_loss=0.0020  test_loss=47.8869  λ_max=1.6948\n",
      "[Muon | lr=0.05] Epoch 868/4000: train_loss=0.0015  test_loss=47.9497  λ_max=1.6422\n",
      "[Muon | lr=0.05] Iter 13900: loss=0.0031\n",
      "[Muon | lr=0.05] Epoch 869/4000: train_loss=0.0018  test_loss=47.9870  λ_max=1.6246\n",
      "[Muon | lr=0.05] Epoch 870/4000: train_loss=0.0018  test_loss=47.9942  λ_max=1.8325\n",
      "[Muon | lr=0.05] Epoch 871/4000: train_loss=0.0022  test_loss=47.9569  λ_max=1.7380\n",
      "[Muon | lr=0.05] Epoch 872/4000: train_loss=0.0019  test_loss=47.9549  λ_max=1.6690\n",
      "[Muon | lr=0.05] Epoch 873/4000: train_loss=0.0018  test_loss=47.9116  λ_max=1.8043\n",
      "[Muon | lr=0.05] Epoch 874/4000: train_loss=0.0019  test_loss=47.9412  λ_max=1.6945\n",
      "[Muon | lr=0.05] Iter 14000: loss=0.0061\n",
      "[Muon | lr=0.05] Epoch 875/4000: train_loss=0.0021  test_loss=47.9832  λ_max=1.6470\n",
      "[Muon | lr=0.05] Epoch 876/4000: train_loss=0.0020  test_loss=47.9273  λ_max=1.8222\n",
      "[Muon | lr=0.05] Epoch 877/4000: train_loss=0.0017  test_loss=47.9990  λ_max=1.6907\n",
      "[Muon | lr=0.05] Epoch 878/4000: train_loss=0.0021  test_loss=48.0596  λ_max=1.7253\n",
      "[Muon | lr=0.05] Epoch 879/4000: train_loss=0.0018  test_loss=48.0668  λ_max=1.7066\n",
      "[Muon | lr=0.05] Epoch 880/4000: train_loss=0.0019  test_loss=48.0753  λ_max=1.7930\n",
      "[Muon | lr=0.05] Epoch 881/4000: train_loss=0.0023  test_loss=48.1375  λ_max=1.8141\n",
      "[Muon | lr=0.05] Iter 14100: loss=0.0012\n",
      "[Muon | lr=0.05] Epoch 882/4000: train_loss=0.0024  test_loss=48.1796  λ_max=1.6710\n",
      "[Muon | lr=0.05] Epoch 883/4000: train_loss=0.0022  test_loss=48.1973  λ_max=1.7155\n",
      "[Muon | lr=0.05] Epoch 884/4000: train_loss=0.0020  test_loss=48.2249  λ_max=1.7401\n",
      "[Muon | lr=0.05] Epoch 885/4000: train_loss=0.0020  test_loss=48.2332  λ_max=1.6023\n",
      "[Muon | lr=0.05] Epoch 886/4000: train_loss=0.0018  test_loss=48.3018  λ_max=1.6439\n",
      "[Muon | lr=0.05] Epoch 887/4000: train_loss=0.0021  test_loss=48.2531  λ_max=1.7749\n",
      "[Muon | lr=0.05] Iter 14200: loss=0.0014\n",
      "[Muon | lr=0.05] Epoch 888/4000: train_loss=0.0018  test_loss=48.1979  λ_max=1.6877\n",
      "[Muon | lr=0.05] Epoch 889/4000: train_loss=0.0018  test_loss=48.1997  λ_max=1.7071\n",
      "[Muon | lr=0.05] Epoch 890/4000: train_loss=0.0017  test_loss=48.2211  λ_max=1.7659\n",
      "[Muon | lr=0.05] Epoch 891/4000: train_loss=0.0020  test_loss=48.2145  λ_max=1.6524\n",
      "[Muon | lr=0.05] Epoch 892/4000: train_loss=0.0018  test_loss=48.2841  λ_max=1.7546\n",
      "[Muon | lr=0.05] Epoch 893/4000: train_loss=0.0020  test_loss=48.3491  λ_max=1.8270\n",
      "[Muon | lr=0.05] Iter 14300: loss=0.0032\n",
      "[Muon | lr=0.05] Epoch 894/4000: train_loss=0.0019  test_loss=48.4149  λ_max=1.6123\n",
      "[Muon | lr=0.05] Epoch 895/4000: train_loss=0.0016  test_loss=48.4940  λ_max=1.7253\n",
      "[Muon | lr=0.05] Epoch 896/4000: train_loss=0.0021  test_loss=48.6075  λ_max=1.7643\n",
      "[Muon | lr=0.05] Epoch 897/4000: train_loss=0.0021  test_loss=48.5855  λ_max=1.7413\n",
      "[Muon | lr=0.05] Epoch 898/4000: train_loss=0.0017  test_loss=48.6335  λ_max=1.6973\n",
      "[Muon | lr=0.05] Epoch 899/4000: train_loss=0.0023  test_loss=48.6536  λ_max=1.7963\n",
      "[Muon | lr=0.05] Iter 14400: loss=0.0011\n",
      "[Muon | lr=0.05] Epoch 900/4000: train_loss=0.0019  test_loss=48.6969  λ_max=1.7320\n",
      "[Muon | lr=0.05] Epoch 901/4000: train_loss=0.0017  test_loss=48.7513  λ_max=1.6970\n",
      "[Muon | lr=0.05] Epoch 902/4000: train_loss=0.0021  test_loss=48.7894  λ_max=1.7166\n",
      "[Muon | lr=0.05] Epoch 903/4000: train_loss=0.0016  test_loss=48.8064  λ_max=1.7916\n",
      "[Muon | lr=0.05] Epoch 904/4000: train_loss=0.0020  test_loss=48.8243  λ_max=1.6814\n",
      "[Muon | lr=0.05] Epoch 905/4000: train_loss=0.0021  test_loss=48.9160  λ_max=1.7562\n",
      "[Muon | lr=0.05] Epoch 906/4000: train_loss=0.0019  test_loss=48.9811  λ_max=1.6233\n",
      "[Muon | lr=0.05] Iter 14500: loss=0.0012\n",
      "[Muon | lr=0.05] Epoch 907/4000: train_loss=0.0020  test_loss=48.9894  λ_max=1.6381\n",
      "[Muon | lr=0.05] Epoch 908/4000: train_loss=0.0014  test_loss=48.9535  λ_max=1.5675\n",
      "[Muon | lr=0.05] Epoch 909/4000: train_loss=0.0016  test_loss=48.8952  λ_max=1.8045\n",
      "[Muon | lr=0.05] Epoch 910/4000: train_loss=0.0020  test_loss=48.9174  λ_max=1.7335\n",
      "[Muon | lr=0.05] Epoch 911/4000: train_loss=0.0023  test_loss=48.9763  λ_max=1.6814\n",
      "[Muon | lr=0.05] Epoch 912/4000: train_loss=0.0018  test_loss=49.0127  λ_max=1.7583\n",
      "[Muon | lr=0.05] Iter 14600: loss=0.0014\n",
      "[Muon | lr=0.05] Epoch 913/4000: train_loss=0.0022  test_loss=49.0072  λ_max=1.7976\n",
      "[Muon | lr=0.05] Epoch 914/4000: train_loss=0.0018  test_loss=49.0717  λ_max=1.6622\n",
      "[Muon | lr=0.05] Epoch 915/4000: train_loss=0.0023  test_loss=49.1283  λ_max=1.6669\n",
      "[Muon | lr=0.05] Epoch 916/4000: train_loss=0.0019  test_loss=49.1919  λ_max=1.7109\n",
      "[Muon | lr=0.05] Epoch 917/4000: train_loss=0.0018  test_loss=49.1953  λ_max=1.8427\n",
      "[Muon | lr=0.05] Epoch 918/4000: train_loss=0.0019  test_loss=49.2582  λ_max=1.7061\n",
      "[Muon | lr=0.05] Iter 14700: loss=0.0038\n",
      "[Muon | lr=0.05] Epoch 919/4000: train_loss=0.0019  test_loss=49.3581  λ_max=1.7125\n",
      "[Muon | lr=0.05] Epoch 920/4000: train_loss=0.0024  test_loss=49.3803  λ_max=1.8133\n",
      "[Muon | lr=0.05] Epoch 921/4000: train_loss=0.0024  test_loss=49.4327  λ_max=1.7237\n",
      "[Muon | lr=0.05] Epoch 922/4000: train_loss=0.0018  test_loss=49.4753  λ_max=1.6915\n",
      "[Muon | lr=0.05] Epoch 923/4000: train_loss=0.0018  test_loss=49.4817  λ_max=1.7492\n",
      "[Muon | lr=0.05] Epoch 924/4000: train_loss=0.0021  test_loss=49.5409  λ_max=1.7041\n",
      "[Muon | lr=0.05] Iter 14800: loss=0.0013\n",
      "[Muon | lr=0.05] Epoch 925/4000: train_loss=0.0019  test_loss=49.6036  λ_max=1.7550\n",
      "[Muon | lr=0.05] Epoch 926/4000: train_loss=0.0017  test_loss=49.5906  λ_max=1.6681\n",
      "[Muon | lr=0.05] Epoch 927/4000: train_loss=0.0021  test_loss=49.6545  λ_max=1.6416\n",
      "[Muon | lr=0.05] Epoch 928/4000: train_loss=0.0021  test_loss=49.6724  λ_max=1.7532\n",
      "[Muon | lr=0.05] Epoch 929/4000: train_loss=0.0016  test_loss=49.7106  λ_max=1.7093\n",
      "[Muon | lr=0.05] Epoch 930/4000: train_loss=0.0018  test_loss=49.7664  λ_max=1.9094\n",
      "[Muon | lr=0.05] Epoch 931/4000: train_loss=0.0020  test_loss=49.8593  λ_max=1.6982\n",
      "[Muon | lr=0.05] Iter 14900: loss=0.0004\n",
      "[Muon | lr=0.05] Epoch 932/4000: train_loss=0.0016  test_loss=49.8759  λ_max=1.7537\n",
      "[Muon | lr=0.05] Epoch 933/4000: train_loss=0.0022  test_loss=49.9152  λ_max=1.7665\n",
      "[Muon | lr=0.05] Epoch 934/4000: train_loss=0.0018  test_loss=49.9324  λ_max=1.8185\n",
      "[Muon | lr=0.05] Epoch 935/4000: train_loss=0.0018  test_loss=49.8858  λ_max=1.8566\n",
      "[Muon | lr=0.05] Epoch 936/4000: train_loss=0.0019  test_loss=49.9012  λ_max=1.7633\n",
      "[Muon | lr=0.05] Epoch 937/4000: train_loss=0.0021  test_loss=49.9686  λ_max=1.8119\n",
      "[Muon | lr=0.05] Iter 15000: loss=0.0036\n",
      "[Muon | lr=0.05] Epoch 938/4000: train_loss=0.0018  test_loss=50.0567  λ_max=1.6977\n",
      "[Muon | lr=0.05] Epoch 939/4000: train_loss=0.0021  test_loss=50.0896  λ_max=1.7892\n",
      "[Muon | lr=0.05] Epoch 940/4000: train_loss=0.0016  test_loss=50.2187  λ_max=1.6631\n",
      "[Muon | lr=0.05] Epoch 941/4000: train_loss=0.0019  test_loss=50.3211  λ_max=1.7489\n",
      "[Muon | lr=0.05] Epoch 942/4000: train_loss=0.0018  test_loss=50.3964  λ_max=1.8056\n",
      "[Muon | lr=0.05] Epoch 943/4000: train_loss=0.0024  test_loss=50.3726  λ_max=1.7038\n",
      "[Muon | lr=0.05] Iter 15100: loss=0.0042\n",
      "[Muon | lr=0.05] Epoch 944/4000: train_loss=0.0021  test_loss=50.3911  λ_max=1.6600\n",
      "[Muon | lr=0.05] Epoch 945/4000: train_loss=0.0019  test_loss=50.3636  λ_max=1.6964\n",
      "[Muon | lr=0.05] Epoch 946/4000: train_loss=0.0022  test_loss=50.3877  λ_max=1.7681\n",
      "[Muon | lr=0.05] Epoch 947/4000: train_loss=0.0019  test_loss=50.4010  λ_max=1.8752\n",
      "[Muon | lr=0.05] Epoch 948/4000: train_loss=0.0018  test_loss=50.4679  λ_max=1.6750\n",
      "[Muon | lr=0.05] Epoch 949/4000: train_loss=0.0020  test_loss=50.4781  λ_max=1.7865\n",
      "[Muon | lr=0.05] Iter 15200: loss=0.0018\n",
      "[Muon | lr=0.05] Epoch 950/4000: train_loss=0.0020  test_loss=50.4113  λ_max=1.6830\n",
      "[Muon | lr=0.05] Epoch 951/4000: train_loss=0.0018  test_loss=50.4373  λ_max=1.6501\n",
      "[Muon | lr=0.05] Epoch 952/4000: train_loss=0.0018  test_loss=50.4310  λ_max=1.8456\n",
      "[Muon | lr=0.05] Epoch 953/4000: train_loss=0.0022  test_loss=50.5132  λ_max=1.6487\n",
      "[Muon | lr=0.05] Epoch 954/4000: train_loss=0.0019  test_loss=50.5525  λ_max=1.7839\n",
      "[Muon | lr=0.05] Epoch 955/4000: train_loss=0.0014  test_loss=50.5296  λ_max=1.8082\n",
      "[Muon | lr=0.05] Epoch 956/4000: train_loss=0.0021  test_loss=50.5476  λ_max=1.6750\n",
      "[Muon | lr=0.05] Iter 15300: loss=0.0001\n",
      "[Muon | lr=0.05] Epoch 957/4000: train_loss=0.0019  test_loss=50.5649  λ_max=1.7455\n",
      "[Muon | lr=0.05] Epoch 958/4000: train_loss=0.0018  test_loss=50.6190  λ_max=1.7452\n",
      "[Muon | lr=0.05] Epoch 959/4000: train_loss=0.0018  test_loss=50.5636  λ_max=1.8795\n",
      "[Muon | lr=0.05] Epoch 960/4000: train_loss=0.0015  test_loss=50.5347  λ_max=1.7179\n",
      "[Muon | lr=0.05] Epoch 961/4000: train_loss=0.0022  test_loss=50.6141  λ_max=1.7258\n",
      "[Muon | lr=0.05] Epoch 962/4000: train_loss=0.0018  test_loss=50.6566  λ_max=1.7324\n",
      "[Muon | lr=0.05] Iter 15400: loss=0.0011\n",
      "[Muon | lr=0.05] Epoch 963/4000: train_loss=0.0017  test_loss=50.6700  λ_max=1.7226\n",
      "[Muon | lr=0.05] Epoch 964/4000: train_loss=0.0015  test_loss=50.6488  λ_max=1.8754\n",
      "[Muon | lr=0.05] Epoch 965/4000: train_loss=0.0017  test_loss=50.6732  λ_max=1.6351\n",
      "[Muon | lr=0.05] Epoch 966/4000: train_loss=0.0023  test_loss=50.7322  λ_max=1.7412\n",
      "[Muon | lr=0.05] Epoch 967/4000: train_loss=0.0016  test_loss=50.7165  λ_max=1.7581\n",
      "[Muon | lr=0.05] Epoch 968/4000: train_loss=0.0020  test_loss=50.6795  λ_max=1.6902\n",
      "[Muon | lr=0.05] Iter 15500: loss=0.0029\n",
      "[Muon | lr=0.05] Epoch 969/4000: train_loss=0.0016  test_loss=50.6850  λ_max=1.7319\n",
      "[Muon | lr=0.05] Epoch 970/4000: train_loss=0.0018  test_loss=50.7818  λ_max=1.7374\n",
      "[Muon | lr=0.05] Epoch 971/4000: train_loss=0.0016  test_loss=50.8157  λ_max=1.7682\n",
      "[Muon | lr=0.05] Epoch 972/4000: train_loss=0.0016  test_loss=50.8565  λ_max=1.7066\n",
      "[Muon | lr=0.05] Epoch 973/4000: train_loss=0.0015  test_loss=50.8344  λ_max=1.8117\n",
      "[Muon | lr=0.05] Epoch 974/4000: train_loss=0.0019  test_loss=50.8463  λ_max=1.7439\n",
      "[Muon | lr=0.05] Iter 15600: loss=0.0017\n",
      "[Muon | lr=0.05] Epoch 975/4000: train_loss=0.0014  test_loss=50.9238  λ_max=1.6985\n",
      "[Muon | lr=0.05] Epoch 976/4000: train_loss=0.0018  test_loss=51.0206  λ_max=1.7859\n",
      "[Muon | lr=0.05] Epoch 977/4000: train_loss=0.0018  test_loss=51.0310  λ_max=1.8686\n",
      "[Muon | lr=0.05] Epoch 978/4000: train_loss=0.0018  test_loss=51.0338  λ_max=1.7131\n",
      "[Muon | lr=0.05] Epoch 979/4000: train_loss=0.0019  test_loss=51.1337  λ_max=1.8204\n",
      "[Muon | lr=0.05] Epoch 980/4000: train_loss=0.0018  test_loss=51.1052  λ_max=1.7949\n",
      "[Muon | lr=0.05] Epoch 981/4000: train_loss=0.0021  test_loss=51.0651  λ_max=1.7891\n",
      "[Muon | lr=0.05] Iter 15700: loss=0.0004\n",
      "[Muon | lr=0.05] Epoch 982/4000: train_loss=0.0018  test_loss=51.1209  λ_max=1.7768\n",
      "[Muon | lr=0.05] Epoch 983/4000: train_loss=0.0017  test_loss=51.0872  λ_max=1.8142\n",
      "[Muon | lr=0.05] Epoch 984/4000: train_loss=0.0021  test_loss=51.1124  λ_max=1.7804\n",
      "[Muon | lr=0.05] Epoch 985/4000: train_loss=0.0021  test_loss=51.1984  λ_max=1.8453\n",
      "[Muon | lr=0.05] Epoch 986/4000: train_loss=0.0020  test_loss=51.1931  λ_max=1.7757\n",
      "[Muon | lr=0.05] Epoch 987/4000: train_loss=0.0018  test_loss=51.2980  λ_max=1.7808\n",
      "[Muon | lr=0.05] Iter 15800: loss=0.0021\n",
      "[Muon | lr=0.05] Epoch 988/4000: train_loss=0.0016  test_loss=51.3541  λ_max=1.7382\n",
      "[Muon | lr=0.05] Epoch 989/4000: train_loss=0.0019  test_loss=51.3754  λ_max=1.8413\n",
      "[Muon | lr=0.05] Epoch 990/4000: train_loss=0.0017  test_loss=51.5029  λ_max=1.7726\n",
      "[Muon | lr=0.05] Epoch 991/4000: train_loss=0.0017  test_loss=51.6205  λ_max=1.7956\n",
      "[Muon | lr=0.05] Epoch 992/4000: train_loss=0.0016  test_loss=51.5907  λ_max=1.8316\n",
      "[Muon | lr=0.05] Epoch 993/4000: train_loss=0.0019  test_loss=51.6649  λ_max=1.7442\n",
      "[Muon | lr=0.05] Iter 15900: loss=0.0015\n",
      "[Muon | lr=0.05] Epoch 994/4000: train_loss=0.0018  test_loss=51.6988  λ_max=1.7288\n",
      "[Muon | lr=0.05] Epoch 995/4000: train_loss=0.0015  test_loss=51.7071  λ_max=1.6987\n",
      "[Muon | lr=0.05] Epoch 996/4000: train_loss=0.0015  test_loss=51.7482  λ_max=1.8332\n",
      "[Muon | lr=0.05] Epoch 997/4000: train_loss=0.0021  test_loss=51.8189  λ_max=1.7186\n",
      "[Muon | lr=0.05] Epoch 998/4000: train_loss=0.0019  test_loss=51.8422  λ_max=1.7845\n",
      "[Muon | lr=0.05] Epoch 999/4000: train_loss=0.0019  test_loss=51.8481  λ_max=1.8260\n",
      "[Muon | lr=0.05] Iter 16000: loss=0.0015\n",
      "[Muon | lr=0.05] Epoch 1000/4000: train_loss=0.0018  test_loss=51.8663  λ_max=1.7577\n",
      "[Muon | lr=0.05] Epoch 1001/4000: train_loss=0.0019  test_loss=51.9537  λ_max=1.8059\n",
      "[Muon | lr=0.05] Epoch 1002/4000: train_loss=0.0019  test_loss=52.0280  λ_max=1.8678\n",
      "[Muon | lr=0.05] Epoch 1003/4000: train_loss=0.0018  test_loss=52.0957  λ_max=1.6748\n",
      "[Muon | lr=0.05] Epoch 1004/4000: train_loss=0.0016  test_loss=52.1426  λ_max=1.7300\n",
      "[Muon | lr=0.05] Epoch 1005/4000: train_loss=0.0016  test_loss=52.2220  λ_max=1.7687\n",
      "[Muon | lr=0.05] Epoch 1006/4000: train_loss=0.0023  test_loss=52.1788  λ_max=1.6634\n",
      "[Muon | lr=0.05] Iter 16100: loss=0.0007\n",
      "[Muon | lr=0.05] Epoch 1007/4000: train_loss=0.0022  test_loss=52.1973  λ_max=1.7851\n",
      "[Muon | lr=0.05] Epoch 1008/4000: train_loss=0.0017  test_loss=52.2983  λ_max=1.7862\n",
      "[Muon | lr=0.05] Epoch 1009/4000: train_loss=0.0019  test_loss=52.4397  λ_max=1.7587\n",
      "[Muon | lr=0.05] Epoch 1010/4000: train_loss=0.0019  test_loss=52.4096  λ_max=1.7108\n",
      "[Muon | lr=0.05] Epoch 1011/4000: train_loss=0.0019  test_loss=52.3849  λ_max=1.7055\n",
      "[Muon | lr=0.05] Epoch 1012/4000: train_loss=0.0016  test_loss=52.4172  λ_max=1.7503\n",
      "[Muon | lr=0.05] Iter 16200: loss=0.0010\n",
      "[Muon | lr=0.05] Epoch 1013/4000: train_loss=0.0016  test_loss=52.5268  λ_max=1.8349\n",
      "[Muon | lr=0.05] Epoch 1014/4000: train_loss=0.0019  test_loss=52.6375  λ_max=1.6624\n",
      "[Muon | lr=0.05] Epoch 1015/4000: train_loss=0.0017  test_loss=52.6823  λ_max=1.6504\n",
      "[Muon | lr=0.05] Epoch 1016/4000: train_loss=0.0018  test_loss=52.6599  λ_max=1.8063\n",
      "[Muon | lr=0.05] Epoch 1017/4000: train_loss=0.0015  test_loss=52.7065  λ_max=1.7279\n",
      "[Muon | lr=0.05] Epoch 1018/4000: train_loss=0.0017  test_loss=52.7929  λ_max=1.7087\n",
      "[Muon | lr=0.05] Iter 16300: loss=0.0015\n",
      "[Muon | lr=0.05] Epoch 1019/4000: train_loss=0.0019  test_loss=52.8732  λ_max=1.7534\n",
      "[Muon | lr=0.05] Epoch 1020/4000: train_loss=0.0017  test_loss=52.9767  λ_max=1.6430\n",
      "[Muon | lr=0.05] Epoch 1021/4000: train_loss=0.0014  test_loss=52.9839  λ_max=1.7688\n",
      "[Muon | lr=0.05] Epoch 1022/4000: train_loss=0.0016  test_loss=52.9777  λ_max=1.6165\n",
      "[Muon | lr=0.05] Epoch 1023/4000: train_loss=0.0018  test_loss=53.0089  λ_max=1.7194\n",
      "[Muon | lr=0.05] Epoch 1024/4000: train_loss=0.0015  test_loss=52.9891  λ_max=1.7061\n",
      "[Muon | lr=0.05] Iter 16400: loss=0.0030\n",
      "[Muon | lr=0.05] Epoch 1025/4000: train_loss=0.0018  test_loss=52.9980  λ_max=1.7051\n",
      "[Muon | lr=0.05] Epoch 1026/4000: train_loss=0.0019  test_loss=52.9669  λ_max=1.7729\n",
      "[Muon | lr=0.05] Epoch 1027/4000: train_loss=0.0017  test_loss=52.9074  λ_max=1.6142\n",
      "[Muon | lr=0.05] Epoch 1028/4000: train_loss=0.0017  test_loss=53.0081  λ_max=1.8191\n",
      "[Muon | lr=0.05] Epoch 1029/4000: train_loss=0.0017  test_loss=52.9591  λ_max=1.7805\n",
      "[Muon | lr=0.05] Epoch 1030/4000: train_loss=0.0019  test_loss=52.9360  λ_max=1.7100\n",
      "[Muon | lr=0.05] Epoch 1031/4000: train_loss=0.0018  test_loss=52.9879  λ_max=1.7077\n",
      "[Muon | lr=0.05] Iter 16500: loss=0.0006\n",
      "[Muon | lr=0.05] Epoch 1032/4000: train_loss=0.0015  test_loss=53.0580  λ_max=1.7557\n",
      "[Muon | lr=0.05] Epoch 1033/4000: train_loss=0.0017  test_loss=53.0554  λ_max=1.7348\n",
      "[Muon | lr=0.05] Epoch 1034/4000: train_loss=0.0016  test_loss=53.1350  λ_max=1.8224\n",
      "[Muon | lr=0.05] Epoch 1035/4000: train_loss=0.0018  test_loss=53.1860  λ_max=1.7982\n",
      "[Muon | lr=0.05] Epoch 1036/4000: train_loss=0.0016  test_loss=53.2136  λ_max=1.6638\n",
      "[Muon | lr=0.05] Epoch 1037/4000: train_loss=0.0021  test_loss=53.2033  λ_max=1.8296\n",
      "[Muon | lr=0.05] Iter 16600: loss=0.0011\n",
      "[Muon | lr=0.05] Epoch 1038/4000: train_loss=0.0018  test_loss=53.1987  λ_max=1.7420\n",
      "[Muon | lr=0.05] Epoch 1039/4000: train_loss=0.0016  test_loss=53.2735  λ_max=1.9360\n",
      "[Muon | lr=0.05] Epoch 1040/4000: train_loss=0.0018  test_loss=53.2420  λ_max=1.7004\n",
      "[Muon | lr=0.05] Epoch 1041/4000: train_loss=0.0011  test_loss=53.2809  λ_max=1.7265\n",
      "[Muon | lr=0.05] Epoch 1042/4000: train_loss=0.0017  test_loss=53.2988  λ_max=1.8062\n",
      "[Muon | lr=0.05] Epoch 1043/4000: train_loss=0.0017  test_loss=53.2746  λ_max=1.7613\n",
      "[Muon | lr=0.05] Iter 16700: loss=0.0047\n",
      "[Muon | lr=0.05] Epoch 1044/4000: train_loss=0.0020  test_loss=53.2873  λ_max=1.8882\n",
      "[Muon | lr=0.05] Epoch 1045/4000: train_loss=0.0016  test_loss=53.3299  λ_max=1.8720\n",
      "[Muon | lr=0.05] Epoch 1046/4000: train_loss=0.0016  test_loss=53.3369  λ_max=1.7953\n",
      "[Muon | lr=0.05] Epoch 1047/4000: train_loss=0.0017  test_loss=53.3844  λ_max=1.6877\n",
      "[Muon | lr=0.05] Epoch 1048/4000: train_loss=0.0016  test_loss=53.4176  λ_max=1.7427\n",
      "[Muon | lr=0.05] Epoch 1049/4000: train_loss=0.0017  test_loss=53.4047  λ_max=1.7574\n",
      "[Muon | lr=0.05] Iter 16800: loss=0.0029\n",
      "[Muon | lr=0.05] Epoch 1050/4000: train_loss=0.0015  test_loss=53.4495  λ_max=1.7361\n",
      "[Muon | lr=0.05] Epoch 1051/4000: train_loss=0.0017  test_loss=53.4996  λ_max=1.7602\n",
      "[Muon | lr=0.05] Epoch 1052/4000: train_loss=0.0017  test_loss=53.4949  λ_max=1.8294\n",
      "[Muon | lr=0.05] Epoch 1053/4000: train_loss=0.0017  test_loss=53.5199  λ_max=1.7417\n",
      "[Muon | lr=0.05] Epoch 1054/4000: train_loss=0.0017  test_loss=53.5258  λ_max=1.6310\n",
      "[Muon | lr=0.05] Epoch 1055/4000: train_loss=0.0018  test_loss=53.6237  λ_max=1.9107\n",
      "[Muon | lr=0.05] Epoch 1056/4000: train_loss=0.0017  test_loss=53.6567  λ_max=1.7656\n",
      "[Muon | lr=0.05] Iter 16900: loss=0.0004\n",
      "[Muon | lr=0.05] Epoch 1057/4000: train_loss=0.0018  test_loss=53.6580  λ_max=1.8076\n",
      "[Muon | lr=0.05] Epoch 1058/4000: train_loss=0.0018  test_loss=53.6644  λ_max=1.7701\n",
      "[Muon | lr=0.05] Epoch 1059/4000: train_loss=0.0016  test_loss=53.6840  λ_max=1.7293\n",
      "[Muon | lr=0.05] Epoch 1060/4000: train_loss=0.0018  test_loss=53.7255  λ_max=1.7670\n",
      "[Muon | lr=0.05] Epoch 1061/4000: train_loss=0.0015  test_loss=53.7312  λ_max=1.8687\n",
      "[Muon | lr=0.05] Epoch 1062/4000: train_loss=0.0020  test_loss=53.7049  λ_max=1.8067\n",
      "[Muon | lr=0.05] Iter 17000: loss=0.0004\n",
      "[Muon | lr=0.05] Epoch 1063/4000: train_loss=0.0014  test_loss=53.6856  λ_max=1.7342\n",
      "[Muon | lr=0.05] Epoch 1064/4000: train_loss=0.0018  test_loss=53.7801  λ_max=1.7563\n",
      "[Muon | lr=0.05] Epoch 1065/4000: train_loss=0.0017  test_loss=53.7699  λ_max=1.6698\n",
      "[Muon | lr=0.05] Epoch 1066/4000: train_loss=0.0015  test_loss=53.8124  λ_max=1.7234\n",
      "[Muon | lr=0.05] Epoch 1067/4000: train_loss=0.0017  test_loss=53.8163  λ_max=1.8948\n",
      "[Muon | lr=0.05] Epoch 1068/4000: train_loss=0.0013  test_loss=53.8999  λ_max=1.7932\n",
      "[Muon | lr=0.05] Iter 17100: loss=0.0019\n",
      "[Muon | lr=0.05] Epoch 1069/4000: train_loss=0.0015  test_loss=54.0240  λ_max=1.6886\n",
      "[Muon | lr=0.05] Epoch 1070/4000: train_loss=0.0015  test_loss=54.0141  λ_max=1.8612\n",
      "[Muon | lr=0.05] Epoch 1071/4000: train_loss=0.0014  test_loss=53.9967  λ_max=1.8268\n",
      "[Muon | lr=0.05] Epoch 1072/4000: train_loss=0.0019  test_loss=54.0024  λ_max=1.7510\n",
      "[Muon | lr=0.05] Epoch 1073/4000: train_loss=0.0016  test_loss=54.0254  λ_max=1.9117\n",
      "[Muon | lr=0.05] Epoch 1074/4000: train_loss=0.0015  test_loss=54.0580  λ_max=1.8408\n",
      "[Muon | lr=0.05] Iter 17200: loss=0.0007\n",
      "[Muon | lr=0.05] Epoch 1075/4000: train_loss=0.0012  test_loss=54.1252  λ_max=1.7787\n",
      "[Muon | lr=0.05] Epoch 1076/4000: train_loss=0.0015  test_loss=54.0952  λ_max=1.8386\n",
      "[Muon | lr=0.05] Epoch 1077/4000: train_loss=0.0016  test_loss=54.0927  λ_max=1.9039\n",
      "[Muon | lr=0.05] Epoch 1078/4000: train_loss=0.0020  test_loss=54.1654  λ_max=1.8210\n",
      "[Muon | lr=0.05] Epoch 1079/4000: train_loss=0.0016  test_loss=54.2205  λ_max=1.8182\n",
      "[Muon | lr=0.05] Epoch 1080/4000: train_loss=0.0016  test_loss=54.2853  λ_max=1.6637\n",
      "[Muon | lr=0.05] Epoch 1081/4000: train_loss=0.0017  test_loss=54.3735  λ_max=1.7147\n",
      "[Muon | lr=0.05] Iter 17300: loss=0.0002\n",
      "[Muon | lr=0.05] Epoch 1082/4000: train_loss=0.0018  test_loss=54.3625  λ_max=1.7921\n",
      "[Muon | lr=0.05] Epoch 1083/4000: train_loss=0.0016  test_loss=54.3528  λ_max=1.8537\n",
      "[Muon | lr=0.05] Epoch 1084/4000: train_loss=0.0020  test_loss=54.3364  λ_max=1.7495\n",
      "[Muon | lr=0.05] Epoch 1085/4000: train_loss=0.0016  test_loss=54.3303  λ_max=1.7625\n",
      "[Muon | lr=0.05] Epoch 1086/4000: train_loss=0.0016  test_loss=54.3733  λ_max=1.7465\n",
      "[Muon | lr=0.05] Epoch 1087/4000: train_loss=0.0015  test_loss=54.3200  λ_max=1.7042\n",
      "[Muon | lr=0.05] Iter 17400: loss=0.0008\n",
      "[Muon | lr=0.05] Epoch 1088/4000: train_loss=0.0013  test_loss=54.2852  λ_max=1.7190\n",
      "[Muon | lr=0.05] Epoch 1089/4000: train_loss=0.0015  test_loss=54.2640  λ_max=1.6650\n",
      "[Muon | lr=0.05] Epoch 1090/4000: train_loss=0.0016  test_loss=54.2524  λ_max=1.7846\n",
      "[Muon | lr=0.05] Epoch 1091/4000: train_loss=0.0015  test_loss=54.2006  λ_max=1.8639\n",
      "[Muon | lr=0.05] Epoch 1092/4000: train_loss=0.0018  test_loss=54.1413  λ_max=1.8587\n",
      "[Muon | lr=0.05] Epoch 1093/4000: train_loss=0.0016  test_loss=54.2005  λ_max=1.7819\n",
      "[Muon | lr=0.05] Iter 17500: loss=0.0024\n",
      "[Muon | lr=0.05] Epoch 1094/4000: train_loss=0.0017  test_loss=54.2452  λ_max=1.6945\n",
      "[Muon | lr=0.05] Epoch 1095/4000: train_loss=0.0017  test_loss=54.3011  λ_max=1.8050\n",
      "[Muon | lr=0.05] Epoch 1096/4000: train_loss=0.0014  test_loss=54.3283  λ_max=1.8425\n",
      "[Muon | lr=0.05] Epoch 1097/4000: train_loss=0.0016  test_loss=54.3610  λ_max=1.9150\n",
      "[Muon | lr=0.05] Epoch 1098/4000: train_loss=0.0017  test_loss=54.4392  λ_max=1.7750\n",
      "[Muon | lr=0.05] Epoch 1099/4000: train_loss=0.0018  test_loss=54.6460  λ_max=1.7367\n",
      "[Muon | lr=0.05] Iter 17600: loss=0.0020\n",
      "[Muon | lr=0.05] Epoch 1100/4000: train_loss=0.0018  test_loss=54.6699  λ_max=1.7796\n",
      "[Muon | lr=0.05] Epoch 1101/4000: train_loss=0.0019  test_loss=54.7392  λ_max=1.8592\n",
      "[Muon | lr=0.05] Epoch 1102/4000: train_loss=0.0017  test_loss=54.8066  λ_max=1.7714\n",
      "[Muon | lr=0.05] Epoch 1103/4000: train_loss=0.0016  test_loss=54.8036  λ_max=1.7425\n",
      "[Muon | lr=0.05] Epoch 1104/4000: train_loss=0.0017  test_loss=54.8280  λ_max=1.7552\n",
      "[Muon | lr=0.05] Epoch 1105/4000: train_loss=0.0019  test_loss=54.8690  λ_max=1.8036\n",
      "[Muon | lr=0.05] Epoch 1106/4000: train_loss=0.0017  test_loss=54.8850  λ_max=1.7413\n",
      "[Muon | lr=0.05] Iter 17700: loss=0.0009\n",
      "[Muon | lr=0.05] Epoch 1107/4000: train_loss=0.0019  test_loss=54.8698  λ_max=1.9111\n",
      "[Muon | lr=0.05] Epoch 1108/4000: train_loss=0.0016  test_loss=54.8945  λ_max=1.8100\n",
      "[Muon | lr=0.05] Epoch 1109/4000: train_loss=0.0014  test_loss=54.9347  λ_max=1.7654\n",
      "[Muon | lr=0.05] Epoch 1110/4000: train_loss=0.0014  test_loss=54.9202  λ_max=1.8726\n",
      "[Muon | lr=0.05] Epoch 1111/4000: train_loss=0.0014  test_loss=54.9370  λ_max=1.8483\n",
      "[Muon | lr=0.05] Epoch 1112/4000: train_loss=0.0014  test_loss=54.9442  λ_max=1.8234\n",
      "[Muon | lr=0.05] Iter 17800: loss=0.0033\n",
      "[Muon | lr=0.05] Epoch 1113/4000: train_loss=0.0016  test_loss=54.9884  λ_max=1.8652\n",
      "[Muon | lr=0.05] Epoch 1114/4000: train_loss=0.0017  test_loss=55.0464  λ_max=1.7242\n",
      "[Muon | lr=0.05] Epoch 1115/4000: train_loss=0.0017  test_loss=55.1204  λ_max=1.6927\n",
      "[Muon | lr=0.05] Epoch 1116/4000: train_loss=0.0017  test_loss=55.1825  λ_max=1.7145\n",
      "[Muon | lr=0.05] Epoch 1117/4000: train_loss=0.0013  test_loss=55.1786  λ_max=1.7561\n",
      "[Muon | lr=0.05] Epoch 1118/4000: train_loss=0.0014  test_loss=55.2223  λ_max=1.7290\n",
      "[Muon | lr=0.05] Iter 17900: loss=0.0028\n",
      "[Muon | lr=0.05] Epoch 1119/4000: train_loss=0.0017  test_loss=55.2846  λ_max=1.8858\n",
      "[Muon | lr=0.05] Epoch 1120/4000: train_loss=0.0017  test_loss=55.3403  λ_max=1.6820\n",
      "[Muon | lr=0.05] Epoch 1121/4000: train_loss=0.0018  test_loss=55.3541  λ_max=1.8266\n",
      "[Muon | lr=0.05] Epoch 1122/4000: train_loss=0.0016  test_loss=55.3731  λ_max=1.7836\n",
      "[Muon | lr=0.05] Epoch 1123/4000: train_loss=0.0014  test_loss=55.3199  λ_max=1.8509\n",
      "[Muon | lr=0.05] Epoch 1124/4000: train_loss=0.0014  test_loss=55.3023  λ_max=1.8499\n",
      "[Muon | lr=0.05] Iter 18000: loss=0.0028\n",
      "[Muon | lr=0.05] Epoch 1125/4000: train_loss=0.0015  test_loss=55.3493  λ_max=1.8093\n",
      "[Muon | lr=0.05] Epoch 1126/4000: train_loss=0.0016  test_loss=55.3004  λ_max=1.8382\n",
      "[Muon | lr=0.05] Epoch 1127/4000: train_loss=0.0017  test_loss=55.3920  λ_max=1.7635\n",
      "[Muon | lr=0.05] Epoch 1128/4000: train_loss=0.0019  test_loss=55.4492  λ_max=1.7414\n",
      "[Muon | lr=0.05] Epoch 1129/4000: train_loss=0.0014  test_loss=55.5182  λ_max=1.8081\n",
      "[Muon | lr=0.05] Epoch 1130/4000: train_loss=0.0019  test_loss=55.5488  λ_max=1.8872\n",
      "[Muon | lr=0.05] Epoch 1131/4000: train_loss=0.0018  test_loss=55.6187  λ_max=1.7547\n",
      "[Muon | lr=0.05] Iter 18100: loss=0.0010\n",
      "[Muon | lr=0.05] Epoch 1132/4000: train_loss=0.0019  test_loss=55.6259  λ_max=1.8564\n",
      "[Muon | lr=0.05] Epoch 1133/4000: train_loss=0.0017  test_loss=55.6316  λ_max=1.7671\n",
      "[Muon | lr=0.05] Epoch 1134/4000: train_loss=0.0015  test_loss=55.6879  λ_max=1.8051\n",
      "[Muon | lr=0.05] Epoch 1135/4000: train_loss=0.0013  test_loss=55.7961  λ_max=1.8829\n",
      "[Muon | lr=0.05] Epoch 1136/4000: train_loss=0.0016  test_loss=55.8551  λ_max=1.8029\n",
      "[Muon | lr=0.05] Epoch 1137/4000: train_loss=0.0015  test_loss=55.9047  λ_max=1.7591\n",
      "[Muon | lr=0.05] Iter 18200: loss=0.0016\n",
      "[Muon | lr=0.05] Epoch 1138/4000: train_loss=0.0017  test_loss=55.9813  λ_max=1.7279\n",
      "[Muon | lr=0.05] Epoch 1139/4000: train_loss=0.0014  test_loss=55.9271  λ_max=1.7756\n",
      "[Muon | lr=0.05] Epoch 1140/4000: train_loss=0.0020  test_loss=55.9733  λ_max=1.8127\n",
      "[Muon | lr=0.05] Epoch 1141/4000: train_loss=0.0017  test_loss=55.9802  λ_max=1.8479\n",
      "[Muon | lr=0.05] Epoch 1142/4000: train_loss=0.0018  test_loss=55.9920  λ_max=1.7041\n",
      "[Muon | lr=0.05] Epoch 1143/4000: train_loss=0.0021  test_loss=56.0002  λ_max=1.7123\n",
      "[Muon | lr=0.05] Iter 18300: loss=0.0014\n",
      "[Muon | lr=0.05] Epoch 1144/4000: train_loss=0.0016  test_loss=56.1032  λ_max=1.8345\n",
      "[Muon | lr=0.05] Epoch 1145/4000: train_loss=0.0014  test_loss=56.1515  λ_max=1.7056\n",
      "[Muon | lr=0.05] Epoch 1146/4000: train_loss=0.0018  test_loss=56.1674  λ_max=1.8131\n",
      "[Muon | lr=0.05] Epoch 1147/4000: train_loss=0.0014  test_loss=56.1624  λ_max=1.8509\n",
      "[Muon | lr=0.05] Epoch 1148/4000: train_loss=0.0014  test_loss=56.1478  λ_max=1.9046\n",
      "[Muon | lr=0.05] Epoch 1149/4000: train_loss=0.0014  test_loss=56.1857  λ_max=2.0085\n",
      "[Muon | lr=0.05] Iter 18400: loss=0.0039\n",
      "[Muon | lr=0.05] Epoch 1150/4000: train_loss=0.0017  test_loss=56.2333  λ_max=1.7536\n",
      "[Muon | lr=0.05] Epoch 1151/4000: train_loss=0.0014  test_loss=56.3012  λ_max=1.8002\n",
      "[Muon | lr=0.05] Epoch 1152/4000: train_loss=0.0012  test_loss=56.3971  λ_max=1.8832\n",
      "[Muon | lr=0.05] Epoch 1153/4000: train_loss=0.0016  test_loss=56.4295  λ_max=1.7856\n",
      "[Muon | lr=0.05] Epoch 1154/4000: train_loss=0.0014  test_loss=56.4154  λ_max=1.8783\n",
      "[Muon | lr=0.05] Epoch 1155/4000: train_loss=0.0015  test_loss=56.4519  λ_max=1.7371\n",
      "[Muon | lr=0.05] Epoch 1156/4000: train_loss=0.0012  test_loss=56.4671  λ_max=1.8633\n",
      "[Muon | lr=0.05] Iter 18500: loss=0.0004\n",
      "[Muon | lr=0.05] Epoch 1157/4000: train_loss=0.0016  test_loss=56.6045  λ_max=1.6930\n",
      "[Muon | lr=0.05] Epoch 1158/4000: train_loss=0.0015  test_loss=56.6745  λ_max=1.7473\n",
      "[Muon | lr=0.05] Epoch 1159/4000: train_loss=0.0018  test_loss=56.6752  λ_max=1.9180\n",
      "[Muon | lr=0.05] Epoch 1160/4000: train_loss=0.0020  test_loss=56.7123  λ_max=1.8107\n",
      "[Muon | lr=0.05] Epoch 1161/4000: train_loss=0.0014  test_loss=56.8401  λ_max=1.7492\n",
      "[Muon | lr=0.05] Epoch 1162/4000: train_loss=0.0013  test_loss=56.7821  λ_max=1.7775\n",
      "[Muon | lr=0.05] Iter 18600: loss=0.0015\n",
      "[Muon | lr=0.05] Epoch 1163/4000: train_loss=0.0015  test_loss=56.7857  λ_max=1.9342\n",
      "[Muon | lr=0.05] Epoch 1164/4000: train_loss=0.0018  test_loss=56.8583  λ_max=1.8202\n",
      "[Muon | lr=0.05] Epoch 1165/4000: train_loss=0.0020  test_loss=56.9178  λ_max=1.7799\n",
      "[Muon | lr=0.05] Epoch 1166/4000: train_loss=0.0016  test_loss=56.9197  λ_max=1.8018\n",
      "[Muon | lr=0.05] Epoch 1167/4000: train_loss=0.0013  test_loss=56.9222  λ_max=2.0283\n",
      "[Muon | lr=0.05] Epoch 1168/4000: train_loss=0.0016  test_loss=57.0338  λ_max=2.1016\n",
      "[Muon | lr=0.05] Iter 18700: loss=0.0024\n",
      "[Muon | lr=0.05] Epoch 1169/4000: train_loss=0.0015  test_loss=57.0181  λ_max=1.8729\n",
      "[Muon | lr=0.05] Epoch 1170/4000: train_loss=0.0014  test_loss=57.0027  λ_max=1.9541\n",
      "[Muon | lr=0.05] Epoch 1171/4000: train_loss=0.0018  test_loss=57.0651  λ_max=1.8424\n",
      "[Muon | lr=0.05] Epoch 1172/4000: train_loss=0.0016  test_loss=57.0510  λ_max=2.0280\n",
      "[Muon | lr=0.05] Epoch 1173/4000: train_loss=0.0014  test_loss=57.1649  λ_max=1.8101\n",
      "[Muon | lr=0.05] Epoch 1174/4000: train_loss=0.0018  test_loss=57.2641  λ_max=1.7056\n",
      "[Muon | lr=0.05] Iter 18800: loss=0.0071\n",
      "[Muon | lr=0.05] Epoch 1175/4000: train_loss=0.0017  test_loss=57.3013  λ_max=1.8209\n",
      "[Muon | lr=0.05] Epoch 1176/4000: train_loss=0.0020  test_loss=57.3089  λ_max=1.9088\n",
      "[Muon | lr=0.05] Epoch 1177/4000: train_loss=0.0015  test_loss=57.3459  λ_max=1.8131\n",
      "[Muon | lr=0.05] Epoch 1178/4000: train_loss=0.0015  test_loss=57.3573  λ_max=1.8007\n",
      "[Muon | lr=0.05] Epoch 1179/4000: train_loss=0.0015  test_loss=57.3397  λ_max=1.9443\n",
      "[Muon | lr=0.05] Epoch 1180/4000: train_loss=0.0017  test_loss=57.4625  λ_max=1.6670\n",
      "[Muon | lr=0.05] Epoch 1181/4000: train_loss=0.0015  test_loss=57.4779  λ_max=1.7846\n",
      "[Muon | lr=0.05] Iter 18900: loss=0.0017\n",
      "[Muon | lr=0.05] Epoch 1182/4000: train_loss=0.0016  test_loss=57.4212  λ_max=1.7811\n",
      "[Muon | lr=0.05] Epoch 1183/4000: train_loss=0.0015  test_loss=57.4374  λ_max=1.8669\n",
      "[Muon | lr=0.05] Epoch 1184/4000: train_loss=0.0015  test_loss=57.5012  λ_max=1.8502\n",
      "[Muon | lr=0.05] Epoch 1185/4000: train_loss=0.0016  test_loss=57.5899  λ_max=1.7772\n",
      "[Muon | lr=0.05] Epoch 1186/4000: train_loss=0.0017  test_loss=57.5804  λ_max=1.8449\n",
      "[Muon | lr=0.05] Epoch 1187/4000: train_loss=0.0018  test_loss=57.5642  λ_max=1.6802\n",
      "[Muon | lr=0.05] Iter 19000: loss=0.0016\n",
      "[Muon | lr=0.05] Epoch 1188/4000: train_loss=0.0015  test_loss=57.5655  λ_max=1.8705\n",
      "[Muon | lr=0.05] Epoch 1189/4000: train_loss=0.0014  test_loss=57.5696  λ_max=1.8874\n",
      "[Muon | lr=0.05] Epoch 1190/4000: train_loss=0.0016  test_loss=57.5365  λ_max=1.7908\n",
      "[Muon | lr=0.05] Epoch 1191/4000: train_loss=0.0012  test_loss=57.5562  λ_max=1.9376\n",
      "[Muon | lr=0.05] Epoch 1192/4000: train_loss=0.0014  test_loss=57.5949  λ_max=1.9571\n",
      "[Muon | lr=0.05] Epoch 1193/4000: train_loss=0.0015  test_loss=57.6593  λ_max=1.7981\n",
      "[Muon | lr=0.05] Iter 19100: loss=0.0029\n",
      "[Muon | lr=0.05] Epoch 1194/4000: train_loss=0.0015  test_loss=57.6858  λ_max=1.7105\n",
      "[Muon | lr=0.05] Epoch 1195/4000: train_loss=0.0016  test_loss=57.6878  λ_max=1.7407\n",
      "[Muon | lr=0.05] Epoch 1196/4000: train_loss=0.0016  test_loss=57.6732  λ_max=1.7397\n",
      "[Muon | lr=0.05] Epoch 1197/4000: train_loss=0.0014  test_loss=57.6943  λ_max=1.7469\n",
      "[Muon | lr=0.05] Epoch 1198/4000: train_loss=0.0013  test_loss=57.8035  λ_max=1.8478\n",
      "[Muon | lr=0.05] Epoch 1199/4000: train_loss=0.0018  test_loss=57.8451  λ_max=1.7516\n",
      "[Muon | lr=0.05] Iter 19200: loss=0.0024\n",
      "[Muon | lr=0.05] Epoch 1200/4000: train_loss=0.0014  test_loss=57.8659  λ_max=1.8615\n",
      "[Muon | lr=0.05] Epoch 1201/4000: train_loss=0.0016  test_loss=57.9172  λ_max=1.8868\n",
      "[Muon | lr=0.05] Epoch 1202/4000: train_loss=0.0016  test_loss=57.8097  λ_max=1.8128\n",
      "[Muon | lr=0.05] Epoch 1203/4000: train_loss=0.0014  test_loss=57.7198  λ_max=1.9635\n",
      "[Muon | lr=0.05] Epoch 1204/4000: train_loss=0.0016  test_loss=57.7497  λ_max=1.9596\n",
      "[Muon | lr=0.05] Epoch 1205/4000: train_loss=0.0017  test_loss=57.7733  λ_max=1.8450\n",
      "[Muon | lr=0.05] Epoch 1206/4000: train_loss=0.0019  test_loss=57.8465  λ_max=1.8378\n",
      "[Muon | lr=0.05] Iter 19300: loss=0.0005\n",
      "[Muon | lr=0.05] Epoch 1207/4000: train_loss=0.0014  test_loss=57.9761  λ_max=1.8708\n",
      "[Muon | lr=0.05] Epoch 1208/4000: train_loss=0.0014  test_loss=58.0562  λ_max=1.7775\n",
      "[Muon | lr=0.05] Epoch 1209/4000: train_loss=0.0012  test_loss=58.1471  λ_max=1.8377\n",
      "[Muon | lr=0.05] Epoch 1210/4000: train_loss=0.0012  test_loss=58.2218  λ_max=1.7176\n",
      "[Muon | lr=0.05] Epoch 1211/4000: train_loss=0.0015  test_loss=58.2887  λ_max=1.8701\n",
      "[Muon | lr=0.05] Epoch 1212/4000: train_loss=0.0017  test_loss=58.2951  λ_max=1.8214\n",
      "[Muon | lr=0.05] Iter 19400: loss=0.0018\n",
      "[Muon | lr=0.05] Epoch 1213/4000: train_loss=0.0019  test_loss=58.2423  λ_max=1.7596\n",
      "[Muon | lr=0.05] Epoch 1214/4000: train_loss=0.0016  test_loss=58.2716  λ_max=1.8739\n",
      "[Muon | lr=0.05] Epoch 1215/4000: train_loss=0.0016  test_loss=58.3282  λ_max=1.7484\n",
      "[Muon | lr=0.05] Epoch 1216/4000: train_loss=0.0020  test_loss=58.3289  λ_max=1.7611\n",
      "[Muon | lr=0.05] Epoch 1217/4000: train_loss=0.0014  test_loss=58.3810  λ_max=1.8981\n",
      "[Muon | lr=0.05] Epoch 1218/4000: train_loss=0.0014  test_loss=58.4313  λ_max=1.8575\n",
      "[Muon | lr=0.05] Iter 19500: loss=0.0025\n",
      "[Muon | lr=0.05] Epoch 1219/4000: train_loss=0.0017  test_loss=58.4273  λ_max=1.8400\n",
      "[Muon | lr=0.05] Epoch 1220/4000: train_loss=0.0014  test_loss=58.4642  λ_max=1.8701\n",
      "[Muon | lr=0.05] Epoch 1221/4000: train_loss=0.0013  test_loss=58.5072  λ_max=1.9361\n",
      "[Muon | lr=0.05] Epoch 1222/4000: train_loss=0.0013  test_loss=58.5207  λ_max=1.8380\n",
      "[Muon | lr=0.05] Epoch 1223/4000: train_loss=0.0017  test_loss=58.5405  λ_max=1.9744\n",
      "[Muon | lr=0.05] Epoch 1224/4000: train_loss=0.0016  test_loss=58.6108  λ_max=1.8157\n",
      "[Muon | lr=0.05] Iter 19600: loss=0.0091\n",
      "[Muon | lr=0.05] Epoch 1225/4000: train_loss=0.0018  test_loss=58.5730  λ_max=1.9169\n",
      "[Muon | lr=0.05] Epoch 1226/4000: train_loss=0.0014  test_loss=58.6833  λ_max=1.8014\n",
      "[Muon | lr=0.05] Epoch 1227/4000: train_loss=0.0015  test_loss=58.7115  λ_max=1.7811\n",
      "[Muon | lr=0.05] Epoch 1228/4000: train_loss=0.0015  test_loss=58.7690  λ_max=1.9828\n",
      "[Muon | lr=0.05] Epoch 1229/4000: train_loss=0.0018  test_loss=58.8511  λ_max=1.7467\n",
      "[Muon | lr=0.05] Epoch 1230/4000: train_loss=0.0017  test_loss=58.8988  λ_max=1.7708\n",
      "[Muon | lr=0.05] Epoch 1231/4000: train_loss=0.0020  test_loss=58.8909  λ_max=1.7648\n",
      "[Muon | lr=0.05] Iter 19700: loss=0.0002\n",
      "[Muon | lr=0.05] Epoch 1232/4000: train_loss=0.0017  test_loss=58.8911  λ_max=1.8917\n",
      "[Muon | lr=0.05] Epoch 1233/4000: train_loss=0.0014  test_loss=58.8679  λ_max=1.7713\n",
      "[Muon | lr=0.05] Epoch 1234/4000: train_loss=0.0018  test_loss=58.9054  λ_max=1.8544\n",
      "[Muon | lr=0.05] Epoch 1235/4000: train_loss=0.0014  test_loss=58.9454  λ_max=1.8317\n",
      "[Muon | lr=0.05] Epoch 1236/4000: train_loss=0.0017  test_loss=58.9480  λ_max=1.8837\n",
      "[Muon | lr=0.05] Epoch 1237/4000: train_loss=0.0018  test_loss=58.9881  λ_max=1.8579\n",
      "[Muon | lr=0.05] Iter 19800: loss=0.0008\n",
      "[Muon | lr=0.05] Epoch 1238/4000: train_loss=0.0013  test_loss=59.0716  λ_max=1.7661\n",
      "[Muon | lr=0.05] Epoch 1239/4000: train_loss=0.0015  test_loss=59.0759  λ_max=1.9305\n",
      "[Muon | lr=0.05] Epoch 1240/4000: train_loss=0.0017  test_loss=58.9935  λ_max=1.8551\n",
      "[Muon | lr=0.05] Epoch 1241/4000: train_loss=0.0017  test_loss=59.0074  λ_max=1.8425\n",
      "[Muon | lr=0.05] Epoch 1242/4000: train_loss=0.0018  test_loss=59.0088  λ_max=1.8149\n",
      "[Muon | lr=0.05] Epoch 1243/4000: train_loss=0.0015  test_loss=59.0747  λ_max=1.8290\n",
      "[Muon | lr=0.05] Iter 19900: loss=0.0020\n",
      "[Muon | lr=0.05] Epoch 1244/4000: train_loss=0.0011  test_loss=59.1660  λ_max=1.7923\n",
      "[Muon | lr=0.05] Epoch 1245/4000: train_loss=0.0013  test_loss=59.1901  λ_max=1.8057\n",
      "[Muon | lr=0.05] Epoch 1246/4000: train_loss=0.0014  test_loss=59.3137  λ_max=1.8951\n",
      "[Muon | lr=0.05] Epoch 1247/4000: train_loss=0.0012  test_loss=59.4128  λ_max=1.8166\n",
      "[Muon | lr=0.05] Epoch 1248/4000: train_loss=0.0016  test_loss=59.4385  λ_max=1.8828\n",
      "[Muon | lr=0.05] Epoch 1249/4000: train_loss=0.0017  test_loss=59.5287  λ_max=1.8071\n",
      "[Muon | lr=0.05] Iter 20000: loss=0.0040\n",
      "[Muon | lr=0.05] Epoch 1250/4000: train_loss=0.0016  test_loss=59.5842  λ_max=1.7799\n",
      "[Muon | lr=0.05] Epoch 1251/4000: train_loss=0.0016  test_loss=59.5647  λ_max=1.8034\n",
      "[Muon | lr=0.05] Epoch 1252/4000: train_loss=0.0013  test_loss=59.5374  λ_max=1.8250\n",
      "[Muon | lr=0.05] Epoch 1253/4000: train_loss=0.0013  test_loss=59.5330  λ_max=2.0880\n",
      "[Muon | lr=0.05] Epoch 1254/4000: train_loss=0.0011  test_loss=59.4769  λ_max=1.9322\n",
      "[Muon | lr=0.05] Epoch 1255/4000: train_loss=0.0012  test_loss=59.5030  λ_max=1.9859\n",
      "[Muon | lr=0.05] Epoch 1256/4000: train_loss=0.0015  test_loss=59.4808  λ_max=1.8577\n",
      "[Muon | lr=0.05] Iter 20100: loss=0.0008\n",
      "[Muon | lr=0.05] Epoch 1257/4000: train_loss=0.0015  test_loss=59.4902  λ_max=2.0445\n",
      "[Muon | lr=0.05] Epoch 1258/4000: train_loss=0.0016  test_loss=59.5855  λ_max=1.8682\n",
      "[Muon | lr=0.05] Epoch 1259/4000: train_loss=0.0014  test_loss=59.5296  λ_max=1.8874\n",
      "[Muon | lr=0.05] Epoch 1260/4000: train_loss=0.0014  test_loss=59.5298  λ_max=1.9404\n",
      "[Muon | lr=0.05] Epoch 1261/4000: train_loss=0.0019  test_loss=59.5982  λ_max=1.8822\n",
      "[Muon | lr=0.05] Epoch 1262/4000: train_loss=0.0012  test_loss=59.5689  λ_max=1.7692\n",
      "[Muon | lr=0.05] Iter 20200: loss=0.0008\n",
      "[Muon | lr=0.05] Epoch 1263/4000: train_loss=0.0013  test_loss=59.3967  λ_max=2.0192\n",
      "[Muon | lr=0.05] Epoch 1264/4000: train_loss=0.0015  test_loss=59.3979  λ_max=1.8537\n",
      "[Muon | lr=0.05] Epoch 1265/4000: train_loss=0.0013  test_loss=59.3960  λ_max=1.9638\n",
      "[Muon | lr=0.05] Epoch 1266/4000: train_loss=0.0015  test_loss=59.3874  λ_max=1.8936\n",
      "[Muon | lr=0.05] Epoch 1267/4000: train_loss=0.0016  test_loss=59.3883  λ_max=1.9741\n",
      "[Muon | lr=0.05] Epoch 1268/4000: train_loss=0.0013  test_loss=59.4763  λ_max=1.9541\n",
      "[Muon | lr=0.05] Iter 20300: loss=0.0031\n",
      "[Muon | lr=0.05] Epoch 1269/4000: train_loss=0.0017  test_loss=59.5089  λ_max=1.8178\n",
      "[Muon | lr=0.05] Epoch 1270/4000: train_loss=0.0015  test_loss=59.5716  λ_max=1.9463\n",
      "[Muon | lr=0.05] Epoch 1271/4000: train_loss=0.0013  test_loss=59.6487  λ_max=1.9856\n",
      "[Muon | lr=0.05] Epoch 1272/4000: train_loss=0.0014  test_loss=59.6910  λ_max=1.8497\n",
      "[Muon | lr=0.05] Epoch 1273/4000: train_loss=0.0013  test_loss=59.7066  λ_max=1.8128\n",
      "[Muon | lr=0.05] Epoch 1274/4000: train_loss=0.0019  test_loss=59.6811  λ_max=2.0457\n",
      "[Muon | lr=0.05] Iter 20400: loss=0.0023\n",
      "[Muon | lr=0.05] Epoch 1275/4000: train_loss=0.0015  test_loss=59.7228  λ_max=1.8396\n",
      "[Muon | lr=0.05] Epoch 1276/4000: train_loss=0.0017  test_loss=59.7109  λ_max=1.9357\n",
      "[Muon | lr=0.05] Epoch 1277/4000: train_loss=0.0015  test_loss=59.7026  λ_max=1.8943\n",
      "[Muon | lr=0.05] Epoch 1278/4000: train_loss=0.0019  test_loss=59.6842  λ_max=1.8900\n",
      "[Muon | lr=0.05] Epoch 1279/4000: train_loss=0.0010  test_loss=59.6836  λ_max=1.9117\n",
      "[Muon | lr=0.05] Epoch 1280/4000: train_loss=0.0015  test_loss=59.7340  λ_max=1.9405\n",
      "[Muon | lr=0.05] Epoch 1281/4000: train_loss=0.0018  test_loss=59.7483  λ_max=2.0560\n",
      "[Muon | lr=0.05] Iter 20500: loss=0.0008\n",
      "[Muon | lr=0.05] Epoch 1282/4000: train_loss=0.0013  test_loss=59.6438  λ_max=2.0088\n",
      "[Muon | lr=0.05] Epoch 1283/4000: train_loss=0.0015  test_loss=59.6205  λ_max=1.9351\n",
      "[Muon | lr=0.05] Epoch 1284/4000: train_loss=0.0013  test_loss=59.7085  λ_max=2.0350\n",
      "[Muon | lr=0.05] Epoch 1285/4000: train_loss=0.0016  test_loss=59.8099  λ_max=1.9428\n",
      "[Muon | lr=0.05] Epoch 1286/4000: train_loss=0.0014  test_loss=59.8104  λ_max=1.8599\n",
      "[Muon | lr=0.05] Epoch 1287/4000: train_loss=0.0015  test_loss=59.8530  λ_max=1.8571\n",
      "[Muon | lr=0.05] Iter 20600: loss=0.0013\n",
      "[Muon | lr=0.05] Epoch 1288/4000: train_loss=0.0012  test_loss=59.8198  λ_max=1.8830\n",
      "[Muon | lr=0.05] Epoch 1289/4000: train_loss=0.0016  test_loss=59.8800  λ_max=1.7742\n",
      "[Muon | lr=0.05] Epoch 1290/4000: train_loss=0.0015  test_loss=59.8853  λ_max=1.9219\n",
      "[Muon | lr=0.05] Epoch 1291/4000: train_loss=0.0014  test_loss=59.7927  λ_max=1.9029\n",
      "[Muon | lr=0.05] Epoch 1292/4000: train_loss=0.0014  test_loss=59.7806  λ_max=2.0092\n",
      "[Muon | lr=0.05] Epoch 1293/4000: train_loss=0.0012  test_loss=59.7787  λ_max=1.8194\n",
      "[Muon | lr=0.05] Iter 20700: loss=0.0022\n",
      "[Muon | lr=0.05] Epoch 1294/4000: train_loss=0.0014  test_loss=59.8566  λ_max=1.8430\n",
      "[Muon | lr=0.05] Epoch 1295/4000: train_loss=0.0015  test_loss=59.8958  λ_max=1.9378\n",
      "[Muon | lr=0.05] Epoch 1296/4000: train_loss=0.0014  test_loss=59.8941  λ_max=1.9304\n",
      "[Muon | lr=0.05] Epoch 1297/4000: train_loss=0.0013  test_loss=59.9958  λ_max=1.9851\n",
      "[Muon | lr=0.05] Epoch 1298/4000: train_loss=0.0010  test_loss=60.0885  λ_max=1.8701\n",
      "[Muon | lr=0.05] Epoch 1299/4000: train_loss=0.0015  test_loss=60.1515  λ_max=1.9674\n",
      "[Muon | lr=0.05] Iter 20800: loss=0.0012\n",
      "[Muon | lr=0.05] Epoch 1300/4000: train_loss=0.0013  test_loss=60.2166  λ_max=1.8489\n",
      "[Muon | lr=0.05] Epoch 1301/4000: train_loss=0.0014  test_loss=60.1200  λ_max=1.9833\n",
      "[Muon | lr=0.05] Epoch 1302/4000: train_loss=0.0016  test_loss=60.1094  λ_max=1.8791\n",
      "[Muon | lr=0.05] Epoch 1303/4000: train_loss=0.0017  test_loss=60.1443  λ_max=1.9131\n",
      "[Muon | lr=0.05] Epoch 1304/4000: train_loss=0.0015  test_loss=60.2915  λ_max=1.8881\n",
      "[Muon | lr=0.05] Epoch 1305/4000: train_loss=0.0012  test_loss=60.3210  λ_max=1.8795\n",
      "[Muon | lr=0.05] Epoch 1306/4000: train_loss=0.0013  test_loss=60.3339  λ_max=1.9359\n",
      "[Muon | lr=0.05] Iter 20900: loss=0.0003\n",
      "[Muon | lr=0.05] Epoch 1307/4000: train_loss=0.0014  test_loss=60.3980  λ_max=1.8567\n",
      "[Muon | lr=0.05] Epoch 1308/4000: train_loss=0.0014  test_loss=60.3869  λ_max=1.8557\n",
      "[Muon | lr=0.05] Epoch 1309/4000: train_loss=0.0012  test_loss=60.3145  λ_max=1.8497\n",
      "[Muon | lr=0.05] Epoch 1310/4000: train_loss=0.0014  test_loss=60.3167  λ_max=2.0019\n",
      "[Muon | lr=0.05] Epoch 1311/4000: train_loss=0.0017  test_loss=60.3863  λ_max=1.9235\n",
      "[Muon | lr=0.05] Epoch 1312/4000: train_loss=0.0015  test_loss=60.3710  λ_max=1.8731\n",
      "[Muon | lr=0.05] Iter 21000: loss=0.0012\n",
      "[Muon | lr=0.05] Epoch 1313/4000: train_loss=0.0011  test_loss=60.4388  λ_max=1.9071\n",
      "[Muon | lr=0.05] Epoch 1314/4000: train_loss=0.0015  test_loss=60.4950  λ_max=1.9355\n",
      "[Muon | lr=0.05] Epoch 1315/4000: train_loss=0.0014  test_loss=60.5358  λ_max=1.9978\n",
      "[Muon | lr=0.05] Epoch 1316/4000: train_loss=0.0013  test_loss=60.6496  λ_max=1.9871\n",
      "[Muon | lr=0.05] Epoch 1317/4000: train_loss=0.0015  test_loss=60.7213  λ_max=1.8628\n",
      "[Muon | lr=0.05] Epoch 1318/4000: train_loss=0.0014  test_loss=60.7802  λ_max=1.8261\n",
      "[Muon | lr=0.05] Iter 21100: loss=0.0017\n",
      "[Muon | lr=0.05] Epoch 1319/4000: train_loss=0.0015  test_loss=60.8023  λ_max=1.9670\n",
      "[Muon | lr=0.05] Epoch 1320/4000: train_loss=0.0017  test_loss=60.8064  λ_max=1.9372\n",
      "[Muon | lr=0.05] Epoch 1321/4000: train_loss=0.0016  test_loss=60.7689  λ_max=1.8348\n",
      "[Muon | lr=0.05] Epoch 1322/4000: train_loss=0.0018  test_loss=60.7337  λ_max=1.9271\n",
      "[Muon | lr=0.05] Epoch 1323/4000: train_loss=0.0009  test_loss=60.7275  λ_max=2.1927\n",
      "[Muon | lr=0.05] Epoch 1324/4000: train_loss=0.0012  test_loss=60.7928  λ_max=1.9767\n",
      "[Muon | lr=0.05] Iter 21200: loss=0.0042\n",
      "[Muon | lr=0.05] Epoch 1325/4000: train_loss=0.0015  test_loss=60.8180  λ_max=1.8590\n",
      "[Muon | lr=0.05] Epoch 1326/4000: train_loss=0.0016  test_loss=60.8036  λ_max=2.0692\n",
      "[Muon | lr=0.05] Epoch 1327/4000: train_loss=0.0015  test_loss=60.8129  λ_max=1.8809\n",
      "[Muon | lr=0.05] Epoch 1328/4000: train_loss=0.0010  test_loss=60.8773  λ_max=1.9371\n",
      "[Muon | lr=0.05] Epoch 1329/4000: train_loss=0.0013  test_loss=60.9968  λ_max=1.8346\n",
      "[Muon | lr=0.05] Epoch 1330/4000: train_loss=0.0011  test_loss=60.9102  λ_max=1.8486\n",
      "[Muon | lr=0.05] Epoch 1331/4000: train_loss=0.0013  test_loss=60.8802  λ_max=1.9653\n",
      "[Muon | lr=0.05] Iter 21300: loss=0.0003\n",
      "[Muon | lr=0.05] Epoch 1332/4000: train_loss=0.0015  test_loss=60.9806  λ_max=1.9410\n",
      "[Muon | lr=0.05] Epoch 1333/4000: train_loss=0.0012  test_loss=61.0211  λ_max=1.8571\n",
      "[Muon | lr=0.05] Epoch 1334/4000: train_loss=0.0012  test_loss=61.1040  λ_max=1.9107\n",
      "[Muon | lr=0.05] Epoch 1335/4000: train_loss=0.0012  test_loss=61.1522  λ_max=1.9136\n",
      "[Muon | lr=0.05] Epoch 1336/4000: train_loss=0.0013  test_loss=61.1626  λ_max=1.8017\n",
      "[Muon | lr=0.05] Epoch 1337/4000: train_loss=0.0017  test_loss=61.2076  λ_max=1.9235\n",
      "[Muon | lr=0.05] Iter 21400: loss=0.0013\n",
      "[Muon | lr=0.05] Epoch 1338/4000: train_loss=0.0015  test_loss=61.2648  λ_max=1.8832\n",
      "[Muon | lr=0.05] Epoch 1339/4000: train_loss=0.0018  test_loss=61.4151  λ_max=1.9387\n",
      "[Muon | lr=0.05] Epoch 1340/4000: train_loss=0.0017  test_loss=61.4321  λ_max=1.9366\n",
      "[Muon | lr=0.05] Epoch 1341/4000: train_loss=0.0011  test_loss=61.5172  λ_max=1.9772\n",
      "[Muon | lr=0.05] Epoch 1342/4000: train_loss=0.0014  test_loss=61.6093  λ_max=1.9507\n",
      "[Muon | lr=0.05] Epoch 1343/4000: train_loss=0.0016  test_loss=61.6352  λ_max=2.0078\n",
      "[Muon | lr=0.05] Iter 21500: loss=0.0011\n",
      "[Muon | lr=0.05] Epoch 1344/4000: train_loss=0.0014  test_loss=61.6856  λ_max=1.9007\n",
      "[Muon | lr=0.05] Epoch 1345/4000: train_loss=0.0015  test_loss=61.6576  λ_max=1.8370\n",
      "[Muon | lr=0.05] Epoch 1346/4000: train_loss=0.0015  test_loss=61.6793  λ_max=1.9241\n",
      "[Muon | lr=0.05] Epoch 1347/4000: train_loss=0.0012  test_loss=61.7127  λ_max=1.9313\n",
      "[Muon | lr=0.05] Epoch 1348/4000: train_loss=0.0016  test_loss=61.7627  λ_max=2.0284\n",
      "[Muon | lr=0.05] Epoch 1349/4000: train_loss=0.0013  test_loss=61.8218  λ_max=2.0450\n",
      "[Muon | lr=0.05] Iter 21600: loss=0.0048\n",
      "[Muon | lr=0.05] Epoch 1350/4000: train_loss=0.0016  test_loss=61.8354  λ_max=1.7837\n",
      "[Muon | lr=0.05] Epoch 1351/4000: train_loss=0.0019  test_loss=61.7686  λ_max=1.8766\n",
      "[Muon | lr=0.05] Epoch 1352/4000: train_loss=0.0015  test_loss=61.7281  λ_max=2.0524\n",
      "[Muon | lr=0.05] Epoch 1353/4000: train_loss=0.0012  test_loss=61.8083  λ_max=1.9406\n",
      "[Muon | lr=0.05] Epoch 1354/4000: train_loss=0.0014  test_loss=61.8750  λ_max=2.0447\n",
      "[Muon | lr=0.05] Epoch 1355/4000: train_loss=0.0014  test_loss=61.9691  λ_max=1.8673\n",
      "[Muon | lr=0.05] Epoch 1356/4000: train_loss=0.0014  test_loss=62.0163  λ_max=1.9862\n",
      "[Muon | lr=0.05] Iter 21700: loss=0.0005\n",
      "[Muon | lr=0.05] Epoch 1357/4000: train_loss=0.0014  test_loss=62.0398  λ_max=1.8895\n",
      "[Muon | lr=0.05] Epoch 1358/4000: train_loss=0.0017  test_loss=62.0557  λ_max=2.0653\n",
      "[Muon | lr=0.05] Epoch 1359/4000: train_loss=0.0011  test_loss=62.1094  λ_max=2.0575\n",
      "[Muon | lr=0.05] Epoch 1360/4000: train_loss=0.0015  test_loss=62.1598  λ_max=1.9455\n",
      "[Muon | lr=0.05] Epoch 1361/4000: train_loss=0.0016  test_loss=62.1967  λ_max=1.8959\n",
      "[Muon | lr=0.05] Epoch 1362/4000: train_loss=0.0014  test_loss=62.2650  λ_max=1.9309\n",
      "[Muon | lr=0.05] Iter 21800: loss=0.0011\n",
      "[Muon | lr=0.05] Epoch 1363/4000: train_loss=0.0011  test_loss=62.3653  λ_max=1.9445\n",
      "[Muon | lr=0.05] Epoch 1364/4000: train_loss=0.0014  test_loss=62.3938  λ_max=1.9381\n",
      "[Muon | lr=0.05] Epoch 1365/4000: train_loss=0.0014  test_loss=62.4089  λ_max=1.9414\n",
      "[Muon | lr=0.05] Epoch 1366/4000: train_loss=0.0016  test_loss=62.4120  λ_max=1.8915\n",
      "[Muon | lr=0.05] Epoch 1367/4000: train_loss=0.0017  test_loss=62.5023  λ_max=1.8433\n",
      "[Muon | lr=0.05] Epoch 1368/4000: train_loss=0.0013  test_loss=62.6004  λ_max=1.8823\n",
      "[Muon | lr=0.05] Iter 21900: loss=0.0022\n",
      "[Muon | lr=0.05] Epoch 1369/4000: train_loss=0.0014  test_loss=62.6114  λ_max=1.9575\n",
      "[Muon | lr=0.05] Epoch 1370/4000: train_loss=0.0010  test_loss=62.6640  λ_max=1.9464\n",
      "[Muon | lr=0.05] Epoch 1371/4000: train_loss=0.0014  test_loss=62.7548  λ_max=1.9349\n",
      "[Muon | lr=0.05] Epoch 1372/4000: train_loss=0.0014  test_loss=62.8889  λ_max=1.9831\n",
      "[Muon | lr=0.05] Epoch 1373/4000: train_loss=0.0012  test_loss=62.9798  λ_max=1.8801\n",
      "[Muon | lr=0.05] Epoch 1374/4000: train_loss=0.0014  test_loss=63.0424  λ_max=1.8315\n",
      "[Muon | lr=0.05] Iter 22000: loss=0.0092\n",
      "[Muon | lr=0.05] Epoch 1375/4000: train_loss=0.0018  test_loss=63.0789  λ_max=1.9174\n",
      "[Muon | lr=0.05] Epoch 1376/4000: train_loss=0.0012  test_loss=63.0998  λ_max=1.8495\n",
      "[Muon | lr=0.05] Epoch 1377/4000: train_loss=0.0010  test_loss=63.1645  λ_max=1.8858\n",
      "[Muon | lr=0.05] Epoch 1378/4000: train_loss=0.0013  test_loss=63.2647  λ_max=1.8162\n",
      "[Muon | lr=0.05] Epoch 1379/4000: train_loss=0.0012  test_loss=63.3183  λ_max=1.8840\n",
      "[Muon | lr=0.05] Epoch 1380/4000: train_loss=0.0012  test_loss=63.3245  λ_max=1.9985\n",
      "[Muon | lr=0.05] Epoch 1381/4000: train_loss=0.0012  test_loss=63.3134  λ_max=1.9724\n",
      "[Muon | lr=0.05] Iter 22100: loss=0.0003\n",
      "[Muon | lr=0.05] Epoch 1382/4000: train_loss=0.0012  test_loss=63.2967  λ_max=1.8460\n",
      "[Muon | lr=0.05] Epoch 1383/4000: train_loss=0.0013  test_loss=63.2407  λ_max=1.8202\n",
      "[Muon | lr=0.05] Epoch 1384/4000: train_loss=0.0012  test_loss=63.1493  λ_max=1.8492\n",
      "[Muon | lr=0.05] Epoch 1385/4000: train_loss=0.0014  test_loss=63.1501  λ_max=1.9572\n",
      "[Muon | lr=0.05] Epoch 1386/4000: train_loss=0.0014  test_loss=63.1793  λ_max=1.9699\n",
      "[Muon | lr=0.05] Epoch 1387/4000: train_loss=0.0015  test_loss=63.1944  λ_max=1.7858\n",
      "[Muon | lr=0.05] Iter 22200: loss=0.0006\n",
      "[Muon | lr=0.05] Epoch 1388/4000: train_loss=0.0017  test_loss=63.2103  λ_max=1.8571\n",
      "[Muon | lr=0.05] Epoch 1389/4000: train_loss=0.0014  test_loss=63.2775  λ_max=1.8542\n",
      "[Muon | lr=0.05] Epoch 1390/4000: train_loss=0.0014  test_loss=63.3410  λ_max=1.8596\n",
      "[Muon | lr=0.05] Epoch 1391/4000: train_loss=0.0016  test_loss=63.3576  λ_max=1.9211\n",
      "[Muon | lr=0.05] Epoch 1392/4000: train_loss=0.0016  test_loss=63.4130  λ_max=1.9768\n",
      "[Muon | lr=0.05] Epoch 1393/4000: train_loss=0.0013  test_loss=63.4488  λ_max=1.9438\n",
      "[Muon | lr=0.05] Iter 22300: loss=0.0007\n",
      "[Muon | lr=0.05] Epoch 1394/4000: train_loss=0.0013  test_loss=63.4086  λ_max=1.8743\n",
      "[Muon | lr=0.05] Epoch 1395/4000: train_loss=0.0013  test_loss=63.5579  λ_max=1.9397\n",
      "[Muon | lr=0.05] Epoch 1396/4000: train_loss=0.0012  test_loss=63.6041  λ_max=1.9120\n",
      "[Muon | lr=0.05] Epoch 1397/4000: train_loss=0.0012  test_loss=63.6023  λ_max=2.0414\n",
      "[Muon | lr=0.05] Epoch 1398/4000: train_loss=0.0016  test_loss=63.6207  λ_max=1.9174\n",
      "[Muon | lr=0.05] Epoch 1399/4000: train_loss=0.0014  test_loss=63.6883  λ_max=1.8251\n",
      "[Muon | lr=0.05] Iter 22400: loss=0.0021\n",
      "[Muon | lr=0.05] Epoch 1400/4000: train_loss=0.0012  test_loss=63.7802  λ_max=1.6779\n",
      "[Muon | lr=0.05] Epoch 1401/4000: train_loss=0.0015  test_loss=63.7447  λ_max=1.8698\n",
      "[Muon | lr=0.05] Epoch 1402/4000: train_loss=0.0015  test_loss=63.7727  λ_max=1.8791\n",
      "[Muon | lr=0.05] Epoch 1403/4000: train_loss=0.0011  test_loss=63.8197  λ_max=1.9417\n",
      "[Muon | lr=0.05] Epoch 1404/4000: train_loss=0.0015  test_loss=63.9438  λ_max=1.9016\n",
      "[Muon | lr=0.05] Epoch 1405/4000: train_loss=0.0012  test_loss=63.9625  λ_max=1.9430\n",
      "[Muon | lr=0.05] Epoch 1406/4000: train_loss=0.0010  test_loss=63.9191  λ_max=1.7711\n",
      "[Muon | lr=0.05] Iter 22500: loss=0.0011\n",
      "[Muon | lr=0.05] Epoch 1407/4000: train_loss=0.0015  test_loss=63.9731  λ_max=1.8248\n",
      "[Muon | lr=0.05] Epoch 1408/4000: train_loss=0.0013  test_loss=63.9318  λ_max=1.8353\n",
      "[Muon | lr=0.05] Epoch 1409/4000: train_loss=0.0016  test_loss=63.8277  λ_max=2.0111\n",
      "[Muon | lr=0.05] Epoch 1410/4000: train_loss=0.0012  test_loss=63.8835  λ_max=1.8455\n",
      "[Muon | lr=0.05] Epoch 1411/4000: train_loss=0.0014  test_loss=63.8867  λ_max=1.9564\n",
      "[Muon | lr=0.05] Epoch 1412/4000: train_loss=0.0011  test_loss=63.8125  λ_max=1.8720\n",
      "[Muon | lr=0.05] Iter 22600: loss=0.0011\n",
      "[Muon | lr=0.05] Epoch 1413/4000: train_loss=0.0011  test_loss=63.9033  λ_max=1.8251\n",
      "[Muon | lr=0.05] Epoch 1414/4000: train_loss=0.0012  test_loss=63.8809  λ_max=1.9999\n",
      "[Muon | lr=0.05] Epoch 1415/4000: train_loss=0.0014  test_loss=63.7972  λ_max=1.8525\n",
      "[Muon | lr=0.05] Epoch 1416/4000: train_loss=0.0011  test_loss=63.7584  λ_max=2.1863\n",
      "[Muon | lr=0.05] Epoch 1417/4000: train_loss=0.0016  test_loss=63.7746  λ_max=1.9664\n",
      "[Muon | lr=0.05] Epoch 1418/4000: train_loss=0.0016  test_loss=63.7923  λ_max=1.8843\n",
      "[Muon | lr=0.05] Iter 22700: loss=0.0021\n",
      "[Muon | lr=0.05] Epoch 1419/4000: train_loss=0.0014  test_loss=63.8001  λ_max=1.8977\n",
      "[Muon | lr=0.05] Epoch 1420/4000: train_loss=0.0012  test_loss=63.7424  λ_max=1.8348\n",
      "[Muon | lr=0.05] Epoch 1421/4000: train_loss=0.0011  test_loss=63.8045  λ_max=1.9513\n",
      "[Muon | lr=0.05] Epoch 1422/4000: train_loss=0.0012  test_loss=63.9301  λ_max=1.9553\n",
      "[Muon | lr=0.05] Epoch 1423/4000: train_loss=0.0017  test_loss=64.0469  λ_max=1.9963\n",
      "[Muon | lr=0.05] Epoch 1424/4000: train_loss=0.0013  test_loss=64.0385  λ_max=1.9555\n",
      "[Muon | lr=0.05] Iter 22800: loss=0.0020\n",
      "[Muon | lr=0.05] Epoch 1425/4000: train_loss=0.0010  test_loss=63.9859  λ_max=1.9660\n",
      "[Muon | lr=0.05] Epoch 1426/4000: train_loss=0.0013  test_loss=64.1359  λ_max=1.7803\n",
      "[Muon | lr=0.05] Epoch 1427/4000: train_loss=0.0015  test_loss=64.1931  λ_max=1.9399\n",
      "[Muon | lr=0.05] Epoch 1428/4000: train_loss=0.0015  test_loss=64.2389  λ_max=2.0871\n",
      "[Muon | lr=0.05] Epoch 1429/4000: train_loss=0.0014  test_loss=64.3123  λ_max=1.9425\n",
      "[Muon | lr=0.05] Epoch 1430/4000: train_loss=0.0013  test_loss=64.3342  λ_max=1.8849\n",
      "[Muon | lr=0.05] Epoch 1431/4000: train_loss=0.0011  test_loss=64.3403  λ_max=1.8989\n",
      "[Muon | lr=0.05] Iter 22900: loss=0.0008\n",
      "[Muon | lr=0.05] Epoch 1432/4000: train_loss=0.0010  test_loss=64.4347  λ_max=2.0183\n",
      "[Muon | lr=0.05] Epoch 1433/4000: train_loss=0.0016  test_loss=64.5266  λ_max=1.9374\n",
      "[Muon | lr=0.05] Epoch 1434/4000: train_loss=0.0013  test_loss=64.5995  λ_max=1.9609\n",
      "[Muon | lr=0.05] Epoch 1435/4000: train_loss=0.0013  test_loss=64.6554  λ_max=1.9552\n",
      "[Muon | lr=0.05] Epoch 1436/4000: train_loss=0.0009  test_loss=64.7220  λ_max=2.0061\n",
      "[Muon | lr=0.05] Epoch 1437/4000: train_loss=0.0015  test_loss=64.7814  λ_max=1.8606\n",
      "[Muon | lr=0.05] Iter 23000: loss=0.0008\n",
      "[Muon | lr=0.05] Epoch 1438/4000: train_loss=0.0011  test_loss=64.8004  λ_max=1.9295\n",
      "[Muon | lr=0.05] Epoch 1439/4000: train_loss=0.0015  test_loss=64.8647  λ_max=1.9454\n",
      "[Muon | lr=0.05] Epoch 1440/4000: train_loss=0.0014  test_loss=64.8943  λ_max=1.8755\n",
      "[Muon | lr=0.05] Epoch 1441/4000: train_loss=0.0012  test_loss=64.8995  λ_max=1.8553\n",
      "[Muon | lr=0.05] Epoch 1442/4000: train_loss=0.0014  test_loss=64.9164  λ_max=1.8129\n",
      "[Muon | lr=0.05] Epoch 1443/4000: train_loss=0.0013  test_loss=64.9418  λ_max=1.6976\n",
      "[Muon | lr=0.05] Iter 23100: loss=0.0008\n",
      "[Muon | lr=0.05] Epoch 1444/4000: train_loss=0.0010  test_loss=65.0047  λ_max=1.9288\n",
      "[Muon | lr=0.05] Epoch 1445/4000: train_loss=0.0016  test_loss=65.1251  λ_max=1.7606\n",
      "[Muon | lr=0.05] Epoch 1446/4000: train_loss=0.0014  test_loss=65.1366  λ_max=1.8692\n",
      "[Muon | lr=0.05] Epoch 1447/4000: train_loss=0.0013  test_loss=65.0813  λ_max=2.0135\n",
      "[Muon | lr=0.05] Epoch 1448/4000: train_loss=0.0012  test_loss=65.1458  λ_max=1.9950\n",
      "[Muon | lr=0.05] Epoch 1449/4000: train_loss=0.0011  test_loss=65.1837  λ_max=1.9931\n",
      "[Muon | lr=0.05] Iter 23200: loss=0.0041\n",
      "[Muon | lr=0.05] Epoch 1450/4000: train_loss=0.0017  test_loss=65.2516  λ_max=1.8796\n",
      "[Muon | lr=0.05] Epoch 1451/4000: train_loss=0.0011  test_loss=65.3055  λ_max=1.8016\n",
      "[Muon | lr=0.05] Epoch 1452/4000: train_loss=0.0009  test_loss=65.3259  λ_max=1.9031\n",
      "[Muon | lr=0.05] Epoch 1453/4000: train_loss=0.0014  test_loss=65.4090  λ_max=1.9138\n",
      "[Muon | lr=0.05] Epoch 1454/4000: train_loss=0.0011  test_loss=65.4754  λ_max=1.9887\n",
      "[Muon | lr=0.05] Epoch 1455/4000: train_loss=0.0015  test_loss=65.5593  λ_max=2.0645\n",
      "[Muon | lr=0.05] Epoch 1456/4000: train_loss=0.0015  test_loss=65.5674  λ_max=2.0551\n",
      "[Muon | lr=0.05] Iter 23300: loss=0.0003\n",
      "[Muon | lr=0.05] Epoch 1457/4000: train_loss=0.0013  test_loss=65.5320  λ_max=1.9412\n",
      "[Muon | lr=0.05] Epoch 1458/4000: train_loss=0.0015  test_loss=65.5480  λ_max=1.9330\n",
      "[Muon | lr=0.05] Epoch 1459/4000: train_loss=0.0013  test_loss=65.6480  λ_max=1.9129\n",
      "[Muon | lr=0.05] Epoch 1460/4000: train_loss=0.0012  test_loss=65.6562  λ_max=1.8162\n",
      "[Muon | lr=0.05] Epoch 1461/4000: train_loss=0.0015  test_loss=65.6279  λ_max=1.9702\n",
      "[Muon | lr=0.05] Epoch 1462/4000: train_loss=0.0012  test_loss=65.6163  λ_max=1.8816\n",
      "[Muon | lr=0.05] Iter 23400: loss=0.0007\n",
      "[Muon | lr=0.05] Epoch 1463/4000: train_loss=0.0012  test_loss=65.6305  λ_max=1.8948\n",
      "[Muon | lr=0.05] Epoch 1464/4000: train_loss=0.0014  test_loss=65.5433  λ_max=1.8846\n",
      "[Muon | lr=0.05] Epoch 1465/4000: train_loss=0.0011  test_loss=65.6120  λ_max=1.8925\n",
      "[Muon | lr=0.05] Epoch 1466/4000: train_loss=0.0014  test_loss=65.5820  λ_max=1.8968\n",
      "[Muon | lr=0.05] Epoch 1467/4000: train_loss=0.0015  test_loss=65.5763  λ_max=1.8326\n",
      "[Muon | lr=0.05] Epoch 1468/4000: train_loss=0.0013  test_loss=65.5703  λ_max=1.9470\n",
      "[Muon | lr=0.05] Iter 23500: loss=0.0018\n",
      "[Muon | lr=0.05] Epoch 1469/4000: train_loss=0.0012  test_loss=65.5691  λ_max=1.8848\n",
      "[Muon | lr=0.05] Epoch 1470/4000: train_loss=0.0013  test_loss=65.6464  λ_max=1.8654\n",
      "[Muon | lr=0.05] Epoch 1471/4000: train_loss=0.0013  test_loss=65.7333  λ_max=1.8528\n",
      "[Muon | lr=0.05] Epoch 1472/4000: train_loss=0.0010  test_loss=65.7557  λ_max=1.8798\n",
      "[Muon | lr=0.05] Epoch 1473/4000: train_loss=0.0011  test_loss=65.8529  λ_max=1.8074\n",
      "[Muon | lr=0.05] Epoch 1474/4000: train_loss=0.0015  test_loss=65.8299  λ_max=1.9152\n",
      "[Muon | lr=0.05] Iter 23600: loss=0.0035\n",
      "[Muon | lr=0.05] Epoch 1475/4000: train_loss=0.0013  test_loss=65.7452  λ_max=1.9072\n",
      "[Muon | lr=0.05] Epoch 1476/4000: train_loss=0.0009  test_loss=65.6838  λ_max=1.8337\n",
      "[Muon | lr=0.05] Epoch 1477/4000: train_loss=0.0011  test_loss=65.5974  λ_max=1.8948\n",
      "[Muon | lr=0.05] Epoch 1478/4000: train_loss=0.0012  test_loss=65.5961  λ_max=1.9492\n",
      "[Muon | lr=0.05] Epoch 1479/4000: train_loss=0.0011  test_loss=65.6278  λ_max=1.8641\n",
      "[Muon | lr=0.05] Epoch 1480/4000: train_loss=0.0011  test_loss=65.5801  λ_max=1.9424\n",
      "[Muon | lr=0.05] Epoch 1481/4000: train_loss=0.0011  test_loss=65.6363  λ_max=2.0337\n",
      "[Muon | lr=0.05] Iter 23700: loss=0.0013\n",
      "[Muon | lr=0.05] Epoch 1482/4000: train_loss=0.0008  test_loss=65.7329  λ_max=1.9251\n",
      "[Muon | lr=0.05] Epoch 1483/4000: train_loss=0.0015  test_loss=65.7368  λ_max=1.9797\n",
      "[Muon | lr=0.05] Epoch 1484/4000: train_loss=0.0015  test_loss=65.8616  λ_max=1.8871\n",
      "[Muon | lr=0.05] Epoch 1485/4000: train_loss=0.0014  test_loss=65.8687  λ_max=2.0508\n",
      "[Muon | lr=0.05] Epoch 1486/4000: train_loss=0.0010  test_loss=65.9287  λ_max=1.9109\n",
      "[Muon | lr=0.05] Epoch 1487/4000: train_loss=0.0012  test_loss=65.9425  λ_max=1.8838\n",
      "[Muon | lr=0.05] Iter 23800: loss=0.0011\n",
      "[Muon | lr=0.05] Epoch 1488/4000: train_loss=0.0014  test_loss=65.9622  λ_max=1.8713\n",
      "[Muon | lr=0.05] Epoch 1489/4000: train_loss=0.0013  test_loss=65.9482  λ_max=1.9400\n",
      "[Muon | lr=0.05] Epoch 1490/4000: train_loss=0.0011  test_loss=65.9654  λ_max=1.9769\n",
      "[Muon | lr=0.05] Epoch 1491/4000: train_loss=0.0011  test_loss=65.9975  λ_max=1.9572\n",
      "[Muon | lr=0.05] Epoch 1492/4000: train_loss=0.0011  test_loss=65.9817  λ_max=1.9400\n",
      "[Muon | lr=0.05] Epoch 1493/4000: train_loss=0.0013  test_loss=66.0891  λ_max=2.1453\n",
      "[Muon | lr=0.05] Iter 23900: loss=0.0028\n",
      "[Muon | lr=0.05] Epoch 1494/4000: train_loss=0.0012  test_loss=66.1411  λ_max=1.9003\n",
      "[Muon | lr=0.05] Epoch 1495/4000: train_loss=0.0011  test_loss=66.0879  λ_max=2.0178\n",
      "[Muon | lr=0.05] Epoch 1496/4000: train_loss=0.0014  test_loss=66.0575  λ_max=1.9121\n",
      "[Muon | lr=0.05] Epoch 1497/4000: train_loss=0.0015  test_loss=66.0565  λ_max=1.8639\n",
      "[Muon | lr=0.05] Epoch 1498/4000: train_loss=0.0015  test_loss=66.1119  λ_max=1.9401\n",
      "[Muon | lr=0.05] Epoch 1499/4000: train_loss=0.0014  test_loss=66.1225  λ_max=2.0103\n",
      "[Muon | lr=0.05] Iter 24000: loss=0.0019\n",
      "[Muon | lr=0.05] Epoch 1500/4000: train_loss=0.0014  test_loss=66.2114  λ_max=1.9529\n",
      "[Muon | lr=0.05] Epoch 1501/4000: train_loss=0.0014  test_loss=66.1737  λ_max=1.8022\n",
      "[Muon | lr=0.05] Epoch 1502/4000: train_loss=0.0015  test_loss=66.2005  λ_max=1.9821\n",
      "[Muon | lr=0.05] Epoch 1503/4000: train_loss=0.0012  test_loss=66.3000  λ_max=1.9678\n",
      "[Muon | lr=0.05] Epoch 1504/4000: train_loss=0.0012  test_loss=66.4765  λ_max=1.9389\n",
      "[Muon | lr=0.05] Epoch 1505/4000: train_loss=0.0013  test_loss=66.5555  λ_max=1.8488\n",
      "[Muon | lr=0.05] Epoch 1506/4000: train_loss=0.0013  test_loss=66.6969  λ_max=1.8841\n",
      "[Muon | lr=0.05] Iter 24100: loss=0.0002\n",
      "[Muon | lr=0.05] Epoch 1507/4000: train_loss=0.0015  test_loss=66.7856  λ_max=2.0326\n",
      "[Muon | lr=0.05] Epoch 1508/4000: train_loss=0.0016  test_loss=66.7767  λ_max=1.8468\n",
      "[Muon | lr=0.05] Epoch 1509/4000: train_loss=0.0013  test_loss=66.8716  λ_max=1.9657\n",
      "[Muon | lr=0.05] Epoch 1510/4000: train_loss=0.0011  test_loss=66.8923  λ_max=1.9767\n",
      "[Muon | lr=0.05] Epoch 1511/4000: train_loss=0.0013  test_loss=66.8441  λ_max=1.9364\n",
      "[Muon | lr=0.05] Epoch 1512/4000: train_loss=0.0014  test_loss=66.8675  λ_max=1.9400\n",
      "[Muon | lr=0.05] Iter 24200: loss=0.0006\n",
      "[Muon | lr=0.05] Epoch 1513/4000: train_loss=0.0015  test_loss=66.9076  λ_max=1.8509\n",
      "[Muon | lr=0.05] Epoch 1514/4000: train_loss=0.0011  test_loss=66.9645  λ_max=2.0029\n",
      "[Muon | lr=0.05] Epoch 1515/4000: train_loss=0.0014  test_loss=66.9641  λ_max=1.9752\n",
      "[Muon | lr=0.05] Epoch 1516/4000: train_loss=0.0013  test_loss=66.9675  λ_max=1.9084\n",
      "[Muon | lr=0.05] Epoch 1517/4000: train_loss=0.0011  test_loss=66.9933  λ_max=1.9312\n",
      "[Muon | lr=0.05] Epoch 1518/4000: train_loss=0.0012  test_loss=66.9550  λ_max=2.0239\n",
      "[Muon | lr=0.05] Iter 24300: loss=0.0029\n",
      "[Muon | lr=0.05] Epoch 1519/4000: train_loss=0.0011  test_loss=66.9637  λ_max=1.9621\n",
      "[Muon | lr=0.05] Epoch 1520/4000: train_loss=0.0012  test_loss=67.0920  λ_max=2.0443\n",
      "[Muon | lr=0.05] Epoch 1521/4000: train_loss=0.0009  test_loss=67.2147  λ_max=1.9569\n",
      "[Muon | lr=0.05] Epoch 1522/4000: train_loss=0.0011  test_loss=67.3384  λ_max=2.0925\n",
      "[Muon | lr=0.05] Epoch 1523/4000: train_loss=0.0011  test_loss=67.3401  λ_max=1.9827\n",
      "[Muon | lr=0.05] Epoch 1524/4000: train_loss=0.0010  test_loss=67.3972  λ_max=1.8966\n",
      "[Muon | lr=0.05] Iter 24400: loss=0.0009\n",
      "[Muon | lr=0.05] Epoch 1525/4000: train_loss=0.0009  test_loss=67.3686  λ_max=1.9211\n",
      "[Muon | lr=0.05] Epoch 1526/4000: train_loss=0.0011  test_loss=67.3240  λ_max=2.0032\n",
      "[Muon | lr=0.05] Epoch 1527/4000: train_loss=0.0011  test_loss=67.2851  λ_max=1.9017\n",
      "[Muon | lr=0.05] Epoch 1528/4000: train_loss=0.0013  test_loss=67.2899  λ_max=2.1159\n",
      "[Muon | lr=0.05] Epoch 1529/4000: train_loss=0.0012  test_loss=67.3345  λ_max=1.9878\n",
      "[Muon | lr=0.05] Epoch 1530/4000: train_loss=0.0013  test_loss=67.3430  λ_max=1.9829\n",
      "[Muon | lr=0.05] Epoch 1531/4000: train_loss=0.0012  test_loss=67.3727  λ_max=1.8477\n",
      "[Muon | lr=0.05] Iter 24500: loss=0.0003\n",
      "[Muon | lr=0.05] Epoch 1532/4000: train_loss=0.0012  test_loss=67.4422  λ_max=1.9841\n",
      "[Muon | lr=0.05] Epoch 1533/4000: train_loss=0.0011  test_loss=67.4769  λ_max=2.0451\n",
      "[Muon | lr=0.05] Epoch 1534/4000: train_loss=0.0010  test_loss=67.5028  λ_max=1.9151\n",
      "[Muon | lr=0.05] Epoch 1535/4000: train_loss=0.0011  test_loss=67.5505  λ_max=2.0124\n",
      "[Muon | lr=0.05] Epoch 1536/4000: train_loss=0.0012  test_loss=67.5878  λ_max=1.9122\n",
      "[Muon | lr=0.05] Epoch 1537/4000: train_loss=0.0016  test_loss=67.5525  λ_max=1.8836\n",
      "[Muon | lr=0.05] Iter 24600: loss=0.0010\n",
      "[Muon | lr=0.05] Epoch 1538/4000: train_loss=0.0012  test_loss=67.6309  λ_max=1.8713\n",
      "[Muon | lr=0.05] Epoch 1539/4000: train_loss=0.0012  test_loss=67.6618  λ_max=2.0402\n",
      "[Muon | lr=0.05] Epoch 1540/4000: train_loss=0.0012  test_loss=67.6521  λ_max=1.9165\n",
      "[Muon | lr=0.05] Epoch 1541/4000: train_loss=0.0013  test_loss=67.7063  λ_max=1.8880\n",
      "[Muon | lr=0.05] Epoch 1542/4000: train_loss=0.0010  test_loss=67.8352  λ_max=2.0144\n",
      "[Muon | lr=0.05] Epoch 1543/4000: train_loss=0.0011  test_loss=67.8479  λ_max=2.0277\n",
      "[Muon | lr=0.05] Iter 24700: loss=0.0024\n",
      "[Muon | lr=0.05] Epoch 1544/4000: train_loss=0.0011  test_loss=67.8792  λ_max=1.9630\n",
      "[Muon | lr=0.05] Epoch 1545/4000: train_loss=0.0011  test_loss=67.9664  λ_max=2.0856\n",
      "[Muon | lr=0.05] Epoch 1546/4000: train_loss=0.0010  test_loss=67.8910  λ_max=1.9202\n",
      "[Muon | lr=0.05] Epoch 1547/4000: train_loss=0.0009  test_loss=67.9447  λ_max=1.9011\n",
      "[Muon | lr=0.05] Epoch 1548/4000: train_loss=0.0015  test_loss=67.9959  λ_max=2.0558\n",
      "[Muon | lr=0.05] Epoch 1549/4000: train_loss=0.0013  test_loss=68.0779  λ_max=2.0235\n",
      "[Muon | lr=0.05] Iter 24800: loss=0.0056\n",
      "[Muon | lr=0.05] Epoch 1550/4000: train_loss=0.0013  test_loss=68.0462  λ_max=2.0622\n",
      "[Muon | lr=0.05] Epoch 1551/4000: train_loss=0.0012  test_loss=68.0656  λ_max=1.9950\n",
      "[Muon | lr=0.05] Epoch 1552/4000: train_loss=0.0012  test_loss=68.1670  λ_max=1.7544\n",
      "[Muon | lr=0.05] Epoch 1553/4000: train_loss=0.0013  test_loss=68.1298  λ_max=2.0215\n",
      "[Muon | lr=0.05] Epoch 1554/4000: train_loss=0.0013  test_loss=68.0878  λ_max=1.9641\n",
      "[Muon | lr=0.05] Epoch 1555/4000: train_loss=0.0011  test_loss=68.1455  λ_max=2.0403\n",
      "[Muon | lr=0.05] Epoch 1556/4000: train_loss=0.0012  test_loss=68.2647  λ_max=2.1287\n",
      "[Muon | lr=0.05] Iter 24900: loss=0.0003\n",
      "[Muon | lr=0.05] Epoch 1557/4000: train_loss=0.0009  test_loss=68.3262  λ_max=1.8870\n",
      "[Muon | lr=0.05] Epoch 1558/4000: train_loss=0.0015  test_loss=68.4115  λ_max=1.9359\n",
      "[Muon | lr=0.05] Epoch 1559/4000: train_loss=0.0012  test_loss=68.4211  λ_max=1.9473\n",
      "[Muon | lr=0.05] Epoch 1560/4000: train_loss=0.0011  test_loss=68.4259  λ_max=2.0447\n",
      "[Muon | lr=0.05] Epoch 1561/4000: train_loss=0.0011  test_loss=68.4693  λ_max=2.1584\n",
      "[Muon | lr=0.05] Epoch 1562/4000: train_loss=0.0012  test_loss=68.5107  λ_max=1.9038\n",
      "[Muon | lr=0.05] Iter 25000: loss=0.0008\n",
      "[Muon | lr=0.05] Epoch 1563/4000: train_loss=0.0012  test_loss=68.5809  λ_max=2.0410\n",
      "[Muon | lr=0.05] Epoch 1564/4000: train_loss=0.0011  test_loss=68.6172  λ_max=2.1301\n",
      "[Muon | lr=0.05] Epoch 1565/4000: train_loss=0.0012  test_loss=68.6997  λ_max=2.0939\n",
      "[Muon | lr=0.05] Epoch 1566/4000: train_loss=0.0014  test_loss=68.6691  λ_max=2.0685\n",
      "[Muon | lr=0.05] Epoch 1567/4000: train_loss=0.0011  test_loss=68.6950  λ_max=2.1204\n",
      "[Muon | lr=0.05] Epoch 1568/4000: train_loss=0.0013  test_loss=68.7059  λ_max=2.0262\n",
      "[Muon | lr=0.05] Iter 25100: loss=0.0012\n",
      "[Muon | lr=0.05] Epoch 1569/4000: train_loss=0.0011  test_loss=68.7051  λ_max=1.9205\n",
      "[Muon | lr=0.05] Epoch 1570/4000: train_loss=0.0013  test_loss=68.6942  λ_max=1.9229\n",
      "[Muon | lr=0.05] Epoch 1571/4000: train_loss=0.0014  test_loss=68.6790  λ_max=1.9616\n",
      "[Muon | lr=0.05] Epoch 1572/4000: train_loss=0.0011  test_loss=68.6905  λ_max=1.9469\n",
      "[Muon | lr=0.05] Epoch 1573/4000: train_loss=0.0011  test_loss=68.7627  λ_max=1.9761\n",
      "[Muon | lr=0.05] Epoch 1574/4000: train_loss=0.0012  test_loss=68.7361  λ_max=2.0460\n",
      "[Muon | lr=0.05] Iter 25200: loss=0.0033\n",
      "[Muon | lr=0.05] Epoch 1575/4000: train_loss=0.0012  test_loss=68.6803  λ_max=1.9458\n",
      "[Muon | lr=0.05] Epoch 1576/4000: train_loss=0.0012  test_loss=68.6598  λ_max=1.9133\n",
      "[Muon | lr=0.05] Epoch 1577/4000: train_loss=0.0013  test_loss=68.6303  λ_max=1.9980\n",
      "[Muon | lr=0.05] Epoch 1578/4000: train_loss=0.0015  test_loss=68.6467  λ_max=1.9058\n",
      "[Muon | lr=0.05] Epoch 1579/4000: train_loss=0.0012  test_loss=68.6397  λ_max=1.9669\n",
      "[Muon | lr=0.05] Epoch 1580/4000: train_loss=0.0010  test_loss=68.6305  λ_max=1.9888\n",
      "[Muon | lr=0.05] Epoch 1581/4000: train_loss=0.0017  test_loss=68.6290  λ_max=1.8669\n",
      "[Muon | lr=0.05] Iter 25300: loss=0.0004\n",
      "[Muon | lr=0.05] Epoch 1582/4000: train_loss=0.0010  test_loss=68.5642  λ_max=2.0171\n",
      "[Muon | lr=0.05] Epoch 1583/4000: train_loss=0.0012  test_loss=68.6600  λ_max=1.8387\n",
      "[Muon | lr=0.05] Epoch 1584/4000: train_loss=0.0013  test_loss=68.7701  λ_max=1.7799\n",
      "[Muon | lr=0.05] Epoch 1585/4000: train_loss=0.0010  test_loss=68.7297  λ_max=2.0187\n",
      "[Muon | lr=0.05] Epoch 1586/4000: train_loss=0.0009  test_loss=68.7388  λ_max=2.0944\n",
      "[Muon | lr=0.05] Epoch 1587/4000: train_loss=0.0012  test_loss=68.7460  λ_max=1.8652\n",
      "[Muon | lr=0.05] Iter 25400: loss=0.0009\n",
      "[Muon | lr=0.05] Epoch 1588/4000: train_loss=0.0013  test_loss=68.7859  λ_max=1.8593\n",
      "[Muon | lr=0.05] Epoch 1589/4000: train_loss=0.0013  test_loss=68.8670  λ_max=1.9467\n",
      "[Muon | lr=0.05] Epoch 1590/4000: train_loss=0.0013  test_loss=68.8603  λ_max=1.8072\n",
      "[Muon | lr=0.05] Epoch 1591/4000: train_loss=0.0014  test_loss=68.9639  λ_max=1.9876\n",
      "[Muon | lr=0.05] Epoch 1592/4000: train_loss=0.0010  test_loss=69.0229  λ_max=2.1289\n",
      "[Muon | lr=0.05] Epoch 1593/4000: train_loss=0.0012  test_loss=69.0395  λ_max=1.8516\n",
      "[Muon | lr=0.05] Iter 25500: loss=0.0010\n",
      "[Muon | lr=0.05] Epoch 1594/4000: train_loss=0.0013  test_loss=69.0123  λ_max=1.9992\n",
      "[Muon | lr=0.05] Epoch 1595/4000: train_loss=0.0012  test_loss=69.0280  λ_max=2.0774\n",
      "[Muon | lr=0.05] Epoch 1596/4000: train_loss=0.0013  test_loss=69.0324  λ_max=2.0887\n",
      "[Muon | lr=0.05] Epoch 1597/4000: train_loss=0.0009  test_loss=69.0199  λ_max=1.9309\n",
      "[Muon | lr=0.05] Epoch 1598/4000: train_loss=0.0011  test_loss=68.9949  λ_max=1.9143\n",
      "[Muon | lr=0.05] Epoch 1599/4000: train_loss=0.0012  test_loss=68.9693  λ_max=1.8221\n",
      "[Muon | lr=0.05] Iter 25600: loss=0.0020\n",
      "[Muon | lr=0.05] Epoch 1600/4000: train_loss=0.0014  test_loss=68.9540  λ_max=2.0282\n",
      "[Muon | lr=0.05] Epoch 1601/4000: train_loss=0.0010  test_loss=68.9308  λ_max=2.0662\n",
      "[Muon | lr=0.05] Epoch 1602/4000: train_loss=0.0008  test_loss=68.9570  λ_max=1.9910\n",
      "[Muon | lr=0.05] Epoch 1603/4000: train_loss=0.0012  test_loss=68.9410  λ_max=2.0762\n",
      "[Muon | lr=0.05] Epoch 1604/4000: train_loss=0.0010  test_loss=69.0350  λ_max=2.0183\n",
      "[Muon | lr=0.05] Epoch 1605/4000: train_loss=0.0014  test_loss=69.1276  λ_max=1.9300\n",
      "[Muon | lr=0.05] Epoch 1606/4000: train_loss=0.0011  test_loss=69.2166  λ_max=2.0590\n",
      "[Muon | lr=0.05] Iter 25700: loss=0.0002\n",
      "[Muon | lr=0.05] Epoch 1607/4000: train_loss=0.0009  test_loss=69.2613  λ_max=2.0307\n",
      "[Muon | lr=0.05] Epoch 1608/4000: train_loss=0.0012  test_loss=69.2297  λ_max=1.9044\n",
      "[Muon | lr=0.05] Epoch 1609/4000: train_loss=0.0010  test_loss=69.2219  λ_max=1.9972\n",
      "[Muon | lr=0.05] Epoch 1610/4000: train_loss=0.0013  test_loss=69.3854  λ_max=2.0589\n",
      "[Muon | lr=0.05] Epoch 1611/4000: train_loss=0.0011  test_loss=69.5161  λ_max=1.9841\n",
      "[Muon | lr=0.05] Epoch 1612/4000: train_loss=0.0010  test_loss=69.5613  λ_max=2.1070\n",
      "[Muon | lr=0.05] Iter 25800: loss=0.0012\n",
      "[Muon | lr=0.05] Epoch 1613/4000: train_loss=0.0011  test_loss=69.6419  λ_max=1.9532\n",
      "[Muon | lr=0.05] Epoch 1614/4000: train_loss=0.0008  test_loss=69.6731  λ_max=2.0784\n",
      "[Muon | lr=0.05] Epoch 1615/4000: train_loss=0.0010  test_loss=69.6957  λ_max=1.9646\n",
      "[Muon | lr=0.05] Epoch 1616/4000: train_loss=0.0010  test_loss=69.6999  λ_max=1.8021\n",
      "[Muon | lr=0.05] Epoch 1617/4000: train_loss=0.0015  test_loss=69.6030  λ_max=2.0581\n",
      "[Muon | lr=0.05] Epoch 1618/4000: train_loss=0.0012  test_loss=69.6548  λ_max=1.9586\n",
      "[Muon | lr=0.05] Iter 25900: loss=0.0018\n",
      "[Muon | lr=0.05] Epoch 1619/4000: train_loss=0.0013  test_loss=69.7539  λ_max=1.9619\n",
      "[Muon | lr=0.05] Epoch 1620/4000: train_loss=0.0014  test_loss=69.7982  λ_max=1.9320\n",
      "[Muon | lr=0.05] Epoch 1621/4000: train_loss=0.0015  test_loss=69.8281  λ_max=1.9207\n",
      "[Muon | lr=0.05] Epoch 1622/4000: train_loss=0.0012  test_loss=69.8594  λ_max=1.9752\n",
      "[Muon | lr=0.05] Epoch 1623/4000: train_loss=0.0009  test_loss=69.8912  λ_max=2.0204\n",
      "[Muon | lr=0.05] Epoch 1624/4000: train_loss=0.0009  test_loss=69.9372  λ_max=2.1017\n",
      "[Muon | lr=0.05] Iter 26000: loss=0.0062\n",
      "[Muon | lr=0.05] Epoch 1625/4000: train_loss=0.0013  test_loss=70.0143  λ_max=2.1228\n",
      "[Muon | lr=0.05] Epoch 1626/4000: train_loss=0.0011  test_loss=69.9478  λ_max=1.9760\n",
      "[Muon | lr=0.05] Epoch 1627/4000: train_loss=0.0012  test_loss=69.9329  λ_max=1.9983\n",
      "[Muon | lr=0.05] Epoch 1628/4000: train_loss=0.0010  test_loss=69.9950  λ_max=2.1264\n",
      "[Muon | lr=0.05] Epoch 1629/4000: train_loss=0.0012  test_loss=69.9799  λ_max=2.1987\n",
      "[Muon | lr=0.05] Epoch 1630/4000: train_loss=0.0009  test_loss=70.0209  λ_max=1.9842\n",
      "[Muon | lr=0.05] Epoch 1631/4000: train_loss=0.0012  test_loss=70.0820  λ_max=2.0269\n",
      "[Muon | lr=0.05] Iter 26100: loss=0.0002\n",
      "[Muon | lr=0.05] Epoch 1632/4000: train_loss=0.0009  test_loss=70.2045  λ_max=2.1047\n",
      "[Muon | lr=0.05] Epoch 1633/4000: train_loss=0.0008  test_loss=70.2453  λ_max=2.1331\n",
      "[Muon | lr=0.05] Epoch 1634/4000: train_loss=0.0014  test_loss=70.3033  λ_max=2.0001\n",
      "[Muon | lr=0.05] Epoch 1635/4000: train_loss=0.0011  test_loss=70.3681  λ_max=1.9505\n",
      "[Muon | lr=0.05] Epoch 1636/4000: train_loss=0.0014  test_loss=70.3985  λ_max=2.0770\n",
      "[Muon | lr=0.05] Epoch 1637/4000: train_loss=0.0011  test_loss=70.3908  λ_max=2.2555\n",
      "[Muon | lr=0.05] Iter 26200: loss=0.0007\n",
      "[Muon | lr=0.05] Epoch 1638/4000: train_loss=0.0011  test_loss=70.4083  λ_max=2.0547\n",
      "[Muon | lr=0.05] Epoch 1639/4000: train_loss=0.0013  test_loss=70.3320  λ_max=2.2360\n",
      "[Muon | lr=0.05] Epoch 1640/4000: train_loss=0.0010  test_loss=70.3975  λ_max=1.9506\n",
      "[Muon | lr=0.05] Epoch 1641/4000: train_loss=0.0011  test_loss=70.4639  λ_max=2.0461\n",
      "[Muon | lr=0.05] Epoch 1642/4000: train_loss=0.0013  test_loss=70.4960  λ_max=2.0307\n",
      "[Muon | lr=0.05] Epoch 1643/4000: train_loss=0.0012  test_loss=70.4935  λ_max=2.1092\n",
      "[Muon | lr=0.05] Iter 26300: loss=0.0013\n",
      "[Muon | lr=0.05] Epoch 1644/4000: train_loss=0.0010  test_loss=70.5089  λ_max=1.9444\n",
      "[Muon | lr=0.05] Epoch 1645/4000: train_loss=0.0013  test_loss=70.6096  λ_max=2.0175\n",
      "[Muon | lr=0.05] Epoch 1646/4000: train_loss=0.0011  test_loss=70.6613  λ_max=2.0866\n",
      "[Muon | lr=0.05] Epoch 1647/4000: train_loss=0.0013  test_loss=70.7206  λ_max=2.0630\n",
      "[Muon | lr=0.05] Epoch 1648/4000: train_loss=0.0010  test_loss=70.7960  λ_max=1.8355\n",
      "[Muon | lr=0.05] Epoch 1649/4000: train_loss=0.0013  test_loss=70.8411  λ_max=1.8723\n",
      "[Muon | lr=0.05] Iter 26400: loss=0.0033\n",
      "[Muon | lr=0.05] Epoch 1650/4000: train_loss=0.0011  test_loss=70.9705  λ_max=1.9202\n",
      "[Muon | lr=0.05] Epoch 1651/4000: train_loss=0.0015  test_loss=71.0758  λ_max=1.8688\n",
      "[Muon | lr=0.05] Epoch 1652/4000: train_loss=0.0009  test_loss=71.1632  λ_max=1.9176\n",
      "[Muon | lr=0.05] Epoch 1653/4000: train_loss=0.0012  test_loss=71.2880  λ_max=1.9400\n",
      "[Muon | lr=0.05] Epoch 1654/4000: train_loss=0.0012  test_loss=71.3685  λ_max=2.0488\n",
      "[Muon | lr=0.05] Epoch 1655/4000: train_loss=0.0008  test_loss=71.3374  λ_max=1.9713\n",
      "[Muon | lr=0.05] Epoch 1656/4000: train_loss=0.0014  test_loss=71.2943  λ_max=2.0158\n",
      "[Muon | lr=0.05] Iter 26500: loss=0.0000\n",
      "[Muon | lr=0.05] Epoch 1657/4000: train_loss=0.0011  test_loss=71.3593  λ_max=1.9670\n",
      "[Muon | lr=0.05] Epoch 1658/4000: train_loss=0.0011  test_loss=71.3461  λ_max=2.0630\n",
      "[Muon | lr=0.05] Epoch 1659/4000: train_loss=0.0015  test_loss=71.3551  λ_max=2.0907\n",
      "[Muon | lr=0.05] Epoch 1660/4000: train_loss=0.0009  test_loss=71.3728  λ_max=2.1139\n",
      "[Muon | lr=0.05] Epoch 1661/4000: train_loss=0.0013  test_loss=71.4087  λ_max=1.8984\n",
      "[Muon | lr=0.05] Epoch 1662/4000: train_loss=0.0013  test_loss=71.4757  λ_max=2.0474\n",
      "[Muon | lr=0.05] Iter 26600: loss=0.0008\n",
      "[Muon | lr=0.05] Epoch 1663/4000: train_loss=0.0011  test_loss=71.6051  λ_max=1.9489\n",
      "[Muon | lr=0.05] Epoch 1664/4000: train_loss=0.0008  test_loss=71.7578  λ_max=2.0164\n",
      "[Muon | lr=0.05] Epoch 1665/4000: train_loss=0.0010  test_loss=71.8331  λ_max=2.0210\n",
      "[Muon | lr=0.05] Epoch 1666/4000: train_loss=0.0013  test_loss=71.8213  λ_max=1.9242\n",
      "[Muon | lr=0.05] Epoch 1667/4000: train_loss=0.0010  test_loss=71.7904  λ_max=2.0252\n",
      "[Muon | lr=0.05] Epoch 1668/4000: train_loss=0.0012  test_loss=71.8658  λ_max=1.9858\n",
      "[Muon | lr=0.05] Iter 26700: loss=0.0015\n",
      "[Muon | lr=0.05] Epoch 1669/4000: train_loss=0.0012  test_loss=71.8851  λ_max=1.8593\n",
      "[Muon | lr=0.05] Epoch 1670/4000: train_loss=0.0013  test_loss=71.8481  λ_max=2.0637\n",
      "[Muon | lr=0.05] Epoch 1671/4000: train_loss=0.0010  test_loss=71.8862  λ_max=1.9346\n",
      "[Muon | lr=0.05] Epoch 1672/4000: train_loss=0.0012  test_loss=71.8519  λ_max=2.0081\n",
      "[Muon | lr=0.05] Epoch 1673/4000: train_loss=0.0010  test_loss=71.8504  λ_max=1.9677\n",
      "[Muon | lr=0.05] Epoch 1674/4000: train_loss=0.0011  test_loss=71.8608  λ_max=2.0183\n",
      "[Muon | lr=0.05] Iter 26800: loss=0.0019\n",
      "[Muon | lr=0.05] Epoch 1675/4000: train_loss=0.0011  test_loss=71.8510  λ_max=1.8832\n",
      "[Muon | lr=0.05] Epoch 1676/4000: train_loss=0.0012  test_loss=71.9231  λ_max=1.8310\n",
      "[Muon | lr=0.05] Epoch 1677/4000: train_loss=0.0009  test_loss=71.9185  λ_max=2.0176\n",
      "[Muon | lr=0.05] Epoch 1678/4000: train_loss=0.0011  test_loss=71.9975  λ_max=2.0380\n",
      "[Muon | lr=0.05] Epoch 1679/4000: train_loss=0.0013  test_loss=72.0557  λ_max=1.8791\n",
      "[Muon | lr=0.05] Epoch 1680/4000: train_loss=0.0009  test_loss=72.1830  λ_max=2.0046\n",
      "[Muon | lr=0.05] Epoch 1681/4000: train_loss=0.0010  test_loss=72.2186  λ_max=1.9025\n",
      "[Muon | lr=0.05] Iter 26900: loss=0.0006\n",
      "[Muon | lr=0.05] Epoch 1682/4000: train_loss=0.0012  test_loss=72.1985  λ_max=1.9153\n",
      "[Muon | lr=0.05] Epoch 1683/4000: train_loss=0.0010  test_loss=72.2463  λ_max=2.1446\n",
      "[Muon | lr=0.05] Epoch 1684/4000: train_loss=0.0011  test_loss=72.3473  λ_max=1.9914\n",
      "[Muon | lr=0.05] Epoch 1685/4000: train_loss=0.0012  test_loss=72.3479  λ_max=2.0705\n",
      "[Muon | lr=0.05] Epoch 1686/4000: train_loss=0.0014  test_loss=72.4080  λ_max=1.8768\n",
      "[Muon | lr=0.05] Epoch 1687/4000: train_loss=0.0015  test_loss=72.4962  λ_max=1.8153\n",
      "[Muon | lr=0.05] Iter 27000: loss=0.0006\n",
      "[Muon | lr=0.05] Epoch 1688/4000: train_loss=0.0012  test_loss=72.5875  λ_max=1.9251\n",
      "[Muon | lr=0.05] Epoch 1689/4000: train_loss=0.0011  test_loss=72.6598  λ_max=1.9948\n",
      "[Muon | lr=0.05] Epoch 1690/4000: train_loss=0.0013  test_loss=72.7393  λ_max=2.1907\n",
      "[Muon | lr=0.05] Epoch 1691/4000: train_loss=0.0009  test_loss=72.7932  λ_max=2.0052\n",
      "[Muon | lr=0.05] Epoch 1692/4000: train_loss=0.0012  test_loss=72.8237  λ_max=2.0478\n",
      "[Muon | lr=0.05] Epoch 1693/4000: train_loss=0.0009  test_loss=72.8850  λ_max=1.8786\n",
      "[Muon | lr=0.05] Iter 27100: loss=0.0014\n",
      "[Muon | lr=0.05] Epoch 1694/4000: train_loss=0.0010  test_loss=72.8785  λ_max=1.9682\n",
      "[Muon | lr=0.05] Epoch 1695/4000: train_loss=0.0010  test_loss=72.8359  λ_max=2.0818\n",
      "[Muon | lr=0.05] Epoch 1696/4000: train_loss=0.0009  test_loss=72.8223  λ_max=2.1134\n",
      "[Muon | lr=0.05] Epoch 1697/4000: train_loss=0.0010  test_loss=72.8604  λ_max=2.0327\n",
      "[Muon | lr=0.05] Epoch 1698/4000: train_loss=0.0010  test_loss=72.8105  λ_max=2.0052\n",
      "[Muon | lr=0.05] Epoch 1699/4000: train_loss=0.0009  test_loss=72.7727  λ_max=2.0022\n",
      "[Muon | lr=0.05] Iter 27200: loss=0.0011\n",
      "[Muon | lr=0.05] Epoch 1700/4000: train_loss=0.0011  test_loss=72.7197  λ_max=2.0553\n",
      "[Muon | lr=0.05] Epoch 1701/4000: train_loss=0.0012  test_loss=72.7008  λ_max=1.9535\n",
      "[Muon | lr=0.05] Epoch 1702/4000: train_loss=0.0011  test_loss=72.7267  λ_max=2.0184\n",
      "[Muon | lr=0.05] Epoch 1703/4000: train_loss=0.0010  test_loss=72.7750  λ_max=2.0158\n",
      "[Muon | lr=0.05] Epoch 1704/4000: train_loss=0.0013  test_loss=72.7555  λ_max=2.0949\n",
      "[Muon | lr=0.05] Epoch 1705/4000: train_loss=0.0010  test_loss=72.7615  λ_max=2.2350\n",
      "[Muon | lr=0.05] Epoch 1706/4000: train_loss=0.0009  test_loss=72.8241  λ_max=1.9829\n",
      "[Muon | lr=0.05] Iter 27300: loss=0.0005\n",
      "[Muon | lr=0.05] Epoch 1707/4000: train_loss=0.0011  test_loss=72.8105  λ_max=2.0606\n",
      "[Muon | lr=0.05] Epoch 1708/4000: train_loss=0.0011  test_loss=72.7893  λ_max=2.0886\n",
      "[Muon | lr=0.05] Epoch 1709/4000: train_loss=0.0012  test_loss=72.7189  λ_max=1.9920\n",
      "[Muon | lr=0.05] Epoch 1710/4000: train_loss=0.0011  test_loss=72.7289  λ_max=1.9389\n",
      "[Muon | lr=0.05] Epoch 1711/4000: train_loss=0.0014  test_loss=72.7389  λ_max=2.0079\n",
      "[Muon | lr=0.05] Epoch 1712/4000: train_loss=0.0013  test_loss=72.7092  λ_max=2.1513\n",
      "[Muon | lr=0.05] Iter 27400: loss=0.0025\n",
      "[Muon | lr=0.05] Epoch 1713/4000: train_loss=0.0011  test_loss=72.7024  λ_max=2.1847\n",
      "[Muon | lr=0.05] Epoch 1714/4000: train_loss=0.0009  test_loss=72.7840  λ_max=1.8824\n",
      "[Muon | lr=0.05] Epoch 1715/4000: train_loss=0.0011  test_loss=72.9137  λ_max=2.0224\n",
      "[Muon | lr=0.05] Epoch 1716/4000: train_loss=0.0009  test_loss=73.0127  λ_max=1.9075\n",
      "[Muon | lr=0.05] Epoch 1717/4000: train_loss=0.0012  test_loss=73.0190  λ_max=1.9347\n",
      "[Muon | lr=0.05] Epoch 1718/4000: train_loss=0.0009  test_loss=72.9586  λ_max=2.0123\n",
      "[Muon | lr=0.05] Iter 27500: loss=0.0016\n",
      "[Muon | lr=0.05] Epoch 1719/4000: train_loss=0.0008  test_loss=72.9915  λ_max=1.9707\n",
      "[Muon | lr=0.05] Epoch 1720/4000: train_loss=0.0014  test_loss=73.0177  λ_max=2.0372\n",
      "[Muon | lr=0.05] Epoch 1721/4000: train_loss=0.0010  test_loss=73.0139  λ_max=1.9154\n",
      "[Muon | lr=0.05] Epoch 1722/4000: train_loss=0.0010  test_loss=72.9954  λ_max=1.9142\n",
      "[Muon | lr=0.05] Epoch 1723/4000: train_loss=0.0009  test_loss=72.9756  λ_max=2.0049\n",
      "[Muon | lr=0.05] Epoch 1724/4000: train_loss=0.0012  test_loss=72.9959  λ_max=1.9328\n",
      "[Muon | lr=0.05] Iter 27600: loss=0.0062\n",
      "[Muon | lr=0.05] Epoch 1725/4000: train_loss=0.0014  test_loss=73.0040  λ_max=1.9496\n",
      "[Muon | lr=0.05] Epoch 1726/4000: train_loss=0.0011  test_loss=73.0245  λ_max=2.0409\n",
      "[Muon | lr=0.05] Epoch 1727/4000: train_loss=0.0011  test_loss=73.0907  λ_max=2.2154\n",
      "[Muon | lr=0.05] Epoch 1728/4000: train_loss=0.0011  test_loss=73.0982  λ_max=1.9902\n",
      "[Muon | lr=0.05] Epoch 1729/4000: train_loss=0.0012  test_loss=73.0813  λ_max=2.0657\n",
      "[Muon | lr=0.05] Epoch 1730/4000: train_loss=0.0013  test_loss=73.1705  λ_max=2.1058\n",
      "[Muon | lr=0.05] Epoch 1731/4000: train_loss=0.0011  test_loss=73.0612  λ_max=2.0627\n",
      "[Muon | lr=0.05] Iter 27700: loss=0.0005\n",
      "[Muon | lr=0.05] Epoch 1732/4000: train_loss=0.0012  test_loss=73.0246  λ_max=1.9640\n",
      "[Muon | lr=0.05] Epoch 1733/4000: train_loss=0.0012  test_loss=73.0611  λ_max=2.1851\n",
      "[Muon | lr=0.05] Epoch 1734/4000: train_loss=0.0013  test_loss=73.0601  λ_max=1.9401\n",
      "[Muon | lr=0.05] Epoch 1735/4000: train_loss=0.0010  test_loss=73.1796  λ_max=2.1537\n",
      "[Muon | lr=0.05] Epoch 1736/4000: train_loss=0.0008  test_loss=73.2760  λ_max=2.0226\n",
      "[Muon | lr=0.05] Epoch 1737/4000: train_loss=0.0015  test_loss=73.2721  λ_max=2.0110\n",
      "[Muon | lr=0.05] Iter 27800: loss=0.0002\n",
      "[Muon | lr=0.05] Epoch 1738/4000: train_loss=0.0011  test_loss=73.2520  λ_max=2.0507\n",
      "[Muon | lr=0.05] Epoch 1739/4000: train_loss=0.0014  test_loss=73.2415  λ_max=1.9077\n",
      "[Muon | lr=0.05] Epoch 1740/4000: train_loss=0.0010  test_loss=73.2359  λ_max=1.9976\n",
      "[Muon | lr=0.05] Epoch 1741/4000: train_loss=0.0009  test_loss=73.1900  λ_max=2.0114\n",
      "[Muon | lr=0.05] Epoch 1742/4000: train_loss=0.0010  test_loss=73.1533  λ_max=2.0108\n",
      "[Muon | lr=0.05] Epoch 1743/4000: train_loss=0.0011  test_loss=73.0981  λ_max=2.0824\n",
      "[Muon | lr=0.05] Iter 27900: loss=0.0012\n",
      "[Muon | lr=0.05] Epoch 1744/4000: train_loss=0.0011  test_loss=73.0071  λ_max=2.0124\n",
      "[Muon | lr=0.05] Epoch 1745/4000: train_loss=0.0012  test_loss=72.9839  λ_max=2.1850\n",
      "[Muon | lr=0.05] Epoch 1746/4000: train_loss=0.0013  test_loss=73.0405  λ_max=1.9379\n",
      "[Muon | lr=0.05] Epoch 1747/4000: train_loss=0.0007  test_loss=73.0072  λ_max=2.2594\n",
      "[Muon | lr=0.05] Epoch 1748/4000: train_loss=0.0011  test_loss=72.9751  λ_max=2.1068\n",
      "[Muon | lr=0.05] Epoch 1749/4000: train_loss=0.0011  test_loss=73.0672  λ_max=2.2373\n",
      "[Muon | lr=0.05] Iter 28000: loss=0.0028\n",
      "[Muon | lr=0.05] Epoch 1750/4000: train_loss=0.0014  test_loss=73.1203  λ_max=2.0431\n",
      "[Muon | lr=0.05] Epoch 1751/4000: train_loss=0.0009  test_loss=73.1280  λ_max=2.0241\n",
      "[Muon | lr=0.05] Epoch 1752/4000: train_loss=0.0009  test_loss=73.1070  λ_max=2.1596\n",
      "[Muon | lr=0.05] Epoch 1753/4000: train_loss=0.0009  test_loss=73.1430  λ_max=2.1366\n",
      "[Muon | lr=0.05] Epoch 1754/4000: train_loss=0.0011  test_loss=73.1868  λ_max=2.0707\n",
      "[Muon | lr=0.05] Epoch 1755/4000: train_loss=0.0011  test_loss=73.2328  λ_max=2.1588\n",
      "[Muon | lr=0.05] Epoch 1756/4000: train_loss=0.0012  test_loss=73.2494  λ_max=2.1335\n",
      "[Muon | lr=0.05] Iter 28100: loss=0.0009\n",
      "[Muon | lr=0.05] Epoch 1757/4000: train_loss=0.0010  test_loss=73.3076  λ_max=1.9483\n",
      "[Muon | lr=0.05] Epoch 1758/4000: train_loss=0.0010  test_loss=73.3210  λ_max=2.1944\n",
      "[Muon | lr=0.05] Epoch 1759/4000: train_loss=0.0013  test_loss=73.3905  λ_max=2.0971\n",
      "[Muon | lr=0.05] Epoch 1760/4000: train_loss=0.0013  test_loss=73.4586  λ_max=2.0740\n",
      "[Muon | lr=0.05] Epoch 1761/4000: train_loss=0.0010  test_loss=73.4479  λ_max=2.0792\n",
      "[Muon | lr=0.05] Epoch 1762/4000: train_loss=0.0011  test_loss=73.5251  λ_max=1.9855\n",
      "[Muon | lr=0.05] Iter 28200: loss=0.0002\n",
      "[Muon | lr=0.05] Epoch 1763/4000: train_loss=0.0011  test_loss=73.5507  λ_max=1.9922\n",
      "[Muon | lr=0.05] Epoch 1764/4000: train_loss=0.0012  test_loss=73.6461  λ_max=2.0174\n",
      "[Muon | lr=0.05] Epoch 1765/4000: train_loss=0.0012  test_loss=73.7315  λ_max=2.1374\n",
      "[Muon | lr=0.05] Epoch 1766/4000: train_loss=0.0012  test_loss=73.7432  λ_max=2.0258\n",
      "[Muon | lr=0.05] Epoch 1767/4000: train_loss=0.0015  test_loss=73.7293  λ_max=2.0598\n",
      "[Muon | lr=0.05] Epoch 1768/4000: train_loss=0.0015  test_loss=73.8053  λ_max=2.0219\n",
      "[Muon | lr=0.05] Iter 28300: loss=0.0006\n",
      "[Muon | lr=0.05] Epoch 1769/4000: train_loss=0.0012  test_loss=73.8691  λ_max=2.0303\n",
      "[Muon | lr=0.05] Epoch 1770/4000: train_loss=0.0011  test_loss=73.8173  λ_max=2.2477\n",
      "[Muon | lr=0.05] Epoch 1771/4000: train_loss=0.0011  test_loss=73.8743  λ_max=2.0043\n",
      "[Muon | lr=0.05] Epoch 1772/4000: train_loss=0.0012  test_loss=73.9151  λ_max=2.0653\n",
      "[Muon | lr=0.05] Epoch 1773/4000: train_loss=0.0009  test_loss=74.0034  λ_max=2.0738\n",
      "[Muon | lr=0.05] Epoch 1774/4000: train_loss=0.0012  test_loss=73.9978  λ_max=2.1525\n",
      "[Muon | lr=0.05] Iter 28400: loss=0.0020\n",
      "[Muon | lr=0.05] Epoch 1775/4000: train_loss=0.0011  test_loss=74.0016  λ_max=2.0483\n",
      "[Muon | lr=0.05] Epoch 1776/4000: train_loss=0.0010  test_loss=74.0517  λ_max=2.1173\n",
      "[Muon | lr=0.05] Epoch 1777/4000: train_loss=0.0010  test_loss=74.1456  λ_max=2.2312\n",
      "[Muon | lr=0.05] Epoch 1778/4000: train_loss=0.0011  test_loss=74.1270  λ_max=2.1172\n",
      "[Muon | lr=0.05] Epoch 1779/4000: train_loss=0.0010  test_loss=74.1732  λ_max=2.1366\n",
      "[Muon | lr=0.05] Epoch 1780/4000: train_loss=0.0010  test_loss=74.2114  λ_max=2.0236\n",
      "[Muon | lr=0.05] Epoch 1781/4000: train_loss=0.0011  test_loss=74.2222  λ_max=2.0914\n",
      "[Muon | lr=0.05] Iter 28500: loss=0.0002\n",
      "[Muon | lr=0.05] Epoch 1782/4000: train_loss=0.0012  test_loss=74.2270  λ_max=2.0044\n",
      "[Muon | lr=0.05] Epoch 1783/4000: train_loss=0.0014  test_loss=74.1850  λ_max=2.0959\n",
      "[Muon | lr=0.05] Epoch 1784/4000: train_loss=0.0011  test_loss=74.1793  λ_max=1.9795\n",
      "[Muon | lr=0.05] Epoch 1785/4000: train_loss=0.0009  test_loss=74.2392  λ_max=2.0772\n",
      "[Muon | lr=0.05] Epoch 1786/4000: train_loss=0.0013  test_loss=74.2019  λ_max=2.0647\n",
      "[Muon | lr=0.05] Epoch 1787/4000: train_loss=0.0011  test_loss=74.2286  λ_max=1.9123\n",
      "[Muon | lr=0.05] Iter 28600: loss=0.0003\n",
      "[Muon | lr=0.05] Epoch 1788/4000: train_loss=0.0013  test_loss=74.3387  λ_max=2.0606\n",
      "[Muon | lr=0.05] Epoch 1789/4000: train_loss=0.0012  test_loss=74.3206  λ_max=2.1617\n",
      "[Muon | lr=0.05] Epoch 1790/4000: train_loss=0.0009  test_loss=74.3889  λ_max=2.1384\n",
      "[Muon | lr=0.05] Epoch 1791/4000: train_loss=0.0009  test_loss=74.3939  λ_max=2.1126\n",
      "[Muon | lr=0.05] Epoch 1792/4000: train_loss=0.0014  test_loss=74.4656  λ_max=2.1650\n",
      "[Muon | lr=0.05] Epoch 1793/4000: train_loss=0.0012  test_loss=74.4895  λ_max=2.0526\n",
      "[Muon | lr=0.05] Iter 28700: loss=0.0016\n",
      "[Muon | lr=0.05] Epoch 1794/4000: train_loss=0.0011  test_loss=74.4454  λ_max=2.1049\n",
      "[Muon | lr=0.05] Epoch 1795/4000: train_loss=0.0012  test_loss=74.4534  λ_max=1.9709\n",
      "[Muon | lr=0.05] Epoch 1796/4000: train_loss=0.0011  test_loss=74.4984  λ_max=2.0655\n",
      "[Muon | lr=0.05] Epoch 1797/4000: train_loss=0.0011  test_loss=74.6000  λ_max=2.0081\n",
      "[Muon | lr=0.05] Epoch 1798/4000: train_loss=0.0008  test_loss=74.7295  λ_max=2.1484\n",
      "[Muon | lr=0.05] Epoch 1799/4000: train_loss=0.0010  test_loss=74.7646  λ_max=2.1555\n",
      "[Muon | lr=0.05] Iter 28800: loss=0.0029\n",
      "[Muon | lr=0.05] Epoch 1800/4000: train_loss=0.0010  test_loss=74.7955  λ_max=2.1587\n",
      "[Muon | lr=0.05] Epoch 1801/4000: train_loss=0.0009  test_loss=74.8802  λ_max=2.1307\n",
      "[Muon | lr=0.05] Epoch 1802/4000: train_loss=0.0010  test_loss=74.9661  λ_max=2.1979\n",
      "[Muon | lr=0.05] Epoch 1803/4000: train_loss=0.0012  test_loss=75.0794  λ_max=2.1223\n",
      "[Muon | lr=0.05] Epoch 1804/4000: train_loss=0.0012  test_loss=75.0327  λ_max=2.0151\n",
      "[Muon | lr=0.05] Epoch 1805/4000: train_loss=0.0010  test_loss=75.0652  λ_max=2.1254\n",
      "[Muon | lr=0.05] Epoch 1806/4000: train_loss=0.0011  test_loss=75.1083  λ_max=1.9959\n",
      "[Muon | lr=0.05] Iter 28900: loss=0.0005\n",
      "[Muon | lr=0.05] Epoch 1807/4000: train_loss=0.0011  test_loss=75.0571  λ_max=1.9271\n",
      "[Muon | lr=0.05] Epoch 1808/4000: train_loss=0.0011  test_loss=75.0407  λ_max=2.0821\n",
      "[Muon | lr=0.05] Epoch 1809/4000: train_loss=0.0010  test_loss=75.1274  λ_max=2.0828\n",
      "[Muon | lr=0.05] Epoch 1810/4000: train_loss=0.0012  test_loss=75.1609  λ_max=1.9766\n",
      "[Muon | lr=0.05] Epoch 1811/4000: train_loss=0.0011  test_loss=75.1395  λ_max=2.1829\n",
      "[Muon | lr=0.05] Epoch 1812/4000: train_loss=0.0011  test_loss=75.1195  λ_max=2.1486\n",
      "[Muon | lr=0.05] Iter 29000: loss=0.0011\n",
      "[Muon | lr=0.05] Epoch 1813/4000: train_loss=0.0011  test_loss=75.1029  λ_max=2.1762\n",
      "[Muon | lr=0.05] Epoch 1814/4000: train_loss=0.0011  test_loss=75.0781  λ_max=1.9657\n",
      "[Muon | lr=0.05] Epoch 1815/4000: train_loss=0.0011  test_loss=75.0053  λ_max=1.9559\n",
      "[Muon | lr=0.05] Epoch 1816/4000: train_loss=0.0012  test_loss=74.9780  λ_max=2.1829\n",
      "[Muon | lr=0.05] Epoch 1817/4000: train_loss=0.0011  test_loss=74.9675  λ_max=2.1208\n",
      "[Muon | lr=0.05] Epoch 1818/4000: train_loss=0.0010  test_loss=74.9969  λ_max=2.3172\n",
      "[Muon | lr=0.05] Iter 29100: loss=0.0012\n",
      "[Muon | lr=0.05] Epoch 1819/4000: train_loss=0.0013  test_loss=75.0325  λ_max=2.0903\n",
      "[Muon | lr=0.05] Epoch 1820/4000: train_loss=0.0009  test_loss=75.0615  λ_max=2.1568\n",
      "[Muon | lr=0.05] Epoch 1821/4000: train_loss=0.0013  test_loss=75.0630  λ_max=2.1135\n",
      "[Muon | lr=0.05] Epoch 1822/4000: train_loss=0.0007  test_loss=75.0753  λ_max=2.2726\n",
      "[Muon | lr=0.05] Epoch 1823/4000: train_loss=0.0013  test_loss=75.1761  λ_max=2.0384\n",
      "[Muon | lr=0.05] Epoch 1824/4000: train_loss=0.0008  test_loss=75.3339  λ_max=2.0433\n",
      "[Muon | lr=0.05] Iter 29200: loss=0.0028\n",
      "[Muon | lr=0.05] Epoch 1825/4000: train_loss=0.0011  test_loss=75.2719  λ_max=2.1680\n",
      "[Muon | lr=0.05] Epoch 1826/4000: train_loss=0.0008  test_loss=75.3722  λ_max=1.9751\n",
      "[Muon | lr=0.05] Epoch 1827/4000: train_loss=0.0011  test_loss=75.4658  λ_max=2.0410\n",
      "[Muon | lr=0.05] Epoch 1828/4000: train_loss=0.0008  test_loss=75.5528  λ_max=2.1083\n",
      "[Muon | lr=0.05] Epoch 1829/4000: train_loss=0.0011  test_loss=75.5620  λ_max=2.0713\n",
      "[Muon | lr=0.05] Epoch 1830/4000: train_loss=0.0008  test_loss=75.5706  λ_max=2.1152\n",
      "[Muon | lr=0.05] Epoch 1831/4000: train_loss=0.0012  test_loss=75.6101  λ_max=2.0218\n",
      "[Muon | lr=0.05] Iter 29300: loss=0.0005\n",
      "[Muon | lr=0.05] Epoch 1832/4000: train_loss=0.0010  test_loss=75.6119  λ_max=2.1288\n",
      "[Muon | lr=0.05] Epoch 1833/4000: train_loss=0.0012  test_loss=75.6736  λ_max=2.1550\n",
      "[Muon | lr=0.05] Epoch 1834/4000: train_loss=0.0008  test_loss=75.8852  λ_max=2.1211\n",
      "[Muon | lr=0.05] Epoch 1835/4000: train_loss=0.0013  test_loss=75.9707  λ_max=2.0942\n",
      "[Muon | lr=0.05] Epoch 1836/4000: train_loss=0.0013  test_loss=75.9525  λ_max=2.0628\n",
      "[Muon | lr=0.05] Epoch 1837/4000: train_loss=0.0011  test_loss=76.0371  λ_max=2.1498\n",
      "[Muon | lr=0.05] Iter 29400: loss=0.0016\n",
      "[Muon | lr=0.05] Epoch 1838/4000: train_loss=0.0010  test_loss=76.0267  λ_max=2.1860\n",
      "[Muon | lr=0.05] Epoch 1839/4000: train_loss=0.0009  test_loss=76.0289  λ_max=2.1765\n",
      "[Muon | lr=0.05] Epoch 1840/4000: train_loss=0.0012  test_loss=76.0315  λ_max=2.2176\n",
      "[Muon | lr=0.05] Epoch 1841/4000: train_loss=0.0011  test_loss=76.1003  λ_max=2.1823\n",
      "[Muon | lr=0.05] Epoch 1842/4000: train_loss=0.0008  test_loss=76.0633  λ_max=2.0777\n",
      "[Muon | lr=0.05] Epoch 1843/4000: train_loss=0.0010  test_loss=76.1117  λ_max=2.3396\n",
      "[Muon | lr=0.05] Iter 29500: loss=0.0005\n",
      "[Muon | lr=0.05] Epoch 1844/4000: train_loss=0.0010  test_loss=76.2359  λ_max=2.1295\n",
      "[Muon | lr=0.05] Epoch 1845/4000: train_loss=0.0012  test_loss=76.2677  λ_max=2.1778\n",
      "[Muon | lr=0.05] Epoch 1846/4000: train_loss=0.0011  test_loss=76.3156  λ_max=2.1786\n",
      "[Muon | lr=0.05] Epoch 1847/4000: train_loss=0.0011  test_loss=76.2896  λ_max=2.1930\n",
      "[Muon | lr=0.05] Epoch 1848/4000: train_loss=0.0011  test_loss=76.2755  λ_max=2.0238\n",
      "[Muon | lr=0.05] Epoch 1849/4000: train_loss=0.0010  test_loss=76.2241  λ_max=2.1359\n",
      "[Muon | lr=0.05] Iter 29600: loss=0.0006\n",
      "[Muon | lr=0.05] Epoch 1850/4000: train_loss=0.0011  test_loss=76.1390  λ_max=1.9675\n",
      "[Muon | lr=0.05] Epoch 1851/4000: train_loss=0.0009  test_loss=76.1160  λ_max=2.0343\n",
      "[Muon | lr=0.05] Epoch 1852/4000: train_loss=0.0016  test_loss=76.1003  λ_max=2.1275\n",
      "[Muon | lr=0.05] Epoch 1853/4000: train_loss=0.0012  test_loss=76.0969  λ_max=2.0402\n",
      "[Muon | lr=0.05] Epoch 1854/4000: train_loss=0.0009  test_loss=76.0378  λ_max=2.0273\n",
      "[Muon | lr=0.05] Epoch 1855/4000: train_loss=0.0011  test_loss=76.0304  λ_max=2.2342\n",
      "[Muon | lr=0.05] Epoch 1856/4000: train_loss=0.0011  test_loss=76.0453  λ_max=2.1051\n",
      "[Muon | lr=0.05] Iter 29700: loss=0.0015\n",
      "[Muon | lr=0.05] Epoch 1857/4000: train_loss=0.0013  test_loss=76.0975  λ_max=2.2609\n",
      "[Muon | lr=0.05] Epoch 1858/4000: train_loss=0.0011  test_loss=76.2199  λ_max=2.1703\n",
      "[Muon | lr=0.05] Epoch 1859/4000: train_loss=0.0009  test_loss=76.1641  λ_max=2.0722\n",
      "[Muon | lr=0.05] Epoch 1860/4000: train_loss=0.0012  test_loss=76.1008  λ_max=2.0562\n",
      "[Muon | lr=0.05] Epoch 1861/4000: train_loss=0.0011  test_loss=76.0946  λ_max=2.1187\n",
      "[Muon | lr=0.05] Epoch 1862/4000: train_loss=0.0012  test_loss=76.1335  λ_max=2.0016\n",
      "[Muon | lr=0.05] Iter 29800: loss=0.0006\n",
      "[Muon | lr=0.05] Epoch 1863/4000: train_loss=0.0010  test_loss=76.2036  λ_max=2.0335\n",
      "[Muon | lr=0.05] Epoch 1864/4000: train_loss=0.0011  test_loss=76.2243  λ_max=2.0584\n",
      "[Muon | lr=0.05] Epoch 1865/4000: train_loss=0.0012  test_loss=76.3100  λ_max=2.1251\n",
      "[Muon | lr=0.05] Epoch 1866/4000: train_loss=0.0009  test_loss=76.3707  λ_max=2.1862\n",
      "[Muon | lr=0.05] Epoch 1867/4000: train_loss=0.0013  test_loss=76.4228  λ_max=2.0802\n",
      "[Muon | lr=0.05] Epoch 1868/4000: train_loss=0.0009  test_loss=76.4981  λ_max=2.2945\n",
      "[Muon | lr=0.05] Iter 29900: loss=0.0033\n",
      "[Muon | lr=0.05] Epoch 1869/4000: train_loss=0.0015  test_loss=76.5702  λ_max=2.2253\n",
      "[Muon | lr=0.05] Epoch 1870/4000: train_loss=0.0010  test_loss=76.4638  λ_max=2.1254\n",
      "[Muon | lr=0.05] Epoch 1871/4000: train_loss=0.0012  test_loss=76.4741  λ_max=2.0741\n",
      "[Muon | lr=0.05] Epoch 1872/4000: train_loss=0.0011  test_loss=76.4428  λ_max=2.1844\n",
      "[Muon | lr=0.05] Epoch 1873/4000: train_loss=0.0012  test_loss=76.3521  λ_max=2.0254\n",
      "[Muon | lr=0.05] Epoch 1874/4000: train_loss=0.0010  test_loss=76.4480  λ_max=2.0072\n",
      "[Muon | lr=0.05] Iter 30000: loss=0.0009\n",
      "[Muon | lr=0.05] Epoch 1875/4000: train_loss=0.0009  test_loss=76.4806  λ_max=2.0998\n",
      "[Muon | lr=0.05] Epoch 1876/4000: train_loss=0.0012  test_loss=76.5502  λ_max=2.0188\n",
      "[Muon | lr=0.05] Epoch 1877/4000: train_loss=0.0008  test_loss=76.5804  λ_max=2.1707\n",
      "[Muon | lr=0.05] Epoch 1878/4000: train_loss=0.0007  test_loss=76.6653  λ_max=2.0919\n",
      "[Muon | lr=0.05] Epoch 1879/4000: train_loss=0.0015  test_loss=76.7726  λ_max=2.0711\n",
      "[Muon | lr=0.05] Epoch 1880/4000: train_loss=0.0013  test_loss=76.7573  λ_max=2.0863\n",
      "[Muon | lr=0.05] Epoch 1881/4000: train_loss=0.0009  test_loss=76.8065  λ_max=2.0130\n",
      "[Muon | lr=0.05] Iter 30100: loss=0.0000\n",
      "[Muon | lr=0.05] Epoch 1882/4000: train_loss=0.0011  test_loss=76.8283  λ_max=2.0515\n",
      "[Muon | lr=0.05] Epoch 1883/4000: train_loss=0.0011  test_loss=76.8511  λ_max=2.1866\n",
      "[Muon | lr=0.05] Epoch 1884/4000: train_loss=0.0008  test_loss=76.9027  λ_max=2.1788\n",
      "[Muon | lr=0.05] Epoch 1885/4000: train_loss=0.0013  test_loss=76.9744  λ_max=2.1497\n",
      "[Muon | lr=0.05] Epoch 1886/4000: train_loss=0.0010  test_loss=76.9322  λ_max=2.0409\n",
      "[Muon | lr=0.05] Epoch 1887/4000: train_loss=0.0009  test_loss=76.9872  λ_max=2.0931\n",
      "[Muon | lr=0.05] Iter 30200: loss=0.0014\n",
      "[Muon | lr=0.05] Epoch 1888/4000: train_loss=0.0009  test_loss=77.0882  λ_max=2.3634\n",
      "[Muon | lr=0.05] Epoch 1889/4000: train_loss=0.0011  test_loss=77.0771  λ_max=2.1256\n",
      "[Muon | lr=0.05] Epoch 1890/4000: train_loss=0.0014  test_loss=77.0316  λ_max=2.0473\n",
      "[Muon | lr=0.05] Epoch 1891/4000: train_loss=0.0013  test_loss=77.0099  λ_max=2.1211\n",
      "[Muon | lr=0.05] Epoch 1892/4000: train_loss=0.0013  test_loss=76.9654  λ_max=2.0151\n",
      "[Muon | lr=0.05] Epoch 1893/4000: train_loss=0.0011  test_loss=76.9170  λ_max=1.9670\n",
      "[Muon | lr=0.05] Iter 30300: loss=0.0018\n",
      "[Muon | lr=0.05] Epoch 1894/4000: train_loss=0.0011  test_loss=76.8991  λ_max=2.1113\n",
      "[Muon | lr=0.05] Epoch 1895/4000: train_loss=0.0015  test_loss=76.9867  λ_max=2.1145\n",
      "[Muon | lr=0.05] Epoch 1896/4000: train_loss=0.0012  test_loss=76.9882  λ_max=1.9744\n",
      "[Muon | lr=0.05] Epoch 1897/4000: train_loss=0.0013  test_loss=77.0561  λ_max=2.2315\n",
      "[Muon | lr=0.05] Epoch 1898/4000: train_loss=0.0011  test_loss=77.1367  λ_max=2.1115\n",
      "[Muon | lr=0.05] Epoch 1899/4000: train_loss=0.0008  test_loss=77.1180  λ_max=2.3795\n",
      "[Muon | lr=0.05] Iter 30400: loss=0.0061\n",
      "[Muon | lr=0.05] Epoch 1900/4000: train_loss=0.0013  test_loss=77.1677  λ_max=2.1406\n",
      "[Muon | lr=0.05] Epoch 1901/4000: train_loss=0.0012  test_loss=77.1774  λ_max=2.1576\n",
      "[Muon | lr=0.05] Epoch 1902/4000: train_loss=0.0011  test_loss=77.1440  λ_max=2.2400\n",
      "[Muon | lr=0.05] Epoch 1903/4000: train_loss=0.0011  test_loss=77.1409  λ_max=2.0192\n",
      "[Muon | lr=0.05] Epoch 1904/4000: train_loss=0.0009  test_loss=77.1451  λ_max=2.0802\n",
      "[Muon | lr=0.05] Epoch 1905/4000: train_loss=0.0011  test_loss=77.1712  λ_max=2.1183\n",
      "[Muon | lr=0.05] Epoch 1906/4000: train_loss=0.0009  test_loss=77.2254  λ_max=2.2071\n",
      "[Muon | lr=0.05] Iter 30500: loss=0.0001\n",
      "[Muon | lr=0.05] Epoch 1907/4000: train_loss=0.0010  test_loss=77.2782  λ_max=2.1126\n",
      "[Muon | lr=0.05] Epoch 1908/4000: train_loss=0.0009  test_loss=77.3097  λ_max=2.1908\n",
      "[Muon | lr=0.05] Epoch 1909/4000: train_loss=0.0014  test_loss=77.3848  λ_max=2.0545\n",
      "[Muon | lr=0.05] Epoch 1910/4000: train_loss=0.0013  test_loss=77.4411  λ_max=2.3175\n",
      "[Muon | lr=0.05] Epoch 1911/4000: train_loss=0.0013  test_loss=77.4691  λ_max=2.0593\n",
      "[Muon | lr=0.05] Epoch 1912/4000: train_loss=0.0010  test_loss=77.4611  λ_max=2.0135\n",
      "[Muon | lr=0.05] Iter 30600: loss=0.0004\n",
      "[Muon | lr=0.05] Epoch 1913/4000: train_loss=0.0010  test_loss=77.4987  λ_max=2.2100\n",
      "[Muon | lr=0.05] Epoch 1914/4000: train_loss=0.0008  test_loss=77.5594  λ_max=2.1013\n",
      "[Muon | lr=0.05] Epoch 1915/4000: train_loss=0.0010  test_loss=77.5864  λ_max=2.1538\n",
      "[Muon | lr=0.05] Epoch 1916/4000: train_loss=0.0012  test_loss=77.6047  λ_max=2.1157\n",
      "[Muon | lr=0.05] Epoch 1917/4000: train_loss=0.0012  test_loss=77.6712  λ_max=2.1387\n",
      "[Muon | lr=0.05] Epoch 1918/4000: train_loss=0.0010  test_loss=77.7666  λ_max=2.0406\n",
      "[Muon | lr=0.05] Iter 30700: loss=0.0007\n",
      "[Muon | lr=0.05] Epoch 1919/4000: train_loss=0.0008  test_loss=77.7666  λ_max=2.1095\n",
      "[Muon | lr=0.05] Epoch 1920/4000: train_loss=0.0012  test_loss=77.7953  λ_max=2.0226\n",
      "[Muon | lr=0.05] Epoch 1921/4000: train_loss=0.0010  test_loss=77.8329  λ_max=2.1203\n",
      "[Muon | lr=0.05] Epoch 1922/4000: train_loss=0.0008  test_loss=77.8260  λ_max=2.1633\n",
      "[Muon | lr=0.05] Epoch 1923/4000: train_loss=0.0010  test_loss=77.8141  λ_max=2.0511\n",
      "[Muon | lr=0.05] Epoch 1924/4000: train_loss=0.0009  test_loss=77.8582  λ_max=1.9650\n",
      "[Muon | lr=0.05] Iter 30800: loss=0.0002\n",
      "[Muon | lr=0.05] Epoch 1925/4000: train_loss=0.0008  test_loss=77.8952  λ_max=2.0609\n",
      "[Muon | lr=0.05] Epoch 1926/4000: train_loss=0.0009  test_loss=77.8940  λ_max=2.1568\n",
      "[Muon | lr=0.05] Epoch 1927/4000: train_loss=0.0010  test_loss=77.9504  λ_max=2.1136\n",
      "[Muon | lr=0.05] Epoch 1928/4000: train_loss=0.0012  test_loss=78.0475  λ_max=2.2020\n",
      "[Muon | lr=0.05] Epoch 1929/4000: train_loss=0.0011  test_loss=78.0915  λ_max=2.1419\n",
      "[Muon | lr=0.05] Epoch 1930/4000: train_loss=0.0011  test_loss=78.0410  λ_max=2.2374\n",
      "[Muon | lr=0.05] Epoch 1931/4000: train_loss=0.0010  test_loss=77.9807  λ_max=2.1528\n",
      "[Muon | lr=0.05] Iter 30900: loss=0.0000\n",
      "[Muon | lr=0.05] Epoch 1932/4000: train_loss=0.0008  test_loss=78.0501  λ_max=2.2274\n",
      "[Muon | lr=0.05] Epoch 1933/4000: train_loss=0.0008  test_loss=78.0967  λ_max=1.9284\n",
      "[Muon | lr=0.05] Epoch 1934/4000: train_loss=0.0010  test_loss=78.0253  λ_max=2.0942\n",
      "[Muon | lr=0.05] Epoch 1935/4000: train_loss=0.0010  test_loss=78.0062  λ_max=2.1348\n",
      "[Muon | lr=0.05] Epoch 1936/4000: train_loss=0.0009  test_loss=78.1032  λ_max=2.1445\n",
      "[Muon | lr=0.05] Epoch 1937/4000: train_loss=0.0013  test_loss=78.1583  λ_max=2.0995\n",
      "[Muon | lr=0.05] Iter 31000: loss=0.0010\n",
      "[Muon | lr=0.05] Epoch 1938/4000: train_loss=0.0009  test_loss=78.2102  λ_max=2.0244\n",
      "[Muon | lr=0.05] Epoch 1939/4000: train_loss=0.0011  test_loss=78.1687  λ_max=2.1623\n",
      "[Muon | lr=0.05] Epoch 1940/4000: train_loss=0.0007  test_loss=78.1534  λ_max=2.1150\n",
      "[Muon | lr=0.05] Epoch 1941/4000: train_loss=0.0012  test_loss=78.1889  λ_max=2.0706\n",
      "[Muon | lr=0.05] Epoch 1942/4000: train_loss=0.0009  test_loss=78.2237  λ_max=2.1308\n",
      "[Muon | lr=0.05] Epoch 1943/4000: train_loss=0.0008  test_loss=78.2348  λ_max=2.2900\n",
      "[Muon | lr=0.05] Iter 31100: loss=0.0022\n",
      "[Muon | lr=0.05] Epoch 1944/4000: train_loss=0.0011  test_loss=78.2561  λ_max=2.2565\n",
      "[Muon | lr=0.05] Epoch 1945/4000: train_loss=0.0011  test_loss=78.2160  λ_max=2.1176\n",
      "[Muon | lr=0.05] Epoch 1946/4000: train_loss=0.0008  test_loss=78.1328  λ_max=2.1214\n",
      "[Muon | lr=0.05] Epoch 1947/4000: train_loss=0.0010  test_loss=78.1136  λ_max=2.2677\n",
      "[Muon | lr=0.05] Epoch 1948/4000: train_loss=0.0010  test_loss=78.1352  λ_max=2.3183\n",
      "[Muon | lr=0.05] Epoch 1949/4000: train_loss=0.0009  test_loss=78.1627  λ_max=2.2665\n",
      "[Muon | lr=0.05] Iter 31200: loss=0.0023\n",
      "[Muon | lr=0.05] Epoch 1950/4000: train_loss=0.0010  test_loss=78.1776  λ_max=2.3185\n",
      "[Muon | lr=0.05] Epoch 1951/4000: train_loss=0.0010  test_loss=78.1734  λ_max=2.2729\n",
      "[Muon | lr=0.05] Epoch 1952/4000: train_loss=0.0010  test_loss=78.0739  λ_max=2.2884\n",
      "[Muon | lr=0.05] Epoch 1953/4000: train_loss=0.0011  test_loss=78.0601  λ_max=2.3161\n",
      "[Muon | lr=0.05] Epoch 1954/4000: train_loss=0.0012  test_loss=78.0544  λ_max=2.1614\n",
      "[Muon | lr=0.05] Epoch 1955/4000: train_loss=0.0008  test_loss=78.0886  λ_max=2.2359\n",
      "[Muon | lr=0.05] Epoch 1956/4000: train_loss=0.0010  test_loss=78.1270  λ_max=2.2228\n",
      "[Muon | lr=0.05] Iter 31300: loss=0.0001\n",
      "[Muon | lr=0.05] Epoch 1957/4000: train_loss=0.0008  test_loss=78.1628  λ_max=2.2444\n",
      "[Muon | lr=0.05] Epoch 1958/4000: train_loss=0.0009  test_loss=78.1826  λ_max=2.2044\n",
      "[Muon | lr=0.05] Epoch 1959/4000: train_loss=0.0011  test_loss=78.2189  λ_max=2.0830\n",
      "[Muon | lr=0.05] Epoch 1960/4000: train_loss=0.0011  test_loss=78.2972  λ_max=2.1452\n",
      "[Muon | lr=0.05] Epoch 1961/4000: train_loss=0.0013  test_loss=78.3527  λ_max=2.1794\n",
      "[Muon | lr=0.05] Epoch 1962/4000: train_loss=0.0011  test_loss=78.3918  λ_max=2.1622\n",
      "[Muon | lr=0.05] Iter 31400: loss=0.0007\n",
      "[Muon | lr=0.05] Epoch 1963/4000: train_loss=0.0008  test_loss=78.5523  λ_max=2.2249\n",
      "[Muon | lr=0.05] Epoch 1964/4000: train_loss=0.0009  test_loss=78.6100  λ_max=2.0706\n",
      "[Muon | lr=0.05] Epoch 1965/4000: train_loss=0.0011  test_loss=78.6558  λ_max=2.1055\n",
      "[Muon | lr=0.05] Epoch 1966/4000: train_loss=0.0011  test_loss=78.7001  λ_max=2.2163\n",
      "[Muon | lr=0.05] Epoch 1967/4000: train_loss=0.0008  test_loss=78.7036  λ_max=2.0608\n",
      "[Muon | lr=0.05] Epoch 1968/4000: train_loss=0.0008  test_loss=78.6989  λ_max=2.0791\n",
      "[Muon | lr=0.05] Iter 31500: loss=0.0012\n",
      "[Muon | lr=0.05] Epoch 1969/4000: train_loss=0.0010  test_loss=78.6585  λ_max=2.0999\n",
      "[Muon | lr=0.05] Epoch 1970/4000: train_loss=0.0012  test_loss=78.6741  λ_max=2.2100\n",
      "[Muon | lr=0.05] Epoch 1971/4000: train_loss=0.0012  test_loss=78.7059  λ_max=2.1957\n",
      "[Muon | lr=0.05] Epoch 1972/4000: train_loss=0.0010  test_loss=78.7175  λ_max=2.2547\n",
      "[Muon | lr=0.05] Epoch 1973/4000: train_loss=0.0010  test_loss=78.6254  λ_max=2.2729\n",
      "[Muon | lr=0.05] Epoch 1974/4000: train_loss=0.0008  test_loss=78.6206  λ_max=2.2165\n",
      "[Muon | lr=0.05] Iter 31600: loss=0.0002\n",
      "[Muon | lr=0.05] Epoch 1975/4000: train_loss=0.0009  test_loss=78.6141  λ_max=2.0723\n",
      "[Muon | lr=0.05] Epoch 1976/4000: train_loss=0.0010  test_loss=78.5835  λ_max=2.3568\n",
      "[Muon | lr=0.05] Epoch 1977/4000: train_loss=0.0012  test_loss=78.6009  λ_max=2.2509\n",
      "[Muon | lr=0.05] Epoch 1978/4000: train_loss=0.0009  test_loss=78.6651  λ_max=2.1283\n",
      "[Muon | lr=0.05] Epoch 1979/4000: train_loss=0.0009  test_loss=78.6843  λ_max=2.0754\n",
      "[Muon | lr=0.05] Epoch 1980/4000: train_loss=0.0010  test_loss=78.7020  λ_max=2.1979\n",
      "[Muon | lr=0.05] Epoch 1981/4000: train_loss=0.0011  test_loss=78.7527  λ_max=2.1558\n",
      "[Muon | lr=0.05] Iter 31700: loss=0.0004\n",
      "[Muon | lr=0.05] Epoch 1982/4000: train_loss=0.0011  test_loss=78.7690  λ_max=2.3245\n",
      "[Muon | lr=0.05] Epoch 1983/4000: train_loss=0.0011  test_loss=78.8159  λ_max=2.1736\n",
      "[Muon | lr=0.05] Epoch 1984/4000: train_loss=0.0008  test_loss=78.8729  λ_max=2.1105\n",
      "[Muon | lr=0.05] Epoch 1985/4000: train_loss=0.0008  test_loss=78.9805  λ_max=2.0709\n",
      "[Muon | lr=0.05] Epoch 1986/4000: train_loss=0.0012  test_loss=79.0282  λ_max=2.2999\n",
      "[Muon | lr=0.05] Epoch 1987/4000: train_loss=0.0010  test_loss=79.0837  λ_max=2.1738\n",
      "[Muon | lr=0.05] Iter 31800: loss=0.0008\n",
      "[Muon | lr=0.05] Epoch 1988/4000: train_loss=0.0011  test_loss=79.1227  λ_max=2.2329\n",
      "[Muon | lr=0.05] Epoch 1989/4000: train_loss=0.0007  test_loss=79.2255  λ_max=2.2100\n",
      "[Muon | lr=0.05] Epoch 1990/4000: train_loss=0.0011  test_loss=79.3253  λ_max=2.3494\n",
      "[Muon | lr=0.05] Epoch 1991/4000: train_loss=0.0009  test_loss=79.3486  λ_max=2.1632\n",
      "[Muon | lr=0.05] Epoch 1992/4000: train_loss=0.0011  test_loss=79.3901  λ_max=2.2352\n",
      "[Muon | lr=0.05] Epoch 1993/4000: train_loss=0.0009  test_loss=79.3138  λ_max=2.1613\n",
      "[Muon | lr=0.05] Iter 31900: loss=0.0004\n",
      "[Muon | lr=0.05] Epoch 1994/4000: train_loss=0.0008  test_loss=79.3195  λ_max=2.3541\n",
      "[Muon | lr=0.05] Epoch 1995/4000: train_loss=0.0009  test_loss=79.2376  λ_max=2.2506\n",
      "[Muon | lr=0.05] Epoch 1996/4000: train_loss=0.0008  test_loss=79.2376  λ_max=2.0861\n",
      "[Muon | lr=0.05] Epoch 1997/4000: train_loss=0.0014  test_loss=79.2617  λ_max=2.0792\n",
      "[Muon | lr=0.05] Epoch 1998/4000: train_loss=0.0009  test_loss=79.2497  λ_max=1.9208\n",
      "[Muon | lr=0.05] Epoch 1999/4000: train_loss=0.0010  test_loss=79.2689  λ_max=2.0082\n",
      "[Muon | lr=0.05] Iter 32000: loss=0.0029\n",
      "[Muon | lr=0.05] Epoch 2000/4000: train_loss=0.0011  test_loss=79.2187  λ_max=2.1914\n",
      "[Muon | lr=0.05] Epoch 2001/4000: train_loss=0.0009  test_loss=79.2969  λ_max=2.0767\n",
      "[Muon | lr=0.05] Epoch 2002/4000: train_loss=0.0013  test_loss=79.3262  λ_max=2.3189\n",
      "[Muon | lr=0.05] Epoch 2003/4000: train_loss=0.0011  test_loss=79.3700  λ_max=2.0719\n",
      "[Muon | lr=0.05] Epoch 2004/4000: train_loss=0.0009  test_loss=79.4007  λ_max=2.1518\n",
      "[Muon | lr=0.05] Epoch 2005/4000: train_loss=0.0011  test_loss=79.3925  λ_max=2.2819\n",
      "[Muon | lr=0.05] Epoch 2006/4000: train_loss=0.0009  test_loss=79.4427  λ_max=2.2351\n",
      "[Muon | lr=0.05] Iter 32100: loss=0.0003\n",
      "[Muon | lr=0.05] Epoch 2007/4000: train_loss=0.0014  test_loss=79.4352  λ_max=2.0822\n",
      "[Muon | lr=0.05] Epoch 2008/4000: train_loss=0.0013  test_loss=79.5131  λ_max=2.1315\n",
      "[Muon | lr=0.05] Epoch 2009/4000: train_loss=0.0012  test_loss=79.4663  λ_max=2.3044\n",
      "[Muon | lr=0.05] Epoch 2010/4000: train_loss=0.0011  test_loss=79.4363  λ_max=2.0921\n",
      "[Muon | lr=0.05] Epoch 2011/4000: train_loss=0.0009  test_loss=79.4412  λ_max=2.2398\n",
      "[Muon | lr=0.05] Epoch 2012/4000: train_loss=0.0012  test_loss=79.5441  λ_max=2.1706\n",
      "[Muon | lr=0.05] Iter 32200: loss=0.0005\n",
      "[Muon | lr=0.05] Epoch 2013/4000: train_loss=0.0011  test_loss=79.6872  λ_max=2.1389\n",
      "[Muon | lr=0.05] Epoch 2014/4000: train_loss=0.0011  test_loss=79.7188  λ_max=2.1301\n",
      "[Muon | lr=0.05] Epoch 2015/4000: train_loss=0.0009  test_loss=79.7765  λ_max=2.3831\n",
      "[Muon | lr=0.05] Epoch 2016/4000: train_loss=0.0010  test_loss=79.8358  λ_max=2.1050\n",
      "[Muon | lr=0.05] Epoch 2017/4000: train_loss=0.0009  test_loss=79.8116  λ_max=2.2903\n",
      "[Muon | lr=0.05] Epoch 2018/4000: train_loss=0.0009  test_loss=79.9132  λ_max=2.1640\n",
      "[Muon | lr=0.05] Iter 32300: loss=0.0028\n",
      "[Muon | lr=0.05] Epoch 2019/4000: train_loss=0.0012  test_loss=80.0235  λ_max=2.0317\n",
      "[Muon | lr=0.05] Epoch 2020/4000: train_loss=0.0010  test_loss=80.1170  λ_max=2.1062\n",
      "[Muon | lr=0.05] Epoch 2021/4000: train_loss=0.0009  test_loss=80.2331  λ_max=2.1557\n",
      "[Muon | lr=0.05] Epoch 2022/4000: train_loss=0.0010  test_loss=80.2528  λ_max=2.2949\n",
      "[Muon | lr=0.05] Epoch 2023/4000: train_loss=0.0009  test_loss=80.2505  λ_max=2.2040\n",
      "[Muon | lr=0.05] Epoch 2024/4000: train_loss=0.0010  test_loss=80.3415  λ_max=2.1353\n",
      "[Muon | lr=0.05] Iter 32400: loss=0.0009\n",
      "[Muon | lr=0.05] Epoch 2025/4000: train_loss=0.0010  test_loss=80.4639  λ_max=2.1244\n",
      "[Muon | lr=0.05] Epoch 2026/4000: train_loss=0.0009  test_loss=80.4748  λ_max=2.2918\n",
      "[Muon | lr=0.05] Epoch 2027/4000: train_loss=0.0009  test_loss=80.5168  λ_max=2.1593\n",
      "[Muon | lr=0.05] Epoch 2028/4000: train_loss=0.0009  test_loss=80.5022  λ_max=2.4252\n",
      "[Muon | lr=0.05] Epoch 2029/4000: train_loss=0.0012  test_loss=80.5083  λ_max=2.0283\n",
      "[Muon | lr=0.05] Epoch 2030/4000: train_loss=0.0009  test_loss=80.5159  λ_max=2.3287\n",
      "[Muon | lr=0.05] Epoch 2031/4000: train_loss=0.0009  test_loss=80.5012  λ_max=2.2891\n",
      "[Muon | lr=0.05] Iter 32500: loss=0.0000\n",
      "[Muon | lr=0.05] Epoch 2032/4000: train_loss=0.0008  test_loss=80.5216  λ_max=2.1815\n",
      "[Muon | lr=0.05] Epoch 2033/4000: train_loss=0.0006  test_loss=80.5534  λ_max=2.3346\n",
      "[Muon | lr=0.05] Epoch 2034/4000: train_loss=0.0010  test_loss=80.5624  λ_max=2.0881\n",
      "[Muon | lr=0.05] Epoch 2035/4000: train_loss=0.0010  test_loss=80.6279  λ_max=2.1299\n",
      "[Muon | lr=0.05] Epoch 2036/4000: train_loss=0.0006  test_loss=80.7088  λ_max=2.1124\n",
      "[Muon | lr=0.05] Epoch 2037/4000: train_loss=0.0011  test_loss=80.6723  λ_max=2.0374\n",
      "[Muon | lr=0.05] Iter 32600: loss=0.0014\n",
      "[Muon | lr=0.05] Epoch 2038/4000: train_loss=0.0010  test_loss=80.6315  λ_max=2.1924\n",
      "[Muon | lr=0.05] Epoch 2039/4000: train_loss=0.0010  test_loss=80.6190  λ_max=2.2248\n",
      "[Muon | lr=0.05] Epoch 2040/4000: train_loss=0.0011  test_loss=80.6730  λ_max=2.1945\n",
      "[Muon | lr=0.05] Epoch 2041/4000: train_loss=0.0012  test_loss=80.5757  λ_max=2.2875\n",
      "[Muon | lr=0.05] Epoch 2042/4000: train_loss=0.0008  test_loss=80.5626  λ_max=2.1454\n",
      "[Muon | lr=0.05] Epoch 2043/4000: train_loss=0.0009  test_loss=80.6258  λ_max=2.1256\n",
      "[Muon | lr=0.05] Iter 32700: loss=0.0026\n",
      "[Muon | lr=0.05] Epoch 2044/4000: train_loss=0.0012  test_loss=80.6631  λ_max=2.0864\n",
      "[Muon | lr=0.05] Epoch 2045/4000: train_loss=0.0010  test_loss=80.6531  λ_max=2.3305\n",
      "[Muon | lr=0.05] Epoch 2046/4000: train_loss=0.0009  test_loss=80.6713  λ_max=2.2021\n",
      "[Muon | lr=0.05] Epoch 2047/4000: train_loss=0.0010  test_loss=80.7356  λ_max=2.1865\n",
      "[Muon | lr=0.05] Epoch 2048/4000: train_loss=0.0007  test_loss=80.7706  λ_max=2.3811\n",
      "[Muon | lr=0.05] Epoch 2049/4000: train_loss=0.0011  test_loss=80.7481  λ_max=2.2681\n",
      "[Muon | lr=0.05] Iter 32800: loss=0.0036\n",
      "[Muon | lr=0.05] Epoch 2050/4000: train_loss=0.0012  test_loss=80.8135  λ_max=2.1758\n",
      "[Muon | lr=0.05] Epoch 2051/4000: train_loss=0.0012  test_loss=80.8475  λ_max=2.1137\n",
      "[Muon | lr=0.05] Epoch 2052/4000: train_loss=0.0008  test_loss=80.8357  λ_max=2.1679\n",
      "[Muon | lr=0.05] Epoch 2053/4000: train_loss=0.0009  test_loss=80.7630  λ_max=2.2471\n",
      "[Muon | lr=0.05] Epoch 2054/4000: train_loss=0.0008  test_loss=80.8003  λ_max=2.1395\n",
      "[Muon | lr=0.05] Epoch 2055/4000: train_loss=0.0009  test_loss=80.6878  λ_max=2.2175\n",
      "[Muon | lr=0.05] Epoch 2056/4000: train_loss=0.0011  test_loss=80.7281  λ_max=2.1323\n",
      "[Muon | lr=0.05] Iter 32900: loss=0.0005\n",
      "[Muon | lr=0.05] Epoch 2057/4000: train_loss=0.0010  test_loss=80.8078  λ_max=2.3435\n",
      "[Muon | lr=0.05] Epoch 2058/4000: train_loss=0.0010  test_loss=80.7611  λ_max=2.1936\n",
      "[Muon | lr=0.05] Epoch 2059/4000: train_loss=0.0008  test_loss=80.8296  λ_max=2.1794\n",
      "[Muon | lr=0.05] Epoch 2060/4000: train_loss=0.0011  test_loss=80.8444  λ_max=2.1468\n",
      "[Muon | lr=0.05] Epoch 2061/4000: train_loss=0.0007  test_loss=80.9200  λ_max=2.3202\n",
      "[Muon | lr=0.05] Epoch 2062/4000: train_loss=0.0010  test_loss=81.0069  λ_max=2.0856\n",
      "[Muon | lr=0.05] Iter 33000: loss=0.0008\n",
      "[Muon | lr=0.05] Epoch 2063/4000: train_loss=0.0008  test_loss=81.0313  λ_max=2.0557\n",
      "[Muon | lr=0.05] Epoch 2064/4000: train_loss=0.0009  test_loss=81.0504  λ_max=2.3705\n",
      "[Muon | lr=0.05] Epoch 2065/4000: train_loss=0.0008  test_loss=81.0855  λ_max=2.2485\n",
      "[Muon | lr=0.05] Epoch 2066/4000: train_loss=0.0008  test_loss=81.0802  λ_max=2.2727\n",
      "[Muon | lr=0.05] Epoch 2067/4000: train_loss=0.0010  test_loss=81.0874  λ_max=2.2200\n",
      "[Muon | lr=0.05] Epoch 2068/4000: train_loss=0.0010  test_loss=81.2694  λ_max=2.1776\n",
      "[Muon | lr=0.05] Iter 33100: loss=0.0011\n",
      "[Muon | lr=0.05] Epoch 2069/4000: train_loss=0.0008  test_loss=81.3299  λ_max=2.2038\n",
      "[Muon | lr=0.05] Epoch 2070/4000: train_loss=0.0009  test_loss=81.2880  λ_max=2.1888\n",
      "[Muon | lr=0.05] Epoch 2071/4000: train_loss=0.0008  test_loss=81.2876  λ_max=2.1907\n",
      "[Muon | lr=0.05] Epoch 2072/4000: train_loss=0.0009  test_loss=81.2927  λ_max=2.2223\n",
      "[Muon | lr=0.05] Epoch 2073/4000: train_loss=0.0009  test_loss=81.2455  λ_max=2.1700\n",
      "[Muon | lr=0.05] Epoch 2074/4000: train_loss=0.0009  test_loss=81.2316  λ_max=2.1912\n",
      "[Muon | lr=0.05] Iter 33200: loss=0.0034\n",
      "[Muon | lr=0.05] Epoch 2075/4000: train_loss=0.0011  test_loss=81.2859  λ_max=2.2458\n",
      "[Muon | lr=0.05] Epoch 2076/4000: train_loss=0.0012  test_loss=81.2776  λ_max=2.1800\n",
      "[Muon | lr=0.05] Epoch 2077/4000: train_loss=0.0011  test_loss=81.2327  λ_max=2.1717\n",
      "[Muon | lr=0.05] Epoch 2078/4000: train_loss=0.0008  test_loss=81.2289  λ_max=2.3509\n",
      "[Muon | lr=0.05] Epoch 2079/4000: train_loss=0.0009  test_loss=81.2470  λ_max=2.2074\n",
      "[Muon | lr=0.05] Epoch 2080/4000: train_loss=0.0012  test_loss=81.3305  λ_max=2.2029\n",
      "[Muon | lr=0.05] Epoch 2081/4000: train_loss=0.0011  test_loss=81.4912  λ_max=2.1434\n",
      "[Muon | lr=0.05] Iter 33300: loss=0.0006\n",
      "[Muon | lr=0.05] Epoch 2082/4000: train_loss=0.0010  test_loss=81.5513  λ_max=2.1911\n",
      "[Muon | lr=0.05] Epoch 2083/4000: train_loss=0.0010  test_loss=81.6150  λ_max=2.0416\n",
      "[Muon | lr=0.05] Epoch 2084/4000: train_loss=0.0006  test_loss=81.5162  λ_max=2.1840\n",
      "[Muon | lr=0.05] Epoch 2085/4000: train_loss=0.0011  test_loss=81.4524  λ_max=2.1821\n",
      "[Muon | lr=0.05] Epoch 2086/4000: train_loss=0.0010  test_loss=81.4901  λ_max=2.2076\n",
      "[Muon | lr=0.05] Epoch 2087/4000: train_loss=0.0009  test_loss=81.4623  λ_max=2.2723\n",
      "[Muon | lr=0.05] Iter 33400: loss=0.0004\n",
      "[Muon | lr=0.05] Epoch 2088/4000: train_loss=0.0010  test_loss=81.5122  λ_max=2.1170\n",
      "[Muon | lr=0.05] Epoch 2089/4000: train_loss=0.0008  test_loss=81.6606  λ_max=2.1332\n",
      "[Muon | lr=0.05] Epoch 2090/4000: train_loss=0.0010  test_loss=81.6196  λ_max=2.0367\n",
      "[Muon | lr=0.05] Epoch 2091/4000: train_loss=0.0010  test_loss=81.6832  λ_max=2.0075\n",
      "[Muon | lr=0.05] Epoch 2092/4000: train_loss=0.0011  test_loss=81.7860  λ_max=2.2355\n",
      "[Muon | lr=0.05] Epoch 2093/4000: train_loss=0.0011  test_loss=81.8601  λ_max=2.3313\n",
      "[Muon | lr=0.05] Iter 33500: loss=0.0016\n",
      "[Muon | lr=0.05] Epoch 2094/4000: train_loss=0.0010  test_loss=81.8551  λ_max=2.1145\n",
      "[Muon | lr=0.05] Epoch 2095/4000: train_loss=0.0008  test_loss=81.8975  λ_max=2.1668\n",
      "[Muon | lr=0.05] Epoch 2096/4000: train_loss=0.0008  test_loss=81.9339  λ_max=2.2858\n",
      "[Muon | lr=0.05] Epoch 2097/4000: train_loss=0.0010  test_loss=81.9946  λ_max=2.1471\n",
      "[Muon | lr=0.05] Epoch 2098/4000: train_loss=0.0012  test_loss=82.1203  λ_max=2.1438\n",
      "[Muon | lr=0.05] Epoch 2099/4000: train_loss=0.0007  test_loss=82.1240  λ_max=2.2130\n",
      "[Muon | lr=0.05] Iter 33600: loss=0.0003\n",
      "[Muon | lr=0.05] Epoch 2100/4000: train_loss=0.0007  test_loss=82.2155  λ_max=2.2003\n",
      "[Muon | lr=0.05] Epoch 2101/4000: train_loss=0.0011  test_loss=82.3316  λ_max=2.0574\n",
      "[Muon | lr=0.05] Epoch 2102/4000: train_loss=0.0008  test_loss=82.4406  λ_max=2.2274\n",
      "[Muon | lr=0.05] Epoch 2103/4000: train_loss=0.0006  test_loss=82.4892  λ_max=2.2008\n",
      "[Muon | lr=0.05] Epoch 2104/4000: train_loss=0.0006  test_loss=82.4364  λ_max=2.0155\n",
      "[Muon | lr=0.05] Epoch 2105/4000: train_loss=0.0008  test_loss=82.4878  λ_max=2.1056\n",
      "[Muon | lr=0.05] Epoch 2106/4000: train_loss=0.0010  test_loss=82.6125  λ_max=2.2236\n",
      "[Muon | lr=0.05] Iter 33700: loss=0.0000\n",
      "[Muon | lr=0.05] Epoch 2107/4000: train_loss=0.0007  test_loss=82.5790  λ_max=2.1904\n",
      "[Muon | lr=0.05] Epoch 2108/4000: train_loss=0.0012  test_loss=82.6045  λ_max=2.1931\n",
      "[Muon | lr=0.05] Epoch 2109/4000: train_loss=0.0010  test_loss=82.6422  λ_max=2.5481\n",
      "[Muon | lr=0.05] Epoch 2110/4000: train_loss=0.0007  test_loss=82.6122  λ_max=2.0979\n",
      "[Muon | lr=0.05] Epoch 2111/4000: train_loss=0.0008  test_loss=82.6185  λ_max=2.1368\n",
      "[Muon | lr=0.05] Epoch 2112/4000: train_loss=0.0014  test_loss=82.6945  λ_max=2.3051\n",
      "[Muon | lr=0.05] Iter 33800: loss=0.0005\n",
      "[Muon | lr=0.05] Epoch 2113/4000: train_loss=0.0007  test_loss=82.6347  λ_max=2.1551\n",
      "[Muon | lr=0.05] Epoch 2114/4000: train_loss=0.0007  test_loss=82.7152  λ_max=2.1648\n",
      "[Muon | lr=0.05] Epoch 2115/4000: train_loss=0.0010  test_loss=82.6901  λ_max=2.2751\n",
      "[Muon | lr=0.05] Epoch 2116/4000: train_loss=0.0010  test_loss=82.7105  λ_max=2.0409\n",
      "[Muon | lr=0.05] Epoch 2117/4000: train_loss=0.0012  test_loss=82.7102  λ_max=2.1253\n",
      "[Muon | lr=0.05] Epoch 2118/4000: train_loss=0.0007  test_loss=82.6897  λ_max=2.1602\n",
      "[Muon | lr=0.05] Iter 33900: loss=0.0020\n",
      "[Muon | lr=0.05] Epoch 2119/4000: train_loss=0.0010  test_loss=82.6771  λ_max=1.9710\n",
      "[Muon | lr=0.05] Epoch 2120/4000: train_loss=0.0011  test_loss=82.6136  λ_max=2.2475\n",
      "[Muon | lr=0.05] Epoch 2121/4000: train_loss=0.0008  test_loss=82.5133  λ_max=2.1664\n",
      "[Muon | lr=0.05] Epoch 2122/4000: train_loss=0.0006  test_loss=82.4012  λ_max=2.1031\n",
      "[Muon | lr=0.05] Epoch 2123/4000: train_loss=0.0007  test_loss=82.4566  λ_max=2.2244\n",
      "[Muon | lr=0.05] Epoch 2124/4000: train_loss=0.0012  test_loss=82.4822  λ_max=2.2242\n",
      "[Muon | lr=0.05] Iter 34000: loss=0.0021\n",
      "[Muon | lr=0.05] Epoch 2125/4000: train_loss=0.0010  test_loss=82.5371  λ_max=2.2796\n",
      "[Muon | lr=0.05] Epoch 2126/4000: train_loss=0.0009  test_loss=82.7114  λ_max=2.0812\n",
      "[Muon | lr=0.05] Epoch 2127/4000: train_loss=0.0009  test_loss=82.8354  λ_max=2.2735\n",
      "[Muon | lr=0.05] Epoch 2128/4000: train_loss=0.0009  test_loss=82.8507  λ_max=2.3651\n",
      "[Muon | lr=0.05] Epoch 2129/4000: train_loss=0.0010  test_loss=82.8984  λ_max=2.1776\n",
      "[Muon | lr=0.05] Epoch 2130/4000: train_loss=0.0010  test_loss=82.9507  λ_max=2.1605\n",
      "[Muon | lr=0.05] Epoch 2131/4000: train_loss=0.0012  test_loss=82.9943  λ_max=2.2726\n",
      "[Muon | lr=0.05] Iter 34100: loss=0.0002\n",
      "[Muon | lr=0.05] Epoch 2132/4000: train_loss=0.0010  test_loss=83.0399  λ_max=2.1412\n",
      "[Muon | lr=0.05] Epoch 2133/4000: train_loss=0.0008  test_loss=83.0553  λ_max=2.1229\n",
      "[Muon | lr=0.05] Epoch 2134/4000: train_loss=0.0010  test_loss=83.0739  λ_max=2.3134\n",
      "[Muon | lr=0.05] Epoch 2135/4000: train_loss=0.0010  test_loss=83.1898  λ_max=2.3858\n",
      "[Muon | lr=0.05] Epoch 2136/4000: train_loss=0.0012  test_loss=83.2232  λ_max=2.2181\n",
      "[Muon | lr=0.05] Epoch 2137/4000: train_loss=0.0009  test_loss=83.2112  λ_max=2.1951\n",
      "[Muon | lr=0.05] Iter 34200: loss=0.0016\n",
      "[Muon | lr=0.05] Epoch 2138/4000: train_loss=0.0008  test_loss=83.2189  λ_max=2.2994\n",
      "[Muon | lr=0.05] Epoch 2139/4000: train_loss=0.0007  test_loss=83.1846  λ_max=2.2743\n",
      "[Muon | lr=0.05] Epoch 2140/4000: train_loss=0.0009  test_loss=83.2817  λ_max=2.1109\n",
      "[Muon | lr=0.05] Epoch 2141/4000: train_loss=0.0008  test_loss=83.3396  λ_max=2.3528\n",
      "[Muon | lr=0.05] Epoch 2142/4000: train_loss=0.0006  test_loss=83.4769  λ_max=2.1569\n",
      "[Muon | lr=0.05] Epoch 2143/4000: train_loss=0.0011  test_loss=83.5416  λ_max=2.4038\n",
      "[Muon | lr=0.05] Iter 34300: loss=0.0003\n",
      "[Muon | lr=0.05] Epoch 2144/4000: train_loss=0.0011  test_loss=83.5699  λ_max=2.3030\n",
      "[Muon | lr=0.05] Epoch 2145/4000: train_loss=0.0009  test_loss=83.5972  λ_max=2.1793\n",
      "[Muon | lr=0.05] Epoch 2146/4000: train_loss=0.0008  test_loss=83.5705  λ_max=2.1632\n",
      "[Muon | lr=0.05] Epoch 2147/4000: train_loss=0.0008  test_loss=83.5853  λ_max=2.2477\n",
      "[Muon | lr=0.05] Epoch 2148/4000: train_loss=0.0012  test_loss=83.6205  λ_max=2.1991\n",
      "[Muon | lr=0.05] Epoch 2149/4000: train_loss=0.0006  test_loss=83.5994  λ_max=2.1711\n",
      "[Muon | lr=0.05] Iter 34400: loss=0.0033\n",
      "[Muon | lr=0.05] Epoch 2150/4000: train_loss=0.0010  test_loss=83.6991  λ_max=2.0792\n",
      "[Muon | lr=0.05] Epoch 2151/4000: train_loss=0.0007  test_loss=83.7033  λ_max=2.1157\n",
      "[Muon | lr=0.05] Epoch 2152/4000: train_loss=0.0008  test_loss=83.6585  λ_max=2.1349\n",
      "[Muon | lr=0.05] Epoch 2153/4000: train_loss=0.0008  test_loss=83.6960  λ_max=2.0835\n",
      "[Muon | lr=0.05] Epoch 2154/4000: train_loss=0.0008  test_loss=83.7487  λ_max=2.1380\n",
      "[Muon | lr=0.05] Epoch 2155/4000: train_loss=0.0008  test_loss=83.7561  λ_max=2.3200\n",
      "[Muon | lr=0.05] Epoch 2156/4000: train_loss=0.0010  test_loss=83.7521  λ_max=2.2155\n",
      "[Muon | lr=0.05] Iter 34500: loss=0.0007\n",
      "[Muon | lr=0.05] Epoch 2157/4000: train_loss=0.0010  test_loss=83.8545  λ_max=2.1973\n",
      "[Muon | lr=0.05] Epoch 2158/4000: train_loss=0.0008  test_loss=83.8268  λ_max=2.1092\n",
      "[Muon | lr=0.05] Epoch 2159/4000: train_loss=0.0009  test_loss=83.9235  λ_max=2.1548\n",
      "[Muon | lr=0.05] Epoch 2160/4000: train_loss=0.0012  test_loss=84.0511  λ_max=2.2663\n",
      "[Muon | lr=0.05] Epoch 2161/4000: train_loss=0.0007  test_loss=84.1571  λ_max=2.1958\n",
      "[Muon | lr=0.05] Epoch 2162/4000: train_loss=0.0007  test_loss=84.2285  λ_max=2.2702\n",
      "[Muon | lr=0.05] Iter 34600: loss=0.0012\n",
      "[Muon | lr=0.05] Epoch 2163/4000: train_loss=0.0010  test_loss=84.2443  λ_max=2.2569\n",
      "[Muon | lr=0.05] Epoch 2164/4000: train_loss=0.0012  test_loss=84.3589  λ_max=2.0542\n",
      "[Muon | lr=0.05] Epoch 2165/4000: train_loss=0.0012  test_loss=84.4291  λ_max=2.2787\n",
      "[Muon | lr=0.05] Epoch 2166/4000: train_loss=0.0008  test_loss=84.3546  λ_max=2.0711\n",
      "[Muon | lr=0.05] Epoch 2167/4000: train_loss=0.0010  test_loss=84.3892  λ_max=2.1759\n",
      "[Muon | lr=0.05] Epoch 2168/4000: train_loss=0.0011  test_loss=84.4036  λ_max=2.3163\n",
      "[Muon | lr=0.05] Iter 34700: loss=0.0015\n",
      "[Muon | lr=0.05] Epoch 2169/4000: train_loss=0.0008  test_loss=84.3251  λ_max=2.2750\n",
      "[Muon | lr=0.05] Epoch 2170/4000: train_loss=0.0012  test_loss=84.2977  λ_max=2.2866\n",
      "[Muon | lr=0.05] Epoch 2171/4000: train_loss=0.0007  test_loss=84.3579  λ_max=2.2076\n",
      "[Muon | lr=0.05] Epoch 2172/4000: train_loss=0.0009  test_loss=84.4324  λ_max=1.9892\n",
      "[Muon | lr=0.05] Epoch 2173/4000: train_loss=0.0011  test_loss=84.4287  λ_max=2.2798\n",
      "[Muon | lr=0.05] Epoch 2174/4000: train_loss=0.0008  test_loss=84.4213  λ_max=2.4071\n",
      "[Muon | lr=0.05] Iter 34800: loss=0.0007\n",
      "[Muon | lr=0.05] Epoch 2175/4000: train_loss=0.0009  test_loss=84.4668  λ_max=2.1509\n",
      "[Muon | lr=0.05] Epoch 2176/4000: train_loss=0.0010  test_loss=84.5055  λ_max=2.1869\n",
      "[Muon | lr=0.05] Epoch 2177/4000: train_loss=0.0010  test_loss=84.5642  λ_max=2.1972\n",
      "[Muon | lr=0.05] Epoch 2178/4000: train_loss=0.0008  test_loss=84.5533  λ_max=2.3013\n",
      "[Muon | lr=0.05] Epoch 2179/4000: train_loss=0.0008  test_loss=84.5561  λ_max=2.1143\n",
      "[Muon | lr=0.05] Epoch 2180/4000: train_loss=0.0010  test_loss=84.5140  λ_max=2.2410\n",
      "[Muon | lr=0.05] Epoch 2181/4000: train_loss=0.0011  test_loss=84.5230  λ_max=2.4150\n",
      "[Muon | lr=0.05] Iter 34900: loss=0.0002\n",
      "[Muon | lr=0.05] Epoch 2182/4000: train_loss=0.0010  test_loss=84.4951  λ_max=2.2661\n",
      "[Muon | lr=0.05] Epoch 2183/4000: train_loss=0.0008  test_loss=84.5454  λ_max=2.2757\n",
      "[Muon | lr=0.05] Epoch 2184/4000: train_loss=0.0011  test_loss=84.6398  λ_max=2.3081\n",
      "[Muon | lr=0.05] Epoch 2185/4000: train_loss=0.0009  test_loss=84.5679  λ_max=2.0407\n",
      "[Muon | lr=0.05] Epoch 2186/4000: train_loss=0.0010  test_loss=84.5177  λ_max=2.2714\n",
      "[Muon | lr=0.05] Epoch 2187/4000: train_loss=0.0009  test_loss=84.5316  λ_max=2.2303\n",
      "[Muon | lr=0.05] Iter 35000: loss=0.0003\n",
      "[Muon | lr=0.05] Epoch 2188/4000: train_loss=0.0009  test_loss=84.3746  λ_max=2.1818\n",
      "[Muon | lr=0.05] Epoch 2189/4000: train_loss=0.0008  test_loss=84.2783  λ_max=2.2028\n",
      "[Muon | lr=0.05] Epoch 2190/4000: train_loss=0.0008  test_loss=84.2243  λ_max=2.0361\n",
      "[Muon | lr=0.05] Epoch 2191/4000: train_loss=0.0008  test_loss=84.2683  λ_max=2.1371\n",
      "[Muon | lr=0.05] Epoch 2192/4000: train_loss=0.0009  test_loss=84.3252  λ_max=2.2547\n",
      "[Muon | lr=0.05] Epoch 2193/4000: train_loss=0.0011  test_loss=84.4207  λ_max=2.2752\n",
      "[Muon | lr=0.05] Iter 35100: loss=0.0027\n",
      "[Muon | lr=0.05] Epoch 2194/4000: train_loss=0.0012  test_loss=84.4552  λ_max=2.2612\n",
      "[Muon | lr=0.05] Epoch 2195/4000: train_loss=0.0009  test_loss=84.4477  λ_max=2.2962\n",
      "[Muon | lr=0.05] Epoch 2196/4000: train_loss=0.0008  test_loss=84.4125  λ_max=2.2576\n",
      "[Muon | lr=0.05] Epoch 2197/4000: train_loss=0.0010  test_loss=84.4745  λ_max=2.3260\n",
      "[Muon | lr=0.05] Epoch 2198/4000: train_loss=0.0010  test_loss=84.5139  λ_max=2.2313\n",
      "[Muon | lr=0.05] Epoch 2199/4000: train_loss=0.0011  test_loss=84.4712  λ_max=2.2454\n",
      "[Muon | lr=0.05] Iter 35200: loss=0.0029\n",
      "[Muon | lr=0.05] Epoch 2200/4000: train_loss=0.0008  test_loss=84.6183  λ_max=2.3421\n",
      "[Muon | lr=0.05] Epoch 2201/4000: train_loss=0.0007  test_loss=84.7055  λ_max=2.2876\n",
      "[Muon | lr=0.05] Epoch 2202/4000: train_loss=0.0009  test_loss=84.7635  λ_max=2.2474\n",
      "[Muon | lr=0.05] Epoch 2203/4000: train_loss=0.0011  test_loss=84.7484  λ_max=2.3279\n",
      "[Muon | lr=0.05] Epoch 2204/4000: train_loss=0.0010  test_loss=84.7224  λ_max=2.0837\n",
      "[Muon | lr=0.05] Epoch 2205/4000: train_loss=0.0009  test_loss=84.6488  λ_max=2.2611\n",
      "[Muon | lr=0.05] Epoch 2206/4000: train_loss=0.0012  test_loss=84.6584  λ_max=2.4817\n",
      "[Muon | lr=0.05] Iter 35300: loss=0.0000\n",
      "[Muon | lr=0.05] Epoch 2207/4000: train_loss=0.0007  test_loss=84.6842  λ_max=2.2870\n",
      "[Muon | lr=0.05] Epoch 2208/4000: train_loss=0.0006  test_loss=84.7615  λ_max=2.3729\n",
      "[Muon | lr=0.05] Epoch 2209/4000: train_loss=0.0008  test_loss=84.7212  λ_max=2.2562\n",
      "[Muon | lr=0.05] Epoch 2210/4000: train_loss=0.0007  test_loss=84.7551  λ_max=2.1137\n",
      "[Muon | lr=0.05] Epoch 2211/4000: train_loss=0.0008  test_loss=84.8835  λ_max=2.2484\n",
      "[Muon | lr=0.05] Epoch 2212/4000: train_loss=0.0009  test_loss=84.8964  λ_max=2.3630\n",
      "[Muon | lr=0.05] Iter 35400: loss=0.0008\n",
      "[Muon | lr=0.05] Epoch 2213/4000: train_loss=0.0013  test_loss=84.8148  λ_max=2.2576\n",
      "[Muon | lr=0.05] Epoch 2214/4000: train_loss=0.0009  test_loss=84.7632  λ_max=2.2944\n",
      "[Muon | lr=0.05] Epoch 2215/4000: train_loss=0.0014  test_loss=84.6970  λ_max=2.3957\n",
      "[Muon | lr=0.05] Epoch 2216/4000: train_loss=0.0010  test_loss=84.6592  λ_max=2.2165\n",
      "[Muon | lr=0.05] Epoch 2217/4000: train_loss=0.0009  test_loss=84.7355  λ_max=2.3082\n",
      "[Muon | lr=0.05] Epoch 2218/4000: train_loss=0.0009  test_loss=84.7490  λ_max=2.3978\n",
      "[Muon | lr=0.05] Iter 35500: loss=0.0015\n",
      "[Muon | lr=0.05] Epoch 2219/4000: train_loss=0.0009  test_loss=84.8027  λ_max=2.2375\n",
      "[Muon | lr=0.05] Epoch 2220/4000: train_loss=0.0010  test_loss=84.8686  λ_max=2.2696\n",
      "[Muon | lr=0.05] Epoch 2221/4000: train_loss=0.0010  test_loss=84.8635  λ_max=2.3234\n",
      "[Muon | lr=0.05] Epoch 2222/4000: train_loss=0.0007  test_loss=84.9448  λ_max=2.2682\n",
      "[Muon | lr=0.05] Epoch 2223/4000: train_loss=0.0008  test_loss=84.9927  λ_max=2.3407\n",
      "[Muon | lr=0.05] Epoch 2224/4000: train_loss=0.0011  test_loss=84.9781  λ_max=2.3365\n",
      "[Muon | lr=0.05] Iter 35600: loss=0.0037\n",
      "[Muon | lr=0.05] Epoch 2225/4000: train_loss=0.0009  test_loss=85.0458  λ_max=2.2847\n",
      "[Muon | lr=0.05] Epoch 2226/4000: train_loss=0.0008  test_loss=85.1865  λ_max=2.1602\n",
      "[Muon | lr=0.05] Epoch 2227/4000: train_loss=0.0009  test_loss=85.2824  λ_max=2.2815\n",
      "[Muon | lr=0.05] Epoch 2228/4000: train_loss=0.0006  test_loss=85.3489  λ_max=2.2160\n",
      "[Muon | lr=0.05] Epoch 2229/4000: train_loss=0.0008  test_loss=85.3666  λ_max=2.1527\n",
      "[Muon | lr=0.05] Epoch 2230/4000: train_loss=0.0007  test_loss=85.4764  λ_max=2.2718\n",
      "[Muon | lr=0.05] Epoch 2231/4000: train_loss=0.0014  test_loss=85.5215  λ_max=2.3497\n",
      "[Muon | lr=0.05] Iter 35700: loss=0.0002\n",
      "[Muon | lr=0.05] Epoch 2232/4000: train_loss=0.0009  test_loss=85.5709  λ_max=2.1742\n",
      "[Muon | lr=0.05] Epoch 2233/4000: train_loss=0.0009  test_loss=85.5850  λ_max=2.1834\n",
      "[Muon | lr=0.05] Epoch 2234/4000: train_loss=0.0008  test_loss=85.6304  λ_max=2.3658\n",
      "[Muon | lr=0.05] Epoch 2235/4000: train_loss=0.0009  test_loss=85.6455  λ_max=2.1746\n",
      "[Muon | lr=0.05] Epoch 2236/4000: train_loss=0.0010  test_loss=85.6838  λ_max=2.2439\n",
      "[Muon | lr=0.05] Epoch 2237/4000: train_loss=0.0009  test_loss=85.8041  λ_max=2.3051\n",
      "[Muon | lr=0.05] Iter 35800: loss=0.0007\n",
      "[Muon | lr=0.05] Epoch 2238/4000: train_loss=0.0009  test_loss=85.9043  λ_max=2.3501\n",
      "[Muon | lr=0.05] Epoch 2239/4000: train_loss=0.0013  test_loss=86.0068  λ_max=2.1740\n",
      "[Muon | lr=0.05] Epoch 2240/4000: train_loss=0.0007  test_loss=86.0123  λ_max=2.2081\n",
      "[Muon | lr=0.05] Epoch 2241/4000: train_loss=0.0007  test_loss=85.9744  λ_max=2.2414\n",
      "[Muon | lr=0.05] Epoch 2242/4000: train_loss=0.0009  test_loss=86.0427  λ_max=2.1932\n",
      "[Muon | lr=0.05] Epoch 2243/4000: train_loss=0.0007  test_loss=86.0670  λ_max=2.2066\n",
      "[Muon | lr=0.05] Iter 35900: loss=0.0014\n",
      "[Muon | lr=0.05] Epoch 2244/4000: train_loss=0.0009  test_loss=86.0189  λ_max=2.1693\n",
      "[Muon | lr=0.05] Epoch 2245/4000: train_loss=0.0008  test_loss=86.0738  λ_max=2.4347\n",
      "[Muon | lr=0.05] Epoch 2246/4000: train_loss=0.0011  test_loss=86.0909  λ_max=2.3053\n",
      "[Muon | lr=0.05] Epoch 2247/4000: train_loss=0.0012  test_loss=86.1124  λ_max=2.1820\n",
      "[Muon | lr=0.05] Epoch 2248/4000: train_loss=0.0007  test_loss=86.1149  λ_max=2.4776\n",
      "[Muon | lr=0.05] Epoch 2249/4000: train_loss=0.0008  test_loss=86.1512  λ_max=2.2885\n",
      "[Muon | lr=0.05] Iter 36000: loss=0.0031\n",
      "[Muon | lr=0.05] Epoch 2250/4000: train_loss=0.0012  test_loss=86.2071  λ_max=2.3727\n",
      "[Muon | lr=0.05] Epoch 2251/4000: train_loss=0.0009  test_loss=86.2093  λ_max=2.3527\n",
      "[Muon | lr=0.05] Epoch 2252/4000: train_loss=0.0006  test_loss=86.2049  λ_max=2.3306\n",
      "[Muon | lr=0.05] Epoch 2253/4000: train_loss=0.0013  test_loss=86.1061  λ_max=2.2106\n",
      "[Muon | lr=0.05] Epoch 2254/4000: train_loss=0.0010  test_loss=86.0093  λ_max=2.3088\n",
      "[Muon | lr=0.05] Epoch 2255/4000: train_loss=0.0007  test_loss=85.9664  λ_max=2.2762\n",
      "[Muon | lr=0.05] Epoch 2256/4000: train_loss=0.0010  test_loss=86.0782  λ_max=2.4236\n",
      "[Muon | lr=0.05] Iter 36100: loss=0.0002\n",
      "[Muon | lr=0.05] Epoch 2257/4000: train_loss=0.0008  test_loss=86.0933  λ_max=2.2320\n",
      "[Muon | lr=0.05] Epoch 2258/4000: train_loss=0.0009  test_loss=86.0387  λ_max=2.3437\n",
      "[Muon | lr=0.05] Epoch 2259/4000: train_loss=0.0007  test_loss=86.1207  λ_max=2.2696\n",
      "[Muon | lr=0.05] Epoch 2260/4000: train_loss=0.0012  test_loss=86.2337  λ_max=2.3017\n",
      "[Muon | lr=0.05] Epoch 2261/4000: train_loss=0.0008  test_loss=86.2940  λ_max=2.2317\n",
      "[Muon | lr=0.05] Epoch 2262/4000: train_loss=0.0008  test_loss=86.3191  λ_max=2.3396\n",
      "[Muon | lr=0.05] Iter 36200: loss=0.0007\n",
      "[Muon | lr=0.05] Epoch 2263/4000: train_loss=0.0011  test_loss=86.3970  λ_max=2.1774\n",
      "[Muon | lr=0.05] Epoch 2264/4000: train_loss=0.0010  test_loss=86.3687  λ_max=2.2686\n",
      "[Muon | lr=0.05] Epoch 2265/4000: train_loss=0.0010  test_loss=86.3832  λ_max=2.3210\n",
      "[Muon | lr=0.05] Epoch 2266/4000: train_loss=0.0011  test_loss=86.4358  λ_max=2.1952\n",
      "[Muon | lr=0.05] Epoch 2267/4000: train_loss=0.0011  test_loss=86.4897  λ_max=2.3494\n",
      "[Muon | lr=0.05] Epoch 2268/4000: train_loss=0.0008  test_loss=86.5613  λ_max=2.3253\n",
      "[Muon | lr=0.05] Iter 36300: loss=0.0014\n",
      "[Muon | lr=0.05] Epoch 2269/4000: train_loss=0.0011  test_loss=86.6107  λ_max=2.3263\n",
      "[Muon | lr=0.05] Epoch 2270/4000: train_loss=0.0009  test_loss=86.6226  λ_max=2.3355\n",
      "[Muon | lr=0.05] Epoch 2271/4000: train_loss=0.0007  test_loss=86.7290  λ_max=2.2097\n",
      "[Muon | lr=0.05] Epoch 2272/4000: train_loss=0.0008  test_loss=86.7193  λ_max=2.3310\n",
      "[Muon | lr=0.05] Epoch 2273/4000: train_loss=0.0006  test_loss=86.7641  λ_max=2.3471\n",
      "[Muon | lr=0.05] Epoch 2274/4000: train_loss=0.0008  test_loss=86.7517  λ_max=2.4092\n",
      "[Muon | lr=0.05] Iter 36400: loss=0.0046\n",
      "[Muon | lr=0.05] Epoch 2275/4000: train_loss=0.0012  test_loss=86.6999  λ_max=2.2216\n",
      "[Muon | lr=0.05] Epoch 2276/4000: train_loss=0.0010  test_loss=86.7533  λ_max=2.3079\n",
      "[Muon | lr=0.05] Epoch 2277/4000: train_loss=0.0009  test_loss=86.8542  λ_max=2.1734\n",
      "[Muon | lr=0.05] Epoch 2278/4000: train_loss=0.0006  test_loss=86.8478  λ_max=2.2842\n",
      "[Muon | lr=0.05] Epoch 2279/4000: train_loss=0.0009  test_loss=86.8180  λ_max=2.2077\n",
      "[Muon | lr=0.05] Epoch 2280/4000: train_loss=0.0010  test_loss=86.8945  λ_max=2.2436\n",
      "[Muon | lr=0.05] Epoch 2281/4000: train_loss=0.0009  test_loss=86.8727  λ_max=2.4008\n",
      "[Muon | lr=0.05] Iter 36500: loss=0.0001\n",
      "[Muon | lr=0.05] Epoch 2282/4000: train_loss=0.0009  test_loss=86.8993  λ_max=2.2356\n",
      "[Muon | lr=0.05] Epoch 2283/4000: train_loss=0.0008  test_loss=86.9890  λ_max=2.2295\n",
      "[Muon | lr=0.05] Epoch 2284/4000: train_loss=0.0012  test_loss=87.1273  λ_max=2.2220\n",
      "[Muon | lr=0.05] Epoch 2285/4000: train_loss=0.0009  test_loss=87.1763  λ_max=2.1990\n",
      "[Muon | lr=0.05] Epoch 2286/4000: train_loss=0.0008  test_loss=87.1779  λ_max=2.2357\n",
      "[Muon | lr=0.05] Epoch 2287/4000: train_loss=0.0007  test_loss=87.1645  λ_max=2.2381\n",
      "[Muon | lr=0.05] Iter 36600: loss=0.0008\n",
      "[Muon | lr=0.05] Epoch 2288/4000: train_loss=0.0009  test_loss=87.1060  λ_max=2.1338\n",
      "[Muon | lr=0.05] Epoch 2289/4000: train_loss=0.0009  test_loss=87.0605  λ_max=2.2968\n",
      "[Muon | lr=0.05] Epoch 2290/4000: train_loss=0.0008  test_loss=87.0095  λ_max=2.2053\n",
      "[Muon | lr=0.05] Epoch 2291/4000: train_loss=0.0006  test_loss=86.9772  λ_max=2.1906\n",
      "[Muon | lr=0.05] Epoch 2292/4000: train_loss=0.0009  test_loss=86.9780  λ_max=2.3122\n",
      "[Muon | lr=0.05] Epoch 2293/4000: train_loss=0.0007  test_loss=86.9939  λ_max=2.1892\n",
      "[Muon | lr=0.05] Iter 36700: loss=0.0010\n",
      "[Muon | lr=0.05] Epoch 2294/4000: train_loss=0.0009  test_loss=86.9600  λ_max=2.3969\n",
      "[Muon | lr=0.05] Epoch 2295/4000: train_loss=0.0007  test_loss=86.9478  λ_max=2.4208\n",
      "[Muon | lr=0.05] Epoch 2296/4000: train_loss=0.0008  test_loss=86.9323  λ_max=2.3401\n",
      "[Muon | lr=0.05] Epoch 2297/4000: train_loss=0.0008  test_loss=86.9470  λ_max=2.1771\n",
      "[Muon | lr=0.05] Epoch 2298/4000: train_loss=0.0009  test_loss=86.9548  λ_max=2.1867\n",
      "[Muon | lr=0.05] Epoch 2299/4000: train_loss=0.0010  test_loss=86.9339  λ_max=2.2323\n",
      "[Muon | lr=0.05] Iter 36800: loss=0.0008\n",
      "[Muon | lr=0.05] Epoch 2300/4000: train_loss=0.0010  test_loss=86.9186  λ_max=2.4578\n",
      "[Muon | lr=0.05] Epoch 2301/4000: train_loss=0.0010  test_loss=86.9353  λ_max=2.1712\n",
      "[Muon | lr=0.05] Epoch 2302/4000: train_loss=0.0009  test_loss=87.0026  λ_max=2.1168\n",
      "[Muon | lr=0.05] Epoch 2303/4000: train_loss=0.0011  test_loss=87.0436  λ_max=2.2594\n",
      "[Muon | lr=0.05] Epoch 2304/4000: train_loss=0.0007  test_loss=87.0502  λ_max=2.2180\n",
      "[Muon | lr=0.05] Epoch 2305/4000: train_loss=0.0010  test_loss=87.1763  λ_max=2.2865\n",
      "[Muon | lr=0.05] Epoch 2306/4000: train_loss=0.0009  test_loss=87.2394  λ_max=2.3723\n",
      "[Muon | lr=0.05] Iter 36900: loss=0.0004\n",
      "[Muon | lr=0.05] Epoch 2307/4000: train_loss=0.0009  test_loss=87.2650  λ_max=2.2249\n",
      "[Muon | lr=0.05] Epoch 2308/4000: train_loss=0.0011  test_loss=87.3432  λ_max=2.4608\n",
      "[Muon | lr=0.05] Epoch 2309/4000: train_loss=0.0010  test_loss=87.3846  λ_max=2.3087\n",
      "[Muon | lr=0.05] Epoch 2310/4000: train_loss=0.0010  test_loss=87.3974  λ_max=2.1650\n",
      "[Muon | lr=0.05] Epoch 2311/4000: train_loss=0.0009  test_loss=87.4475  λ_max=2.0944\n",
      "[Muon | lr=0.05] Epoch 2312/4000: train_loss=0.0007  test_loss=87.4239  λ_max=2.2261\n",
      "[Muon | lr=0.05] Iter 37000: loss=0.0001\n",
      "[Muon | lr=0.05] Epoch 2313/4000: train_loss=0.0009  test_loss=87.4040  λ_max=2.2337\n",
      "[Muon | lr=0.05] Epoch 2314/4000: train_loss=0.0010  test_loss=87.4511  λ_max=2.3688\n",
      "[Muon | lr=0.05] Epoch 2315/4000: train_loss=0.0010  test_loss=87.4535  λ_max=2.4344\n",
      "[Muon | lr=0.05] Epoch 2316/4000: train_loss=0.0010  test_loss=87.4732  λ_max=2.3351\n",
      "[Muon | lr=0.05] Epoch 2317/4000: train_loss=0.0008  test_loss=87.5625  λ_max=2.2936\n",
      "[Muon | lr=0.05] Epoch 2318/4000: train_loss=0.0008  test_loss=87.6307  λ_max=2.2608\n",
      "[Muon | lr=0.05] Iter 37100: loss=0.0012\n",
      "[Muon | lr=0.05] Epoch 2319/4000: train_loss=0.0009  test_loss=87.5990  λ_max=2.2420\n",
      "[Muon | lr=0.05] Epoch 2320/4000: train_loss=0.0010  test_loss=87.5941  λ_max=2.3217\n",
      "[Muon | lr=0.05] Epoch 2321/4000: train_loss=0.0008  test_loss=87.5817  λ_max=2.4219\n",
      "[Muon | lr=0.05] Epoch 2322/4000: train_loss=0.0008  test_loss=87.6644  λ_max=2.3488\n",
      "[Muon | lr=0.05] Epoch 2323/4000: train_loss=0.0009  test_loss=87.6857  λ_max=2.2111\n",
      "[Muon | lr=0.05] Epoch 2324/4000: train_loss=0.0009  test_loss=87.7313  λ_max=2.1527\n",
      "[Muon | lr=0.05] Iter 37200: loss=0.0018\n",
      "[Muon | lr=0.05] Epoch 2325/4000: train_loss=0.0008  test_loss=87.7760  λ_max=2.2616\n",
      "[Muon | lr=0.05] Epoch 2326/4000: train_loss=0.0010  test_loss=87.9194  λ_max=2.2739\n",
      "[Muon | lr=0.05] Epoch 2327/4000: train_loss=0.0008  test_loss=87.9761  λ_max=2.3175\n",
      "[Muon | lr=0.05] Epoch 2328/4000: train_loss=0.0008  test_loss=88.0839  λ_max=2.3958\n",
      "[Muon | lr=0.05] Epoch 2329/4000: train_loss=0.0011  test_loss=88.1027  λ_max=2.2633\n",
      "[Muon | lr=0.05] Epoch 2330/4000: train_loss=0.0010  test_loss=88.0897  λ_max=2.3149\n",
      "[Muon | lr=0.05] Epoch 2331/4000: train_loss=0.0009  test_loss=88.1776  λ_max=2.2341\n",
      "[Muon | lr=0.05] Iter 37300: loss=0.0009\n",
      "[Muon | lr=0.05] Epoch 2332/4000: train_loss=0.0009  test_loss=88.1561  λ_max=2.3468\n",
      "[Muon | lr=0.05] Epoch 2333/4000: train_loss=0.0010  test_loss=88.1346  λ_max=2.3298\n",
      "[Muon | lr=0.05] Epoch 2334/4000: train_loss=0.0009  test_loss=88.1196  λ_max=2.5622\n",
      "[Muon | lr=0.05] Epoch 2335/4000: train_loss=0.0011  test_loss=88.1473  λ_max=2.2089\n",
      "[Muon | lr=0.05] Epoch 2336/4000: train_loss=0.0012  test_loss=88.2102  λ_max=2.2082\n",
      "[Muon | lr=0.05] Epoch 2337/4000: train_loss=0.0009  test_loss=88.2177  λ_max=2.3994\n",
      "[Muon | lr=0.05] Iter 37400: loss=0.0021\n",
      "[Muon | lr=0.05] Epoch 2338/4000: train_loss=0.0009  test_loss=88.3146  λ_max=2.2979\n",
      "[Muon | lr=0.05] Epoch 2339/4000: train_loss=0.0007  test_loss=88.3667  λ_max=2.3493\n",
      "[Muon | lr=0.05] Epoch 2340/4000: train_loss=0.0013  test_loss=88.3995  λ_max=2.2908\n",
      "[Muon | lr=0.05] Epoch 2341/4000: train_loss=0.0008  test_loss=88.4574  λ_max=2.4327\n",
      "[Muon | lr=0.05] Epoch 2342/4000: train_loss=0.0012  test_loss=88.4789  λ_max=2.5452\n",
      "[Muon | lr=0.05] Epoch 2343/4000: train_loss=0.0011  test_loss=88.5098  λ_max=2.2502\n",
      "[Muon | lr=0.05] Iter 37500: loss=0.0017\n",
      "[Muon | lr=0.05] Epoch 2344/4000: train_loss=0.0009  test_loss=88.4556  λ_max=2.3111\n",
      "[Muon | lr=0.05] Epoch 2345/4000: train_loss=0.0008  test_loss=88.5220  λ_max=2.2934\n",
      "[Muon | lr=0.05] Epoch 2346/4000: train_loss=0.0011  test_loss=88.6337  λ_max=2.2467\n",
      "[Muon | lr=0.05] Epoch 2347/4000: train_loss=0.0008  test_loss=88.7184  λ_max=2.2695\n",
      "[Muon | lr=0.05] Epoch 2348/4000: train_loss=0.0007  test_loss=88.7633  λ_max=2.3403\n",
      "[Muon | lr=0.05] Epoch 2349/4000: train_loss=0.0010  test_loss=88.8909  λ_max=2.3973\n",
      "[Muon | lr=0.05] Iter 37600: loss=0.0013\n",
      "[Muon | lr=0.05] Epoch 2350/4000: train_loss=0.0006  test_loss=88.9376  λ_max=2.5394\n",
      "[Muon | lr=0.05] Epoch 2351/4000: train_loss=0.0008  test_loss=89.0267  λ_max=2.1359\n",
      "[Muon | lr=0.05] Epoch 2352/4000: train_loss=0.0008  test_loss=89.0999  λ_max=2.2082\n",
      "[Muon | lr=0.05] Epoch 2353/4000: train_loss=0.0009  test_loss=89.1287  λ_max=2.2040\n",
      "[Muon | lr=0.05] Epoch 2354/4000: train_loss=0.0007  test_loss=89.2070  λ_max=2.1432\n",
      "[Muon | lr=0.05] Epoch 2355/4000: train_loss=0.0008  test_loss=89.1314  λ_max=2.2267\n",
      "[Muon | lr=0.05] Epoch 2356/4000: train_loss=0.0006  test_loss=89.1274  λ_max=2.3580\n",
      "[Muon | lr=0.05] Iter 37700: loss=0.0011\n",
      "[Muon | lr=0.05] Epoch 2357/4000: train_loss=0.0008  test_loss=89.1354  λ_max=2.0565\n",
      "[Muon | lr=0.05] Epoch 2358/4000: train_loss=0.0008  test_loss=89.1663  λ_max=2.2845\n",
      "[Muon | lr=0.05] Epoch 2359/4000: train_loss=0.0009  test_loss=89.1220  λ_max=2.3219\n",
      "[Muon | lr=0.05] Epoch 2360/4000: train_loss=0.0006  test_loss=89.1516  λ_max=2.2991\n",
      "[Muon | lr=0.05] Epoch 2361/4000: train_loss=0.0010  test_loss=89.2264  λ_max=2.2093\n",
      "[Muon | lr=0.05] Epoch 2362/4000: train_loss=0.0010  test_loss=89.3011  λ_max=2.2493\n",
      "[Muon | lr=0.05] Iter 37800: loss=0.0017\n",
      "[Muon | lr=0.05] Epoch 2363/4000: train_loss=0.0008  test_loss=89.2937  λ_max=2.3625\n",
      "[Muon | lr=0.05] Epoch 2364/4000: train_loss=0.0008  test_loss=89.2741  λ_max=2.2876\n",
      "[Muon | lr=0.05] Epoch 2365/4000: train_loss=0.0009  test_loss=89.2286  λ_max=2.3460\n",
      "[Muon | lr=0.05] Epoch 2366/4000: train_loss=0.0007  test_loss=89.2633  λ_max=2.2780\n",
      "[Muon | lr=0.05] Epoch 2367/4000: train_loss=0.0008  test_loss=89.2601  λ_max=2.3408\n",
      "[Muon | lr=0.05] Epoch 2368/4000: train_loss=0.0011  test_loss=89.2266  λ_max=2.2920\n",
      "[Muon | lr=0.05] Iter 37900: loss=0.0007\n",
      "[Muon | lr=0.05] Epoch 2369/4000: train_loss=0.0006  test_loss=89.2242  λ_max=2.2724\n",
      "[Muon | lr=0.05] Epoch 2370/4000: train_loss=0.0009  test_loss=89.1697  λ_max=2.4286\n",
      "[Muon | lr=0.05] Epoch 2371/4000: train_loss=0.0011  test_loss=89.1765  λ_max=2.3075\n",
      "[Muon | lr=0.05] Epoch 2372/4000: train_loss=0.0010  test_loss=89.2044  λ_max=2.2911\n",
      "[Muon | lr=0.05] Epoch 2373/4000: train_loss=0.0006  test_loss=89.2100  λ_max=2.4885\n",
      "[Muon | lr=0.05] Epoch 2374/4000: train_loss=0.0007  test_loss=89.1916  λ_max=2.3753\n",
      "[Muon | lr=0.05] Iter 38000: loss=0.0040\n",
      "[Muon | lr=0.05] Epoch 2375/4000: train_loss=0.0009  test_loss=89.2276  λ_max=2.2616\n",
      "[Muon | lr=0.05] Epoch 2376/4000: train_loss=0.0008  test_loss=89.3400  λ_max=2.1820\n",
      "[Muon | lr=0.05] Epoch 2377/4000: train_loss=0.0010  test_loss=89.4032  λ_max=2.1302\n",
      "[Muon | lr=0.05] Epoch 2378/4000: train_loss=0.0010  test_loss=89.4794  λ_max=2.3026\n",
      "[Muon | lr=0.05] Epoch 2379/4000: train_loss=0.0008  test_loss=89.5593  λ_max=2.5793\n",
      "[Muon | lr=0.05] Epoch 2380/4000: train_loss=0.0009  test_loss=89.5721  λ_max=2.1627\n",
      "[Muon | lr=0.05] Epoch 2381/4000: train_loss=0.0006  test_loss=89.6088  λ_max=2.3460\n",
      "[Muon | lr=0.05] Iter 38100: loss=0.0000\n",
      "[Muon | lr=0.05] Epoch 2382/4000: train_loss=0.0005  test_loss=89.5881  λ_max=2.2437\n",
      "[Muon | lr=0.05] Epoch 2383/4000: train_loss=0.0010  test_loss=89.5923  λ_max=2.3667\n",
      "[Muon | lr=0.05] Epoch 2384/4000: train_loss=0.0010  test_loss=89.6104  λ_max=2.4142\n",
      "[Muon | lr=0.05] Epoch 2385/4000: train_loss=0.0009  test_loss=89.5773  λ_max=2.4398\n",
      "[Muon | lr=0.05] Epoch 2386/4000: train_loss=0.0005  test_loss=89.4882  λ_max=2.2463\n",
      "[Muon | lr=0.05] Epoch 2387/4000: train_loss=0.0008  test_loss=89.6134  λ_max=2.1851\n",
      "[Muon | lr=0.05] Iter 38200: loss=0.0001\n",
      "[Muon | lr=0.05] Epoch 2388/4000: train_loss=0.0011  test_loss=89.7007  λ_max=2.1373\n",
      "[Muon | lr=0.05] Epoch 2389/4000: train_loss=0.0011  test_loss=89.7426  λ_max=2.2638\n",
      "[Muon | lr=0.05] Epoch 2390/4000: train_loss=0.0007  test_loss=89.8001  λ_max=2.3134\n",
      "[Muon | lr=0.05] Epoch 2391/4000: train_loss=0.0008  test_loss=89.8689  λ_max=2.4676\n",
      "[Muon | lr=0.05] Epoch 2392/4000: train_loss=0.0010  test_loss=89.8419  λ_max=2.5604\n",
      "[Muon | lr=0.05] Epoch 2393/4000: train_loss=0.0006  test_loss=89.8886  λ_max=2.4881\n",
      "[Muon | lr=0.05] Iter 38300: loss=0.0007\n",
      "[Muon | lr=0.05] Epoch 2394/4000: train_loss=0.0008  test_loss=89.9400  λ_max=2.2274\n",
      "[Muon | lr=0.05] Epoch 2395/4000: train_loss=0.0013  test_loss=90.0107  λ_max=2.1893\n",
      "[Muon | lr=0.05] Epoch 2396/4000: train_loss=0.0009  test_loss=89.9830  λ_max=2.2479\n",
      "[Muon | lr=0.05] Epoch 2397/4000: train_loss=0.0009  test_loss=89.9917  λ_max=2.4231\n",
      "[Muon | lr=0.05] Epoch 2398/4000: train_loss=0.0006  test_loss=90.1404  λ_max=2.2363\n",
      "[Muon | lr=0.05] Epoch 2399/4000: train_loss=0.0006  test_loss=90.1966  λ_max=2.3224\n",
      "[Muon | lr=0.05] Iter 38400: loss=0.0006\n",
      "[Muon | lr=0.05] Epoch 2400/4000: train_loss=0.0009  test_loss=90.2275  λ_max=2.2850\n",
      "[Muon | lr=0.05] Epoch 2401/4000: train_loss=0.0010  test_loss=90.2792  λ_max=2.4221\n",
      "[Muon | lr=0.05] Epoch 2402/4000: train_loss=0.0007  test_loss=90.2524  λ_max=2.2705\n",
      "[Muon | lr=0.05] Epoch 2403/4000: train_loss=0.0007  test_loss=90.2326  λ_max=2.2449\n",
      "[Muon | lr=0.05] Epoch 2404/4000: train_loss=0.0013  test_loss=90.3393  λ_max=2.2983\n",
      "[Muon | lr=0.05] Epoch 2405/4000: train_loss=0.0008  test_loss=90.3205  λ_max=2.4200\n",
      "[Muon | lr=0.05] Epoch 2406/4000: train_loss=0.0006  test_loss=90.2699  λ_max=2.4244\n",
      "[Muon | lr=0.05] Iter 38500: loss=0.0004\n",
      "[Muon | lr=0.05] Epoch 2407/4000: train_loss=0.0008  test_loss=90.2923  λ_max=2.3284\n",
      "[Muon | lr=0.05] Epoch 2408/4000: train_loss=0.0011  test_loss=90.3216  λ_max=2.3672\n",
      "[Muon | lr=0.05] Epoch 2409/4000: train_loss=0.0013  test_loss=90.3336  λ_max=2.4009\n",
      "[Muon | lr=0.05] Epoch 2410/4000: train_loss=0.0009  test_loss=90.2789  λ_max=2.3388\n",
      "[Muon | lr=0.05] Epoch 2411/4000: train_loss=0.0008  test_loss=90.2802  λ_max=2.4028\n",
      "[Muon | lr=0.05] Epoch 2412/4000: train_loss=0.0010  test_loss=90.2455  λ_max=2.2727\n",
      "[Muon | lr=0.05] Iter 38600: loss=0.0004\n",
      "[Muon | lr=0.05] Epoch 2413/4000: train_loss=0.0008  test_loss=90.1502  λ_max=2.2853\n",
      "[Muon | lr=0.05] Epoch 2414/4000: train_loss=0.0006  test_loss=90.1357  λ_max=2.2723\n",
      "[Muon | lr=0.05] Epoch 2415/4000: train_loss=0.0008  test_loss=90.1091  λ_max=2.2449\n",
      "[Muon | lr=0.05] Epoch 2416/4000: train_loss=0.0012  test_loss=90.0274  λ_max=2.2474\n",
      "[Muon | lr=0.05] Epoch 2417/4000: train_loss=0.0011  test_loss=90.0757  λ_max=2.4178\n",
      "[Muon | lr=0.05] Epoch 2418/4000: train_loss=0.0004  test_loss=90.1362  λ_max=2.2726\n",
      "[Muon | lr=0.05] Iter 38700: loss=0.0009\n",
      "[Muon | lr=0.05] Epoch 2419/4000: train_loss=0.0007  test_loss=90.1862  λ_max=2.2970\n",
      "[Muon | lr=0.05] Epoch 2420/4000: train_loss=0.0008  test_loss=90.1951  λ_max=2.2880\n",
      "[Muon | lr=0.05] Epoch 2421/4000: train_loss=0.0008  test_loss=90.2874  λ_max=2.3927\n",
      "[Muon | lr=0.05] Epoch 2422/4000: train_loss=0.0010  test_loss=90.2813  λ_max=2.2887\n",
      "[Muon | lr=0.05] Epoch 2423/4000: train_loss=0.0008  test_loss=90.1643  λ_max=2.3498\n",
      "[Muon | lr=0.05] Epoch 2424/4000: train_loss=0.0009  test_loss=90.0545  λ_max=2.5022\n",
      "[Muon | lr=0.05] Iter 38800: loss=0.0006\n",
      "[Muon | lr=0.05] Epoch 2425/4000: train_loss=0.0008  test_loss=90.1338  λ_max=2.4151\n",
      "[Muon | lr=0.05] Epoch 2426/4000: train_loss=0.0008  test_loss=90.2306  λ_max=2.5307\n",
      "[Muon | lr=0.05] Epoch 2427/4000: train_loss=0.0008  test_loss=90.2724  λ_max=2.3147\n",
      "[Muon | lr=0.05] Epoch 2428/4000: train_loss=0.0005  test_loss=90.3061  λ_max=2.3606\n",
      "[Muon | lr=0.05] Epoch 2429/4000: train_loss=0.0009  test_loss=90.2874  λ_max=2.2801\n",
      "[Muon | lr=0.05] Epoch 2430/4000: train_loss=0.0008  test_loss=90.2287  λ_max=2.2947\n",
      "[Muon | lr=0.05] Epoch 2431/4000: train_loss=0.0007  test_loss=90.1669  λ_max=2.3897\n",
      "[Muon | lr=0.05] Iter 38900: loss=0.0001\n",
      "[Muon | lr=0.05] Epoch 2432/4000: train_loss=0.0008  test_loss=90.1907  λ_max=2.3486\n",
      "[Muon | lr=0.05] Epoch 2433/4000: train_loss=0.0008  test_loss=90.2872  λ_max=2.3764\n",
      "[Muon | lr=0.05] Epoch 2434/4000: train_loss=0.0012  test_loss=90.2556  λ_max=2.2084\n",
      "[Muon | lr=0.05] Epoch 2435/4000: train_loss=0.0006  test_loss=90.3106  λ_max=2.5216\n",
      "[Muon | lr=0.05] Epoch 2436/4000: train_loss=0.0010  test_loss=90.2355  λ_max=2.2832\n",
      "[Muon | lr=0.05] Epoch 2437/4000: train_loss=0.0010  test_loss=90.1708  λ_max=2.3033\n",
      "[Muon | lr=0.05] Iter 39000: loss=0.0008\n",
      "[Muon | lr=0.05] Epoch 2438/4000: train_loss=0.0006  test_loss=90.2297  λ_max=2.3883\n",
      "[Muon | lr=0.05] Epoch 2439/4000: train_loss=0.0009  test_loss=90.2511  λ_max=2.3443\n",
      "[Muon | lr=0.05] Epoch 2440/4000: train_loss=0.0006  test_loss=90.2198  λ_max=2.3365\n",
      "[Muon | lr=0.05] Epoch 2441/4000: train_loss=0.0007  test_loss=90.2485  λ_max=2.5556\n",
      "[Muon | lr=0.05] Epoch 2442/4000: train_loss=0.0007  test_loss=90.3825  λ_max=2.3760\n",
      "[Muon | lr=0.05] Epoch 2443/4000: train_loss=0.0007  test_loss=90.4684  λ_max=2.2977\n",
      "[Muon | lr=0.05] Iter 39100: loss=0.0011\n",
      "[Muon | lr=0.05] Epoch 2444/4000: train_loss=0.0008  test_loss=90.5194  λ_max=2.4456\n",
      "[Muon | lr=0.05] Epoch 2445/4000: train_loss=0.0008  test_loss=90.5841  λ_max=2.3754\n",
      "[Muon | lr=0.05] Epoch 2446/4000: train_loss=0.0008  test_loss=90.6325  λ_max=2.1964\n",
      "[Muon | lr=0.05] Epoch 2447/4000: train_loss=0.0006  test_loss=90.6560  λ_max=2.2886\n",
      "[Muon | lr=0.05] Epoch 2448/4000: train_loss=0.0008  test_loss=90.6958  λ_max=2.3267\n",
      "[Muon | lr=0.05] Epoch 2449/4000: train_loss=0.0011  test_loss=90.6654  λ_max=2.3447\n",
      "[Muon | lr=0.05] Iter 39200: loss=0.0004\n",
      "[Muon | lr=0.05] Epoch 2450/4000: train_loss=0.0009  test_loss=90.7269  λ_max=2.3583\n",
      "[Muon | lr=0.05] Epoch 2451/4000: train_loss=0.0009  test_loss=90.7795  λ_max=2.4094\n",
      "[Muon | lr=0.05] Epoch 2452/4000: train_loss=0.0008  test_loss=90.7861  λ_max=2.4798\n",
      "[Muon | lr=0.05] Epoch 2453/4000: train_loss=0.0007  test_loss=90.8654  λ_max=2.4450\n",
      "[Muon | lr=0.05] Epoch 2454/4000: train_loss=0.0007  test_loss=90.8275  λ_max=2.2526\n",
      "[Muon | lr=0.05] Epoch 2455/4000: train_loss=0.0008  test_loss=90.8533  λ_max=2.2108\n",
      "[Muon | lr=0.05] Epoch 2456/4000: train_loss=0.0009  test_loss=90.7963  λ_max=2.2466\n",
      "[Muon | lr=0.05] Iter 39300: loss=0.0001\n",
      "[Muon | lr=0.05] Epoch 2457/4000: train_loss=0.0009  test_loss=90.7333  λ_max=2.4241\n",
      "[Muon | lr=0.05] Epoch 2458/4000: train_loss=0.0007  test_loss=90.8053  λ_max=2.4219\n",
      "[Muon | lr=0.05] Epoch 2459/4000: train_loss=0.0009  test_loss=90.8282  λ_max=2.4849\n",
      "[Muon | lr=0.05] Epoch 2460/4000: train_loss=0.0007  test_loss=90.8925  λ_max=2.2184\n",
      "[Muon | lr=0.05] Epoch 2461/4000: train_loss=0.0009  test_loss=90.9076  λ_max=2.4387\n",
      "[Muon | lr=0.05] Epoch 2462/4000: train_loss=0.0005  test_loss=90.8112  λ_max=2.2903\n",
      "[Muon | lr=0.05] Iter 39400: loss=0.0008\n",
      "[Muon | lr=0.05] Epoch 2463/4000: train_loss=0.0008  test_loss=90.7505  λ_max=2.5186\n",
      "[Muon | lr=0.05] Epoch 2464/4000: train_loss=0.0008  test_loss=90.7340  λ_max=2.3137\n",
      "[Muon | lr=0.05] Epoch 2465/4000: train_loss=0.0006  test_loss=90.7571  λ_max=2.6028\n",
      "[Muon | lr=0.05] Epoch 2466/4000: train_loss=0.0008  test_loss=90.7360  λ_max=2.3765\n",
      "[Muon | lr=0.05] Epoch 2467/4000: train_loss=0.0011  test_loss=90.6855  λ_max=2.2787\n",
      "[Muon | lr=0.05] Epoch 2468/4000: train_loss=0.0010  test_loss=90.6822  λ_max=2.2646\n",
      "[Muon | lr=0.05] Iter 39500: loss=0.0009\n",
      "[Muon | lr=0.05] Epoch 2469/4000: train_loss=0.0005  test_loss=90.7170  λ_max=2.3968\n",
      "[Muon | lr=0.05] Epoch 2470/4000: train_loss=0.0005  test_loss=90.7793  λ_max=2.4520\n",
      "[Muon | lr=0.05] Epoch 2471/4000: train_loss=0.0008  test_loss=90.8312  λ_max=2.3075\n",
      "[Muon | lr=0.05] Epoch 2472/4000: train_loss=0.0010  test_loss=90.8537  λ_max=2.2679\n",
      "[Muon | lr=0.05] Epoch 2473/4000: train_loss=0.0010  test_loss=90.8587  λ_max=2.1761\n",
      "[Muon | lr=0.05] Epoch 2474/4000: train_loss=0.0008  test_loss=90.9346  λ_max=2.3097\n",
      "[Muon | lr=0.05] Iter 39600: loss=0.0015\n",
      "[Muon | lr=0.05] Epoch 2475/4000: train_loss=0.0008  test_loss=91.0472  λ_max=2.2944\n",
      "[Muon | lr=0.05] Epoch 2476/4000: train_loss=0.0008  test_loss=91.0432  λ_max=2.2477\n",
      "[Muon | lr=0.05] Epoch 2477/4000: train_loss=0.0006  test_loss=91.0106  λ_max=2.3895\n",
      "[Muon | lr=0.05] Epoch 2478/4000: train_loss=0.0007  test_loss=91.0013  λ_max=2.4063\n",
      "[Muon | lr=0.05] Epoch 2479/4000: train_loss=0.0007  test_loss=91.0153  λ_max=2.3293\n",
      "[Muon | lr=0.05] Epoch 2480/4000: train_loss=0.0009  test_loss=91.1609  λ_max=2.4247\n",
      "[Muon | lr=0.05] Epoch 2481/4000: train_loss=0.0009  test_loss=91.1700  λ_max=2.2107\n",
      "[Muon | lr=0.05] Iter 39700: loss=0.0005\n",
      "[Muon | lr=0.05] Epoch 2482/4000: train_loss=0.0005  test_loss=91.0798  λ_max=2.3253\n",
      "[Muon | lr=0.05] Epoch 2483/4000: train_loss=0.0007  test_loss=91.1258  λ_max=2.4649\n",
      "[Muon | lr=0.05] Epoch 2484/4000: train_loss=0.0006  test_loss=91.2229  λ_max=2.1350\n",
      "[Muon | lr=0.05] Epoch 2485/4000: train_loss=0.0010  test_loss=91.3432  λ_max=2.3766\n",
      "[Muon | lr=0.05] Epoch 2486/4000: train_loss=0.0006  test_loss=91.4171  λ_max=2.3360\n",
      "[Muon | lr=0.05] Epoch 2487/4000: train_loss=0.0013  test_loss=91.5379  λ_max=2.3585\n",
      "[Muon | lr=0.05] Iter 39800: loss=0.0016\n",
      "[Muon | lr=0.05] Epoch 2488/4000: train_loss=0.0012  test_loss=91.6172  λ_max=2.3461\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Sudoku solver — Muon optimizer\n",
    "----------------------------------------------------\n",
    "Trains a Sudoku neural network using the Muon optimizer and measures Hessian sharpness.\n",
    "Runs a learning-rate sweep and saves results + plots in ./results_muon/\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from datasets import load_dataset\n",
    "import pickle\n",
    "import torch.distributed as dist\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# ---- SINGLE-PROCESS PATCH FOR MUON ----\n",
    "# ============================================================\n",
    "def _sp_true(*args, **kwargs): return True\n",
    "def _sp_zero(*args, **kwargs): return 0\n",
    "def _sp_one(*args, **kwargs):  return 1\n",
    "def _sp_none(*args, **kwargs): return None\n",
    "\n",
    "def _sp_all_gather(tensor_list, tensor, *args, **kwargs):\n",
    "    \"\"\"Stub replacement for dist.all_gather in single-process mode.\"\"\"\n",
    "    if isinstance(tensor_list, (list, tuple)) and len(tensor_list) > 0:\n",
    "        for i in range(len(tensor_list)):\n",
    "            if hasattr(tensor_list[i], \"data\") and hasattr(tensor, \"data\"):\n",
    "                tensor_list[i].data.copy_(tensor.data)\n",
    "            else:\n",
    "                tensor_list[i].copy_(tensor)\n",
    "    return None\n",
    "\n",
    "dist.is_initialized = _sp_true\n",
    "dist.get_rank = _sp_zero\n",
    "dist.get_world_size = _sp_one\n",
    "dist.barrier = _sp_none\n",
    "dist.broadcast_object_list = _sp_none\n",
    "dist.all_gather = _sp_all_gather\n",
    "\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Import Muon optimizer\n",
    "# ============================================================\n",
    "try:\n",
    "    from muon import MuonWithAuxAdam\n",
    "except ImportError:\n",
    "    raise ImportError(\n",
    "        \"\\n Muon optimizer not found.\"\n",
    "    )\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Dataset\n",
    "# ============================================================\n",
    "class SudokuHFDataset(Dataset):\n",
    "    def __init__(self, split=\"train\", max_size=None):\n",
    "        ds = load_dataset(\"sapientinc/sudoku-extreme\", split=split)\n",
    "        if max_size is not None:\n",
    "            ds = ds.select(range(min(max_size, len(ds))))\n",
    "        self.ds = ds\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        puzzle_str = self.ds[idx][\"question\"].replace(\".\", \"0\")\n",
    "        sol_str = self.ds[idx][\"answer\"]\n",
    "\n",
    "        puzzle = np.array([int(c) for c in puzzle_str], dtype=np.int64)\n",
    "        sol = np.array([int(c) for c in sol_str], dtype=np.int64)\n",
    "\n",
    "        x = np.zeros((81, 10), dtype=np.float32)\n",
    "        for i, v in enumerate(puzzle):\n",
    "            x[i, v] = 1.0\n",
    "        x = x.reshape(81 * 10)\n",
    "        y = sol - 1\n",
    "        return x, y\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Model\n",
    "# ============================================================\n",
    "class SudokuNet(nn.Module):\n",
    "    def __init__(self, hidden_dim=512):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(81 * 10, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.LayerNorm(hidden_dim),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.LayerNorm(hidden_dim),\n",
    "            nn.Linear(hidden_dim, 81 * 9),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.net(x)\n",
    "        return out.view(-1, 81, 9)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Hessian sharpness (λ_max)\n",
    "# ============================================================\n",
    "def hessian_largest_eigval(model, loss_fn, x, y, device=\"cpu\", num_iters=10):\n",
    "    \"\"\"\n",
    "    Implementation of Hessian λ_max using power iteration.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    x, y = x.to(device), y.to(device)\n",
    "\n",
    "    def grad_vec():\n",
    "        out = model(x)\n",
    "        loss = loss_fn(out.view(-1, 9), y.view(-1))\n",
    "        grads = torch.autograd.grad(loss, model.parameters(), create_graph=True)\n",
    "        return torch.cat([g.reshape(-1) for g in grads])\n",
    "\n",
    "    # Initial unit vector\n",
    "    v = torch.randn_like(grad_vec())\n",
    "    v /= (v.norm() + 1e-12)\n",
    "\n",
    "    # Power iteration\n",
    "    for _ in range(num_iters):\n",
    "        g = grad_vec()\n",
    "        Hv = torch.autograd.grad(\n",
    "            g,\n",
    "            model.parameters(),\n",
    "            grad_outputs=v,\n",
    "            retain_graph=True,\n",
    "            create_graph=True,\n",
    "        )\n",
    "        Hv_vec = torch.cat([h.reshape(-1) for h in Hv])\n",
    "        v = Hv_vec / (Hv_vec.norm() + 1e-12)\n",
    "\n",
    "    # Final Rayleigh quotient\n",
    "    g = grad_vec()\n",
    "    Hv = torch.autograd.grad(g, model.parameters(), grad_outputs=v)\n",
    "    Hv_vec = torch.cat([h.reshape(-1) for h in Hv])\n",
    "    eigval = torch.dot(v, Hv_vec).item()\n",
    "    return eigval\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Training with Muon\n",
    "# ============================================================\n",
    "def run_muon_training(\n",
    "    lr,\n",
    "    device,\n",
    "    epochs,\n",
    "    batch_size,\n",
    "    hidden_dim,\n",
    "    num_train,\n",
    "    num_test,\n",
    "    print_every=100,\n",
    "):\n",
    "    train_ds = SudokuHFDataset(\"train\", max_size=num_train)\n",
    "    test_ds = SudokuHFDataset(\"test\", max_size=num_test)\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_ds, batch_size=batch_size)\n",
    "\n",
    "    model = SudokuNet(hidden_dim=hidden_dim).to(device)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    hidden_weights = [p for p in model.parameters() if p.ndim >= 2]\n",
    "    other_params = [p for p in model.parameters() if p.ndim < 2]\n",
    "    param_groups = [\n",
    "        {\"params\": hidden_weights, \"use_muon\": True, \"lr\": lr},\n",
    "        {\"params\": other_params, \"use_muon\": False, \"lr\": lr / 10.0},\n",
    "    ]\n",
    "    optimizer = MuonWithAuxAdam(param_groups)\n",
    "\n",
    "    train_losses, test_losses, sharpness_vals = [], [], []\n",
    "    iteration = 0\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "\n",
    "        for x, y in train_loader:\n",
    "            iteration += 1\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            out = model(x)\n",
    "            loss = loss_fn(out.view(-1, 9), y.view(-1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            if iteration % print_every == 0:\n",
    "                print(f\"[Muon | lr={lr:.4g}] Iter {iteration}: loss={loss.item():.4f}\")\n",
    "\n",
    "        avg_train_loss = total_loss / len(train_loader)\n",
    "        train_losses.append(avg_train_loss)\n",
    "\n",
    "        # Evaluation + sharpness on one test batch\n",
    "        model.eval()\n",
    "        test_x, test_y = next(iter(test_loader))\n",
    "        test_x, test_y = test_x.to(device), test_y.to(device)\n",
    "        with torch.no_grad():\n",
    "            out_val = model(test_x)\n",
    "            test_loss = loss_fn(out_val.view(-1, 9), test_y.view(-1)).item()\n",
    "        test_losses.append(test_loss)\n",
    "\n",
    "        eigval = hessian_largest_eigval(model, loss_fn, test_x, test_y, device=device)\n",
    "        sharpness_vals.append(eigval)\n",
    "\n",
    "        print(\n",
    "            f\"[Muon | lr={lr:.4g}] Epoch {epoch}/{epochs}: \"\n",
    "            f\"train_loss={avg_train_loss:.4f}  test_loss={test_loss:.4f}  λ_max={eigval:.4f}\"\n",
    "        )\n",
    "\n",
    "    return {\n",
    "        \"train_losses\": train_losses,\n",
    "        \"test_losses\": test_losses,\n",
    "        \"sharpness_vals\": sharpness_vals,\n",
    "    }\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# LR sweep\n",
    "# ============================================================\n",
    "def muon_lr_sweep(\n",
    "    lrs,\n",
    "    device,\n",
    "    epochs,\n",
    "    batch_size,\n",
    "    hidden_dim,\n",
    "    num_train,\n",
    "    num_test,\n",
    "    print_every=100,\n",
    "    seed=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Run Muon across multiple learning rates and save results.\n",
    "\n",
    "    If seed is not None, sets torch + numpy seeds for reproducibility.\n",
    "    \"\"\"\n",
    "    if seed is not None:\n",
    "        torch.manual_seed(seed)\n",
    "        np.random.seed(seed)\n",
    "\n",
    "    os.makedirs(\"results_muon\", exist_ok=True)\n",
    "    results = {}\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    for lr in lrs:\n",
    "        print(f\"\\n Running Muon with lr={lr:.4g}\")\n",
    "        res = run_muon_training(\n",
    "            lr=lr,\n",
    "            device=device,\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            hidden_dim=hidden_dim,\n",
    "            num_train=num_train,\n",
    "            num_test=num_test,\n",
    "            print_every=print_every,\n",
    "        )\n",
    "        results[lr] = res\n",
    "\n",
    "        # Save raw arrays\n",
    "        np.savez(\n",
    "            f\"results_muon/Muon_lr{lr:.4g}.npz\",\n",
    "            train_losses=np.array(res[\"train_losses\"]),\n",
    "            test_losses=np.array(res[\"test_losses\"]),\n",
    "            sharpness_vals=np.array(res[\"sharpness_vals\"]),\n",
    "        )\n",
    "\n",
    "        # Individual sharpness plot\n",
    "        plt_ind = plt.figure(figsize=(8, 4))\n",
    "        plt.plot(range(1, len(res[\"sharpness_vals\"]) + 1),\n",
    "                 res[\"sharpness_vals\"], marker='o')\n",
    "        plt.title(f\"Muon – lr={lr:.4g}\")\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"λₘₐₓ\")\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"results_muon/Muon_lr{lr:.4g}_sharpness.png\")\n",
    "        plt.close(plt_ind)\n",
    "\n",
    "        # Add to combined plot\n",
    "        plt.plot(range(1, len(res[\"sharpness_vals\"]) + 1),\n",
    "                 res[\"sharpness_vals\"],\n",
    "                 lw=2, label=f\"lr={lr:g}\")\n",
    "\n",
    "    plt.title(\"Hessian Sharpness vs Epochs – Muon\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"λₘₐₓ\")\n",
    "    plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"results_muon/Muon_combined_sharpness.png\")\n",
    "    plt.close()\n",
    "\n",
    "    with open(\"results_muon/muon_all_results.pkl\", \"wb\") as f:\n",
    "        pickle.dump(results, f)\n",
    "\n",
    "    print(\"Saved all results in results_muon/\")\n",
    "    return results\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Entry point\n",
    "# ============================================================\n",
    "if __name__ == \"__main__\":\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    muon_results = muon_lr_sweep(\n",
    "        lrs=[1e-1, 5e-2, 1e-2, 1e-3],\n",
    "        device=device,\n",
    "        epochs=4000,\n",
    "        batch_size=128,\n",
    "        hidden_dim=512,\n",
    "        num_train=2000,\n",
    "        num_test=500,\n",
    "        print_every=100,\n",
    "        seed=42,   \n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9925c312-a5a3-498a-b9bf-e5fa57a6c85c",
   "metadata": {},
   "source": [
    "# TRM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2d46ec-f14b-40d9-b356-db9b27bc90a0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (/home/aradilla/.cache/huggingface/datasets/sapientinc___csv/sapientinc--sudoku-extreme-798989c95bd556dd/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n",
      "Found cached dataset csv (/home/aradilla/.cache/huggingface/datasets/sapientinc___csv/sapientinc--sudoku-extreme-798989c95bd556dd/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/500:   0%|          | 0/78 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01/500 | train_loss=1.6766  test_loss=1.5220  cell-acc=39.14%  λ_max=12.4529\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/500:   0%|          | 0/78 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 02/500 | train_loss=1.5251  test_loss=1.5099  cell-acc=40.20%  λ_max=11.4661\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/500:   0%|          | 0/78 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 03/500 | train_loss=1.5158  test_loss=1.5027  cell-acc=40.81%  λ_max=11.5277\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/500:   0%|          | 0/78 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 04/500 | train_loss=1.5101  test_loss=1.4995  cell-acc=41.03%  λ_max=11.5753\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/500:   0%|          | 0/78 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 05/500 | train_loss=1.5068  test_loss=1.4963  cell-acc=41.21%  λ_max=12.1045\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6/500:   0%|          | 0/78 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 06/500 | train_loss=1.5004  test_loss=1.4829  cell-acc=41.84%  λ_max=12.3069\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7/500:   0%|          | 0/78 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 07/500 | train_loss=1.4706  test_loss=1.4214  cell-acc=42.95%  λ_max=14.7272\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8/500:   0%|          | 0/78 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 08/500 | train_loss=1.3814  test_loss=1.3033  cell-acc=44.69%  λ_max=16.3293\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9/500:   0%|          | 0/78 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 09/500 | train_loss=1.2861  test_loss=1.2234  cell-acc=46.57%  λ_max=18.9297\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10/500:   0%|          | 0/78 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/500 | train_loss=1.2236  test_loss=1.1695  cell-acc=48.00%  λ_max=15.8229\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 11/500:   0%|          | 0/78 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/500 | train_loss=1.1744  test_loss=1.1235  cell-acc=49.86%  λ_max=22.1795\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 12/500:   0%|          | 0/78 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/500 | train_loss=1.1339  test_loss=1.0842  cell-acc=51.83%  λ_max=19.4406\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d73a9ebef5f14bd79851eb666a636dce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 13/500:   0%|          | 0/78 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/500 | train_loss=0.9701  test_loss=0.9359  cell-acc=57.65%  λ_max=38.2835\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 20/500:   0%|          | 0/78 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/500 | train_loss=0.9541  test_loss=0.9213  cell-acc=58.49%  λ_max=37.4743\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 21/500:   0%|          | 0/78 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/500 | train_loss=0.9409  test_loss=0.9093  cell-acc=58.98%  λ_max=41.8699\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 22/500:   0%|          | 0/78 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/500 | train_loss=0.9283  test_loss=0.8992  cell-acc=59.42%  λ_max=43.0280\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 23/500:   0%|          | 0/78 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/500 | train_loss=0.9177  test_loss=0.8908  cell-acc=59.71%  λ_max=46.1717\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 24/500:   0%|          | 0/78 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/500 | train_loss=0.9093  test_loss=0.8852  cell-acc=60.00%  λ_max=49.5220\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 25/500:   0%|          | 0/78 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/500 | train_loss=0.9033  test_loss=0.8807  cell-acc=60.19%  λ_max=55.3794\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 26/500:   0%|          | 0/78 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/500 | train_loss=0.8980  test_loss=0.8753  cell-acc=60.49%  λ_max=55.4311\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 27/500:   0%|          | 0/78 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/500 | train_loss=0.8919  test_loss=0.8728  cell-acc=60.53%  λ_max=56.5148\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 28/500:   0%|          | 0/78 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/500 | train_loss=0.8878  test_loss=0.8679  cell-acc=60.76%  λ_max=56.7381\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 29/500:   0%|          | 0/78 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/500 | train_loss=0.8819  test_loss=0.8605  cell-acc=60.86%  λ_max=62.2981\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 30/500:   0%|          | 0/78 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/500 | train_loss=0.8747  test_loss=0.8545  cell-acc=61.07%  λ_max=59.7313\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ec5b90eb13a40c1b5dcf1b5159155d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 31/500:   0%|          | 0/78 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/500 | train_loss=0.8672  test_loss=0.8487  cell-acc=61.46%  λ_max=65.9094\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79c5387c3247498696693a538b94a563",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 32/500:   0%|          | 0/78 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/500 | train_loss=0.8323  test_loss=0.8212  cell-acc=62.67%  λ_max=64.5496\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d90d45d82f1f4fdbba45861402ee5a1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 41/500:   0%|          | 0/78 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/500 | train_loss=0.8297  test_loss=0.8219  cell-acc=62.57%  λ_max=72.0812\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6aba0f44e4784586b387f33492d90a69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 42/500:   0%|          | 0/78 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/500 | train_loss=0.8280  test_loss=0.8190  cell-acc=62.78%  λ_max=70.7188\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfaa19cd44a54519bae1dada01830647",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 43/500:   0%|          | 0/78 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/500 | train_loss=0.8265  test_loss=0.8193  cell-acc=62.72%  λ_max=69.8266\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aeb3c86656f5469b9b6f74f5dc9d586f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 44/500:   0%|          | 0/78 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/500 | train_loss=0.8245  test_loss=0.8161  cell-acc=62.92%  λ_max=69.8506\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "941510b2cd4e487fbb32b5ae7be471a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 45/500:   0%|          | 0/78 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/500 | train_loss=0.8164  test_loss=0.8105  cell-acc=63.27%  λ_max=76.8673\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dee3f0f047143b38ee412eb1658628c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 50/500:   0%|          | 0/78 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/500 | train_loss=0.8148  test_loss=0.8099  cell-acc=63.17%  λ_max=72.6514\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "691a1b2126654a3eb1ef25264cf5b16c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 51/500:   0%|          | 0/78 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/500 | train_loss=0.8132  test_loss=0.8097  cell-acc=63.17%  λ_max=73.7517\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f93bc1bfa70f416085b16e6fbbb3fc49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 52/500:   0%|          | 0/78 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/500 | train_loss=0.8115  test_loss=0.8098  cell-acc=63.14%  λ_max=68.0825\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb1f63b788a84e89be4e891c3d658f77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 53/500:   0%|          | 0/78 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/500 | train_loss=0.8104  test_loss=0.8074  cell-acc=63.33%  λ_max=69.9104\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea7e79ad62b143aeb4977008f89c8e34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 54/500:   0%|          | 0/78 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/500 | train_loss=0.8079  test_loss=0.8067  cell-acc=63.55%  λ_max=64.2073\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a0463d4b12845b180dda9de7cdd817b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 55/500:   0%|          | 0/78 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/500 | train_loss=0.8078  test_loss=0.8043  cell-acc=63.51%  λ_max=69.4594\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "376f1ce321c04b5bb2b480523189d121",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 56/500:   0%|          | 0/78 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/500 | train_loss=0.8028  test_loss=0.8015  cell-acc=63.70%  λ_max=68.1643\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 59/500:   0%|          | 0/78 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/500 | train_loss=0.8013  test_loss=0.8003  cell-acc=63.71%  λ_max=63.3739\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 60/500:   0%|          | 0/78 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/500 | train_loss=0.7996  test_loss=0.7995  cell-acc=63.87%  λ_max=68.9342\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 61/500:   0%|          | 0/78 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/500 | train_loss=0.7980  test_loss=0.7993  cell-acc=63.69%  λ_max=61.0849\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 62/500:   0%|          | 0/78 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/500 | train_loss=0.7962  test_loss=0.7996  cell-acc=63.70%  λ_max=66.3543\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 63/500:   0%|          | 0/78 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/500 | train_loss=0.7959  test_loss=0.7970  cell-acc=63.90%  λ_max=64.3947\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 64/500:   0%|          | 0/78 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64/500 | train_loss=0.7945  test_loss=0.7962  cell-acc=63.89%  λ_max=60.6343\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 65/500:   0%|          | 0/78 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/500 | train_loss=0.7930  test_loss=0.7967  cell-acc=63.72%  λ_max=66.6430\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 66/500:   0%|          | 0/78 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/500 | train_loss=0.7911  test_loss=0.7952  cell-acc=63.97%  λ_max=60.0553\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 67/500:   0%|          | 0/78 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/500 | train_loss=0.7906  test_loss=0.7948  cell-acc=63.99%  λ_max=57.8799\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 68/500:   0%|          | 0/78 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/500 | train_loss=0.7882  test_loss=0.7934  cell-acc=64.00%  λ_max=60.8426\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 69/500:   0%|          | 0/78 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/500 | train_loss=0.7875  test_loss=0.7922  cell-acc=64.02%  λ_max=59.4965\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 70/500:   0%|          | 0/78 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/500 | train_loss=0.7856  test_loss=0.7936  cell-acc=63.94%  λ_max=56.7274\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 71/500:   0%|          | 0/78 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/500 | train_loss=0.7851  test_loss=0.7919  cell-acc=64.07%  λ_max=46.5773\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 72/500:   0%|          | 0/78 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/500 | train_loss=0.7832  test_loss=0.7923  cell-acc=64.04%  λ_max=58.5522\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 73/500:   0%|          | 0/78 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Sudoku solver with a TRM-style Recursive Transformer + Sharpness\n",
    "================================================================\n",
    "\n",
    "- TRM-style model:\n",
    "    * Token embeddings for digits (0–9), 0 = blank\n",
    "    * Positional embeddings for 81 cells\n",
    "    * Pre-LN Transformer blocks with self-attention + MLP\n",
    "    * Residual connections\n",
    "    * Repeated application (T steps) of the same block(s)\n",
    "\n",
    "- Trains on \"sapientinc/sudoku-extreme\"\n",
    "- Tracks:\n",
    "    * train_loss, test_loss, test cell accuracy\n",
    "    * Hessian sharpness (λ_max via power iteration) each epoch\n",
    "\n",
    "- Saves:\n",
    "    * Loss/accuracy/sharpness arrays -> 'trm_sudoku_metrics.npz'\n",
    "    * Loss plot -> 'trm_sudoku_loss.png'\n",
    "    * Accuracy plot -> 'trm_sudoku_accuracy.png'\n",
    "    * Sharpness plot -> 'trm_sudoku_sharpness.png'\n",
    "    * Model weights -> 'trm_sudoku_model.pth'\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import copy\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from datasets import load_dataset\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Dataset\n",
    "# ============================================================\n",
    "class SudokuHFDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Wraps 'sapientinc/sudoku-extreme'.\n",
    "\n",
    "    Returns:\n",
    "        puzzle_onehot: (81*10,) float32 — one-hot of puzzle (unused by TRM, kept for compatibility)\n",
    "        sol_labels:    (81,) int64 — solution digits encoded as 0–8 (for CE)\n",
    "        puzzle_digits: (81,) int64 — puzzle digits 0–9 (0 = blank, 1–9 given)\n",
    "    \"\"\"\n",
    "    def __init__(self, split=\"train\", max_size=None):\n",
    "        ds = load_dataset(\"sapientinc/sudoku-extreme\", split=split)\n",
    "        if max_size:\n",
    "            ds = ds.select(range(min(max_size, len(ds))))\n",
    "        self.ds = ds\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.ds[idx]\n",
    "        q = row[\"question\"].replace(\".\", \"0\")  # '.' → '0' for blanks\n",
    "        a = row[\"answer\"]\n",
    "\n",
    "        puzzle = np.array([int(ch) for ch in q], dtype=np.int64)   # 0–9\n",
    "        sol    = np.array([int(ch) for ch in a], dtype=np.int64)   # 1–9\n",
    "\n",
    "        # One-hot puzzle (81×10) — not strictly needed for TRM, but kept\n",
    "        x = np.zeros((81, 10), dtype=np.float32)\n",
    "        for i, v in enumerate(puzzle):\n",
    "            x[i, v] = 1.0\n",
    "        x = x.reshape(81 * 10)\n",
    "\n",
    "        # Targets: 1–9 → 0–8\n",
    "        y = sol - 1\n",
    "\n",
    "        return x, y, puzzle  # (onehot, labels, puzzle_digits)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# TRM-style Blocks\n",
    "# ============================================================\n",
    "class TRMBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    A single TRM-style Transformer block:\n",
    "\n",
    "        z -> z + SelfAttention(LN(z))\n",
    "        z -> z + MLP(LN(z))\n",
    "\n",
    "    Applied repeatedly T times in TRMModel.\n",
    "    \"\"\"\n",
    "    def __init__(self, emb_dim=64, num_heads=4, mlp_hidden_dim=128, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.ln1 = nn.LayerNorm(emb_dim)\n",
    "        self.attn = nn.MultiheadAttention(\n",
    "            embed_dim=emb_dim,\n",
    "            num_heads=num_heads,\n",
    "            dropout=dropout,\n",
    "            batch_first=False,  # expects (L, B, D)\n",
    "        )\n",
    "        self.ln2 = nn.LayerNorm(emb_dim)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(emb_dim, mlp_hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(mlp_hidden_dim, emb_dim),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        \"\"\"\n",
    "        z: (B, L, D)\n",
    "        Returns: (B, L, D)\n",
    "        \"\"\"\n",
    "        B, L, D = z.shape\n",
    "\n",
    "        # Self-attention block with pre-LN\n",
    "        z_norm = self.ln1(z)               # (B, L, D)\n",
    "        z_attn_input = z_norm.transpose(0, 1)  # (L, B, D)\n",
    "        attn_out, _ = self.attn(z_attn_input, z_attn_input, z_attn_input)\n",
    "        attn_out = attn_out.transpose(0, 1)    # (B, L, D)\n",
    "        z = z + attn_out                      # Residual\n",
    "\n",
    "        # MLP block with pre-LN\n",
    "        z_norm = self.ln2(z)\n",
    "        mlp_out = self.mlp(z_norm)\n",
    "        z = z + mlp_out                       # Residual\n",
    "\n",
    "        return z\n",
    "\n",
    "\n",
    "class TRMModel(nn.Module):\n",
    "    \"\"\"\n",
    "    TRM-style Sudoku model:\n",
    "\n",
    "      - token_emb: 10 tokens (0–9), 0 = blank\n",
    "      - pos_emb:   81 positions (cells)\n",
    "      - z_0 = token_emb(puzzle_digits) + pos_emb\n",
    "      - Apply TRMBlock recursively T times\n",
    "      - Output head: LN(z_T) -> Linear -> 9 logits (digits 1–9) per cell\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        emb_dim=64,\n",
    "        num_heads=4,\n",
    "        mlp_hidden_dim=128,\n",
    "        num_layers=1,\n",
    "        T=8,        # number of recursive applications\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.emb_dim = emb_dim\n",
    "        self.T = T\n",
    "\n",
    "        # token embedding: digits 0–9\n",
    "        self.token_emb = nn.Embedding(10, emb_dim)\n",
    "\n",
    "        # positional embedding for 81 cells\n",
    "        self.pos_emb = nn.Embedding(81, emb_dim)\n",
    "\n",
    "        # TRM-style blocks\n",
    "        self.blocks = nn.ModuleList([\n",
    "            TRMBlock(emb_dim=emb_dim, num_heads=num_heads, mlp_hidden_dim=mlp_hidden_dim)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "\n",
    "        # final layer norm & output head\n",
    "        self.ln_out = nn.LayerNorm(emb_dim)\n",
    "        self.out_head = nn.Linear(emb_dim, 9)   # logits for digits 1–9\n",
    "\n",
    "    def forward(self, puzzle_digits):\n",
    "        \"\"\"\n",
    "        puzzle_digits: (B, 81), int64 in [0..9]\n",
    "        Returns:\n",
    "            logits: (B, 81, 9)\n",
    "        \"\"\"\n",
    "        device = puzzle_digits.device\n",
    "        B, L = puzzle_digits.shape\n",
    "        assert L == 81, \"Expecting 81 Sudoku cells\"\n",
    "\n",
    "        # token + positional embeddings\n",
    "        pos_ids = torch.arange(L, device=device).unsqueeze(0).expand(B, L)  # (B, 81)\n",
    "        z = self.token_emb(puzzle_digits) + self.pos_emb(pos_ids)           # (B, 81, D)\n",
    "\n",
    "        # Recursive Transformer updates: apply blocks T times\n",
    "        for _ in range(self.T):\n",
    "            for block in self.blocks:\n",
    "                z = block(z)\n",
    "\n",
    "        # Final normalization + output head\n",
    "        z = self.ln_out(z)                    # (B, 81, D)\n",
    "        logits = self.out_head(z)             # (B, 81, 9)\n",
    "        return logits\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Hessian Sharpness via Power Iteration\n",
    "# ============================================================\n",
    "def hessian_largest_eigval(\n",
    "    model,\n",
    "    loss_fn,\n",
    "    puzzle_digits,\n",
    "    y_labels,\n",
    "    device=\"cpu\",\n",
    "    num_iters=10,\n",
    "):\n",
    "    \"\"\"\n",
    "    Estimate the largest eigenvalue λ_max of the (mini-batch) Hessian of the loss\n",
    "    with respect to model parameters, using power iteration.\n",
    "\n",
    "    puzzle_digits: (B, 81), int64\n",
    "    y_labels:      (B, 81), int64 in [0..8]\n",
    "    \"\"\"\n",
    "    model_copy = copy.deepcopy(model).to(device)\n",
    "    model_copy.eval()\n",
    "    for p in model_copy.parameters():\n",
    "        p.requires_grad_(True)\n",
    "\n",
    "    puzzle_digits = puzzle_digits.to(device)\n",
    "    y_labels      = y_labels.to(device)\n",
    "\n",
    "    params = [p for p in model_copy.parameters() if p.requires_grad]\n",
    "\n",
    "    def grad_vec():\n",
    "        logits = model_copy(puzzle_digits)          # (B, 81, 9)\n",
    "        B, N, C = logits.shape\n",
    "        loss = loss_fn(logits.view(B * N, C), y_labels.view(B * N))\n",
    "        grads = torch.autograd.grad(\n",
    "            loss,\n",
    "            params,\n",
    "            create_graph=True,\n",
    "            allow_unused=True,  \n",
    "        )\n",
    "        g_flat = torch.cat([\n",
    "            (torch.zeros_like(p).view(-1) if g is None else g.view(-1))\n",
    "            for p, g in zip(params, grads)\n",
    "        ])\n",
    "        return g_flat\n",
    "\n",
    "    # Initial v\n",
    "    v = torch.randn_like(grad_vec())\n",
    "    v /= (v.norm() + 1e-12)\n",
    "\n",
    "    # Power iteration\n",
    "    for _ in range(num_iters):\n",
    "        g = grad_vec()\n",
    "        Hv = torch.autograd.grad(\n",
    "            g,\n",
    "            params,\n",
    "            grad_outputs=v,\n",
    "            retain_graph=True,\n",
    "            create_graph=True,\n",
    "            allow_unused=True,\n",
    "        )\n",
    "        Hv_flat = torch.cat([\n",
    "            (torch.zeros_like(p).view(-1) if h is None else h.view(-1))\n",
    "            for p, h in zip(params, Hv)\n",
    "        ])\n",
    "        v = Hv_flat / (Hv_flat.norm() + 1e-12)\n",
    "\n",
    "    # Rayleigh quotient: v^T H v\n",
    "    g = grad_vec()\n",
    "    Hv = torch.autograd.grad(\n",
    "        g,\n",
    "        params,\n",
    "        grad_outputs=v,\n",
    "        allow_unused=True,\n",
    "    )\n",
    "    Hv_flat = torch.cat([\n",
    "        (torch.zeros_like(p).view(-1) if h is None else h.view(-1))\n",
    "        for p, h in zip(params, Hv)\n",
    "    ])\n",
    "    eigval = torch.dot(v, Hv_flat).item()\n",
    "    return eigval\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Training Loop\n",
    "# ============================================================\n",
    "def train_trm_sudoku(\n",
    "    device=\"cpu\",\n",
    "    emb_dim=64,\n",
    "    num_heads=4,\n",
    "    mlp_hidden_dim=128,\n",
    "    num_layers=1,\n",
    "    T=8,\n",
    "    epochs=20,\n",
    "    batch_size=64,\n",
    "    lr=3e-4,\n",
    "    weight_decay=1e-4,\n",
    "    grad_clip=1.0,\n",
    "    num_train=2000,\n",
    "    num_test=500,\n",
    "    sharp_batch_size=64,\n",
    "    sharp_num_iters=10,\n",
    "    seed=42,\n",
    "):\n",
    "    # ----- Seeds -----\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "    # ----- Data -----\n",
    "    train_ds = SudokuHFDataset(\"train\", max_size=num_train)\n",
    "    test_ds  = SudokuHFDataset(\"test\",  max_size=num_test)\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "    test_loader  = DataLoader(test_ds,  batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "\n",
    "    # A fixed small batch for sharpness (from test set)\n",
    "    sharp_loader = DataLoader(test_ds, batch_size=sharp_batch_size, shuffle=False, drop_last=True)\n",
    "    sharp_x_onehot, sharp_y_labels, sharp_puzzle_digits = next(iter(sharp_loader))\n",
    "\n",
    "    sharp_puzzle_digits = sharp_puzzle_digits.to(device)\n",
    "    sharp_y_labels      = sharp_y_labels.to(device)\n",
    "\n",
    "    # ----- Model -----\n",
    "    model = TRMModel(\n",
    "        emb_dim=emb_dim,\n",
    "        num_heads=num_heads,\n",
    "        mlp_hidden_dim=mlp_hidden_dim,\n",
    "        num_layers=num_layers,\n",
    "        T=T,\n",
    "    ).to(device)\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "    train_losses = []\n",
    "    test_losses  = []\n",
    "    test_accs    = []\n",
    "    sharpness_vals = []\n",
    "\n",
    "    os.makedirs(\"results_trm\", exist_ok=True)\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        # -------- Train --------\n",
    "        for batch in tqdm(train_loader, desc=f\"Epoch {epoch}/{epochs}\", leave=False):\n",
    "            x_onehot, y_labels, puzzle_digits = batch  # x_onehot unused\n",
    "            puzzle_digits = puzzle_digits.to(device)   # (B, 81), digits 0–9\n",
    "            y_labels      = y_labels.to(device)        # (B, 81), labels 0–8\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            logits = model(puzzle_digits)              # (B, 81, 9)\n",
    "            B, N, C = logits.shape\n",
    "            loss = loss_fn(logits.view(B * N, C), y_labels.view(B * N))\n",
    "\n",
    "            loss.backward()\n",
    "            if grad_clip is not None:\n",
    "                nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        avg_train_loss = running_loss / len(train_loader)\n",
    "        train_losses.append(avg_train_loss)\n",
    "\n",
    "        # -------- Eval on test --------\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            test_loss = 0.0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for batch in test_loader:\n",
    "                x_onehot, y_labels, puzzle_digits = batch\n",
    "                puzzle_digits = puzzle_digits.to(device)\n",
    "                y_labels      = y_labels.to(device)\n",
    "\n",
    "                logits = model(puzzle_digits)\n",
    "                B, N, C = logits.shape\n",
    "                loss = loss_fn(logits.view(B * N, C), y_labels.view(B * N))\n",
    "                test_loss += loss.item()\n",
    "\n",
    "                preds = logits.argmax(dim=-1)  # (B, 81), in [0..8]\n",
    "                correct += (preds == y_labels).sum().item()\n",
    "                total   += y_labels.numel()\n",
    "\n",
    "            avg_test_loss = test_loss / len(test_loader)\n",
    "            test_losses.append(avg_test_loss)\n",
    "            test_acc = correct / total\n",
    "            test_accs.append(test_acc)\n",
    "\n",
    "        # -------- Hessian sharpness (λ_max) on fixed batch --------\n",
    "        lambda_max = hessian_largest_eigval(\n",
    "            model,\n",
    "            loss_fn,\n",
    "            sharp_puzzle_digits,\n",
    "            sharp_y_labels,\n",
    "            device=device,\n",
    "            num_iters=sharp_num_iters,\n",
    "        )\n",
    "        sharpness_vals.append(lambda_max)\n",
    "\n",
    "        print(\n",
    "            f\"Epoch {epoch:02d}/{epochs:02d} | \"\n",
    "            f\"train_loss={avg_train_loss:.4f}  \"\n",
    "            f\"test_loss={avg_test_loss:.4f}  \"\n",
    "            f\"cell-acc={test_acc*100:.2f}%  \"\n",
    "            f\"λ_max={lambda_max:.4f}\"\n",
    "        )\n",
    "\n",
    "    # ----- Save metrics -----\n",
    "    metrics_path = \"results_trm/trm_sudoku_metrics.npz\"\n",
    "    np.savez(\n",
    "        metrics_path,\n",
    "        train_losses=np.array(train_losses),\n",
    "        test_losses=np.array(test_losses),\n",
    "        test_accs=np.array(test_accs),\n",
    "        sharpness_vals=np.array(sharpness_vals),\n",
    "    )\n",
    "    print(f\"Saved metrics to '{metrics_path}'\")\n",
    "\n",
    "    # ----- Plots -----\n",
    "    # Loss\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.plot(train_losses, label=\"train_loss\")\n",
    "    plt.plot(test_losses, label=\"test_loss\")\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.title(\"TRM Sudoku – Loss\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    loss_plot_path = \"results_trm/trm_sudoku_loss.png\"\n",
    "    plt.savefig(loss_plot_path, dpi=300)\n",
    "    plt.show()\n",
    "    print(f\"Saved loss plot to '{loss_plot_path}'\")\n",
    "\n",
    "    # Accuracy\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.plot(test_accs, label=\"test cell accuracy\")\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.ylabel(\"accuracy\")\n",
    "    plt.title(\"TRM Sudoku – Test Cell Accuracy\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    acc_plot_path = \"results_trm/trm_sudoku_accuracy.png\"\n",
    "    plt.savefig(acc_plot_path, dpi=300)\n",
    "    plt.show()\n",
    "    print(f\"Saved accuracy plot to '{acc_plot_path}'\")\n",
    "\n",
    "    # Sharpness\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.plot(sharpness_vals, label=\"λ_max (Hessian sharpness)\")\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.ylabel(\"λ_max\")\n",
    "    plt.title(\"TRM Sudoku – Hessian Sharpness\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    sharp_plot_path = \"results_trm/trm_sudoku_sharpness.png\"\n",
    "    plt.savefig(sharp_plot_path, dpi=300)\n",
    "    plt.show()\n",
    "    print(f\"Saved sharpness plot to '{sharp_plot_path}'\")\n",
    "\n",
    "    # Save model\n",
    "    model_path = \"results_trm/trm_sudoku_model.pth\"\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    print(f\"Saved model to '{model_path}'.\")\n",
    "\n",
    "    return model, {\n",
    "        \"train_losses\": train_losses,\n",
    "        \"test_losses\": test_losses,\n",
    "        \"test_accs\": test_accs,\n",
    "        \"sharpness_vals\": sharpness_vals,\n",
    "    }\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Run\n",
    "# ============================================================\n",
    "if __name__ == \"__main__\":\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    model, logs = train_trm_sudoku(\n",
    "        device=device,\n",
    "        emb_dim=64,\n",
    "        num_heads=4,\n",
    "        mlp_hidden_dim=128,\n",
    "        num_layers=1,\n",
    "        T=8,                 # recursive depth, N_sup in JM 2025 paper\n",
    "        epochs=500,\n",
    "        batch_size=64,\n",
    "        lr=1e-3,\n",
    "        weight_decay=1e-4,\n",
    "        grad_clip=1.0,\n",
    "        num_train=5000,\n",
    "        num_test=1000,\n",
    "        sharp_batch_size=64,\n",
    "        sharp_num_iters=10,\n",
    "        seed=42,\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
